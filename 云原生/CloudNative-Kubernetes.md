# CloudNative



## ä»€ä¹ˆæ˜¯äº‘åŸç”Ÿï¼ˆCloud Nativeï¼‰?



**äº‘åŸç”Ÿï¼ˆCloud Nativeï¼‰æ˜¯ä¸€ç§è®¾è®¡ç†å¿µå’ŒæŠ€æœ¯æ¶æ„**ï¼Œæ—¨åœ¨å……åˆ†åˆ©ç”¨äº‘ç¯å¢ƒçš„ä¼˜åŠ¿ï¼Œæ¥å¼€å‘ã€éƒ¨ç½²å’Œç®¡ç†**é«˜æ•ˆã€å¼¹æ€§ã€å¯æ‰©å±•å’Œè‡ªåŠ¨åŒ–çš„ç°ä»£åŒ–åº”ç”¨ç¨‹åº**ã€‚

äº‘åŸç”Ÿçš„æ ¸å¿ƒç›®æ ‡æ˜¯è®©åº”ç”¨ç¨‹åºèƒ½å¤Ÿ**åŠ¨æ€è°ƒæ•´èµ„æº**ï¼Œå®ç°**é«˜å¯ç”¨æ€§**ã€**é«˜å¯æ‰©å±•æ€§**å’Œ**çµæ´»æ€§**ã€‚äº‘åŸç”Ÿçš„å®ç°é€šå¸¸ä¾èµ–äº**å®¹å™¨åŒ–æŠ€æœ¯ï¼ˆå¦‚Dockerï¼‰**ã€**ç¼–æ’ç³»ç»Ÿï¼ˆå¦‚Kubernetesï¼‰**ã€**å¾®æœåŠ¡æ¶æ„**å’Œ**æŒç»­äº¤ä»˜/é›†æˆï¼ˆCI/CDï¼‰**ç­‰æŠ€æœ¯ã€‚





## äº‘åŸç”Ÿçš„æ ¸å¿ƒæ€æƒ³



**æ¾è€¦åˆçš„æ¶æ„**

- ä¼ ç»Ÿçš„â€œå•ä½“åº”ç”¨â€ä¸â€œäº‘åŸç”Ÿåº”ç”¨â€æœ€å¤§çš„åŒºåˆ«æ˜¯ï¼Œäº‘åŸç”Ÿåº”ç”¨é€šè¿‡**å¾®æœåŠ¡**å°†æ¯ä¸ªæ¨¡å—ç‹¬ç«‹éƒ¨ç½²ã€ç‹¬ç«‹æ‰©ç¼©ã€‚
- äº‘åŸç”Ÿåº”ç”¨**æ¯ä¸ªæœåŠ¡æ¨¡å—ç‹¬ç«‹å¼€å‘ã€ç‹¬ç«‹æµ‹è¯•ã€ç‹¬ç«‹éƒ¨ç½²**ï¼Œäº’ä¸å½±å“ã€‚

**å£°æ˜å¼çš„API**

- äº‘åŸç”Ÿä½¿ç”¨**å£°æ˜å¼API**ï¼ˆDeclarative APIï¼‰ç®¡ç†åŸºç¡€æ¶æ„å’ŒæœåŠ¡ã€‚
- ä¾‹å¦‚ï¼ŒKubernetesä¸­çš„**YAMLæ–‡ä»¶**å°±æ˜¯å£°æ˜å¼APIçš„å…¸å‹ç¤ºä¾‹ï¼Œç”¨æˆ·åªéœ€è¦å£°æ˜æœŸæœ›çš„çŠ¶æ€ï¼Œè€Œä¸éœ€è¦å…³å¿ƒå¦‚ä½•å®ç°ã€‚

**è‡ªåŠ¨åŒ–è¿ç»´ (Self-Healing)**

- äº‘åŸç”Ÿåº”ç”¨ä¾èµ–**è‡ªåŠ¨åŒ–ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ**ã€‚
- Kubernetesä¸­çš„**é‡å¯ç­–ç•¥ã€å¥åº·æ£€æŸ¥ï¼ˆhealth checkï¼‰ã€å°±ç»ªæ¢é’ˆï¼ˆreadiness probeï¼‰**ï¼Œéƒ½å¯ä»¥å®ç°è‡ªåŠ¨æ¢å¤å’Œä¿®å¤ã€‚
- åœ¨å®¹å™¨å¤±è´¥ã€å´©æºƒæ—¶ï¼ŒKubernetesä¼š**è‡ªåŠ¨é‡å»ºPod**ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚

**å¼¹æ€§å’Œè‡ªé€‚åº”èƒ½åŠ›**

- äº‘åŸç”Ÿåº”ç”¨å…·å¤‡**è‡ªåŠ¨æ‰©å®¹å’Œç¼©å®¹**çš„èƒ½åŠ›ã€‚
- å½“æµé‡æ¿€å¢æ—¶ï¼ŒKuberneteså¯ä»¥åœ¨å‡ ç§’é’Ÿå†…**è‡ªåŠ¨æ‰©å±•Podæ•°é‡**ï¼Œå½“æµé‡ä¸‹é™æ—¶ï¼ŒPodæ•°é‡ä¼šè‡ªåŠ¨å‡å°‘ï¼Œé™ä½æˆæœ¬ã€‚

**åŸºç¡€è®¾æ–½å³ä»£ç  (IaC)**

- äº‘åŸç”Ÿå¼ºè°ƒ**ä¸€åˆ‡åŸºç¡€è®¾æ–½å’Œé…ç½®éƒ½è¦ä»¥ä»£ç çš„å½¢å¼å­˜åœ¨**ï¼Œè¿™ä½¿å¾—ç¯å¢ƒçš„åˆ›å»ºã€å˜æ›´å’Œé”€æ¯éƒ½å˜å¾—å¯è‡ªåŠ¨åŒ–ã€‚
- ä½¿ç”¨çš„å·¥å…·æœ‰**Terraform**ã€**Ansible**ã€**Helm**ç­‰ã€‚

**å¯è§‚æµ‹æ€§**

- åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œå¿…é¡»ç¡®ä¿ç³»ç»Ÿçš„**æ—¥å¿—ï¼ˆlogï¼‰**ã€**æŒ‡æ ‡ï¼ˆmetricsï¼‰\**å’Œ\**è¿½è¸ªï¼ˆtracingï¼‰**ã€‚
- ä½¿ç”¨Prometheusã€Grafanaç­‰å·¥å…·ï¼Œå¯ä»¥ç›´è§‚åœ°äº†è§£äº‘åŸç”Ÿç³»ç»Ÿçš„è¿è¡ŒçŠ¶æ€ï¼Œæ£€æµ‹ç“¶é¢ˆå’Œæ•…éšœç‚¹ã€‚





## äº‘åŸç”Ÿçš„å››å¤§æŠ€æœ¯åŸºçŸ³



**å®¹å™¨åŒ– (Containerization)**

- å®¹å™¨æ˜¯äº‘åŸç”Ÿçš„æœ€æ ¸å¿ƒæŠ€æœ¯ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªä¸æ“ä½œç³»ç»Ÿéš”ç¦»çš„è¿è¡Œç¯å¢ƒï¼Œä¾¿äº**è·¨å¹³å°éƒ¨ç½²**ã€‚
- **Docker** å’Œ **OCI å®¹å™¨**ï¼ˆå¦‚containerdã€Podmanï¼‰ç­‰å·¥å…·å°±æ˜¯å®¹å™¨åŒ–çš„å…¸å‹ä»£è¡¨ã€‚
- **å¥½å¤„**ï¼šæ›´å¿«çš„å¯åŠ¨ã€æ›´é«˜çš„èµ„æºåˆ©ç”¨ç‡ã€ç¯å¢ƒä¸€è‡´æ€§å’Œé«˜å¯ç§»æ¤æ€§ã€‚

**åŠ¨æ€ç¼–æ’ (Orchestration)**

- å®¹å™¨åŒ–çš„åº”ç”¨éœ€è¦ä¸€ä¸ªè°ƒåº¦å™¨æ¥ç®¡ç†è¿™äº›å®¹å™¨çš„**è‡ªåŠ¨éƒ¨ç½²ã€æ‰©ç¼©å®¹å’Œæ•…éšœä¿®å¤**ã€‚
- **Kubernetes**ï¼ˆK8sï¼‰å°±æ˜¯è¿™ç§è°ƒåº¦å™¨çš„ä»£è¡¨ã€‚
- Kuberneteså¯ä»¥ç®¡ç†**å¤šé›†ç¾¤çš„å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼æœåŠ¡**ï¼Œä»¥å®ç°è·¨äº‘å¹³å°çš„é«˜å¯ç”¨éƒ¨ç½²ã€‚

**å¾®æœåŠ¡æ¶æ„ (Microservices)**

- å°†åŸæœ¬çš„å•ä½“åº”ç”¨æ‹†è§£æˆå¤šä¸ª**å¯ç‹¬ç«‹å¼€å‘å’Œéƒ¨ç½²çš„å¾®æœåŠ¡**ï¼Œè¿™äº›å¾®æœåŠ¡é€šè¿‡**APIæˆ–æ¶ˆæ¯é˜Ÿåˆ—**è¿›è¡Œé€šä¿¡ã€‚
- å„å¾®æœåŠ¡å¯ä»¥å•ç‹¬éƒ¨ç½²ã€æ‰©å®¹ã€å›æ»šã€å‡çº§ï¼Œè€Œä¸å½±å“å…¶ä»–æ¨¡å—ã€‚

**æŒç»­äº¤ä»˜å’ŒæŒç»­é›†æˆ (CI/CD)**

- **CI/CD**ä½¿å¾—å¼€å‘äººå‘˜çš„ä»£ç å˜æ›´èƒ½å¤Ÿè¢«**è‡ªåŠ¨åŒ–æ„å»ºã€æµ‹è¯•å’Œéƒ¨ç½²**ã€‚
- ä½¿ç”¨çš„å·¥å…·æœ‰**Jenkins**ã€**GitLab CI/CD** å’Œ **ArgoCD** ç­‰ã€‚
- CI/CDæµæ°´çº¿å¯åœ¨å¼€å‘åˆ°ç”Ÿäº§çš„è¿‡ç¨‹ä¸­è¿›è¡Œ**è‡ªåŠ¨åŒ–éªŒè¯ã€å›æ»šå’Œç›‘æ§**ã€‚





## äº‘åŸç”Ÿçš„å…³é”®æŠ€æœ¯æ ˆ



| **é¢†åŸŸ**       | **æŠ€æœ¯**             | **ä½œç”¨**                             |
| -------------- | -------------------- | ------------------------------------ |
| **å®¹å™¨åŒ–**     | Docker, Podman       | æä¾›æ ‡å‡†çš„å®¹å™¨åŒ–è¿è¡Œç¯å¢ƒ             |
| **å®¹å™¨ç¼–æ’**   | Kubernetes (K8s)     | ç®¡ç†å’Œç¼–æ’å®¹å™¨ï¼Œæä¾›æ‰©ç¼©å®¹å’Œè‡ªæ„ˆèƒ½åŠ› |
| **å¾®æœåŠ¡**     | Spring Boot, Istio   | æ”¯æŒå¾®æœåŠ¡æ¶æ„                       |
| **CI/CD**      | Jenkins, GitLab CI   | æŒç»­äº¤ä»˜å’ŒæŒç»­é›†æˆ                   |
| **ç›‘æ§ä¸æ—¥å¿—** | Prometheus, Grafana  | ç›‘æ§ã€æ—¥å¿—ã€å‘Šè­¦ç³»ç»Ÿ                 |
| **ç½‘ç»œç®¡ç†**   | Calico, Flannel      | å®¹å™¨ç½‘ç»œ                             |
| **æœåŠ¡ç½‘æ ¼**   | Istio, Linkerd       | ç®¡ç†å¾®æœåŠ¡çš„é€šä¿¡ï¼Œæä¾›å¯è§‚å¯Ÿæ€§       |
| **å­˜å‚¨**       | Ceph, Rook, Longhorn | æä¾›äº‘åŸç”Ÿçš„åˆ†å¸ƒå¼å­˜å‚¨è§£å†³æ–¹æ¡ˆ       |
| **é…ç½®ç®¡ç†**   | Helm, Ansible        | ç®¡ç†åº”ç”¨å’Œé›†ç¾¤çš„é…ç½®                 |

------





## äº‘åŸç”Ÿçš„å®é™…åœºæ™¯



1. **ç”µå•†å¤§ä¿ƒé”€**
   - ä¿ƒé”€æ´»åŠ¨æµé‡é«˜å³°ï¼Œä½¿ç”¨Kubernetesçš„**HPAï¼ˆæ°´å¹³è‡ªåŠ¨æ‰©å±•ï¼‰**æ¥åŠ¨æ€æ‰©å±•æœåŠ¡å®ä¾‹ã€‚
   - æ—¥å¸¸æµé‡ä½æ—¶ï¼ŒPodæ•°é‡å‡å°‘ï¼Œ**èŠ‚çœè®¡ç®—èµ„æº**ã€‚
2. **é‡‘èæ”¯ä»˜ç³»ç»Ÿ**
   - **å¾®æœåŠ¡æ¶æ„**å¯å°†æ”¯ä»˜ç³»ç»Ÿæ‹†åˆ†ä¸ºå¤šä¸ªæœåŠ¡ï¼šç”¨æˆ·æœåŠ¡ã€æ”¯ä»˜æœåŠ¡ã€è®¢å•æœåŠ¡ç­‰ã€‚
   - **æœåŠ¡ç½‘æ ¼ï¼ˆå¦‚Istioï¼‰**å®ç°å¾®æœåŠ¡çš„æµé‡æ²»ç†ã€ç†”æ–­ã€æµé‡é™æµå’Œåˆ†å¸ƒå¼è¿½è¸ªã€‚
3. **DevOpså¹³å°**
   - ä½¿ç”¨**Jenkins + Docker + Kubernetes**ï¼Œæ„å»ºCI/CDæµæ°´çº¿ï¼Œè‡ªåŠ¨åŒ–éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒã€‚
   - **GitOps**ä½¿ç”¨**ArgoCD**ï¼Œå°†ä»£ç æäº¤åˆ°Gitåï¼Œè‡ªåŠ¨å®Œæˆéƒ¨ç½²ã€‚





## äº‘åŸç”Ÿçš„ä¼˜åŠ¿



| **ä¼˜åŠ¿**         | **æè¿°**                                       |
| ---------------- | ---------------------------------------------- |
| **æ•æ·æ€§**       | é€šè¿‡CI/CDæµæ°´çº¿å®ç°å¿«é€Ÿçš„è¿­ä»£å‘å¸ƒ              |
| **å¼¹æ€§æ‰©å±•**     | åŠ¨æ€æ‰©ç¼©å®¹ï¼Œæµé‡é«˜å³°æœŸè‡ªåŠ¨æ‰©å±•ï¼Œä½å³°æœŸç¼©å®¹     |
| **é«˜å¯ç”¨æ€§**     | æ•…éšœèŠ‚ç‚¹è‡ªåŠ¨æ¢å¤ï¼Œé¿å…å®•æœº                     |
| **å¤šäº‘/æ··åˆäº‘**  | æ”¯æŒè·¨äº‘éƒ¨ç½²ï¼Œé¿å…å•ä¸€äº‘æœåŠ¡å•†çš„é”å®š           |
| **èµ„æºåˆ©ç”¨ç‡é«˜** | ä½¿ç”¨å®¹å™¨åŒ–å’ŒKubernetesçš„èµ„æºè°ƒåº¦å®ç°èµ„æºæœ€ä¼˜åŒ– |



## äº‘åŸç”Ÿå®˜ç½‘

``````
https://www.cncf.io/
``````




# Skywalking












â€‹                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   

# Kubernetes



## Kubernetsé€»è¾‘æ¶æ„

![alt text](images/image15.png)



## Kubernetesç»„ä»¶



### Kubernetesç»„ä»¶é—´å®‰å…¨é€šä¿¡

![alt text](images/image28.png)



**Kubernetesé›†ç¾¤ä¸­æœ‰ä¸‰å¥—CAæœºåˆ¶**

- **etcd-ca**        ETCDé›†ç¾¤å†…éƒ¨çš„TLSé€šä¿¡
- **kubernetes-ca**    Kubernetesé›†ç¾¤å†…éƒ¨èŠ‚ç‚¹é—´çš„åŒå‘TLSé€šä¿¡
- **front-proxy-ca**    Kubernetesé›†ç¾¤ä¸å¤–éƒ¨æ‰©å±•æœåŠ¡ç®€å•åŒå‘TLSé€šä¿¡





#### è¯¦è§£Kubernetes-ca



**ç”¨é€”**ï¼šKubernetes é›†ç¾¤å†…éƒ¨çš„åŒå‘ TLS é€šä¿¡



**ä½œç”¨å’Œåœºæ™¯**

- **kubernetes-ca** æ˜¯ Kubernetes é›†ç¾¤çš„**ä¸»CA**ï¼Œä¸º**é›†ç¾¤æ ¸å¿ƒç»„ä»¶çš„å†…éƒ¨åŒå‘é€šä¿¡**æä¾› TLS è¯ä¹¦ã€‚
- å®ƒç¡®ä¿**é›†ç¾¤ä¸­çš„å„ä¸ªæ ¸å¿ƒç»„ä»¶ä¹‹é—´çš„åŒå‘ TLS é€šä¿¡æ˜¯å®‰å…¨çš„**ã€‚
- ç»„ä»¶é€šè¿‡ **kubernetes-ca** ç­¾å‘çš„è¯ä¹¦æ¥**éªŒè¯å½¼æ­¤çš„èº«ä»½**ï¼Œå¹¶ä¸”**æ‰€æœ‰çš„é€šä¿¡å†…å®¹éƒ½ä¼šåŠ å¯†**ã€‚
- ä¸»è¦ç”¨äº**Kubernetes æ§åˆ¶å¹³é¢ç»„ä»¶ã€å·¥ä½œèŠ‚ç‚¹å’Œå®¢æˆ·ç«¯**ä¹‹é—´çš„é€šä¿¡ã€‚



**ä¸»è¦å—æ§çš„ç»„ä»¶å’Œé€šä¿¡åœºæ™¯**

| **é€šä¿¡ç»„ä»¶1**      | **é€šä¿¡ç»„ä»¶2**               | **ä½¿ç”¨çš„è¯ä¹¦**        | **ä½¿ç”¨çš„CA**      |
| ------------------ | --------------------------- | --------------------- | ----------------- |
| **kube-apiserver** | **kubelet**                 | kubelet-client.crt    | **kubernetes-ca** |
| **kube-apiserver** | **kube-scheduler**          | scheduler-client.crt  | **kubernetes-ca** |
| **kube-apiserver** | **kube-controller-manager** | controller-client.crt | **kubernetes-ca** |
| **kube-apiserver** | **kubectlå®¢æˆ·ç«¯**           | kubectl.crt           | **kubernetes-ca** |
| **kube-apiserver** | **etcd**                    | etcd-client.crt       | **kubernetes-ca** |
| **kube-apiserver** | **service-account token**   | service-account.crt   | **kubernetes-ca** |
| **kubelet**        | **kube-apiserver**          | kubelet-server.crt    | **kubernetes-ca** |
| **kube-proxy**     | **kube-apiserver**          | kube-proxy-client.crt | **kubernetes-ca** |

> **ç¤ºä¾‹è§£é‡Šï¼š**

- **kube-apiserver å’Œ kubelet ä¹‹é—´çš„é€šä¿¡**ï¼š

  - kube-apiserver éœ€è¦ä½¿ç”¨å®¢æˆ·ç«¯è¯ä¹¦ï¼ˆ`kubelet-client.crt`ï¼‰é€šè¿‡åŒå‘TLSé€šä¿¡è®¿é—®å·¥ä½œèŠ‚ç‚¹çš„ kubelet APIã€‚
  - kubelet ä¹Ÿä¼šä½¿ç”¨æœåŠ¡å™¨è¯ä¹¦ï¼ˆ`kubelet-server.crt`ï¼‰æ¥ç¡®è®¤è‡ªå·±çš„èº«ä»½ã€‚
  - è¿™äº›è¯ä¹¦éƒ½ç”± **kubernetes-ca** ç­¾å‘ã€‚

- **kubectl å’Œ kube-apiserver çš„é€šä¿¡**ï¼š

  - ç”¨æˆ·çš„ kubectl å‘½ä»¤è¡Œå·¥å…·é€šè¿‡ TLS è¿æ¥åˆ° kube-apiserverï¼Œ**kubectl** ä½¿ç”¨çš„å®¢æˆ·ç«¯è¯ä¹¦ï¼ˆæˆ– KubeConfig æ–‡ä»¶ï¼‰ç”±**kubernetes-ca** ç­¾å‘ã€‚
  - è¿™ç¡®ä¿äº†**kubectl çš„ç”¨æˆ·èº«ä»½éªŒè¯**å’Œ**ä¸ API Server çš„é€šä¿¡åŠ å¯†**ã€‚

  

**å…¸å‹è¯ä¹¦**

- **kubernetes-ca.crt**ï¼šæ ¹ CA è¯ä¹¦ï¼Œæ‰€æœ‰çš„å­è¯ä¹¦éƒ½ç”±å®ƒç­¾å‘ã€‚
- **kube-apiserver.crt**ï¼škube-apiserver çš„æœåŠ¡å™¨è¯ä¹¦ã€‚
- **kube-apiserver-key.pem**ï¼škube-apiserver è¯ä¹¦çš„ç§é’¥ã€‚
- **kubelet.crt** å’Œ **kubelet-key.pem**ï¼škubelet æœåŠ¡å™¨è¯ä¹¦å’Œç§é’¥ã€‚
- **kube-controller-manager.crt**ï¼šcontroller manager ä½¿ç”¨çš„å®¢æˆ·ç«¯è¯ä¹¦ã€‚
- **kube-scheduler.crt**ï¼šscheduler ä½¿ç”¨çš„å®¢æˆ·ç«¯è¯ä¹¦ã€‚
- **kube-proxy.crt**ï¼škube-proxy ç»„ä»¶çš„å®¢æˆ·ç«¯è¯ä¹¦ã€‚



####  Front-proxy-ca

**ç”¨é€”ï¼š**ç”¨äº Kubernetes çš„ API èšåˆå±‚çš„ TLS é€šä¿¡



**ä½œç”¨å’Œåœºæ™¯**

- **front-proxy-ca** æ˜¯ä¸ºäº†æ”¯æŒ**Kubernetesçš„APIèšåˆå±‚**ï¼Œç¡®ä¿èšåˆå±‚ç»„ä»¶ï¼ˆå¦‚`metrics-server`å’Œ`custom-apis`ï¼‰çš„é€šä¿¡å®‰å…¨ã€‚
- å®ƒçš„ä¸»è¦ç›®çš„æ˜¯**ä¸ºAPIä»£ç†å’Œæ‰©å±•APIæœåŠ¡å™¨ï¼ˆå¦‚Aggregator Serverï¼‰ä¹‹é—´çš„åŒå‘é€šä¿¡æä¾›TLSåŠ å¯†å’Œèº«ä»½éªŒè¯**ã€‚
- è¿™ä½¿å¾—å¤–éƒ¨çš„ API å¯ä»¥æ— ç¼åœ°é›†æˆåˆ°Kubernetes APIä¸­ã€‚

> **API èšåˆå±‚çš„åœºæ™¯ï¼š**

- **metrics-server** æ˜¯ä¸€ä¸ªå¸¸è§çš„ç¤ºä¾‹ã€‚
- ç”¨æˆ·è°ƒç”¨ `kubectl top nodes` å‘½ä»¤ï¼Œkube-apiserver éœ€è¦**è½¬å‘è¯·æ±‚åˆ°metrics-server**ã€‚
- è¿™æ—¶ï¼Œkube-apiserver ä¼šä½¿ç”¨**front-proxy-client.crt** ä¸**metrics-server**é€šä¿¡ï¼Œç¡®ä¿æ•°æ®æ˜¯åŠ å¯†çš„ï¼Œå¹¶èƒ½**éªŒè¯metrics-serverçš„èº«ä»½**ã€‚





**ä¸»è¦å—æ§çš„ç»„ä»¶å’Œé€šä¿¡åœºæ™¯**

| **é€šä¿¡ç»„ä»¶1**      | **é€šä¿¡ç»„ä»¶2**          | **ä½¿ç”¨çš„è¯ä¹¦**         | **ä½¿ç”¨çš„CA**       |
| ------------------ | ---------------------- | ---------------------- | ------------------ |
| **kube-apiserver** | **APIèšåˆå±‚**          | front-proxy-client.crt | **front-proxy-ca** |
| **kube-apiserver** | **metrics-server**     | metrics-server.crt     | **front-proxy-ca** |
| **kube-apiserver** | **Custom API Service** | custom-api.crt         | **front-proxy-ca** |

> **ç¤ºä¾‹è§£é‡Šï¼š**

- **kube-apiserver å’Œ metrics-server çš„é€šä¿¡**ï¼š
  - kube-apiserver é€šè¿‡ TLS è¯·æ±‚ metrics-serverã€‚
  - metrics-server ä½¿ç”¨**front-proxy-ca** é¢å‘çš„è¯ä¹¦ï¼ˆå¦‚`metrics-server.crt`ï¼‰æ¥éªŒè¯è‡ªå·±çš„èº«ä»½ã€‚
  - **kube-apiserver ä¹Ÿä¼šä½¿ç”¨`front-proxy-client.crt` è¿›è¡Œè®¤è¯å’Œé€šä¿¡**ã€‚
- **kube-apiserver å’Œ Custom API Service çš„é€šä¿¡**ï¼š
  - ç”¨æˆ·å¯èƒ½ä¼šåœ¨é›†ç¾¤ä¸­éƒ¨ç½²ä¸€ä¸ª**è‡ªå®šä¹‰ API æ‰©å±•**ã€‚
  - è¿™æ—¶ï¼Œkube-apiserver ä½¿ç”¨**front-proxy-client.crt** è¿æ¥åˆ°**Aggregator Server**ï¼Œå¹¶é€šè¿‡TLSé€šä¿¡ä¸æ‰©å±•APIæœåŠ¡é€šä¿¡ã€‚





**å…¸å‹è¯ä¹¦**

- **front-proxy-ca.crt**ï¼šå‰ç«¯ä»£ç†CAçš„æ ¹è¯ä¹¦ã€‚
- **front-proxy-client.crt**ï¼škube-apiserver è¿æ¥ API èšåˆå±‚ï¼ˆå¦‚ metrics-serverï¼‰çš„è¯ä¹¦ã€‚
- **front-proxy-client-key.pem**ï¼škube-apiserver ä½¿ç”¨çš„å‰ç«¯ä»£ç†çš„ç§é’¥ã€‚



#### APIèšåˆå™¨æ˜¯ä»€ä¹ˆï¼Ÿ

API èšåˆå™¨æ˜¯ **kube-apiserver çš„ä¸€ä¸ªé€»è¾‘ç»„ä»¶**ï¼Œå®ƒçš„ä¸»è¦èŒè´£æ˜¯ï¼š

- **å°†ç¬¬ä¸‰æ–¹ API æœåŠ¡å’Œ Kubernetes è‡ªèº«çš„ API è¿›è¡Œèšåˆ**ã€‚
- **ç»Ÿä¸€æš´éœ² API ç«¯ç‚¹**ï¼Œä½¿å®¢æˆ·ç«¯ï¼ˆä¾‹å¦‚ `kubectl`ï¼‰å¯ä»¥åƒæ“ä½œåŸç”Ÿèµ„æºï¼ˆå¦‚Podã€Serviceï¼‰ä¸€æ ·æ“ä½œè‡ªå®šä¹‰çš„ API èµ„æºã€‚
- é€šè¿‡ `kubectl get`ã€`kubectl describe` ç­‰å‘½ä»¤ç®¡ç†è¿™äº›**éåŸç”Ÿèµ„æº**ã€‚
- **å°†å¤šä¸ª API æ‰©å±•çš„è·¯å¾„æŒ‚è½½åˆ° kube-apiserver** çš„ URL ç»“æ„ä¸­ï¼Œé€šå¸¸è·¯å¾„æ˜¯ `/apis/{API_GROUP}/{VERSION}/{RESOURCE}`ã€‚





**APIèšåˆå™¨çš„ä½ç½®å’Œä½œç”¨**

åœ¨ Kubernetes æ¶æ„ä¸­ï¼ŒAPI èšåˆå™¨æ˜¯**kube-apiserverçš„ä¸€éƒ¨åˆ†**ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒAPI èšåˆå™¨ä¸ kube-apiserver æ˜¯ä¸€ä½“çš„ã€‚

```lua
+------------------------------------------------------+
|                   kube-apiserver                     |
|                                                      |
|   +----------------+  +---------------------------+  |
|   | åŸç”Ÿ API èµ„æº  |  |   è‡ªå®šä¹‰ API èšåˆå±‚      |  |
|   | (pods, svc)    |  | (metrics-server, custom)  |  |
|   +----------------+  +---------------------------+  |
|                                                      |
+------------------------------------------------------+
                          |
                          |
         +------------------------------------+
         |           API èšåˆå™¨                |
         +------------------------------------+
                          |
                          |
         +----------------+      +------------------+
         | å¤–éƒ¨ API æœåŠ¡   |      | è‡ªå®šä¹‰APIæœåŠ¡    |
         +----------------+      +------------------+
```

------

**å…·ä½“çš„å·¥ä½œæµç¨‹**

1. **è¯·æ±‚çš„å‘èµ·**ï¼šå®¢æˆ·ç«¯ï¼ˆå¦‚ `kubectl top nodes`ï¼‰å‘èµ· API è¯·æ±‚ï¼Œè·¯å¾„ä¸º `/apis/metrics.k8s.io/v1beta1/nodes`ã€‚
2. **kube-apiserver è·¯ç”±**ï¼škube-apiserver è¯†åˆ«åˆ° `/apis/metrics.k8s.io/` æ˜¯**è‡ªå®šä¹‰APIè·¯å¾„**ï¼Œäºæ˜¯å°†è¯·æ±‚è½¬å‘åˆ°**APIèšåˆå™¨**ã€‚
3. APIèšåˆå™¨å·¥ä½œï¼š
   - APIèšåˆå™¨é€šè¿‡**front-proxy-client.crt** è¯ä¹¦ä¸**å¤–éƒ¨çš„æ‰©å±•APIæœåŠ¡å™¨**é€šä¿¡ã€‚
   - å°†è¯·æ±‚è½¬å‘åˆ°**æ‰©å±•APIæœåŠ¡**ï¼Œå¦‚**metrics-server**ã€‚
4. æ•°æ®è¿”å›ï¼š
   - æ‰©å±• API æœåŠ¡ï¼ˆå¦‚ metrics-serverï¼‰å¤„ç†è¯·æ±‚ï¼Œå¹¶è¿”å›**ç›‘æ§æ•°æ®**ã€‚
   - API èšåˆå™¨å°†æ•°æ®è¿”å›ç»™ kube-apiserverï¼Œæœ€ç»ˆè¿”å›ç»™ `kubectl`ã€‚





## Kubernetes ç‰ˆæœ¬

**é€šå¸¸æ¯å¹´æ›´æ–°å››ä¸ªå¤§ç‰ˆæœ¬,ä»v1.22åå·²ç»ä¿®æ”¹ä¸ºæ¯å¹´å‘å¸ƒ3ä¸ªå¤§ç‰ˆæœ¬** 

Kubernetes çš„ç‰ˆæœ¬ä»¥ X.Y.Z æ¨¡å¼å‘½åï¼Œå…¶ä¸­ X æ˜¯ä¸»ç‰ˆæœ¬å·ï¼ŒY æ˜¯å°ç‰ˆæœ¬å·ï¼ŒZ æ˜¯è¡¥ä¸ç‰ˆæœ¬å·ã€‚

 Kubernetes ä¸€æ¬¡æ”¯æŒä¸‰ä¸ªå°ç‰ˆæœ¬ï¼Œä¹Ÿå°±æ˜¯åªæ”¯æŒåŒ…å«å½“å‰çš„å‘å¸ƒç‰ˆæœ¬å’Œä¸¤ä¸ªä¹‹å‰çš„ç‰ˆæœ¬ã€‚ 

å‚é˜… GitHub ä¸Šçš„  Kubernetes Release é¡µé¢ä»¥è·å–æœ€æ–°çš„å‘å¸ƒä¿¡æ¯ã€‚





## Kubernetesæ‰©å±•æ¥å£
![alt text](images/image16.png)



Kubernetesæä¾›äº†ä¸‰ä¸ªç‰¹å®šåŠŸèƒ½çš„æ¥å£,kubernetesé€šè¿‡è°ƒç”¨è¿™å‡ ä¸ªæ¥å£ï¼Œæ¥å®Œæˆç›¸åº”çš„åŠŸèƒ½ã€‚

- **å®¹å™¨è¿è¡Œæ—¶æ¥å£CRI**: Container Runtime Interface 

  - CRI é¦–æ¬¡å‘å¸ƒäº2016å¹´12æœˆçš„Kubernetes 1.5 ç‰ˆæœ¬ã€‚ 

  - åœ¨æ­¤ç‰ˆæœ¬ä¹‹å‰ï¼ŒKubernetes ç›´æ¥ä¸ Docker é€šä¿¡ï¼Œæ²¡æœ‰æ ‡å‡†åŒ–çš„æ¥å£ã€‚ 

  - ä» Kubernetes 1.5 å¼€å§‹ï¼ŒCRI æˆä¸º Kubernetes ä¸å®¹å™¨è¿è¡Œæ—¶äº¤äº’çš„æ ‡å‡†æ¥å£ï¼Œä½¿å¾— Kubernetes  å¯ä»¥ä¸å„ç§å®¹å™¨è¿è¡Œæ—¶è¿›è¡Œé€šä¿¡ï¼Œä»è€Œå¢åŠ äº†çµæ´»æ€§å’Œå¯ç§»æ¤æ€§ã€‚

  - kubernetes å¯¹äºå®¹å™¨çš„è§£å†³æ–¹æ¡ˆï¼Œåªæ˜¯é¢„ç•™äº†å®¹å™¨æ¥å£ï¼Œåªè¦ç¬¦åˆCRIæ ‡å‡†çš„è§£å†³æ–¹æ¡ˆéƒ½å¯ä»¥ä½¿ç”¨

![alt text](images/image17.png)
![alt text](images/image18.png)



#### æ‰©å±•ï¼šdockershim æ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå®ƒä¼šæ¶ˆå¤±

``````
åœ¨ Kubernetes çš„æ—©æœŸï¼Œæˆ‘ä»¬åªæ”¯æŒä¸€ä¸ªå®¹å™¨è¿è¡Œæ—¶ã€‚é‚£ä¸ªè¿è¡Œæ—¶æ˜¯ Docker Engineã€‚å½“æ—¶ï¼Œæ²¡æœ‰å¤ªå¤šå…¶ä»–é€‰æ‹©ï¼ŒDocker æ˜¯å¤„ç†å®¹å™¨çš„ä¸»è¦å·¥å…·ï¼Œæ‰€ä»¥è¿™ä¸æ˜¯ä¸ªæœ‰äº‰è®®çš„é€‰æ‹©ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬å¼€å§‹æ·»åŠ æ›´å¤šçš„å®¹å™¨è¿è¡Œæ—¶ï¼Œæ¯”å¦‚ rkt å’Œ hypernetesï¼Œå¾ˆæ˜æ˜¾ Kubernetes ç”¨æˆ·å¸Œæœ›é€‰æ‹©æœ€é€‚åˆä»–ä»¬çš„è¿è¡Œæ—¶ã€‚å› æ­¤ Kubernetes éœ€è¦ç§æ–¹æ³•ï¼Œæ¥å…è®¸é›†ç¾¤æ“ä½œè€…çµæ´»åœ°ä½¿ç”¨ä»–ä»¬é€‰æ‹©çš„ä»»ä½•è¿è¡Œæ—¶ã€‚

å‘å¸ƒCRI[1]ï¼ˆContainer Runtime Interfaceï¼Œå®¹å™¨è¿è¡Œæ—¶æ¥å£ï¼‰å°±æ˜¯ä¸ºäº†æä¾›è¿™ç§çµæ´»æ€§ã€‚CRI çš„å¼•å…¥å¯¹é¡¹ç›®å’Œç”¨æˆ·æ¥è¯´éƒ½å¾ˆæ£’ï¼Œä½†å®ƒä¹Ÿå¼•å…¥äº†ä¸€ä¸ªé—®é¢˜ï¼šDocker Engine ä½œä¸ºå®¹å™¨è¿è¡Œæ—¶çš„ä½¿ç”¨æ—©äº CRIï¼ŒDocker Engine ä¸ CRI ä¸å…¼å®¹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ä¸ªå°è½¯ä»¶å«ç‰‡ï¼ˆ"shim"ï¼Œdockershimï¼‰ä½œä¸º kubelet ç»„ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œä¸“é—¨ç”¨äºå¡«è¡¥ Docker Engine å’Œ CRI ä¹‹é—´çš„ç©ºç™½ï¼Œå…è®¸é›†ç¾¤è¿è¥å•†ç»§ç»­ä½¿ç”¨ Docker Engine ä½œä¸ºä»–ä»¬çš„å®¹å™¨è¿è¡Œæ—¶ï¼ŒåŸºæœ¬ä¸Šä¸ä¼šç»™ä¸­æ–­ã€‚

ç„¶è€Œï¼Œè¿™ä¸ªå°å°çš„è½¯ä»¶å«ç‰‡ä»æ¥å°±ä¸æ˜¯æ°¸ä¹…çš„è§£å†³æ–¹æ¡ˆã€‚å¤šå¹´æ¥ï¼Œå®ƒçš„å­˜åœ¨ç»™ kubelet æœ¬èº«å¸¦æ¥äº†è®¸å¤šä¸å¿…è¦çš„å¤æ‚æ€§ã€‚ç”±äºè¿™ä¸ªå«ç‰‡ï¼ŒDocker çš„ä¸€äº›é›†æˆå®ç°ä¸ä¸€è‡´ï¼Œå¯¼è‡´ç»´æŠ¤äººå‘˜çš„è´Ÿæ‹…å¢åŠ ï¼Œå¹¶ä¸”ç»´æŠ¤ç‰¹å®šäºä¾›åº”å•†çš„ä»£ç ä¸ç¬¦åˆæˆ‘ä»¬çš„å¼€æºç†å¿µã€‚ä¸ºäº†å‡å°‘è¿™ç§ç»´æŠ¤è´Ÿæ‹…ï¼Œå¹¶å‘ä¸€ä¸ªæ”¯æŒå¼€æ”¾æ ‡å‡†çš„æ›´å…·åä½œæ€§çš„ç¤¾åŒºå‘å±•ï¼ŒKEP-2221 è·å¼•å…¥[2]ï¼Œå®ƒå»ºè®®å»æ‰ dockershimã€‚éšç€ Kubernetes v1.20 çš„å‘å¸ƒï¼Œè¿™ä¸€å¼ƒç”¨æˆä¸º
æ­£å¼ã€‚

æˆ‘ä»¬æ²¡æœ‰å¾ˆå¥½åœ°ä¼ è¾¾è¿™ä¸€ç‚¹ï¼Œä¸å¹¸çš„æ˜¯ï¼Œå¼ƒç”¨å£°æ˜å¯¼è‡´äº†ç¤¾åŒºå†…çš„ä¸€äº›ææ…Œã€‚å¯¹äº Docker ä½œä¸ºä¸€å®¶å…¬å¸æ¥è¯´è¿™æ„å‘³ç€ä»€ä¹ˆï¼Œç”± Docker æ„å»ºçš„å®¹å™¨é•œåƒèƒ½å¦è¿è¡Œï¼Œä»¥åŠ Docker Engine å®é™…æ˜¯ä»€ä¹ˆå¯¼è‡´äº†ç¤¾äº¤åª’ä½“ä¸Šçš„ä¸€åœºå¤§ç«ã€‚è¿™æ˜¯æˆ‘ä»¬çš„è¿‡å¤±ï¼›æˆ‘ä»¬åº”è¯¥æ›´æ¸…æ¥šåœ°æ²Ÿé€šå½“æ—¶å‘ç”Ÿäº†ä»€ä¹ˆä»¥åŠåŸå› ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªåšå®¢[3]å’Œç›¸å…³çš„å¸¸è§é—®é¢˜[4]ï¼Œä»¥å‡è½»ç¤¾åŒºçš„ææƒ§ï¼Œå¹¶çº æ­£ä¸€äº›å…³äº Docker æ˜¯ä»€ä¹ˆï¼Œä»¥åŠå®¹
å™¨å¦‚ä½•åœ¨ Kubernetes ä¸­å·¥ä½œçš„è¯¯è§£ã€‚ç”±äºç¤¾åŒºçš„å…³æ³¨ï¼ŒDocker å’Œ Mirantis å…±åŒåŒæ„ä»¥cridocker[5]çš„å½¢å¼ç»§ç»­æ”¯æŒ dockershim ä»£ç ï¼Œå…è®¸ä½ åœ¨éœ€è¦æ—¶ç»§ç»­ä½¿ç”¨ Docker Engine ä½œä¸ºä½ çš„å®¹å™¨è¿è¡Œæ—¶ã€‚ä¸ºäº†è®©é‚£äº›æƒ³å°è¯•å…¶ä»–è¿è¡Œæ—¶ï¼ˆå¦‚ containerd æˆ– cri-oï¼‰çš„ç”¨æˆ·æ„Ÿå…´è¶£ï¼Œç¼–å†™äº†è¿ç§»æ–‡æ¡£[6]ã€‚

æˆ‘ä»¬åæ¥å¯¹ç¤¾åŒºè¿›è¡Œäº†è°ƒæŸ¥[7]ï¼Œå‘ç°ä»ç„¶æœ‰è®¸å¤šç”¨æˆ·æœ‰é—®é¢˜å’Œé¡¾è™‘[8]ã€‚ä½œä¸ºå›åº”ï¼ŒKubernetes ç»´æŠ¤è€…å’ŒCNCF è‡´åŠ›äºé€šè¿‡æ‰©å±•æ–‡æ¡£å’Œå…¶ä»–ç¨‹åºæ¥è§£å†³è¿™äº›é—®é¢˜ã€‚äº‹å®ä¸Šï¼Œè¿™ç¯‡åšæ–‡å°±æ˜¯è¿™ä¸ªè®¡åˆ’çš„ä¸€éƒ¨åˆ†ã€‚éšç€å¦‚æ­¤å¤šçš„æœ€ç»ˆç”¨æˆ·æˆåŠŸåœ°è¿ç§»åˆ°å…¶ä»–è¿è¡Œæ—¶ï¼Œä»¥åŠæ–‡æ¡£çš„æ”¹è¿›ï¼Œæˆ‘ä»¬ç›¸ä¿¡ç°åœ¨æ¯ä¸ªäººéƒ½æœ‰äº†è¿ç§»çš„é“è·¯

æ— è®ºæ˜¯ä½œä¸ºå·¥å…·è¿˜æ˜¯ä½œä¸ºå…¬å¸ï¼ŒDocker éƒ½ä¸ä¼šæ¶ˆå¤±ã€‚å®ƒæ˜¯äº‘åŸç”Ÿç¤¾åŒºå’Œ Kubernetes é¡¹ç›®å†å²çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚æ²¡æœ‰ä»–ä»¬æˆ‘ä»¬ä¸ä¼šæœ‰ä»Šå¤©ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä» kubelet ä¸­ç§»é™¤ dockershim æœ€ç»ˆå¯¹ç¤¾åŒºã€ç”Ÿæ€ç³»ç»Ÿã€é¡¹ç›®å’Œæ•´ä¸ªå¼€æºéƒ½æœ‰å¥½å¤„ã€‚è¿™æ˜¯æˆ‘ä»¬æ‰€æœ‰äººä¸€èµ·æ”¯æŒå¼€æ”¾æ ‡å‡†çš„æœºä¼šï¼Œæˆ‘ä»¬å¾ˆé«˜å…´åœ¨ Docker å’Œç¤¾åŒºçš„å¸®åŠ©ä¸‹è¿™æ ·åšã€‚
``````



- æ–¹å¼1: Containerd 
  - é»˜è®¤æƒ…å†µä¸‹,Kubernetesåœ¨åˆ›å»ºé›†ç¾¤çš„æ—¶å€™,ä½¿ç”¨çš„å°±æ˜¯Containerd æ–¹å¼ã€‚ 
- æ–¹å¼2: Docker 
  - Docker Engine æ²¡æœ‰å®ç° CRIï¼Œ è€Œè¿™æ˜¯å®¹å™¨è¿è¡Œæ—¶åœ¨ Kubernetes ä¸­å·¥ä½œæ‰€éœ€è¦çš„ã€‚  å› æ­¤å¿…é¡»å®‰è£…ä¸€ä¸ªé¢å¤–çš„æœåŠ¡,æ—©æœŸä½¿ç”¨ç”±k8sæä¾›çš„dockershim,ä½†å®ƒåœ¨ 1.24 ç‰ˆæœ¬ä» kubelet ä¸­è¢« ç§»é™¤ è¿˜å¯ä»¥å€ŸåŠ©äºMirantisç»´æŠ¤çš„cri-dockerdæ’ä»¶æ–¹å¼æ¥å®ç°Kubernetesé›†ç¾¤çš„åˆ›å»ºã€‚ cri-dockerd é¡¹ç›®ç«™ç‚¹:  https://github.com/Mirantis/cri-dockerd 
- æ–¹å¼3: CRI-O 
  - 2016å¹´æˆç«‹,2019å¹´4æœˆ8å·åŠ å…¥CNCFå­µåŒ–ã€‚ CRI-Oçš„æ–¹å¼æ˜¯Kubernetesåˆ›å»ºå®¹å™¨æœ€ç›´æ¥çš„ä¸€ç§æ–¹å¼ åœ¨åˆ›å»ºé›†ç¾¤çš„æ—¶å€™,éœ€è¦å€ŸåŠ©äºcri-oæ’ä»¶çš„æ–¹å¼æ¥å®ç°Kubernetesé›†ç¾¤çš„åˆ›å»ºã€‚

![alt text](images/image19.png)
![alt text](images/image20.png)


- **å®¹å™¨ç½‘ç»œæ¥å£CN**I: Container Network Interface
  - kubernetes å¯¹äºç½‘ç»œçš„è§£å†³æ–¹æ¡ˆï¼Œåªæ˜¯é¢„ç•™äº†ç½‘ç»œæ¥å£ï¼Œåªè¦ç¬¦åˆCNIæ ‡å‡†çš„è§£å†³æ–¹æ¡ˆéƒ½å¯ä»¥ä½¿ç”¨
- **å®¹å™¨å­˜å‚¨æ¥å£CSI:** Container Storage Interface
  - kubernetes å¯¹äºå­˜å‚¨çš„è§£å†³æ–¹æ¡ˆï¼Œåªæ˜¯é¢„ç•™äº†å­˜å‚¨æ¥å£ï¼Œåªè¦ç¬¦åˆCSIæ ‡å‡†çš„è§£å†³æ–¹æ¡ˆéƒ½å¯ä»¥ä½¿ç”¨ æ­¤æ¥å£éå¿…é¡»





## Kubernetesé›†ç¾¤éƒ¨ç½²



### Kubernetes é›†ç¾¤ç»„ä»¶è¿è¡Œæ¨¡å¼

#### **ç‹¬ç«‹ç»„ä»¶æ¨¡å¼** 

- å„å…³é”®ç»„ä»¶éƒ½ä»¥äºŒè¿›åˆ¶æ–¹å¼éƒ¨ç½²äºä¸»æœºèŠ‚ç‚¹ä¸Šï¼Œå¹¶ä»¥å®ˆæŠ¤è¿›ç¨‹å½¢å¼è¿è¡Œ 
- å„é™„ä»¶Add-ons åˆ™ä»¥Podå½¢å¼è¿è¡Œ 
- éœ€è¦å®ç°å„ç§è¯ä¹¦çš„ç”³è¯·é¢å‘
-  éƒ¨ç½²è¿‡ç¨‹ç¹çå¤æ‚

![alt text](images/image21.png)



#### **é™æ€Podæ¨¡å¼**

- **kubeletå’Œå®¹å™¨è¿è¡Œæ—¶dockerä»¥äºŒè¿›åˆ¶éƒ¨ç½²ï¼Œè¿è¡Œä¸ºå®ˆæŠ¤è¿›ç¨‹**
- é™¤æ­¤ä¹‹å¤–æ‰€æœ‰ç»„ä»¶ä¸ºPod æ–¹å¼è¿è¡Œ

- æ§åˆ¶å¹³å°å„ç»„ä»¶ä»¥é™æ€Podå¯¹è±¡è¿è¡ŒäºMasterä¸»æœºä¹‹ä¸Š
- é™æ€Podç”±kubeletæ‰€æ§åˆ¶å®ç°åˆ›å»ºç®¡ç†,è€Œæ— éœ€ä¾èµ–kube-apiserverç­‰æ§åˆ¶å¹³å°ç»„ä»¶
- kube-proxyç­‰åˆ™ä»¥Podå½¢å¼è¿è¡Œ
- ç›¸å…³podæ—©æœŸæ˜¯ä»ä»“åº“k8s.gcr.ioä¸‹è½½é•œåƒï¼Œæ–°ç‰ˆæ”¹ä¸ºä»“åº“registry.k8s.io
- ä½¿ç”¨kuberneteså®˜æ–¹æä¾›çš„kubeadmå·¥å…·å®ç°kubernetesé›†ç¾¤æ–¹ä¾¿å¿«é€Ÿçš„éƒ¨ç½²

![alt text](images/image22.png)



### åŸºäºKubeadmå’Œ Docker éƒ¨ç½² kubernetes é«˜å¯ç”¨é›†ç¾¤


![alt text](images/image23.png)


å‚è€ƒæ–‡æ¡£ï¼š

``````
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/
https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md
``````



kubeadmæ˜¯Kubernetesç¤¾åŒºæä¾›çš„é›†ç¾¤æ„å»ºå·¥å…·

- è´Ÿè´£æ‰§è¡Œæ„å»ºä¸€ä¸ªæœ€å°åŒ–å¯ç”¨é›†ç¾¤å¹¶å°†å…¶å¯åŠ¨ç­‰å¿…è¦çš„åŸºæœ¬æ­¥éª¤
- Kubernetesé›†ç¾¤å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å·¥å…·ï¼Œå¯ç”¨äºå®ç°é›†ç¾¤çš„éƒ¨ç½²ã€å‡çº§/é™çº§åŠå¸è½½ç­‰
- kubeadmä»…å…³å¿ƒå¦‚ä½•åˆå§‹åŒ–å¹¶æ‹‰èµ·ä¸€ä¸ªé›†ç¾¤ï¼Œå…¶èŒè´£ä»…é™äºä¸‹å›¾ä¸­èƒŒæ™¯è“è‰²çš„éƒ¨åˆ†
- è“è‰²çš„éƒ¨åˆ†ä»¥å¤–çš„å…¶å®ƒç»„ä»¶è¿˜éœ€è¦è‡ªè¡Œéƒ¨ç½² 

![alt text](images/image24.png)

æ³¨æ„ï¼šåœ¨kubeadmæ–¹å¼å®‰è£…æ—¶ï¼ŒKubernetes çš„æ‰€æœ‰ç»„ä»¶ä¸­é™¤kubelet æ˜¯ä»¥ä¼ ç»ŸæœåŠ¡è¿›ç¨‹çš„æ–¹å¼è¿è¡Œï¼Œå…¶å®ƒéƒ½ä»¥å®¹å™¨è¿è¡Œ



#### éƒ¨ç½²ç¯å¢ƒè¯´æ˜

![alt text](images/image25.png)



| IP         | ä¸»æœºå           | è§’è‰²                                      |
| ---------- | ---------------- | ----------------------------------------- |
| 10.0.0.101 | master1.wang.org | K8s é›†ç¾¤ä¸»èŠ‚ç‚¹ 1ï¼ŒMasterå’Œetcd            |
| 10.0.0.102 | master2.wang.org | K8s é›†ç¾¤ä¸»èŠ‚ç‚¹ 2ï¼ŒMasterå’Œetcd            |
| 10.0.0.103 | master3.wang.org | K8s é›†ç¾¤ä¸»èŠ‚ç‚¹ 3ï¼ŒMasterå’Œetcd            |
| 10.0.0.104 | node1.wang.org   | K8s é›†ç¾¤å·¥ä½œèŠ‚ç‚¹ 1                        |
| 10.0.0.105 | node2.wang.org   | K8s é›†ç¾¤å·¥ä½œèŠ‚ç‚¹ 2                        |
| 10.0.0.106 | node3.wang.org   | K8s é›†ç¾¤å·¥ä½œèŠ‚ç‚¹ 3                        |
| 10.0.0.107 | ha1.wang.org     | K8s ä¸»èŠ‚ç‚¹è®¿é—®å…¥å£ 1,æä¾›é«˜å¯ç”¨åŠè´Ÿè½½å‡è¡¡ |
| 10.0.0.108 | ha2.wang.org     | K8s ä¸»èŠ‚ç‚¹è®¿é—®å…¥å£ 2,æä¾›é«˜å¯ç”¨åŠè´Ÿè½½å‡è¡¡ |
| 10.0.0.109 | harbor.wang.org  | å®¹å™¨é•œåƒä»“åº“                              |
| 10.0.0.100 | kubeapi.wang.org | VIPï¼Œåœ¨ha1å’Œha2ä¸»æœºå®ç°                   |

æ³¨æ„ï¼š MasterèŠ‚ç‚¹å†…å­˜è‡³å°‘2Gä»¥ä¸Šï¼Œå¦åˆ™åœ¨åˆå§‹åŒ–æ—¶ä¼šå‡ºé”™



#### ç½‘ç»œåœ°å€è§„åˆ’

``````bash
ç‰©ç†ä¸»æœºç½‘ç»œ        10.0.0.0/24 
é›†ç¾¤podç½‘ç»œ        --pod-network-cidr=10.244.0.0/16
åº”ç”¨serviceç½‘ç»œ    --service-cidr=10.96.0.0/12 
``````

![alt text](images/image26.png)



#### åŸºäº kubeadm å’Œ Docker å®ç°Kuberenetesé›†ç¾¤æµç¨‹è¯´æ˜

- æ¯ä¸ªèŠ‚ç‚¹ä¸»æœºçš„åˆå§‹ç¯å¢ƒå‡†å¤‡
- å‡†å¤‡ä»£ç†æœåŠ¡,ä»¥ä¾¿è®¿é—®k8s.gcr.ioï¼Œæˆ–æ ¹æ®éƒ¨ç½²è¿‡ç¨‹æç¤ºçš„æ–¹æ³•è·å–ç›¸åº”çš„Iå›½å†…é•œåƒçš„imageï¼ˆå¯é€‰ï¼‰
- Kubernetesé›†ç¾¤APIè®¿é—®å…¥å£çš„é«˜å¯ç”¨å’Œharborï¼ˆå¯é€‰ï¼‰
- **åœ¨æ‰€æœ‰Masterå’ŒNodeèŠ‚ç‚¹éƒ½å®‰è£…å®¹å™¨è¿è¡Œæ—¶ Docker**
- **åœ¨æ‰€æœ‰èŠ‚ç‚¹å®‰è£…å’Œé…ç½® cri-dockerd(kubernetes-v1.24ç‰ˆæœ¬ä»¥åéœ€è¦)**
- **åœ¨æ‰€æœ‰Masterå’ŒNodeèŠ‚ç‚¹éƒ½å®‰è£…kubeadm ã€kubeletã€kubectl(é›†ç¾¤ç®¡ç†å·¥å…·,åœ¨nodeèŠ‚ç‚¹å¯ ä¸å®‰è£…)**
- **åœ¨ç¬¬ä¸€ä¸ª master èŠ‚ç‚¹è¿è¡Œ kubeadm init åˆå§‹åŒ–å‘½ä»¤ ,å¹¶éªŒè¯ master èŠ‚ç‚¹çŠ¶æ€**
- **åœ¨ç¬¬ä¸€ä¸ª master èŠ‚ç‚¹å®‰è£…é…ç½®CNIè§„èŒƒçš„ç½‘ç»œæ’ä»¶**
- åœ¨å…¶å®ƒmasterèŠ‚ç‚¹è¿è¡Œkubeadm join å‘½ä»¤åŠ å…¥åˆ°æ§åˆ¶å¹³é¢é›†ç¾¤ä¸­å®ç°é«˜å¯ç”¨(æµ‹è¯•ç¯å¢ƒå¯é€‰)
- **åœ¨æ‰€æœ‰ node èŠ‚ç‚¹ä½¿ç”¨ kubeadm join å‘½ä»¤åŠ å…¥é›†ç¾¤ , å¹¶éªŒè¯ node èŠ‚ç‚¹çŠ¶æ€**
- åˆ›å»º pod å¹¶å¯åŠ¨å®¹å™¨æµ‹è¯•è®¿é—® ï¼Œå¹¶æµ‹è¯•ç½‘ç»œé€šä¿¡



#### åˆå§‹ç¯å¢ƒå‡†å¤‡

- ç¡¬ä»¶å‡†å¤‡ç¯å¢ƒ: æ¯ä¸ªä¸»æœºè‡³å°‘2Gä»¥ä¸Šå†…å­˜,CPU2æ ¸ä»¥ä¸Š
- æ“ä½œç³»ç»Ÿ: æœ€å°åŒ–å®‰è£…æ”¯æŒKubernetesçš„Linuxç³»ç»Ÿ
- å”¯ä¸€çš„ä¸»æœºåï¼ŒMACåœ°å€ä»¥åŠproduct_uuidå’Œä¸»æœºåè§£æ
- ä¿è¯å„ä¸ªèŠ‚ç‚¹ç½‘ç»œé…ç½®æ­£ç¡®,å¹¶ä¸”ä¿è¯é€šä¿¡æ­£å¸¸
- ç¦ç”¨ swap 
- ç¦ç”¨ SELinux
- æ”¾è¡ŒKubernetesä½¿ç”¨åˆ°çš„ç›¸å…³ç«¯å£æˆ–ç¦ç”¨firewalld/iptables
- é…ç½®æ­£ç¡®çš„æ—¶åŒºå’Œæ—¶é—´åŒæ­¥
- å†…æ ¸å‚æ•°ä¼˜åŒ– 
- æ‰€æœ‰èŠ‚ç‚¹å®ç°åŸºäº ssh key éªŒè¯(å¯é€‰)



**æ£€æŸ¥æ¯å°æœºå™¨çš„product_uuidï¼Œproject_uuidè¦å…·å¤‡å”¯ä¸€æ€§**

``````bash
[root@ubuntu2204 ~]#cat /sys/class/dmi/id/product_uuid
e0c84d56-f33b-6754-eab2-d5e7cb846dc1
 
[root@rocky8 ~]#cat /sys/class/dmi/id/product_uuid
10324d56-9c12-c716-dfa1-196e5242b4d3
``````





**æ¯å¤©æœºå™¨ä¸Šè®¾ç½®hostname,å¹¶é…ç½®/etc/hosts**

``````bash
# cat >> /etc/hosts <<EOF
10.0.0.100 kubeapi kubeapi.wang.org 
10.0.0.101 master1 master1.wang.org
10.0.0.102 master2 master2.wang.org
10.0.0.103 master3 master3.wang.org
10.0.0.104 node1 node1.wang.org
10.0.0.105 node2 node2.wang.org
10.0.0.106 node3 node3.wang.org
10.0.0.107 ha1 ha1.wang.org
10.0.0.108 ha2 ha2.wang.org
10.0.0.109 harbor harbor.wang.org
EOF
``````



**ä½¿ç”¨sshæ‰“é€šæ¯å°æœºå™¨**

``````bash
ssh-keygen

ssh-copy-id 127.0.0.1

for i in {101..108}; do scp -r .ssh 10.0.0.$i:/root/; done
``````



**è®¾ç½®æ¯å°ä¸»æœºçš„ä¸»æœºå**

``````bash
for i in {1..3} ;do ssh 10.0.0.10$i hostnamectl set-hostname master$i;done
for i in {4..6} ;do ssh 10.0.0.10$i hostnamectl set-hostname node$(($i-3));done
ssh 10.0.0.107 hostnamectl set-hostname ha1
ssh 10.0.0.108 hostnamectl set-hostname ha2
``````



**å®ç°ä¸»æœºæ—¶é—´åŒæ­¥**

``````bash
timedatectl set-timezone Asia/Shanghai

apt update
apt install  chrony -y

vim /etc/chrony/chrony.conf
 #åŠ ä¸‹é¢ä¸€è¡Œ
pool ntp.aliyun.com        iburst maxsources 2
pool ntp.ubuntu.com        iburst maxsources 4
pool 0.ubuntu.pool.ntp.org iburst maxsources 1
pool 1.ubuntu.pool.ntp.org iburst maxsources 1
pool 2.ubuntu.pool.ntp.org iburst maxsources 2

systemctl enable chrony
systemctl restart chrony
``````



 **å…³é—­SELinux**

``````bash
 ~# setenforce 0
 ~# sed -i 's#^\(SELINUX=\).*#\1disabled#' /etc/sysconfig/selinux
``````



**å…³é—­é˜²ç«å¢™**

``````bash
# Rocky
systemctl disable --now firewalld 

# Ubuntu
systemctl disable --now ufw
``````



 **ç¦ç”¨ Swap è®¾å¤‡**

``````bash
#æ–¹æ³•1
~# swapoff -a
~# sed -i  '/swap/s/^/#/' /etc/fstab
~# for i in {101..106};do ssh 10.0.0.$i "sed -i  '/swap/s/^/#/' /etc/fstab"; ssh 10.0.0.$i swapoff -a ; done

#æ–¹æ³•2
~# systemctl stop  swap.img.swap
~# systemctl mask swap.img.swap æˆ–è€… systemctl mask swap.target
 
#æ–¹æ³•3
~# systemctl mask swap.img.swap æˆ–è€… systemctl mask swap.target
~# reboot

#ç¡®è®¤æ˜¯å¦ç¦ç”¨swap
~# systemctl -t swap 
~# swapon -s 

``````



**å†…æ ¸ä¼˜åŒ–**  

æ ¹æ®ç¡¬ä»¶å’Œä¸šåŠ¡éœ€æ±‚,å¯¹å†…æ ¸å‚æ•°åšç›¸åº”çš„ä¼˜åŒ– 

æ³¨æ„:å®‰è£…dockeræ—¶ä¼šè‡ªåŠ¨ä¿®æ”¹å†…æ ¸å‚æ•°





#### å®ç°é«˜å¯ç”¨çš„åå‘ä»£ç†



**å®ç° keepalived**

åœ¨ä¸¤å°ä¸»æœºha1å’Œha2 æŒ‰ä¸‹é¢æ­¥éª¤éƒ¨ç½²å’Œé…ç½® keepalived

``````bash
[root@ha1 ~]#apt update && apt -y install keepalived 

#keepalivedé…ç½®
[root@ha1 ~]#cp  /usr/share/doc/keepalived/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf

[root@ha1 ~]#vim /etc/keepalived/keepalived.conf

! Configuration File for keepalived
global_defs {
  notification_email {
    acassen
  }
  notification_email_from Alexandre.Cassen@firewall.loc
  smtp_server 192.168.200.1
  smtp_connect_timeout 30
  router_id ha1.wang.org  #æŒ‡å®šrouter_id,#åœ¨ha2ä¸Šä¸ºha2.wang.org
}
vrrp_script check_haproxy {
   script "/etc/keepalived/check_haproxy.sh"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
vrrp_instance VI_1 {
   state MASTER              #åœ¨ha2ä¸Šä¸ºBACKUP        
   interface eth0
   garp_master_delay 10
   smtp_alert
   virtual_router_id 66      #æŒ‡å®šè™šæ‹Ÿè·¯ç”±å™¨ID,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ
   priority 100              #åœ¨ha2ä¸Šä¸º80          
   advert_int 1
   authentication {
       auth_type PASS
       auth_pass 123456      #æŒ‡å®šéªŒè¯å¯†ç ,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ  
   }
   virtual_ipaddress {
       10.0.0.100/24 dev eth0  label eth0:1  #æŒ‡å®šVIP,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ
   }
   track_script {
       check_haproxy 
   }
}
 [root@ha1 ~]#cat /etc/keepalived/check_haproxy.sh
 #!/bin/bash
 /usr/bin/killall -0 haproxy  || systemctl restart haproxy
 [root@ha1 ~]#chmod +x /etc/keepalived/check_haproxy.sh
 [root@ha1 ~]#hostname -I
 10.0.0.107 
[root@ha1 ~]#systemctl start keepalived.service 
#éªŒè¯keepalivedæœåŠ¡æ˜¯å¦æ­£å¸¸
``````





**å®ç° Haproxy**

é€šè¿‡ Harproxy å®ç° kubernetes Api-serverçš„å››å±‚åå‘ä»£ç†å’Œè´Ÿè½½å‡è¡¡åŠŸèƒ½

``````bash
#åœ¨ä¸¤å°ä¸»æœºha1å’Œha2éƒ½æ‰§è¡Œä¸‹é¢æ“ä½œ
[root@ha1 ~]#cat >> /etc/sysctl.conf <<EOF
net.ipv4.ip_nonlocal_bind = 1
EOF
root@ha1 ~]#sysctl -p 

#å®‰è£…é…ç½®haproxy
[root@ha1 ~]#apt -y install haproxy
[root@ha1 ~]#vim /etc/haproxy/haproxy.cfg 
[root@ha1 ~]#cat /etc/haproxy/haproxy.cfg

global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http

##########æ·»åŠ ä»¥ä¸‹å†…å®¹######################

listen stats
    mode http
    bind 0.0.0.0:8888
    stats enable
    log global
    stats uri /status
    stats auth admin:123456

listen  kubernetes-api-6443
    bind 10.0.0.100:6443
    mode tcp 
    server master1 10.0.0.101:6443 check inter 3s fall 3 rise 3 
    server master2 10.0.0.102:6443 check inter 3s fall 3 rise 3 
    server master3 10.0.0.103:6443 check inter 3s fall 3 rise 3 
``````



æµè§ˆå™¨è®¿é—®ï¼š http://ha2.wang.org:8888/status ï¼Œå¯ä»¥çœ‹åˆ°ä¸‹é¢ç•Œé¢


![alt text](images/image27.png)



#### åœ¨masterå’Œworkerä¸Šå®‰è£…docker

``````bash
# master
wget https://www.mysticalrecluse.com/script/Shell/install_docker_offline.sh
bash install_docker_offline.sh
``````



####  æ‰€æœ‰ä¸»æœºå®‰è£… cri-dockerd(v1.24ä»¥åç‰ˆæœ¬)

```````bash
wget https://mirror.ghproxy.com/https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.14/cri-dockerd_0.3.14.3-0.ubuntu-jammy_amd64.deb

# å¦‚æœå‡ºç°ä¾èµ–é—®é¢˜ï¼Œä½¿ç”¨è¯¥å‘½ä»¤ä¿®å¤
apt --fix-broken install -y

# å¦‚æœå‡ºç°å¦‚ä¸‹æŠ¥é”™
[root@ubuntu2204 ~]#systemctl status cri-docker.service 
â—‹ cri-docker.service - CRI Interface for Docker Application Container Engine
     Loaded: loaded (/lib/systemd/system/cri-docker.service; enabled; vendor preset: enabled)
     Active: inactive (dead)
TriggeredBy: Ã— cri-docker.socket
       Docs: https://docs.mirantis.com

12æœˆ 15 16:23:19 master2 systemd[1]: Dependency failed for CRI Interface for Docker Application Container Engine.
12æœˆ 15 16:23:19 master2 systemd[1]: cri-docker.service: Job cri-docker.service/start failed with result 'dependency'.

# è§£å†³æ–¹æ³•ï¼šæ·»åŠ dockerç»„
groupadd docker

# é‡å¯cri-docker
systemctl restart cri-docker.service
systemctl status cri-docker.service
```````





#### æ‰€æœ‰ä¸»æœºé…ç½® cri-dockerd(v1.24ä»¥åç‰ˆæœ¬

``````bash
# vim /lib/systemd/system/cri-docker.service
ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint fd:// --pod-infra-container-image registry.aliyuncs.com/google_containers/pause:3.9
``````





#### æ‰€æœ‰ master å’Œ node èŠ‚ç‚¹å®‰è£…kubeadmç­‰ç›¸å…³åŒ…

æ‰€æœ‰ master å’Œ node èŠ‚ç‚¹éƒ½å®‰è£…kubeadm, kubelet,kubectl ç›¸å…³åŒ…

æ³¨æ„: nodeèŠ‚ç‚¹å¯ä»¥ä¸å®‰è£…ç®¡ç†å·¥å…· kubectl åŒ…,ä½†ä¾èµ–å…³ç³»ä¼šè‡ªåŠ¨å®‰è£…



``````bash
# cat install_k8s.sh
#!/bin/bash
apt update && apt-get install -y apt-transport-https
curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/deb/ /" | tee /etc/apt/sources.list.d/kubernetes.list
apt-get update
apt-get install -y kubelet kubeadm kubectl
``````





#### åœ¨ç¬¬ä¸€ä¸ª master èŠ‚ç‚¹è¿è¡Œ kubeadm init åˆå§‹åŒ–å‘½ä»¤

``````
K8S_RELEASE_VERSION=1.30.2 && kubeadm init --control-plane-endpoint kubeapi.wang.org --kubernetes-version=v${K8S_RELEASE_VERSION} --pod-network-cidr 10.244.0.0/16 --service-cidr 10.96.0.0/12 --image-repository registry.aliyuncs.com/google_containers --token-ttl=0 --upload-certs --cri-socket=unix:///run/cri-dockerd.sock
``````



**å®Œæ•´å‘½ä»¤**

``````bash
K8S_RELEASE_VERSION=1.30.2 && kubeadm init --control-plane-endpoint master1.mystical.org --kubernetes-version=v${K8S_RELEASE_VERSION} --pod-network-cidr 10.244.0.0/16 --service-cidr 10.96.0.0/12 --image-repository registry.aliyuncs.com/google_containers --token-ttl=0 --upload-certs --cri-socket=unix:///run/cri-dockerd.sock
``````



**é€ä¸ªå­—æ®µçš„è¯¦ç»†è§£é‡Š**

1ï¸âƒ£ `K8S_RELEASE_VERSION=1.30.2`

- **å«ä¹‰**ï¼šå®šä¹‰ä¸€ä¸ªç¯å¢ƒå˜é‡ `K8S_RELEASE_VERSION`ï¼Œç”¨äºæŒ‡å®š Kubernetes ç‰ˆæœ¬ã€‚

- **ä½œç”¨**ï¼šåœ¨ `kubeadm init` å‘½ä»¤ä¸­ï¼Œé€šè¿‡ `${K8S_RELEASE_VERSION}` å¼•ç”¨è¿™ä¸ªå˜é‡ï¼Œç®€åŒ–ç‰ˆæœ¬æ§åˆ¶ï¼Œä¾¿äºæ›´æ–° Kubernetes ç‰ˆæœ¬ã€‚

- ç¤ºä¾‹ï¼š

  ```
  bashCopy codeK8S_RELEASE_VERSION=1.30.2
  echo $K8S_RELEASE_VERSION  # è¾“å‡º 1.30.2
  ```



2ï¸âƒ£ **`kubeadm init`**

- **å«ä¹‰**ï¼š`kubeadm init` å‘½ä»¤ç”¨äºåˆå§‹åŒ– Kubernetes æ§åˆ¶å¹³é¢ï¼ˆMaster èŠ‚ç‚¹ï¼‰ã€‚
- **ä½œç”¨**ï¼šè¯¥å‘½ä»¤åœ¨æ§åˆ¶èŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œåˆå§‹åŒ– Kubernetes é›†ç¾¤ï¼Œç”Ÿæˆ tokenã€è¯ä¹¦å’Œ Kubeconfig æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆ `kubeadm join` å‘½ä»¤ï¼Œä»¥ä¾¿å…¶ä»–èŠ‚ç‚¹åŠ å…¥é›†ç¾¤ã€‚



3ï¸âƒ£ **`--control-plane-endpoint kubeapi.wang.org`**

- **å«ä¹‰**ï¼šè®¾ç½® Kubernetes æ§åˆ¶å¹³é¢çš„**é«˜å¯ç”¨å…¥å£åœ°å€**ã€‚
- ä½œç”¨ï¼š
  - å¦‚æœä½ æœ‰å¤šä¸ª master æ§åˆ¶å¹³é¢èŠ‚ç‚¹ï¼Œéœ€è¦ä¸ºè¿™äº›æ§åˆ¶å¹³é¢æä¾›ä¸€ä¸ª**ç»Ÿä¸€çš„è®¿é—®å…¥å£**ã€‚
  - è¿™ä¸ªæ§åˆ¶å¹³é¢å…¥å£ï¼ˆ`kubeapi.wang.org`ï¼‰é€šå¸¸æ˜¯ä¸€ä¸ª **VIP (è™šæ‹ŸIP)**ï¼Œæˆ–è€…æ˜¯ä¸€ä¸ªå¯ä»¥è´Ÿè½½å‡è¡¡åˆ°å¤šä¸ªæ§åˆ¶å¹³é¢èŠ‚ç‚¹çš„ FQDNã€‚
  - è¿™æ ·ï¼ŒKubernetes é›†ç¾¤å†…çš„ kubelet åªéœ€è¿æ¥è¿™ä¸ªåŸŸåï¼Œ**ä¸éœ€è¦çŸ¥é“å…·ä½“çš„æ§åˆ¶å¹³é¢èŠ‚ç‚¹çš„ IP**ã€‚
- ç¤ºä¾‹ï¼š
  - å¦‚æœä½ æœ‰ 3 å°æ§åˆ¶å¹³é¢èŠ‚ç‚¹ï¼Œ`10.0.0.1, 10.0.0.2, 10.0.0.3`ï¼Œé‚£ä¹ˆä½ å¯ä»¥è®¾ç½®ä¸€ä¸ª VIP ä¾‹å¦‚ `10.0.0.100` å¹¶å°†åŸŸå `kubeapi.wang.org` è§£æä¸º `10.0.0.100`ã€‚
  - é€šè¿‡ **Keepalived** å’Œ **HAProxy**ï¼Œå¯ä»¥å°†è¯·æ±‚ä» `10.0.0.100` è½¬å‘åˆ° 3 å°æ§åˆ¶å¹³é¢èŠ‚ç‚¹ä¸­çš„ä»»æ„ä¸€ä¸ªã€‚



4ï¸âƒ£ **`--kubernetes-version=v${K8S_RELEASE_VERSION}`**

- **å«ä¹‰**ï¼šæŒ‡å®šè¦å®‰è£…çš„ Kubernetes ç‰ˆæœ¬ã€‚

- **ä½œç”¨**ï¼šå¼ºåˆ¶ kubeadm ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬çš„ Kubernetes ç»„ä»¶ã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --kubernetes-version=v1.30.2
  ```



5ï¸âƒ£ **`--pod-network-cidr 10.244.0.0/16`**

- **å«ä¹‰**ï¼šè®¾ç½® Pod ç½‘ç»œçš„ CIDR åœ°å€æ®µã€‚
- ä½œç”¨ï¼š
  - åœ¨ Kubernetes é›†ç¾¤ä¸­ï¼Œæ¯ä¸ª Pod éƒ½éœ€è¦æœ‰ä¸€ä¸ªå”¯ä¸€çš„ IP åœ°å€ã€‚
  - `--pod-network-cidr` æŒ‡å®šäº†**Pod IP åœ°å€æ®µ**ã€‚
  - è¯¥ IP åœ°å€æ®µè¢« CNIï¼ˆå¦‚ Flannelã€Calicoã€Weaveï¼‰ä½¿ç”¨ï¼Œé€šå¸¸ä¸ä¸æœåŠ¡å™¨çš„æœ¬åœ° IP åœ°å€å†²çªã€‚
- æ³¨æ„äº‹é¡¹ï¼š
  - Flannel é€šå¸¸ä½¿ç”¨ `10.244.0.0/16`ã€‚
  - Calico é»˜è®¤ä½¿ç”¨ `192.168.0.0/16`ã€‚
- ç¤ºä¾‹ï¼š
  - `--pod-network-cidr=10.244.0.0/16` è¡¨ç¤º Pod IP åœ°å€çš„èŒƒå›´æ˜¯ `10.244.0.0 - 10.244.255.255`ã€‚



6ï¸âƒ£ **`--service-cidr 10.96.0.0/12`**

- **å«ä¹‰**ï¼šæŒ‡å®š Service çš„è™šæ‹Ÿ IP åœ°å€æ®µã€‚

- ä½œç”¨ï¼š

  - åœ¨ Kubernetes ä¸­ï¼ŒService æ˜¯ä¸€ç§é›†ç¾¤å†…çš„**è™šæ‹Ÿ IP**ï¼Œè¿™äº› IP ä¸ä¸ç‰©ç†ä¸»æœº IP å†²çªã€‚
  - è¿™ä¸ª IP æ®µç”± kube-proxy å’Œ iptables ç»´æŠ¤ã€‚

- æ³¨æ„äº‹é¡¹ï¼š

  - Service IP åªèƒ½åœ¨**é›†ç¾¤å†…éƒ¨è®¿é—®**ã€‚
  - é€šå¸¸ä¸ä¸ç‰©ç†ç½‘ç»œ IP æ®µå†²çªã€‚
  - ä¸€èˆ¬æ˜¯ `10.96.0.0/12`ï¼Œè¡¨ç¤º `10.96.0.0 - 10.111.255.255` è¿™ä¸ªèŒƒå›´ã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --service-cidr=10.96.0.0/12
  ```





7ï¸âƒ£ **`--image-repository registry.aliyuncs.com/google_containers`**

- **å«ä¹‰**ï¼šæŒ‡å®š Kubernetes ç»„ä»¶é•œåƒçš„æ‹‰å–åœ°å€ã€‚

- ä½œç”¨ï¼š

  - ç”±äºå›½å†…æ— æ³•ç›´æ¥è®¿é—® **Google å®¹å™¨é•œåƒä»“åº“ (gcr.io)**ï¼Œæ‰€ä»¥ç”¨é˜¿é‡Œäº‘çš„é•œåƒæºã€‚
  - `registry.aliyuncs.com/google_containers` æ˜¯å›½å†…å¸¸ç”¨çš„é•œåƒæºï¼ŒåŒ…å«æ‰€æœ‰ Kubernetes ç›¸å…³çš„é•œåƒã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --image-repository registry.aliyuncs.com/google_containers
  ```





8ï¸âƒ£ **`--token-ttl=0`**

- **å«ä¹‰**ï¼šè®¾ç½® kubeadm join å‘½ä»¤ä¸­ Token çš„æœ‰æ•ˆæ—¶é—´ã€‚

- ä½œç”¨ï¼š

  - é»˜è®¤çš„ token è¿‡æœŸæ—¶é—´æ˜¯ 24 å°æ—¶ã€‚
  - é€šè¿‡ `--token-ttl=0`ï¼Œè¡¨ç¤ºç”Ÿæˆçš„ token**æ°¸ä¸è¿‡æœŸ**ã€‚
  - é€‚ç”¨äºé•¿æ—¶é—´éƒ¨ç½²èŠ‚ç‚¹ï¼Œæˆ–è€…éœ€è¦ä¸€æ®µæ—¶é—´å†…å¤šæ¬¡åŠ å…¥æ–°èŠ‚ç‚¹çš„åœºæ™¯ã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --token-ttl=0
  ```





9ï¸âƒ£ **`--upload-certs`**

- **å«ä¹‰**ï¼šå°†è¯ä¹¦ä¸Šä¼ åˆ°é›†ç¾¤ä¸­çš„æ§åˆ¶å¹³é¢èŠ‚ç‚¹ã€‚

- ä½œç”¨ï¼š

  - åœ¨é«˜å¯ç”¨é›†ç¾¤ä¸­ï¼Œæ§åˆ¶å¹³é¢èŠ‚ç‚¹ä¹‹é—´éœ€è¦å…±äº«è¯ä¹¦ã€‚
  - kubeadm ä¼šå°†è¯ä¹¦åŠ å¯†å­˜å‚¨åœ¨ **Kubernetes Secret** ä¸­ã€‚
  - é€šè¿‡è¿™ä¸ªå‚æ•°ï¼Œ**å…è®¸å…¶ä»–æ§åˆ¶å¹³é¢èŠ‚ç‚¹ä¸‹è½½è¿™äº›è¯ä¹¦**ã€‚

- ç¤ºä¾‹ï¼š

  ```
  --upload-certs
  ```





ğŸ”Ÿ **`--cri-socket=unix:///run/cri-dockerd.sock`**

- **å«ä¹‰**ï¼šæŒ‡å®š Kubelet è¿æ¥çš„ CRIï¼ˆå®¹å™¨è¿è¡Œæ—¶æ¥å£ï¼‰ã€‚

- ä½œç”¨ï¼š

  - Kubernetes æ”¯æŒå¤šä¸ª CRIï¼Œå¦‚ **containerd**ã€**cri-o** å’Œ **Docker**ã€‚
  - cri-dockerd æ˜¯ä¸€ä¸ªä¸“é—¨çš„ Docker CRI æ’ä»¶ã€‚
  - æ­¤é€‰é¡¹å‘Šè¯‰ Kubernetesï¼š**å°† Kubelet è¿æ¥åˆ° /run/cri-dockerd.sock**ã€‚

- æ³¨æ„ï¼š

  - å¦‚æœæœªæŒ‡å®šæ­¤é€‰é¡¹ï¼ŒKubelet å°†å°è¯•è‡ªåŠ¨æ£€æµ‹ CRIã€‚
  - cri-dockerd æ˜¯ç”¨äºä» Docker è½¬æ¢åˆ° Containerd çš„ä¸´æ—¶è§£å†³æ–¹æ¡ˆã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --cri-socket=unix:///run/cri-dockerd.sock
  ```





**æ€»ç»“**

| é€‰é¡¹                       | å«ä¹‰                 | ç¤ºä¾‹                           |
| -------------------------- | -------------------- | ------------------------------ |
| `--control-plane-endpoint` | æ§åˆ¶å¹³é¢çš„é«˜å¯ç”¨å…¥å£ | `kubeapi.feng.org`             |
| `--kubernetes-version`     | æŒ‡å®š Kubernetes ç‰ˆæœ¬ | `v1.30.2`                      |
| `--pod-network-cidr`       | æŒ‡å®š Pod IP åœ°å€æ®µ   | `10.244.0.0/16`                |
| `--service-cidr`           | Service IP åœ°å€æ®µ    | `10.96.0.0/12`                 |
| `--image-repository`       | å®¹å™¨é•œåƒä»“åº“         | `registry.aliyuncs.com`        |
| `--token-ttl`              | kubeadm token æœ‰æ•ˆæœŸ | `0` è¡¨ç¤ºæ°¸ä¸è¿‡æœŸ               |
| `--upload-certs`           | ä¸Šä¼ æ§åˆ¶å¹³é¢è¯ä¹¦     | **å¯ç”¨è¯ä¹¦å…±äº«**               |
| `--cri-socket`             | å®¹å™¨è¿è¡Œæ—¶æ¥å£ (CRI) | `unix:///run/cri-dockerd.sock` |



å¦‚æœè¿è¡Œå‡ºç°é—®é¢˜ï¼Œéœ€è¦é‡ç½®ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤

``````
kubeadm reset -f
``````



#### å°†å…¶ä»–çš„masterå’Œworkerä¸»æœºåŠ å…¥é›†ç¾¤



æ‰§è¡Œä¸Šè¿°åˆå§‹åŒ–å‘½ä»¤åï¼Œå¾—åˆ°å¦‚ä¸‹ç»“æœ

``````bash
############ è¿™éƒ¨åˆ†æ˜¯æˆæƒkubectlå‘½ä»¤ #######################################################
o start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

############## è¿™éƒ¨åˆ†æ˜¯masterèŠ‚ç‚¹åŠ å…¥é›†ç¾¤çš„å‘½ä»¤###############################

  kubeadm join kubeapi.wang.org:6443 --token jizd9o.tjfoyvdoisbklfi5 \
	--discovery-token-ca-cert-hash sha256:c27e15a7a39394b6d64e419b60df835f9dedb7b015a92c1d9285effa1fbea600 \
	--control-plane --certificate-key 9fa84696a800c6b995a9249972c1dd76735701e5ea2ae05191c9f612a0d1252c --cri-socket=unix:///run/cri-dockerd.sock # åé¢è¿½åŠ  --cri-socket=unix:///run/cri-dockerd.sock

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

############## è¿™éƒ¨åˆ†æ˜¯workerèŠ‚ç‚¹åŠ å…¥é›†ç¾¤çš„å‘½ä»¤###############################

kubeadm join kubeapi.wang.org:6443 --token jizd9o.tjfoyvdoisbklfi5 \
	--discovery-token-ca-cert-hash sha256:c27e15a7a39394b6d64e419b60df835f9dedb7b015a92c1d9285effa1fbea600 --cri-socket=unix:///run/cri-dockerd.sock # åé¢è¿½åŠ  --cri-socket=unix:///run/cri-dockerd.sock
``````



æ ¹æ®ä¸Šè¿°æŒ‡ä»¤åŠ masterä¸»æœºå’Œå…¶ä»–workerä¸»æœºåŠ å…¥é›†ç¾¤



#### å®‰è£…ç½‘ç»œæ’ä»¶flanny

``````bash
wget https://mirror.ghproxy.com/https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

# è¦ç¡®ä¿dockerå¯ä»¥æ‹‰å–é•œåƒï¼Œå»ºè®®å¼€ä»£ç†
kubectl apply -f kube-flannel.yml
``````



#### æŸ¥çœ‹æ˜¯å¦éƒ¨ç½²æˆåŠŸ

``````bash
[root@ubuntu2204 ~]#kubectl get nodes
NAME      STATUS   ROLES           AGE   VERSION
master1   Ready    control-plane   97m   v1.30.8
master2   Ready    control-plane   94m   v1.30.8
master3   Ready    control-plane   93m   v1.30.8
node1     Ready    <none>          92m   v1.30.8
node2     Ready    <none>          92m   v1.30.8
node3     Ready    <none>          92m   v1.30.8

``````



#### å¯ç”¨è‡ªåŠ¨è¡¥å…¨è„šæœ¬







### åŸºäºKubeadmå’ŒContainerdéƒ¨ç½²Kubernetes

éƒ¨ç½²ç¯å¢ƒUbuntu 22.04.X

```bash
root@k8s-master1
root@k8s-node1
root@k8s-node2
```



#### å®‰è£…è¿è¡Œæ—¶

```bash
# æ‰€æœ‰èŠ‚ç‚¹éƒ½éƒ¨ç½²containerdï¼Œruncï¼Œcniï¼Œnerdctlï¼ˆnodeèŠ‚ç‚¹é€‰åšï¼‰
[root@node1 ~]# bash k8s_containerd_runc_cni.sh

# æŸ¥çœ‹è„šæœ¬
#!/bin/bash

PROXY_IP=11.0.1.1
PROXY_PORT=10809
DIR=/usr/local/src

ubuntu_install_containerd() {
	if [ -e k8s_contaierd-2.0.4-runc-1.2.6-buildkit-0.20.2-nerdctl-2.0.4-cni-1.6.2.tar ];then
		echo -e "\e[1;32må®‰è£…åŒ…å·²å­˜åœ¨\e[0m"

        else
	        wget https://www.mysticalrecluse.com/script/tools/k8s_contaierd-2.0.4-runc-1.2.6-buildkit-0.20.2-nerdctl-2.0.4-cni-1.6.2.tar
	fi
	tar xf k8s_contaierd-2.0.4-runc-1.2.6-buildkit-0.20.2-nerdctl-2.0.4-cni-1.6.2.tar -C ${DIR}
	tar xf ${DIR}/containerd-2.0.4-linux-amd64.tar.gz -C /usr/local
	cat >/lib/systemd/system/containerd.service<<EOF
[Unit]
Description=containerd container runtime
Documentation=https://containerd.io
After=network.target local-fs.target dbus.service

[Service]
#uncomment to enable the experimental sbservice (sandboxed) version of containerd/cri integration
#Environment="ENABLE_CRI_SANDBOXES=sandboxed"
Environment="HTTP_PROXY=http://${PROXY_IP}:${PROXY_PORT}"
Environment="HTTPS_PROXY=http://${PROXY_IP}:${PROXY_PORT}"
ExecStartPre=-/sbin/modprobe overlay
ExecStart=/usr/local/bin/containerd

Type=notify
Delegate=yes
KillMode=process
Restart=always
RestartSec=5
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNPROC=infinity
LimitCORE=infinity
LimitNOFILE=infinity
# Comment TasksMax if your systemd version does not supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
OOMScoreAdjust=-999

[Install]
WantedBy=multi-user.target
EOF
    mkdir /etc/containerd -p
	containerd config default > /etc/containerd/config.toml
    systemctl daemon-reload
	systemctl restart containerd.service
	systemctl enable containerd.service
	chmod a+x ${DIR}/runc.amd64
	mv ${DIR}/runc.amd64 /usr/local/bin/runc
	tar xf ${DIR}/nerdctl-2.0.4-linux-amd64.tar.gz  -C /usr/local/bin
	tar xf ${DIR}/buildkit-v0.20.2.linux-amd64.tar.gz -C /usr/local/bin
	mkdir /etc/nerdctl
	cat > /etc/nerdctl/nerdctl.toml <<EOF
namespace    = "k8s.io"
debug        = false
debug_full   = false
insecure_registry = true
address = "/run/containerd/containerd.sock"
EOF
        mkdir /opt/cni/bin -p
	tar xf ${DIR}/cni-plugins-linux-amd64-v1.6.2.tgz -C /opt/cni/bin/
	if echo $? &>/dev/null ;then
	        echo -e "\e[1;32må®‰è£…åŒ…å·²å­˜åœ¨\e[0m"
	else
		echo -e "\e[1;31méƒ¨ç½²å¤±è´¥\e[0m"
	fi
    
}

ubuntu_install_containerd
```



#### éƒ¨ç½² kubeadmã€kubectlã€kubelet

```bash
# Debian/Ubuntu
apt-get update && apt-get install -y apt-transport-https
curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/deb/Release.key |
    gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb/ /" |
    tee /etc/apt/sources.list.d/kubernetes.list
apt-get update
apt-get install -y kubelet kubeadm kubectl

# CentOS / RHEL / Fedora
cat <<EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/repodata/repomd.xml.key
EOF
setenforce 0
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet && systemctl start kubelet
```



#### é…ç½®ä»£ç†

```bash
[root@master1 ~]# vim .bashrc
export http_proxy=http://11.0.1.1:10809
export https_proxy=http://11.0.1.1:10809
export no_proxy="localhost,127.0.0.1,::1,10.0.0.0/8,10.96.0.0/12,10.244.0.0/16,11.0.1.101,11.0.1.102,11.0.1.103,master1.mystical.org,node1.mystical.org,node2.mystical.org,192.168.0.0/16"

[root@master1 ~]# . .bashrc
```





#### ä¸‹è½½ Kubernetes é•œåƒ

æå‰ä¸‹è½½é•œåƒçš„å¥½å¤„ï¼šé˜²æ­¢åˆå§‹åŒ–çš„æ—¶å€™ç”±äºé•œåƒä¸‹è½½è¶…æ—¶è€ŒæŠ¥é”™

```bash
# æŸ¥çœ‹éœ€è¦çš„é•œåƒ
[root@master1 ~]# kubeadm config images list --kubernetes-version v1.32.0
registry.k8s.io/kube-apiserver:v1.32.0
registry.k8s.io/kube-controller-manager:v1.32.0
registry.k8s.io/kube-scheduler:v1.32.0
registry.k8s.io/kube-proxy:v1.32.0
registry.k8s.io/pause:3.9
registry.k8s.io/etcd:3.5.15-0
registry.k8s.io/coredns/coredns:v1.10.1

# ä¸‹è½½
[root@master1 ~]# cat images-down.sh 
#!/bin/bash
#nerdctl pull registry.k8s.io/kube-apiserver:v1.32.0
#nerdctl pull registry.k8s.io/kube-controller-manager:v1.32.0
#nerdctl pull registry.k8s.io/kube-scheduler:v1.32.0
#nerdctl pull registry.k8s.io/kube-proxy:v1.32.0
#nerdctl pull registry.k8s.io/pause:3.9
#nerdctl pull registry.k8s.io/etcd:3.5.15-0
#nerdctl pull registry.k8s.io/coredns/coredns:v1.10.1

nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.32.0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.32.0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.32.0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.32.0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.9
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.15-0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.10.1
```



#### å†…æ ¸å‚æ•°ä¼˜åŒ–

```bash
[root@master1 ~]# vim /etc/sysctl.conf
net.ipv4.ip_forward=1                     # æ•°æ®åŒ…è·¨ç½‘å¡ä¼ è¾“ï¼Œå¿…é¡»æ‰“å¼€
vm.max_map_count=262144
kernel.pid.max=4194303
fs.file-max=100000
net.ipv4.tcp_max_tw_buckets=6000
net.netfilter.nf_conntrack_max=2097152

net.bridge.bridge-nf-call-ip6tables=1
net.bridge.bridge-nf-call-iptables=1      # å†…æ ¸æ”¯æŒå¯¹ç½‘æ¡¥ä¸Šçš„æŠ¥æ–‡çš„æ£€æŸ¥ï¼Œå¿…é¡»æ‰“å¼€
vm.swappiness=0

[root@node1 ~]# sysctl --load

# å†…æ ¸æ¨¡å—å¼€æœºæŒ‚è½½
[root@master1 ~]# vim /etc/modules-load.d/modules.conf 
ip_vs
ip_vs_ls
ip_vs_lblc
ip_vs_lblcr
ip_vs_rr
ip_vs_wrr
ip_vs_sh
ip_vs_dh
ip_vs_fo
ip_vs_nq
ip_vs_sed
ip_vs_ftp
ip_vs_sh
ip_tables
ip_set
ipt_set
ipt_rpfilter
ipt_REJECT
ipip
xt_set
br_netfilter
nf_conntrack
overlay

# éªŒè¯å†…æ ¸æ¨¡å—ä¸å†…å­˜å‚æ•°
[root@master1 ~]# lsmod|grep br_netfilter

# ä¼˜åŒ–å†…æ ¸èƒ½æ‰“å¼€çš„æœ€å¤§æ–‡ä»¶æ•°ï¼ˆç”Ÿäº§ä¸­ä¸€å®šè¦åšï¼‰
[root@master1 ~]# vim /etc/security/limits.conf
root     soft   core  unlimited
root     hard   core  unlimited
root     soft   nproc  1000000
root     hard   nproc  1000000
root     soft   nofile 1000000
root     hard   nofile 1000000
root     soft   memlock 32000
root     hard   memlock 32000
root     soft   msgqueue 819200
root     hard   msgqueue 819200

# ä¿®æ”¹åé‡å¯
[root@master1 ~]# reboot
```



#### Kubernetes é›†ç¾¤åˆå§‹åŒ–

```bash
# è¿™é‡Œçš„ç‰ˆæœ¬ä¸€å®šè¦å’Œä¸Šé¢çš„kubeadmåŒ¹é…ï¼Œå¦åˆ™å®¹æ˜“æŠ¥é”™
k8s_release_version=1.32.0 && kubeadm init --control-plane-endpoint master1.mystical.org --kubernetes-version=v${k8s_release_version} --pod-network-cidr 192.168.0.0/16 --service-cidr 10.96.0.0/12 --token-ttl=0 --upload-certs

# åˆå§‹åŒ–
  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config
```



#### Kubernetes - åŸºäºinitæ–‡ä»¶åˆå§‹åŒ– - æ¨è

```bash
# kubeadm config print init-defaults # è¾“å‡ºé»˜è®¤åˆå§‹åŒ–é…ç½®
# kubeadm config print init-defaults > kubeadm-init.yaml  # å°†é»˜è®¤é…ç½®è¾“å‡ºè‡³æ–‡ä»¶
# cat kubeadm-init.yaml  # ä¿®æ”¹åçš„åˆå§‹åŒ–æ–‡ä»¶å†…å®¹
[root@master1 ~]# cat kubeadm-init.yaml 
apiVersion: kubeadm.k8s.io/v1beta4
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 11.0.1.101   # è¿™é‡Œæ”¹ä¸ºæŸä¸ªmasterä¸Šçš„IPåœ°å€ï¼Œä¸€èˆ¬ä¸ºå½“å‰masterçš„IPåœ°å€
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock  # è¿™é‡Œé»˜è®¤1.24å¼€å§‹ä½¿ç”¨containerd,è¿™é‡Œæ˜¯containerdçš„                                                                 socketæ–‡ä»¶
  imagePullPolicy: IfNotPresent
  imagePullSerial: true
  name: node
  taints: null
timeouts:
  controlPlaneComponentHealthCheck: 4m0s
  discovery: 5m0s
  etcdAPICall: 2m0s
  kubeletHealthCheck: 4m0s
  kubernetesAPICall: 1m0s
  tlsBootstrap: 5m0s
  upgradeManifests: 5m0s
---
apiServer: 
  timeoutForControlPlane: 4m0s       # è¿™é‡Œæ·»åŠ åˆå§‹åŒ–çš„è¶…æ—¶æ—¶é—´
apiVersion: kubeadm.k8s.io/v1beta4
caCertificateValidityPeriod: 87600h0m0s
certificateValidityPeriod: 8760h0m0s
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: IP:6443        # è‡ªè¡Œæ·»åŠ è¿™è¡Œï¼Œè¿™è¡Œæ˜¯ä¸€èˆ¬æ˜¯è´Ÿè½½å‡è¡¡å™¨çš„VIPç›‘å¬çš„ç«¯å£åœ°å€
                                     # å¦‚æœæ²¡æœ‰ä½¿ç”¨è´Ÿè½½å‡è¡¡å™¨ï¼Œè¿™é‡Œå¯ä»¥åˆ æ‰
controllerManager: {}
dns: {}
encryptionAlgorithm: RSA-2048
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.k8s.io      # é•œåƒä»“åº“ï¼Œå¯ä»¥æ¢æˆå›½å†…ä»“åº“ï¼Œæ¯”å¦‚ï¼š
                                      # registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: 1.32.0             # è¿™é‡Œå¯ä»¥æ¢æˆä½ æƒ³è£…çš„k8sç‰ˆæœ¬
networking:
  dnsDomain: cluster.local
  podSubnet: 10.200.0.0/16            # è‡ªè¡Œåœ¨è¿™é‡Œæ·»åŠ podç½‘ç»œç½‘æ®µï¼Œå’ŒCNIç½‘ç»œæ’ä»¶çš„ç½‘æ®µåœ°å€ä¸€è‡´
  serviceSubnet: 10.96.0.0/12
proxy: {}
scheduler: {}

--- # æŒ‡å®škubeletä½¿ç”¨systemd
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
cgroupDriver: systemd            # è¿™é‡Œè¦å’Œcontainerdçš„cgroupé©±åŠ¨ä¸€è‡´
                                 # å°¤å…¶æ˜¯ubuntu22.04ä¹‹åï¼Œcgroupä½¿ç”¨v2ï¼Œè¿™é‡Œå°±å¿…é¡»å¼ºè¡ŒæŒ‡å®šä¸ºsystemd

--- # æŒ‡å®šKubeproxyä½¿ç”¨ipvs
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs

# ä½¿ç”¨åˆå§‹åŒ–æ–‡ä»¶è¿›è¡Œåˆå§‹åŒ–
[root@master1 ~]# kubeadm init --config kubeadm-init.yaml   # åŸºäºæ–‡ä»¶æ‰§è¡Œk8s masteråˆå§‹åŒ–
```



##### è¡¥å……ï¼škubelet ä¸å®¹å™¨è¿è¡Œæ—¶çš„ cgroup driver è¦ä¸€è‡´

**èƒŒæ™¯ï¼šèµ„æºé™åˆ¶ä¾èµ–çš„ cgroup é©±åŠ¨**

- å®¹å™¨è¿è¡Œæ—¶å¦‚ `Docker`ã€`containerd` éƒ½ä½¿ç”¨ Linux çš„ **cgroup** å®ç°èµ„æºé™åˆ¶ï¼ˆå¦‚ CPUã€å†…å­˜ï¼‰ã€‚
- `cgroup` æœ¬èº«æœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼š**cgroup v1** å’Œ **cgroup v2**ã€‚
- å¯¹äºå¦‚ä½•**ç®¡ç†è¿™äº› cgroup çš„åˆ†å±‚ç»“æ„**ï¼Œå­˜åœ¨ä¸¤ç§ä¸»æµé©±åŠ¨æ–¹å¼ï¼š
  - **`cgroupfs`**ï¼ˆæ—©æœŸ Docker é»˜è®¤ï¼‰
  - **`systemd`**ï¼ˆKubernetes æ¨èï¼‰



**kubelet ä¸å®¹å™¨è¿è¡Œæ—¶çš„ cgroup driver è¦ä¸€è‡´**

 kubelet å’Œå®¹å™¨è¿è¡Œæ—¶ï¼ˆæ— è®ºæ˜¯ docker è¿˜æ˜¯ containerdï¼‰**å¿…é¡»ä½¿ç”¨åŒä¸€ç§ cgroup é©±åŠ¨**ï¼Œå¦åˆ™ pod ä¼šå› ä¸ºèµ„æºæ— æ³•é™åˆ¶æˆ–è¯†åˆ«è€Œè°ƒåº¦å¤±è´¥ã€‚



**æŸ¥çœ‹ containerd çš„ cgroup é©±åŠ¨**

**æŸ¥çœ‹ containerd é…ç½®æ–‡ä»¶**

æ‰“å¼€é…ç½®æ–‡ä»¶ `/etc/containerd/config.toml`ï¼Œæ‰¾åˆ°è¿™ä¸€æ®µï¼š

```toml
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
  SystemdCgroup = true
```

- `SystemdCgroup = true` è¡¨ç¤ºä½¿ç”¨ `systemd` é©±åŠ¨
- `SystemdCgroup = true` æˆ–ä¸å­˜åœ¨è¯¥å­—æ®µï¼Œåˆ™è¡¨ç¤ºä½¿ç”¨ `cgroupfs`



å¦‚æœæ²¡æœ‰è¯¥é…ç½®æ–‡ä»¶ï¼Œå¯è‡ªè¡Œåˆ›å»ºä¿®æ”¹

```bash
containerd config default > /etc/containerd/config.toml
```

ç„¶åç¼–è¾‘ `config.toml`ï¼Œæ‰‹åŠ¨åŠ ä¸Š `SystemdCgroup = true`ï¼š

```toml
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
  SystemdCgroup = true
```

âš ï¸ ä¿®æ”¹åè¯·åŠ¡å¿…é‡å¯ containerdï¼š

```bash
systemctl restart containerd
```



**åŒæ—¶åˆ«å¿˜äº†ç¡®ä¿ kubelet çš„é…ç½®ä¸€è‡´ï¼š**

```yaml
# /var/lib/kubelet/config.yaml
cgroupDriver: systemd
```

ä¹Ÿéœ€è¦é‡å¯ kubeletï¼š

```bash
systemctl restart kubelet
```



#### å°†nodeèŠ‚ç‚¹åŠ å…¥é›†ç¾¤

````bash
kubeadm join master1.mystical.org:6443 --token 75y4xk.fceeqawwqvujq7la \
	--discovery-token-ca-cert-hash sha256:441a979658ef2c8605752dbf7f87d15423963a25ec0099d09aea864e7821c88e
````



#### éƒ¨ç½²ç½‘ç»œæ’ä»¶Calico

```bash
curl https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/calico.yaml -o

# ç¼–è¾‘ä¿®æ”¹calico.yaml
# é€‰ç”¨çš„pod cidråŠå­ç½‘æ©ç é•¿åº¦  
- name: calico_ipv4pool_cidr
  vlaue: "192.168.0.0/16"
  name: calico_ipv4pool_block_size
  values: "24"

# é€‰ç”¨çš„è·¯ç”±æ¨¡å¼ï¼šalways, never, cross-subnet
env:
- name: IP_AUTODETECTION_METHOD   # æŒ‡å®šåŸºäºeth0çš„ç½‘å¡IPå»ºç«‹BGPè¿æ¥ï¼Œé»˜è®¤ä¸ºæœåŠ¡å™¨ç¬¬ä¸€å—
  value: "interface=eth0"
- name: calico_ipv4pool_ipip
  value: "always"
- name: calico_ipv4pool_vxlan
  value: "never"
- name: calico_ipv6pool_vxlan
  value: "never"
```

- æ‰§è¡Œcalicoçš„yaml

```shell
kubectl apply -f calico.yaml

# calicoéœ€è¦å°†.kube/configæ–‡ä»¶æ‹·è´åˆ°æ‰€æœ‰èŠ‚ç‚¹ï¼Œå› ä¸ºcalicoéœ€è¦åšè®¤è¯
scp .kube/config node1:
scp .kube/config node2:

# ä¸‹è½½calicoctl
curl -l https://github.com/projectcalico/calico/releases/download/v3.28.1/calicoctl-linux-amd64 -o calicoctl

# æˆæƒå¹¶åŠ å…¥pathå˜é‡
chmod +x ./calicoctl
mv calicoctl /usr/local/bin

# ä½¿ç”¨calicoctlæŸ¥çœ‹nodeçŠ¶æ€
[root@master1 ~]#calicoctl get node -o wide
name               asn       ipv4            ipv6   
master1.feng.org   (64512)   10.0.0.121/24          
worker1.feng.org   (64512)   10.0.0.122/24          
worker2.feng.org   (64512)   10.0.0.123/24          
worker3.feng.org   (64512)   10.0.0.124/24 
```





### äºŒè¿›åˆ¶éƒ¨ç½²é«˜å¯ç”¨k8sé›†ç¾¤éƒ¨ç½²

- å¤šmasterã€å®ç°masteré«˜å¯ç”¨å’Œé«˜æ€§èƒ½ï¼Œmasteræœ€å°‘ä¸‰ä¸ªï¼Œåˆ†å¸ƒåœ¨ä¸åŒå¯ç”¨åŒº
- å•ç‹¬çš„etcdåˆ†å¸ƒå¼é›†ç¾¤ï¼Œé«˜å¯ç”¨æŒä¹…åŒ–Kubernetesèµ„æºå¯¹è±¡æ•°æ®ï¼Œå¹¶å®ç°é«˜å¯ç”¨
  - etcdåº”è¯¥ä½¿ç”¨é«˜æ€§èƒ½ç¡¬ç›˜ï¼Œæ¯”å¦‚SSD
  - ä¹Ÿå¯ä»¥ä½¿ç”¨4å—10000-15000è½¬çš„SASç›˜åšraid10ï¼Œåœ¨ç»„raidçš„æ—¶å€™ï¼Œå»ºè®®åŒå‚å•†ï¼ŒåŒè§„æ ¼ï¼Œè‡³å°‘è¦ä¿è¯åŒè§„æ ¼
  - etcdæœ€å°‘ä¸‰ä¸ªï¼Œåˆ†å¸ƒåœ¨ä¸åŒå¯ç”¨åŒº
- å¤šnodeèŠ‚ç‚¹è¿è¡Œä¸šåŠ¡podï¼ŒnodeèŠ‚ç‚¹å¯ä»¥æ˜¯ä¸åŒç¡¬ä»¶è§„æ ¼ï¼Œå¦‚CPUèŠ‚ç‚¹ã€MemoryèŠ‚ç‚¹ï¼ŒGPUèŠ‚ç‚¹ï¼ŒBigdataèŠ‚ç‚¹ç­‰
- å„nodeèŠ‚ç‚¹é€šè¿‡è´Ÿè½½å‡è¡¡å™¨ä¸Masterç›¸è¿ï¼Œç”±è´Ÿè½½å‡è¡¡å™¨å®ç°å¯¹masterçš„è½®è¯¢è°ƒç”¨åŠçŠ¶æ€ç›‘æµ‹åŠè·¯éšœè½¬ç§»ï¼Œä»¥åœ¨masterå‡ºç°å®•æœºçš„æ—¶å€™ä¾ç„¶å¯ä»¥ä¿æŒnodeä¸masterçš„é€šä¿¡
  - åŒæ—¶å®ç°nodeèŠ‚ç‚¹ä¸masterèŠ‚ç‚¹ä¹‹é—´çš„è§£è€¦
  - è´Ÿè½½å‡è¡¡å™¨ä¼šè´Ÿè´£å¯¹masterå³åç«¯æœåŠ¡å™¨è¿›è¡Œå‘¨æœŸæ€§å¥åº·æ€§ç›‘æµ‹
- å„èŠ‚ç‚¹å¯å¼¹æ€§ä¼¸ç¼©

| ç±»å‹        | æœåŠ¡å™¨IP   | ä¸»æœºå               | VIP        |
| ----------- | ---------- | -------------------- | ---------- |
| K8S Master1 | 10.0.0.201 | master1.mystical.org | 10.0.0.200 |
| K8S Master2 | 10.0.0.202 | master2.mystical.org | rooroot    |
| K8S Master3 | 10.0.0.203 | master3.mystical.org |            |
| Harbor1     | 10.0.0.204 | harbor1.mystical.org |            |
| Harbor2     | 10.0.0.205 | harbor2.mystical.org |            |
| etcdèŠ‚ç‚¹1   | 10.0.0.206 | etcd1.mystical.org   |            |
| etcdèŠ‚ç‚¹2   | 10.0.0.207 | etcd2.mystical.org   |            |
| etcdèŠ‚ç‚¹3   | 10.0.0.208 | etcd3.mystical.org   |            |
| Haproxy1    | 10.0.0.209 | ha1.mystical.org     |            |
| Haproxy2    | 10.0.0.210 | ha2.mystical.org     |            |
| NodeèŠ‚ç‚¹1   | 10.0.0.211 | node1.mystical.org   |            |
| NodeèŠ‚ç‚¹2   | 10.0.0.212 | node2.mystical.org   |            |
| NodeèŠ‚ç‚¹3   | 100.0.213  | node3.mystical.org   |            |

- k8sé›†ç¾¤èŠ‚ç‚¹çš„ä¸»æœºåä¸€å®šä¸èƒ½ä¸€æ ·ï¼Œå¦åˆ™åæœŸkube-proxyä¼šå‡ºç°å¼‚å¸¸

- machine-idä¹Ÿä¸èƒ½ä¸€æ ·ï¼Œå¦‚æœä¸€æ ·éœ€è¦é‡æ–°ç”Ÿæˆä¸ä¸€æ ·çš„id

  ```bash
  rm -rf /etc/machine-id && dbus-uuidgen --ensure=/etc/machine-id && cat /etc/macheine-id
  ```

- åœ¨k8sé›†ç¾¤è¿™ä¸€å±‚ï¼Œmachine-idä¸€æ ·æ˜¯æ²¡é—®é¢˜çš„ï¼Œé‚£æ˜¯æœ‰äº›æœåŠ¡ä¼šå‡ºé—®é¢˜ï¼Œæ‰€ä»¥å»ºè®®æ‰€ä»¥èŠ‚ç‚¹çš„machine-idä¿®æ”¹ä¸ºä¸ä¸€æ ·çš„

- å‘etcd,zookeeperè¿™ç§æœåŠ¡ï¼Œå¹¶ä¸æ˜¯æœºå™¨è¶Šå¤šï¼Œæ€§èƒ½è¶Šå¼ºï¼Œå› ä¸ºä¼šæœ‰**å†™æ”¾å¤§**ç°è±¡ï¼Œå¦‚æœé›†ç¾¤æ•°é‡è¶Šå¤šï¼Œä¸€ä¸»å¤šå¤‡çš„æƒ…å†µä¸‹ï¼Œå‘ä¸»æ•°æ®åº“å†™å…¥æ•°æ®ï¼Œå®ƒä¼šå‘å…¶ä»–æ‰€æœ‰å¤‡ç”¨æ•°æ®åº“è¿›è¡Œå¤åˆ¶ï¼Œæ‰€ä»¥å¤‡ç”¨æ•°æ®åº“è¶Šå¤šï¼Œä¼šå¯¼è‡´å†™IOè¿‡å¤šï¼Œæ€§èƒ½å˜å·®



#### Linux Kernel å‡çº§ï¼ˆé€‰åšï¼‰

k8s,docker,ciliumç­‰å¾ˆå¤šåŠŸèƒ½ã€**ç‰¹æ€§éœ€è¦è¾ƒæ–°çš„linuxå†…æ ¸æ”¯æŒï¼Œæ‰€ä»¥æœ‰å¿…è¦åœ¨é›†ç¾¤éƒ¨ç½²å‰å¯¹å†…æ ¸è¿›è¡Œå‡çº§**ï¼›CentOS7 å’Œ Ubuntu16.04å¯ä»¥å¾ˆæ–¹ä¾¿çš„å®Œæˆå†…æ ¸å‡çº§ã€‚

##### CentOS7

çº¢å¸½ä¼ä¸šç‰ˆ Linux ä»“åº“ç½‘ç«™ [https://www.elrepo.orgï¼Œä¸»è¦æä¾›å„ç§ç¡¬ä»¶é©±åŠ¨ï¼ˆæ˜¾å¡ã€ç½‘å¡ã€å£°å¡ç­‰ï¼‰å’Œå†…æ ¸å‡çº§ç›¸å…³èµ„æºï¼›å…¼å®¹](https://www.elrepo.xn--org,();-2o3fa1948e1xbtycqzkwdwf25rn5cinbb925a0zdt91bfjp0v1chhnvsmjj7bb70codjwwk02l531a36exp2iil2ag45h/) CentOS7 å†…æ ¸å‡çº§ã€‚å¦‚ä¸‹æŒ‰ç…§ç½‘ç«™æç¤ºè½½å…¥elrepoå…¬é’¥åŠæœ€æ–°elrepoç‰ˆæœ¬ï¼Œç„¶åæŒ‰æ­¥éª¤å‡çº§å†…æ ¸ï¼ˆä»¥å®‰è£…é•¿æœŸæ”¯æŒç‰ˆæœ¬ kernel-lt ä¸ºä¾‹ï¼‰

```bash
# è½½å…¥å…¬é’¥
rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
# å®‰è£…ELRepo
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
# è½½å…¥elrepo-kernelå…ƒæ•°æ®
yum --disablerepo=\* --enablerepo=elrepo-kernel repolist
# æŸ¥çœ‹å¯ç”¨çš„rpmåŒ…
yum --disablerepo=\* --enablerepo=elrepo-kernel list kernel*
# å®‰è£…é•¿æœŸæ”¯æŒç‰ˆæœ¬çš„kernel
yum --disablerepo=\* --enablerepo=elrepo-kernel install -y kernel-lt.x86_64
# åˆ é™¤æ—§ç‰ˆæœ¬å·¥å…·åŒ…
yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64 -y
# å®‰è£…æ–°ç‰ˆæœ¬å·¥å…·åŒ…
yum --disablerepo=\* --enablerepo=elrepo-kernel install -y kernel-lt-tools.x86_64

#æŸ¥çœ‹é»˜è®¤å¯åŠ¨é¡ºåº
awk -F\' '$1=="menuentry " {print $2}' /etc/grub2.cfg  
CentOS Linux (4.4.183-1.el7.elrepo.x86_64) 7 (Core)  
CentOS Linux (3.10.0-327.10.1.el7.x86_64) 7 (Core)  
CentOS Linux (0-rescue-c52097a1078c403da03b8eddeac5080b) 7 (Core)
#é»˜è®¤å¯åŠ¨çš„é¡ºåºæ˜¯ä»0å¼€å§‹ï¼Œæ–°å†…æ ¸æ˜¯ä»å¤´æ’å…¥ï¼ˆç›®å‰ä½ç½®åœ¨0ï¼Œè€Œ4.4.4çš„æ˜¯åœ¨1ï¼‰ï¼Œæ‰€ä»¥éœ€è¦é€‰æ‹©0ã€‚
grub2-set-default 0  
#é‡å¯å¹¶æ£€æŸ¥
reboot
```



##### Ubuntu16.04

```bash
æ‰“å¼€ http://kernel.ubuntu.com/~kernel-ppa/mainline/ å¹¶é€‰æ‹©åˆ—è¡¨ä¸­é€‰æ‹©ä½ éœ€è¦çš„ç‰ˆæœ¬ï¼ˆä»¥4.16.3ä¸ºä¾‹ï¼‰ã€‚
æ¥ä¸‹æ¥ï¼Œæ ¹æ®ä½ çš„ç³»ç»Ÿæ¶æ„ä¸‹è½½ å¦‚ä¸‹.deb æ–‡ä»¶ï¼š
Build for amd64 succeeded (see BUILD.LOG.amd64):
  linux-headers-4.16.3-041603_4.16.3-041603.201804190730_all.deb
  linux-headers-4.16.3-041603-generic_4.16.3-041603.201804190730_amd64.deb
  linux-image-4.16.3-041603-generic_4.16.3-041603.201804190730_amd64.deb
#å®‰è£…åé‡å¯å³å¯
$ sudo dpkg -i *.deb
```



#### éƒ¨ç½² keepalived å’Œ haproxy

##### å®ç° keepalived

```bash
# haproxy1.mystical.org å’Œ haproxy2.mystical.org è¿™ä¸¤ä¸ªæœåŠ¡å™¨ä¸Šéƒ¨ç½²
[root@haproxy1 ~]#apt install -y keepalived haproxy

# ä½¿ç”¨keepalivedé…ç½®vip
[root@haproxy1 ~]#cp  /usr/share/doc/keepalived/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf

[root@haproxy1 ~]#vim /etc/keepalived/keepalived.conf

! Configuration File for keepalived
global_defs {
  notification_email {
    acassen
  }
  notification_email_from Alexandre.Cassen@firewall.loc
  smtp_server 192.168.200.1
  smtp_connect_timeout 30
  router_id ha1.wang.org  #æŒ‡å®šrouter_id,#åœ¨ha2ä¸Šä¸ºha2.wang.org
}
vrrp_script check_haproxy {
   script "/etc/keepalived/check_haproxy.sh"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
vrrp_instance VI_1 {
   state MASTER              #åœ¨ha2ä¸Šä¸ºBACKUP        
   interface eth0
   garp_master_delay 10
   smtp_alert
   virtual_router_id 66      #æŒ‡å®šè™šæ‹Ÿè·¯ç”±å™¨ID,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ
   priority 100              #åœ¨ha2ä¸Šä¸º80          
   advert_int 1
   authentication {
       auth_type PASS
       auth_pass 123456      #æŒ‡å®šéªŒè¯å¯†ç ,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ  
   }
   virtual_ipaddress {
        10.0.0.88/24 dev eth0 label eth0:0   # è¿™é‡Œæ˜¯k8s-masterçš„vip
        10.0.0.89/24 dev eth0 label eth0:1   # åç»­æœåŠ¡çš„vipï¼Œç”¨äºæµ‹è¯•k8sä¸­çš„vipèƒ½å¦è®¿é—®
        10.0.0.90/24 dev eth0 label eth0:2   # åç»­æœåŠ¡çš„vipï¼Œç”¨äºæµ‹è¯•k8sä¸­çš„vipèƒ½å¦è®¿é—®
        10.0.0.91/24 dev eth0 label eth0:3   # åç»­æœåŠ¡çš„vipï¼Œç”¨äºæµ‹è¯•k8sä¸­çš„vipèƒ½å¦è®¿é—®

   }
   track_script {
       check_haproxy 
   }
}
 [root@ha1 ~]#cat /etc/keepalived/check_haproxy.sh
 #!/bin/bash
 /usr/bin/killall -0 haproxy  || systemctl restart haproxy
 [root@ha1 ~]#chmod +x /etc/keepalived/check_haproxy.sh
 [root@ha1 ~]#hostname -I
 10.0.0.107 
[root@ha1 ~]#systemctl start keepalived.service 
#éªŒè¯keepalivedæœåŠ¡æ˜¯å¦æ­£å¸¸

# å¯ç”¨å¼€æœºè‡ªå¯
[root@haproxy1 ~]# systemctl enable keepalived
Synchronizing state of keepalived.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable keepalived
```



**å®ç° Haproxy**

é€šè¿‡ Harproxy å®ç° kubernetes Api-serverçš„å››å±‚åå‘ä»£ç†å’Œè´Ÿè½½å‡è¡¡åŠŸèƒ½

``````bash
#åœ¨ä¸¤å°ä¸»æœºha1å’Œha2éƒ½æ‰§è¡Œä¸‹é¢æ“ä½œ
# ä¸‹é¢çš„å†…æ ¸å‚æ•°å¿…é¡»ä¿®æ”¹ï¼Œå› ä¸ºhaproxyé»˜è®¤ä¸èƒ½ç›‘å¬æœ¬æœºæ²¡æœ‰çš„ipï¼ŒåŠ ä¸Šå¼€å¯ä¸‹é¢çš„å†…æ ¸å‚æ•°ï¼Œæ‰èƒ½å…è®¸
[root@ha1 ~]#cat >> /etc/sysctl.conf <<EOF
net.ipv4.ip_nonlocal_bind = 1
EOF
root@ha1 ~]#sysctl -p 

#å®‰è£…é…ç½®haproxy
[root@ha1 ~]#apt -y install haproxy
[root@ha1 ~]#vim /etc/haproxy/haproxy.cfg 
[root@ha1 ~]#cat /etc/haproxy/haproxy.cfg

global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http

##########æ·»åŠ ä»¥ä¸‹å†…å®¹######################

listen stats
    mode http
    bind 0.0.0.0:8888
    stats enable
    log global
    stats uri /status
    stats auth admin:123456

listen  kubernetes-api-6443
    bind 10.0.0.88:6443
    mode tcp 
    server master1 10.0.0.201:6443 check inter 3s fall 3 rise 3 
    server master2 10.0.0.202:6443 check inter 3s fall 3 rise 3 
    server master3 10.0.0.203:6443 check inter 3s fall 3 rise 3 
``````



æµè§ˆå™¨è®¿é—®ï¼š http://ha2.wang.org:8888/status ï¼Œå¯ä»¥çœ‹åˆ°ä¸‹é¢ç•Œé¢



#### éƒ¨ç½²harbor

##### ç”³è¯·è¯ä¹¦ï¼ˆç”Ÿäº§ç¯å¢ƒä¸­ä¸å»ºè®®ä½¿ç”¨è‡ªç­¾è¯ä¹¦ï¼‰

è¦ä½¿ç”¨httpsçš„harborï¼Œå»ºè®®ä½¿ç”¨å•†ä¸šç‰ˆçš„è¯ä¹¦ï¼Œè€Œä¸æ˜¯è‡ªç­¾è¯ä¹¦

åœ¨é˜¿é‡Œäº‘æˆ–è…¾è®¯äº‘ä¹°ä¸ªåŸŸåï¼Œæœ‰å…è´¹è¯ä¹¦é¢åº¦ï¼Œå¯ä»¥ä½¿ç”¨å…è´¹è¯ä¹¦

![image-20250407091828813](../markdown_img/image-20250407091828813.png)

![image-20250407092306507](../markdown_img/image-20250407092306507.png)

![image-20250407092332226](../markdown_img/image-20250407092332226.png)

![image-20250407110939341](../markdown_img/image-20250407110939341.png)

![image-20250407111225625](../markdown_img/image-20250407111225625.png)



##### **æ·»åŠ ä¸€å—æ•°æ®ç›˜ï¼Œç”¨æ¥æ”¾harborçš„é•œåƒ**

```bash
# æŸ¥çœ‹æ–°åŠ ç£ç›˜æ˜¯å¦è¯†åˆ«
[root@harbor1 ~]#fdisk -l
Disk /dev/sdaï¼š200 GiBï¼Œ214748364800 å­—èŠ‚ï¼Œ419430400 ä¸ªæ‰‡åŒº
Disk model: VMware Virtual S
å•å…ƒï¼šæ‰‡åŒº / 1 * 512 = 512 å­—èŠ‚
æ‰‡åŒºå¤§å°(é€»è¾‘/ç‰©ç†)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚
I/O å¤§å°(æœ€å°/æœ€ä½³)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚
ç£ç›˜æ ‡ç­¾ç±»å‹ï¼šgpt
ç£ç›˜æ ‡è¯†ç¬¦ï¼šCD107A96-8A31-4B05-B62C-EA05609760ED

è®¾å¤‡          èµ·ç‚¹      æœ«å°¾      æ‰‡åŒº  å¤§å° ç±»å‹
/dev/sda1     2048      4095      2048    1M BIOS å¯åŠ¨
/dev/sda2     4096   4198399   4194304    2G Linux æ–‡ä»¶ç³»ç»Ÿ
/dev/sda3  4198400 419428351 415229952  198G Linux æ–‡ä»¶ç³»ç»Ÿ


Disk /dev/sdbï¼š500 GiBï¼Œ536870912000 å­—èŠ‚ï¼Œ1048576000 ä¸ªæ‰‡åŒº       # å·²è¯†åˆ«
Disk model: VMware Virtual S
å•å…ƒï¼šæ‰‡åŒº / 1 * 512 = 512 å­—èŠ‚
æ‰‡åŒºå¤§å°(é€»è¾‘/ç‰©ç†)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚
I/O å¤§å°(æœ€å°/æœ€ä½³)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚


Disk /dev/mapper/ubuntu--vg-ubuntu--lvï¼š99 GiBï¼Œ106296246272 å­—èŠ‚ï¼Œ207609856 ä¸ªæ‰‡åŒº
å•å…ƒï¼šæ‰‡åŒº / 1 * 512 = 512 å­—èŠ‚
æ‰‡åŒºå¤§å°(é€»è¾‘/ç‰©ç†)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚
I/O å¤§å°(æœ€å°/æœ€ä½³)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚

# æ ¼å¼åŒ–ç£ç›˜
[root@harbor1 ~]#mkfs.xfs /dev/sdb
meta-data=/dev/sdb               isize=512    agcount=4, agsize=32768000 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=1, rmapbt=0
         =                       reflink=1    bigtime=0 inobtcount=0
data     =                       bsize=4096   blocks=131072000, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
log      =internal log           bsize=4096   blocks=64000, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =æ—                     extsz=4096   blocks=0, rtextents=0

# ç¼–è¾‘ä¸‹/etc/fstab
[root@harbor1 ~]#vim /etc/fstab 
/dev/sdb /data  xfs defaults 0 0    # æ·»åŠ è¿™è¡Œ

[root@harbor1 ~]#mkdir /data
[root@harbor1 ~]#mount -a

# æ£€æŸ¥æ˜¯å¦æˆåŠŸæŒ‚è½½
[root@harbor1 ~]#df -TH
æ–‡ä»¶ç³»ç»Ÿ                          ç±»å‹   å¤§å°  å·²ç”¨  å¯ç”¨ å·²ç”¨% æŒ‚è½½ç‚¹
tmpfs                             tmpfs  407M  1.6M  405M    1% /run
/dev/mapper/ubuntu--vg-ubuntu--lv ext4   105G  9.0G   90G   10% /
tmpfs                             tmpfs  2.1G     0  2.1G    0% /dev/shm
tmpfs                             tmpfs  5.3M     0  5.3M    0% /run/lock
/dev/sda2                         ext4   2.1G  247M  1.7G   13% /boot
tmpfs                             tmpfs  407M     0  407M    0% /run/user/0
/dev/sdb                          xfs    537G  3.8G  533G    1% /data             # æŒ‚è½½æˆåŠŸ
```



##### éƒ¨ç½²harbor

harborä¸‹è½½ç½‘å€

```http
https://github.com/goharbor/harbor/releases   # æ³¨æ„ä¸‹è½½æ­£å¼ç‰ˆï¼Œä¸è¦ä¸‹è½½rcç‰ˆæœ¬
```

```bash
# ä¸‹è½½harbor
[root@harbor1 ~]#wget https://github.com/goharbor/harbor/releases/download/v2.12.2/harbor-offline-installer-v2.12.2.tgz

# éƒ¨ç½²docker
[root@harbor1 harbor]#wget https://www.mysticalrecluse.com/script/Shell/install_docker_offline.sh
[root@harbor1 harbor]#bash install_docker_offline.sh
[root@harbor1 harbor]#source /etc/bash_completion.d/docker_completion

# éƒ¨ç½²docker-compose
[root@harbor1 harbor]# cat ~/docker-compose-repo.sh
# Add Docker's official GPG key:
apt-get update
apt-get install ca-certificates curl
install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
chmod a+r /etc/apt/keyrings/docker.asc

echo "GPG OVER"

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update

[root@harbor1 harbor]# bash ~/docker-compose-repo.sh

# å®˜æ–¹ä»“åº“é…ç½®å¥½åï¼Œæ‰§è¡Œä¸‹é¢çš„æŒ‡ä»¤
[root@ubuntu2204 ~]#apt install -y docker-compose-plugin

# åˆ›å»ºæ”¾ç½®harborçš„ç›®å½•
[root@ubuntu2204 ~]#mkdir /apps
[root@ubuntu2204 ~]#tar xvf harbor-offline-installer-v2.12.2.tgz -C /apps/
harbor/harbor.v2.12.2.tar.gz
harbor/prepare
harbor/LICENSE
harbor/install.sh
harbor/common.sh
harbor/harbor.yml.tmpl

[root@ubuntu2204 harbor]# cd /apps/harbor

# åˆ›å»ºè¯ä¹¦ç›®å½•
[root@harbor1 harbor]#mkdir certs

# å°†ä¸‹è½½nginxæ ¼å¼çš„è¯ä¹¦ä¼ å…¥è¯¥ç›®å½•
[root@harbor1 certs]# ls
harbor.mysticalrecluse.com_nginx.zip

# è§£å‹
[root@harbor1 certs]#unzip harbor.mysticalrecluse.com_nginx.zip 
Archive:  harbor.mysticalrecluse.com_nginx.zip
   creating: harbor.mysticalrecluse.com_nginx/
  inflating: harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com.csr  
  inflating: harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com_bundle.crt  
  inflating: harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com_bundle.pem  
  inflating: harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com.key
[root@harbor1 certs]# cd harbor.mysticalrecluse.com_nginx/
[root@harbor1 harbor.mysticalrecluse.com_nginx]# ls
harbor.mysticalrecluse.com_bundle.crt  harbor.mysticalrecluse.com.csr
harbor.mysticalrecluse.com_bundle.pem  harbor.mysticalrecluse.com.key


[root@ubuntu2204 harbor]#cp harbor.yml.tmpl harbor.yml
[root@ubuntu2204 harbor]#vim harbor.yml
# è¿™é‡Œçš„åŸŸåä¸€å®šå’Œè¯ä¹¦çš„åŸŸåä¸€è‡´
hostname: harbor.mysticalrecluse.com

# http related config
http:
  # port for http, default is 80. If https enabled, this port will redirect to https port
  port: 80

# https related config
https:
  # https port for harbor, default is 443
  port: 443
  # The path of cert and key files for nginx  
  certificate: /apps/harbor/certs/harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com_bundle.pem
  private_key: /apps/harbor/certs/harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com.key
......
# æ›´æ”¹harborçš„å¯†ç 
harbor_admin_password: 646130

......
# è¿™é‡Œå¯ä»¥æ›´æ”¹harborçš„æ•°æ®å­˜æ”¾è·¯å¾„ï¼Œå»ºè®®è¿™é‡ŒæŒ‚ä¸€ä¸ªæ•°æ®ç›˜æ¥ä¿å­˜harborçš„é•œåƒï¼Œå°†æ•°æ®å’Œç³»ç»Ÿåˆ†å¼€ï¼Œç³»ç»ŸæŒ‚äº†ä¸å½±å“æ•°æ®
data_volume: /data

# å¯ç”¨é•œåƒæ¼æ´æ‰«æ
trivy:
  enabled: true

# å¯ç”¨éƒ¨ç½²harbor
[root@harbor1 harbor]#./install.sh 
......
[Step 5]: starting Harbor ...
[+] Running 10/10
 âœ” Network harbor_harbor        Created                                               0.2s 
 âœ” Container harbor-log         Started                                               1.4s 
 âœ” Container redis              Started                                               4.5s 
 âœ” Container registryctl        Started                                               5.2s 
 âœ” Container harbor-db          Started                                               5.2s 
 âœ” Container harbor-portal      Started                                               4.8s 
 âœ” Container registry           Started                                               4.5s 
 âœ” Container harbor-core        Started                                               6.3s 
 âœ” Container harbor-jobservice  Started                                               7.9s 
 âœ” Container nginx              Started                                               8.6s 
âœ” ----Harbor has been installed and started successfully.----

# éƒ¨ç½²æˆåŠŸåï¼Œæµè§ˆå™¨è®¿é—®æµ‹è¯•
https://harbor.mysticalrecluse.com/
```

![image-20250407115822490](../markdown_img/image-20250407115822490.png)

ä¸ºå…¬å¸åˆ›å»ºä¸€ä¸ªé¡¹ç›®ï¼ˆæš‚è®¾ä¸ºå…¬å¼€ï¼Œå¦‚æœè®¾ä¸ºç§æœ‰ï¼Œåé¢éœ€è¦åœ¨k8sä¸­é…ç½®secretï¼‰

![image-20250407120231183](../markdown_img/image-20250407120231183.png)

![image-20250407120248022](../markdown_img/image-20250407120248022.png)



##### nerdctlæµ‹è¯•ç™»å½•harbor

åœ¨harbor2èŠ‚ç‚¹æµ‹è¯•ç™»å½•harboræœåŠ¡å™¨ï¼Œä»¥éªŒè¯æ˜¯å¦èƒ½å¤Ÿç™»å½•harboråŠpushé•œåƒ

```bash
# å®‰è£…éƒ¨ç½²containerdåŠå®¢æˆ·ç«¯nerdctl
[root@harbor2 ~]#wget https://www.mysticalrecluse.com/script/Shell/k8s_containerd_runc_cni.sh
[root@harbor2 ~]#bash k8s_containerd_runc_cni.sh
[root@harbor2 ~]#nerdctl login harbor.mysticalrecluse.com
Enter Username: admin
Enter Password: 
WARN[0004] skipping verifying HTTPS certs for "harbor.mysticalrecluse.com:443" 

WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.
Configure a credential helper to remove this warning. See
https://docs.docker.com/go/credential-store/

Login Succeeded

# æµ‹è¯•ä¸Šä¼ 
[root@harbor2 ~]#nerdctl pull alpine
docker.io/library/alpine:latest:                                                  resolved       |++++++++++++++++++++++++++++++++++++++| 
index-sha256:a8560b36e8b8210634f77d9f7f9efd7ffa463e380b75e2e74aff4511df3ef88c:    done           |++++++++++++++++++++++++++++++++++++++| 
manifest-sha256:1c4eef651f65e2f7daee7ee785882ac164b02b78fb74503052a26dc061c90474: done           |++++++++++++++++++++++++++++++++++++++| 
config-sha256:aded1e1a5b3705116fa0a92ba074a5e0b0031647d9c315983ccba2ee5428ec8b:   done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:f18232174bc91741fdf3da96d85011092101a032a93a388b79e99e69c2d5c870:    done           |++++++++++++++++++++++++++++++++++++++| 
elapsed: 8.5 s                                                                    total:  3.5 Mi (419.7 KiB/s) 

[root@harbor2 ~]#nerdctl tag alpine:latest harbor.mysticalrecluse.com/baseimages/alpine:latest
[root@harbor2 ~]#nerdctl push harbor.mysticalrecluse.com/baseimages/alpine
INFO[0000] pushing as a reduced-platform image (application/vnd.oci.image.index.v1+json, sha256:c5048da63aaf2a23ef85098b8a8dfc0cf571ccfa285812d28b71e21e7d60de7f) 
WARN[0000] skipping verifying HTTPS certs for "harbor.mysticalrecluse.com" 
index-sha256:c5048da63aaf2a23ef85098b8a8dfc0cf571ccfa285812d28b71e21e7d60de7f:    done           |++++++++++++++++++++++++++++++++++++++| 
manifest-sha256:1c4eef651f65e2f7daee7ee785882ac164b02b78fb74503052a26dc061c90474: done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:f18232174bc91741fdf3da96d85011092101a032a93a388b79e99e69c2d5c870:    done           |++++++++++++++++++++++++++++++++++++++| 
config-sha256:aded1e1a5b3705116fa0a92ba074a5e0b0031647d9c315983ccba2ee5428ec8b:   done           |++++++++++++++++++++++++++++++++++++++| 
elapsed: 0.8 s                                                                    total:  3.5 Mi (4.3 MiB/s)

# æŸ¥çœ‹harbor
```

![image-20250407122040531](../markdown_img/image-20250407122040531.png)

```bash
# æµ‹è¯•ä¸‹è½½
[root@harbor2 ~]#nerdctl images
REPOSITORY                                      TAG       IMAGE ID        CREATED          PLATFORM       SIZE       BLOB SIZE
harbor.mysticalrecluse.com/baseimages/alpine    latest    a8560b36e8b8    2 minutes ago    linux/amd64    8.503MB    3.644MB
<none>                                          <none>    a8560b36e8b8    4 minutes ago    linux/amd64    8.503MB    3.644MB
alpine                                          latest    a8560b36e8b8    4 minutes ago    linux/amd64    8.503MB    3.644MB
[root@harbor2 ~]#nerdctl rmi -f a8560b36e8b8
[root@harbor2 ~]#nerdctl pull harbor.mysticalrecluse.com/baseimages/alpine
WARN[0000] skipping verifying HTTPS certs for "harbor.mysticalrecluse.com" 
harbor.mysticalrecluse.com/baseimages/alpine:latest:                              resolved       |++++++++++++++++++++++++++++++++++++++| 
index-sha256:c5048da63aaf2a23ef85098b8a8dfc0cf571ccfa285812d28b71e21e7d60de7f:    done           |++++++++++++++++++++++++++++++++++++++| 
manifest-sha256:1c4eef651f65e2f7daee7ee785882ac164b02b78fb74503052a26dc061c90474: done           |++++++++++++++++++++++++++++++++++++++| 
config-sha256:aded1e1a5b3705116fa0a92ba074a5e0b0031647d9c315983ccba2ee5428ec8b:   done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:f18232174bc91741fdf3da96d85011092101a032a93a388b79e99e69c2d5c870:    done           |++++++++++++++++++++++++++++++++++++++| 
elapsed: 1.1 s                                                                    total:  3.5 Mi (3.2 MiB/s) 
```



#### kubeaszéƒ¨ç½²é«˜å¯ç”¨Kubernetes

![image-20250407123739224](D:\git_repository\cyber_security_learning\markdown_img\image-20250407123739224.png)

- ä¸Šè¿°æ¶æ„æœ‰ä¸¤ç±»è´Ÿè½½å‡è¡¡å™¨
  - kube-lbï¼šä½¿ç”¨nignxå®ç°ï¼Œæ‰€æœ‰çš„kubeletå°†è¯·æ±‚å‘ç»™127.0.0.1:6443ï¼Œç„¶åç”±nginxï¼Œåå‘ä»£ç†ç»™å„master
  - external-lbï¼šè¿™é‡Œä½¿ç”¨haproxyï¼Œç”¨äºæ‰¿æ¥kubectlæˆ–è€…dashboardç­‰å¤–éƒ¨è¯·æ±‚ï¼Œç¼“è§£äº†å¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨çš„å‹åŠ›



ä½¿ç”¨ansibleåœ¨éƒ¨ç½²æœåŠ¡å™¨éƒ¨ç½²k8sé›†ç¾¤

```bash
#!/bin/bash

# å¯†é’¥æ‰“é€šè„šæœ¬
IP="
10.0.0.201
10.0.0.202
10.0.0.203
10.0.0.204
10.0.0.205
10.0.0.206
10.0.0.207
10.0.0.208
10.0.0.209
10.0.0.210
10.0.0.211
10.0.0.212
10.0.0.213
"
REMOTE_PORT="22"
REMOTE_USER="root"
REMOTE_PASS="646130"

for REMOTE_HOST in ${IP}; do
  REMOTE_CMD="echo ${REMOTE_HOST} is successfully!"
  # æ·»åŠ ç›®æ ‡è¿œç¨‹ä¸»æœºå…¬é’¥ï¼Œç›¸å½“äºè¾“å…¥yes
  ssh-keyscan -p "${REMOTE_PORT}" "${REMOTE_HOST}" >> ~/.ssh/known_hosts
  
  # é€šè¿‡sshpassé…ç½®å…ç§˜é’¥ç™»å½•ï¼Œå¹¶åˆ›å»ºpython3è½¯é“¾æ¥
  apt install -y sshpass
  sshpass -p "${REMOTE_PASS}" ssh-copy-id "${REMOTE_USER}@${REMOTE_HOST}"
  ssh ${REMOTE_HOST} ln -sv /usr/bin/python3 /usr/bin/python
  echo ${REMOTE_HOST} å…ç§˜é’¥é…ç½®å®Œæˆï¼
done
```



```bash
# éƒ¨ç½²ansibleï¼Œè¿™é‡Œåœ¨haproxy1æœåŠ¡å™¨ä½œä¸ºéƒ¨ç½²æœåŠ¡å™¨
[root@haproxy1 ~]#wget https://www.mysticalrecluse.com/script/Shell/install_ansible.sh
[root@haproxy1 ~]#bash install_ansible.sh

# æ‰€æœ‰èŠ‚ç‚¹æ‰“é€šï¼Œé…ç½®å…å¯†è®¤è¯
# æµ‹è¯•
[root@haproxy1 ansible]#ansible test -m ping
10.0.0.202 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.207 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.201 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.206 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.203 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.208 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.213 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.212 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.211 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}

```



#### ä¸‹è½½kubeaszé¡¹ç›®åŠç»„ä»¶

```bash
# ç°éƒ¨ç½²k8sv1.30
[root@haproxy1 ~]#mkdir 1.30
[root@haproxy1 ~]#cd 1.30/
[root@haproxy1 1.30]#wget https://github.com/easzlab/kubeasz/releases/download/3.6.4/ezdow
[root@haproxy1 1.30]#chmod a+x ezdown
[root@haproxy1 1.30]#./ezdown -D
```



#### ç”Ÿäº§å¹¶è‡ªå®šä¹‰hostsæ–‡ä»¶

```bash
[root@haproxy1 1.30]#cd /etc/kubeasz/
[root@haproxy1 kubeasz]#ls
ansible.cfg  docs  example  ezdown     pics       README.md  tools
bin          down  ezctl    manifests  playbooks  roles

[root@haproxy1 kubeasz]#./ezctl new k8s-cluster1
2025-04-07 15:33:44 DEBUG generate custom cluster files in /etc/kubeasz/clusters/k8s-cluster1
2025-04-07 15:33:44 DEBUG set versions
2025-04-07 15:33:44 DEBUG cluster k8s-cluster1: files successfully created.
2025-04-07 15:33:44 INFO next steps 1: to config '/etc/kubeasz/clusters/k8s-cluster1/hosts'
2025-04-07 15:33:44 INFO next steps 2: to config '/etc/kubeasz/clusters/k8s-cluster1/config.yml'

# config.yamlé’ˆå¯¹Kubernetesçš„å…·ä½“é…ç½®
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/config.yml
......
############################
# role:deploy
############################
# default: ca will expire in 100 years
# default: certs issued by the ca will expire in 50 years
CA_EXPIRY: "876000h"           # è¿™é‡Œé…ç½®è¯ä¹¦æœ‰æ•ˆæœŸ
CERT_EXPIRY: "438000h"

############################
# role:etcd
############################
# è®¾ç½®ä¸åŒçš„walç›®å½•ï¼Œå¯ä»¥é¿å…ç£ç›˜ioç«äº‰ï¼Œæé«˜æ€§èƒ½ï¼Œetcdè¿™é‡Œæœ€å¥½æ˜¯é«˜æ€§èƒ½å›ºæ€ç›˜ï¼Œæ€§èƒ½å¥½ï¼Œetcdéå¸¸æ¶ˆè€—ç£ç›˜IO
ETCD_DATA_DIR: "/var/lib/etcd"
ETCD_WAL_DIR: ""


############################
# role:runtime [containerd,docker]
############################
# [.]å¯ç”¨æ‹‰å–åŠ é€Ÿé•œåƒä»“åº“
ENABLE_MIRROR_REGISTRY: true

# [.]æ·»åŠ ä¿¡ä»»çš„ç§æœ‰ä»“åº“
# å¿…é¡»æŒ‰ç…§å¦‚ä¸‹ç¤ºä¾‹æ ¼å¼ï¼Œåè®®å¤´'http://'å’Œ'https://'ä¸èƒ½çœç•¥
INSECURE_REG:                                               # è¿™é‡Œå¯ä»¥æ”¾æœ¬åœ°è‡ªç­¾åçš„harboråœ°å€ï¼Œè¿›è¡Œä¿¡ä»»
  - "http://easzlab.io.local:5000"
  - "https://reg.yourcompany.com"

# [.]åŸºç¡€å®¹å™¨é•œåƒ
SANDBOX_IMAGE: "easzlab.io.local:5000/easzlab/pause:3.9"     # è¿™é‡Œå¯ä»¥æ¢æˆç§æœ‰ä»“åº“çš„åœ°å€æä¾›pauseå®¹å™¨

# [containerd]å®¹å™¨æŒä¹…åŒ–å­˜å‚¨ç›®å½•
CONTAINERD_STORAGE_DIR: "/var/lib/containerd"                # å®¹å™¨æ•°æ®ç›®å½•å¯ä»¥å•ç‹¬ç»™ä¸€å—é«˜æ€§èƒ½æ•°æ®ç›˜ï¼Œæé«˜å®¹å™¨çš„è¿è¡Œ                                                                é€Ÿåº¦ï¼Œå¦‚æœä½¿ç”¨æœºæ¢°ç›˜ï¼Œé€Ÿåº¦éå¸¸æ…¢

# [docker]å®¹å™¨å­˜å‚¨ç›®å½•
DOCKER_STORAGE_DIR: "/var/lib/docker"

......
############################
# role:kube-master
############################
# k8s é›†ç¾¤ master èŠ‚ç‚¹è¯ä¹¦é…ç½®ï¼Œå¯ä»¥æ·»åŠ å¤šä¸ªipå’ŒåŸŸåï¼ˆæ¯”å¦‚å¢åŠ å…¬ç½‘ipå’ŒåŸŸåï¼‰
MASTER_CERT_HOSTS:
  - "10.0.0.88"                                              # æ‰“ç®—é€šè¿‡å“ªé‡Œè®¿é—®ï¼Œè¿™é‡Œè¯ä¹¦å°±ç­¾å‘ç»™è°ï¼Œæ¯”å¦‚é€šè¿‡è´Ÿè½½å‡è¡¡                                                                å™¨è®¿é—®ï¼Œè¿™ä¸ªåœ°å€å°±æ˜¯ç”¨vip,ä¹Ÿå› æ­¤å…¬æœ‰äº‘ä¸Šçš„å…¬ç½‘ipæ˜¯ä¸                                                                èƒ½éšä¾¿æ¢çš„ï¼Œå¦åˆ™ä¼šå¯¼è‡´è¯ä¹¦å’Œå¯¹åº”çš„ipä¸ä¸€è‡´ï¼Œä¼šå‡ºé—®é¢˜
  - "api.mystical.org"
  #- "www.test.com"

# node èŠ‚ç‚¹ä¸Š pod ç½‘æ®µæ©ç é•¿åº¦ï¼ˆå†³å®šæ¯ä¸ªèŠ‚ç‚¹æœ€å¤šèƒ½åˆ†é…çš„pod ipåœ°å€ï¼‰
# å¦‚æœflannel ä½¿ç”¨ --kube-subnet-mgr å‚æ•°ï¼Œé‚£ä¹ˆå®ƒå°†è¯»å–è¯¥è®¾ç½®ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ†é…podç½‘æ®µ
# https://github.com/coreos/flannel/issues/847
NODE_CIDR_LEN: 24

############################
# role:kube-node
############################
# Kubelet æ ¹ç›®å½•
KUBELET_ROOT_DIR: "/var/lib/kubelet"

# nodeèŠ‚ç‚¹æœ€å¤§pod æ•°
MAX_PODS: 110                                              # å¦‚æœæœåŠ¡å™¨æ€§èƒ½ç‰¹åˆ«å¼ºï¼Œè¿™é‡Œå¯ä»¥æŠŠpodæ•°ä¸Šè°ƒ

############################
# role:cluster-addon
############################
# coredns è‡ªåŠ¨å®‰è£…
dns_install: "no"                                          # è¿™é‡Œæ”¹ä¸ºnoï¼Œå¯ä»¥åé¢è‡ªå·±è£…
corednsVer: "1.11.1"
ENABLE_LOCAL_DNS_CACHE: false                              # trueå¯ç”¨ç¼“å­˜ï¼Œæé«˜æ€§èƒ½
dnsNodeCacheVer: "1.22.28"
# è®¾ç½® local dns cache åœ°å€
LOCAL_DNS_CACHE: "169.254.20.10"

# metric server è‡ªåŠ¨å®‰è£…
metricsserver_install: "no"
metricsVer: "v0.7.1"

# dashboard è‡ªåŠ¨å®‰è£…
dashboard_install: "no"
dashboardVer: "v2.7.0"
dashboardMetricsScraperVer: "v1.0.8"

# prometheus è‡ªåŠ¨å®‰è£…
prom_install: "no"
prom_namespace: "monitor"

```



#### ç¼–è¾‘ansible hostsæ–‡ä»¶

æŒ‡å®šetcdèŠ‚ç‚¹ã€masterèŠ‚ç‚¹ã€nodeèŠ‚ç‚¹ã€VIPã€è¿è¡Œæ—¶ã€ç½‘ç»œç»„ä»¶ç±»å‹ã€Service IPä¸Pod IPèŒƒå›´ç­‰é…ç½®ä¿¡æ¯

```bash
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/hosts
# 'etcd' cluster should have odd member(s) (1,3,5,...)
[etcd]
10.0.0.206
10.0.0.207
10.0.0.208
# master node(s), set unique 'k8s_nodename' for each node
# CAUTION: 'k8s_nodename' must consist of lower case alphanumeric characters, '-' or '.',
# and must start and end with an alphanumeric character
[kube_master]
10.0.0.201 k8s_nodename='master-01'
10.0.0.202 k8s_nodename='master-02'

# work node(s), set unique 'k8s_nodename' for each node
# CAUTION: 'k8s_nodename' must consist of lower case alphanumeric characters, '-' or '.',
# and must start and end with an alphanumeric character
[kube_node]
10.0.0.211 k8s_nodename='worker-01'
10.0.0.212 k8s_nodename='worker-02'
......
# K8S Service CIDR, not overlap with node(host) networking      # ä¸åŒæœºæˆ¿çš„ç½‘æ®µä¸€å®šä¸èƒ½ä¸€æ ·ï¼Œå¦åˆ™ä¼šå¯¼è‡´æ— æ³•é€šä¿¡
SERVICE_CIDR="10.100.0.0/16"

# Cluster CIDR (Pod CIDR), not overlap with node(host) networking
CLUSTER_CIDR="10.200.0.0/16"
......

bin_dir="/user/local/bin"          # äºŒè¿›åˆ¶æ–‡ä»¶æ”¾ç½®è·¯å¾„

......
# Default python interpreter
ansible_python_interpreter=/usr/bin/python3.10
```



#### å¯ç”¨Kubeaszéƒ¨ç½² â€” ç¯å¢ƒåˆå§‹åŒ–

```bash
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 00
Usage: ezctl setup <cluster> <step>
available steps:
    01  prepare            to prepare CA/certs & kubeconfig & other system settings 
    02  etcd               to setup the etcd cluster
    03  container-runtime  to setup the container runtime(docker or containerd)
    04  kube-master        to setup the master nodes
    05  kube-node          to setup the worker nodes
    06  network            to setup the network plugin
    07  cluster-addon      to setup other useful plugins
    90  all                to run 01~07 all at once
    10  ex-lb              to install external loadbalance for accessing k8s from outside
    11  harbor             to install a new harbor server or to integrate with an existed one

examples: ./ezctl setup test-k8s 01  (or ./ezctl setup test-k8s prepare)
	  ./ezctl setup test-k8s 02  (or ./ezctl setup test-k8s etcd)
          ./ezctl setup test-k8s all
          ./ezctl setup test-k8s 04 -t restart_master
          
# å¯ç”¨01,ç¯å¢ƒåˆå§‹åŒ–
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 01
......
PLAY RECAP ********************************************************************************
10.0.0.201                 : ok=28   changed=7    unreachable=0    failed=0    skipped=115  rescued=0    ignored=0   
10.0.0.202                 : ok=25   changed=4    unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.206                 : ok=25   changed=20   unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.207                 : ok=25   changed=4    unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.208                 : ok=25   changed=4    unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.211                 : ok=25   changed=4    unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.212                 : ok=25   changed=20   unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
localhost                  : ok=31   changed=21   unreachable=0    failed=0    skipped=13   rescued=0    ignored=0 
```



#### éƒ¨ç½²ETCDé›†ç¾¤

```bash
# éƒ¨ç½²etcdé›†ç¾¤,02
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 02
......
PLAY RECAP ********************************************************************************
10.0.0.206                 : ok=10   changed=9    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
10.0.0.207                 : ok=8    changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
10.0.0.208                 : ok=8    changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0 

# å„etcdæœåŠ¡å™¨éªŒè¯etcdæœåŠ¡
[root@haproxy1 kubeasz]# export NODE_IPS="10.0.0.206 10.0.0.207 10.0.0.208"
[root@k8s-10-0-0-206 ~]#for ip in ${NODE_IPS}; do ETCDCTL_API=3 etcdctl --endpoints=https://${ip}:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem endpoint health; done
https://10.0.0.206:2379 is healthy: successfully committed proposal: took = 79.772114ms
https://10.0.0.207:2379 is healthy: successfully committed proposal: took = 96.188498ms
https://10.0.0.208:2379 is healthy: successfully committed proposal: took = 92.900676ms

# æŸ¥çœ‹etcd.serviceæ–‡ä»¶
[root@k8s-10-0-0-206 ~]#vim /etc/systemd/system/etcd.service
```



#### éƒ¨ç½²å®¹å™¨è¿è¡Œæ—¶containerd

ç”±è¯ä¹¦ç­¾å‘æœºæ„ç­¾å‘çš„è¯ä¹¦ä¸éœ€è¦æ‰§è¡Œåˆ†å‘æ­¥éª¤ï¼Œè¯ä¹¦å¯è¢«ä¿¡ä»»

```bash
# éªŒè¯åŸºç¡€å®¹å™¨é•œåƒ
[root@haproxy1 kubeasz]#grep SANDBOX_IMAGE ./clusters/* -R
./clusters/k8s-cluster1/config.yml:SANDBOX_IMAGE: "harbor.mysticalrecluse.com/baseimages/pause:3.9â€œ

# å°†pauseå®¹å™¨æ‹‰ä¸‹æ¥åï¼Œä¸Šä¼ è‡³ç§æœ‰harborä»“åº“ï¼Œåç»­çš„pauseå®¹å™¨ä»ç§æœ‰ä»“æ‹‰å–
[root@harbor1 harbor]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.9
[root@harbor1 harbor]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.9 harbor.mysticalrecluse.com/baseimages/pause:3.9
[root@harbor1 harbor]#docker push harbor.mysticalrecluse.com/baseimages/pause:3.9

# é…ç½®åŸºç¡€é•œåƒ
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/config.yml
......
SANDBOX_IMAGE: "harbor.mysticalrecluse.com/baseimages/pause:3.9â€œ
......

# é…ç½®harboré•œåƒä»“åº“åŸŸåè§£æ-å…¬å¸æœ‰DNSæœåŠ¡å™¨è¿›è¡ŒåŸŸåè§£æ
[root@haproxy1 kubeasz]#vim roles/containerd/tasks/main.yml
......
    - name: æ·»åŠ  crictl è‡ªåŠ¨è¡¥å…¨
      lineinfile:
        dest: ~/.bashrc
        state: present
        regexp: 'crictl completion'
        line: 'source <(crictl completion bash) # generated by kubeasz'

    # æ·»åŠ å¦‚ä¸‹ä¸¤è¡Œ
    - name: æ·»åŠ åŸŸåè§£æ
      shell: "echo '10.0.0.204 harbor.mysticalrecluse.com' >> /etc/hosts"

# å¯é€‰è‡ªå®šä¹‰containersé…ç½®æ–‡ä»¶
[root@haproxy1 kubeasz]#vim roles/containerd/templates/config.toml.j2 


# é…ç½®nerdctlå®¢æˆ·ç«¯
[root@haproxy1 ~]#wget https://github.com/containerd/nerdctl/releases/download/v2.0.4/nerdctl-2.0.4-linux-amd64.tar.gz
[root@haproxy1 ~]#tar xvf nerdctl-2.0.4-linux-amd64.tar.gz -C /etc/kubeasz/bin/containerd-bin/
nerdctl
containerd-rootless-setuptool.sh
containerd-rootless.sh

[root@haproxy1 roles]#vim containerd/tasks/main.yml
- block:
    - name: å‡†å¤‡containerdç›¸å…³ç›®å½•
      file: name={{ item }} state=directory
      with_items:
      - "{{ bin_dir }}/containerd-bin"
      - "/etc/containerd"
      - "/etc/nerdctl/"                          # æ·»åŠ è¿™è¡Œï¼Œé…ç½®æ–‡ä»¶ç›®å½•
      
      
    - name: ä¸‹è½½ containerd äºŒè¿›åˆ¶æ–‡ä»¶
      copy: src={{ item }} dest={{ bin_dir }}/containerd-bin/ mode=0755
      with_fileglob:                             # ç”¨æ¥æ‰¹é‡è¯»å–æœ¬åœ°å¤šä¸ªæ–‡ä»¶ï¼Œå¹¶å¾ªç¯å¤„ç†
      - "{{ base_dir }}/bin/containerd-bin/*"
      tags: upgrade

    - name: åˆ›å»º containerd é…ç½®æ–‡ä»¶
      template: src=config.toml.j2 dest=/etc/containerd/config.toml
      tags: upgrade

    # æ·»åŠ ä¸‹é¢ä¸‰è¡Œ
    - name: åˆ›å»º nerdctl é…ç½®æ–‡ä»¶
      template: src=nerdctl.toml.j2 dest=/etc/nerdctl/nerdctl.toml
      tags: upgrade
      
[root@haproxy1 kubeasz]#vim roles/containerd/templates/nerdctl.toml.j2
namespace    = "k8s.io"
debug        = false
debug_full   = false
insecure_registry = true

# å¯ç”¨03 åˆ›å»ºè¿è¡Œæ—¶
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 03
......
PLAY RECAP ********************************************************************************
10.0.0.201                 : ok=15   changed=14   unreachable=0    failed=0    skipped=13   rescued=0    ignored=0   
10.0.0.202                 : ok=15   changed=14   unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
10.0.0.211                 : ok=15   changed=14   unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
10.0.0.212                 : ok=15   changed=14   unreachable=0    failed=0    skipped=10   rescued=0    ignored=0 

# åœ¨master2æµ‹è¯•
[root@master-02 ~]# nerdctl pull nginx
[root@master-02 ~]# nerdctl tag nginx:lastest harbor.mysticalrecluse.com/myserver/nginx:v1
[root@master-02 ~]# nerdctl login harbor.mysticalrecluse.com
[root@master-02 ~]# nerdctl push harbor.mysticalrecluse.com/myserver/nginx:v1

# åœ¨node1æµ‹è¯•æ˜¯å¦èƒ½æ‹‰ç§æœ‰ä»“çš„é•œåƒ
[root@worker-01 ~]#nerdctl pull harbor.mysticalrecluse.com/myserver/nginx:v1
```



#### éƒ¨ç½² Kubernetes master èŠ‚ç‚¹

å¯é€‰æ›´æ”¹å¯åŠ¨è„šæœ¬å‚æ•°ä»¥åŠè·¯å¾„ç­‰è‡ªå®šä¹‰åŠŸèƒ½

```bash
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 04

# é»˜è®¤æƒ…å†µä¸‹ï¼Œåªåœ¨éƒ¨ç½²èŠ‚ç‚¹æœ‰kubeconfigæ–‡ä»¶
[root@haproxy1 kubeasz]#kubectl get nodes
NAME        STATUS                     ROLES    AGE    VERSION
master-01   Ready,SchedulingDisabled   master   8m8s   v1.30.1
master-02   Ready,SchedulingDisabled   master   8m8s   v1.30.1
```



#### éƒ¨ç½² Kubernetes Node èŠ‚ç‚¹

```bash
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 05
......
PLAY RECAP ********************************************************************************
10.0.0.211                 : ok=38   changed=36   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
10.0.0.212                 : ok=38   changed=36   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0

# åœ¨éƒ¨ç½²èŠ‚ç‚¹æŸ¥çœ‹
[root@haproxy1 kubeasz]#kubectl get nodes
NAME        STATUS                     ROLES    AGE    VERSION
master-01   Ready,SchedulingDisabled   master   8m8s   v1.30.1
master-02   Ready,SchedulingDisabled   master   8m8s   v1.30.1
worker-01   Ready                      node     32s    v1.30.1
worker-02   Ready                      node     33s    v1.30.1

```



#### éƒ¨ç½²ç½‘ç»œæœåŠ¡calico

å¯é€‰æ›´æ”¹calicoçš„é•œåƒåœ°å€åŠå„ç§é…ç½®ä¿¡æ¯

```bash
[root@haproxy1 kubeasz]# vim clusters/k8s-cluster1/config.yml
# ------------------------------------------- calico
# [calico] IPIPéš§é“æ¨¡å¼å¯é€‰é¡¹æœ‰: [Always, CrossSubnet, Never],è·¨å­ç½‘å¯ä»¥é…ç½®ä¸ºAlwaysä¸CrossSubnet(å…¬æœ‰äº‘å»ºè®®ä½¿ç”¨alwaysæ¯”è¾ƒçœäº‹ï¼Œå…¶ä»–çš„è¯éœ€è¦ä¿®æ”¹å„è‡ªå…¬æœ‰äº‘çš„ç½‘ç»œé…ç½®ï¼Œå…·ä½“å¯ä»¥å‚è€ƒå„ä¸ª
å…¬æœ‰äº‘è¯´æ˜)
# å…¶æ¬¡CrossSubnetä¸ºéš§é“+BGPè·¯ç”±æ··åˆæ¨¡å¼å¯ä»¥æå‡ç½‘ç»œæ€§èƒ½ï¼ŒåŒå­ç½‘é…ç½®ä¸ºNeverå³å¯.
CALICO_IPV4POOL_IPIP: "Always"

# [calico]è®¾ç½® calico-nodeä½¿ç”¨çš„host IPï¼Œbgpé‚»å±…é€šè¿‡è¯¥åœ°å€å»ºç«‹ï¼Œå¯æ‰‹å·¥æŒ‡å®šä¹Ÿå¯ä»¥è‡ªåŠ¨å‘ç°
IP_AUTODETECTION_METHOD: "can-reach={{ groups['kube_master'][0] }}"

# [calico]è®¾ç½®calico ç½‘ç»œ backend: bird, vxlan, none
CALICO_NETWORKING_BACKEND: "bird"

# [calico]è®¾ç½®calico æ˜¯å¦ä½¿ç”¨route reflectors
# å¦‚æœé›†ç¾¤è§„æ¨¡è¶…è¿‡50ä¸ªèŠ‚ç‚¹ï¼Œå»ºè®®å¯ç”¨è¯¥ç‰¹æ€§
CALICO_RR_ENABLED: false

# CALICO_RR_NODES é…ç½®route reflectorsçš„èŠ‚ç‚¹ï¼Œå¦‚æœæœªè®¾ç½®é»˜è®¤ä½¿ç”¨é›†ç¾¤masterèŠ‚ç‚¹ 
# CALICO_RR_NODES: ["192.168.1.1", "192.168.1.2"]
CALICO_RR_NODES: []

# [calico]æ›´æ–°æ”¯æŒcalico ç‰ˆæœ¬: ["3.19", "3.23"]
calico_ver: "v3.26.4"

# [calico]calico ä¸»ç‰ˆæœ¬
calico_ver_main: "{{ calico_ver.split('.')[0] }}.{{ calico_ver.split('.')[1] }}"


# æŸ¥çœ‹éƒ¨ç½²èŠ‚ç‚¹é•œåƒ
[root@haproxy1 kubeasz]#docker images
REPOSITORY                                           TAG       IMAGE ID       CREATED         SIZE
easzlab/kubeasz                                      3.6.4     1108a8be8fcc   9 months ago    157MB
easzlab/kubeasz-ext-bin                              1.10.1    fb29543bf6ab   10 months ago   722MB
easzlab/kubeasz-k8s-bin                              v1.30.1   41c3580883c5   10 months ago   1.2GB
easzlab/metrics-server                               v0.7.1    2c06895dd9cd   12 months ago   66.9MB
easzlab.io.local:5000/easzlab/metrics-server         v0.7.1    2c06895dd9cd   12 months ago   66.9MB
calico/kube-controllers                              v3.26.4   b32f99198153   16 months ago   74.7MB
easzlab.io.local:5000/calico/kube-controllers        v3.26.4   b32f99198153   16 months ago   74.7MB
easzlab.io.local:5000/calico/cni                     v3.26.4   17d35f5bad38   16 months ago   209MB
calico/cni                                           v3.26.4   17d35f5bad38   16 months ago   209MB
calico/node                                          v3.26.4   ded66453eb63   16 months ago   252MB
easzlab.io.local:5000/calico/node                    v3.26.4   ded66453eb63   16 months ago   252MB
easzlab/k8s-dns-node-cache                           1.22.28   c0120d8e4c91   17 months ago   77.5MB
easzlab.io.local:5000/easzlab/k8s-dns-node-cache     1.22.28   c0120d8e4c91   17 months ago   77.5MB
registry                                             2         26b2eb03618e   18 months ago   25.4MB
coredns/coredns                                      1.11.1    cbb01a7bd410   20 months ago   59.8MB
easzlab.io.local:5000/coredns/coredns                1.11.1    cbb01a7bd410   20 months ago   59.8MB
easzlab/pause                                        3.9       78d53e70b442   2 years ago     744kB
easzlab.io.local:5000/easzlab/pause                  3.9       78d53e70b442   2 years ago     744kB
kubernetesui/dashboard                               v2.7.0    07655ddf2eeb   2 years ago     246MB
easzlab.io.local:5000/kubernetesui/dashboard         v2.7.0    07655ddf2eeb   2 years ago     246MB
kubernetesui/metrics-scraper                         v1.0.8    115053965e86   2 years ago     43.8MB
easzlab.io.local:5000/kubernetesui/metrics-scraper   v1.0.8    115053965e86   2 years ago     43.8MB

# æŸ¥çœ‹ansibleæ–‡ä»¶ï¼Œå¼•ç”¨çš„é•œåƒ
[root@haproxy1 kubeasz]#grep "image:" roles/calico/templates/calico-v3.26.yaml.j2 
          image: easzlab.io.local:5000/calico/cni:{{ calico_ver }}
          image: easzlab.io.local:5000/calico/node:{{ calico_ver }} 
          image: easzlab.io.local:5000/calico/node:{{ calico_ver }}
          image: easzlab.io.local:5000/calico/kube-controllers:{{ calico_ver }}
          
# æŸ¥çœ‹/kubeasz/clusters/k8s-cluster1/config.yml
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/config.yml
......
# [calico]æ›´æ–°æ”¯æŒcalico ç‰ˆæœ¬: ["3.19", "3.23"]
calico_ver: "v3.26.4

# å°†calicoç›¸å…³é•œåƒä¸Šä¼ åˆ°ç§æœ‰ä»“åº“
[root@haproxy1 kubeasz]# docker login harbor.mysticalrecluse.com
Username: admin
Password: 
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded

[root@haproxy1 ~]# docker tag easzlab.io.local:5000/calico/cni:v3.26.4 harbor.mysticalrecluse.com/baseimages/calico-cni:v3.26.4
[root@haproxy1 ~]# docker push harbor.mysticalrecluse.com/baseimages/calico-cni:v3.26.4
[root@haproxy1 ~]#docker tag easzlab.io.local:5000/calico/node:v3.26.4 harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
[root@haproxy1 ~]#docker push harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
[root@haproxy1 ~]#docker tag easzlab.io.local:5000/calico/kube-controllers:v3.26.4 harbor.mysticalrecluse.com/baseimages/calico-kube-controllers:v3.26.4
[root@haproxy1 ~]#docker push harbor.mysticalrecluse.com/baseimages/calico-kube-controllers:v3.26.4

# æ›´æ”¹é…ç½®æ–‡ä»¶
[root@haproxy1 kubeasz]#vim roles/calico/templates/calico-v3.26.yaml.j2
......
initContainers:
        # This container installs the CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          #image: easzlab.io.local:5000/calico/cni:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-cni:v3.26.4
          imagePullPolicy: IfNotPresent
          command: ["/opt/cni/bin/install"]
          envFrom:
          - configMapRef:
              # Allow KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT to be overridden for eBPF mode.
......
        # in best effort fashion, i.e. no failure for errors, to not disrupt pod creation in iptable mode.
        - name: "mount-bpffs"
          # image: easzlab.io.local:5000/calico/node:{{ calico_ver }} 
          image: harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
          imagePullPolicy: IfNotPresent
          command: ["calico-node", "-init", "-best-effort"]
          volumeMounts:
            - mountPath: /sys/fs
              name: sys-fs
......
      containers:
        # Runs calico-node container on each Kubernetes node. This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          # image: easzlab.io.local:5000/calico/node:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
          imagePullPolicy: IfNotPresent
          envFrom:
          - configMapRef:
              # Allow KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT to be overridden for eBPF mode.
              name: kubernetes-services-endpoint
              optional: true
......
      containers:
        - name: calico-kube-controllers
          # image: easzlab.io.local:5000/calico/kube-controllers:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-kube-controllers:v3.26.4
          imagePullPolicy: IfNotPresent
          env:
            # The location of the etcd cluster.
            - name: ETCD_ENDPOINTS
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_endpoints
                  
# æ£€æŸ¥æµ‹è¯•
[root@haproxy1 kubeasz]#grep "image:" roles/calico/templates/calico-v3.26.yaml.j2
          # image: easzlab.io.local:5000/calico/cni:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-cni:v3.26.4
          # image: easzlab.io.local:5000/calico/node:{{ calico_ver }} 
          image: harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
          # image: easzlab.io.local:5000/calico/node:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
          # image: easzlab.io.local:5000/calico/kube-controllers:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-kube-controllers:v3.26.4

# httpsé•œåƒä»“åº“é…ç½®ä¸‹è½½è®¤è¯

# å¯ç”¨
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 06
......
PLAY RECAP ********************************************************************************
10.0.0.201                 : ok=13   changed=12   unreachable=0    failed=0    skipped=36   rescued=0    ignored=0   
10.0.0.202                 : ok=7    changed=6    unreachable=0    failed=0    skipped=13   rescued=0    ignored=0   
10.0.0.211                 : ok=7    changed=6    unreachable=0    failed=0    skipped=13   rescued=0    ignored=0   
10.0.0.212                 : ok=7    changed=6    unreachable=0    failed=0    skipped=13   rescued=0    ignored=0 

# åœ¨masterèŠ‚ç‚¹æµ‹è¯•
[root@master-01 ~]#calicoctl node status
Calico process is running.

IPv4 BGP status
+--------------+-------------------+-------+----------+-------------+
| PEER ADDRESS |     PEER TYPE     | STATE |  SINCE   |    INFO     |
+--------------+-------------------+-------+----------+-------------+
| 10.0.0.212   | node-to-node mesh | up    | 02:43:28 | Established |
| 10.0.0.211   | node-to-node mesh | up    | 02:43:41 | Established |
| 10.0.0.202   | node-to-node mesh | up    | 02:43:50 | Established |
+--------------+-------------------+-------+----------+-------------+

IPv6 BGP status
No IPv6 peers found.

# å°†éƒ¨ç½²èŠ‚ç‚¹çš„configæ–‡ä»¶å¤åˆ¶åˆ°masterèŠ‚ç‚¹
[root@haproxy1 kubeasz]#scp /root/.kube/config master1:/root/.kube/
config                                                   100% 6194     2.8MB/s   00:00 

# åœ¨workerçš„contianerd.serviceé…ç½®ä»£ç†ï¼Œæ³¨æ„ï¼šè¿™é‡Œè¿›ä½œç”¨äºcontainerdï¼Œå¯¹å®¿ä¸»æœºæ— æ•ˆ
# åŒæ—¶åœ¨å®¿ä¸»æœºé…ç½®çš„ä»£ç†ï¼Œä»…ä½œç”¨äºå®¿ä¸»æœºï¼Œå¯¹containerdæ— æ•ˆï¼Œè€Œk8sä¸­æ˜¯kubeletè°ƒç”¨containerdè¿›è¡Œé•œåƒæ‹‰å–
[root@worker-02 ~]#vim /etc/systemd/system/containerd.service
[Service]
Environment="HTTP_PROXY=http://your.proxy:port"
Environment="HTTPS_PROXY=http://your.proxy:port"
Environment="NO_PROXY=127.0.0.1,localhost,::1,10.0.0.0/8,10.244.0.0/16,10.96.0.0/12"
```



#### éªŒè¯Podé€šä¿¡

```bash
[root@master-01 ~]#kubectl run net-test1 --image=centos:7.9.2009 sleep 10000000
[root@master-01 ~]#kubectl run net-test2 --image=centos:7.9.2009 sleep 10000000
[root@master-01 ~]#kubectl get pod
NAME        READY   STATUS    RESTARTS   AGE
net-test1   1/1     Running   0          11m
net-test2   1/1     Running   0          23m

# æµ‹è¯•ï¼Œè®¿é—®å¤–ç½‘ip
[root@master-01 ~]#kubectl exec net-test1 -- ping 223.6.6.6
PING 223.6.6.6 (223.6.6.6) 56(84) bytes of data.
64 bytes from 223.6.6.6: icmp_seq=1 ttl=127 time=6.32 ms
64 bytes from 223.6.6.6: icmp_seq=2 ttl=127 time=5.81 ms

# æµ‹è¯•ï¼Œè®¿é—®net-test2
[root@master-01 ~]#kubectl exec net-test1 -- ping 10.200.171.2
```



### é›†ç¾¤èŠ‚ç‚¹ä¼¸ç¼©ç®¡ç†

é›†ç¾¤ç®¡ç†ä¸»è¦æ˜¯æ·»åŠ masterã€æ·»åŠ nodeã€åˆ é™¤masterä¸åˆ é™¤nodeç­‰èŠ‚ç‚¹ç®¡ç†åŠç›‘æ§

```bash
# å½“å‰é›†ç¾¤çŠ¶æ€
[root@master-01 ~]#kubectl get nodes
NAME        STATUS                     ROLES    AGE    VERSION
master-01   Ready,SchedulingDisabled   master   128m   v1.30.1
master-02   Ready,SchedulingDisabled   master   128m   v1.30.1
worker-01   Ready                      node     120m   v1.30.1
worker-02   Ready                      node     120m   v1.30.1

[root@haproxy1 kubeasz]#./ezctl --help
Usage: ezctl COMMAND [args]
-------------------------------------------------------------------------------------
Cluster setups:
    list		             to list all of the managed clusters
    checkout    <cluster>            to switch default kubeconfig of the cluster
    new         <cluster>            to start a new k8s deploy with name 'cluster'
    setup       <cluster>  <step>    to setup a cluster, also supporting a step-by-step way
    start       <cluster>            to start all of the k8s services stopped by 'ezctl stop'
    stop        <cluster>            to stop all of the k8s services temporarily
    upgrade     <cluster>            to upgrade the k8s cluster
    destroy     <cluster>            to destroy the k8s cluster
    backup      <cluster>            to backup the cluster state (etcd snapshot)
    restore     <cluster>            to restore the cluster state from backups
    start-aio		             to quickly setup an all-in-one cluster with default settings

Cluster ops:
    add-etcd    <cluster>  <ip>      to add a etcd-node to the etcd cluster
    add-master  <cluster>  <ip>      to add a master node to the k8s cluster
    add-node    <cluster>  <ip>      to add a work node to the k8s cluster
    del-etcd    <cluster>  <ip>      to delete a etcd-node from the etcd cluster
    del-master  <cluster>  <ip>      to delete a master node from the k8s cluster
    del-node    <cluster>  <ip>      to delete a work node from the k8s cluster

Extra operation:
    kca-renew   <cluster>            to force renew CA certs and all the other certs (with caution)
    kcfg-adm    <cluster>  <args>    to manage client kubeconfig of the k8s cluster

Use "ezctl help <command>" for more information about a given command.

```



#### æ·»åŠ NodeèŠ‚ç‚¹

```bash
# 1. æ‰“é€šæ–°åŠ å…¥çš„NodeèŠ‚ç‚¹å’Œé›†ç¾¤å†…å…¶ä»–èŠ‚ç‚¹çš„ssh

# 2. åœ¨é›†ç¾¤éƒ¨ç½²æœåŠ¡å™¨ï¼Œå³kubeaszæ‰€åœ¨æœåŠ¡å™¨ï¼Œæ¯”å¦‚æ–°åŠ å…¥nodeçš„ipæ˜¯10.0.0.213
[root@haproxy1 kubeasz]#./ezctl add-node k8s-cluster1 10.0.0.213

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE    VERSION
k8s-10-0-0-213   Ready                      node     54s    v1.30.1
master-01        Ready,SchedulingDisabled   master   144m   v1.30.1
master-02        Ready,SchedulingDisabled   master   144m   v1.30.1
worker-01        Ready                      node     137m   v1.30.1
worker-02        Ready                      node     137m   v1.30.1
```



#### æ·»åŠ masterèŠ‚ç‚¹

```bash
# 1. æ‰“é€šæ–°åŠ å…¥çš„masterèŠ‚ç‚¹å’Œé›†ç¾¤å†…å…¶ä»–èŠ‚ç‚¹çš„ssh

# 2. åœ¨é›†ç¾¤éƒ¨ç½²æœåŠ¡å™¨ï¼Œå³kubeaszæ‰€åœ¨æœåŠ¡å™¨ï¼Œæ¯”å¦‚æ–°åŠ å…¥masterçš„ipæ˜¯10.0.0.203
[root@haproxy1 kubeasz]#./ezctl add-master k8s-cluster1 10.0.0.203

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   2m36s   v1.30.1
k8s-10-0-0-213   Ready                      node     19m     v1.30.1
master-01        Ready,SchedulingDisabled   master   163m    v1.30.1
master-02        Ready,SchedulingDisabled   master   163m    v1.30.1
worker-01        Ready                      node     155m    v1.30.1
worker-02        Ready                      node     155m    v1.30.1
```



#### åˆ é™¤nodeèŠ‚ç‚¹

```bash
# æœ¬è´¨ä¸Šæ˜¯å¿½ç•¥daemonset,å¼ºåˆ¶drainé©±é€nodeä¸Šçš„podï¼Œå†è¸¢å‡ºnodeèŠ‚ç‚¹
# --delete-local-data --ignore-daemonsets --force
# --delete-emptydir-data --ignore-daemonsets --force

# æ³¨æ„ï¼ï¼ï¼ï¼Œè¯¥æ“ä½œä¸å»ºè®®åœ¨ä¸šåŠ¡é«˜å³°æœŸæ‰§è¡Œ

# æ‰§è¡Œåˆ é™¤æŒ‡å®šèŠ‚ç‚¹
[root@haproxy1 kubeasz]#./ezctl del-node k8s-cluster1 10.0.0.213

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE    VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   10m    v1.30.1
master-01        Ready,SchedulingDisabled   master   170m   v1.30.1
master-02        Ready,SchedulingDisabled   master   170m   v1.30.1
worker-01        Ready                      node     163m   v1.30.1
worker-02        Ready                      node     163m   v1.30.1

# åˆ é™¤åï¼Œé‡å¯è¢«åˆ é™¤çš„nodeèŠ‚ç‚¹ï¼Œä»¥æ¸…ç†ç¼“å­˜ä¿¡æ¯
# ä½†æ˜¯ï¼ï¼ï¼ï¼Œæ­¤æ—¶å¯èƒ½ä¼šå‡ºç°ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åˆ é™¤çš„èŠ‚ç‚¹ï¼Œæ— æ³•ç›´æ¥å†åŠ å…¥é›†ç¾¤ï¼ŒåŸå› æ˜¯hostsæ–‡ä»¶å†…çš„è¯¥ä¸»æœºåæ²¡æœ‰è¢«åˆ é™¤ï¼Œåˆ é™¤åé‡æ–°æ·»åŠ å°±å¯ä»¥äº†
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/hosts
[kube_node]
10.0.0.211 k8s_nodename='worker-01'
10.0.0.212 k8s_nodename='worker-02'
# ï¼Ÿï¼Ÿï¼Ÿ åŸ10.0.0.213ï¼Œå¦‚æœè¿™é‡Œæ²¡æœ‰ä»ç„¶åç—•è¿¹ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ— æ³•åŠ å…¥é›†ç¾¤

# å°†10.0.0.213å†æ¬¡åŠ å…¥é›†ç¾¤
[root@haproxy1 kubeasz]#./ezctl add-node k8s-cluster1 10.0.0.213

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   36m     v1.30.1
k8s-10-0-0-213   Ready                      node     17m     v1.30.1
master-01        Ready,SchedulingDisabled   master   3h17m   v1.30.1
master-02        Ready,SchedulingDisabled   master   3h17m   v1.30.1
worker-01        Ready                      node     3h10m   v1.30.1
worker-02        Ready                      node     3h10m   v1.30.1
```



### å‡çº§é›†ç¾¤

å¯¹å½“å‰ Kubernetes é›†ç¾¤è¿›è¡Œç‰ˆæœ¬æ›´æ–°ï¼Œè§£å†³å·²çŸ¥ Bug æˆ–æ–°å¢æŸäº›åŠŸèƒ½

å‡çº§çš„ä¸»è¦è¡Œä¸ºæ˜¯æ›¿æ¢äºŒè¿›åˆ¶

å¦‚æœè·¨å°ç‰ˆæœ¬å‡çº§ï¼Œæ¯”å¦‚1.26.0å‡çº§åˆ°1.26.4ï¼Œé€šå¸¸æ²¡æœ‰é—®é¢˜ï¼Œå¦‚æœæ˜¯è·¨å¤§ç‰ˆæœ¬å‡çº§ï¼Œæ¯”å¦‚1.26å‡çº§åˆ°1.27ï¼Œéœ€è¦çœ‹å®˜æ–¹çš„å…¼å®¹æ€§ï¼Œå¯èƒ½ä¼šå‡ºé—®é¢˜ï¼Œæ¯”å¦‚å¤§ç‰ˆæœ¬å‡çº§åï¼Œæºç‰ˆæœ¬çš„å‚æ•°å¯èƒ½åœ¨æ–°ç‰ˆæœ¬ä¸æ”¯æŒ

```bash
[root@master-01 src]#kubectl api-resources 
NAME                                SHORTNAMES   APIVERSION                        NAMESPACED   KIND
bindings                                         v1                                true         Binding
componentstatuses                   cs           v1                                false        ComponentStatus
configmaps                          cm           v1                                true         ConfigMap
endpoints                           ep           v1                                true         Endpoints
events                              ev           v1                                true         Event
limitranges                         limits       v1                                true         LimitRange
namespaces                          ns           v1                                false        Namespace
nodes                               no           v1                                false        Node
persistentvolumeclaims              pvc          v1                                true         PersistentVolumeClaim
persistentvolumes                   pv           v1                                false        PersistentVolume
pods                                po           v1                                true         Pod
podtemplates                                     v1                                true         PodTemplate
replicationcontrollers              rc           v1                                true         ReplicationController
resourcequotas                      quota        v1                                true         ResourceQuota
secrets                                          v1                                true         Secret
serviceaccounts                     sa           v1                                true         ServiceAccount
services                            svc          v1                                true         Service
mutatingwebhookconfigurations                    admissionregistration.k8s.io/v1   false        MutatingWebhookConfiguration
validatingadmissionpolicies                      admissionregistration.k8s.io/v1   false        ValidatingAdmissionPolicy
validatingadmissionpolicybindings                admissionregistration.k8s.io/v1   false        ValidatingAdmissionPolicyBinding
validatingwebhookconfigurations                  admissionregistration.k8s.io/v1   false        ValidatingWebhookConfiguration
customresourcedefinitions           crd,crds     apiextensions.k8s.io/v1           false        CustomResourceDefinition
apiservices                                      apiregistration.k8s.io/v1         false        APIService
controllerrevisions                              apps/v1                           true         ControllerRevision
daemonsets                          ds           apps/v1                           true         DaemonSet
deployments                         deploy       apps/v1                           true         Deployment
replicasets                         rs           apps/v1                           true         ReplicaSet
statefulsets                        sts          apps/v1                           true         StatefulSet
......

# å¦‚æœå‡çº§åï¼Œæ¯”å¦‚Statefulsetçš„apiVersionä»apps/v1å˜ä¸ºv1ï¼Œé‚£ä¹ˆå‡çº§åï¼Œæºk8sé›†ç¾¤çš„Statefulsæ— æ³•ä½¿ç”¨ï¼Œæ‰€ä»¥æ‰€æœ‰çš„Statefulséƒ½éœ€è¦é‡æ–°åˆ›å»ºï¼Œå› æ­¤è·¨å¤§ç‰ˆæœ¬å‡çº§ï¼Œæœ€å¥½åœ¨æµ‹è¯•ç¯å¢ƒåšå¥½è¶³å¤Ÿçš„æµ‹è¯•å†å‡çº§
# é€šå¸¸æƒ…å†µä¸‹ï¼Œå‡çº§1åˆ°2ä¸ªå¤§ç‰ˆæœ¬ï¼Œæ²¡æœ‰å¤§é—®é¢˜ï¼Œé‡ç‚¹çœ‹å®˜æ–¹è¯´æ˜
```





#### æ‰¹é‡æ›´æ–°

```bash
# å½“å‰é›†ç¾¤ç‰ˆæœ¬
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   85m     v1.30.1
k8s-10-0-0-213   Ready                      node     66m     v1.30.1
master-01        Ready,SchedulingDisabled   master   4h6m    v1.30.1
master-02        Ready,SchedulingDisabled   master   4h6m    v1.30.1
worker-01        Ready                      node     3h58m   v1.30.1
worker-02        Ready                      node     3h58m   v1.30.1

```

**å‡çº§éœ€è¦ä¸‹è½½Kuberneteså¯¹åº”ç‰ˆæœ¬çš„æºç åŒ…å’ŒäºŒè¿›åˆ¶åŒ…**
**ä¸‹è½½ç½‘ç«™**

```http
https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.30.md#source-code
```

![image-20250408135807496](../markdown_img/image-20250408135807496.png)

![image-20250408140107110](../markdown_img/image-20250408140107110.png)

```bash
[root@haproxy1 src]#pwd
/usr/local/src

# ä¸‹è½½Source Code
[root@haproxy1 src]# wget https://dl.k8s.io/v1.30.11/kubernetes.tar.gz

# ä¸‹è½½ Client Binaries
[root@haproxy1 src]#wget https://dl.k8s.io/v1.30.11/kubernetes-client-linux-amd64.tar.gz

# ä¸‹è½½ Server Binaries
[root@haproxy1 src]#wget https://dl.k8s.io/v1.30.11/kubernetes-server-linux-amd64.tar.gz

# ä¸‹è½½ Node Binaries
[root@haproxy1 src]#wget https://dl.k8s.io/v1.30.11/kubernetes-node-linux-amd64.tar.gz

# æŸ¥çœ‹
[root@haproxy1 src]#ls
kubernetes-client-linux-amd64.tar.gz  kubernetes-server-linux-amd64.tar.gz
kubernetes-node-linux-amd64.tar.gz    kubernetes.tar.gz


# å…¨éƒ¨è§£å‹
[root@haproxy1 src]#tar xf kubernetes-client-linux-amd64.tar.gz 
[root@haproxy1 src]#tar xf kubernetes-node-linux-amd64.tar.gz 
[root@haproxy1 src]#tar xf kubernetes-server-linux-amd64.tar.gz 
[root@haproxy1 src]#tar xf kubernetes.tar.gz 

# æŸ¥çœ‹
[root@haproxy1 src]#ls
kubernetes                            kubernetes-server-linux-amd64.tar.gz
kubernetes-client-linux-amd64.tar.gz  kubernetes.tar.gz
kubernetes-node-linux-amd64.tar.gz
[root@haproxy1 src]#ls kubernetes
addons  cluster  hack                   LICENSES  README.md  version
client  docs     kubernetes-src.tar.gz  node      server

# è¿›å…¥äºŒè¿›åˆ¶æ‰€åœ¨ç›®å½•
[root@haproxy1 src]#cd kubernetes/server/bin/
[root@haproxy1 bin]#ls
apiextensions-apiserver             kubectl.docker_tag
kubeadm                             kubectl.tar
kube-aggregator                     kubelet
kube-apiserver                      kube-log-runner
kube-apiserver.docker_tag           kube-proxy
kube-apiserver.tar                  kube-proxy.docker_tag
kube-controller-manager             kube-proxy.tar
kube-controller-manager.docker_tag  kube-scheduler
kube-controller-manager.tar         kube-scheduler.docker_tag
kubectl                             kube-scheduler.tar
kubectl-convert                     mounter


# æŸ¥çœ‹æºäºŒè¿›åˆ¶æ–‡ä»¶ç‰ˆæœ¬
[root@haproxy1 bin]#/etc/kubeasz/bin/kube-apiserver --version
Kubernetes v1.30.1

# ï¼ˆå¯é€‰ï¼‰å¦‚æœæ˜¯è·¨å¤§ç‰ˆæœ¬å‡çº§ï¼Œå¯èƒ½éœ€è¦æ”¹kube-apiserverï¼Œkube-schedulerç­‰serviceæ–‡ä»¶
[root@haproxy1 bin]#vim /etc/kubeasz/roles/kube-master/templates/
aggregator-proxy-csr.json.j2        kubernetes-csr.json.j2
kube-apiserver.service.j2           kube-scheduler.service.j2
kube-controller-manager.service.j2 

# å°†æ‰€æœ‰çš„æ–°ç‰ˆäºŒè¿›åˆ¶å¤åˆ¶åˆ°kubeaszé¡¹ç›®çš„binç›®å½•ä¸‹
[root@haproxy1 bin]#cp kube-apiserver kube-controller-manager kubectl kubelet kube-proxy kube-scheduler /etc/kubeasz/bin/

# è¦†ç›–åæŸ¥çœ‹ç‰ˆæœ¬ï¼Œç¡®è®¤è¦†ç›–æˆåŠŸ
[root@haproxy1 bin]#/etc/kubeasz/bin/kube-apiserver --version
Kubernetes v1.30.11

# æ‰§è¡Œå‘½ä»¤ï¼Œæ‰¹é‡å‡çº§
[root@haproxy1 kubeasz]#./ezctl upgrade k8s-cluster1
......
PLAY RECAP ***************************************************************************
10.0.0.201                 : ok=50   changed=38   unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
10.0.0.202                 : ok=50   changed=38   unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
10.0.0.203                 : ok=55   changed=40   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
10.0.0.211                 : ok=31   changed=22   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
10.0.0.212                 : ok=31   changed=22   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
10.0.0.213                 : ok=31   changed=22   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0  

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE   VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   18m   v1.30.11
k8s-10-0-0-213   Ready                      node     16m   v1.30.11
master-01        Ready,SchedulingDisabled   master   18m   v1.30.11
master-02        Ready,SchedulingDisabled   master   18m   v1.30.11
worker-01        Ready                      node     16m   v1.30.11
worker-02        Ready                      node     16m   v1.30.11
```

```ABAP
ä¸ºé¿å…å¯¹ä¸šåŠ¡é€ æˆå®è´¨æ€§å½±å“ï¼Œä¸€å®šè¦åœ¨æ™šä¸Šå‡çº§
```



#### æ‰‹åŠ¨æ›´æ–°

**æ–¹å¼1**ï¼šå°†äºŒè¿›åˆ¶æ–‡ä»¶åŒæ­¥åˆ°å…¶å®ƒè·¯å¾„ï¼Œä¿®æ”¹serviceæ–‡ä»¶åŠ è½½æ–°ç‰ˆæœ¬äºŒè¿›åˆ¶ï¼š**å³ç”¨æ–°ç‰ˆæœ¬æ›¿æ¢æ—§ç‰ˆæœ¬**

**æ–¹æ³•2**ï¼šå…³é—­æºæœåŠ¡ï¼Œæ›¿æ¢äºŒè¿›åˆ¶æ–‡ä»¶ç„¶åå¯åŠ¨æœåŠ¡ï¼š**å³ç›´æ¥æ›¿æ¢æ—§ç‰ˆæœ¬**

```bash
# å‡çº§nodeèŠ‚ç‚¹

# æ³¨æ„è¦†ç›–äºŒè¿›åˆ¶ï¼Œå°½é‡åœ¨ä¸šåŠ¡ä½å³°æœŸæ‰§è¡Œï¼Œå› ä¸ºä¼šåœæœåŠ¡
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   146m    v1.30.1
k8s-10-0-0-213   Ready                      node     127m    v1.30.1
master-01        Ready,SchedulingDisabled   master   5h7m    v1.30.1
master-02        Ready,SchedulingDisabled   master   5h7m    v1.30.1
worker-01        Ready                      node     4h59m   v1.30.1
worker-02        Ready                      node     4h59m   v1.30.1

# ä¸‹çº¿å¾…æ›´æ–°èŠ‚ç‚¹ï¼Œå³åç»­ä¸ä¼šå¾€è¿™ä¸ªèŠ‚ç‚¹è°ƒåº¦pod
[root@master-01 ~]#kubectl cordon k8s-10-0-0-213
node/k8s-10-0-0-213 cordoned

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE    VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   147m   v1.30.1
k8s-10-0-0-213   Ready,SchedulingDisabled   node     127m   v1.30.1
master-01        Ready,SchedulingDisabled   master   5h7m   v1.30.1
master-02        Ready,SchedulingDisabled   master   5h7m   v1.30.1
worker-01        Ready                      node     5h     v1.30.1
worker-02        Ready                      node     5h     v1.30.1

# é©±é€ä¸‹çº¿èŠ‚ç‚¹ä¸Šé¢çš„podï¼Œdadmonsetsç±»å‹çš„podè¦å¿½ç•¥æ‰ï¼Œå¦‚æœæœ‰å¸¦æ•°æ®çš„podï¼Œä¹Ÿè¦å¿½ç•¥æ‰
[root@master-01 ~]#kubectl drain k8s-10-0-0-213 --ignore-daemonsets
node/k8s-10-0-0-213 already cordoned
Warning: ignoring DaemonSet-managed Pods: kube-system/calico-node-btpzm
node/k8s-10-0-0-213 drained

# æ­¤æ—¶å°±å¯ä»¥åœ¨10.0.0.213è¿™ä¸ªèŠ‚ç‚¹ä»»æ„æ“ä½œï¼Œä¸ä¼šå½±å“åˆ°åŸé›†ç¾¤
# æ›¿æ¢å‡çº§kubelet
## æŸ¥çœ‹åŸkubeletç‰ˆæœ¬
[root@k8s-10-0-0-213 ~]#/usr/local/bin/kubelet --version
Kubernetes v1.30.1

## åœæ­¢æœåŠ¡
[root@k8s-10-0-0-213 ~]#systemctl stop kubelet.service

## ç”¨æ–°ç‰ˆkubeletæ›¿æ¢æ‰æ—§ç‰ˆkubelet 
[root@haproxy1 bin]#scp kubelet node3:/usr/local/bin/
kubelet                                             100%   96MB  42.5MB/s   00:02 

## æŸ¥çœ‹
[root@k8s-10-0-0-213 ~]#/usr/local/bin/kubelet --version
Kubernetes v1.30.11

## ç„¶åå¯åŠ¨kubelet
[root@k8s-10-0-0-213 ~]#systemctl start kubelet.service

## åœ¨masterèŠ‚ç‚¹æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   155m    v1.30.1
k8s-10-0-0-213   Ready,SchedulingDisabled   node     136m    v1.30.11      # å‡çº§æˆåŠŸ
master-01        Ready,SchedulingDisabled   master   5h16m   v1.30.1
master-02        Ready,SchedulingDisabled   master   5h16m   v1.30.1
worker-01        Ready                      node     5h8m    v1.30.1
worker-02        Ready                      node     5h8m    v1.30.1

## å‡çº§æˆåŠŸåï¼Œæ¢å¤è°ƒåº¦
[root@master-01 ~]#kubectl uncordon k8s-10-0-0-213
node/k8s-10-0-0-213 uncordoned
```



### éƒ¨ç½²Kuberneteså†…éƒ¨åŸŸåè§£ææœåŠ¡â€”CoreDNS

ç›®å‰å¸¸ç”¨çš„dnsç»„ä»¶æœ‰kube-dnså’ŒCorednsä¸¤ä¸ªï¼Œåˆ°k8sç‰ˆæœ¬1.17.Xéƒ½å¯ä»¥ä½¿ç”¨ï¼Œkube-dnså’Œcorednsç”¨äºè§£æk8sé›†ç¾¤ä¸­service nameæ‰€å¯¹åº”å¾—åˆ°IPåœ°å€ï¼Œä»Kubernetes v1.18å¼€å§‹ä¸æ”¯æŒä½¿ç”¨kube-dns



#### éƒ¨ç½²Coredns

å¤åˆ¶coredns.yamlæ¨¡ç‰ˆ

```http
https://github.com/coredns/deployment/blob/master/kubernetes/coredns.yaml.sed
```

![image-20250408180337386](D:\git_repository\cyber_security_learning\markdown_img\image-20250408180337386.png)

```bash
# æ‹·è´å¹¶æ›´æ”¹coredns.yamlæ¨¡ç‰ˆ
[root@master-01 ~]# vim coredns.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    - pods
    - namespaces
    verbs:
    - list
    - watch
  - apiGroups:
    - discovery.k8s.io
    resources:
    - endpointslices
    verbs:
    - list
    - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors                      # errorsæ’ä»¶ï¼šé”™è¯¯ä¿¡æ¯æ ‡å‡†è¾“å‡º
        health {                    # healthæ’ä»¶ï¼šåœ¨CoreDNSçš„http://localhost:8080/healthç«¯å£æä¾›CoreDNSæœåŠ¡çš„å¥                                       åº·æŠ¥å‘Š
          lameduck 5s
        }
        ready                       # readyæ’ä»¶ï¼šç›‘å¬8181ç«¯å£ï¼Œå½“corednsçš„æ’ä»¶éƒ½å·²å°±ç»ªæ—¶ï¼Œè®¿é—®è¯¥ç«¯å£ä¼šè¿”å›200 OK
        # CLUSTER_DOMAIN REVERSE_CIDRS æ”¹ä¸º cluster.local in-addr.arpa ip6.arpa
        # åŸºäºKubernetes service nameè¿›è¡ŒDNSæŸ¥è¯¢å¹¶è¿”å›æŸ¥è¯¢è®°å½•ç»™å®¢æˆ·ç«¯
        kubernetes CLUSTER_DOMAIN REVERSE_CIDRS {
          fallthrough in-addr.arpa ip6.arpa
        }
        # CoreDNSçš„åº¦é‡æŒ‡æ ‡æ•°æ®ä»¥Prometheusçš„key-valueçš„æ ¼å¼åœ¨http://localhost:9153/metrics URLä¸Šæä¾›
        prometheus :9153
        # è¿™é‡Œ UPSTREAMNAMESERVER æ”¹ä¸º /etc/resolv.conf
        # é›†ç¾¤å†…è§£æä¸äº†çš„åŸŸåï¼Œè½¬å‘ç»™å®¿ä¸»æœºçš„/etc/resolv.confè§£æ
        forward . UPSTREAMNAMESERVER {
          max_concurrent 1000
        }
        cache 30             # å¯ç”¨serviceè§£æç¼“å­˜ï¼Œå•ä½ä¸ºç§’
        # æ£€æµ‹åŸŸåè§£ææ˜¯å¦æœ‰æ­»å¾ªç¯ï¼Œå¦‚corednsè½¬å‘ç»™å†…ç½‘DNSæœåŠ¡å™¨ï¼Œè€Œå†…ç½‘DNSæœåŠ¡å™¨åˆè½¬ç»™corednsï¼Œå¦‚æœå‘ç°è§£ææ˜¯æ­»å¾ªç¯ï¼Œåˆ™å¼ºåˆ¶           ä¸­æ­¢CoreDNSè¿›ç¨‹ï¼ˆKubernetesä¼šé‡å»ºï¼‰
        loop
        # æ£€æµ‹corefileæ˜¯å¦æ›´æ”¹ï¼Œåœ¨é‡æ–°ç¼–è¾‘configmapé…ç½®åï¼Œé»˜è®¤2åˆ†é’Ÿåä¼šä¼˜é›…çš„è‡ªåŠ¨åŠ è½½
        reload
        loadbalance           # è½®è¯¢DNSåŸŸåè§£æï¼Œå¦‚æœä¸€ä¸ªåŸŸåå­˜åœ¨å¤šä¸ªè®°å½•åˆ™è½®è¯¢è§£æ
    }STUBDOMAINS              # åˆ é™¤ STUBDOMAINS
    
    # é›†ç¾¤å†…è§£æä¸äº†çš„åŸŸåï¼Œè½¬å‘ç»™233.6.6.6è§£æ
    forward . 223.6.6.6 {
        max_concurrent 1000
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/name: "CoreDNS"
    app.kubernetes.io/name: coredns
spec:
  # replicas: not specified here:
  # 1. Default is 1.
  # 2. Will be tuned in real time if DNS horizontal auto-scaling is turned on.
  # è¿™é‡Œå¯ä»¥æ”¹ä¸º replicas: 2ï¼Œä¿è¯é«˜å¯ç”¨
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
      app.kubernetes.io/name: coredns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
        app.kubernetes.io/name: coredns
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: coredns
      tolerations:
        - key: "CriticalAddonsOnly"
          operator: "Exists"
      nodeSelector:
        kubernetes.io/os: linux
      affinity:
         podAntiAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
               - key: k8s-app
                 operator: In
                 values: ["kube-dns"]
             topologyKey: kubernetes.io/hostname
      containers:
      - name: coredns
        image: coredns/coredns:1.9.4            # è¿™é‡Œå¯ä»¥æ”¹ä¸ºç§æœ‰é•œåƒä»“åº“åœ°å€
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            memory: 170Mi
          requests:                          # è¿™é‡Œçš„èµ„æºé™åˆ¶ï¼Œåœ¨é«˜è´Ÿè½½ï¼Œéœ€è¦é¢‘ç¹è§£æåŸŸåçš„åœºæ™¯ä¸‹ï¼Œå¯èƒ½è¦åŠ å¤§èµ„æºï¼ˆæ¯”                                                  å¦‚1-2CPU,512Miå†…å­˜/1G,è¿™ä¸ªè¦æ ¹æ®ç›‘æ§æ¥å®šï¼‰ï¼Œå¦åˆ™CoreDNSä¼šè§£æåŸŸåå¯èƒ½                                                ä¼šå¾ˆæ…¢ï¼Œå¯¼è‡´ç½‘ç«™æ‰“å¼€æ…¢ï¼Œå†æˆ–è€…ä¹Ÿå¯ä»¥å¤šå‰¯æœ¬è§£å†³
            cpu: 100m            
            memory: 70Mi
        args: [ "-conf", "/etc/coredns/Corefile" ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
          readOnly: true
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        - containerPort: 9153
          name: metrics
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - all
          readOnlyRootFilesystem: true
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8181
            scheme: HTTP
      dnsPolicy: Default
      volumes:
        - name: config-volume
          configMap:
            name: coredns
            items:
            - key: Corefile
              path: Corefile
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  annotations:
    prometheus.io/port: "9153"
    prometheus.io/scrape: "true"
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "CoreDNS"
    app.kubernetes.io/name: coredns
spec:
  selector:
    k8s-app: kube-dns
    app.kubernetes.io/name: coredns
  clusterIP: CLUSTER_DNS_IP    # è¿™é‡Œæ”¹ä¸º10.100.0.2 ,æ ¹æ®POD_IPç½‘æ®µç¡®å®šï¼Œé€šå¸¸æ˜¯ç¬¬äºŒä¸ª
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP
  - name: metrics
    port: 9153
    protocol: TCP
```

```bash
# å¯ç”¨
[root@master-01 ~]#kubectl apply -f coredns.yaml
```



### Kubectl å¸¸ç”¨å‘½ä»¤

**kubectlå‘½ä»¤è¡Œä½¿ç”¨ç®€ä»‹**

```http
https://kubernetes.io/zh-cn/docs/reference/kubectl/generated/
```

| å‘½ä»¤é›†       | å‘½ä»¤                                                         | ç”¨é€”         |
| ------------ | ------------------------------------------------------------ | ------------ |
| åŸºç¡€å‘½ä»¤     | **create/delete/edit/get/describe/logs/scale**               | å¢åˆ æ”¹æŸ¥     |
| é…ç½®å‘½ä»¤     | **Label**ï¼šæ ‡ç­¾ç®¡ç†<br />**apply**ï¼šåŠ¨æ€é…ç½®<br />**cluster-info/top**ï¼šé›†ç¾¤çŠ¶æ€ |              |
| é›†ç¾¤ç®¡ç†å‘½ä»¤ | **cordon**ï¼šè­¦æˆ’çº¿ï¼Œæ ‡è®°nodeä¸è¢«è°ƒåº¦<br />**uncordon**ï¼šå–æ¶ˆè­¦æˆ’çº¿æ ‡è®°ä¸ºcordonçš„node<br />**drain**ï¼šé©±é€nodeä¸Šçš„podï¼Œç”¨äºnodeä¸‹çº¿ç­‰åœºæ™¯<br />**taint**ï¼šç»™nodeæ ‡è®°æ±¡ç‚¹ï¼Œå®ç°åäº²å’Œä¸nodeåäº²å’Œæ€§<br />**api-resources/api-versions/version**ï¼šapièµ„æº<br />**config**ï¼šå®¢æˆ·ç«¯kube-configé…ç½® | nodeèŠ‚ç‚¹ç®¡ç† |



## Kubernetesâ€”etcd

### etcdç®€ä»‹

- etcdæ˜¯CoreOSå›¢é˜Ÿäº2013å¹´6æœˆå‘èµ·çš„å¼€æºé¡¹ç›®ï¼Œå®ƒçš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªé«˜å¯ç”¨çš„åˆ†å¸ƒå¼é”®å€¼ï¼ˆkey-valueï¼‰æ•°æ®åº“ã€‚etcdå†…éƒ¨é‡‡ç”¨raftåè®®ä½œä¸ºä¸€è‡´æ€§ç®—æ³•ï¼ŒetcdåŸºäºGoè¯­è¨€å®ç°
- å®˜æ–¹ç½‘ç«™ï¼šhttp://etcd.io
- githubåœ°å€ï¼šhttps://github.com/etcd-io/etcd
- å®˜æ–¹ç¡¬ä»¶æ¨èï¼šhttps://etcd.io/docs/v3.5/op-guide/hardware/
- å®˜æ–¹æ–‡æ¡£ï¼šhttps://etcd.io/docs/v3.5/op-guide/maintenance



![image-20250409120720107](../markdown_img/image-20250409120720107.png)



**etcdå…·æœ‰ä¸‹é¢è¿™äº›å±æ€§**

- å®Œå…¨å¤åˆ¶ï¼šé›†ç¾¤ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½å¯ä»¥ä½¿ç”¨å®Œæ•´çš„å­˜æ¡£
- é«˜å¯ç”¨æ€§ï¼šEtcdå¯ç”¨äºé¿å…ç¡¬ä»¶çš„å•ç‚¹æ•…éšœæˆ–ç½‘ç»œé—®é¢˜
- ä¸€è‡´æ€§ï¼šæ¯æ¬¡è¯»å–éƒ½ä¼šè¿”å›è·¨å¤šä¸»æœºçš„æœ€æ–°å†™å…¥
- ç®€å•ï¼šåŒ…æ‹¬ä¸€ä¸ªå®šä¹‰è‰¯å¥½ï¼Œé¢å‘ç”¨æˆ·çš„APIï¼ˆgRPCï¼‰
- å®‰å…¨ï¼šå®ç°äº†å¸¦æœ‰å¯é€‰çš„å®¢æˆ·ç«¯è¯ä¹¦èº«ä»½éªŒè¯çš„è‡ªåŠ¨åŒ–TLS
- å¿«é€Ÿï¼šæ¯ç§’10000æ¬¡å†™å…¥åŸºå‡†é€Ÿåº¦
- å¯é ï¼šä½¿ç”¨Raftç®—æ³•å®ç°äº†å­˜å‚¨çš„åˆç†åˆ†å¸ƒEtcdçš„å·¥ä½œåŸç†



**etcdçš„serviceæ–‡ä»¶**

```bash
[root@k8s-10-0-0-206 ~]#cat /etc/systemd/system/etcd.service
[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target
Documentation=https://github.com/coreos

[Service]
Type=notify
WorkingDirectory=/var/lib/etcd
# etcdæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œç›´æ¥ä¼ é€’å‚æ•°
ExecStart=/usr/local/bin/etcd \
  --name=etcd-10.0.0.206 \        # etcdåŸºäºå½“å‰èŠ‚ç‚¹åç§°è¯†åˆ«èŠ‚ç‚¹ï¼Œå› æ­¤etcdé›†ç¾¤çš„æ¯ä¸ªèŠ‚ç‚¹åç§°ä¸èƒ½ä¸€æ ·
  --cert-file=/etc/kubernetes/ssl/etcd.pem \
  --key-file=/etc/kubernetes/ssl/etcd-key.pem \
  --peer-cert-file=/etc/kubernetes/ssl/etcd.pem \
  --peer-key-file=/etc/kubernetes/ssl/etcd-key.pem \
  --trusted-ca-file=/etc/kubernetes/ssl/ca.pem \
  --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem \
  --initial-advertise-peer-urls=https://10.0.0.206:2380 \   # é€šå‘Šè‡ªå·±çš„é›†ç¾¤ç«¯å£
  --listen-peer-urls=https://10.0.0.206:2380 \              # é›†ç¾¤ä¹‹é—´çš„é€šä¿¡ç«¯å£
  --listen-client-urls=https://10.0.0.206:2379,http://127.0.0.1:2379 \   # å®¢æˆ·ç«¯è®¿é—®åœ°å€
  --advertise-client-urls=https://10.0.0.206:2379 \                      # é€šå‘Šè‡ªå·±çš„å®¢æˆ·ç«¯ç«¯å£
  --initial-cluster-token=etcd-cluster-0 \               # åˆ›å»ºé›†ç¾¤ä½¿ç”¨çš„tokenï¼Œä¸€ä¸ªé›†ç¾¤å†…çš„èŠ‚ç‚¹ä¿æŒä¸€è‡´
  --initial-cluster=etcd-10.0.0.206=https://10.0.0.206:2380,etcd-10.0.0.207=https://10.0.0.207:2380,etcd-10.0.0.208=https://10.0.0.208:2380 \                     # é›†ç¾¤æ‰€æœ‰çš„èŠ‚ç‚¹ä¿¡æ¯ï¼ŒèŠ‚ç‚¹é—´ä¼šè¿›è¡Œå¥åº·æ€§æ£€æµ‹
  --initial-cluster-state=new \                # æ–°å»ºé›†ç¾¤çš„æ—¶å€™çš„å€¼ä¸ºnewï¼Œå¦‚æœæ˜¯å·²ç»å­˜åœ¨çš„é›†ç¾¤ä¸ºexisting
  --data-dir=/var/lib/etcd \                   # æ•°æ®ç›®å½•è·¯å¾„
  --wal-dir= \
  --snapshot-count=50000 \
  --auto-compaction-retention=1 \
  --auto-compaction-mode=periodic \
  --max-request-bytes=10485760 \
  --quota-backend-bytes=8589934592
Restart=always
RestartSec=15
LimitNOFILE=65536
OOMScoreAdjust=-999

[Install]
WantedBy=multi-user.target
```



### etcdé€‰ä¸¾

- etcdåŸºäºRaftç®—æ³•è¿›è¡Œé›†ç¾¤è§’è‰²é€‰ä¸¾ï¼Œä½¿ç”¨Raftçš„è¿˜æœ‰consulï¼ŒInfluxDBï¼ŒKafkaç­‰
- [Raftåè®®è¯¦è§£](CloudNative-Kubernetes.md##Raftåè®®)



### etcdé…ç½®ä¼˜åŒ–

```bash
# rquests size limit (è¯·æ±‚çš„æœ€å¤§å­—èŠ‚æ•°ï¼Œé»˜è®¤ä¸€ä¸ªkeyæœ€å¤§1.5Mibï¼Œå®˜æ–¹æœ€å¤§ä¸è¦è¶…è¿‡10Mib)
--max-request-bytes=10485760 

# storage size limit (ç£ç›˜å­˜å‚¨ç©ºé—´å¤§å°é™åˆ¶ï¼Œé»˜è®¤ä¸º2Gï¼Œæ­¤å€¼è¶…è¿‡8Gå¯åŠ¨ä¼šæœ‰è­¦å‘Šä¿¡æ¯)
# å› ä¸ºetcdå­˜å‚¨çš„é€šå¸¸éƒ½æ˜¯é›†ç¾¤çš„å…ƒæ•°æ®ï¼Œå› æ­¤å ç”¨ç£ç›˜å¤§å°ä¸å¤§ï¼Œä½†æ˜¯ç£ç›˜IOå¾ˆé«˜
--quota-backend-bytes=8589934592

# é›†ç¾¤ç¢ç‰‡æ•´ç†ï¼Œæ—¶é—´é•¿äº†å¯ä»¥åšä¸€ä¸‹ï¼Œæå‡æ€§èƒ½
# æ—©æœŸ
ETCDCTL_API=3 /usr/local/bin/etcdctl defrag --cluster --endpoints=https://10.0.0.206:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem

# ç°åœ¨åŸºæœ¬éƒ½æ˜¯ä½¿ç”¨v3ï¼Œä»¥å‰å¯èƒ½æœ‰ä½¿ç”¨v2çš„ï¼Œå› æ­¤éœ€è¦å£°æ˜v3ï¼Œç°åœ¨é»˜è®¤éƒ½æ˜¯v3ï¼Œæ‰€ä»¥ä¸éœ€è¦å£°æ˜
[root@k8s-10-0-0-206 ~]#/usr/local/bin/etcdctl defrag --cluster --endpoints=https://10.0.0.206:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem
Finished defragmenting etcd member[https://10.0.0.207:2379]
Finished defragmenting etcd member[https://10.0.0.206:2379]
Finished defragmenting etcd member[https://10.0.0.208:2379]

```



### etcdæ“ä½œ

#### etcdæˆå‘˜åˆ—è¡¨

```bash
[root@k8s-10-0-0-206 ~]#export NODE_IPS="10.0.0.206 10.0.0.207 10.0.0.208"

[root@k8s-10-0-0-206 ~]#ETCDCTL_API=3 /usr/local/bin/etcdctl --write-out=table member list --endpoints=https://10.0.0.206:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem
+------------------+---------+-----------------+-------------------------+-------------------------+------------+
|        ID        | STATUS  |      NAME       |       PEER ADDRS        |      CLIENT ADDRS       | IS LEARNER |
+------------------+---------+-----------------+-------------------------+-------------------------+------------+
| 2323451019f6428d | started | etcd-10.0.0.207 | https://10.0.0.207:2380 | https://10.0.0.207:2379 |      false |
| 23d31ba59ca79fa0 | started | etcd-10.0.0.206 | https://10.0.0.206:2380 | https://10.0.0.206:2379 |      false |
| 7a42012c95def99e | started | etcd-10.0.0.208 | https://10.0.0.208:2380 | https://10.0.0.208:2379 |      false |
+------------------+---------+-----------------+-------------------------+-------------------------+------------+
```



#### etcdéªŒè¯èŠ‚ç‚¹å¿ƒè·³çŠ¶æ€

```bash
[root@k8s-10-0-0-207 ~]#for ip in ${NODE_IPS}; do ETCDCTL_API=3 /usr/local/bin/etcdctl --endpoints=https://${ip}:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem endpoint health; done
https://10.0.0.206:2379 is healthy: successfully committed proposal: took = 68.505353ms
https://10.0.0.207:2379 is healthy: successfully committed proposal: took = 101.925588ms
https://10.0.0.208:2379 is healthy: successfully committed proposal: took = 109.962263ms
```



#### etcdæŸ¥çœ‹è¯¦ç»†ä¿¡æ¯

```bash
[root@k8s-10-0-0-207 ~]#for ip in ${NODE_IPS}; do ETCDCTL_API=3 /usr/local/bin/etcdctl --write-out=table endpoint status --endpoints=https://${ip}:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem; done
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
|        ENDPOINT         |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
| https://10.0.0.206:2379 | 23d31ba59ca79fa0 |  3.5.12 |  2.2 MB |     false |      false |         4 |     144353 |             144353 |        |
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
|        ENDPOINT         |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
| https://10.0.0.207:2379 | 2323451019f6428d |  3.5.12 |  2.2 MB |      true |      false |         4 |     144354 |             144354 |        |
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
|        ENDPOINT         |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
| https://10.0.0.208:2379 | 7a42012c95def99e |  3.5.12 |  2.2 MB |     false |      false |         4 |     144354 |             144354 |        |
+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+

```



#### æŸ¥çœ‹etcdæ•°æ®

```bash
# ä»¥è·¯å¾„çš„æ–¹å¼æ‰€æœ‰keyä¿¡æ¯
ETCD_API=3 etcdctl get / --prefix --keys-only  

# æŸ¥çœ‹podä¿¡æ¯ï¼š
[root@k8s-10-0-0-207 ~]#ETCD_API=3 etcdctl get / --prefix --keys-only|grep pod
/calico/ipam/v2/handle/k8s-pod-network.bff6832b73978900eea1e2cb579bbd2efaee3e114030af52c8a68e27b879e7be
/calico/resources/v3/projectcalico.org/profiles/ksa.kube-system.horizontal-pod-autoscaler
/calico/resources/v3/projectcalico.org/profiles/ksa.kube-system.pod-garbage-collector
/registry/clusterrolebindings/system:controller:horizontal-pod-autoscaler
/registry/clusterrolebindings/system:controller:pod-garbage-collector
/registry/clusterroles/system:controller:horizontal-pod-autoscaler
/registry/clusterroles/system:controller:pod-garbage-collector
/registry/poddisruptionbudgets/kube-system/calico-kube-controllers
/registry/pods/kube-system/calico-kube-controllers-cdf8978d8-d2xmc
/registry/pods/kube-system/calico-node-57htk
/registry/pods/kube-system/calico-node-5hmhr
/registry/pods/kube-system/calico-node-79jxn
/registry/pods/kube-system/calico-node-gs4xt
/registry/pods/kube-system/calico-node-j25th
/registry/pods/kube-system/calico-node-slntd
/registry/pods/kube-system/coredns-55c868d7f5-d76zv
/registry/serviceaccounts/kube-system/horizontal-pod-autoscaler
/registry/serviceaccounts/kube-system/pod-garbage-collector

# namespaceä¿¡æ¯
[root@k8s-10-0-0-207 ~]#ETCD_API=3 etcdctl get / --prefix --keys-only|grep namespaces
/registry/namespaces/default
/registry/namespaces/kube-node-lease
/registry/namespaces/kube-public
/registry/namespaces/kube-system

# æŸ¥çœ‹deploymentæ§åˆ¶å™¨ä¿¡æ¯
[root@k8s-10-0-0-207 ~]#ETCD_API=3 etcdctl get / --prefix --keys-only|grep deployment
/calico/resources/v3/projectcalico.org/profiles/ksa.kube-system.deployment-controller
/registry/clusterrolebindings/system:controller:deployment-controller
/registry/clusterroles/system:controller:deployment-controller
/registry/deployments/kube-system/calico-kube-controllers
/registry/deployments/kube-system/coredns
/registry/serviceaccounts/kube-system/deployment-controller

# æŸ¥çœ‹calicoç»„ä»¶ä¿¡æ¯
[root@k8s-10-0-0-207 ~]#ETCD_API=3 etcdctl get / --prefix --keys-only|grep calico
/calico/ipam/v2/assignment/ipv4/block/10.200.129.0-26
/calico/ipam/v2/assignment/ipv4/block/10.200.171.0-26
/calico/ipam/v2/assignment/ipv4/block/10.200.184.64-26
/calico/ipam/v2/assignment/ipv4/block/10.200.222.0-26
/calico/ipam/v2/assignment/ipv4/block/10.200.37.192-26
/calico/ipam/v2/assignment/ipv4/block/10.200.49.0-26
/calico/ipam/v2/config
......

# æŸ¥çœ‹keyçš„å€¼ï¼Œå†…å®¹å¯èƒ½å­˜åœ¨ä¹±ç ï¼Œéœ€è¦å·¥å…·ï¼ˆaugerï¼‰è¿›è¡Œè§£ç ï¼Œå°†etcdç¼–ç çš„æ•°æ®é‡æ–°æ’åˆ—
# ä¸‹è½½
[root@k8s-10-0-0-207 ~]# wget https://github.com/etcd-io/auger/releases/download/v1.0.3/auger_1.0.3_linux_amd64.tar.gz
[root@k8s-10-0-0-206 ~]#tar xf auger_1.0.3_linux_amd64.tar.gz 
[root@k8s-10-0-0-206 ~]#mv auger augerctl /usr/local/bin

# ç›¸å½“äºkubectl get pod -n kube-system calico-node-57htk -o yaml
[root@k8s-10-0-0-206 ~]#etcdctl get /registry/pods/kube-system/calico-node-57htk|auger decode
```



#### etcdå¢åˆ æ”¹æŸ¥

```bash
# æ·»åŠ æ•°æ®
[root@k8s-10-0-0-206 ~]# etcdctl put /name "tom"
OK

# æŸ¥è¯¢æ•°æ®
[root@k8s-10-0-0-206 ~]#etcdctl get /name
/name
tom

# ä¿®æ”¹æ•°æ®ï¼Œé‡æ–°putï¼Œå°†å€¼è¦†ç›–æ‰
[root@k8s-10-0-0-206 ~]#etcdctl put /name curry
OK
[root@k8s-10-0-0-206 ~]#etcdctl get /name
/name
curry

# åˆ é™¤æ•°æ®
[root@k8s-10-0-0-206 ~]#etcdctl del /name
1
```



#### etcdæ•°æ®watchæœºåˆ¶

åŸºäºä¸æ–­ç›‘çœ‹æ•°æ®ï¼Œå‘ç”Ÿå˜åŒ–å°±ä¸»åŠ¨è§¦å‘é€šçŸ¥å®¢æˆ·ç«¯ï¼ŒEtcd v3 çš„watchæœºåˆ¶æ”¯æŒwatchæŸä¸ªå›ºå®šçš„keyï¼Œä¹Ÿæ”¯æŒwatchä¸€ä¸ªèŒƒå›´

```bash
# åœ¨etcd1 ä¸Šwatchä¸€ä¸ªkeyï¼Œæ²¡æœ‰æ­¤keyä¹Ÿå¯ä»¥æ‰§è¡Œwatchï¼ŒåæœŸå¯ä»¥å†åˆ›å»º
[root@k8s-10-0-0-206 ~]#etcdctl watch /data

# åœ¨etcd2 ä¿®æ”¹æ•°æ®ï¼ŒéªŒè¯etcd1æ˜¯å¦å‘ç”Ÿæ•°æ®å˜åŒ–
[root@k8s-10-0-0-207 ~]#etcdctl put /data "data v1"
OK

# è§‚å¯Ÿetcd1
[root@k8s-10-0-0-206 ~]#etcdctl watch /data
PUT
/data
data v1

[root@k8s-10-0-0-207 ~]#etcdctl put /data "data v2"
OK

[root@k8s-10-0-0-206 ~]#etcdctl watch /data
PUT
/data
data v1
PUT
/data
data v2
```



#### Kubernetes ä¸Š Watchæœºåˆ¶ç¤ºä¾‹

```bash
# kuber-schedulerä¼šwatch /registry/podsï¼Œ/registry/nodesï¼Œ/registry/bindings
# åœ¨etcd1 watch /registry/pods
[root@k8s-10-0-0-206 ~]#etcdctl watch --prefix /registry/pods

# åˆ›å»ºä¸€ä¸ªpod
[root@master-01 pod]#kubectl apply -f myapp.yaml 
pod/alpine3 created

# è§‚å¯Ÿåˆšåˆšwatchçš„è·¯å¾„
[root@k8s-10-0-0-206 ~]#etcdctl watch --prefix /registry/pods
PUT
/registry/pods/default/alpine3
k8s
......

# åˆ é™¤åˆšåˆšåˆ›å»ºçš„pod->alpine3
# æŸ¥çœ‹etcdçš„key
[root@k8s-10-0-0-207 ~]#etcdctl get / --prefix --keys-only |grep events
/registry/apiregistration.k8s.io/apiservices/v1.events.k8s.io
/registry/events/default/alpine3.1834a7d6ad5491c5
/registry/events/default/alpine3.1834a7d6ffc8fbb9
/registry/events/default/alpine3.1834a7d86aa93aa4
/registry/events/default/alpine3.1834a7d8788b8e49
/registry/events/default/alpine3.1834a7d88764f93d
/registry/events/default/alpine3.1834a7dbe6982b44
/registry/events/default/alpine3.1834a7eec882ed84
/registry/events/default/alpine3.1834a7ef13aa3e3e
/registry/events/default/alpine3.1834a7f05f0ef84e
/registry/events/default/alpine3.1834a7f0616b646a
/registry/events/default/alpine3.1834a7f06d7c3b22
/registry/events/default/alpine3.1834a7f0f67862de

# ä¸ºä»€ä¹ˆ /registry/events/default/alpine3.* æœ‰è¿™ä¹ˆå¤šæ¡ç›®ï¼Ÿ
# ä½ åˆ›å»º Pod alpine3 åï¼ŒKubernetes æ§åˆ¶å¹³é¢ï¼ˆå°¤å…¶æ˜¯ kubelet å’Œ controller-managerï¼‰ä¼šå¯¹è¯¥ Pod çš„ç”Ÿå‘½å‘¨æœŸè¿‡ç¨‹ä¸æ–­è®°å½•äº‹ä»¶ï¼Œä¾‹å¦‚ï¼šScheduledï¼ŒPulling imageï¼ŒCreated containerï¼ŒStarted container......
# æ¯æ¡äº‹ä»¶éƒ½ä¼šå•ç‹¬ä½œä¸ºä¸€ä¸ªå¯¹è±¡å†™å…¥ etcdï¼Œè·¯å¾„å°±æ˜¯ï¼š/registry/events/{namespace}/{pod-name}.{event-uuid}
# æ‰€ä»¥ä¼šçœ‹åˆ°å¾ˆå¤šæ¡/registry/events/default/alpine3.XXXXXXX

# é‚£æˆ‘æŠŠ Pod åˆ é™¤äº†ï¼Œä¸ºä»€ä¹ˆè¿™äº›äº‹ä»¶è¿˜åœ¨ï¼Ÿ
# äº‹ä»¶èµ„æºï¼ˆevents.k8s.ioï¼‰æ˜¯ éç»‘å®šç”Ÿå‘½å‘¨æœŸèµ„æºï¼ˆnon-owner referenceï¼‰ï¼Œå³ä½¿ Pod è¢«åˆ é™¤ï¼Œäº‹ä»¶å¹¶ä¸ä¼šé©¬ä¸Šè¢«æ¸…ç†æ‰ã€‚

# äº‹ä»¶çš„ä¿ç•™ç­–ç•¥å¦‚ä¸‹ï¼š
# ç±»å‹: CoreV1 Event   ---->  é»˜è®¤ä¿ç•™æ—¶é—´ ~1 å°æ—¶å·¦å³ï¼ˆ1hï¼‰
# ç±»å‹: Events.k8s.io/v1   ---->  é»˜è®¤ä¹Ÿå¤§çº¦ 1 å°æ—¶ï¼Œå…·ä½“å–å†³äº GC ç­–ç•¥

# è¿™äº›äº‹ä»¶ç”± event æ§åˆ¶å™¨å®šæœŸæ¸…ç†ï¼Œæˆ–è€…ç”±ç»„ä»¶ï¼ˆå¦‚ kube-controller-managerï¼‰åå°åƒåœ¾å›æ”¶ã€‚
# ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼éªŒè¯å…¶ TTLï¼škubectl get events --all-namespaces --output=wide
# ä½ ä¹Ÿå¯ä»¥ watch /registry/events çš„å˜åŒ–ï¼Œè¿‡ä¸€ä¼šå®ƒä»¬ä¼šè‡ªåŠ¨ä» etcd ä¸­æ¸…é™¤ã€‚

# kube-proxyä¼š watch /registry/services/specs/
# å¦‚æœæƒ³è¦è§‚å¯Ÿåˆ°è¿™ä¸ªè·¯å¾„ä¸‹çš„å˜åŒ–è¦å…³æ‰æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„kube-proxyï¼Œå¦åˆ™åˆšåˆ é™¤æ•°æ®å˜åŒ–ï¼Œå°±ä¼šè¢«kube-proxyæ¶ˆè´¹æ‰
```



### etcd v3 APIç‰ˆæœ¬æ•°æ®å¤‡ä»½ä¸æ¢å¤

**WAL**æ˜¯write ahead logï¼ˆé¢„å†™æ—¥å¿—ï¼‰çš„ç¼©å†™ï¼Œé¡¾åæ€ä¹‰ï¼Œä¹Ÿå°±æ˜¯åœ¨æ‰§è¡ŒçœŸæ­£çš„å†™æ“ä½œä¹‹å‰å…ˆå†™ä¸€ä¸ªæ—¥å¿—ï¼Œé¢„å†™æ—¥å¿—ï¼ˆè¯¦æƒ…å¯ä»¥çœ‹è¡¥å……ï¼šraftåè®®è¯¦è§£ï¼‰

**WAL**ï¼šå­˜æ”¾é¢„å†™å¼æ—¥å¿—ï¼Œæœ€å¤§çš„ä½œç”¨æ˜¯è®°å½•äº†æ•´ä¸ªæ•°æ®å˜åŒ–çš„å…¨éƒ¨å†ç¨‹ã€‚åœ¨etcdä¸­ï¼Œæ‰€æœ‰æ•°æ®çš„ä¿®æ”¹åœ¨æäº¤å‰ï¼Œéƒ½è¦å…ˆå†™å…¥åˆ°WALä¸­ã€‚



#### V3ç‰ˆæœ¬å¤‡ä»½æ•°æ®

```bash
ETCDCTL_API=3 etcdctl snapshot save snapshot.db

# ç¤ºä¾‹
[root@k8s-10-0-0-206 ~]#etcdctl snapshot save /tmp/etcd.db
{"level":"info","ts":"2025-04-09T21:43:15.766559+0800","caller":"snapshot/v3_snapshot.go:65","msg":"created temporary db file","path":"/tmp/etcd.db.part"}
{"level":"info","ts":"2025-04-09T21:43:15.776496+0800","logger":"client","caller":"v3@v3.5.12/maintenance.go:212","msg":"opened snapshot stream; downloading"}
{"level":"info","ts":"2025-04-09T21:43:15.776865+0800","caller":"snapshot/v3_snapshot.go:73","msg":"fetching snapshot","endpoint":"127.0.0.1:2379"}
{"level":"info","ts":"2025-04-09T21:43:15.998158+0800","logger":"client","caller":"v3@v3.5.12/maintenance.go:220","msg":"completed snapshot read; closing"}
{"level":"info","ts":"2025-04-09T21:43:16.006574+0800","caller":"snapshot/v3_snapshot.go:88","msg":"fetched snapshot","endpoint":"127.0.0.1:2379","size":"2.3 MB","took":"now"}
{"level":"info","ts":"2025-04-09T21:43:16.007478+0800","caller":"snapshot/v3_snapshot.go:97","msg":"saved","path":"/tmp/etcd.db"}
Snapshot saved at /tmp/etcd.db

# æŸ¥çœ‹
[root@k8s-10-0-0-206 ~]#ls /tmp/
etcd.db

# å¦‚æœåæœŸetcdé›†ç¾¤æ•°æ®æŸåï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ªetcd.dbï¼Œå°†æ•°æ®æ¢å¤
```



#### V3ç‰ˆæœ¬æ¢å¤æ•°æ®

```bash
# å°†æ•°æ®æ¢å¤åˆ°ä¸€ä¸ªæ–°çš„ä¸å­˜åœ¨çš„ç›®å½•ä¸­ï¼Œå•æœºæ¢å¤
# æ¢å¤æ•°æ®æŒ‡å®šçš„æ•°æ®ç›®å½•å¿…é¡»æ˜¯æ–°çš„
ETCDCTL_API=3 etcdctl snapshot restore snapshot.db --data-dir=/opt/etcd-testdir

# å®é™…ç”Ÿäº§ä¸­æ•°æ®æ¢å¤
# æ³¨æ„ï¼šé›†ç¾¤æ¢å¤å¿…é¡»åŠ ä¸‹é¢çš„å‚æ•°ï¼Œå¦åˆ™æ¢å¤çš„æ˜¯å•æœºçŠ¶æ€ï¼ï¼ï¼
ETCDCTL_API=3 /usr/local/bin/etcdctl snapshot restore snapshot.db \
--name etcd-{{ inventory_hostname }} \    # è¿™é‡Œå¿…é¡»åŠ etcdçš„nameï¼Œä¸‹é¢çš„å‚æ•°å¯ä»¥é€šè¿‡etcd.serviceæŸ¥çœ‹
--initial-cluster {{ ETCD_NODES }} \
--initial-cluster-token etcd-cluster-0 \
--initial-advertise-peer-urls https://{{ inventory_hostname }}:2380

# æ¢å¤æ•°æ®è‡³etcdæ•°æ®ç›®å½•
cp -rf /etc/_backup/etcd-{{ inventory_hostnamme }}.etcd/member {{ ETCD_DATA_DIR }}/

# é‡å¯etcdæ•°æ®ç›®å½•
systemctl restart etcd.service
```



#### è‡ªåŠ¨å¤‡ä»½æ•°æ®

```bash
[root@k8s-10-0-0-206 ~]# mkdir /data/etcd-backup-dir/ -p
[root@k8s-10-0-0-206 ~]# cat etcd-backup.sh
#!/bin/bash
source /etc/profile
DATE=`data +%Y-%m-%d_%H-%M-%S`
ETCDCTL_API=3 /usr/local/bin/etcdctl snapshot save /data/etcd-backup-dir/etcd-snapshot-${DATE}.db
```



#### ä½¿ç”¨kubeaszå¤‡ä»½æ¢å¤é›†ç¾¤æ•°æ®

```bash
# ./ezctl backup <é›†ç¾¤å>
[root@haproxy1 ~]#./ezctl backup k8s-cluster1

# æŸ¥çœ‹å¤‡ä»½çš„æ•°æ®
[root@haproxy1 kubeasz]#ls clusters/k8s-cluster1/backup/
snapshot_202504092210.db  snapshot.db

# æ¢å¤æŒ‡å®šç‰ˆæœ¬/æ—¥æœŸçš„å¤‡ä»½æ–‡ä»¶
# æ–¹æ³•1ï¼šä¿®æ”¹ansible
[root@haproxy1 kubeasz]# vim ./roles/cluster-restore/defaults/main.yaml
# æŒ‡å®šéœ€è¦æ¢å¤çš„ etcd æ•°æ®å¤‡ä»½ï¼Œé»˜è®¤ä½¿ç”¨æœ€è¿‘çš„ä¸€æ¬¡å¤‡ä»½
# åœ¨ansible æ§åˆ¶ç«¯æŸ¥çœ‹å¤‡ä»½ç›®å½•ï¼š/etc/kubeasz/clusters/_cluster_name_/backup
db_to_restore: "snapshot.db"    # æ”¹è¿™é‡Œ

# æ–¹æ³•2ï¼šå°†æŒ‡å®šç‰ˆæœ¬/æ—¥æœŸå¤‡ä»½æ–‡ä»¶è¦†ç›–snapshot.db
[root@haproxy1 kubeasz]# cd  clusters/k8s-cluster1/backup/ && cp snapshot_XXXX.db snapshot.db

# æ¢å¤æ•°æ®
# æ¢å¤æ•°æ®çš„æ—¶å€™ï¼Œä¼šå…³é—­masterä¸Šçš„apiserverç¦æ­¢å†™å…¥
[root@haproxy1 kubeasz]# ./ezctl restore k8s-cluster1

# æ³¨æ„ï¼ï¼ï¼ï¼šæ‰§è¡Œæ¢å¤å‰æŸ¥çœ‹
[root@haproxy1 kubeasz]#cat roles/cluster-restore/tasks/main.yml 
- name: åœæ­¢ectd æœåŠ¡
  service: name=etcd state=stopped

- name: æ¸…é™¤etcd æ•°æ®ç›®å½•
  file: name={{ ETCD_DATA_DIR }}/member state=absent

- name: æ¸…ç†ä¸Šæ¬¡å¤‡ä»½æ¢å¤æ•°æ®
  file: name=/etcd_backup state=absent

- name: ç”Ÿæˆå¤‡ä»½ç›®å½•
  file: name=/etcd_backup state=directory

- name: å‡†å¤‡æŒ‡å®šçš„å¤‡ä»½etcd æ•°æ®
  copy:
    src: "{{ cluster_dir }}/backup/{{ db_to_restore }}"
    dest: "/etcd_backup/snapshot.db"

- name: etcd æ•°æ®æ¢å¤
  shell: "cd /etcd_backup && \
	ETCDCTL_API=3 {{ bin_dir }}/etcdctl snapshot restore snapshot.db \   # ä¸‹é¢å¿…é¡»åŠ å‚æ•°ï¼Œå¦åˆ™ä¼šå‡ºç°bug
	--name etcd-{{ inventory_hostname }} \
	--initial-cluster {{ ETCD_NODES }} \
	--initial-cluster-token etcd-cluster-0 \
	--initial-advertise-peer-urls https://{{ inventory_hostname }}:2380"

- name: æ¢å¤æ•°æ®è‡³etcd æ•°æ®ç›®å½•
  shell: "cp -rf /etcd_backup/etcd-{{ inventory_hostname }}.etcd/member {{ ETCD_DATA_DIR }}/"

- name: é‡å¯etcd æœåŠ¡
  service: name=etcd state=restarted

- name: ä»¥è½®è¯¢çš„æ–¹å¼ç­‰å¾…æœåŠ¡åŒæ­¥å®Œæˆ
  shell: "systemctl is-active etcd.service"
  register: etcd_status
  until: '"active" in etcd_status.stdout'
  retries: 8
  delay: 8
```



#### ETCDæ•°æ®æ¢å¤æµç¨‹

å½“etcdé›†ç¾¤å®•æœºæ•°é‡è¶…è¿‡é›†ç¾¤æ€»èŠ‚ç‚¹ä¸€åŠä»¥ä¸Šçš„æ—¶å€™ï¼ˆå¦‚æ€»æ•°ä¸ºä¸‰å°å®•æœºä¸¤å°ï¼‰ï¼Œå°±ä¼šå¯¼è‡´æ•´ä¸ªé›†ç¾¤å®•æœºï¼ŒåæœŸéœ€è¦æ¢å¤æ•°æ®

- æ¢å¤æœåŠ¡å™¨ç³»ç»Ÿ
- é‡æ–°éƒ¨ç½²ETCDé›†ç¾¤
- åœæ­¢kube-apisever/controller-manager/scheduler/kubelet/kube-proxy
- åœæ­¢ETCDé›†ç¾¤
- å„ETCDèŠ‚ç‚¹æ¢å¤åŒä¸€ä»½å¤‡ä»½æ•°æ®
- å¯åŠ¨å„èŠ‚ç‚¹å¹¶éªŒè¯ETCDé›†ç¾¤
- å¯åŠ¨kube-apisever/controller-manager/scheduler/kubelet/kube-proxy
- éªŒè¯k8s masterçŠ¶æ€åŠpodæ•°æ®



### ETCDé›†ç¾¤èŠ‚ç‚¹æ·»åŠ ä¸åˆ é™¤

- add-etcd
- del-etcd



## Kubernetesèµ„æºå¯¹è±¡å’ŒPodèµ„æº



**æœ¬ç« å†…å®¹**

- **èµ„æºå¯¹è±¡**
- **åç§°ç©ºé—´**
- **Podèµ„æº**
- **Podå·¥ä½œæœºåˆ¶**



### èµ„æºå¯¹è±¡

#### Kuberneteså¸¸è§èµ„æºå¯¹è±¡

![alt text](images/image29.png)



#### Kubernetesä¸­èµ„æºå¯¹è±¡çš„åˆ†ç±»



**ç‹¬ç«‹å­˜åœ¨çš„èµ„æº**

Kubernetes ç³»ç»Ÿå°†ä¸€åˆ‡äº‹ç‰©éƒ½ç§°ä¸ºèµ„æºå¯¹è±¡, ç›¸å½“äºé¢å‘å¯¹è±¡çš„æ€æƒ³ 

æœ‰ä¸€äº›ç‹¬ç«‹å­˜åœ¨,å³ä¸ä¾èµ–äºå…¶å®ƒå¯¹è±¡å­˜åœ¨çš„èµ„æºç±»å‹, Kubernetes æä¾›äº†å•ç‹¬çš„ API èµ„æºï¼Œå…¶**éµå¾ª  REST é£æ ¼**ç»„ç»‡å¹¶ç®¡ç†è¿™äº›èµ„æºå¯¹è±¡

å¯¹è¿™äº›API èµ„æºç±»å‹æ”¯æŒä½¿ç”¨æ ‡å‡†çš„ HTTP æ–¹æ³•(POST,PUT,PATCH,DELETE å’Œ GET)å¯¹èµ„æºè¿›è¡Œå¢ã€åˆ ã€ æ”¹å’ŒæŸ¥ã€‚



**ä¸èƒ½ç‹¬ç«‹å­˜åœ¨çš„èµ„æº**

ä¹Ÿæœ‰ä¸€äº›èµ„æºKubernetes  ä¸­å¹¶æ²¡æœ‰æä¾›å¯¹åº”ç‹¬ç«‹çš„APIèµ„æºç±»å‹,ä¸èƒ½ç‹¬ç«‹åˆ›å»º,éœ€è¦ä¾é™„å…¶å®ƒèµ„æºçš„å­˜ åœ¨, æ¯”å¦‚: Label,emptyDirç­‰



```ABAP
åœ¨ Kubernetes ç³»ç»Ÿä¸­ï¼Œèµ„æºä»£è¡¨äº†å¯¹è±¡çš„é›†åˆï¼Œä¾‹å¦‚ï¼šPod èµ„æºå¯ç”¨äºæè¿°æ‰€æœ‰ Podç±»å‹çš„å¯¹è±¡ã€‚å¯¹ è±¡å®è´¨æ˜¯èµ„æºç±»å‹ç”Ÿæˆçš„å®ä¾‹ã€‚
```



 

**Kubernetes çš„API  èµ„æºåˆ†ä¸ºä¸¤ç§:**

- å†…ç½®API èµ„æº: Kubernetes å®‰è£…åè‡ªèº«å…·æœ‰çš„è‡ªå®šä¹‰çš„API èµ„æº: 
- ç”¨æˆ·è‡ªå®šä¹‰çš„API,ç§°ä¸ºCRD(Custom Resource Definition),å¯ä»¥é€šè¿‡å®‰è£…ä¸€äº›ç»„ä»¶ç”Ÿæˆ



**ä»èµ„æºçš„ä¸»è¦åŠŸèƒ½ä¸ŠKubernetes çš„èµ„æºå¯¹è±¡åˆ†ä¸º**

- Workloads(å·¥ä½œè´Ÿè½½)
- Service,LoadBalancing and Networking(æœåŠ¡å‘ç°å’Œè´Ÿè½½å‡è¡¡)
- å­˜å‚¨å’Œé…ç½®(Storage&Configuration)
- Cluster Admin(é›†ç¾¤ç®¡ç†)
- Policies&Scheduling(ç­–ç•¥å’Œè°ƒåº¦)
-  Metadata(å…ƒæ•°æ®)



**K8Sèµ„æºè¿˜å¯ä»¥æŒ‰é€‚ç”¨èŒƒå›´åˆ†ä¸º:åç§°ç©ºé—´çº§åˆ«ã€é›†ç¾¤çº§åˆ«ã€å…ƒæ•°æ®ç±»å‹**

- **åç§°ç©ºé—´çº§åˆ«**
  - ä»…åœ¨æ­¤åç§°ä¸­ç”Ÿæ•ˆã€‚ä¸¾ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬ä¹‹å‰é€šè¿‡ kubeadm å»å®‰è£…æˆ‘ä»¬K8S é›†ç¾¤çš„æ—¶ å€™ï¼Œä»–ä¼šé»˜è®¤æŠŠæ‰€æœ‰ç»„ä»¶æ”¾åˆ° kube-system è¿™ä¸ªåç§°ç©ºé—´ä¸‹å»è¿è¡Œï¼Œç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡å‘½ä»¤ kubectl get pod çš„æ—¶å€™ä¼šçœ‹åˆ°å®ƒè·å–ä¸åˆ°ï¼Œå¯¹åº”çš„æˆ‘ä»¬ç³»ç»Ÿä¸€äº› pod çš„ä¿¡æ¯ï¼ŒåŸå› æ˜¯é»˜è®¤æƒ…å†µ ä¸‹è¯¥å‘½ä»¤ä»€ä¹ˆéƒ½ä¸åŠ çš„è¯ç›¸å½“äºæ˜¯ kubectl get pod -n default ï¼Œä½†æ˜¯æˆ‘ä»¬çš„  K8S æœ¬èº«ç»„ä»¶ä»– æ˜¯æ”¾åœ¨æˆ‘ä»¬çš„ kube-system åç§°ç©ºé—´ä¸‹çš„ï¼Œæ‰€æœ‰è¿™ç§æƒ…å†µæˆ‘ä»¬ä¼šå‘ç°ï¼Œåœ¨  kube-system åç§°ç©ºé—´ ä¸‹çš„èµ„æºæˆ‘ä»¬åœ¨å…¶ä»–åç§°ç©ºé—´ä¸­æ˜¯çœ‹ä¸è§çš„ã€‚è¿™å°±æ˜¯å…¸å‹çš„åç§°ç©ºé—´çº§åˆ«èµ„æºã€‚



- **é›†ç¾¤çº§åˆ«**
  - æ¯”å¦‚ã€role ç­‰ç­‰ï¼Œè¿™éƒ½æ˜¯é›†ç¾¤çº§åˆ«çš„èµ„æºï¼Œä¸ç®¡åœ¨ä»€ä¹ˆåç§°ç©ºé—´ä¸‹å»å®šä¹‰ï¼Œåœ¨å…¶ä»–çš„å ç§°ç©ºé—´ä¸‹éƒ½èƒ½å¤Ÿçœ‹å¾—åˆ°ï¼Œå…¶å®ä»–åœ¨å®šä¹‰çš„æ—¶å€™éƒ½æ²¡æœ‰å»æŒ‡å®šæ‰€è°“çš„åç§°ç©ºé—´ï¼Œä¹Ÿå°±æ„å‘³ç€ä¸€æ—¦ç»è¿‡ å®šä¹‰ä»¥ååœ¨å…¨é›†ç¾¤ä¸­éƒ½èƒ½å¤Ÿè¢«å¯è§ä»¥åŠè°ƒç”¨ï¼Œè¿™ç§çº§åˆ«å‘¢æˆ‘ä»¬å°±æŠŠå®ƒé›†ç¾¤çº§åˆ«ä¸‹çš„åç§°ç©ºé—´ï¼Œå¹¶ä¸” æŠŠè¿™ç§ä¸œè¥¿å«åšé›†ç¾¤çº§åˆ«çš„èµ„æº



- **å…ƒæ•°æ®å‹**
  - è´Ÿè´£æä¾›ä¸€ç§æŒ‡æ ‡ï¼Œæºæ•°æ®ç±»å‹å®ƒä¸åƒæˆ‘ä»¬çš„åç§°ç©ºé—´çº§åˆ«å’Œé›†ç¾¤çº§åˆ«ï¼Œå…¶å®å®ƒä¹Ÿå¯ä»¥ å½’å±åœ¨è¿™ä¸¤è€…ä¹‹é—´ï¼Œä½†æ˜¯å®ƒåˆæœ‰è‡ªå·±çš„ç‰¹ç‚¹æ‰€ä»¥æˆ‘ä»¬å°†ä»–æ‹¿å‡ºæ¥è¿›è¡Œå•ç‹¬çš„åˆ†ç±»ã€‚æ¯”å¦‚å‰é¢è®²è¿‡çš„  HPA ä»–å°±æ˜¯å¯ä»¥é€šè¿‡æˆ‘ä»¬çš„ CPU è¿›è¡Œå¹³æ»‘æ‰©å±•ï¼Œä»–å°±æ˜¯å…¸å‹çš„æºæ•°æ®å‹ã€‚é€šè¿‡æˆ‘ä»¬çš„æŒ‡æ ‡è¿›è¡Œæ“ ä½œã€‚



#### èµ„æºåŠå…¶åœ¨ API ä¸­çš„ç»„ç»‡å½¢å¼

Kubernetes åˆ©ç”¨æ ‡å‡†çš„ **RESTful æœ¯è¯­**æ¥æè¿°å…¶ API æ¦‚å¿µ

- **èµ„æºç±»å‹**ï¼šæ˜¯æŒ‡åœ¨ URL ä¸­ä½¿ç”¨çš„åç§°ï¼Œå¦‚ Podã€Namespace å’Œ Service ç­‰ï¼Œå…¶ URL æ ¼å¼ ä¸º"**/GROUP/VERSION/RESOURCE**"ï¼Œç¤ºä¾‹ï¼š/apps/v1/deployment

- æ‰€æœ‰èµ„æºç±»å‹éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„ JSON è¡¨ç¤ºæ ¼å¼ï¼š**kind(ç§ç±»)**ï¼Œåœ¨ K8s ä¸­ç”¨æˆ·åˆ›å»ºå¯¹è±¡å¿…é¡»ä»¥ JSONæ ¼ å¼æäº¤å¯¹è±¡çš„é…ç½®ä¿¡æ¯
- éš¶å±äºåŒä¸€èµ„æºç±»å‹çš„å¯¹è±¡ç»„æˆçš„åˆ—è¡¨ç§°ä¸º **collection(é›†åˆ)**ï¼Œå¦‚ PodList
-   æŸç§ç±»å‹çš„å•ä¸ªå®ä¾‹ç§°ä¸º**"resource"(èµ„æº)**æˆ–**"object"(å¯¹è±¡)**ï¼Œå¦‚è¿è¡Œçš„åä¸º pod-test çš„ Pod å¯¹è±¡



**APIç¾¤ç»„**

Kubernetes å°† API åˆ†å‰²ä¸ºå¤šä¸ªé€»è¾‘ç»„åˆï¼Œç§°ä¸ºAPI ç¾¤ç»„ï¼Œä¸åŒçš„ç¾¤ç»„æ”¯æŒå•ç‹¬å¯ç”¨æˆ–ç¦ç”¨ï¼Œå¹¶å¯ä»¥å†æ¬¡ åˆ†è§£ã€‚ç¾¤ç»„åŒ–ç®¡ç†çš„ API ä½¿å¾—å…¶å¯ä»¥æ›´è½»æ¾çš„è¿›è¡Œæ‰©å±•ã€‚å½“å‰ K8s é›†ç¾¤ç³»ç»Ÿä¸Šçš„ API server ä¸Šçš„ç›¸å…³ä¿¡ æ¯å¯ä»¥ä½¿ç”¨ kubectl api-versions è·å–ã€‚é…ç½®èµ„æºæ¸…å•æ—¶ä¼šä½¿ç”¨ API ç¾¤ç»„

```bash
#æ˜¾ç¤ºAPIç¾¤ç»„,ç»“æœæ ¼å¼ä¸º: GROUP_NAME/VERSOIN,åŒä¸€ä¸ªç»„å¯ä»¥æœ‰å¤šç‰ˆæœ¬å¹¶å­˜
#GROUP_NAMEï¼šAPIç¾¤ç»„åï¼Œå¦‚æœçœç•¥è¡¨ç¤ºå±äºcoreæ ¸å¿ƒç»„
#VERSION:v1,ç»è¿‡éªŒè¯çš„ç¨³å®šç‰ˆæœ¬ï¼Œå¯ä»¥ç”Ÿäº§ç¯å¢ƒä½¿ç”¨,å¦‚:apps/v1
#alpha:å†…æµ‹,å¯èƒ½åŒ…å«é”™è¯¯ï¼Œç”Ÿäº§ä¸å»ºè®®ä½¿ç”¨
#beta: å…¬æµ‹ï¼Œå­˜åœ¨å˜åŠ¨çš„å¯èƒ½æˆ–è€…æ½œåœ¨çš„é—®é¢˜ï¼Œç”Ÿäº§ä¸å»ºè®®ä½¿ç”¨,å¦‚:autoscaling/v2beta2
```

Kubernetes çš„ API ä»¥å±‚çº§ç»“æ„ç»„ç»‡åœ¨ä¸€èµ·

- Objectï¼šèµ„æºå‹å¯¹è±¡ï¼Œè¡¨ç°ä¸º **http urlä¸­path**
- éObjectï¼šéèµ„æºå‹å¯¹è±¡ï¼Œkubernetesç‰¹æœ‰ï¼Œä¾‹å¦‚: /healthz



Objectèµ„æºå‹å¯¹è±¡å¯¹åº”çš„ API ç¾¤ç»„å¯ä»¥å½’ä¸ºä»¥ä¸‹ä¸¤ç±»ï¼š

- **æ ¸å¿ƒç¾¤ç»„(core group)ï¼š**

  -  åœ¨èµ„æºçš„é…ç½®ä¿¡æ¯ apiVersion å­—æ®µä¸­å¼•ç”¨æ—¶å¯ä»¥ä¸ç”¨æŒ‡å®šè·¯å¾„,å¦‚:"apiVersion: v1
  - **REST è·¯å¾„ä¸º /api/v1**

  ```bash
  # RESTfulé£æ ¼çš„URLæ ¼å¼ 
  https://API_SERVER:HOST/api/v1/namespaces/<NS_NAME>/<RESOURCE_NANE>/<OBJECT_NAME>
  
  #defaultåç§°ç©ºé—´ä¸‹çš„mypodçš„Podèµ„æºï¼ŒURLè·¯å¾„ç›´æ¥è®¿é—®
  curl https://API_SERVER:HOST/api/vl/namespaces/default/pods/mypod
  ```

  æ‰©å±•ï¼š**kubectl get --raw ä½œç”¨è¯¦è§£**

  - **ç›´æ¥è®¿é—® Kubernetes API**

    - `kubectl get --raw` ä¸åƒ `kubectl get pods` è¿™æ ·çš„å‘½ä»¤ä¼šå¯¹æ•°æ®åšé¢å¤–çš„å¤„ç†
    - å®ƒçš„æ•ˆæœå’Œä»¥ä¸‹å‘½ä»¤å‡ ä¹ä¸€è‡´ï¼š

    ```bash
    curl -k -H "Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)" \
      https://<API_SERVER>:6443/api/v1/namespaces/default/pods/myapp-7b94444f8d-66d4h
    ```

  - **è¿”å›çš„æ˜¯å®Œæ•´çš„åŸå§‹ JSON æ ¼å¼çš„å“åº”**

    - `kubectl get pods` é€šå¸¸ä¼šè¾“å‡ºè¡¨æ ¼æ•°æ®ï¼š

    ```bash
    NAME                          READY   STATUS    RESTARTS   AGE
    myapp-7b94444f8d-66d4h        1/1     Running   0          10m
    ```

    - ä½†æ˜¯ `kubectl get --raw` è¿”å›çš„åˆ™æ˜¯ **åŸå§‹çš„ JSON æ ¼å¼**ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

    ```json
    {
      "kind": "Pod",
      "apiVersion": "v1",
      "metadata": {
        "name": "myapp-7b94444f8d-66d4h",
        "namespace": "default",
        "uid": "12345678-1234-1234-1234-123456789abc",
        "creationTimestamp": "2024-12-15T10:00:00Z"
      },
      "spec": {
        "containers": [
          {
            "name": "myapp",
            "image": "nginx:1.26.0",
            "ports": [
              {
                "containerPort": 80,
                "protocol": "TCP"
              }
            ]
          }
        ]
      },
      "status": {
        "phase": "Running",
        "conditions": [
          {
            "type": "Initialized",
            "status": "True"
          },
          {
            "type": "Ready",
            "status": "True"
          },
          {
            "type": "ContainersReady",
            "status": "True"
          }
        ]
      }
    }
    
    ```

  - **å¸¸è§ä½¿ç”¨åœºæ™¯**

    - **æŸ¥çœ‹ Kubernetes çš„æ‰€æœ‰APIèµ„æº**

    ```bash
    kubectl get --raw="/apis"
    # è¿™ä¼šåˆ—å‡ºå½“å‰ Kubernetes é›†ç¾¤ä¸­å¯ç”¨çš„ API ç‰ˆæœ¬å’Œèµ„æº
    ```

    - **è·å–ç‰¹å®špodçš„è¯¦ç»†ä¿¡æ¯**

    ```bash
    kubectl get --raw="/api/v1/namespaces/default/pods/myapp-7b94444f8d-66d4h"
    # è§£é‡Šï¼šè¿”å›è¿™ä¸ª pod çš„è¯¦ç»†ä¿¡æ¯ï¼Œæ¯” kubectl get pod myapp-7b94444f8d-66d4h -o json æä¾›æ›´å¤šçš„APIå…ƒæ•°æ®ä¿¡æ¯ã€‚
    ```

    -  **è·å– Kube-Proxy çš„å¥åº·æ£€æŸ¥**

    ```bash
    kubectl get --raw="/healthz"
    # è¿”å›å­—ç¬¦ä¸²
    ```

    - **æŸ¥çœ‹æ‰€æœ‰ Kubernetes ç‰ˆæœ¬API**

    ```bash
    kubectl get --raw="/version"
    # è¿”å›jsonæ•°æ®
    ```

    - **è®¿é—® webhook è¯·æ±‚æ—¥å¿—**

    ```bash
    kubectl get --raw="/logs"
    ```

- **å‘½åçš„ç¾¤ç»„(named group)**

  - å³æœ‰åç§°çš„ç¾¤ç»„
  -  REST è·¯å¾„ä¸º `/apis/$GROUP_NAME/$VERSION` , å¦‚ `/apis/apps/v1`

  ```bash
  https://API_SERVER:HOST/apis/GROUP_NANE/VERSION/namespaces/<NS_MTNE>/<RESOURCE_NAME>/<0B3ECT_NNE
  /apis/<GROUP_NAME>/<VERSION>/<NAMESPACE>/default/deployments/
  /apis/<GROUP_NAME>/<VERSION>/<NAMESPACE>/default/deployments/<PODNAME>
   
  #ç¤ºä¾‹ï¼š 
  kubectl get --raw="/apis/apps/v1/namespaces/kube-system/deployments/coredns" | jq
  ```

  

#### è®¿é—® Kubernetes REST API

```bash
# è¿™ä¸ªTOKENåœ¨åé¢å­¦ä¹ åˆ›å»ºSAçš„æ—¶å€™ä¼šå­¦ä¹ å¦‚ä½•å¾—åˆ°
#TOKEN=$(echo ZXlKaGJHY2lw==|base64 -d)

#åˆ©ç”¨ä¸Šé¢ç”Ÿæˆçš„TOEKNæ‰èƒ½è®¿é—®
curl -s  --cacert /etc/kubernetes/pki/ca.crt -H "Authorization: Bearer ${TOKEN}" https://kubeapi.wang.org:6443
```



#### æŸ¥çœ‹èµ„æºå¯¹è±¡çš„å‘½ä»¤

##### æŸ¥çœ‹èµ„æºç±»å‹

```bash
[root@ubuntu2204 ~]# kubectl api-resources 

NAME                                SHORTNAMES   APIVERSION                        NAMESPACED   KIND
bindings                                         v1                                true         Binding
componentstatuses                   cs           v1                                false        ComponentStatus
#configmaps                          cm           v1                                true         ConfigMap
#endpoints                           ep           v1                                true         Endpoints
events                              ev           v1                                true         Event
#limitranges                         limits       v1                                true         LimitRange
#namespaces                          ns           v1                                false        Namespace
#nodes                               no           v1                                false        Node
#persistentvolumeclaims              pvc          v1                                true         PersistentVolumeClaim
#persistentvolumes                   pv           v1                                false        PersistentVolume
#pods                                po           v1                                true         Pod
#podtemplates                                     v1                                true         PodTemplate
#replicationcontrollers              rc           v1                                true         ReplicationController
resourcequotas                      quota        v1                                true         ResourceQuota
#secrets                                          v1                                true         Secret
#serviceaccounts                     sa           v1                                true         ServiceAccount
#services                            svc          v1                                true         Service
mutatingwebhookconfigurations                    admissionregistration.k8s.io/v1   false        MutatingWebhookConfiguration
validatingadmissionpolicies                      admissionregistration.k8s.io/v1   false        ValidatingAdmissionPolicy
validatingadmissionpolicybindings                admissionregistration.k8s.io/v1   false        ValidatingAdmissionPolicyBinding
validatingwebhookconfigurations                  admissionregistration.k8s.io/v1   false        ValidatingWebhookConfiguration
customresourcedefinitions           crd,crds     apiextensions.k8s.io/v1           false        CustomResourceDefinition
apiservices                                      apiregistration.k8s.io/v1         false        APIService
controllerrevisions                              apps/v1                           true         ControllerRevision
#daemonsets                          ds           apps/v1                           true         DaemonSet
#deployments                         deploy       apps/v1                           true         Deployment
#replicasets                         rs           apps/v1                           true         ReplicaSet
#statefulsets                        sts          apps/v1                           true         StatefulSet
selfsubjectreviews                               authentication.k8s.io/v1          false        SelfSubjectReview
tokenreviews                                     authentication.k8s.io/v1          false        TokenReview
localsubjectaccessreviews                        authorization.k8s.io/v1           true         LocalSubjectAccessReview
selfsubjectaccessreviews                         authorization.k8s.io/v1           false        SelfSubjectAccessReview
selfsubjectrulesreviews                          authorization.k8s.io/v1           false        SelfSubjectRulesReview
subjectaccessreviews                             authorization.k8s.io/v1           false        SubjectAccessReview
horizontalpodautoscalers            hpa          autoscaling/v2                    true         HorizontalPodAutoscaler
#cronjobs                            cj           batch/v1                          true         CronJob
#jobs                                             batch/v1                          true         Job
certificatesigningrequests          csr          certificates.k8s.io/v1            false        CertificateSigningRequest
leases                                           coordination.k8s.io/v1            true         Lease
endpointslices                                   discovery.k8s.io/v1               true         EndpointSlice
events                              ev           events.k8s.io/v1                  true         Event
flowschemas                                      flowcontrol.apiserver.k8s.io/v1   false        FlowSchema
prioritylevelconfigurations                      flowcontrol.apiserver.k8s.io/v1   false        PriorityLevelConfiguration
ingressclasses                                   networking.k8s.io/v1              false        IngressClass
#ingresses                           ing          networking.k8s.io/v1              true         Ingress
networkpolicies                     netpol       networking.k8s.io/v1              true         NetworkPolicy
runtimeclasses                                   node.k8s.io/v1                    false        RuntimeClass
poddisruptionbudgets                pdb          policy/v1                         true         PodDisruptionBudget
#clusterrolebindings                              rbac.authorization.k8s.io/v1      false        #ClusterRoleBinding
#clusterroles                                     rbac.authorization.k8s.io/v1      false        ClusterRole
#rolebindings                                     rbac.authorization.k8s.io/v1      true         RoleBinding
#roles                                            rbac.authorization.k8s.io/v1      true         Role
priorityclasses                     pc           scheduling.k8s.io/v1              false        PriorityClass
csidrivers                                       storage.k8s.io/v1                 false        CSIDriver
csinodes                                         storage.k8s.io/v1                 false        CSINode
csistoragecapacities                             storage.k8s.io/v1                 true         CSIStorageCapacity
#storageclasses                      sc           storage.k8s.io/v1                 false        StorageClass
volumeattachments                                storage.k8s.io/v1                 false        VolumeAttachment
```



##### æŸ¥çœ‹æ‰€æœ‰èµ„æº

```bash
[root@ubuntu2204 ~]# kubectl get all -A

NAMESPACE      NAME                                  READY   STATUS    RESTARTS        AGE
default        pod/myapp-7b94444f8d-66d4h            1/1     Running   0               161m
default        pod/myapp-7b94444f8d-nctmp            1/1     Running   0               161m
default        pod/myapp-7b94444f8d-tnj2j            1/1     Running   0               161m
kube-flannel   pod/kube-flannel-ds-8c9x7             1/1     Running   0               3h42m
kube-flannel   pod/kube-flannel-ds-8xd9g             1/1     Running   0               3h42m
kube-flannel   pod/kube-flannel-ds-lgtbb             1/1     Running   0               3h42m
kube-flannel   pod/kube-flannel-ds-q2fvl             1/1     Running   0               3h42m
kube-flannel   pod/kube-flannel-ds-wdmsn             1/1     Running   0               3h42m
kube-flannel   pod/kube-flannel-ds-wfmst             1/1     Running   0               3h42m
kube-system    pod/coredns-cb4864fb5-4tsg8           1/1     Running   0               4h13m
kube-system    pod/coredns-cb4864fb5-kpzdd           1/1     Running   0               4h13m
kube-system    pod/etcd-master1                      1/1     Running   1 (3h45m ago)   4h13m
kube-system    pod/etcd-master2                      1/1     Running   1 (3h43m ago)   4h10m
kube-system    pod/etcd-master3                      1/1     Running   1 (3h43m ago)   4h8m
kube-system    pod/kube-apiserver-master1            1/1     Running   1 (3h45m ago)   4h13m
kube-system    pod/kube-apiserver-master2            1/1     Running   1 (3h43m ago)   4h10m
kube-system    pod/kube-apiserver-master3            1/1     Running   1               4h8m
kube-system    pod/kube-controller-manager-master1   1/1     Running   1 (3h45m ago)   4h13m
kube-system    pod/kube-controller-manager-master2   1/1     Running   1 (3h43m ago)   4h10m
kube-system    pod/kube-controller-manager-master3   1/1     Running   1               4h8m
kube-system    pod/kube-proxy-42n9v                  1/1     Running   1               4h8m
kube-system    pod/kube-proxy-4ckkx                  1/1     Running   1 (3h43m ago)   4h7m
kube-system    pod/kube-proxy-755mw                  1/1     Running   1 (3h45m ago)   4h13m
kube-system    pod/kube-proxy-c977c                  1/1     Running   1 (3h43m ago)   4h7m
kube-system    pod/kube-proxy-htdr6                  1/1     Running   1 (3h43m ago)   4h8m
kube-system    pod/kube-proxy-nxqr6                  1/1     Running   1 (3h43m ago)   4h10m
kube-system    pod/kube-scheduler-master1            1/1     Running   1 (3h45m ago)   4h13m
kube-system    pod/kube-scheduler-master2            1/1     Running   1 (3h43m ago)   4h10m
kube-system    pod/kube-scheduler-master3            1/1     Running   1 (3h43m ago)   4h8m


```



##### æŸ¥çœ‹CRD

```bash
[root@master1 ~]# kubectl get crd
NAME                                                  CREATED AT
bgpconfigurations.crd.projectcalico.org               2023-07-22T12:10:37Z             
bgpfilters.crd.projectcalico.org                      2023-07-22T12:10:37Z                  
bgppeers.crd.projectcalico.org                        2023-07-22T12:10:37Z                    
blockaffinities.crd.projectcalico.org                 2023-07-22T12:10:37Z            
caliconodestatuses.crd.projectcalico.org              2023-07-22T12:10:37Z
clusterinformations.crd.projectcalico.org             2023-07-22T12:10:37Z 
felixconfigurations.crd.projectcalico.org             2023-07-22T12:10:37Z
globalnetworkpolicies.crd.projectcalico.org           2023-07-22T12:10:37Z
globalnetworksets.crd.projectcalico.org               2023-07-22T12:10:37Z
hostendpoints.crd.projectcalico.org                   2023-07-22T12:10:37Z  
```



##### æŸ¥çœ‹æŒ‡å®šAPI Groupçš„èµ„æº

```bash
[root@ubuntu2204 ~]# kubectl api-resources --api-group apps
NAME                  SHORTNAMES   APIVERSION   NAMESPACED   KIND
controllerrevisions                apps/v1      true         ControllerRevision
daemonsets            ds           apps/v1      true         DaemonSet
deployments           deploy       apps/v1      true         Deployment
replicasets           rs           apps/v1      true         ReplicaSet
statefulsets          sts          apps/v1      true         StatefulSet
```



#### ç”¨ä»£ç†è®¿é—®è®¿é—®APIServer

```bash
# å‰å°å¯åŠ¨ä¸€ä¸ªä»£ç†
[root@master1 ~]#kubectl proxy --port=8081
Starting to serve on 127.0.0.1:8081

#åœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œä¸‹é¢
#ä½¿ç”¨ jq å‘½ä»¤(json æ•°æ®å¤„ç†çš„å‘½ä»¤è¡Œå·¥å…·)å¤„ç†ç»“æœï¼š
[root@master1 ~]#curl -s 127.0.0.1:8081/api/  | jq .kind
"APIVersions"

# æŸ¥çœ‹ç‰ˆæœ¬
[root@master1 ~]#curl -s 127.0.0.1:8081/version  | jq 
{
  "major": "1",
  "minor": "30",
  "gitVersion": "v1.30.2",
  "gitCommit": "39683505b630ff2121012f3c5b16215a1449d5ed",
  "gitTreeState": "clean",
  "buildDate": "2024-06-11T20:21:00Z",
  "goVersion": "go1.22.4",
  "compiler": "gc",
  "platform": "linux/amd64"
}
```



### èµ„æºæ¸…å•æ ¼å¼

#### èµ„æºé…ç½®æ¸…å•ä»‹ç»

èµ„æºé…ç½®æ¸…å•çš„æ ¼å¼é‡‡ç”¨ Yaml æ ¼å¼

ç¬¬ä¸€çº§å­—æ®µåä¸€èˆ¬åŒ…æ‹¬: **apiVersion**ã€**kind**ã€**metadata**ã€**spec**ã€**status** äº”ä¸ªå­—æ®µ

å­—æ®µåé‡‡æœ‰å°é©¼å³°å‘½åæ³•,è€Œå€¼ä¸€èˆ¬é‡‡ç”¨å¤§é©¼å³°å‘½ä»¤æ³•



**ç¬¬ä¸€çº§å­—æ®µç®€ä»‹**

- apiVersionã€kind å’Œ metadata å­—æ®µçš„åŠŸèƒ½åŸºæœ¬ç›¸åŒ
- spec ç”¨äºè§„å®šèµ„æºçš„æœŸæœ›çŠ¶æ€ï¼Œè€Œèµ„æºçš„åµŒå¥—å±æ€§æ˜¯æœ‰å¾ˆå¤§å·®åˆ«çš„ã€‚
- statuså­—æ®µåˆ™è®°å½•æ´»åŠ¨å¯¹è±¡çš„å½“å‰çŠ¶æ€ï¼Œå…¶è¦ä¸ spec ä¸­å®šä¹‰çš„çŠ¶æ€ç›¸åŒï¼Œæˆ–è€…å¤„äºæ­£è½¬æ¢ä¸ºä¸å…¶ç›¸åŒçš„ è¿‡ç¨‹ä¸­ã€‚
- ç”¨æˆ·å¯ä»¥ä½¿ç”¨ `kubectl get TYPE/NAME -o yaml/json` å‘½ä»¤æ¥è·å–ä»»ä½•ä¸€ä¸ªå¯¹è±¡çš„yaml æˆ–è€… json æ ¼å¼ çš„é…ç½®æ¸…å•



**èµ„æºæ¸…å•ç¤ºä¾‹**

```yaml
# kubectl get namespace kube-system -o yaml
apiVersion: v1
kind: Namespace
metadata:
  creationTimestamp: "2020-02-22T07:56:11Z"
  labels:
    kubernetes.io/metadata.name: kube-system
  name: kube-system
  resourceVersion: "7"
  uid: a176ab46-ab7b-4737-ab52-2e53ca1d1d46
spec:
  finalizers:- kubernetes
status:
  phase: Active
  
  
# kubectl get namespace kube-system -o json
{
 "apiVersion": "v1",
 "kind": "Namespace",
 "metadata": {
 "creationTimestamp": "2020-02-22T07:56:11Z",
 "labels": {
 "kubernetes.io/metadata.name": "kube-system"
        },
 "name": "kube-system",
 "resourceVersion": "7",
 "uid": "a176ab46-ab7b-4737-ab52-2e53ca1d1d46"
    },
 "spec": {
 "finalizers": [
 "kubernetes"
        ]
    },
 "status": {
 "phase": "Active"
    }
}
```



#### apiVersionå’Œkind

apiVersionå’Œkind æè¿°ç±»å‹çš„å…ƒæ•°æ®

- **apiVersion**ï¼šAPIç‰ˆæœ¬,ç”¨äºå¯¹åŒä¸€èµ„æºå¯¹è±¡çš„ä¸åŒç‰ˆæœ¬è¿›è¡Œå¹¶è¡Œç®¡ç†ï¼Œä¸»è¦æœ‰ alphaã€betalã€ stable
  - æ ¼å¼ï¼šç»„å/ç‰ˆæœ¬
  - æŸ¥çœ‹å‘½ä»¤ï¼škubectl api-versionsï¼Œå¯ä»¥çœ‹åˆ°å½“å‰å…±æœ‰27+ä¸ªåˆ†ç»„å’Œç‰ˆæœ¬
- **kind**ï¼šèµ„æºç±»å‹,kubernetesçš„ä¸“ç”¨èµ„æºå¯¹è±¡
  - æŸ¥çœ‹å‘½ä»¤ï¼š kubectl api-resources  [--api-group=]ï¼Œå¯ä»¥çœ‹åˆ°å½“å‰å…±æœ‰50+ç§èµ„æºå¯¹è±¡å’Œå¯¹åº”çš„ APIVERSION ç‰ˆæœ¬ä¿¡æ¯



#### metadata åµŒå¥—å­—æ®µ

metadata å­—æ®µç”¨äºæè¿°å¯¹è±¡çš„å…ƒæ•°æ®,å³å±æ€§ä¿¡æ¯ï¼Œå…¶å†…åµŒå¤šä¸ªç”¨äºå®šä¹‰èµ„æºçš„å…ƒæ•°æ®ï¼Œå¦‚ **name** å’Œ  **labels** ç­‰ã€‚è¿™äº›å­—æ®µå¯ä»¥åˆ†ä¸ºå¿…é€‰å­—æ®µå’Œå¯é€‰å­—æ®µ



**å¿…é€‰å­—æ®µï¼š**

- **name**: è®¾å®šå½“å‰å¯¹è±¡çš„åç§°ï¼Œåç§°ç©ºé—´é—´çº§çš„èµ„æºåœ¨å…¶æ‰€å±çš„åç§°ç©ºé—´çš„åŒä¸€ç±»å‹ä¸­å¿…é¡»å”¯ä¸€
- **namespace**: æŒ‡å®šå½“å‰å¯¹è±¡éš¶å±çš„åç§°ç©ºé—´ï¼Œé»˜è®¤å€¼ä¸º defaultï¼Œå®ç°èµ„æºéš”ç¦»
- **uid**: å½“å‰å¯¹è±¡çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºåŒºåˆ«"å·²åˆ é™¤"å’Œ"é‡æ–°åˆ›å»º"çš„åŒä¸€ä¸ªåç§°çš„å¯¹è±¡,ç³»ç»Ÿå¯ä»¥è‡ªåŠ¨ç”Ÿ æˆ



**å¯é€‰å­—æ®µï¼š**

- **labels**: è®¾å®šç”¨äºæ ‡è¯†å½“å‰å¯¹è±¡çš„æ ‡ç­¾ï¼Œé”®å€¼æ•°æ®ï¼Œæ ¼å¼ï¼škey1: value1 ,å¸¸ç”¨ä½œæ ‡ç­¾é€‰æ‹©å™¨çš„æŒ‘é€‰æ¡ä»¶
- **annotation**: éæ ‡è¯†å‹é”®å€¼æ•°æ®ï¼Œæ ¼å¼ï¼škey1: value1,ç”¨æ¥ä½œä¸ºæŒ‘é€‰æ¡ä»¶ï¼Œç”¨äº labels çš„è¡¥å……ï¼Œä¸æ”¯æŒæ ‡ç­¾é€‰æ‹©å™¨çš„é€‰æ‹©
- **resourceVersion**:å½“å‰å¯¹è±¡çš„å†…éƒ¨ç‰ˆæœ¬æ ‡è¯†ï¼Œç”¨æ¥è®©å®¢æˆ·ç«¯ç¡®å®šå¯¹è±¡çš„å˜åŠ¨ä¸å¦
- **generation**: æ ‡è¯†å½“å‰å¯¹è±¡ç›®æ ‡çŠ¶æ€çš„ä»£åˆ«
- **creationTimestamp**: å½“å‰å¯¹è±¡åˆ›å»ºæ—¥æœŸçš„æ—¶é—´æˆ³
- **deletionTimestamp**: å½“å‰å¯¹è±¡åˆ é™¤æ—¥æœŸçš„æ—¶é—´æˆ³



####  spec å’Œ status å­—æ®µ

å®šä¹‰èµ„æºé…ç½®æ¸…å•æ—¶ï¼Œspec æ˜¯å¿…é¡»çš„å­—æ®µã€‚ç”¨äºæè¿°å¯¹è±¡çš„ç›®æ ‡çŠ¶æ€ï¼Œä¹Ÿå°±æ˜¯ç”¨æˆ·æœŸæœ›å¯¹è±¡æ‰€è¡¨ç°å‡ºæ¥çš„ç‰¹å¾ã€‚

**spec å­—æ®µ**

- Specification è§„æ ¼å­—æ®µ
- æ­¤å­—æ®µå¯¹äºä¸åŒçš„å¯¹è±¡ç±»å‹æ¥è¯´å„ä¸ç›¸åŒï¼Œå…·ä½“å­—æ®µå«ä¹‰åŠæ‰€æ¥å—çš„æ•°æ®ç±»å‹éœ€è¦å‚ç…§ Kubernets  API æ‰‹å†Œä¸­çš„è¯´æ˜è¿›è¡Œè·å–ã€‚å¯é€šè¿‡å‘½ä»¤  **kubectl explain KIND.spec** è·å–å…·ä½“å¸®åŠ©



**status å­—æ®µ**

- æ­¤å­—æ®µè®°å½•å¯¹è±¡çš„å½“å‰å®é™…è¿è¡Œçš„çŠ¶æ€ï¼Œç”± Kubernetes ç³»ç»Ÿè´Ÿè´£æ›´æ–°ï¼Œç”¨æˆ·ä¸èƒ½æ‰‹åŠ¨å®šä¹‰ã€‚
- Master èŠ‚ç‚¹çš„ controller manager é€šè¿‡ç›¸åº”çš„æ§åˆ¶å™¨ç»„ä»¶åŠ¨æ€ç®¡ç†å¹¶ç¡®ä¿å¯¹è±¡çš„å®é™…è½¬æ€åŒ¹é…ç”¨ æˆ·æ‰€æœŸæœ›çš„çŠ¶æ€ã€‚æ¯”å¦‚:Deployment æ˜¯ä¸€ç§æè¿°é›†ç¾¤ä¸­è¿è¡Œåº”ç”¨çš„èµ„æºå¯¹è±¡ï¼Œå› æ­¤ï¼Œåˆ›å»º  Deployment ç±»å‹å¯¹è±¡æ—¶ï¼Œéœ€è¦ä¸ºç›®æ ‡ Deployment å¯¹è±¡è®¾å®š specï¼ŒæŒ‡å®šæœŸæœ›éœ€è¦è¿è¡Œçš„ Pod å‰¯ æœ¬æ•°é‡ã€ä½¿ç”¨çš„æ ‡ç­¾é€‰æ‹©å™¨ä»¥åŠ Pod æ¨¡æ¿ç­‰ã€‚åœ¨åˆ›å»ºæ—¶ï¼ŒKubernetes ç›¸å…³ç»„ä»¶è¯»å–å¾…åˆ›å»ºçš„  Deployment å¯¹è±¡çš„ specä»¥åŠç³»ç»Ÿä¸Šç›¸åº”çš„æ´»åŠ¨å¯¹è±¡çš„å½“å‰çŠ¶æ€ï¼Œå¿…è¦æ—¶å¯¹æ´»åŠ¨çš„å¯¹è±¡æ›´æ–°ä»¥ç¡® ä¿ status å­—æ®µå»åˆ spec å­—æ®µä¸­æœŸæœ›çš„çŠ¶æ€ã€‚
- **æ³¨æ„ï¼š**æ•°æ®ç±»çš„èµ„æºå¯¹è±¡æ— spec, Status å­—æ®µï¼Œæ¯”å¦‚ï¼šconfigmapsï¼Œsecrets ï¼Œ endpoints ç­‰



#### ä½¿ç”¨å‘½ä»¤ç”Ÿæˆæ¸…å•æ–‡ä»¶

``````yaml
# ä¸æ‰§è¡Œï¼Œè€Œæ˜¯ç”Ÿäº§å¯¹åº”çš„æ¸…å•æ–‡æœ¬å†…å®¹è¾“å‡ºåˆ°ç»ˆç«¯
kubectl create deployment myapp --image registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v1.0 --replicas 3 --dry-run=client -o yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: myapp
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: myapp
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v1.0
        name: myapp
        resources: {}
status: {}


# å°†å…¶è¾“å…¥åˆ°æ–‡ä»¶
kubectl create deployment myapp --image registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v1.0 --replicas 3 --dry-run=client -o yaml > myapp.yaml

# å¾—åˆ°èµ„æºæ¸…å•åï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚è¿›è¡Œæ›´æ”¹
``````



#### åŸºäºç°æœ‰èµ„æºç”Ÿæˆæ¸…å•æ–‡ä»¶

```yaml
# æŸ¥çœ‹ç°æœ‰Servicesèµ„æº
[root@master1 ~]# kubectl get services
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        7h4m
myapp        NodePort    10.98.161.155   <none>        80:31021/TCP   5h29m

# åŸºäºmyappï¼Œè¾“å‡ºå®ƒçš„èµ„æºæ¸…å•æ–‡ä»¶
[root@master1 ~]# kubectl get services myapp -o yaml
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2024-12-15T12:03:41Z"
  labels:
    app: myapp
  name: myapp
  namespace: default
  resourceVersion: "13753"
  uid: e9d14260-ef75-4256-8887-200867c3d60a
spec:
  clusterIP: 10.98.161.155
  clusterIPs:
  - 10.98.161.155
  externalTrafficPolicy: Cluster
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: 80-80
    nodePort: 31021
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: myapp
  sessionAffinity: None
  type: NodePort
status:
  loadBalancer: {}
```



#### èµ„æºæ¸…å•æ ¼å¼æ–‡æ¡£å¸®åŠ©Explain

```bash
[root@master1 ~]#kubectl explain pod
KIND:       Pod
VERSION:    v1

DESCRIPTION:
    Pod is a collection of containers that can run on a host. This resource is
    created by clients and scheduled onto hosts.
    
FIELDS:
  apiVersion	<string>
    APIVersion defines the versioned schema of this representation of an object.
    Servers should convert recognized schemas to the latest internal value, and
    may reject unrecognized values. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources

  kind	<string>
    Kind is a string value representing the REST resource this object
    represents. Servers may infer this from the endpoint the client submits
    requests to. Cannot be updated. In CamelCase. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds

  metadata	<ObjectMeta>
    Standard object's metadata. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata

  spec	<PodSpec>
    Specification of the desired behavior of the pod. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status

  status	<PodStatus>
    Most recently observed status of the pod. This data may not be up to date.
    Populated by the system. Read-only. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status

# é€’è¿›æŸ¥è¯¢
[root@master1 ~]#kubectl explain pod.spec
KIND:       Pod
VERSION:    v1

FIELD: spec <PodSpec>


DESCRIPTION:
    Specification of the desired behavior of the pod. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
    PodSpec is a description of a pod.
    
FIELDS:
  activeDeadlineSeconds	<integer>
    Optional duration in seconds the pod may be active on the node relative to
    StartTime before the system will actively try to mark it failed and kill
    associated containers. Value must be a positive integer.

  affinity	<Affinity>
    If specified, the pod's scheduling constraints

  automountServiceAccountToken	<boolean>
    AutomountServiceAccountToken indicates whether a service account token
    should be automatically mounted.

  containers	<[]Container> -required-
    List of containers belonging to the pod. Containers cannot currently be
    added or removed. There must be at least one container in a Pod. Cannot be
    updated.

  dnsConfig	<PodDNSConfig>
    Specifies the DNS parameters of a pod. Parameters specified here will be
    merged to the generated DNS configuration based on DNSPolicy.
...
```





#### èµ„æºå¯¹è±¡çš„ç®¡ç†æ–¹å¼

kubectl å‘½ä»¤å¯åˆ†ä¸ºä¸‰ç±»å‘½ä»¤ï¼š

- **æŒ‡ä»¤å¼å‘½ä»¤(imperative command)**

  - æŒ‡ä»¤å¼å‘½ä»¤åŒ…æ‹¬**kubectl run/expose/delete/ge**tç­‰å‘½ä»¤
  - é€‚åˆå®Œæˆä¸€æ¬¡æ€§çš„æ“ä½œä»»åŠ¡

  

- **æŒ‡ä»¤å¼å¯¹è±¡é…ç½®(imperative object configuration)**

  - æŒ‡ä»¤å¼å¯¹è±¡é…ç½®ç®¡ç†åŒ…æ‹¬**kubectl create/delete/get/replace/edit**ç­‰
  - åŸºäºèµ„æºé…ç½®æ–‡ä»¶æ‰§è¡Œå¯¹è±¡ç®¡ç†æ“ä½œï¼Œä½†åªèƒ½ç‹¬ç«‹å¼•ç”¨æ¯ä¸ªé…ç½®æ¸…å•æ–‡ä»¶
  - **æ­¤æ–¹å¼æ²¡æœ‰å¹‚ç­‰æ€§,é‡å¤æ‰§è¡Œå¯èƒ½ä¼šå‡ºé”™,ç”Ÿäº§ä¸æ¨èä½¿ç”¨**

  

- **å£°æ˜å¼å¯¹è±¡é…ç½®(declarative object configration)**

  - åŸºäºèµ„æºé…ç½®æ–‡ä»¶æ‰§è¡Œå¯¹è±¡ç®¡ç†æ“ä½œ
  - å¯ç›´æ¥å¼•ç”¨ç›®å½•ä¸‹çš„æ‰€æœ‰é…ç½®æ¸…å•æ–‡ä»¶ï¼Œä¹Ÿå¯ç›´æ¥ä½œç”¨äºå•ä¸ªé…ç½®æ–‡ä»¶
  - èµ„æºå¯¹è±¡çš„åˆ›å»ºã€åˆ é™¤åŠä¿®æ”¹æ“ä½œå…¨éƒ¨é€šè¿‡å‘½ä»¤**kubectl apply/patch**ç­‰æ¥å®Œæˆï¼Œå¹¶ä¸”æ¯æ¬¡æ“ä½œ æ—¶ï¼Œæä¾›ç»™å‘½ä»¤çš„é…ç½®ä¿¡æ¯éƒ½å°†ä¿å­˜äºå¯¹è±¡çš„æ³¨é‡Šä¿¡æ¯(kubectl.kubernetes.io/last-applied configuration)ä¸­ï¼Œ

  

  ```bash
  kubectl apply -f /path/file -f .....    #åŠ è½½æŒ‡å®šæ–‡ä»¶
  kubectl apply -f /path                  #åŠ è½½æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ä»¥.yaml,.yml,.jsonåç¼€çš„æ–‡ä»¶
  kubectl apply -f /path -f /path1/path2  # ä¸æ”¯æŒé€’å½’ï¼Œæ‰€ä»¥å¦‚æœç›®å½•ä¸‹æœ‰å­ç›®å½•ï¼Œéœ€è¦å¤šä¸ª-fåˆ†åˆ«åŠ è½½
  kubectl apply -f URL                    #åŠ è½½URLçš„æ–‡ä»¶
  ```

  



### åç§°ç©ºé—´



#### åç§°ç©ºé—´è¯´æ˜

![alt text](images\image30.png)



Kubernetes çš„èµ„æºå·¥ä½œçš„æœ‰æ•ˆèŒƒå›´åˆ†æˆä¸¤ç§çº§åˆ«:

- **é›†ç¾¤çº§åˆ«**: é’ˆå¯¹æ•´ä¸ªKubernetesé›†ç¾¤å†…éƒ½æœ‰æ•ˆ
  - 
- **åç§°ç©ºé—´çº§åˆ«**: åªé’ˆå¯¹æŒ‡å®šåç§°ç©ºé—´å†…æœ‰æ•ˆ,è€Œä¸å±äºä»»åŠ¡åç§°ç©ºé—´



##### **åç§°ç©ºé—´çš„ä½œç”¨**

- åç§°ç©ºé—´ Namespace ç”¨äºå°†é›†ç¾¤åˆ†éš”ä¸ºå¤šä¸ªéš”ç¦»çš„é€»è¾‘åˆ†åŒºä»¥é…ç½®ç»™ä¸åŒçš„ç”¨æˆ·ã€ç§Ÿæˆ·ã€ç¯å¢ƒæˆ–è€…é¡¹ç›®ä½¿ç”¨ã€‚
- åç§°ç©ºé—´é™å®šäº†èµ„æºå¯¹è±¡å·¥ä½œåœ¨æŒ‡å®šçš„åç§°èŒƒå›´å†…çš„ä½œç”¨åŸŸ
- **æ³¨æ„: åç§°ç©ºé—´æœ¬èº«æ˜¯ Kubernetes é›†ç¾¤çº§åˆ«çš„èµ„æº**



##### **åç§°ç©ºé—´çš„ä½¿ç”¨åœºæ™¯**

- **ç¯å¢ƒç®¡ç†**ï¼šéœ€è¦åœ¨åŒä¸€Kubernetesé›†ç¾¤ä¸Šéš”ç¦»ç ”å‘ã€é¢„å‘å’Œç”Ÿäº§ç­‰ä¸€ç±»çš„ç¯å¢ƒæ—¶ï¼Œå¯ä»¥é€šè¿‡åç§°ç©ºé—´è¿›è¡Œ
- **éš”ç¦»**ï¼šå¤šä¸ªé¡¹ç›®å›¢é˜Ÿçš„ä¸åŒäº§å“çº¿éœ€è¦éƒ¨ç½²äºåŒä¸€Kubernetesé›†ç¾¤æ—¶ï¼Œå¯ä»¥ä½¿ç”¨åç§°ç©ºé—´è¿›è¡Œéš”ç¦»
- **èµ„æºæ§åˆ¶**ï¼šåç§°ç©ºé—´å¯ç”¨ä½œèµ„æºé…é¢çš„æ‰¿è½½å•ä½ï¼Œä»è€Œé™åˆ¶å…¶å†…éƒ¨æ‰€æœ‰åº”ç”¨å¯ä»¥ä½¿ç”¨çš„CPU/Memory/PVå„è‡ª çš„èµ„æºæ€»å’Œ
  - éœ€è¦åœ¨äº§å“çº¿æˆ–å›¢é˜Ÿç­‰éš”ç¦»ç›®æ ‡ä¸Šåˆ†é…å„è‡ªæ€»ä½“å¯ç”¨çš„ç³»ç»Ÿèµ„æºæ—¶ï¼Œå¯é€šè¿‡åç§°ç©ºé—´å®ç°
- **æƒé™æ§åˆ¶**ï¼šåŸºäºRBACé‰´æƒä½“ç³»ï¼Œèƒ½å¤Ÿåœ¨åç§°ç©ºé—´çº§åˆ«è¿›è¡Œæƒé™é…ç½®
- **æé«˜é›†ç¾¤æ€§èƒ½**ï¼šè¿›è¡Œèµ„æºæœç´¢æ—¶ï¼Œåç§°ç©ºé—´æœ‰åˆ©äºKubernetes APIç¼©å°æŸ¥æ‰¾èŒƒå›´ï¼Œä»è€Œå¯¹å‡å°‘æœç´¢å»¶è¿Ÿå’Œæå‡æ€§èƒ½ æœ‰ä¸€å®šçš„å¸®åŠ©





##### **åç§°ç©ºé—´åˆ†ç±»**ï¼ˆ**ä¸¤ç±»**ï¼‰

- **ç³»ç»Ÿçº§åç§°ç©ºé—´**
  - ç”±Kubernetesé›†ç¾¤é»˜è®¤åˆ›å»ºï¼Œä¸»è¦ç”¨æ¥éš”ç¦»ç³»ç»Ÿçº§çš„èµ„æºå¯¹è±¡ æ‰€æœ‰çš„ç³»ç»Ÿçº§åç§°ç©ºé—´å‡ä¸èƒ½è¿›è¡Œåˆ é™¤æ“ä½œï¼ˆå³ä½¿åˆ é™¤ä¹Ÿä¼šè‡ªåŠ¨é‡å»ºï¼‰ **é™¤defaultå¤–ï¼Œå…¶å®ƒä¸‰ä¸ªç³»ç»Ÿçº§åç§°ç©ºé—´**ä¸åº”è¯¥ç”¨ä½œä¸šåŠ¡åº”ç”¨çš„éƒ¨ç½²ç›®æ ‡
  - **default**ï¼šä¸ºä»»ä½•åç§°ç©ºé—´çº§åˆ«çš„èµ„æºæä¾›çš„é»˜è®¤çš„åç§°ç©ºé—´
  - **kuhe-system**ï¼šKubernetesé›†ç¾¤è‡ªèº«ç»„ä»¶åŠå…¶å®ƒç³»ç»Ÿçº§ç»„ä»¶ä½¿ç”¨çš„åç§°ç©ºé—´ï¼ŒKubernetesè‡ªèº«çš„ å…³é”®ç»„ä»¶å‡éƒ¨ç½²åœ¨è¯¥åç§°ç©ºé—´ä¸­
  - **kube-public**ï¼šå…¬ä¼—å¼€æ”¾çš„åç§°ç©ºé—´ï¼Œæ‰€æœ‰ç”¨æˆ·ï¼ˆåŒ…æ‹¬Anonymousï¼‰éƒ½å¯ä»¥è¯»å–å†…éƒ¨çš„èµ„æº,é€šå¸¸ä¸ºç©º
  - **kube-node-lease**ï¼šèŠ‚ç‚¹ç§Ÿçº¦èµ„æºæ‰€ç”¨çš„åç§°ç©ºé—´
    - åˆ†å¸ƒå¼ç³»ç»Ÿé€šå¸¸ä½¿ç”¨â€œç§Ÿçº¦(Leqse)â€æœºåˆ¶æ¥é”å®šå…±äº«èµ„æºå¹¶åè°ƒé›†ç¾¤æˆå‘˜ä¹‹é—´çš„æ´»åŠ¨ Kubernetesä¸Šçš„ç§Ÿçº¦æ¦‚å¿µç”±APIç¾¤ç»„coordination.k8s.ioç¾¤ç»„ä¸‹çš„Leaseèµ„æºæ‰€æ‰¿è½½ï¼Œä»¥æ”¯æ’‘ç³»ç»Ÿ çº§åˆ«çš„åŠŸèƒ½éœ€æ±‚ï¼Œä¾‹å¦‚èŠ‚ç‚¹å¿ƒè·³( node heartbeats)å’Œç»„ä»¶çº§çš„é¢†å¯¼é€‰ä¸¾ç­‰ Kubernetesé›†ç¾¤çš„æ¯ä¸ªç®¡ç†ç»„ä»¶åœ¨è¯¥åç§°ç©ºé—´ä¸‹éƒ½æœ‰ä¸€ä¸ªä¸åŒåçš„Ieaseèµ„æºå¯¹è±¡ 
    - `~# kubectl -n kube-node-lease get lease`



- **è‡ªå®šä¹‰åç§°ç©ºé—´**
  - ç”±ç”¨æˆ·æŒ‰éœ€åˆ›å»º
  - æ¯”å¦‚: æ ¹æ®é¡¹ç›®å’Œåœºæ™¯, åˆ†åˆ«åˆ›å»ºå¯¹åº”ä¸åŒçš„åç§°ç©ºé—´





#### æŸ¥çœ‹åç§°ç©ºé—´åŠèµ„æºå¯¹è±¡

```bash
[root@master1 ~]#kubectl get ns
NAME              STATUS   AGE
default           Active   65m
kube-flannel      Active   63m
kube-node-lease   Active   65m
kube-public       Active   65m
kube-system  
Active   65m


[root@master1 ~]#kubectl get ns default -o yaml
apiVersion: v1
kind: Namespace
metadata:
  creationTimestamp: "2024-12-16T05:34:09Z"
  labels:
    kubernetes.io/metadata.name: default
  name: default
  resourceVersion: "42"
  uid: b650835c-84e8-464a-84af-4955cb56285e
spec:
  finalizers:
  - kubernetes
status:
  phase: Active
  
  
# æŸ¥çœ‹æŒ‡å®šä¿¡æ¯
[root@master1 ~]#kubectl get ns default -o jsonpath={.metadata.name}
default

[root@master1 ~]#kubectl get ns default -o jsonpath={.apiVersion}
v1

# æŸ¥çœ‹é»˜è®¤åç§°ä¸‹çš„èµ„æº
[root@master1 ~]# kubectl get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/myapp-7b94444f8d-9xld5   1/1     Running   0          61m
pod/myapp-7b94444f8d-dhkdj   1/1     Running   0          61m
pod/myapp-7b94444f8d-ssp7z   1/1     Running   0          61m

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   69m

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/myapp   3/3     3            3           61m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/myapp-7b94444f8d   3         3         3       61m

# æŸ¥çœ‹æŒ‡å®šåç§°ç©ºé—´çš„èµ„æº
[root@master1 ~]# kubectl get all -n kube-system 
NAME                                  READY   STATUS    RESTARTS   AGE
pod/coredns-cb4864fb5-5rbqf           1/1     Running   0          70m
pod/coredns-cb4864fb5-mzd84           1/1     Running   0          70m
pod/etcd-master1                      1/1     Running   0          70m
pod/kube-apiserver-master1            1/1     Running   0          70m
pod/kube-controller-manager-master1   1/1     Running   0          70m
pod/kube-proxy-h2kx8                  1/1     Running   0          68m
pod/kube-proxy-kklfd                  1/1     Running   0          68m
pod/kube-proxy-kmzqq                  1/1     Running   0          70m
pod/kube-proxy-vlvhj                  1/1     Running   0          69m
pod/kube-scheduler-master1            1/1     Running   0          70m

NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
service/kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   70m

NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/kube-proxy   4         4         4       4            4           kubernetes.io/os=linux   70m

NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/coredns   2/2     2            2           70m

NAME                                DESIRED   CURRENT   READY   AGE
replicaset.apps/coredns-cb4864fb5   2         2         2       70m


```



#### åˆ›å»ºNamespaceèµ„æº



##### **æŒ‡ä»¤å¼å‘½ä»¤åˆ›å»º**

ä½¿ç”¨æŒ‡ä»¤å¼å‘½ä»¤ `kubectl create` å¯ä»¥ç›´æ¥åˆ›å»ºåç§°ç©ºé—´ï¼Œåªéœ€æŒ‡å®šåç§°ç©ºé—´åç§°

```bash
[root@master1 ~]# kubectl create ns ns-mystical
namespace/ns-mystical created

[root@master1 ~]# kubectl get ns ns-mystical 
NAME          STATUS   AGE
ns-mystical   Active   8s
```

**æ³¨æ„**ï¼šå®é™…ç”Ÿäº§ä¸­ä¸å»ºè®®ä½¿ç”¨æŒ‡ä»¤å¼å‘½ä»¤å’Œé…ç½®ï¼Œç›´æ¥ä½¿ç”¨å£°æ˜å¼å°±å¯ä»¥ã€‚



##### **æŒ‡ä»¤å¼é…ç½®åˆ›å»º**

`kubectl create -f </path/to/namespace-obj.yaml `å®ç°åˆ›å»º

æ­¤æ–¹å¼ç”Ÿäº§ä¸å»ºè®®ä½¿ç”¨,æ‰§è¡Œæ­¤å‘½ä»¤éœ€è¦æŒ‡å®šçš„namespaceä¸å­˜åœ¨

```bash
[root@master1 ~]#vim namespace-test1.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: namespace-test1

# åˆ›å»º
[root@master1 ~]#kubectl create -f namespace-test1.yaml 
namespace/namespace-test1 created

# æŸ¥çœ‹
[root@master1 ~]#kubectl get ns namespace-test1 
NAME              STATUS   AGE
namespace-test1   Active   8s
```



##### å£°æ˜å¼é…ç½®åˆ›å»º

Namespace æ˜¯ Kubernetes API çš„æ ‡å‡†èµ„æºç±»å‹ä¹‹ä¸€ï¼Œå…¶é…ç½®ä¸»è¦æœ‰ kindã€apiVolumeã€metadata å’Œ spec ç­‰ä¸€çº§å­—æ®µç»„æˆã€‚ä½¿ç”¨ kubectl create/apply -f /path/to/namespace-obj.yaml å‘½ä»¤å°±å¯ä»¥ åˆ›å»ºåç§°ç©ºé—´èµ„æº

```bash
[root@master1 ~]#vim namespace-test2.yaml 

[root@master1 ~]#cat namespace-test2.yaml 
apiVersion: v1
kind: Namespace
metadata:
  name: namespace-test2
  
[root@master1 ~]#kubectl apply -f namespace-test2.yaml 
namespace/namespace-test2 created

[root@master1 ~]#kubectl get namespaces namespace-test2 
NAME              STATUS   AGE
namespace-test2   Active   16s

# ä½¿ç”¨å‘½ä»¤ç”Ÿæˆå£°æ˜å¼yamlæ–‡ä»¶
[root@master1 ~]# kubectl create ns stage --dry-run=client -o yaml > stage-ns.yaml
[root@master1 ~]# cat stage-ns.yaml 
apiVersion: v1
kind: Namespace
metadata:
  creationTimestamp: null
  name: stage
spec: {}
status: {}
```



#### åˆ é™¤Namespaceèµ„æº

æ³¨æ„: **åˆ é™¤ Namespace ä¼šçº§è”åˆ é™¤æ­¤åç§°ç©ºé—´çš„æ‰€æœ‰èµ„æº**,éå¸¸å±é™©

```bash
[root@master1 ~]#kubectl delete namespaces namespace-test1 
namespace "namespace-test1" deleted

[root@master1 ~]#kubectl delete -f namespace-test2.yaml 
namespace "namespace-test2" deleted

# åœ¨æŒ‡å®šåç§°ç©ºé—´ä¸‹åˆ›å»ºèµ„æº
[root@master1 ~]#kubectl apply -f myapp.yaml -n ns-mystical 
deployment.apps/myapp created

# æŸ¥çœ‹æŒ‡å®šåç§°ç©ºé—´(ns-mystical)ä¸‹çš„æŒ‡å®šèµ„æº(pod)
[root@master1 ~]#kubectl get pod -n ns-mystical 
NAME                     READY   STATUS    RESTARTS   AGE
myapp-7b94444f8d-6ms2c   1/1     Running   0          23s
myapp-7b94444f8d-c9g6n   1/1     Running   0          23s
myapp-7b94444f8d-l5bgb   1/1     Running   0          23s

# åˆ é™¤æŒ‡å®šåç§°ç©ºé—´
[root@master1 ~]#kubectl delete namespaces ns-mystical 
namespace "ns-mystical" deleted

# æ‰€æœ‰æ­¤åç§°ç©ºé—´ä¸‹çš„èµ„æºéƒ½è¢«åˆ é™¤
[root@master1 ~]#kubectl get -n ns-mystical all
No resources found in ns-mystical namespace.
```





#### åˆ é™¤æŒ‡å®šåç§°ç©ºé—´çš„èµ„æº 

ä½¿ç”¨ kubectl ç®¡ç†èµ„æºæ—¶ï¼Œå¦‚æœæä¾›äº†åç§°ç©ºé—´é€‰é¡¹ï¼Œå°±è¡¨ç¤ºæ­¤ç®¡ç†æ“ä½œä»…é’ˆå¯¹æŒ‡å®šåç§°ç©ºé—´è¿›è¡Œï¼Œè€Œ åˆ é™¤ Namespace èµ„æºåˆ™ä¼šçº§è”åˆ é™¤å…¶åŒ…å«çš„æ‰€æœ‰å…¶ä»–èµ„æºå¯¹è±¡

| å‘½ä»¤æ ¼å¼                        | åŠŸèƒ½                                   |
| ------------------------------- | -------------------------------------- |
| kubectl delete TYPE RESOURCE -n | åˆ é™¤æŒ‡å®šåç§°ç©ºé—´å†…çš„æŒ‡å®šèµ„æº           |
| kubectl delete TYPE --all -n    | åˆ é™¤æŒ‡å®šåç§°ç©ºé—´å†…çš„æŒ‡å®šç±»å‹çš„æ‰€æœ‰èµ„æº |
| kubectl delete all -n           | åˆ é™¤æŒ‡å®šåç§°ç©ºé—´å†…çš„æ‰€æœ‰èµ„æº           |
| kubectl delete all --all        | åˆ é™¤æ‰€æœ‰åç§°ç©ºé—´ä¸­çš„æ‰€æœ‰èµ„æº           |



### Podèµ„æº



#### ä»€ä¹ˆæ˜¯ Pod

```ABAP
å…³äºPodæœ€é‡è¦çš„ä¸€ä¸ªäº‹å®æ˜¯ï¼šå®ƒåªæ˜¯ä¸€ä¸ªé€»è¾‘æ¦‚å¿µ
```

ä¹Ÿå°±æ˜¯è¯´ï¼ŒKubernetes çœŸæ­£å¤„ç†çš„ï¼Œè¿˜æ˜¯å®¿ä¸»æœºæ“ä½œç³»ç»Ÿä¸Š Linux å®¹å™¨çš„ Namespace å’Œ Cgroupsï¼Œè€Œå¹¶ä¸å­˜åœ¨ä¸€ä¸ªæ‰€è°“çš„ Pod çš„è¾¹ç•Œæˆ–è€…éš”ç¦»ç¯å¢ƒã€‚

é‚£ä¹ˆï¼ŒPod åˆæ˜¯æ€ä¹ˆè¢«â€œåˆ›å»ºâ€å‡ºæ¥çš„å‘¢ï¼Ÿ

ç­”æ¡ˆæ˜¯ï¼šPodï¼Œå…¶å®æ˜¯ä¸€ç»„å…±äº«äº†æŸäº›èµ„æºçš„å®¹å™¨ã€‚

å…·ä½“çš„è¯´ï¼š**Pod é‡Œçš„æ‰€æœ‰å®¹å™¨ï¼Œå…±äº«çš„æ˜¯åŒä¸€ä¸ª Network Namespaceï¼Œå¹¶ä¸”å¯ä»¥å£°æ˜å…±äº«åŒä¸€ä¸ª Volumeã€‚**

é‚£è¿™ä¹ˆæ¥çœ‹çš„è¯ï¼Œä¸€ä¸ªæœ‰ Aã€B ä¸¤ä¸ªå®¹å™¨çš„ Podï¼Œä¸å°±æ˜¯ç­‰åŒäºä¸€ä¸ªå®¹å™¨ï¼ˆå®¹å™¨ Aï¼‰å…±äº«å¦å¤–ä¸€ä¸ªå®¹å™¨ï¼ˆå®¹å™¨ Bï¼‰çš„ç½‘ç»œå’Œ Volume çš„ç©å„¿æ³•ä¹ˆï¼Ÿ

è¿™å¥½åƒé€šè¿‡ docker run --net --volumes-from è¿™æ ·çš„å‘½ä»¤å°±èƒ½å®ç°å˜›ï¼Œæ¯”å¦‚ï¼š

```bash
$ docker run --net=B --volumes-from=B --name=A image-A ...
```

ä½†æ˜¯ï¼Œä½ æœ‰æ²¡æœ‰è€ƒè™‘è¿‡ï¼Œå¦‚æœçœŸè¿™æ ·åšçš„è¯ï¼Œå®¹å™¨ B å°±å¿…é¡»æ¯”å®¹å™¨ A å…ˆå¯åŠ¨ï¼Œè¿™æ ·ä¸€ä¸ª Pod é‡Œçš„å¤šä¸ªå®¹å™¨å°±ä¸æ˜¯å¯¹ç­‰å…³ç³»ï¼Œè€Œæ˜¯æ‹“æ‰‘å…³ç³»äº†ã€‚

æ‰€ä»¥ï¼Œåœ¨ Kubernetes é¡¹ç›®é‡Œï¼ŒPod çš„å®ç°éœ€è¦ä½¿ç”¨ä¸€ä¸ªä¸­é—´å®¹å™¨ï¼Œè¿™ä¸ªå®¹å™¨å«ä½œ **Infra å®¹å™¨**ã€‚åœ¨è¿™ä¸ª Pod ä¸­ï¼ŒInfra å®¹å™¨æ°¸è¿œéƒ½æ˜¯ç¬¬ä¸€ä¸ªè¢«åˆ›å»ºçš„å®¹å™¨ï¼Œè€Œå…¶ä»–ç”¨æˆ·å®šä¹‰çš„å®¹å™¨ï¼Œåˆ™é€šè¿‡ Join Network Namespace çš„æ–¹å¼ï¼Œä¸ Infra å®¹å™¨å…³è”åœ¨ä¸€èµ·ã€‚è¿™æ ·çš„ç»„ç»‡å…³ç³»ï¼Œå¯ä»¥ç”¨ä¸‹é¢è¿™æ ·ä¸€ä¸ªç¤ºæ„å›¾æ¥è¡¨è¾¾

![image-20250327094347088](../markdown_img/image-20250327094347088.png)



å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™ä¸ª Pod é‡Œæœ‰ä¸¤ä¸ªç”¨æˆ·å®¹å™¨ A å’Œ Bï¼Œè¿˜æœ‰ä¸€ä¸ª Infra å®¹å™¨ã€‚å¾ˆå®¹æ˜“ç†è§£ï¼Œåœ¨ Kubernetes é¡¹ç›®é‡Œï¼ŒInfra å®¹å™¨ä¸€å®šè¦å ç”¨æå°‘çš„èµ„æºï¼Œæ‰€ä»¥å®ƒä½¿ç”¨çš„æ˜¯ä¸€ä¸ªéå¸¸ç‰¹æ®Šçš„é•œåƒï¼Œå«ä½œï¼šk8s.gcr.io/pauseã€‚è¿™ä¸ªé•œåƒæ˜¯ä¸€ä¸ªç”¨æ±‡ç¼–è¯­è¨€ç¼–å†™çš„ã€æ°¸è¿œå¤„äºâ€œæš‚åœâ€çŠ¶æ€çš„å®¹å™¨ï¼Œè§£å‹åçš„å¤§å°ä¹Ÿåªæœ‰ 100~200 KB å·¦å³ã€‚

è€Œåœ¨ Infra å®¹å™¨â€œHold ä½â€Network Namespace åï¼Œç”¨æˆ·å®¹å™¨å°±å¯ä»¥åŠ å…¥åˆ° Infra å®¹å™¨çš„ Network Namespace å½“ä¸­äº†ã€‚æ‰€ä»¥ï¼Œå¦‚æœä½ æŸ¥çœ‹è¿™äº›å®¹å™¨åœ¨å®¿ä¸»æœºä¸Šçš„ Namespace æ–‡ä»¶,å®ƒä»¬æŒ‡å‘çš„å€¼ä¸€å®šæ˜¯å®Œå…¨ä¸€æ ·çš„ã€‚

```bash
[root@node1 ~]#docker ps|grep myapp
2687320f8a75   22193a221b18                                        "/bin/sh -c 'python3â€¦"   24 minutes ago   Up 24 minutes             k8s_pod-test_myapp-547df679bb-9nt5m_default_6a4910c2-a75f-4108-be3c-c00f6cf35889_1
0563af6e6a3b   registry.aliyuncs.com/google_containers/pause:3.9   "/pause"                  24 minutes ago   Up 24 minutes             k8s_POD_myapp-547df679bb-9nt5m_default_6a4910c2-a75f-4108-be3c-c00f6cf35889_1

[root@node1 ~]#docker inspect 2687320f8a75|grep -i pid
            "Pid": 3961,
            "PidMode": "",
            "PidsLimit": null,
[root@node1 ~]#docker inspect 0563af6e6a3b|grep -i pid
            "Pid": 3856,
            "PidMode": "",
            "PidsLimit": null,

[root@node1 ~]#ls -l /proc/3961/ns
æ€»è®¡ 0
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 cgroup -> 'cgroup:[4026533210]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 ipc -> 'ipc:[4026533128]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 mnt -> 'mnt:[4026533207]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 net -> 'net:[4026533130]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 pid -> 'pid:[4026533209]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 pid_for_children -> 'pid:[4026533209]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 time -> 'time:[4026531834]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 time_for_children -> 'time:[4026531834]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 user -> 'user:[4026531837]'
lrwxrwxrwx 1 root root 0  3æœˆ 27 09:31 uts -> 'uts:[4026533208]'
[root@node1 ~]#ls -l /proc/3856/ns
æ€»è®¡ 0
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:32 cgroup -> 'cgroup:[4026533204]'
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:06 ipc -> 'ipc:[4026533128]'                # ç›¸åŒ
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:32 mnt -> 'mnt:[4026533126]'
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:06 net -> 'net:[4026533130]'                # ç›¸åŒ
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:32 pid -> 'pid:[4026533129]'
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:32 pid_for_children -> 'pid:[4026533129]'
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:32 time -> 'time:[4026531834]'              # ç›¸åŒ
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:32 time_for_children -> 'time:[4026531834]' # ç›¸åŒ
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:32 user -> 'user:[4026531837]'              # ç›¸åŒ
lrwxrwxrwx 1 65535 65535 0  3æœˆ 27 09:32 uts -> 'uts:[4026533127]'
```

è¿™ä¹Ÿå°±æ„å‘³ç€ï¼Œå¯¹äº Pod é‡Œçš„å®¹å™¨ A å’Œå®¹å™¨ B æ¥è¯´ï¼š

- å®ƒä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨ localhost è¿›è¡Œé€šä¿¡ï¼›
- å®ƒä»¬çœ‹åˆ°çš„ç½‘ç»œè®¾å¤‡è·Ÿ Infra å®¹å™¨çœ‹åˆ°çš„å®Œå…¨ä¸€æ ·ï¼›
- ä¸€ä¸ª Pod åªæœ‰ä¸€ä¸ª IP åœ°å€ï¼Œä¹Ÿå°±æ˜¯è¿™ä¸ª Pod çš„ Network Namespace å¯¹åº”çš„ IP åœ°å€ï¼›
- å½“ç„¶ï¼Œå…¶ä»–çš„æ‰€æœ‰ç½‘ç»œèµ„æºï¼Œéƒ½æ˜¯ä¸€ä¸ª Pod ä¸€ä»½ï¼Œå¹¶ä¸”è¢«è¯¥ Pod ä¸­çš„æ‰€æœ‰å®¹å™¨å…±äº«ï¼›
- Pod çš„ç”Ÿå‘½å‘¨æœŸåªè·Ÿ Infra å®¹å™¨ä¸€è‡´ï¼Œè€Œä¸å®¹å™¨ A å’Œ B æ— å…³ã€‚

å¯¹äºåŒä¸€ä¸ª Pod é‡Œé¢çš„æ‰€æœ‰ç”¨æˆ·å®¹å™¨æ¥è¯´ï¼Œå®ƒä»¬çš„è¿›å‡ºæµé‡ï¼Œä¹Ÿå¯ä»¥è®¤ä¸ºéƒ½æ˜¯é€šè¿‡ Infra å®¹å™¨å®Œæˆçš„ã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œå› ä¸º**å°†æ¥å¦‚æœä½ è¦ä¸º Kubernetes å¼€å‘ä¸€ä¸ªç½‘ç»œæ’ä»¶æ—¶ï¼Œåº”è¯¥é‡ç‚¹è€ƒè™‘çš„æ˜¯å¦‚ä½•é…ç½®è¿™ä¸ª Pod çš„ Network Namespaceï¼Œè€Œä¸æ˜¯æ¯ä¸€ä¸ªç”¨æˆ·å®¹å™¨å¦‚ä½•ä½¿ç”¨ä½ çš„ç½‘ç»œé…ç½®ï¼Œè¿™æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚**

è¿™å°±æ„å‘³ç€ï¼Œå¦‚æœä½ çš„ç½‘ç»œæ’ä»¶éœ€è¦åœ¨å®¹å™¨é‡Œå®‰è£…æŸäº›åŒ…æˆ–è€…é…ç½®æ‰èƒ½å®Œæˆçš„è¯ï¼Œæ˜¯ä¸å¯å–çš„ï¼šInfra å®¹å™¨é•œåƒçš„ rootfs é‡Œå‡ ä¹ä»€ä¹ˆéƒ½æ²¡æœ‰ï¼Œæ²¡æœ‰ä½ éšæ„å‘æŒ¥çš„ç©ºé—´ã€‚å½“ç„¶ï¼Œè¿™åŒæ—¶ä¹Ÿæ„å‘³ç€ä½ çš„ç½‘ç»œæ’ä»¶å®Œå…¨ä¸å¿…å…³å¿ƒç”¨æˆ·å®¹å™¨çš„å¯åŠ¨ä¸å¦ï¼Œè€Œåªéœ€è¦å…³æ³¨å¦‚ä½•é…ç½® Podï¼Œä¹Ÿå°±æ˜¯ Infra å®¹å™¨çš„ Network Namespace å³å¯ã€‚

æœ‰äº†è¿™ä¸ªè®¾è®¡ä¹‹åï¼Œå…±äº« Volume å°±ç®€å•å¤šäº†ï¼šKubernetes é¡¹ç›®åªè¦æŠŠæ‰€æœ‰ Volume çš„å®šä¹‰éƒ½è®¾è®¡åœ¨ Pod å±‚çº§å³å¯

è¿™æ ·ï¼Œä¸€ä¸ª Volume å¯¹åº”çš„å®¿ä¸»æœºç›®å½•å¯¹äº Pod æ¥è¯´å°±åªæœ‰ä¸€ä¸ªï¼ŒPod é‡Œçš„å®¹å™¨åªè¦å£°æ˜æŒ‚è½½è¿™ä¸ª Volumeï¼Œå°±ä¸€å®šå¯ä»¥å…±äº«è¿™ä¸ª Volume å¯¹åº”çš„å®¿ä¸»æœºç›®å½•ã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: two-containers
spec:
  restartPolicy: Never
  volumes:
  - name: shared-data
    hostPath:      
      path: /data
  containers:
  - name: nginx-container
    image: nginx
    volumeMounts:
    - name: shared-data
      mountPath: /usr/share/nginx/html
  - name: debian-container
    image: debian
    volumeMounts:
    - name: shared-data
      mountPath: /pod-data
    command: ["/bin/sh"]
    args: ["-c", "echo Hello from the debian container > /pod-data/index.html"]
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œdebian-container å’Œ nginx-container éƒ½å£°æ˜æŒ‚è½½äº† shared-data è¿™ä¸ª Volumeã€‚è€Œ shared-data æ˜¯ hostPath ç±»å‹ã€‚æ‰€ä»¥ï¼Œå®ƒå¯¹åº”åœ¨å®¿ä¸»æœºä¸Šçš„ç›®å½•å°±æ˜¯ï¼š/dataã€‚è€Œè¿™ä¸ªç›®å½•ï¼Œå…¶å®å°±è¢«åŒæ—¶ç»‘å®šæŒ‚è½½è¿›äº†ä¸Šè¿°ä¸¤ä¸ªå®¹å™¨å½“ä¸­ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆï¼Œnginx-container å¯ä»¥ä»å®ƒçš„ /usr/share/nginx/html ç›®å½•ä¸­ï¼Œè¯»å–åˆ° debian-container ç”Ÿæˆçš„ index.html æ–‡ä»¶çš„åŸå› ã€‚





#### Podèµ„æºåŸºç¡€

Pod æ˜¯ Kubernetes API ä¸­æœ€å¸¸è§æœ€æ ¸å¿ƒèµ„æºç±»å‹

**Pod æ˜¯ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨çš„é›†åˆ**ï¼Œå› è€Œä¹Ÿå¯ç§°ä¸ºå®¹å™¨é›†ï¼Œä½†å´æ˜¯Kubernetesè°ƒåº¦ã€éƒ¨ç½²å’Œè¿è¡Œåº”ç”¨çš„åŸå­å•å…ƒ

- åŒä¸€Podå†…çš„æ‰€æœ‰å®¹å™¨éƒ½å°†è¿è¡Œäºç”±Scheduleré€‰å®šçš„åŒä¸€ä¸ªworkerèŠ‚ç‚¹ä¸Š
- åœ¨åŒä¸€ä¸ªpodå†…çš„å®¹å™¨å…±äº«çš„**å­˜å‚¨èµ„æº**ã€**ç½‘ç»œåè®®æ ˆ**åŠå®¹å™¨çš„**è¿è¡Œæ§åˆ¶ç­–ç•¥**ç­‰
- æ¯ä¸ªPodä¸­çš„å®¹å™¨ä¾èµ–äºä¸€ä¸ªç‰¹æ®Šåä¸º**pauseå®¹å™¨**äº‹å…ˆåˆ›å»ºå‡ºå¯è¢«å„åº”ç”¨å®¹å™¨å…±äº«çš„**åŸºç¡€ç¯å¢ƒ**ï¼ŒåŒ…æ‹¬ Networkã€IPCå’ŒUTSåç§°ç©ºé—´å…±äº«ç»™Podä¸­å„ä¸ªå®¹å™¨ï¼ŒPIDåç§°ç©ºé—´ä¹Ÿå¯ä»¥å…±äº«ï¼Œä½†éœ€è¦ç”¨æˆ·æ˜¾å¼å®š ä¹‰,**Mountå’ŒUseræ˜¯ä¸å…±äº«çš„**,æ¯ä¸ªå®¹å™¨æœ‰ç‹¬ç«‹çš„Mount,Userçš„åç§°ç©ºé—´


![alt text](images/image31.png)



Podçš„ç»„æˆå½¢å¼æœ‰ä¸¤ç§

- **å•å®¹å™¨Pod**ï¼šé™¤Pauseå®¹å™¨å¤–,ä»…å«æœ‰ä¸€ä¸ªå®¹å™¨
- **å¤šå®¹å™¨Pod**ï¼šé™¤Pauseå®¹å™¨å¤–ï¼Œå«æœ‰å¤šä¸ªå…·æœ‰â€œè¶…äº²å¯†â€å…³ç³»çš„å®¹å™¨ï¼Œä¸€èˆ¬ç”±ä¸»å®¹å™¨å’Œè¾…åŠ©å®¹å™¨ï¼ˆæ¯” å¦‚ï¼š**sidecarå®¹å™¨**ï¼‰æ„æˆ



**Podèµ„æºåˆ†ç±»**

- **è‡ªä¸»å¼ Pod**
  - ç”±ç”¨æˆ·ç›´æ¥å®šä¹‰å¹¶æäº¤ç»™API Serveråˆ›å»ºçš„Pods
- **ç”±Workload Controllerç®¡æ§çš„ Pod**
  - æ¯”å¦‚: ç”±Deploymentæ§åˆ¶å™¨ç®¡ç†çš„Pod
- **é™æ€ Pod**
  - ç”±kubeletåŠ è½½é…ç½®ä¿¡æ¯åï¼Œè‡ªåŠ¨åœ¨å¯¹åº”çš„èŠ‚ç‚¹ä¸Šåˆ›å»ºçš„Pod
  - ç”¨äºå®ç°MasterèŠ‚ç‚¹ä¸Šçš„ç³»ç»Ÿç»„ä»¶API Server ã€Controller-Manager ã€Scheduler å’ŒEtcdåŠŸèƒ½çš„ Pod
  - ç›¸å…³é…ç½®å­˜æ”¾åœ¨æ§åˆ¶èŠ‚ç‚¹çš„ **`/etc/kubernetes/manifests`** ç›®å½•ä¸‹



**æ€»ç»“ï¼š**

- Podä¸­æœ€å°‘æœ‰2ä¸ªå®¹å™¨
- Pod = **Pauseå®¹å™¨** + ä¸šåŠ¡å®¹å™¨



Podçš„ç®¡ç†é“¾

``````ABAP
# è‡ªå®šä¹‰podåˆ›å»ºæµç¨‹
kuebctl --> apiserver --> kubelet --> docker runc --> podå®¹å™¨

# åœ¨/etc/kubernetes/manifestsç›®å½•ä¸‹çš„yamlæ–‡ä»¶ï¼Œä¸éœ€è¦apiserverç®¡ç†ï¼Œä¼šç›´æ¥è¯»å–yamlæ–‡æœ¬æ‰§è¡Œåˆ›å»ºpod

# é™æ€podåˆ›å»ºæµç¨‹
/etc/kubernetes/mainfestsç›®å½•ä¸‹yamlæ–‡ä»¶ ---> kubelet --> docker runc --> ETCD | ApiServer Pod ...
``````



```bash
[root@master1 manifests]#ll /etc/kubernetes/manifests/
æ€»è®¡ 24
drwxrwxr-x 2 root root 4096 12æœˆ 16 13:33 ./
drwxrwxr-x 4 root root 4096 12æœˆ 16 13:33 ../
-rw------- 1 root root 2408 12æœˆ 16 13:33 etcd.yaml
-rw------- 1 root root 4046 12æœˆ 16 13:33 kube-apiserver.yaml
-rw------- 1 root root 3567 12æœˆ 16 13:33 kube-controller-manager.yaml
-rw-r--r-- 1 root root    0 12æœˆ 10 20:09 .kubelet-keep
-rw------- 1 root root 1487 12æœˆ 16 13:33 kube-scheduler.yaml
```





#### è‡ªä¸»å¼Pod



##### æŒ‡ä»¤å¼å‘½ä»¤åˆ›å»ºPod

é€šè¿‡kubectl å‘½ä»¤è¡Œå·¥å…·æŒ‡å®šé€‰é¡¹åˆ›å»º Podï¼Œé€‚åˆ**ä¸´æ—¶æ€§**å·¥ä½œ

åŸºæœ¬è¯­æ³•

```bash
kubectl run NAME --image=image [--port=port] [--replicas=replicas] 

kubectl run NAME --image=image [--env="key=value"] [--port=port] [--dryrun=server|client] [--overrides=inline-json] [--command] -- [COMMAND] [args...] [options]

#å‚æ•°è¯¦è§£
--image='' #æŒ‡å®šå®¹å™¨è¦è¿è¡Œçš„é•œåƒ
--port='' #è®¾å®šå®¹å™¨æš´éœ²çš„ç«¯å£
--dry-run=true #ä»¥æ¨¡æ‹Ÿçš„æ–¹å¼æ¥è¿›è¡Œæ‰§è¡Œå‘½ä»¤
--env=[] #æ‰§è¡Œçš„æ—¶å€™ï¼Œå‘å¯¹è±¡ä¸­ä¼ å…¥ä¸€äº›å˜é‡
--labels='' #è®¾å®špodå¯¹è±¡çš„æ ‡ç­¾
--limits='cpu=200m,memory=512Mi' #è®¾å®šå®¹å™¨å¯åŠ¨åçš„èµ„æºé…ç½®
--replicas=n #è®¾å®špodçš„å‰¯æœ¬æ•°é‡,æ–°ç‰ˆä¸å†æ”¯æŒ
--command=false     #è®¾ä¸ºtrueï¼Œå°† -- åé¢çš„å­—ç¬¦ä¸²åšä¸ºå‘½ä»¤ä»£æ›¿å®¹å™¨é»˜è®¤çš„å¯åŠ¨å‘½ä»¤ï¼Œè€Œéåšä¸ºé»˜
è®¤å¯åŠ¨å‘½ä»¤çš„å‚æ•°
-it            #æ‰“å¼€äº¤äº’ç»ˆç«¯
--rm           #å³å‡ºå³åˆ é™¤å®¹å™¨
--restart=Never #ä¸ä¼šé‡å¯
```



ç¤ºä¾‹

```bash
#åˆå§‹åŒ–ä¸€ä¸ªPodå¯¹è±¡ï¼ŒåŒ…å«ä¸€ä¸ªnginxå®¹å™¨
[root@master1 manifests]#kubectl run myapp-pod --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v1.0
pod/myapp-pod created

#åˆ›å»ºBusyboxçš„Pod,é»˜è®¤busyboxæ²¡æœ‰å‰å°è¿›ç¨‹,éœ€è¦æŒ‡å®šå‰å°ç¨‹åºæ‰èƒ½æŒç»§è¿è¡Œ
[root@master1 manifests]#kubectl run busbox --image busybox:1.30 -- sleep 3600
pod/busbox created

[root@master1 manifests]#kubectl get pod
NAME                     READY   STATUS    RESTARTS   AGE
busbox                   1/1     Running   0          17s

# è¿›å…¥å®¹å™¨
[root@master1 manifests]#kubectl exec -it busbox -- sh
/ # 

# è¿è¡Œpodæ—¶å®šä¹‰ä¸€ä¸ªå˜é‡
[root@master1 manifests]#kubectl run busybox --image busybox:1.30 --env="NAME=mystical" -- sleep 3600
pod/busybox created

[root@master1 manifests]#kubectl get pod
NAME                     READY   STATUS    RESTARTS   AGE
busybox                  1/1     Running   0          8s
myapp-7b94444f8d-9xld5   1/1     Running   0          133m
myapp-7b94444f8d-dhkdj   1/1     Running   0          133m
myapp-7b94444f8d-ssp7z   1/1     Running   0          133m
myapp-pod                1/1     Running   0          8m28s

[root@master1 manifests]#kubectl exec -it busybox -- sh
/ # echo $NAME
mystical
```



#### podèµ„æºæ¸…å•è¯´æ˜



##### yamlæ ¼å¼çš„Podæ¸…å•æ–‡ä»¶-æç®€ç‰ˆ

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: myapp2
  namespace: m58-namespace
spec:
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v1.0
    name: myapp2
```



##### yamlæ ¼å¼çš„Podæ¸…å•æ–‡ä»¶å®ä¾‹-å®Œæ•´ç‰ˆ

```yaml
# yamlæ ¼å¼çš„Podå®šä¹‰æ–‡ä»¶å®Œæ•´å†…å®¹
apiVersion: v1
kind: Pod
metadata:
  name: string
  namespace: string
  labels:
    name: string
  annotations:
    name: string
spec:
  initContainers:
  - name: string
    image: string
    imagePullPolicy: Always  # Options: Always, Never, IfNotPresent
    command: 
      - string
    args: 
      - string
  containers:
  - name: string
    image: string
    imagePullPolicy: Always  # Options: Always, Never, IfNotPresent
    command: 
      - string
    args: 
      - string
    workingDir: string
    volumeMounts:
    - name: string
      mountPath: string
      readOnly: true  # Options: true, false
    ports:
    - name: string
      containerPort: 80  # Replace with the correct port
      hostPort: 80  # Replace with the correct port
      protocol: TCP  # Options: TCP, UDP, SCTP
    env:
    - name: string
      value: string
    resources:
      limits:
        cpu: "500m"  # Replace with actual limit
        memory: "128Mi"  # Replace with actual limit
      requests:
        cpu: "250m"  # Replace with actual request
        memory: "64Mi"  # Replace with actual request
    startupProbe:
      httpGet:
        path: /healthz
        port: 80  # Replace with actual port
    livenessProbe:
      exec:
        command: 
          - string
      httpGet:
        path: /healthz
        port: 80  # Replace with actual port
        host: localhost  # Replace with actual host
        scheme: HTTP  # Options: HTTP, HTTPS
        httpHeaders:
        - name: string
          value: string
      tcpSocket:
        port: 80  # Replace with actual port
      initialDelaySeconds: 10
      timeoutSeconds: 5
      periodSeconds: 10
      successThreshold: 1
      failureThreshold: 3
    securityContext:
      privileged: false  # Options: true, false
  restartPolicy: Always  # Options: Always, Never, OnFailure
  nodeSelector: 
    disktype: ssd  # Example node selector
  nodeName: string  # Replace with actual node name
  imagePullSecrets:
  - name: my-secret  # Replace with actual secret name
  hostNetwork: false  # Options: true, false
  volumes: 
  - name: empty-volume
    emptyDir: {}
  - name: host-path-volume
    hostPath:
      path: /data/volume  # Replace with actual path
  - name: secret-volume
    secret:
      secretName: string  # Replace with actual secret name
      items:     
      - key: string
        path: string
  - name: configmap-volume
    configMap:
      name: string  # Replace with actual ConfigMap name
      items:
      - key: string
        path: string
```



##### æ›´æ–°Podèµ„æº

```bash
# æ–¹æ³•1
# å¯¼å‡ºé…ç½®
# kubectl get pods pod-test1 -o yaml pod-test1-update.yaml

# ç¼–è¯‘å¯¼å‡ºçš„é…ç½®æ¸…å•
[root@master1 ~]# vim myapp-pod-update.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2024-12-16T07:47:09Z"
  labels:
    run: myapp-pod
  name: myapp-pod
  namespace: default
  resourceVersion: "13553"
  uid: 6e9fe649-9761-4d71-a7f9-9e8423e105b4
spec:
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:1.0  # æ”¹ä¸ºmyapp:2.0
    imagePullPolicy: IfNotPresent
...

# æ›´æ–°
kubectl replace -f myapp-pod-update.yaml # replaceä¸å»ºè®®ä½¿ç”¨ï¼Œæ²¡æœ‰å¹‚ç­‰æ€§ï¼Œå»ºè®®apply

# éªŒè¯æ˜¯å¦ä¿®æ”¹
[root@master1 ~]# kubectl describe -f myapp-pod-update.yaml
...
Events:
  Type    Reason     Age                  From               Message
  ----    ------     ----                 ----               -------
  Normal  Scheduled  48m                  default-scheduler  Successfully assigned default/myapp-pod to node1
  Normal  Pulled     48m                  kubelet            Container image "registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v1.0" already present on machine
  Normal  Pulling    5m23s                kubelet            Pulling image "registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v2.0"
  Normal  Pulled     5m12s                kubelet            Successfully pulled image "registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v2.0" in 10.467s (10.468s including waiting). Image size: 23012239 bytes.
  Normal  Killing    60s (x2 over 5m23s)  kubelet            Container myapp-pod definition changed, will be restarted
  Normal  Pulling    60s                  kubelet            Pulling image "registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v3.0"
  Normal  Created    43s (x3 over 48m)    kubelet            Created container myapp-pod
  Normal  Pulled     43s                  kubelet            Successfully pulled image "registry.cn-beijing.aliyuncs.com/wangxiaochun/myapp:v3.0" in 16.971s (16.971s including waiting). Image size: 23012239 bytes.
  Normal  Started    42s (x3 over 48m)    kubelet            Started container myapp-pod

```



##### å£°æ˜å¼å¯¹è±¡ç®¡ç†æ–¹å¼

**åˆ›å»º Pod èµ„æºå¯¹è±¡**

```bash
[root@master1 yaml]#kubectl apply -f pod-test1.yaml 
pod/pod-test1 created

[root@master1 yaml]#kubectl get -f pod-test1.yaml -o wide
NAME       READY   STATUS   RESTARTS   AGE   IP           NODE               
NOMINATED NODE   READINESS GATES
pod-test1   1/1     Running   0         5m8s   172.16.3.13   node1.wang.org   
<none>           <none>

[root@master1 ~]#curl 172.16.3.13 -I
HTTP/1.1 200 OK
Server: nginx/1.21.5
Date: Tue, 01 Mar 2022 04:32:32 GMT
Content-Type: text/html
Content-Length: 615
Last-Modified: Tue, 28 Dec 2021 15:28:38 GMT
Connection: keep-alive
ETag: "61cb2d26-267"
Accept-Ranges: bytes
```



**æ›´æ–°åº”ç”¨ç‰ˆæœ¬**

```bash
# æ›´æ–°å¯¹è±¡çš„æ“ä½œï¼Œå¯ä»¥ç›´æ¥åœ¨åŸæœ‰çš„èµ„æºæ¸…å•æ–‡ä»¶ä¸Šä¿®æ”¹åå†æ‰§è¡Œkubectl apply
# ç”Ÿäº§ç¯å¢ƒä¸‹ï¼Œå»ºè®®ä½¿ç”¨ï¼Œå…·æœ‰å¹‚ç­‰æ€§
[root@master1 yaml]#vim pod-test1.yaml
[root@master1 yaml]#cat pod-test1.yaml
apiVersion: v1
kind: Pod      
metadata:       
 name: pod-test1 
 labels:      
   app: test1  
   version: v1.0
spec:         
 containers:  
  - name: nginx-web01
   image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0 #ä¿®æ”¹æ­¤è¡Œ
   
#åº”ç”¨æ›´æ–°
[root@master1 yaml]#kubectl apply -f pod-test1.yaml 
pod/pod-test1 configured
```



#### PodæŸ¥çœ‹çŠ¶æ€

å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹Pod çŠ¶æ€

```bash
kubectl get pod <pod_name> [(-o|--output=)json|yaml|jsonpath] [-n namespace]
kubectl describe pod <pod_name> [-n namespace]
```



èŒƒä¾‹

``````bash
#æŸ¥çœ‹å½“å‰åç§°ç©ºé—´çš„æ‰€æœ‰pod
[root@master1 ~]# kubectl get pod

#æŸ¥çœ‹æ‰€æœ‰ç©ºé—´çš„æ‰€æœ‰pod
[root@master1 ~]# kubectl get pod -A

#æŸ¥çœ‹æŒ‡å®špodå½“å‰çŠ¶æ€ä¿¡æ¯
[root@master1 yaml]# kubectl get -f pod-test1.yaml 
[root@master1 ~]# kubectl get pod pod-test1 
[root@master1 ~]# kubectl get po pod-test1 #æ”¯æŒç¼©å†™po
NAME       READY   STATUS   RESTARTS   AGE
pod-test1   1/1     Running   0         67s

#æŒç»­æŸ¥çœ‹podçŠ¶æ€
# kubectl get pods pod-test1 -w

#æŸ¥çœ‹æ‰©å±•ä¿¡æ¯
[root@master1 ~]#kubectl get pod pod-test1 -o wide
NAME       READY   STATUS   RESTARTS   AGE   IP           NODE               
NOMINATED NODE   READINESS GATES
pod-test1   1/1     Running   0         88s   172.16.3.12   node1.wang.org   
<none>           <none>

#é€šè¿‡ -o yaml çš„æ–¹å¼æ¥è¿›è¡ŒæŸ¥çœ‹yamlæ ¼å¼çš„è¯¦ç»†ä¿¡æ¯
[root@master1 ~]#kubectl get pod pod-test -o yaml
apiVersion: v1
kind: Pod
metadata:
 annotations:
   kubectl.kubernetes.io/last-applied-configuration: |
......

#æŸ¥çœ‹podä¸Šé¢çš„label
[root@master1 ~]#kubectl get pod pod-test1 --show-labels
NAME       READY   STATUS   RESTARTS       AGE   LABELS
pod-test1   1/1     Running   7 (7h4m ago)   14d   app=test1,version=v2.0
``````



#### æŸ¥çœ‹Podä¸­æŒ‡å®šå®¹å™¨åº”ç”¨çš„æ—¥å¿—

```bash
kubectl logs [-f] (POD | TYPE/NAME) [-c CONTAINER] [options]
# é€‰é¡¹

-p å‰ä¸€ä¸ªå·²é€€å‡ºçš„å®¹å™¨çš„æ—¥å¿—
--all-containers=true æ‰€æœ‰å®¹å™¨
--tail=N æœ€åNä¸ªæ—¥å¿—

# ç¤ºä¾‹
[root@master1 ~]#kubectl logs myapp-pod 
10.244.0.0 - - [16/Dec/2024:16:34:39 +0800] "GET / HTTP/1.1" 200 31 "-" "curl/7.81.0"

# è¿›å…¥å®¹å™¨å†…æ‰§è¡Œæ“ä½œ
[root@master1 ~]#kubectl exec myapp-pod -- ps aux
PID   USER     TIME  COMMAND
    1 root      0:00 nginx: master process nginx -g daemon off;
    7 nginx     0:00 nginx: worker process
    8 root      0:00 ps aux
```



####  è¿›å…¥Pod æ‰§è¡Œå‘½ä»¤

```bash
kubectl exec (POD | TYPE/NAME) [-c CONTAINER] [flags] -- COMMAND [args...] [options]
```

èŒƒä¾‹

```bash
# äº¤äº’å¼æ‰§è¡Œ
[root@master1 ~]#kubectl exec -it myapp-pod -- sh
/ # ps aux
PID   USER     TIME  COMMAND
    1 root      0:00 nginx: master process nginx -g daemon off;
    7 nginx     0:00 nginx: worker process
   14 root      0:00 sh
   20 root      0:00 ps aux
```



#### åˆ é™¤ Pod

åˆ é™¤èµ„æºå¯¹è±¡æ¨èä½¿ç”¨æŒ‡ä»¤å¼ç®¡ç†å‘½ä»¤ `kubectl delete`

```bash
kubectl delete pod <pod_name> ... [--force --grace-period=0]
```



èŒƒä¾‹

```bash
#ä¼˜é›…åˆ é™¤
[root@master1 ~]#kubectl delete pod pod-test1

#ç«‹å³åˆ é™¤
[root@master1 ~]#kubectl delete pod pod-test1 --force --grace-period=0
warning: Immediate deletion does not wait for confirmation that the running 
resource has been terminated. The resource may continue to run on the cluster 
indefinitely.
pod "pod-test1" force deleted

#åˆ é™¤å¤šä¸ªèµ„æº
[root@master1 yaml]#kubectl delete -f pod-test1.yaml -f /data/kubernetes/yaml/pod-test2.yaml

#åˆ é™¤æ‰€æœ‰pod
[root@master1 ~]#kubectl get po|cut -d" " -f1 | tail -n +2 |xargs kubectl delete pod

#å¿«é€Ÿåˆ é™¤æ‰€æœ‰pod
[root@master1 ~]#kubectl get pod|awk 'NR!=1{print $1}'|xargs -i kubectl delete pod {} --force --grace-period=0
```



#### åˆ›å»ºå®šåˆ¶çš„Pod

kubernets æ”¯æŒå¤šç§å®šåˆ¶ Pod çš„å®ç°æ–¹æ³•

- å¯¹äºä¸åŒåº”ç”¨çš„Pod,é‡æ–°å®šåˆ¶å¯¹åº”çš„é•œåƒ
- å¯åŠ¨å®¹å™¨æ—¶æŒ‡å®šenvç¯å¢ƒå˜é‡
- å¯åŠ¨å®¹å™¨çš„æŒ‡å®šcommandå’Œargs
- å°†é…ç½®ä¿¡æ¯åŸºäºå·èµ„æºå¯¹è±¡ï¼Œå†å°†å…¶åŠ è½½åˆ°å®¹å™¨ï¼Œæ¯”å¦‚ï¼šconfigMapå’Œsecretç­‰



#####  åˆ©ç”¨ç¯å¢ƒå˜é‡`env`å®ç°å®¹å™¨ä¼ å‚

åœ¨å®¹å™¨ä¸ŠåµŒå¥—ä½¿ç”¨envå­—æ®µ

- æ¯ä¸ªç¯å¢ƒå˜é‡éœ€è¦é€šè¿‡`pod.spec.containers.env.name`ç»™å‡ºæŒ‡å®šçš„åç§°
- ä¼ é€’çš„å€¼åˆ™å®šä¹‰åœ¨`pod.spec.containers.env.value`å­—æ®µä¸Š



ç¤ºä¾‹ï¼šå®ç°LAMPçš„åº”ç”¨wordpress

```bash
# mysql
[root@master1 lamp]# vim pod-mysql.yaml
[root@master1 lamp]# cat pod-mysql.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: mydb
  namespace: default
spec:
  containers:
  - name: mysql
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/mysql:8.0.29-oracle
    env:
    - name: MYSQL_ROOT_PASSWORD
      value: "654321"
    - name: MYSQL_DATABASE
      value: wordpress
    - name: MYSQL_USER
      value: wpuser
    - name: MYSQL_PASSWORD
      value: "123456
   
# æŸ¥çœ‹MySQLå¯¹åº”Podçš„IP
[root@master1 lamp]#kubectl apply -f pod-mysql.yaml
pod/mydb created

[root@master1 lamp]#kubectl get pods mydb -o wide
NAME   READY   STATUS    RESTARTS   AGE     IP           NODE    NOMINATED NODE   READINESS GATES
mydb   1/1     Running   0          2m44s   10.244.2.6   node2   <none>           <none>


# wordpress
[root@master1 lamp]#vim pod-wordpress.yaml
[root@master1 lamp]#cat pod-wordpress.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: wordpress
  namespace: default
spec:
  hostNetwork: true
  containers:
  - name: wordpress
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/wordpress:php8.2-apache
    env:
    - name: WORDPRESS_DB_HOST
      value: 10.244.2.6
    - name: WORDPRESS_DB_NAME
      value: wordpress
    - name: WORDPRESS_DB_USER
      value: wpuser
    - name: WORDPRESS_DB_PASSWORD
      value: "123456"

[root@master1 lamp]#kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS      AGE     IP           NODE    NOMINATED NODE   READINESS GATES
myapp-7b94444f8d-9xld5   1/1     Running   0             4h16m   10.244.1.2   node1   <none>           <none>
myapp-7b94444f8d-dhkdj   1/1     Running   0             4h16m   10.244.2.2   node2   <none>           <none>
myapp-7b94444f8d-ssp7z   1/1     Running   0             4h16m   10.244.3.4   node3   <none>           <none>
myapp-pod                1/1     Running   2 (84m ago)   131m    10.244.1.5   node1   <none>           <none>
mydb                     1/1     Running   0             48m     10.244.2.6   node2   <none>           <none>
wordpress                1/1     Running   0             5m22s   10.0.0.202   node1   <none>           <none>
```

![alt text](images\image32.png)



##### åˆ©ç”¨`command`å’Œ`args`å­—æ®µä¼ é€’å®¹å™¨çš„å¯åŠ¨å‘½ä»¤å’Œå‚æ•°

Podé…ç½®ä¸­ï¼Œspec.containers[].commandå­—æ®µèƒ½å¤Ÿåœ¨å®¹å™¨ä¸ŠæŒ‡å®šæ›¿ä»£é•œåƒé»˜è®¤è¿è¡Œçš„åº”ç”¨ç¨‹åºï¼Œä¸”å¯ åŒæ—¶ä½¿ç”¨spec.containers[].argså­—æ®µè¿›è¡Œå‚æ•°ä¼ é€’ï¼Œå®ƒä»¬å°†è¦†ç›–é•œåƒä¸­çš„é»˜è®¤å®šä¹‰çš„å‚æ•°ã€‚

- è‹¥ä»…å®šä¹‰äº†commandå­—æ®µæ—¶ï¼Œå…¶å€¼å°†è¦†ç›–é•œåƒä¸­å®šä¹‰çš„ç¨‹åºåŠå‚æ•°ã€‚
- è‹¥ä»…æ˜¯å®šä¹‰äº†argså­—æ®µï¼Œè¯¥å­—æ®µå€¼å°†ä½œä¸ºå‚æ•°ä¼ é€’ç»™é•œåƒä¸­é»˜è®¤æŒ‡å®šè¿è¡Œçš„åº”ç”¨ç¨‹åº
- **æ³¨æ„: argsä¸­ä½¿ç”¨ç¯å¢ƒå˜é‡,éœ€è¦ä½¿ç”¨æ ¼å¼: $(ç¯å¢ƒå˜é‡å)**



**æ·»åŠ è¿è¡Œå‘½ä»¤å’Œå‚æ•°**

```bash
[root@master1 yaml]#cat pod-with-cmd-and-args.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-cmd-and-args
spec:
  containers:
  - name: pod-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
    command: ['/bin/sh','-c']
    args: ['python3 /usr/local/bin/demo.py -p 8080']
    
[root@master1 yaml]#kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS      AGE   IP           NODE    NOMINATED NODE   READINESS GATES
myapp-7b94444f8d-66d4h   1/1     Running   1 (12m ago)   29h   10.244.4.4   node2   <none>           <none>
myapp-7b94444f8d-nctmp   1/1     Running   1 (12m ago)   29h   10.244.3.5   node1   <none>           <none>
myapp-7b94444f8d-tnj2j   1/1     Running   1 (12m ago)   29h   10.244.5.3   node3   <none>           <none>
pod-with-cmd-and-args    1/1     Running   1 (12m ago)   60m   10.244.3.4   node1   <none>           <none>

[root@master1 yaml]#curl 10.244.3.4:8080
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: pod-with-cmd-and-args, ServerIP: 10.244.3.4!
```



**æ·»åŠ è¿è¡Œå‘½ä»¤ï¼Œå‚æ•°å’Œç¯å¢ƒå˜é‡**

```bash
[root@master1 yaml]#cat pod-with-cmd-and-args.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-cmd-and-args
spec:
  containers:
  - name: pod-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
    command: ['/bin/sh','-c']
    args: ['python3 /usr/local/bin/demo.py -p $port']
    env:
    - name: port
      value: "8888"
      
[root@master1 yaml]#kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS      AGE   IP           NODE    NOMINATED NODE   READINESS GATES
myapp-7b94444f8d-66d4h   1/1     Running   1 (29m ago)   29h   10.244.4.4   node2   <none>           <none>
myapp-7b94444f8d-nctmp   1/1     Running   1 (29m ago)   29h   10.244.3.5   node1   <none>           <none>
myapp-7b94444f8d-tnj2j   1/1     Running   1 (29m ago)   29h   10.244.5.3   node3   <none>           <none>
pod-with-cmd-and-args    1/1     Running   0             59s   10.244.5.4   node3   <none>           <none>
      
[root@master1 yaml]#curl 10.244.5.4:8888
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: pod-with-cmd-and-args, ServerIP: 10.244.5.4!
```

 

##### ä½¿ç”¨å®¿ä¸»æœºç½‘ç»œå®ç°å®¹å™¨çš„å¤–éƒ¨è®¿é—®

é»˜è®¤å®¹å™¨ä½¿ç”¨ç§æœ‰çš„ç‹¬ç«‹ç½‘æ®µï¼Œæ— æ³•ä»é›†ç¾¤å¤–ç›´æ¥è®¿é—®ï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢ä¸¤ç§æ–¹å¼å®ç°å¤–éƒ¨è®¿é—®

- è®©å®¹å™¨ç›´æ¥ä½¿ç”¨å®¿ä¸»æœºçš„ç½‘ç»œåœ°å€ï¼Œå³å®¹å™¨ä½¿ç”¨hostçš„ç½‘è·¯æ¨¡å‹
- è®©å®¹å™¨é€šè¿‡å®¿ä¸»æœºçš„ç«¯å£æ˜ å°„å®ç°ï¼Œå³DNAT

æ³¨æ„ï¼šéƒ½è¦é¿å…ç«¯å£å†²çª



```bash
[root@master1 yaml]#cat pod-hostnetwork.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-hostnetwork-demo
spec:
  hostNetwork: true
  containers:
  - name: demo-env
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    env:
    - name: PORT
      value: "9999"
      
[root@master1 yaml]#kubectl apply -f pod-hostnetwork.yaml 
pod/pod-hostnetwork-demo created

[root@master1 yaml]#kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS      AGE     IP           NODE    NOMINATED NODE   READINESS GATES
myapp-7b94444f8d-66d4h   1/1     Running   1 (35m ago)   29h     10.244.4.4   node2   <none>           <none>
myapp-7b94444f8d-nctmp   1/1     Running   1 (35m ago)   29h     10.244.3.5   node1   <none>           <none>
myapp-7b94444f8d-tnj2j   1/1     Running   1 (35m ago)   29h     10.244.5.3   node3   <none>           <none>
pod-hostnetwork-demo     1/1     Running   0             21s     10.0.0.105   node2   <none>           <none>
pod-with-cmd-and-args    1/1     Running   0             7m33s   10.244.5.4   node3   <none>           <none>

[root@master1 yaml]#curl 10.0.0.105:9999
kubernetes pod-test v0.1!! ClientIP: 10.0.0.101, ServerName: node2, ServerIP: 10.0.0.105!
```



ä½¿ç”¨å®¹å™¨æ‰€åœ¨å®¿ä¸»æœºæŒ‡å®šçš„ç«¯å£

```bash
# ä½¿ç”¨ç«¯å£æ˜ å°„
[root@master1 yaml]#cat pod-hostport.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-hostport-demo
spec:
  containers:
  - name: demo-env
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    env:
    - name: PORT
      value: "9999"
    ports:                           # ä½¿ç”¨å®¿ä¸»æœºæŒ‡å®šç«¯å£
    - name: http                     # ä¸æ”¯æŒå¤§å†™å­—æ¯
      containerPort: 9999            # ä½¿ç”¨ä¸Šé¢å˜é‡ç›¸åŒçš„ç«¯å£
      hostPort: 8888


# æœ¬è´¨ä¸Šå°±æ˜¯é€šè¿‡å®¿ä¸»æœºçš„DNATç­–ç•¥å®ç°
[root@master1 yaml]#ssh 10.0.0.104 iptables -vnL -t nat |grep DNAT|grep 8888
    1    60 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:8888 to:10.244.3.6:9999

[root@master1 yaml]#iptables --version
iptables v1.8.7 (nf_tables)

# è¿™é‡Œçš„ (nf_tables) è¡¨ç¤º iptables æ˜¯åœ¨ nftables æ¡†æ¶ä¸­å®ç°çš„
# iptables å®é™…ä¸Šæ˜¯ä¸€ä¸ªå¯¹ nftables çš„å°è£…
```





#### ä¸´æ—¶å®¹å™¨

#####  äº†è§£ä¸´æ—¶å®¹å™¨

Pod æ˜¯ Kubernetes åº”ç”¨ç¨‹åºçš„åŸºæœ¬æ„å»ºå—ã€‚ ç”±äº Pod æ˜¯ä¸€æ¬¡æ€§ä¸”å¯æ›¿æ¢çš„ï¼Œå› æ­¤ä¸€æ—¦ Pod åˆ›å»ºï¼Œå°± æ— æ³•å°†å®¹å™¨åŠ å…¥åˆ° Pod ä¸­ã€‚ å–è€Œä»£ä¹‹çš„æ˜¯ï¼Œé€šå¸¸ä½¿ç”¨ Deployment ä»¥å—æ§çš„æ–¹å¼æ¥åˆ é™¤å¹¶æ›¿æ¢ Podã€‚

æœ‰æ—¶æœ‰å¿…è¦æ£€æŸ¥ç°æœ‰ Pod çš„çŠ¶æ€ã€‚ä¾‹å¦‚ï¼Œå¯¹äºéš¾ä»¥å¤ç°çš„æ•…éšœè¿›è¡Œæ’æŸ¥ã€‚ åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œå¯ä»¥åœ¨ç°æœ‰  Pod ä¸­è¿è¡Œä¸´æ—¶å®¹å™¨æ¥æ£€æŸ¥å…¶çŠ¶æ€å¹¶è¿è¡Œä»»æ„å‘½ä»¤ã€‚

Kubernetes v1.16æ¨å‡ºä¸´æ—¶å®¹å™¨, Kubernetes v1.25ç¨³å®šå¯ç”¨, å°±æ˜¯åœ¨åŸæœ‰çš„Pod ä¸Šï¼Œæ·»åŠ ä¸€ä¸ª**ä¸´æ—¶çš„ Containerï¼Œè¿™ä¸ªContainerå¯ä»¥åŒ…å«æˆ‘ä»¬æ’æŸ¥é—®é¢˜æ‰€æœ‰çš„å·¥å…·**, æ¯”å¦‚: ipã€ssã€psã€pstreeã€topã€killã€ topã€jstatã€jmapç­‰







### Podå·¥ä½œæœºåˆ¶



#### PodåŸºæœ¬åŸç†

![image-20241217182330834](../markdown_img/image-20241217182330834.png)

##### Pauseå®¹å™¨

**ä»€ä¹ˆæ˜¯ pause å®¹å™¨ï¼Ÿ**

- **pause å®¹å™¨** æ˜¯æ¯ä¸ª Pod ä¸­çš„ä¸€ä¸ªâ€œåŸºç¡€â€æˆ–â€œè¾…åŠ©â€å®¹å™¨ï¼Œä½œä¸º **â€œPodçš„åŸºç¡€ç¯å¢ƒâ€**ã€‚
- **pause å®¹å™¨çš„æ ¸å¿ƒç›®çš„æ˜¯**ï¼š
  1. ä½œä¸º Pod ä¸­æ‰€æœ‰å…¶ä»–å®¹å™¨çš„â€œ**æ ¹å‘½åç©ºé—´**â€ï¼ˆåŒ…æ‹¬ç½‘ç»œã€PIDã€IPCã€ç”¨æˆ·å‘½åç©ºé—´ç­‰ï¼‰ã€‚
  2. æä¾›ä¸€ä¸ª**ç®¡ç†æ‰€æœ‰å®¹å™¨çš„çˆ¶å®¹å™¨**ã€‚
  3. å……å½“**ç½‘ç»œæ ˆçš„å®¿ä¸»**ï¼Œå³å°† Pod çš„ IP åœ°å€åˆ†é…åˆ° pause å®¹å™¨ã€‚
  4. **é˜²æ­¢å­¤å„¿è¿›ç¨‹**ï¼špause å®¹å™¨è´Ÿè´£å›æ”¶ Pod ä¸­å­è¿›ç¨‹ï¼ˆå³åƒµå°¸è¿›ç¨‹ï¼‰ï¼Œé˜²æ­¢å­¤å„¿è¿›ç¨‹æ®‹ç•™ã€‚
  5. **ç»Ÿä¸€ç®¡ç†ç”Ÿå‘½å‘¨æœŸ**ï¼šå½“ Pod è¢«é”€æ¯æ—¶ï¼Œ**æ‰€æœ‰ä¸ pause å®¹å™¨å…±äº«å‘½åç©ºé—´çš„å®¹å™¨**ä¹Ÿä¼šè¢«é”€æ¯ã€‚



ğŸŸ¢ **pause å®¹å™¨çš„ä¸»è¦ä½œç”¨**

| **ä½œç”¨**          | **æè¿°**                                                     |
| ----------------- | ------------------------------------------------------------ |
| **ç½‘ç»œå‘½åç©ºé—´**  | Pod ä¸­çš„ç½‘ç»œæ ˆæ˜¯ pause å®¹å™¨çš„ç½‘ç»œæ ˆï¼Œæ‰€æœ‰å…¶ä»–å®¹å™¨ä¸å®ƒå…±äº« IP åœ°å€ã€ç«¯å£å’Œç½‘ç»œå‘½åç©ºé—´ã€‚ |
| **PID å‘½åç©ºé—´**  | Pod å†…çš„æ‰€æœ‰å®¹å™¨ä¸ pause å®¹å™¨å…±äº«ä¸€ä¸ª PID å‘½åç©ºé—´ï¼ŒPod å†…çš„è¿›ç¨‹èƒ½â€œçœ‹åˆ°â€å½¼æ­¤çš„è¿›ç¨‹åˆ—è¡¨ã€‚ |
| **IPC å‘½åç©ºé—´**  | å®¹å™¨ä¹‹é—´çš„è¿›ç¨‹é€šä¿¡ï¼ˆå¦‚ä¿¡å·ã€ä¿¡å·é‡ï¼‰æ˜¯é€šè¿‡ IPC å®ç°çš„ï¼ŒPod ä¸­çš„ IPC å‘½åç©ºé—´ç”± pause å®¹å™¨æä¾›ã€‚ |
| **Volume å·ç®¡ç†** | å¦‚æœ Pod ä¸­æœ‰æŒ‚è½½å·ï¼Œå·çš„è·¯å¾„é€šå¸¸å…ˆæŒ‚è½½åˆ° pause å®¹å™¨çš„æ–‡ä»¶ç³»ç»Ÿä¸­ï¼Œå…¶ä»–å®¹å™¨å…±äº«è¿™ä¸ªè·¯å¾„ã€‚ |
| **åƒµå°¸è¿›ç¨‹å›æ”¶**  | å¦‚æœ Pod å†…çš„æŸä¸ªå®¹å™¨å†…çš„å­è¿›ç¨‹é€€å‡ºï¼Œè¿™ä¸ªåƒµå°¸è¿›ç¨‹ä¸ä¼šç›´æ¥è¢«å®¿ä¸»æœºçš„ init è¿›ç¨‹ (PID 1) å›æ”¶ï¼Œè€Œæ˜¯ç”± pause å®¹å™¨å›æ”¶ã€‚ |
| **çˆ¶è¿›ç¨‹ä½œç”¨**    | pause å®¹å™¨çš„ PID å§‹ç»ˆæ˜¯ Pod ä¸­çš„ç¬¬ä¸€ä¸ªè¿›ç¨‹ (PID=1)ï¼Œæ‰€æœ‰å…¶ä»–è¿›ç¨‹ï¼ˆå³ä¸šåŠ¡å®¹å™¨çš„è¿›ç¨‹ï¼‰éƒ½æ˜¯ pause å®¹å™¨çš„â€œå­è¿›ç¨‹â€ã€‚ |





ğŸŸ¢ **å®é™…çš„æœºåˆ¶ï¼ˆæ·±å…¥å‰–æï¼‰**

- 1ï¸âƒ£ å½“ kubelet å¯åŠ¨ä¸€ä¸ª Pod æ—¶ï¼š
  - **pause å®¹å™¨é¦–å…ˆå¯åŠ¨**ï¼Œè¿™æ˜¯ Pod çš„ç¬¬ä¸€ä¸ªå®¹å™¨ã€‚
  - å¯åŠ¨ pause å®¹å™¨çš„åŸå› æ˜¯ï¼šå®ƒä¼šåˆ›å»º**PID å‘½åç©ºé—´ã€ç½‘ç»œå‘½åç©ºé—´ã€IPC å‘½åç©ºé—´å’Œ UTS å‘½åç©ºé—´**ã€‚
  - pause å®¹å™¨çš„ PID åœ¨ Pod å‘½åç©ºé—´ä¸­æ˜¯ **1**ï¼Œå³**PID=1**ã€‚
- 2ï¸âƒ£ å½“å…¶ä»–ä¸šåŠ¡å®¹å™¨å¯åŠ¨æ—¶ï¼š
  - ä¸šåŠ¡å®¹å™¨ä¸ä¼šä» pause å®¹å™¨ fork() å‡ºæ¥ï¼Œè€Œæ˜¯**containerd æˆ– dockerd** å¯åŠ¨çš„ã€‚
  - ä¸šåŠ¡å®¹å™¨å’Œ pause å®¹å™¨**å…±äº« pause å®¹å™¨çš„å‘½åç©ºé—´**ï¼ˆç½‘ç»œã€IPCã€PIDã€Volume ç­‰ï¼‰ï¼Œè¿™å°±æ˜¯â€œå…±äº«â€å‘½åç©ºé—´çš„å«ä¹‰ã€‚
  - **ä» PID è§†è§’çœ‹**ï¼Œæ‰€æœ‰ä¸šåŠ¡å®¹å™¨ä¸­çš„è¿›ç¨‹éƒ½å±äº pause å®¹å™¨çš„å­è¿›ç¨‹ã€‚



ğŸŸ¢ **ä¸ºä»€ä¹ˆéœ€è¦ pause å®¹å™¨ï¼Ÿ**

- **ç»Ÿä¸€å‘½åç©ºé—´**ï¼š
  - Pod ä¸­çš„å¤šä¸ªä¸šåŠ¡å®¹å™¨å…±äº«**ç½‘ç»œå‘½åç©ºé—´**ï¼Œè¿™ä½¿å¾—å®ƒä»¬å…±äº«ä¸€ä¸ª IP åœ°å€ï¼ˆPod IPï¼‰ã€‚
  - é€šè¿‡ pause å®¹å™¨çš„ PID 1ï¼Œæ‰€æœ‰ä¸šåŠ¡å®¹å™¨å¯ä»¥å…±äº«åŒä¸€ä¸ª PID å‘½åç©ºé—´ã€‚
- **è´Ÿè´£å›æ”¶å­è¿›ç¨‹**ï¼š
  - **å›æ”¶åƒµå°¸è¿›ç¨‹**ï¼šå¦‚æœä¸šåŠ¡å®¹å™¨å†…éƒ¨çš„è¿›ç¨‹ (PID) ç»ˆæ­¢ï¼Œä¼šæˆä¸ºåƒµå°¸è¿›ç¨‹ï¼Œç³»ç»Ÿçš„ init è¿›ç¨‹é€šå¸¸è´Ÿè´£å›æ”¶åƒµå°¸è¿›ç¨‹ã€‚
  - åœ¨ Pod ä¸­ï¼Œ**pause å®¹å™¨å°±æ˜¯ Pod ä¸­çš„ "init è¿›ç¨‹"**ï¼Œè´Ÿè´£å›æ”¶ä¸šåŠ¡å®¹å™¨ä¸­çš„åƒµå°¸è¿›ç¨‹ã€‚
- **ç½‘ç»œæ ˆçš„åŸºç¡€**ï¼š
  - é€šè¿‡ pause å®¹å™¨çš„ç½‘ç»œå‘½åç©ºé—´ï¼ŒPod ä¸­çš„æ¯ä¸ªä¸šåŠ¡å®¹å™¨å…±äº«ä¸€ä¸ª IP åœ°å€å’Œç«¯å£ç©ºé—´ã€‚



**ğŸŸ¢podé€šä¿¡æœºåˆ¶**

- Podå†…å¤šå®¹å™¨é€šä¿¡ï¼šå®¹å™¨ä»¶é€šä¿¡ï¼ˆå®¹å™¨æ¨¡å‹ï¼‰å€ŸåŠ©äºpauseå®¹å™¨å®ç°
- å•èŠ‚ç‚¹å†…å¤šPodé€šä¿¡ï¼šä¸»æœºé—´å®¹å™¨é€šä¿¡ï¼ˆhostæ¨¡å‹ï¼‰ï¼Œåˆ©ç”¨kube-proxyå®ç°
- å¤šèŠ‚ç‚¹å†…å¤šPodé€šä¿¡ï¼šè·¨ä¸»æœºç½‘ç»œè§£å†³æ–¹æ¡ˆï¼ˆoverlayæ¨¡å‹ï¼‰ï¼Œåˆ©ç”¨ç½‘ç»œæ’ä»¶flannelï¼Œcalicoç­‰å®ç°



##### é™æ€Podå’ŒåŠ¨æ€Pod

åŸºäºæ§åˆ¶çš„ç‰¹æ€§Pod ä¸»è¦æœ‰ä¸¤ç±»ï¼š**é™æ€pod**å’Œ**åŠ¨æ€pod**

- åŠ¨æ€Pod

  - ä¹‹å‰åˆ›å»ºç®¡ç†çš„podéƒ½æ˜¯åŠ¨æ€podï¼Œä¹Ÿæ˜¯åº”ç”¨æœ€å¹¿æ³›çš„pod
  - åŠ¨æ€Pod ç›´æ¥è¢«é›†ç¾¤ä¸­çš„API Server è¿›è¡Œç®¡ç†

- é™æ€pod

  - ç”±ç‰¹å®šèŠ‚ç‚¹ä¸Šçš„kubeletè¿›ç¨‹æ¥ç®¡ç†,å¯¹äº**API Server åªèƒ½æŸ¥çœ‹ï¼Œè€Œä¸èƒ½ç®¡ç†**ã€‚

  - åœ¨æœ¬è´¨ä¸Šä¸åŠ¨æ€podæ²¡æœ‰åŒºåˆ«ï¼Œåªæ˜¯åœ¨äºé™æ€podåªèƒ½åœ¨ç‰¹å®šçš„èŠ‚ç‚¹ä¸Šè¿è¡Œ

  - kubelet é»˜è®¤ä¼šåŠ è½½**/etc/kubernetes/manifests/*.yaml** ä»è€Œç”Ÿæˆçš„é™æ€Pod

  - é™æ€podå®ç°æ–¹å¼ä¸»è¦æœ‰ä¸¤ç§ï¼š**é…ç½®æ–‡ä»¶**æˆ–è€…**httpæ–¹å¼**ã€‚

    - é…ç½®æ–‡ä»¶

      æ‰€è°“çš„é…ç½®æ–‡ä»¶çš„æ–¹å¼ï¼Œå…¶å®å°±æ˜¯åœ¨ç‰¹å®šçš„ç›®å½•ä¸‹å­˜æ”¾æˆ‘ä»¬å®šåˆ¶å¥½çš„èµ„æºå¯¹è±¡æ–‡ä»¶ï¼Œç„¶åèŠ‚ç‚¹ä¸Šçš„ kubeletæœåŠ¡å‘¨æœŸæ€§çš„æ£€æŸ¥è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰å†…å®¹ï¼Œå¯¹é™æ€podè¿›è¡Œå¢åˆ æ”¹æŸ¥ã€‚å…¶é…ç½®æ–¹å¼ä¸»è¦æœ‰ä¸¤ æ­¥ 

      1 å®šåˆ¶kubeletæœåŠ¡å®šæœŸæ£€æŸ¥é…ç½®ç›®å½• 

      2 å¢åˆ å®šåˆ¶èµ„æºæ–‡ä»¶ 

    - httpæ–¹å¼

      1 å‡†å¤‡httpæ–¹å¼æä¾›èµ„æºæ–‡ä»¶çš„webç«™ç‚¹ 

      2 å·¥ä½œèŠ‚ç‚¹çš„kubeleté…ç½®â€“manifest-url=<èµ„æºæ–‡ä»¶çš„urlä¸‹è½½åœ°å€>

  ```bash
  # æŸ¥æ‰¾é™æ€æ–‡ä»¶é…ç½®è·¯å¾„çš„è¿‡ç¨‹
  [root@master1 net.d]#systemctl status kubelet.service 
  â— kubelet.service - kubelet: The Kubernetes Node Agent
       Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
      Drop-In: /usr/lib/systemd/system/kubelet.service.d
               â””â”€10-kubeadm.conf
       Active: active (running) since Tue 2024-12-17 14:20:02 CST; 6h ago
         Docs: https://kubernetes.io/docs/
     Main PID: 815 (kubelet)
        Tasks: 13 (limit: 2196)
       Memory: 68.4M
          CPU: 3min 13ms
       CGroup: /system.slice/kubelet.service
               â””â”€815 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig
               
  # åŸºäºä¸Šè¿°çš„loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
  [root@master1 net.d]#cat /lib/systemd/system/kubelet.service.d/10-kubeadm.conf 
  # Note: This dropin only works with kubeadm and kubelet v1.11+
  [Service]
  Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
  Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"
  # This is a file that "kubeadm init" and "kubeadm join" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically
  EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
  # This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use
  # the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.
  EnvironmentFile=-/etc/default/kubelet
  ExecStart=
  ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS
  
  # æ‰¾åˆ°Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"è¿™æ ·ï¼Œè¯´æ˜kubeletçš„é…ç½®å‚æ•°ä¸»è¦æ˜¯åœ¨/var/lib/kubelet/config.yamlæ–‡ä»¶ä¸­å®šä¹‰
  
  [root@master1 net.d]#cat /var/lib/kubelet/config.yaml|grep static
  staticPodPath: /etc/kubernetes/manifests
  
  # è¿™ä¸ªå°±æ˜¯é™æ€podçš„ä¸“ç”¨ç›®å½•
  
  ```



#### Podç®¡ç†æœºåˆ¶

![image-20241217210820679](../markdown_img/image-20241217210820679.png)



#### Podåˆ›å»ºæµç¨‹

å®¢æˆ·ç«¯ä½¿ç”¨kubectlåˆ›å»ºpodï¼Œéœ€è¦å…ˆé€šçŸ¥API Serverï¼Œè€Œkubectlèƒ½é€šçŸ¥API Serveræ˜¯å› ä¸ºé…ç½®ä¸­ï¼Œè®°å½•äº†API Serverçš„åœ°å€

```bash
[root@master1 .kube]#grep server ~/.kube/config 
    server: https://master1.mystical.org:6443
    
# hostä¸­è®°å½•äº†master1.mystical.orgå¯¹åº”çš„ip
[root@master1 .kube]#cat /etc/hosts
127.0.0.1 localhost
127.0.1.1 ubuntu2204

# The following lines are desirable for IPv6 capable hosts
::1     ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

10.0.0.201 master1 master1.mystical.org
10.0.0.202 node1 node1.mystical.org
10.0.0.203 node2 node2.mystical.org
10.0.0.204 node3 node3.mystical.org

```

##### ğŸŒ **1. å…¥å£ï¼škubectl å‘½ä»¤çš„å‘èµ·**

**å‘½ä»¤ç¤ºä¾‹**ï¼š

```bash
kubectl run nginx --image=nginx --replicas=1
```

**æ“ä½œè¿‡ç¨‹**

1. kubectl å‘èµ·è¯·æ±‚ï¼š

   - kubectl å°†è¯·æ±‚æ‰“åŒ…ä¸ºä¸€ä¸ª **HTTP REST è¯·æ±‚**ï¼Œå¹¶å‘é€åˆ° **Kubernetes API Server**ã€‚
   - é€šè¿‡ `kubectl` å‘½ä»¤ï¼ŒAPI Server æ¥æ”¶åˆ°**POSTè¯·æ±‚**ï¼Œå…¶ä¸­åŒ…å«äº† **Podçš„å®šä¹‰ä¿¡æ¯**ï¼ˆYAML/JSON æ ¼å¼çš„PodManifestï¼‰ã€‚

   

##### ğŸ“¡ **2. API Server å¤„ç†è¯·æ±‚**

**API Serverçš„ä½œç”¨**ï¼š

1. éªŒè¯è¯·æ±‚ï¼š

   - è¿›è¡Œèº«ä»½éªŒè¯ï¼ˆAuthenticationï¼‰å’Œæƒé™éªŒè¯ï¼ˆAuthorizationï¼‰ã€‚
   - ä¾‹å¦‚ï¼Œæ£€æŸ¥è¯·æ±‚çš„ç”¨æˆ·æ˜¯å¦å…·æœ‰åˆ›å»ºPodçš„æƒé™ã€‚

   

2. è¯·æ±‚åˆæ³•æ€§æ ¡éªŒï¼š

   - é€šè¿‡ **Admission Controllers** è¿›è¡Œä¸€ç³»åˆ—çš„è§„åˆ™æ£€æŸ¥ï¼ˆæ¯”å¦‚èµ„æºé…é¢ã€Podè°ƒåº¦é™åˆ¶ç­‰ï¼‰ã€‚
   - Admission Controller å¯ä»¥æ‹’ç»ä¸ç¬¦åˆè§„èŒƒçš„Podã€‚

   

3. å¯¹è±¡åºåˆ—åŒ–å’ŒæŒä¹…åŒ–ï¼š

   - æ£€æŸ¥è¯·æ±‚çš„YAML/JSONå®šä¹‰æ˜¯å¦ç¬¦åˆ **Pod Schema**ã€‚
   - å¦‚æœæ£€æŸ¥é€šè¿‡ï¼Œå°†å…¶å­˜å‚¨åˆ° **etcd** ä¸­ã€‚
   - é€šè¿‡ `apiserver` çš„ **etcd client** å°†Podä¿¡æ¯åºåˆ—åŒ–ä¸ºäºŒè¿›åˆ¶æ•°æ®ï¼Œå¹¶å­˜å‚¨åˆ°etcdçš„**å­˜å‚¨è·¯å¾„** `/registry/pods/{namespace}/{pod-name}` ä¸­ã€‚

   

##### ğŸ“¦ **3. etcd å­˜å‚¨ Pod å®šä¹‰**

**etcdçš„ä½œç”¨**ï¼š

1. æ•°æ®å­˜å‚¨ï¼š
   - etcd å­˜å‚¨çš„æ˜¯**å®Œæ•´çš„Podçš„å®šä¹‰**ï¼Œå¦‚é•œåƒã€CPU/å†…å­˜é…é¢ã€ç¯å¢ƒå˜é‡ç­‰ã€‚
   - etcd æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼çš„é”®å€¼å­˜å‚¨ï¼Œæ‰€æœ‰çš„K8sèµ„æºï¼ˆPodã€Serviceã€ConfigMapï¼‰éƒ½ä»¥è·¯å¾„çš„å½¢å¼å­˜å‚¨ã€‚
2. æ•°æ®å˜æ›´è§¦å‘é€šçŸ¥ï¼š
   - etcd ä½œä¸ºä¸€ä¸ª**å‘å¸ƒ/è®¢é˜…ç³»ç»Ÿ**ï¼Œä¸€æ—¦æ–°çš„Podå®šä¹‰è¢«å­˜å‚¨ï¼Œæ‰€æœ‰ç›‘å¬è¯¥è·¯å¾„çš„æ§åˆ¶å™¨ï¼ˆå¦‚**Controller-Manager** å’Œ **Scheduler**ï¼‰éƒ½ä¼šè¢«**Watchäº‹ä»¶**è§¦å‘ã€‚



##### âš™ï¸ **4. Scheduler è°ƒåº¦ Pod**

**Schedulerçš„ä½œç”¨**ï¼š

1. **ç›‘å¬Podçš„å˜æ›´**ï¼š
   - Scheduler ç›‘å¬ `/registry/pods/` ç›®å½•çš„å˜æ›´ã€‚
   - ç›‘å¬åˆ°ä¸€ä¸ª**æœªç»‘å®šNodeçš„Pod**ï¼Œå³ `.spec.nodeName == null`ï¼Œåˆ™å¯åŠ¨è°ƒåº¦ã€‚
2. **è°ƒåº¦å†³ç­–**ï¼š
   - Scheduler ä¼šä»æ‰€æœ‰**å¯ç”¨çš„Nodeä¸­é€‰æ‹©ä¸€ä¸ªæœ€ä¼˜çš„Node**æ¥è¿è¡Œè¿™ä¸ªPodã€‚
   - Schedulerä¼šè€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š
     - **èµ„æºçº¦æŸ**ï¼šNodeçš„CPUã€å†…å­˜æ˜¯å¦è¶³å¤Ÿã€‚
     - **äº²å’Œæ€§/åäº²å’Œæ€§**ï¼šPodçš„äº²å’Œæ€§å’Œåäº²å’Œæ€§è§„åˆ™ã€‚
     - **æ±¡ç‚¹å’Œå®¹å¿åº¦**ï¼šèŠ‚ç‚¹ä¸Šæ˜¯å¦æœ‰æ±¡ç‚¹ã€‚
     - **èŠ‚ç‚¹å¥åº·çŠ¶æ€**ï¼šèŠ‚ç‚¹æ˜¯å¦Readyã€‚
3. **å†™å›è°ƒåº¦ç»“æœ**ï¼š
   - Scheduler å°†è°ƒåº¦çš„ç»“æœï¼ˆ`spec.nodeName: node01`ï¼‰å›å†™åˆ° etcdï¼Œé€šçŸ¥API Serverã€‚



##### ğŸ”„ **5. Kubelet ç›‘æ§ Pod å˜æ›´**

**Kubeletçš„ä½œç”¨**ï¼š

1. **ç›‘å¬ API Server çš„äº‹ä»¶**ï¼š
   - Kubelet ç›‘å¬ `/registry/pods/{namespace}/{pod-name}` ç›®å½•çš„å˜æ›´ã€‚
   - ä¸€æ—¦æœ‰å˜æ›´ï¼ŒKubeletä¼šå‘ç°è‡ªå·±éœ€è¦åœ¨æœ¬èŠ‚ç‚¹ä¸Š**æ‹‰å–ä¸€ä¸ªæ–°çš„Pod**ã€‚
2. **åˆ›å»ºPodæ²™ç®±ï¼ˆPauseå®¹å™¨ï¼‰**ï¼š
   - Kubelet ä½¿ç”¨ **container runtime (Docker/Containerd/CRI-O)** åˆ›å»ºä¸€ä¸ª**pauseå®¹å™¨**ã€‚
   - pause å®¹å™¨çš„ä½œç”¨ï¼š
     - **ç½‘ç»œå‘½åç©ºé—´**ï¼šå…¶ä»–å®¹å™¨ä¼šå’Œpauseå®¹å™¨å…±äº«ç½‘ç»œå‘½åç©ºé—´ã€‚
     - **PIDå‘½åç©ºé—´**ï¼šå…±äº«è¿›ç¨‹å‘½åç©ºé—´ã€‚
     - **æ•°æ®å·ç®¡ç†**ï¼šæŒ‚è½½Podå®šä¹‰çš„å·åˆ°pauseå®¹å™¨ä¸Šï¼Œå…¶ä»–å®¹å™¨å…±äº«ã€‚
3. **åˆ›å»ºPodä¸­çš„ä¸šåŠ¡å®¹å™¨**ï¼š
   - **container runtime** æ‹‰å–é•œåƒï¼ˆå¦‚ nginx:latestï¼‰ï¼Œå¹¶åœ¨ pause å®¹å™¨çš„**ç½‘ç»œå’ŒPIDå‘½åç©ºé—´ä¸­è¿è¡Œä¸šåŠ¡å®¹å™¨**ã€‚
   - è¿™ä¸ªè¿‡ç¨‹åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
     - **æ‹‰å–é•œåƒ**ï¼šä»**é•œåƒä»“åº“**ä¸­æ‹‰å–é•œåƒï¼ˆdocker hubã€Harborç­‰ï¼‰ã€‚
     - **è§£å‹é•œåƒ**ï¼šè§£å‹ tar æ–‡ä»¶ï¼ŒåŠ è½½å®¹å™¨æ–‡ä»¶ç³»ç»Ÿã€‚
     - **å¯åŠ¨å®¹å™¨**ï¼šè°ƒç”¨ `runc` å¯åŠ¨å®¹å™¨ï¼Œå’Œ pause å®¹å™¨å…±äº«å‘½åç©ºé—´ã€‚



##### ğŸ“Š **6. å®¹å™¨çŠ¶æ€åŒæ­¥å› API Server**

**Kubeletçš„åé¦ˆæœºåˆ¶**ï¼š

1. **Kubelet æ±‡æŠ¥PodçŠ¶æ€**ï¼š
   - Pod å¯åŠ¨å®Œæˆåï¼ŒKubelet ä¼šå°†Podçš„çŠ¶æ€åŒæ­¥å›API Serverã€‚
   - API Serverå°†è¿™äº›çŠ¶æ€å†™å…¥ etcdï¼ŒçŠ¶æ€è·¯å¾„æ˜¯ `/registry/pods/{namespace}/{pod-name}`ã€‚
   - ç”¨æˆ·å¯ä»¥é€šè¿‡ `kubectl get pods` æŸ¥çœ‹Podçš„çŠ¶æ€ã€‚
2. **å®¹å™¨å¥åº·æ£€æŸ¥å’ŒLiveness Probe**ï¼š
   - Kubelet å®šæœŸæ£€æŸ¥Podçš„å¥åº·çŠ¶æ€ã€‚
   - å¦‚æœå®¹å™¨çš„Liveness Probeå¤±è´¥ï¼ŒKubeletä¼š**é‡å¯å®¹å™¨**ã€‚



##### æµç¨‹å›¾ï¼ˆå¯è§†åŒ–ç†è§£ï¼‰

```scss
       kubectl run 
           â”‚
           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  API Server     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  (èº«ä»½éªŒè¯ã€è¯·æ±‚éªŒè¯)
           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  etcd å­˜å‚¨      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
   (é€šçŸ¥)  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â””â”€â–¶â”‚ Scheduler è°ƒåº¦  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
               é€‰æ‹©æœ€ä½³èŠ‚ç‚¹
                      â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ etcd å­˜å‚¨ â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
               (ç›‘å¬é€šçŸ¥)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    Kubelet      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      (åœ¨èŠ‚ç‚¹ä¸Šå¯åŠ¨Pod)

```



##### ğŸš€ **é¢è¯•å›ç­”ç¤ºä¾‹**

> **é¢è¯•å®˜é—®**ï¼šKubernetes Pod æ˜¯å¦‚ä½•åˆ›å»ºçš„ï¼Ÿ **å›ç­”æ€è·¯**ï¼š

1. **kubectl run** å°†YAML/JSONè¯·æ±‚å‘åˆ° **API Server**ã€‚
2. **API Server** éªŒè¯è¯·æ±‚ï¼Œå°†Podå®šä¹‰å†™å…¥ **etcd**ã€‚
3. **Scheduler** ç›‘å¬åˆ°**etcdå˜æ›´**ï¼Œè°ƒåº¦Podåˆ°**æœ€ä½³Node**ã€‚
4. **Kubelet** ç›‘å¬åˆ°Podå®šä¹‰ï¼Œå¯åŠ¨**Pauseå®¹å™¨å’Œä¸šåŠ¡å®¹å™¨**ã€‚
5. **Kubelet** åé¦ˆPodçŠ¶æ€ï¼Œç”¨æˆ·å¯é€šè¿‡ `kubectl get pods` æŸ¥çœ‹çŠ¶æ€ã€‚



##### æ³¨æ„äº‹é¡¹

1. **etcd ç›‘å¬ API Server**ï¼š
   å½“ç”¨æˆ·é€šè¿‡ `kubectl` åˆ›å»ºã€æ›´æ–°æˆ–åˆ é™¤ Pod èµ„æºæ—¶ï¼Œè¿™äº›æ›´æ”¹ä¼šå­˜å‚¨åˆ° **etcd**ã€‚
2. **API Server ç›‘å¬ etcd**ï¼š
   **API Server ç›‘å¬ etcd ä¸­çš„å˜åŒ–**ï¼Œå¹¶å°†å˜åŒ–é€šçŸ¥ Kubelet å’Œ Controller Managerã€‚
3. **Kubelet ç›‘å¬ API Server**ï¼š
   Kubelet é€šè¿‡ Watch API ä» API Server è·å–å…¶æ‰€åœ¨ Node ä¸Šçš„ Pod åˆ—è¡¨ï¼Œå¹¶åœ¨æœ¬åœ°å¯åŠ¨æˆ–ç»ˆæ­¢ç›¸åº”çš„ Podã€‚

> ğŸ“ **Kubelet åªèƒ½é€šè¿‡ API Server æ¥ä¸ etcd é—´æ¥é€šä¿¡**ã€‚
> è¿™æ˜¯ä¸ºäº†ç¡®ä¿æ‰€æœ‰æ•°æ®çš„æ“ä½œéƒ½ç”± API Server ç»Ÿä¸€æ§åˆ¶å’ŒéªŒè¯ã€‚





##### Podåˆ›å»ºæµç¨‹è‡ªè¿°ï¼ˆé¢è¯•å¿…èƒŒï¼‰



- å½“ä½¿ç”¨ `kubectl apply -f pod.yaml` æ—¶ï¼Œkubectl ä¼šå°† YAML æ–‡ä»¶ä¸­çš„**Kubernetes èµ„æºå¯¹è±¡**ï¼ˆPodï¼‰è½¬æ¢ä¸º**JSON æ ¼å¼çš„è¯·æ±‚ä½“**ï¼Œå¹¶é€šè¿‡ **HTTP POST** å‘é€åˆ° API Server
  - **kubectl ä½œä¸ºå®¢æˆ·ç«¯**ï¼Œä¼šå°† YAML æ–‡ä»¶è½¬æ¢ä¸º**RESTful API è¯·æ±‚**ï¼ŒAPI Server å……å½“**æœåŠ¡ç«¯**ã€‚
  - ä½¿ç”¨çš„æ˜¯ **HTTP/2**ï¼Œå¹¶ä¸”éœ€è¦èº«ä»½è®¤è¯å’Œæƒé™æ§åˆ¶ï¼ˆRBACï¼‰ã€‚
  - API Server ä¼š**å…ˆå°† Pod èµ„æºä¿å­˜åœ¨å†…å­˜ä¸­ï¼ˆWatch Cacheï¼‰**ï¼Œå¹¶å¼‚æ­¥å†™å…¥ etcdã€‚



- API Serveré€šè¿‡gRPCä¸etcdé€šä¿¡ï¼Œå°†Podçš„æ•°æ®æŒä¹…åŒ–åˆ°etcdï¼Œ**æ­¤æ—¶Podçš„çŠ¶æ€æ˜¯Pending**ï¼Œå› ä¸ºæ­¤æ—¶Podè¿˜æœªè¢«è°ƒåº¦åˆ°æŸä¸ªèŠ‚ç‚¹



- Scheduler é€šè¿‡ **watch æœºåˆ¶ç›‘å¬ API Server ä¸­çš„ Pending Pods**ã€‚å¹¶é€šè¿‡é¢„é€‰è¿‡æ»¤ï¼Œä¼˜é€‰æ‰“åˆ†ï¼Œé€‰æ‹©å‡ºæœ€é€‚åˆçš„èŠ‚ç‚¹ï¼Œå¹¶å°†Podé€šè¿‡POSTè¯·æ±‚bindingåˆ°è¿™ä¸ªç›®æ ‡èŠ‚ç‚¹ä¸Š



- API Server å°† Pod çš„çŠ¶æ€ä» `Pending` å˜ä¸º `Scheduled`ã€‚å¹¶ä½¿ç”¨**PUT è¯·æ±‚** æ›´æ–° Pod çš„çŠ¶æ€ï¼Œå¹¶åŒæ­¥åˆ° etcdã€‚åŒæ—¶**API Server é€šè¿‡ Watch æœºåˆ¶å°† Pod å˜æ›´äº‹ä»¶æ¨é€ç»™ Kubelet**ã€‚



- Kubelet æ”¶åˆ° API Server å‘é€çš„ Pod æ•°æ®åï¼ŒKubelet ä½¿ç”¨**CRIï¼ˆContainer Runtime Interfaceï¼‰è°ƒç”¨ containerd**ã€‚containerd è°ƒç”¨**runc**ï¼Œåˆ›å»º Pod çš„ Linux å®¹å™¨ã€‚Pod è¿›å…¥**Running**çŠ¶æ€ã€‚



#### å„éƒ¨åˆ†è§’è‰² & é€šä¿¡æ–¹å¼è¯´æ˜ï¼š

| ç»„ä»¶                   | ä¸è°é€šä¿¡                     | æ˜¯å®¢æˆ·ç«¯è¿˜æ˜¯æœåŠ¡ç«¯ | ä½¿ç”¨åè®®        | è¯´æ˜                                                         |
| ---------------------- | ---------------------------- | ------------------ | --------------- | ------------------------------------------------------------ |
| **scheduler**          | API Server                   | å®¢æˆ·ç«¯             | HTTP/HTTPS REST | ä½¿ç”¨ API Server æä¾›çš„ `/api/v1/pods` æ¥å£                   |
| **controller-manager** | API Server                   | å®¢æˆ·ç«¯             | HTTP/HTTPS REST | é€šè¿‡ `Watch` æˆ– `List` + `Patch` ç­‰æ–¹æ³•                      |
| **API Server**         | scheduler/controller-manager | æœåŠ¡ç«¯             | HTTP/HTTPS REST | æä¾›ç»Ÿä¸€çš„å…¥å£                                               |
| **API Server**         | etcd                         | å®¢æˆ·ç«¯             | **gRPC**        | é€šè¿‡ [etcd client-go](https://github.com/etcd-io/etcd/tree/main/client/v3) ä¸ etcd é€šä¿¡ |
| **etcd**               | API Server                   | æœåŠ¡ç«¯             | gRPC            | åªå’Œ apiserver é€šä¿¡ï¼Œå…¶ä»–ç»„ä»¶æ— ç›´æ¥æƒé™è®¿é—®                  |



#### Podçš„çŠ¶æ€è¯¦è§£

- **Pending**

  ```bash
  # Pod è¿˜æ²¡æœ‰å®Œå…¨å‡†å¤‡å¥½è¿è¡Œã€‚åŒ…æ‹¬è¿˜æ²¡è¢«è°ƒåº¦ï¼Œæˆ–è°ƒåº¦äº†ä½†å®¹å™¨é•œåƒè¿˜åœ¨æ‹‰å–ç­‰
  # æ€»ç»“èµ·æ¥å°±æ˜¯é•œåƒæ‹‰å–æˆåŠŸå‰çš„çŠ¶æ€
  
  # æ˜¾ç¤ºä½ç½®
  kubectl get pod çš„ statusåˆ—
  
  # å¸¸è§è§¦å‘åŸå› 
  èµ„æºä¸è¶³ã€PVC æœªç»‘å®šã€è°ƒåº¦å™¨è¿˜æ²¡é€‰ä¸­èŠ‚ç‚¹ç­‰
  ```

  - **Unschedulable**

    ```bash
    # æ˜¯ Pending çš„ä¸€ç§ç»†åŒ–åŸå› ï¼Œè¯´æ˜ è°ƒåº¦å™¨å°è¯•è¿‡è°ƒåº¦ä½†å¤±è´¥
    # å±äº Pending çš„å­çŠ¶æ€
    
    # æ˜¾ç¤ºä½ç½®
    æ˜¾ç¤ºåœ¨ kubectl describe pod çš„ Events ä¸­
    
    # å¸¸è§è§¦å‘åŸå› 
    èŠ‚ç‚¹æ²¡æ»¡è¶³æ¡ä»¶ï¼ˆèµ„æºä¸è¶³ã€äº²å’Œæ€§ä¸æ»¡è¶³ã€Taints/Tolerations ä¸åŒ¹é…ï¼‰ç­‰
    ```

  - **PodScheduled**

    ```bash
    # PodScheduled æ˜¯ Pending çŠ¶æ€ä¸‹çš„ä¸€ä¸ªå­æ¡ä»¶ï¼ˆConditionï¼‰
    # ä¸¾ä¸ªä¾‹å­ï¼škubectl get pod -o yaml é‡Œçš„çŠ¶æ€
    status:
      phase: Pending
      conditions:
      - type: PodScheduled
        status: "True"
        lastProbeTime: null
        lastTransitionTime: "2025-04-16T03:11:12Z"
      - type: Initialized
        status: "True"
      - type: ContainersReady
        status: "False"
      - type: Ready
        status: "False"
    
    # PodScheduled çš„å«ä¹‰ï¼šè¡¨ç¤ºè°ƒåº¦å™¨æ˜¯å¦å·²æˆåŠŸå°† Pod åˆ†é…ç»™æŸä¸ªèŠ‚ç‚¹
    # Pod å¤„äº Pending çŠ¶æ€æ—¶ï¼Œå¦‚æœ PodScheduled=Trueï¼Œè¯´æ˜è°ƒåº¦å·²ç»å®Œæˆï¼›
    # å¦‚æœ PodScheduled=False ä¸” Reason=Unschedulableï¼Œé‚£å°±æ˜¯è°ƒåº¦å™¨è¿˜æ²¡æ‰¾åˆ°åˆé€‚èŠ‚ç‚¹ï¼Œå¡åœ¨è°ƒåº¦è¿™ä¸€æ­¥ã€‚
    ```

    

- **Unknown/NotReady**

  ```bash
  # å¦‚æœ kubelet å¼‚å¸¸æˆ–æ— æ³•æ±‡æŠ¥,å½“ kubelet æ— æ³•ä¸ API Server é€šä¿¡ï¼ˆä¾‹å¦‚ kubelet å´©æºƒã€èŠ‚ç‚¹å®•æœºã€ç½‘ç»œæ–­å¼€ç­‰ï¼‰
  1. èŠ‚ç‚¹çš„çŠ¶æ€ NodeStatus å°†åœ¨ä¸€æ®µæ—¶é—´ï¼ˆé»˜è®¤ 40 ç§’ï¼‰åè¢«æ ‡è®°ä¸º: NotReady
  
  2. èŠ‚ç‚¹ä¸Šæ‰€æœ‰çš„ Pod çŠ¶æ€ å°†æ˜¾ç¤ºä¸º: Unknow
  
  # è¯¦è§£ï¼š
  ## Kubelet ä¼šå‘¨æœŸæ€§åœ°å‘ API Server æŠ¥å‘Šï¼š
  å½“å‰èŠ‚ç‚¹çš„çŠ¶æ€ï¼ˆNodeStatusï¼‰
  æ¯ä¸ª Pod çš„çŠ¶æ€ï¼ˆPodStatusï¼‰
  
  ## node-controllerï¼ˆè¿è¡Œåœ¨ controller-manager ä¸­ï¼‰è´Ÿè´£æ£€æµ‹ kubelet æ˜¯å¦å¤±è”
  å¦‚æœ å¿ƒè·³ï¼ˆnode statusï¼‰åœ¨ --node-monitor-grace-periodï¼ˆé»˜è®¤ 40sï¼‰å†…æ²¡æ›´æ–°ï¼Œä¼šè®¤ä¸º kubelet å¼‚å¸¸ï¼Œå¹¶è®¾ç½®
  Node ä¸º NotReady
  Pod çŠ¶æ€ä¸º Unknown
  
  ## å…³é”®å‚æ•°ï¼ˆå¯ä»¥åœ¨ controller-manager é‡Œé…ç½®ï¼‰ï¼š
  
  å‚æ•°å	                         è¯´æ˜	                                   é»˜è®¤å€¼
  --node-monitor-grace-period	   å¤šä¹…æ²¡æ”¶åˆ° kubelet å¿ƒè·³å°±è®¤ä¸ºå®ƒâ€œæ‰çº¿â€	      40s
  --pod-eviction-timeout	       å¤±è”èŠ‚ç‚¹ä¸Šçš„ Pod è¢«é©±é€å‰çš„ç­‰å¾…æ—¶é—´	         5m
  ```



- **Failed**

  ```bash
  # Failed æ˜¯ Pod çš„ä¸€ç§ç»ˆæ€ï¼ˆTerminal Phaseï¼‰
  # Failed è¡¨ç¤ºå·²ç»è¿è¡Œè¿‡äº†ï¼Œä½† å¤±è´¥é€€å‡ºäº†ï¼Œæ˜¯ä¸€ä¸ªç»ˆç‚¹çŠ¶æ€ã€‚
  
  # ä¸¾ä¸ªä¾‹å­å¸®åŠ©ç†è§£
  kubectl get pod mypod -o wide
  å¦‚æœçŠ¶æ€æ˜¯ Failedï¼Œè¯´æ˜ï¼š
  - Pod æ›¾ç»æˆåŠŸè°ƒåº¦åˆ°äº†èŠ‚ç‚¹ã€‚
  - è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨è¿è¡Œè¿‡ã€‚
  - åæ¥å› ä¸º é 0 é€€å‡ºç  æˆ– CrashLoopBackOff æœ€åå¤±è´¥ è¢«æ ‡è®°ä¸ºå¤±è´¥ã€‚
  ```

  

- **CrashLoopBackOff**

  ```bash
  # å®ƒæ˜¯ä¸€ç§ å®¹å™¨çº§åˆ«çš„çŠ¶æ€ï¼Œå‡ºç°åœ¨ Pod çš„å®¹å™¨å› ä¸ºå´©æºƒè€Œä¸æ–­é‡å¯æ—¶
  # å®ƒä¸æ˜¯ status.phase çš„ä¸€ç§ï¼Œè€Œæ˜¯ containerStatuses.state.waiting.reason
  # ç¤ºä¾‹
  state:
    waiting:
      reason: CrashLoopBackOff
  
  # é‡å¯æ¬¡æ•°å’Œå¤±è´¥çŠ¶æ€ä¹‹é—´çš„å…³ç³»è¯¦è§£
  1. é»˜è®¤æƒ…å†µä¸‹ï¼ŒKubernetes ä¼šæ ¹æ® Pod çš„ restartPolicy æ¥å†³å®šæ˜¯å¦é‡å¯å®¹å™¨ã€‚
  - Alwaysï¼ˆé»˜è®¤ï¼‰ï¼šä¸ç®¡å¤±è´¥å¤šå°‘æ¬¡ï¼Œéƒ½ä¼šå°è¯•é‡å¯ã€‚
  - OnFailureï¼šä»…åœ¨é 0 é€€å‡ºæ—¶é‡å¯
  	- ç¤ºä¾‹ï¼šå¦‚æœå®¹å™¨ä¸»è¿›ç¨‹æ˜¯ sleep 10ï¼›10 ç§’åè‡ªç„¶é€€å‡ºï¼Œé€€å‡ºç  0ï¼ŒOnFailure ä¸ä¼šé‡å¯ã€‚
  - Neverï¼šä¸ç®¡é€€å‡ºç å¦‚ä½•ï¼Œéƒ½ä¸ä¼šé‡å¯ã€‚
  
  2. CrashLoopBackOff æ˜¯å¸¦æœ‰æŒ‡æ•°é€€é¿çš„é‡å¯æœºåˆ¶
  - é¦–æ¬¡å¤±è´¥åä¼šé©¬ä¸Šé‡å¯
  - å¤±è´¥å¤šæ¬¡åï¼Œæ¯æ¬¡é‡å¯çš„é—´éš”æ—¶é—´è¶Šæ¥è¶Šé•¿ï¼ˆæœ€å¤§çº¦ä¸º 5 åˆ†é’Ÿï¼‰ã€‚
  
  3. å®ƒä¸ä¼šè‡ªè¡Œè½¬æ¢æˆ Pod çš„ Failed çŠ¶æ€ï¼Œé™¤é restartPolicy: Never/OnFailure ä¸”å¤±è´¥äº†ã€‚
  
  # å¯ä»¥æ§åˆ¶äººä¸ºæ§åˆ¶é‡å¯æ¬¡æ•°ï¼Œå¦åˆ™ä¼šä¸æ–­é‡å¯
  1. å¯¹äº Job
  spec:
    backoffLimit: 3   # Job çš„ Pod é‡å¯å¤±è´¥ 3 æ¬¡åå°± Failed
  
  2. å¯¹äºå®¹å™¨æµ‹è¯•
  å¯ä»¥ä½¿ç”¨ liveness probe è®©å®ƒå¤±è´¥å‡ æ¬¡åè¢«æ ‡è®°ä¸ºä¸å¥åº·ï¼Œä½†è¿™ä¸å½±å“ CrashLoopBackOff æœ¬èº«
  ```



- **ImagePullBackOff**
  - Podæ‰€åœ¨nodeèŠ‚ç‚¹ä¸‹è½½é•œåƒå¤±è´¥

- **Terminating**

  - Podæ­£åœ¨è¢«é”€æ¯

  

#### Podçš„ç”Ÿå‘½å‘¨æœŸ



![image-20241218091558622](../markdown_img/image-20241218091558622.png)



- åˆ›å»ºæŒ‡ä»¤é€åˆ°apiserver
- é€šçŸ¥Scheduleè°ƒåº¦æ­¤è¯·æ±‚åˆ°åˆé€‚çš„èŠ‚ç‚¹
- **initå®¹å™¨**
  - åˆå§‹åŒ–å®¹å™¨ï¼ˆä¸€æ¬¡æ€§å®¹å™¨ï¼Œåˆå§‹åŒ–ç»“æŸï¼Œè¯¥å®¹å™¨å°±é€€å‡ºäº†ï¼‰ï¼Œç‹¬ç«‹äºä¸»å®¹å™¨ä¹‹å¤–ï¼Œå³å’Œä¸»å®¹å™¨æ˜¯éš”ç¦»çš„
  - Podå¯ä»¥æ‹¥æœ‰ä»»æ„æ•°é‡çš„initå®¹å™¨ï¼Œinité¡ºåºæ‰§è¡Œï¼Œæœ€åä¸€ä¸ªæ‰§è¡Œå®Œæˆåï¼Œæ‰å¯åŠ¨ä¸»å®¹å™¨
  - initå®¹å™¨ä¸æ”¯æŒæ¢é’ˆæ£€æµ‹åŠŸèƒ½
    - å®ƒä¸»è¦æ˜¯ä¸ºäº†ä¸»å®¹å™¨å‡†å¤‡è¿è¡Œç¯å¢ƒçš„åŠŸèƒ½ï¼Œæ¯”å¦‚ï¼šç»™ä¸»å®¹å™¨å‡†å¤‡é…ç½®æ–‡ä»¶ï¼Œå‘ä¸»å®¹å™¨çš„å­˜å‚¨å†™å…¥æ•°æ®ï¼Œç„¶åå°†å­˜å‚¨å·æŒ‚è½½åˆ°ä¸»å®¹å™¨ä¸Šï¼Œä¸‹è½½ç›¸å…³èµ„æºï¼Œç›‘æµ‹ä¸»å®¹å™¨ä¾èµ–æœåŠ¡ç­‰
  
  ```yaml
  # init containerç¤ºä¾‹
  ......
  spec:
    containers:
      - name: myserver-myapp-container
        image: nginx:1.20.0
        # imagePullPolicy: Always
        volumeMounts:
        - mountPath: "/usr/share/nginx/html/myserver"
          name: myserver-data
        - name: tz-config
          mountPath: "/etc/localtime"
    initContainers:
      - name: init-web-data
        image: centos:7.9.2009
        command: ['/bin/bash','-c',"for i in `seq 1 10`;do echo '<h1>'$1 web page at $(date +%Y%m%d%H%M%S) '</h1>' >> /data/nginx/html/myserver/index.html; sleep 1; done"]
        volumeMounts:
        - mountPath: "/data/nginx/html/myserver"
          name: server-data
        - name: tz-config
          mountPath: "/etc/localtime"
      - name: change-data-owner
        image: busybox:1.28
        command: ['/bin/sh','-c',"/bin/chmod 644 /data/nginx/html/myserver/* -R"]
        volumeMounts:
        - mountPath: "/data/nginx/html/myserver"
          name: myserver-data
        - name: tz-config
          mountPath: "/etc/localtime"
    volumes:
    - name: myserver-data
      hostPath:
        path: /tmp/data/html
    - name: tz-config
      hostPath:
        path: /etc/localtime
  ```
- **å¯åŠ¨åé’©å­PostStartï¼ˆPost Start Hookï¼‰**: ä¸ä¸»å®¹å™¨åŒæ—¶å¯åŠ¨
- çŠ¶æ€ç›‘æµ‹
- **Startup probeï¼šå¯åŠ¨æ¢é’ˆ**ï¼šå¯åŠ¨æ¢é’ˆç”¨æ¥æ¢æµ‹è¿™ä¸ªæœåŠ¡æ˜¯å¦èµ·æ¥çš„ï¼Œå¦‚æœæ¢é’ˆæ£€æŸ¥å¤±è´¥ï¼Œä¼šè®¤ä¸ºè¯¥å®¹å™¨ä¸å¥åº·ï¼Œå› æ­¤ä¼šé‡æ–°å¯åŠ¨å®¹å™¨ï¼Œå¦‚æœå¥åº·ï¼Œå°±ä¼šè¿›å…¥ä¸‹ä¸€æ­¥
  - å¯åŠ¨æ¢é’ˆåªæ£€æµ‹å®¹å™¨æ˜¯å¦å¯åŠ¨ï¼Œå®¹å™¨å¯åŠ¨åï¼Œåç»­ä¸å†æ£€æŸ¥
  
  ```ABAP
  Startup Probe æ˜¯ä¸ºäº†è§£å†³å®¹å™¨â€œå¯åŠ¨ç‰¹åˆ«æ…¢â€æ—¶è¢«è¯¯æ€çš„é—®é¢˜ã€‚
  ```
  
  - **å®é™…åº”ç”¨åœºæ™¯**
  
    - åœºæ™¯ 1ï¼šå¤§å‹ Java åº”ç”¨å®¹å™¨ï¼ˆSpringBootï¼‰
  
      ```yaml
      startupProbe:
        httpGet:
          path: /healthz
          port: 8080
        failureThreshold: 30
        periodSeconds: 10
      ```
  
      - æŸäº› SpringBoot æœåŠ¡å¯èƒ½éœ€è¦ 3~5 åˆ†é’Ÿæ‰èƒ½å¯åŠ¨ï¼›
      - è‹¥ä½¿ç”¨ `livenessProbe` é»˜è®¤å‚æ•°ï¼ˆå¤±è´¥3æ¬¡ï¼Œé—´éš”10sï¼‰ï¼Œ30ç§’å†…ä¸å“åº”å°±ä¼šè¢«é‡å¯ï¼›
      - è€Œ `startupProbe` è®¾ç½®ä¸ºæœ€å¤šå¤±è´¥ 30 æ¬¡ï¼Œæ¯æ¬¡é—´éš” 10 ç§’ï¼Œæ€»å…± **æœ€å¤šç­‰ 5 åˆ†é’Ÿ**
      - ä¸€æ—¦ `/healthz` è¿”å› 200ï¼Œå°±è¿›å…¥å°±ç»ªé˜¶æ®µï¼Œæ‰å¯ç”¨ livenessProbeã€‚
  
  - **ä»€ä¹ˆæ—¶å€™åº”è¯¥ä½¿ç”¨ `startupProbe`**
  
    | é€‚ç”¨åœºæ™¯                                    | æ˜¯å¦å»ºè®®   |
    | ------------------------------------------- | ---------- |
    | æœåŠ¡å¯åŠ¨æ—¶é—´å¾ˆé•¿ï¼ˆå¤§äº liveness è¶…æ—¶ï¼‰      | âœ… å¼ºçƒˆå»ºè®® |
    | ä½¿ç”¨ Java / .NET Core / å¤§æ¨¡å‹æœåŠ¡          | âœ… å»ºè®®     |
    | å¯åŠ¨æµç¨‹ä¾èµ–å…¶ä»–ç³»ç»Ÿã€DBç­‰å¤–éƒ¨ä¾èµ–          | âœ… å»ºè®®     |
    | å®¹å™¨å¯åŠ¨ç¬é—´ä¼šæŠ¥é”™ï¼ˆå¦‚ healthz ä¸€å¼€å§‹æŠ¥é”™ï¼‰ | âœ… å»ºè®®     |
    | å®¹å™¨å¯åŠ¨æå¿«ï¼ˆ<5 ç§’ï¼‰                       | âŒ å¯çœç•¥   |
- **Liveiness probeï¼ˆå­˜æ´»æ¢é’ˆï¼‰**ï¼šåˆ¤æ–­å½“å‰Podæ˜¯å¦å¤„äºå­˜æ´»çŠ¶æ€ï¼Œæ˜¯Readinesså­˜æ´»çš„å‰æï¼Œå¯¹åº”READYçŠ¶æ€çš„m/nçš„nå€¼
- **Readiness Probeï¼ˆå°±ç»ªæ¢é’ˆ**ï¼‰ï¼šåˆ¤æ–­å½“å‰Podçš„ä¸»åº”ç”¨å®¹å™¨æ˜¯å¦å¯ä»¥æ­£å¸¸å¯¹å¤–æä¾›æœåŠ¡ï¼Œåªæœ‰Liveinessä¸ºå­˜æ´»ï¼ŒReadiness
  - Liveness probeå’ŒReadiness ProbeæŒç»­å®¹å™¨ç»ˆèº«ï¼Œåªè¦å®¹å™¨åœ¨å¯åŠ¨ï¼Œä¼šä¸æ–­åœ°æ¢æµ‹ï¼Œå¦‚æœå®¹å™¨å‡ºæ•…éšœï¼Œå¯ä»¥è¿›è¡Œä¸€äº›æ“ä½œ
  - ä¸‰ä¸ªæ¢é’ˆå°±æ˜¯ç”¨æ¥æ£€æµ‹å®¹å™¨å¥åº·æ€§çš„

- Serviceå…³è”Pod
- æ¥æ”¶ç”¨æˆ·è¯·æ±‚





#### å…³é—­Podæµç¨‹



![image-20241218092215630](../markdown_img/image-20241218092215630.png)





Kubernetes ä¸­çš„ **Pod å…³é—­æµç¨‹**ï¼ˆPod Terminationï¼‰æ˜¯ä¸€ä¸ª**å¤šé˜¶æ®µçš„æœ‰åºè¿‡ç¨‹**ï¼Œå…¶ç›®çš„æ˜¯åœ¨**ä¼˜é›…å…³é—­ï¼ˆGraceful Terminationï¼‰\**å’Œ\**å¼ºåˆ¶åˆ é™¤ï¼ˆForce Deletionï¼‰\**ä¹‹é—´å–å¾—å¹³è¡¡ã€‚è¿™ä¸ªæµç¨‹æ¶‰åŠ\**è´Ÿè½½å‡è¡¡å™¨ï¼ˆService ä»£ç†ï¼‰ã€preStop é’©å­ã€API Serverã€Kubeletã€etcdã€containerd å’Œ runc** ç­‰å¤šä¸ªç»„ä»¶çš„åä½œã€‚



æ•´ä¸ªæµç¨‹å¯åˆ†ä¸º**5 ä¸ªä¸»è¦é˜¶æ®µ**ï¼š



##### é˜¶æ®µ 1ï¼šè¯·æ±‚åˆ é™¤ Pod

**å‘èµ·åˆ é™¤è¯·æ±‚**ï¼š

- é€šè¿‡ `kubectl delete pod <pod-name>`ï¼Œkubectl å‘ API Server å‘èµ·ä¸€ä¸ª**DELETE è¯·æ±‚**ã€‚

- è¿™æ—¶ï¼ŒAPI Server ä¼š**ç«‹å³**å°† Pod çš„**çŠ¶æ€æ ‡è®°ä¸º Terminating**ã€‚

- API è¯·æ±‚ç¤ºä¾‹ï¼š

  ```http
  DELETE /api/v1/namespaces/default/pods/nginx-pod
  ```

**ä½“é¢ç»ˆæ­¢æœŸï¼ˆgraceful termination periodï¼‰è®¾ç½®**ï¼š

- å½“æ‰§è¡Œ `kubectl delete` æ—¶ï¼Œå¯ä»¥é€šè¿‡ `--grace-period=<seconds>` æŒ‡å®š**ä½“é¢ç»ˆæ­¢é™æœŸ**ã€‚

- å¦‚æœæœªæŒ‡å®šï¼Œé»˜è®¤ä¸º 30 ç§’ã€‚

- etcd å­˜å‚¨çš„çŠ¶æ€ï¼š

  ```ABAP
  /registry/pods/default/nginx-pod
  {
    "status": {
      "phase": "Terminating"
    }
  }
  ```

**é€šçŸ¥ Controller å’Œ Service**ï¼š

- API Server é€šè¿‡**watch æœºåˆ¶**é€šçŸ¥ **Controller Manager** å’Œ **Service ä»£ç†ï¼ˆä¾‹å¦‚ kube-proxyï¼‰**ã€‚
- **Service ä»£ç†ï¼ˆä¾‹å¦‚ kube-proxyï¼‰**ä¼šå°† Pod ä» **Endpoints** ä¸­åˆ é™¤ï¼Œä»è€Œä¸å†å°†æµé‡è·¯ç”±åˆ°è¯¥ Pod





##### é˜¶æ®µ 2ï¼šé€šçŸ¥ Kubelet

**Watch æœºåˆ¶é€šçŸ¥ Kubelet**ï¼š

- API Server å‘ Node ä¸Šçš„ Kubelet å‘é€ä¸€ä¸ª**Pod å˜æ›´äº‹ä»¶**ï¼Œæ ‡è¯†è¯¥ Pod å¤„äº **Terminating** çŠ¶æ€ã€‚

- watch URLï¼š

  ```http
  GET /api/v1/nodes/<node-name>/pods?watch=true
  ```

**Kubelet å¤„ç† Pod å˜æ›´**ï¼š

- Kubelet åœ¨æ”¶åˆ°å˜æ›´äº‹ä»¶åï¼Œ**æ£€æŸ¥ Pod çš„ä½“é¢ç»ˆæ­¢é™æœŸï¼ˆgraceful termination periodï¼‰**ã€‚
- Kubelet ç¡®ä¿ Pod åœ¨**å®½é™æœŸå†…åœæ­¢è¿è¡Œ**ã€‚
- **æ³¨æ„**ï¼šåœ¨æ­¤æœŸé—´ï¼ŒPod å¯èƒ½ä»åœ¨è¿è¡Œï¼Œç›´åˆ° **preStop é’©å­**å’Œ**å®¹å™¨è¢«åœæ­¢**



##### **é˜¶æ®µ 3ï¼šæ‰§è¡Œ preStop é’©å­å’Œç»ˆæ­¢å®¹å™¨**

**æ‰§è¡Œ preStop é’©å­**ï¼š

- å¦‚æœåœ¨ Pod çš„ YAML ä¸­å®šä¹‰äº†**preStop é’©å­**ï¼ŒKubelet ä¼š**åŒæ­¥æ‰§è¡Œ preStop é’©å­**ã€‚

- preStop æ˜¯**é˜»å¡æ“ä½œ**ï¼Œå³åœ¨ preStop é’©å­è¿è¡Œå®Œæˆå‰ï¼ŒPod ä¸ä¼šè¿›å…¥ç»ˆæ­¢é˜¶æ®µã€‚

- **ï¼ï¼preStopé’©å­å’ŒSIGTERMåŒæ­¥æ‰§è¡Œ**

- ç¤ºä¾‹ Pod å®šä¹‰ï¼š

  ```yaml
  lifecycle:
    preStop:
      exec:
        command: ["/bin/sh", "-c", "echo 'Goodbye, world!' > /tmp/goodbye.txt"]
  ```

**åœæ­¢å®¹å™¨**ï¼š

- preStop é’©å­æ‰§è¡Œå®Œæ¯•åï¼ŒKubelet è°ƒç”¨ **containerd** å’Œ **runc** åœæ­¢ Pod ä¸­çš„å®¹å™¨ã€‚

- é€šè¿‡è°ƒç”¨ CRI gRPCï¼ŒKubelet æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

  1. **åœæ­¢ä¿¡å·**ï¼šå‘é€**SIGTERM** ä¿¡å·ç»™ Pod ä¸­çš„æ‰€æœ‰å®¹å™¨ã€‚
  2. **ç­‰å¾…ä½“é¢ç»ˆæ­¢é™æœŸ**ï¼šç­‰å¾…å®½é™æœŸï¼ˆé»˜è®¤ 30 ç§’ï¼‰å†…çš„ç»ˆæ­¢ã€‚
  3. æ‰§è¡Œ preStop é’©å­
  4. **å¼ºåˆ¶ç»ˆæ­¢**ï¼šå¦‚æœè¶…æ—¶ï¼ŒKubelet ä¼šå‘å®¹å™¨å‘é€**SIGKILL**ï¼Œå¼ºåˆ¶ç»ˆæ­¢å®¹å™¨ã€‚

- æµç¨‹æ‘˜è¦ï¼š

  ```rust
  Kubelet --> containerd --> runc --> SIGTERM (å®½é™æœŸ)
  Kubelet --> containerd --> runc --> SIGKILL (å¼ºåˆ¶æ€æ­»)
  ```



##### **é˜¶æ®µ 4ï¼šç§»é™¤ Pod Endpointsï¼ˆä»è´Ÿè½½å‡è¡¡ä¸­åˆ é™¤ï¼‰**

**æ›´æ–° Service Endpoints**ï¼š

- prestopé’©å­å’ŒKubeletå‘Podå‘é€SIGTERMä»¥åŠé€šè¿‡**Endpoints Controller**å’Œ**kube-proxy**å°† Pod ä» Service çš„ Endpoints ä¸­ç§»é™¤ã€‚è¿™ä¸‰ä¸ªæ“ä½œåŒæ­¥æ‰§è¡Œ

- åœ¨ä½“é¢ç»ˆæ­¢é™æœŸçš„**å¼€å§‹æ—¶**ï¼ŒAPI Server å°±ä¼šé€šè¿‡**Endpoints Controller**å’Œ**kube-proxy**å°† Pod ä» Service çš„ Endpoints ä¸­ç§»é™¤ã€‚
- **åŸå› **ï¼šå³ä½¿ Pod ä»åœ¨è¿è¡Œï¼Œä½†ä¸ºäº†é˜²æ­¢å‘é€åˆ°å³å°†è¢«ç»ˆæ­¢çš„ Pod çš„æµé‡ï¼Œæå‰å°†å…¶ä»æµé‡è·¯å¾„ä¸­åˆ é™¤ã€‚

**Service è´Ÿè½½å‡è¡¡æ›´æ–°**ï¼š

- kube-proxy ç›‘å¬ Endpoints å˜æ›´ï¼ˆ**watch /api/v1/endpoints**ï¼‰ã€‚
- kube-proxy åœ¨ iptables ä¸­**åˆ é™¤ç›¸å…³çš„è§„åˆ™**ï¼Œä»¥é˜²æ­¢æ–°æµé‡å‘é€åˆ°è¯¥ Podã€‚



##### é˜¶æ®µ 5ï¼šä» etcd ä¸­åˆ é™¤ Pod

**Kubelet å‘ API Server å‘é€åˆ é™¤è¯·æ±‚**ï¼š

- å¦‚æœ Kubelet å‘ç° Pod è¿›ç¨‹å·²å®Œå…¨ç»ˆæ­¢ï¼ˆæ‰€æœ‰å®¹å™¨éƒ½å·²å…³é—­ï¼‰ï¼ŒKubelet å‘ API Server å‘é€ **DELETE è¯·æ±‚**ã€‚

- API è¯·æ±‚ç¤ºä¾‹ï¼š

  ```http
  DELETE /api/v1/namespaces/default/pods/nginx-pod
  ```

**API Server é€šçŸ¥ etcd åˆ é™¤ Pod**ï¼š

- API Server é€šè¿‡ gRPC è°ƒç”¨ etcd åˆ é™¤ä¸ Pod ç›¸å…³çš„

  å­˜å‚¨è·¯å¾„ï¼š

  ```http
  DELETE /registry/pods/default/nginx-pod
  ```

**ä» etcd ä¸­ç§»é™¤ Pod å¯¹è±¡**ï¼š

- Pod å¯¹è±¡ä» etcd ä¸­è¢«ç‰©ç†åˆ é™¤ï¼Œæ‰€æœ‰ä¸ä¹‹ç›¸å…³çš„**watch ç›‘å¬å™¨ï¼ˆKubelet, Controller, Schedulerï¼‰**éƒ½ä¼šç«‹å³æ”¶åˆ°äº‹ä»¶ã€‚



##### æ€»ç»“



**Pod å…³é—­æµç¨‹çš„çŠ¶æ€å˜åŒ–**

| **é˜¶æ®µ**   | **çŠ¶æ€**      | **æè¿°**                                    |
| ---------- | ------------- | ------------------------------------------- |
| **é˜¶æ®µ 1** | `Running`     | Pod å¤„äºæ­£å¸¸è¿è¡ŒçŠ¶æ€                        |
| **é˜¶æ®µ 2** | `Terminating` | `kubectl delete` è§¦å‘äº†åˆ é™¤äº‹ä»¶             |
| **é˜¶æ®µ 3** | `Terminating` | ä½“é¢ç»ˆæ­¢é™æœŸå†…ï¼ŒpreStop é’©å­å’Œ SIGTERM æ‰§è¡Œ |
| **é˜¶æ®µ 4** | `Terminating` | Pod ä» Service çš„ Endpoints ä¸­è¢«åˆ é™¤        |
| **é˜¶æ®µ 5** | **å·²åˆ é™¤**    | ä½“é¢ç»ˆæ­¢é™æœŸç»“æŸï¼ŒPod å½»åº•è¢«æ¸…é™¤            |



**å¼ºåˆ¶åˆ é™¤ï¼ˆForce Deletionï¼‰æµç¨‹**

**å½“æŒ‡å®š `--grace-period=0` æ—¶ï¼Œæµç¨‹çš„å…³é”®å˜åŒ–å¦‚ä¸‹ï¼š**

| **ç»„ä»¶**              | **è¡Œä¸ºå˜åŒ–**         | **è§£é‡Š**                                   |
| --------------------- | -------------------- | ------------------------------------------ |
| **ä½“é¢ç»ˆæ­¢**          | **è·³è¿‡**             | ä¸æ‰§è¡Œå®½é™æœŸï¼Œç›´æ¥å‘å‡º**SIGKILL**          |
| **preStop é’©å­**      | **è·³è¿‡**             | ä¸ä¼šæ‰§è¡Œ preStop è„šæœ¬                      |
| **Service Endpoints** | **ç«‹å³åˆ é™¤**         | Pod ä¼šç«‹åˆ»è¢«ä» Endpoints ä¸­åˆ é™¤            |
| **Pod ç»ˆæ­¢çŠ¶æ€**      | ç«‹å³ç»ˆæ­¢             | API Server å°† Pod ç«‹å³æ ‡è®°ä¸º `Terminating` |
| **Kubelet åˆ é™¤**      | **ç«‹å³å‘å‡º SIGKILL** | Kubelet ç›´æ¥è°ƒç”¨ SIGKILL                   |
| **Pod åˆ é™¤**          | **ç«‹å³åˆ é™¤**         | Kubelet ç›´æ¥è°ƒç”¨ API Server åˆ é™¤           |





**å…³é”®æ€»ç»“**

1. **ä¼˜é›…ç»ˆæ­¢**ï¼š
   - **å®½é™æœŸ**ï¼šä½“é¢ç»ˆæ­¢é™æœŸå†…ï¼ŒPod ä» Service ä¸­è¢«ç§»é™¤ï¼Œæ¥æ”¶ SIGTERMï¼Œå¹¶æ‰§è¡Œ preStop é’©å­ã€‚
   - **çŠ¶æ€å˜æ›´**ï¼šRunning â†’ Terminating â†’ åˆ é™¤ã€‚
   - **åˆ é™¤è¿‡ç¨‹**ï¼šå½“å®½é™æœŸè¶…æ—¶åï¼ŒPod è¢« SIGKILL ç»ˆæ­¢ï¼ŒKubelet å‘ API Server å‘é€åˆ é™¤è¯·æ±‚ã€‚
2. **å¼ºåˆ¶åˆ é™¤**ï¼š
   - **ç›´æ¥è·³è¿‡å®½é™æœŸ**ï¼Œä¸æ‰§è¡Œ preStop é’©å­ï¼Œç«‹å³å‘é€ SIGKILLã€‚
   - **ä»è´Ÿè½½å‡è¡¡ä¸­åˆ é™¤**ï¼šç«‹å³å°† Pod ä» Endpoints ä¸­åˆ é™¤ã€‚





#### è®¾ç½®ç»ˆæ­¢å®½é™æœŸ

```bash
spec.terminationGracePeriodï¼Œé»˜è®¤ä¸º30s,æ­¤å€¼ä¸ºä¼˜é›…ç»ˆæ­¢å®½é™æœŸ

#åˆ é™¤å‘½ä»¤ï¼škubectl delete pod mypod --grace-period=5
#å¼ºåˆ¶åˆ é™¤ï¼škubectl delete pod mypod --grace-period=0 --force
```



èŒƒä¾‹

```bash
[root@master1 ~]#kubectl explain pod.spec.terminationGracePeriodSeconds
KIND:     Pod
VERSION: v1
FIELD:   terminationGracePeriodSeconds <integer>
DESCRIPTION:
     Optional duration in seconds the pod needs to terminate gracefully. May be
     decreased in delete request. Value must be non-negative integer. The value
     zero indicates stop immediately via the kill signal (no opportunity to shut
     down). If this value is nil, the default grace period will be used instead.
     The grace period is the duration in seconds after the processes running in
     the pod are sent a termination signal and the time when the processes are
     forcibly halted with a kill signal. Set this value longer than the expected
     cleanup time for your process. Defaults to 30 seconds.
```



ç¤ºä¾‹

```yaml
spec:
 terminationGracePeriodSeconds: 3600  # Pod çº§åˆ«è®¾ç½®ï¼Œç­‰ä»·äº--grace-period=3600
 containers:
  - name: test
   image: ...
   ports:
    - name: liveness-port
     containerPort: 8080
     hostPort: 8080
   livenessProbe:
     httpGet:
       path: /healthz
         port: liveness-port
       failureThreshold: 1
       periodSeconds: 60
        # é‡è½½ Pod çº§åˆ«çš„ terminationGracePeriodSeconds
       terminationGracePeriodSeconds: 60
       
# è§£æä¸Šè¿°ä¸¤ä¸ªterminationGracePeriodSecondsçš„å«ä¹‰ä¸åŒºåˆ«
# ç¬¬ä¸€ä¸ªterminationGracePeriodSecondsï¼šå†³å®šäº†Kubelet åœ¨å‘é€ SIGKILL ä¿¡å·å‰çš„ç­‰å¾…æ—¶é—´ã€‚ -- Podçº§åˆ«
# ç¬¬äºŒä¸ªterminationGracePeriodSecondsï¼šåœ¨å®¹å™¨é‡å¯æ—¶ç”Ÿæ•ˆã€‚è§¦å‘ä¸‹åˆ—äº‹ä»¶æ—¶ï¼ŒKubeletä¼šé‡å¯æŸä¸ªç‰¹å®šå®¹å™¨ -- å®¹å™¨çº§åˆ«
# Liveness æ¢é’ˆå¤±è´¥ã€‚
# Kubelet å‘ç°å®¹å™¨çŠ¶æ€å¼‚å¸¸ï¼ˆä¾‹å¦‚ OOMã€CrashLoopBackOff ç­‰ï¼‰ã€‚
# å®¹å™¨çš„è‡ªæˆ‘å´©æºƒï¼ˆcontainerd å‘ç°å®¹å™¨è¿›ç¨‹é€€å‡ºï¼‰ã€‚

# è¡Œä¸ºå’Œä¿¡å·æµç¨‹ï¼š

# Kubelet å‘ç°Liveness æ¢é’ˆå¤±è´¥æˆ–å®¹å™¨éœ€è¦é‡å¯ã€‚
# Kubelet å‘ç‰¹å®šçš„å®¹å™¨å‘é€ SIGTERM ä¿¡å·ã€‚
# Kubelet ç­‰å¾… terminationGracePeriodSeconds ç§’ï¼Œé»˜è®¤æ˜¯ 30 ç§’ã€‚
# å¦‚æœåœ¨å®½é™æœŸå†…å®¹å™¨æœªé€€å‡ºï¼ŒKubelet å‘å®¹å™¨å‘é€ SIGKILL ä¿¡å·ã€‚
# Kubelet é€šè¿‡ CRI gRPC è¯·æ±‚ containerd æ¥åˆ é™¤å’Œé‡å¯è¿™ä¸ªå®¹å™¨ã€‚
```



##### ç‰¹åˆ«è¯´æ˜

```ABAP
å½“ Kubernetes åˆ é™¤ä¸€ä¸ª Pod æ—¶ï¼ŒKubelet å‘å®¹å™¨å‘é€ SIGTERM ä¿¡å·çš„åŒæ—¶ï¼Œæ‰§è¡Œ preStop é’©å­ã€‚è¿™ä¸¤ä¸ªåŠ¨ä½œæ˜¯åŒæ—¶è§¦å‘çš„ã€‚å®½é™æœŸï¼ˆgrace periodï¼‰ä»è¿™ä¸¤ä¸ªæ“ä½œå¼€å§‹æ—¶è®¡æ—¶ï¼Œè¿™æ„å‘³ç€ preStop å¿…é¡»åœ¨å®½é™æœŸå†…å®Œæˆï¼Œå¦åˆ™ Kubelet ä¼šåœ¨å®½é™æœŸç»“æŸæ—¶ç›´æ¥å‘å®¹å™¨å‘é€ SIGKILLï¼Œä¸è®º preStop æ˜¯å¦å®Œæˆã€‚

preStop è§¦å‘çš„å…·ä½“æ—¶é—´ç‚¹
è§¦å‘ç‚¹
preStop åœ¨Kubelet å‘é€ SIGTERM çš„åŒæ—¶è§¦å‘ã€‚
è¿™ä¸¤ä¸ªæ“ä½œï¼ˆå‘é€ SIGTERM å’Œ æ‰§è¡Œ preStop é’©å­ï¼‰æ˜¯å¹¶è¡Œçš„ï¼Œä¸ä¾èµ–å½¼æ­¤ã€‚

å¦‚æœ preStop æœªèƒ½åœ¨å®½é™æœŸå†…å®Œæˆï¼ŒKubelet ä»ä¼šåœ¨å®½é™æœŸç»“æŸåå‘é€ SIGKILLï¼Œè¿™ä¼šç«‹å³ç»ˆæ­¢å®¹å™¨
å¦‚æœ preStop æœ¬èº«çš„é€»è¾‘ä¾èµ–äºè¾ƒé•¿æ—¶é—´çš„ä»»åŠ¡ï¼ˆå¦‚æ•°æ®è¿ç§»ã€æŒä¹…åŒ–æ“ä½œï¼‰ï¼Œä½ éœ€è¦ç¡®ä¿ preStop é’©å­åœ¨å®½é™æœŸå†…å®Œæˆã€‚
```





#### ä¸¤ç§é’©å­PostStartå’ŒPreStop



æ ¹æ®ä¸Šé¢Podçš„å¯åŠ¨æµç¨‹ï¼Œå½“å®¹å™¨ä¸­çš„è¿›ç¨‹å¯åŠ¨å‰æˆ–è€…å®¹å™¨ä¸­çš„è¿›ç¨‹ç»ˆæ­¢ä¹‹å‰éƒ½ä¼šæœ‰ä¸€äº›é¢å¤–çš„åŠ¨ä½œæ‰§ è¡Œï¼Œè¿™æ˜¯ç”±kubeletæ‰€è®¾ç½®çš„ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º **pod hookã€‚**



å¯¹äºPodçš„æµç¨‹å¯åŠ¨ï¼Œä¸»è¦æœ‰ä¸¤ç§é’©å­ï¼š

- **postStart**ï¼š**å®¹å™¨åˆ›å»ºå®Œæˆåç«‹å³è¿è¡Œ**ï¼Œä¸ä¿è¯ä¸€å®šä¼šäºå®¹å™¨ä¸­ENTRYPOINTä¹‹å‰è¿è¡Œ,è€ŒInit  Containerå¯ä»¥å®ç°
- **preStop**ï¼š**å®¹å™¨ç»ˆæ­¢æ“ä½œä¹‹å‰ç«‹å³è¿è¡Œ**ï¼Œåœ¨å…¶å®Œæˆå‰ä¼šé˜»å¡åˆ é™¤å®¹å™¨çš„æ“ä½œè°ƒç”¨



##### Poststarté’©å­

```yaml
# cat pod-poststart.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-poststart
spec:
  containers:
    - name: busybox
      image: busybox:1.32.0
      lifecycle:
        postStart:
          exec:
            command: ["/bin/sh","-c","echo lifecycle poststart at $(date) > /tmp/poststart.log"]
      command: ['sh', '-c', 'echo The app is running at $(date) ! && sleep 3600']
      
# æŸ¥çœ‹podæ‰§è¡Œ      
#[root@master1 yaml]#kubectl logs pod-poststart
#The app is running at Wed Dec 18 03:34:41 UTC 2024 !

#[root@master1 yaml]#kubectl exec pod-poststart -- cat /tmp/poststart.log
#lifecycle poststart at Wed Dec 18 03:34:41 UTC 2024
```

```ABAP
åŸºäºä¸Šè¿°ç°è±¡ï¼Œå®¹å™¨å¯åŠ¨å’ŒPostStarté’©å­å‡½æ•°æ‰§è¡Œï¼Œå‡ ä¹æ˜¯åŒæ—¶çš„
```



##### Prestopé’©å­

**åŠŸèƒ½**ï¼šå®ç°podå¯¹è±¡ç§»é™¤ä¹‹å‰ï¼Œéœ€è¦åšä¸€äº›æ¸…ç†å·¥ä½œï¼Œæ¯”å¦‚:é‡Šæ”¾èµ„æºï¼Œè§£é”ç­‰

ç¤ºä¾‹

```yaml
#ç”±äºé»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ é™¤çš„åŠ¨ä½œå’Œæ—¥å¿—æˆ‘ä»¬éƒ½æ²¡æœ‰åŠæ³•çœ‹åˆ°ï¼Œé‚£ä¹ˆæˆ‘ä»¬è¿™é‡Œé‡‡ç”¨ä¸€ç§é—´æ¥çš„æ–¹æ³•ï¼Œåœ¨åˆ é™¤åŠ¨ä½œä¹‹å‰ï¼Œç»™æœ¬åœ°ç›®å½•åˆ›å»ºç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œè¾“å…¥ä¸€äº›å†…å®¹
# cat pod-prestop.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-prestop
spec:
  volumes:
  - name: vol-prestop
    hostPath:
      path: /tmp
  containers:
  - name: prestop-pod-container
    image: busybox:1.32.0
    volumeMounts:
    - name: vol-prestop
      mountPath: /tmp
    command: ['sh', '-c', 'echo The app is running at $(date) ! && sleep 3600']
    lifecycle:
      postStart:
        exec:
          command: ['/bin/sh', '-c', 'echo lifecycle poststart at $(date) > /tmp/poststart.log']
      preStop:
        exec:
          command: ['/bin/sh', '-c', 'echo lifecycle prestop at $(date) > /tmp/prestop.log']
```



#### PodçŠ¶æ€



##### Pod phaseé˜¶æ®µï¼ˆç›¸ä½ï¼‰

![image-20241218141357779](../markdown_img/image-20241218141357779.png)

| Value     | Description                                                  |
| --------- | ------------------------------------------------------------ |
| Pending   | Pod å·²è¢« Kubernetes é›†ç¾¤æ¥å—ï¼Œä½†ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨å°šæœªè®¾ç½®å¹¶å‡†å¤‡å¥½è¿è¡Œã€‚ è¿™ åŒ…æ‹¬ Pod ç­‰å¾…è°ƒåº¦æ‰€èŠ±è´¹çš„æ—¶é—´ä»¥åŠé€šè¿‡ç½‘ç»œä¸‹è½½å®¹å™¨é•œåƒæ‰€èŠ±è´¹çš„æ—¶é—´ã€‚ |
| Running   | Pod å·²ç»ç»‘å®šåˆ°ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå¹¶ä¸”æ‰€æœ‰çš„å®¹å™¨éƒ½å·²ç»åˆ›å»ºã€‚ è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨ä»åœ¨è¿ è¡Œï¼Œæˆ–è€…æ­£åœ¨å¯åŠ¨æˆ–é‡æ–°å¯åŠ¨ã€‚ |
| Succeeded | Pod ä¸­çš„æ‰€æœ‰å®¹å™¨éƒ½å·²æˆåŠŸç»ˆæ­¢ï¼Œå¹¶ä¸”ä¸ä¼šé‡æ–°å¯åŠ¨ã€‚             |
| Failed    | Pod ä¸­çš„æ‰€æœ‰å®¹å™¨éƒ½å·²ç»ˆæ­¢ï¼Œå¹¶ä¸”è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨å› æ•…éšœè€Œç»ˆæ­¢ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œå®¹ å™¨è¦ä¹ˆä»¥éé›¶çŠ¶æ€é€€å‡ºï¼Œè¦ä¹ˆè¢«ç³»ç»Ÿç»ˆæ­¢ã€‚ |
| Unknown   | ç”±äºæŸç§åŸå› ï¼Œæ— æ³•è·å– Pod çš„çŠ¶æ€ã€‚ æ­¤é˜¶æ®µé€šå¸¸æ˜¯ç”±äºä¸ Pod åº”è¿è¡Œçš„èŠ‚ç‚¹é€š ä¿¡æ—¶å‡ºç°é”™è¯¯è€Œå‘ç”Ÿçš„ã€‚ |





##### Pod çš„å¯åŠ¨æµç¨‹çŠ¶æ€

| æµç¨‹çŠ¶æ€        | æè¿°                              |
| --------------- | --------------------------------- |
| PodScheduled    | Podè¢«è°ƒåº¦åˆ°æŸä¸€ä¸ªèŠ‚ç‚¹             |
| Ready           | å‡†å¤‡å°±ç»ªï¼ŒPodå¯ä»¥å¤„ç†è¯·æ±‚         |
| Initialized     | Podä¸­æ‰€æœ‰åˆå§‹initå®¹å™¨å¯åŠ¨å®Œæ¯•     |
| Unschedulable   | ç”±äºèµ„æºç­‰é™åˆ¶ï¼Œå¯¼è‡´podæ— æ³•è¢«è°ƒåº¦ |
| ContainersReady | Podä¸­æ‰€æœ‰çš„å®¹å™¨éƒ½å¯åŠ¨å®Œæ¯•äº†       |





##### Podé‡å¯ç­–ç•¥ï¼ˆé¢è¯•é¢˜ï¼‰



**æ³¨æ„ï¼šåŒä¸€ä¸ª Pod å†…æ‰€æœ‰å®¹å™¨åªèƒ½ä½¿ç”¨ç»Ÿä¸€çš„é‡å¯ç­–ç•¥**



| é‡å¯ç­–ç•¥  | æè¿°                                                         |
| --------- | ------------------------------------------------------------ |
| Always    | æ— è®ºé€€å‡ºç exit codeæ˜¯å¦ä¸º0ï¼Œéƒ½è¦é‡å¯ï¼Œå³åªè¦é€€å‡ºå°±é‡å¯ï¼Œå¹¶ä¸”é‡å¯æ¬¡æ•°å¹¶æ²¡æœ‰é™åˆ¶ï¼Œæ­¤ä¸ºé»˜è®¤å€¼ |
| OnFailure | å®¹å™¨ç»ˆæ­¢è¿è¡Œé€€å‡ºç exit codeä¸ä¸º0æ—¶æ‰é‡å¯,é‡å¯æ¬¡æ•°å¹¶æ²¡æœ‰é™åˆ¶ï¼Œæ¯”å¦‚ï¼šå¦‚æœå®¹å™¨ä¸»è¿›ç¨‹æ˜¯ sleep 10ï¼›10 ç§’åè‡ªç„¶é€€å‡ºï¼Œé€€å‡ºç  0ï¼ŒOnFailure ä¸ä¼šé‡å¯ |
| Never     | æ— è®ºä½•ç§é€€å‡ºç exit code,Podéƒ½ä¸é‡å¯ã€‚ä¸»è¦é’ˆå¯¹Jobå’ŒCronJob    |



ç¤ºä¾‹ï¼š

```bash
[root@master1 tmp]#kubectl get pod myapp-pod -o yaml|grep restartPolicy
  restartPolicy: Always
```



#####  Pod é•œåƒæ‹‰å–çŠ¶æ€ï¼ˆé¢è¯•é¢˜ï¼‰

| æ‹‰å–ç­–ç•¥     | æè¿°                                                         |
| ------------ | ------------------------------------------------------------ |
| Always       | æ€»æ˜¯æ‹‰å–æ–°é•œåƒï¼Œæ³¨æ„ï¼šå¦‚æœ**é•œåƒçš„Tagä¸ºlatest**ï¼Œæ‹‰å–ç­–ç•¥ä¸ºalwaysæˆ– ifNotPresent éƒ½ä¼šé‡æ–°æ‹‰å–é•œåƒ |
| IfNotPresent | æ­¤ä¸ºé»˜è®¤å€¼ï¼Œå¦‚æœæœ¬åœ°ä¸å­˜åœ¨çš„è¯ï¼Œå†æ‹‰å–æ–°é•œåƒï¼Œä¾‹å¤–æƒ…å†µ:å¦‚æœé•œåƒçš„Tagä¸º latestï¼Œä»ä¼šé‡æ–°æ‹‰å–é•œåƒ |
| Never        | åªä½¿ç”¨æœ¬åœ°çš„é•œåƒï¼Œä»ä¸è·å–æ–°é•œåƒ                             |



```bash
[root@master1 tmp]#kubectl get pod myapp-pod -o yaml|grep imagePullPolicy
    imagePullPolicy: IfNotPresent   # é»˜è®¤å€¼
```





##### PodçŠ¶æ€æ±‡æ€»

| çŠ¶æ€                       | æè¿°                                                         |
| -------------------------- | ------------------------------------------------------------ |
| Pending                    | APIserverå·²ç»åˆ›å»ºè¯¥podå¯¹è±¡ï¼Œä½†æ˜¯kubeletå¯åŠ¨å®¹å™¨ä¹‹å‰ï¼Œéƒ½å¤„äºPendingçŠ¶æ€ |
| Running                    | Podå†…æ‰€æœ‰çš„å®¹å™¨å·²åˆ›å»ºï¼Œä¸”**è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨å¤„äºè¿è¡ŒçŠ¶æ€**ï¼Œæ­£ åœ¨å¯åŠ¨æˆ–é‡å¯çŠ¶æ€ |
| Waiting                    | Pod ç­‰å¾…å¯åŠ¨ä¸­                                               |
| Terminating                | Pod æ­£åœ¨åˆ é™¤ï¼Œè‹¥è¶…è¿‡ç»ˆæ­¢å®½é™æœŸä»æ— æ³•åˆ é™¤ï¼Œå¯ä»¥å¼ºåˆ¶åˆ é™¤ kubectl delete pod  -n --grace-period=0 --force |
| Succeeded                  | æ‰€æœ‰å®¹å™¨å‡æˆåŠŸæ‰§è¡Œé€€å‡ºï¼Œä¸”ä¸ä¼šå†é‡å¯                         |
| Ready                      | Pod å·²ç»å‡†å¤‡å¥½,å¯ä»¥æä¾›æœåŠ¡                                  |
| Failed                     | Podå†…æ‰€æœ‰å®¹å™¨éƒ½å·²é€€å‡ºï¼Œå…¶ä¸­è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨é€€å‡ºå¤±è´¥            |
| CrashLookBackOff           | æ›¾ç»å¯åŠ¨PodæˆåŠŸï¼Œä½†æ˜¯åæ¥å¼‚å¸¸æƒ…å†µä¸‹ï¼Œé‡å¯æ¬¡æ•°è¿‡å¤šå¯¼è‡´å¼‚å¸¸<br />**ç»ˆæ­¢Podé€€é¿ç®—æ³•**ï¼šç¬¬1æ¬¡0ç§’ç«‹åˆ»é‡å¯ï¼Œç¬¬äºŒæ¬¡10ç§’åé‡å¯ï¼Œç¬¬ä¸‰æ¬¡ 20ç§’åé‡å¯, ... ç¬¬6æ¬¡160ç§’åé‡å¯ï¼Œç¬¬7æ¬¡300ç§’åé‡å¯ï¼Œå¦‚ä»ç„¶ é‡å¯å¤±è´¥ï¼Œåˆ™ä¸º CrashLookBackOffçŠ¶æ€ |
| Error                      | å› ä¸ºé›†ç¾¤é…ç½®ã€å®‰å…¨é™åˆ¶ã€èµ„æºç­‰åŸå› å¯¼è‡´Pod å¯åŠ¨è¿‡ç¨‹ä¸­å‘ç”Ÿ äº†é”™è¯¯ |
| Evicted                    | é›†ç¾¤èŠ‚ç‚¹ç³»ç»Ÿ**å†…å­˜æˆ–ç¡¬ç›˜èµ„æºä¸è¶³**å¯¼è‡´Podå‡ºç°å¼‚å¸¸            |
| Completed                  | è¡¨ç¤ºPodå·²ç»æ‰§è¡Œå®Œæˆ,æ¯”å¦‚: **ä¸€æ¬¡æ€§çš„Jobæˆ–å‘¨æœŸæ€§çš„CronJob**ä¸­ çš„Podæ‰§è¡Œå®Œæˆå,ä¼šæ˜¾ç¤ºæ­¤çŠ¶æ€ |
| Unschedulable              | Pod ä¸èƒ½è°ƒåº¦åˆ°èŠ‚ç‚¹,ä¸€èˆ¬å¯èƒ½æ˜¯å› ä¸ºæ²¡æœ‰åˆé€‚çš„èŠ‚ç‚¹ä¸»æœº          |
| PodScheduled               | Pod æ­£åœ¨è¢«è°ƒåº¦è¿‡ç¨‹,ä½†æ­¤çŠ¶æ€çš„æ—¶é—´å¾ˆçŸ­                        |
| Initialized                | Podä¸­æ‰€æœ‰åˆå§‹initå®¹å™¨å¯åŠ¨å®Œæ¯•                                |
| ImagePullBackOff           | Podå¯¹åº”çš„é•œåƒæ‹‰å–å¤±è´¥                                        |
| InvalidImageName           | é•œåƒåç§°æ— æ•ˆå¯¼è‡´é•œåƒæ— æ³•ä¸‹è½½                                 |
| ImageInspectError          | é•œåƒæ£€æŸ¥é”™è¯¯ï¼Œé€šå¸¸å› ä¸ºé•œåƒä¸å®Œæ•´                             |
| ErrlmageNeverPull          | æ‹‰å–é•œåƒå› ç­–ç•¥ç¦æ­¢é”™è¯¯ï¼Œ**é•œåƒä»“åº“æƒé™æ‹’ç»æˆ–ç§æœ‰å¯¼è‡´**       |
| RegistryUnavailable        | é•œåƒä»“åº“æœåŠ¡ä¸å¯ç”¨ï¼Œæ¯”å¦‚:ç½‘ç»œåŸå› æˆ–ä»“åº“æœåŠ¡å™¨å®•æœº            |
| ErrImagePull               | é•œåƒæ‹‰å–é”™è¯¯ï¼Œå¯èƒ½æ˜¯å› ä¸ºè¶…æ—¶æˆ–æ‹‰å–è¢«å¼ºè¡Œç»ˆæ­¢                 |
| NetworkPluginNotReady      | ç½‘ç»œæ’ä»¶å¼‚å¸¸,ä¼šå¯¼è‡´æ–°å»ºå®¹å™¨å‡ºé”™,ä½†æ—§çš„å®¹å™¨ä¸å—å½±å“           |
| NodeLost                   | Podæ‰€åœ¨èŠ‚ç‚¹æ— æ³•è”ç³»                                          |
| CreateContainerConfigError | åˆ›å»ºå®¹å™¨é…ç½®é”™è¯¯                                             |
| CreateContainerError       | åˆ›å»ºå®¹å™¨é”™è¯¯                                                 |
| RunContainerError          | è¿è¡Œå®¹å™¨é”™è¯¯ï¼Œæ¯”å¦‚:å®¹å™¨ä¸­æ²¡æœ‰PIDä¸º1çš„å‰å°è¿›ç¨‹ç­‰åŸå›           |
| ContainersNotInitialized   | å®¹å™¨æ²¡æœ‰åˆå§‹åŒ–å®Œæˆ                                           |
| ContainersNotReady         | å®¹å™¨æ²¡æœ‰å‡†å¤‡å¥½                                               |
| ContainerCreating          | å®¹å™¨æ­£åœ¨åˆ›å»ºè¿‡ç¨‹ä¸­                                           |
| PodInitializing            | å®¹å™¨æ­£åœ¨åˆå§‹åŒ–ä¸­                                             |
| DockerDaemonNotReady       | èŠ‚ç‚¹çš„DockeræœåŠ¡å¼‚å¸¸                                         |
|                            |                                                              |



#### Pod çš„å¥åº·çŠ¶æ€ç›‘æµ‹



##### Podçš„çŠ¶æ€ç›‘æ§

å®é™…ä¸Šï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§å¯ä»¥åŠæ—¶çš„è·å–å®¹å™¨çš„å„ç§è¿è¡ŒçŠ¶æ€æ•°æ®ï¼Œæ‰€ä»¥å¯¹äºå®¹å™¨ä»»åŠ¡ç¼–æ’çš„ç¯å¢ƒä¸‹ï¼Œä»–ä»¬éƒ½åº”è¯¥è€ƒè™‘åˆ°ä¸€ç§åœºæ™¯ï¼šä¸»åŠ¨çš„å°†å®¹å™¨è¿è¡Œçš„ç›¸å…³æ•°æ®æš´éœ²å‡ºæ¥ -- **æ•°æ®æš´éœ²æ¥å£**ã€‚æ¯”å¦‚ï¼šåŒ…å«å¤§é‡ metricæŒ‡æ ‡æ•°æ®çš„APIæ¥å£ã€‚



å¯¹äºkuberneteså†…éƒ¨çš„podç¯å¢ƒæ¥è¯´ï¼Œå¸¸è§çš„è¿™äº›APIæ¥å£æœ‰ï¼š

![image-20241218150953385](../markdown_img/image-20241218150953385.png)



```bash
process health #çŠ¶æ€å¥åº·æ£€æµ‹æ¥å£
readiness #å®¹å™¨å¯è¯»çŠ¶æ€çš„æ¥å£
liveness #å®¹å™¨å­˜æ´»çŠ¶æ€çš„æ¥å£
metrics #ç›‘æ§æŒ‡æ ‡æ¥å£
tracing #å…¨é“¾è·¯ç›‘æ§çš„åŸ‹ç‚¹(æ¢é’ˆ)æ¥å£
logs #å®¹å™¨æ—¥å¿—æ¥å£
```





##### Pod çš„å¥åº·æ€§ç›‘æ§

Pod é€šè¿‡**æ¢é’ˆ**è¦åˆ¶å®ç°Pod å¥åº·æ€§ç›‘æ§,å½“ä¸€æ—¦æ£€æµ‹å‡ºPodæ•…éšœæ—¶ï¼Œä¼š**é‡ç½®Pod**æˆ–**å°†Podä»serviceåç«¯ endpointåˆ é™¤**ï¼Œä»è€Œå®ç°æœåŠ¡çš„é«˜å¯ç”¨



**æ¢é’ˆç±»å‹**

é’ˆå¯¹è¿è¡Œä¸­çš„å®¹å™¨ï¼Œ kubelet å¯ä»¥é€‰æ‹©æ˜¯å¦æ‰§è¡Œä»¥ä¸‹ä¸‰ç§æ¢é’ˆï¼Œä»¥åŠå¦‚ä½•é’ˆå¯¹æ¢æµ‹ç»“æœä½œå‡ºååº”



![image-20241218151223781](../markdown_img/image-20241218151223781.png)

**è¿‡ç¨‹è¯¦è§£**



- åˆå§‹åˆšå¯åŠ¨å®¹å™¨çš„æ—¶å€™ï¼Œæœ‰ä¸ªåˆå§‹åŒ–æ—¶é—´ï¼ˆ**InitialDelaySeconds for Startup Probe**è¯¥æ—¶é—´å¯ä»¥è‡ªå·±å®šä¹‰ï¼‰ï¼Œç„¶ååœ¨æ‰§è¡Œ**Startup Probe** Execution
  - è¿™ç§å¯èƒ½ä½¿ç”¨çš„åœºæ™¯ï¼šjavaç¨‹åºå¯åŠ¨è¾ƒæ…¢ï¼Œå®¹å™¨å¯åŠ¨æ—¶é—´å¯èƒ½æ¯”è¾ƒé•¿ï¼Œæ‰€ä»¥éœ€è¦å®¹å™¨å¯åŠ¨ä¸€æ®µæ—¶é—´åï¼Œå†ä½¿ç”¨**Startup Probe**è¿›è¡Œæ¢æµ‹ï¼Œå¦åˆ™å¯èƒ½å®¹å™¨è¿˜æœªå¯åŠ¨æˆåŠŸï¼ŒStartup Probeå°±å¼€å§‹æ¢æµ‹ï¼Œä¼šæ¢æµ‹å¤±è´¥
  - è€ŒStartup Probe**æ¢æµ‹å¤±è´¥**çš„ç»“æœæ˜¯å®¹å™¨ä¼š**ç«‹å³é‡å¯**
  - **Startup Probeåªæ¢æµ‹ä¸€æ¬¡ï¼Œæ¢æµ‹æˆåŠŸåï¼Œåç»­ä¸ä¼šå†æ¢æµ‹**

- å®¹å™¨å¯åŠ¨æˆåŠŸåï¼Œåç»­ä¼šæœ‰ä¸¤ä¸ªæ¢é’ˆLivness Probeå’ŒReadiness Probeï¼Œåœ¨ä¸¤ä¸ªæ¢é’ˆä¹‹å‰ï¼Œåˆ†åˆ«æœ‰ä¸¤ä¸ªç­‰å¾…æ—¶é—´ï¼Œå³
  - Livness Probe ----- initialDelaySeconds for Liveness Probe
  - Readiness Probe ----- initialDelaySeconds for Readiness Probe
- å¦‚æœLiveness Probeæ£€æµ‹å¤±è´¥ï¼Œä¼šé‡å¯å®¹å™¨
- å¦‚æœReadiness Probeæ¢æµ‹å¤±è´¥ï¼Œä¸ä¼šé‡å¯å®¹å™¨ï¼Œè€Œæ˜¯å°†å®¹å™¨ä»è°ƒåº¦åˆ—è¡¨ä¸­ç§»é™¤
  - ç”¨æˆ·é€šå¸¸æ˜¯é€šè¿‡serviceæ¥è®¿é—®åç«¯çš„Podï¼Œå¦‚æœReadiness Probeæ£€æµ‹å¤±è´¥ï¼Œä¼šå°†å…¶ä»Serviceçš„åˆ—è¡¨ä¸­ç§»é™¤ï¼Œä½†æ˜¯Podä¸ä¼šé‡å¯
- å¦‚æœLiveness Probeæ£€æµ‹æˆåŠŸåï¼Œä¼šæœ‰ä¸€ä¸ªç­‰å¾…çš„æ—¶é—´ï¼Œå³PeriodSecondsï¼Œç„¶åä¼šç»§ç»­æ¢æµ‹ï¼Œä¹Ÿå°±æ˜¯è¯´åç»­ä¼šå‘¨æœŸæ€§æ¢æµ‹ï¼Œæ¯è¿‡PeriodSecondsæ—¶é—´ï¼Œä¼šæ¢æµ‹ä¸€æ¬¡
- å¦‚æœReadiness Probeæ£€æµ‹æˆåŠŸï¼Œä¹Ÿä¼šæœ‰ä¸€ä¸ªç­‰å¾…çš„äº‹ä»¶ï¼Œå³PeriodSecondsï¼Œç„¶åä¼šç»§ç»­æ¢æµ‹



##### é…ç½®æ¢é’ˆ

probeæœ‰å¾ˆå¤šé…ç½®å­—æ®µï¼Œå¯ä»¥ä½¿ç”¨è¿™äº›å­—æ®µç²¾ç¡®åœ°æ§åˆ¶å¯åŠ¨ï¼Œå­˜æ´»å’Œå°±ç»ªæ£€æµ‹çš„è¡Œä¸º

- `initialDelaySeconds`ï¼šå®¹å™¨å¯åŠ¨åè¦ç­‰åˆ°å¤šå°‘ç§’åï¼Œæ‰å¯åŠ¨**å¯åŠ¨**ï¼Œ**å­˜æ´»**ï¼Œ**å°±ç»ª**æ¢é’ˆï¼Œé»˜è®¤æ˜¯0ç§’ï¼Œæœ€å°å€¼æ˜¯0.
- `periodSeconds`ï¼šæ‰§è¡Œæ¢æµ‹çš„æ—¶é—´é—´éš”ï¼ˆå•ä½æ˜¯ç§’ï¼‰ã€‚é»˜è®¤æ˜¯10ç§’ï¼Œæœ€å°å€¼æ˜¯1ã€‚
- `timeoutSeconds`ï¼šæ¢æµ‹è¶…æ—¶åï¼Œç­‰å¾…å¤šå°‘ç§’ã€‚é»˜è®¤å€¼æ˜¯1ç§’ï¼Œæœ€å°å€¼æ˜¯1
- `successThreshold`ï¼šæ¢é’ˆåœ¨å¤±è´¥åï¼Œè¢«è§†ä¸ºæˆåŠŸçš„æœ€å°è¿ç»­æˆåŠŸæ•°ã€‚é»˜è®¤å€¼æ˜¯1.å­˜æ´»å’Œå¯åŠ¨æ¢æµ‹çš„è¿™ä¸ªå€¼å¿…é¡»æ˜¯1ï¼Œæœ€å°å€¼æ˜¯1
- `failureThreshold`ï¼šå½“æ¢æµ‹å¤±è´¥æ—¶ï¼ŒKubernetesçš„é‡è¯•æ¬¡æ•°ã€‚å¯¹å­˜æ´»æ¢é’ˆè€Œè¨€ã€‚æ”¾å¼ƒå°±æ„å‘³ç€é‡æ–°å¯åŠ¨å®¹å™¨
  - å¯¹å°±ç»ªæ¢é’ˆè€Œè¨€ï¼Œæ”¾å¼ƒæ„å‘³ç€POdä¼šè¢«æ‰“ä¸Šæœªå°±ç»ªçš„æ ‡ç­¾ã€‚é»˜è®¤æ˜¯3ï¼Œæœ€å°å€¼æ˜¯1





![image-20241218151415616](../markdown_img/image-20241218151415616.png)

``````yaml
spec:
  containers:
  - name: string
    image: string
    livenessProbe:
      exec <Object>                    # å‘½ä»¤å¼æ¢é’ˆ
      httpGet <Object>                 # http GETç±»å‹çš„æ¢é’ˆ
      tcpSocket <Object>               # tcp Socketç±»å‹çš„æ¢é’ˆ
      initialDelaySeconds <integer>    # å‘èµ·åˆæ¬¡æ¢æµ‹è¯·æ±‚å‰çš„å»¶è¿Ÿæ—¶é•¿ï¼Œé»˜è®¤ä¸º0ï¼Œç”Ÿäº§æ ¹æ®æœåŠ¡èµ·å“¦å¤šåŠŸèƒ½æ—¶é•¿æ¥è®¾ç½®ï¼Œæ¯”å¦‚60s
      periodSeconds <integer>          # æ¯æ¬¡æ¢é’ˆè¯·æ±‚é—´éš”ï¼Œå³æ¢æµ‹çš„å‘¨æœŸï¼Œé»˜è®¤10sï¼Œå¦‚æœPodä¼—å¤šï¼Œå¯é€‚å½“è®¾é•¿ï¼Œæ¯”å¦‚60s
      timeoutSeconds <integer>         # æ¢æµ‹çš„è¶…æ—¶æ—¶é•¿ï¼Œé»˜è®¤æ˜¯1s
      successThreshold <integer>       # è¿ç»­æˆåŠŸå‡ æ¬¡æ‰è¡¨ç¤ºçŠ¶æ€æ­£å¸¸ï¼Œé»˜è®¤å€¼æ˜¯1æ¬¡ï¼Œæ³¨æ„ï¼šlivenesså’Œstartupåªèƒ½æ˜¯1
      failureThreshold <integer>       # è¿ç»­å¤±è´¥å‡ æ¬¡æ‰è¡¨ç¤ºçŠ¶æ€å¼‚å¸¸ï¼Œé»˜è®¤å€¼æ˜¯3æ¬¡ï¼Œå³ä»æˆåŠŸå˜ä¸ºå¤±è´¥çš„æ£€æŸ¥æ¬¡æ•°
``````



##### å®ç°æ¢é’ˆçš„ä¸‰ç§æ–¹å¼

å¯¹äºPodä¸­å¤šå®¹å™¨çš„åœºæ™¯ï¼Œåªæœ‰æ‰€æœ‰å®¹å™¨å°±ç»ªï¼Œæ‰è®¤ä¸ºPodå°±ç»ª

kubelet å®šæœŸæ‰§è¡ŒLivenessProbeå’ŒReadinessProbeæ¢é’ˆæ¥è¯Šæ–­Podçš„å¥åº·çŠ¶å†µï¼ŒPodæ¢é’ˆçš„å®ç°æ–¹å¼ æœ‰å¾ˆå¤šï¼Œå¸¸è§çš„æœ‰å¦‚ä¸‹ä¸‰ç§ï¼š

| ç›‘æµ‹çš„å®ç°æ–¹å¼ | è§£æ                                                         |
| -------------- | ------------------------------------------------------------ |
| Exec           | ç›´æ¥æ‰§è¡ŒæŒ‡å®šçš„å‘½ä»¤ï¼Œ**æ ¹æ®**å‘½ä»¤ç»“æœçš„**çŠ¶æ€ç $?åˆ¤æ–­æ˜¯å¦æˆåŠŸ**ï¼ŒæˆåŠŸåˆ™è¿”å›è¡¨ç¤ºæ¢æµ‹æˆåŠŸ |
| TCPSocket      | æ ¹æ®ç›¸åº”TCPå¥—æ¥å­—è¿æ¥å»ºç«‹çŠ¶æ€åˆ¤æ–­,å¦‚æœ**ç«¯å£èƒ½æ­£å¸¸æ‰“å¼€**ï¼Œå³æˆåŠŸ |
| HTTPGet        | æ ¹æ®æŒ‡å®šHttp/HttpsæœåŠ¡URLçš„å“åº”ç ç»“æœåˆ¤æ–­ï¼Œå½“**2xx, 3xxçš„å“åº”ç è¡¨ç¤ºæˆåŠŸ** |
| gRPC           | ä½¿ç”¨ gRPC æ‰§è¡Œä¸€ä¸ªè¿œç¨‹è¿‡ç¨‹è°ƒç”¨ã€‚ ç›®æ ‡åº”è¯¥å®ç° gRPCå¥åº·æ£€æŸ¥ã€‚ å¦‚æœ**å“åº”çš„çŠ¶æ€æ˜¯ "SERVING"**ï¼Œåˆ™è®¤ä¸ºè¯Šæ–­æˆåŠŸã€‚ gRPC æ¢é’ˆæ˜¯ä¸€ä¸ª Alpha ç‰¹æ€§ï¼Œåªæœ‰åœ¨ä½ å¯ç”¨ äº† "GRPCContainerProbe" ç‰¹æ€§é—¨æ§æ—¶æ‰èƒ½ä½¿ç”¨ |

![image-20241219155655923](../markdown_img/image-20241219155655923.png)

##### Execæ–¹å¼æ¡ˆä¾‹

exec å…¶å®å°±æ˜¯å°è¯•é€šè¿‡åœ¨å®¹å™¨å†…éƒ¨æ¥æ‰§è¡Œä¸€ä¸ªå‘½ä»¤ï¼Œçœ‹çœ‹èƒ½ä¸èƒ½æ‰§è¡ŒæˆåŠŸï¼Œå¦‚æœæˆåŠŸï¼Œé‚£ä¹ˆè¯´æ˜è¯¥å¯¹è±¡ æ˜¯æ­£å¸¸çš„ï¼Œå¦åˆ™å°±æ˜¯å¤±è´¥çš„ã€‚

èŒƒä¾‹ï¼šstartup probe

```yaml
# cat pod-startup-exec.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-startup-exec
  namespace: default
  labels:
    app: pod-startup-exec
spec:
  containers:
  - name: pod-startup-exec-container
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
    startupProbe:
      exec:
        command: ['/bin/sh', '-c', '["`$(curl -s 127.0.0.1/lives)" == "0k" ]']
      initialDelaySeconds: 60
      timeoutSeconds: 1
      periodSeconds: 5
      successThreshold: 1
      failureThreshold: 1
      
# å¯åŠ¨POd
kubectl apply -f pod-startup-exec.yaml

# æŸ¥çœ‹
[root@master1 yaml]#kubectl get pod 
NAME               READY   STATUS    RESTARTS      AGE
pod-startup-exec   0/1     Running   2 (12s ago)   3m28s

# è§£æREADY 0/1
# EADY = å½“å‰â€œå¤„äºå°±ç»ª(Ready)çŠ¶æ€çš„å®¹å™¨æ•°â€ / Pod ä¸­çš„æ€»å®¹å™¨æ•°

# è¿™ä¸ªpodé‡Œçš„å®¹å™¨é‡Œçš„ç¨‹åºæ˜¯æ•…æ„ç¬¬ä¸€æ¬¡å¯åŠ¨ä¼šæœ‰ä¸€ä¸ªå»¶è¿Ÿï¼Œè¶…è¿‡1s,ï¼Œå› ä¸ºtimeoutSeconds: 1ï¼Œå› æ­¤ä¼šæ£€æµ‹å¤±è´¥ï¼Œunhealthyï¼Œå¯¼è‡´é‡å¯
# åç»­ä¼šå¾ªç¯é‡å¯

# è§£å†³æ–¹æ¡ˆï¼šå°†è¶…æ—¶æ—¶é—´æ”¹ä¸º10
```



èŒƒä¾‹ï¼šlivenessProbe

```yaml
# cat pod-liveness-exec-cmd.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-liveness-exec-cmd
  namespace: default
spec:
  containers:
  - name: pod-liveness-exec-cmd-container
    image: busybox:1.32.0
    imagePullPolicy: IfNotPresent
    command: ["/bin/sh", "-c", "touch /tmp/healthy; sleep 3; rm -f /tmp/healthy; sleep 3600"]
    livenessProbe:
      exec:
        command: ["test", "-e", "/tmp/healthy"]
      initialDelaySeconds: 1
      periodSeconds: 3
      
# åˆ›å»ºå®¹å™¨
kubectl apply -f pod-liveness-exec-cmd.yaml

# å®æ—¶ç›‘æ§ï¼Œå‘ç°ä¸æ–­é‡å¯
[root@master1 yaml]#kubectl get pod pod-liveness-exec-cmd -w
NAME                    READY   STATUS    RESTARTS   AGE
pod-liveness-exec-cmd   1/1     Running   0          22s
pod-liveness-exec-cmd   1/1     Running   1 (1s ago)   55s
pod-liveness-exec-cmd   1/1     Running   2 (5s ago)   101s
pod-liveness-exec-cmd   1/1     Running   3 (1s ago)   2m19s
pod-liveness-exec-cmd   1/1     Running   4 (1s ago)   3m1s
pod-liveness-exec-cmd   1/1     Running   5 (0s ago)   3m42s
pod-liveness-exec-cmd   0/1     CrashLoopBackOff   5 (1s ago)   4m25s
pod-liveness-exec-cmd   1/1     Running            6 (85s ago)   5m49s
pod-liveness-exec-cmd   0/1     CrashLoopBackOff   6 (1s ago)    6m31s
pod-liveness-exec-cmd   1/1     Running            7 (2m50s ago)   9m20s
pod-liveness-exec-cmd   0/1     CrashLoopBackOff   7 (1s ago)      10m
pod-liveness-exec-cmd   1/1     Running            8 (5m5s ago)    15m
pod-liveness-exec-cmd   1/1     Running            9 (1s ago)      15m
pod-liveness-exec-cmd   0/1     CrashLoopBackOff   9 (1s ago)      16m
```



##### Tcpsocketæ–¹å¼æ¡ˆä¾‹

ä½¿ç”¨æ­¤é…ç½®ï¼Œ kubelet å°†å°è¯•åœ¨æŒ‡å®šç«¯å£ä¸Šæ‰“å¼€å®¹å™¨çš„å¥—æ¥å­—ã€‚å¦‚æœå¯ä»¥å»ºç«‹è¿æ¥ï¼Œå®¹å™¨è¢«è®¤ä¸ºæ˜¯å¥åº· çš„ï¼Œå¦‚æœä¸èƒ½å°±è®¤ä¸ºæ˜¯å¤±è´¥çš„ï¼Œå®é™…ä¸Šå°±æ˜¯**æ£€æŸ¥ç«¯å£**ã€‚

å¯¹äº TCP æ¢æµ‹è€Œè¨€ï¼Œkubelet åœ¨èŠ‚ç‚¹ä¸Šï¼ˆä¸æ˜¯åœ¨ Pod é‡Œé¢ï¼‰å‘èµ·æ¢æµ‹è¿æ¥ï¼Œ è¿™æ„å‘³ç€ä½ ä¸èƒ½åœ¨ host å‚æ•°ä¸Šé…ç½®æœåŠ¡åç§°ï¼Œå› ä¸º kubelet ä¸èƒ½è§£ææœåŠ¡åç§°ã€‚



**livenessçš„Tcpsocketæ¢é’ˆ**

```yaml
# cat pod-liveness-tcpsocket.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-liveness-tcpsocket
  namespace: default
spec:
  containers:
  - name: pod-liveness-tcpsocket-container
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
    ports:
    - name: http           # ç»™æŒ‡å®šç«¯å£å®šä¹‰åˆ«å
      containerPort: 80
    securityContext:       # æ·»åŠ ç‰¹æƒï¼Œå¦åˆ™æ·»åŠ iptablesè§„åˆ™ä¼šæç¤ºï¼šgetsockopt failed strangely: Operation not permitted
      capabilities:
        add:
        - NET_ADMIN
    livenessProbe:
      tcpSocket:
        port: http        # å¼•ç”¨ä¸Šé¢ç«¯å£çš„å®šä¹‰
      periodSeconds: 5
      initialDelaySeconds: 5
      
# æ³¨æ„ï¼šç”±äºæ­¤é•œåƒåº”ç”¨å¯¹å¤–æš´éœ²çš„ç«¯å£æ˜¯80ç«¯å£ï¼Œæ‰€ä»¥è¦æ¢æµ‹80ç«¯å£

# æ¨¡æ‹Ÿæ¢æµ‹å¤±è´¥ï¼Œæ·»åŠ é˜²ç«å¢™è§„åˆ™ï¼Œç¦æ­¢æ¢æµ‹
kubectl exec pod-liveness-tcpsocket -- iptables -A INPUT -p tcp --dport 80 -j REJECT

# æŸ¥çœ‹çŠ¶æ€å¼‚å¸¸
kubectl describe pod pod-liveness-tcpsocket
...
Events:
  Type     Reason     Age               From               Message
  ----     ------     ----              ----               -------
  Normal   Scheduled  98s               default-scheduler  Successfully assigned default/pod-liveness-tcpsocket to node1
  Normal   Pulled     98s               kubelet            Container image "registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1" already present on machine
  Normal   Created    98s               kubelet            Created container pod-liveness-tcpsocket-container
  Normal   Started    97s               kubelet            Started container pod-liveness-tcpsocket-container
  Warning  Unhealthy  3s (x3 over 13s)  kubelet            Liveness probe failed: dial tcp 10.244.1.15:80: connect: connection refused
  Normal   Killing    3s                kubelet            Container pod-liveness-tcpsocket-container failed liveness probe, will be restarted
  
# æ³¨æ„ï¼šlivenessProbeæ¢æµ‹å¤±è´¥ï¼Œä¼šé‡å¯å®¹å™¨ï¼Œè€Œé‡å¯å®¹å™¨å¹¶ä¸æ˜¯é‡æ–°åˆ›å»ºå®¹å™¨ï¼Œå› æ­¤å†…æ ¸ç›¸å…³åŠŸèƒ½æ— æ³•é‡ç½®ï¼Œä¹Ÿå°±å¯¼è‡´å³ä¾¿é‡å¯ï¼Œé˜²ç«å¢™è§„åˆ™ä»ç„¶åœ¨ï¼Œä¼šå¯¼è‡´æ¢æµ‹å¤±è´¥ï¼Œåç»­ä¸æ–­é‡å¯
```



**Readinessçš„Tcpsocketæ¢é’ˆ**

```yaml
# cat pod-readiness-tcpsocket.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-readiness-tcpsocket
  labels: 
    app: pod-readiness-tcpsocket
spec:
  containers:
  - name: pod-readiness-tcpsocket-container
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    readinessProbe:
      tcpSocket:
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
    livenessProbe:
      tcpSocket:
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 20
---
apiVersion: v1
kind: Service
metadata:
  name: pod-readiness-tcpsocket-svc
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: pod-readiness-tcpsocket     # æŒ‡å®šä¸Šé¢Podç›¸åŒçš„æ ‡ç­¾
    
# æŸ¥çœ‹Serviceçš„IP    
[root@master1 yaml]# kubectl get svc
NAME                          TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
kubernetes                    ClusterIP   10.96.0.1      <none>        443/TCP   25h
pod-readiness-tcpsocket-svc   ClusterIP   10.104.62.95   <none>        80/TCP    8s

# curl 10.104.62.95
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
...


# å°†readniessProbeä¸Šçš„æ¢æµ‹ç«¯å£æ”¹ä¸º8080ï¼Œå› ä¸ºæ²¡æœ‰æ‰“å¼€8080ç«¯å£ï¼Œå› æ­¤readinessProbeå¿…ç„¶å¤±è´¥
# cat pod-readiness-tcpsocket.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-readiness-tcpsocket
  labels: 
    app: pod-readiness-tcpsocket
spec:
  containers:
  - name: pod-readiness-tcpsocket-container
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    readinessProbe:
      tcpSocket:
        port: 8080                 # æ”¹ä¸º8080
      initialDelaySeconds: 5
      periodSeconds: 10
    livenessProbe:
      tcpSocket:
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 20
---
apiVersion: v1
kind: Service
metadata:
  name: pod-readiness-tcpsocket-svc
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: pod-readiness-tcpsocket     # æŒ‡å®šä¸Šé¢Podç›¸åŒçš„æ ‡ç­¾
    
# åˆ›å»ºèµ„æº
[root@master1 yaml]#kubectl apply -f pod-readiness-tcpsocket.yaml 
pod/pod-readiness-tcpsocket created
service/pod-readiness-tcpsocket-svc created

# æŸ¥çœ‹çŠ¶æ€
[root@master1 yaml]#kubectl get pod
NAME                      READY   STATUS    RESTARTS   AGE
pod-readiness-tcpsocket   0/1     Running   0          4s
pod-startup-exec          1/1     Running   0          3h26m

[root@master1 yaml]#kubectl describe pod pod-readiness-tcpsocket 
...
Events:
  Type     Reason     Age               From               Message
  ----     ------     ----              ----               -------
  Normal   Scheduled  25s               default-scheduler  Successfully assigned default/pod-readiness-tcpsocket to node1
  Normal   Pulled     24s               kubelet            Container image "registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0" already present on machine
  Normal   Created    24s               kubelet            Created container pod-readiness-tcpsocket-container
  Normal   Started    24s               kubelet            Started container pod-readiness-tcpsocket-container
  Warning  Unhealthy  4s (x2 over 14s)  kubelet            Readiness probe failed: dial tcp 10.244.1.17:8080: connect: connection refused

# å¯ä»¥çœ‹åˆ°Readiness Probeå¤±è´¥
# è§‚å¯ŸServiceçš„ep
[root@master1 yaml]#kubectl get ep
NAME                          ENDPOINTS         AGE
kubernetes                    10.0.0.201:6443   25h
pod-readiness-tcpsocket-svc                     41s

# ç”±äºreadniessProbeæ¢æµ‹å¤±è´¥ï¼Œå› æ­¤å°†Podä»serviceçš„endponitsåˆ—è¡¨ç§»é™¤
```



##### HttpGetæ–¹å¼æ¡ˆä¾‹

HTTP æ¢æµ‹é€šè¿‡å¯¹å®¹å™¨å†…å®¹å¼€æ”¾çš„webæœåŠ¡ï¼Œè¿›è¡Œhttpæ–¹æ³•çš„è¯·æ±‚æ¢æµ‹ï¼Œå¦‚æœ**æ¢æµ‹æˆåŠŸ(çŠ¶æ€ç ä¸º2XXå’Œ 3XX)**ï¼Œé‚£ä¹ˆè¡¨ç¤ºhttpæœåŠ¡æ˜¯æ­£å¸¸çš„ï¼Œå¦åˆ™å°±æ˜¯å¤±è´¥çš„ã€‚

HTTP Probes å…è®¸é’ˆ**å¯¹ httpGet é…ç½®é¢å¤–çš„å­—æ®µ**ï¼š

```yaml
#ç¤ºä¾‹:
httpHeaders:
  - name: user_agent
    value: curl

# å…¶ä»–å­—æ®µ
# hostï¼š è¿æ¥ä½¿ç”¨çš„ä¸»æœºåï¼Œé»˜è®¤æ˜¯ Pod çš„ IPã€‚ä¹Ÿå¯ä»¥åœ¨ HTTP å¤´ä¸­è®¾ç½® â€œHostâ€ æ¥ä»£æ›¿ã€‚ä¸€èˆ¬ä¸é…ç½®æ­¤é¡¹
# scheme ï¼š ç”¨äºè®¾ç½®è¿æ¥ä¸»æœºçš„æ–¹å¼ï¼ˆHTTP è¿˜æ˜¯ HTTPSï¼‰ã€‚é»˜è®¤æ˜¯ "HTTP"ã€‚ä¸€èˆ¬ä¸é…ç½®æ­¤é¡¹
# pathï¼š è®¿é—® HTTP æœåŠ¡çš„è·¯å¾„ã€‚é»˜è®¤å€¼ä¸º "/"ã€‚ä¸€èˆ¬ä¼šé…ç½®æ­¤é¡¹
# portï¼š è®¿é—®å®¹å™¨çš„ç«¯å£å·æˆ–è€…ç«¯å£åã€‚å¦‚æœæ•°å­—å¿…é¡»åœ¨ 1ï½65535 ä¹‹é—´ã€‚ä¸€èˆ¬ä¼šé…ç½®æ­¤é¡¹
# httpHeadersï¼šè¯·æ±‚ä¸­è‡ªå®šä¹‰çš„ HTTP å¤´ã€‚HTTP å¤´å­—æ®µå…è®¸é‡å¤ã€‚ä¸€èˆ¬ä¸é…ç½®æ­¤é¡¹
```



**Livenessçš„httpGetæ¢é’ˆ**

```yaml
# cat pod-liveness-http.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-liveness-http
spec:
  containers:
  - name: pod-liveness-http-container
    image: busybox:1.32.0
    ports:
    - name: http
      containerPort: 80
    livenessProbe:
      httpGet:
        port: http
        path: /index.html
      initialDelaySeconds: 1
      periodSeconds: 3

# å¯ç”¨å®¹å™¨
kubectl apply -f pod-liveness-http.yaml
pod/pod-liveness-http created
```



 **Readiness çš„ httpGet æ¢é’ˆ**

é€šè¿‡readinessçš„å±æ€§ï¼Œå°è¯•åˆ¤æ–­èµ„æºå¯¹è±¡æ˜¯å¦å‡†å¤‡å¥½äº†ç›¸å…³æœåŠ¡ï¼Œæ¥æ¥å—ç”¨æˆ·è¯·æ±‚ã€‚ å¦‚æœreadinessæ£€æµ‹å¤±è´¥,ç›¸å…³çš„serviceä¼šå°†æ­¤podä»Endpointsä¸­ç§»é™¤,ä½†ä¸ä¼šé‡å¯pod 

```yaml
# cat pod-readiness-http.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-readiness-http
spec:
  containers:
  - name: pod-readiness-http-container
    image: busybox:1.32.0
    ports:
    - name: http
      containerPort: 80
    readinessProbe:
      httpGet:
        port: http
        path: /index.html
      initialDelaySeconds: 1
      periodSeconds: 3
      
# åˆ›å»ºå®¹å™¨
kubectl apply -f pod-readiness-http.yaml

#å®æ—¶ç›‘æ§
[root@master1 ~]#kubectl get pod -w
NAME                 READY   STATUS             RESTARTS     AGE
pod-readiness-http   0/1     CrashLoopBackOff   1 (26s ago)   43s
pod-readiness-http   0/1     Completed          2 (32s ago)   49s
```





#### podèµ„æºé™åˆ¶

kubernetes å¯ä»¥æ”¯æŒåœ¨**å®¹å™¨çº§**åŠ**namespaceçº§**åˆ†åˆ«å®ç°èµ„æºé™åˆ¶



Kubernetes å·²ç»å¯¹Podåšäº†ç›¸åº”çš„èµ„æºé…é¢è®¾ç½®ï¼Œè¿™äº›èµ„æºä¸»è¦ä½“ç°åœ¨ï¼šCPUå’Œå†…å­˜ã€å­˜å‚¨ï¼Œå› ä¸ºå­˜å‚¨ åœ¨k8sä¸­æœ‰ä¸“é—¨çš„èµ„æºå¯¹è±¡ï¼ˆPV,PVCï¼‰æ¥è¿›è¡Œç®¡æ§ï¼Œæ‰€ä»¥å½“å‰çš„podèµ„æºé™åˆ¶ï¼Œä¸»è¦æŒ‡çš„è®¡ç®—èµ„æºï¼Œå³**CPUå’Œå†…å­˜ã€‚**



ä¸ºäº†æ–¹ä¾¿ä¸k8sçš„å…¶ä»–å•ç‹¬çš„èµ„æºå¯¹è±¡åŒºåˆ†å¼€æ¥ï¼Œä¸€èˆ¬å°†**CPUå’Œå†…å­˜**å…¶ç§°ä¸º**è®¡ç®—èµ„æº**ã€‚

å¦‚æœè¿è¡Œçš„Podä½¿ç”¨çš„èµ„æºè¶…è¿‡å®¿ä¸»æœºçš„æœ€å¤§å¯ç”¨èµ„æº,ä¼šå¯¼è‡´**OOM**å’Œ**Podé©±é€**åˆ°å…¶å®ƒå®¿ä¸»æœº



##### å¯é™åˆ¶çš„èµ„æºå•ä½

å¸¸è§åœ¨å®¹å™¨çº§åˆ«çš„CPUå’Œå†…å­˜çš„é™åˆ¶



- **CPU**
  - ç‰¹ç‚¹ï¼šæ˜¯ä¸€ç§å¯å‹ç¼©èµ„æºï¼Œcpuèµ„æºæ˜¯æ”¯æŒæŠ¢å çš„
  - å•ä½ï¼šCPUçš„èµ„æºå•ä½æ˜¯CPU(Core)çš„æ•°é‡,æ˜¯ä¸€ä¸ªç»å¯¹
  - å¤§å°ï¼šåœ¨Kubernetesä¸­é€šå¸¸ä»¥åƒåˆ†ä¹‹ä¸€çš„CPU(Core)ä¸ºæœ€å°å•ä½ï¼Œç”¨æ¯« m è¡¨ç¤º,å³**ä¸€ä¸ªCPUæ ¸å¿ƒè¡¨ç¤ºä¸º1000m**
  - ç»éªŒï¼š**ä¸€ä¸ªèµ„æºå ç”¨ä¸å¤šçš„å®¹å™¨å ç”¨çš„CPU**é€šå¸¸åœ¨100~300mï¼Œå³**0.1-0.3ä¸ªCPU**
  - æ³¨æ„ï¼šmi ä»£è¡¨æ˜¯1024è¿›åˆ¶çš„



- **å†…å­˜**
  - ç‰¹ç‚¹ï¼šæ˜¯ä¸å¯å‹ç¼©èµ„æºï¼Œå½“podèµ„æºæ‰©å±•çš„æ—¶å€™ï¼Œå¦‚æœnodeä¸Šèµ„æºä¸å¤Ÿï¼Œé‚£ä¹ˆå°±ä¼šå‘ç”Ÿèµ„æºæŠ¢å ï¼Œ æˆ–è€…OOMé—®é¢˜
  - å•ä½ï¼šå†…å­˜çš„èµ„æºä»¥å­—èŠ‚æ•°ä¸ºå•ä½ï¼Œæ˜¯ä¸€ä¸ªç»å¯¹å€¼
  - å¤§å°ï¼šå†…å­˜é…é¢å¯¹äºç»å¤§å¤šæ•°å®¹å™¨æ¥è¯´å¾ˆé‡è¦ï¼Œåœ¨Kubernetesä¸­é€šå¸¸ä»¥Mi,Giä¸ºå•ä½æ¥åˆ†é…ã€‚é€šå¸¸ åˆ†é…ç½®1G,2G,æœ€å¤š16Gæˆ–32G
  - æ³¨æ„ï¼šå¦‚æœå†…å­˜åˆ†é…ä¸è¶³,å¯èƒ½ä¼šå‡ºç°OOMç°è±¡ï¼ˆJavaç¨‹åºå¸¸è§ï¼‰



- **æ³¨æ„**
  - CPUå±äºå¯å‹ç¼©ï¼ˆcompressibleï¼‰å‹èµ„æºï¼Œå³èµ„æºé¢åº¦å¯æŒ‰éœ€æ”¶ç¼©
  - å†…å­˜ï¼ˆå½“å‰ï¼‰åˆ™æ˜¯ä¸å¯å‹ç¼©å‹èµ„æºï¼Œå¯¹å…¶æ‰§è¡Œæ”¶ç¼©æ“ä½œå¯èƒ½ä¼šå¯¼è‡´æŸç§ç¨‹åº¦çš„é—®é¢˜ï¼Œä¾‹å¦‚è¿›ç¨‹å´©æºƒ ç­‰ã€‚



- **Extended Resources æ‰©å±•èµ„æºé™åˆ¶ï¼ˆå¸¸è§ï¼šGPUèµ„æºï¼‰**
  - æ‰€æœ‰ä¸å±äºkubernetes.ioåŸŸçš„èµ„æº,ä¸ºæ‰©å±•èµ„æº,å¦‚:"**nvidia.com/gpu**"
  - kubernetes ä¹Ÿæ”¯æŒé’ˆåˆ°æ‰©å±•èµ„æºé™åˆ¶





##### é…é¢é™åˆ¶å‚æ•°

Kubernetesä¸­ï¼Œå¯¹äºæ¯ç§èµ„æºçš„é…é¢é™å®šéƒ½éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼š**Requestså’ŒLimits**

![image-20241218152631838](../markdown_img/image-20241218152631838.png)





- **èµ„æºéœ€æ±‚Requests**
  - ä¸šåŠ¡è¿è¡Œæ—¶èµ„æºé¢„ç•™çš„æœ€å°ä½¿ç”¨é‡ï¼Œå³æ‰€éœ€èµ„æºçš„**æœ€ä½ä¸‹é™**ï¼Œ**è¯¥å‚æ•°çš„å€¼å¿…é¡»æ»¡è¶³ï¼Œè‹¥ä¸æ»¡è¶³ï¼Œä¸šåŠ¡æ— æ³•è¿è¡Œ**ã€‚
  - å®¹å™¨è¿è¡Œæ—¶å¯èƒ½ç”¨ä¸åˆ°è¿™äº›é¢åº¦çš„èµ„æºï¼Œä½†ç”¨åˆ°æ—¶å¿…é¡»ç¡®ä¿æœ‰ç›¸åº”æ•°é‡çš„èµ„æºå¯ç”¨
  - èµ„æºéœ€æ±‚çš„å®šä¹‰ä¼šå½±å“è°ƒåº¦å™¨çš„å†³ç­–,åªä¼šå°†Podè°ƒåº¦è‡³æ»¡è¶³æ‰€æœ‰å®¹å™¨æ€»çš„èµ„æºéœ€æ±‚çš„èŠ‚ç‚¹
  - å½“èµ„æºä¸è¶³æ—¶ï¼Œ**å®é™…ä½¿ç”¨çš„èµ„æºè¶…å‡º Requests çš„éƒ¨åˆ†ï¼Œå¯èƒ½ä¼šè¢«å›æ”¶**
  - **ä¸èƒ½è¶…è¿‡å¯¹åº”çš„limitså€¼**
  - **ä¸èƒ½è¶…è¿‡ç‰©ç†èŠ‚ç‚¹å¯ç”¨åˆ†é…çš„èµ„æºå€¼**



- **èµ„æºé™åˆ¶ Limits**
  - è¿è¡Œæ—¶èµ„æºå…è®¸ä½¿ç”¨æœ€å¤§å¯ç”¨é‡ï¼Œå³æ‰€éœ€èµ„æºçš„æœ€é«˜ä¸Šé™ï¼Œè¯¥å‚æ•°çš„å€¼ä¸èƒ½è¢«çªç ´ï¼Œè¶…å‡ºè¯¥é¢åº¦çš„èµ„æºä½¿ç”¨è¯·æ±‚é€šå¸¸ä¼šè¢«æ‹’ç»
  - **è¯¥é™åˆ¶éœ€è¦å¤§äºç­‰äºrequestsçš„å€¼**ï¼Œä½†ç³»ç»Ÿåœ¨å…¶æŸé¡¹èµ„æºç´§å¼ æ—¶ï¼Œä¼šä»å®¹å™¨é‚£é‡Œå›æ”¶å…¶ä½¿ç”¨çš„è¶…å‡º å…¶requestså€¼çš„é‚£éƒ¨åˆ†
  - é’ˆå¯¹å†…å­˜è€Œè¨€,ä¸ºé˜²æ­¢ä¸Šé¢å›æ”¶æƒ…å†µçš„å‘ç”Ÿ,ä¸€èˆ¬**å»ºè®®å°†å†…å­˜çš„ Requests å’Œ Limits è®¾ä¸ºç›¸åŒ**
  - èµ„æºé™åˆ¶**Limit**çš„å®šä¹‰**ä¸å½±å“è°ƒåº¦å™¨çš„å†³ç­–**
  - ä¸èƒ½ä½äºå¯¹åº”çš„limitså€¼
  - å¯ä»¥è¶…è¿‡ç‰©ç†èŠ‚ç‚¹å¯ç”¨åˆ†é…çš„èµ„æºå€¼
  - **æç¤º:ä¸ºä¿è¯æ€§èƒ½,ç”Ÿäº§æ¨èRequestså’ŒLimitsè®¾ç½®ä¸ºç›¸åŒçš„å€¼**



##### k8sèµ„æºæŸ¥çœ‹

è¦å®ç°èµ„æºé™åˆ¶,éœ€è¦å…ˆ**å®‰è£…metrics-server**

```bash
[root@master1 ~]# curl -LO https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

#é»˜è®¤æ–‡ä»¶éœ€è¦ä¿®æ”¹æ‰èƒ½å·¥ä½œ,å› ä¸ºé»˜è®¤éœ€è¦å†…éƒ¨è¯ä¹¦éªŒè¯å’Œé•œåƒåœ°å€k8s.gcr.ioæ‰€ä»¥ä¿®æ”¹
# vim components.yaml
spec:
      containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=10250
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        - --kubelet-insecure-tls
        #image: registry.cn-hangzhou.aliyuncs.com/google_containers/metricsserver:v0.7.1 # å¯ä»¥æ·»åŠ å›½å†…æº
        image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /livez
            port: https
            scheme: HTTPS
          periodSeconds: 10
        name: metrics-server
        ports:
        - containerPort: 10250
          name: https
          protocol: TCP
          
[root@master1 yaml]# kubectl apply -f components.yaml 
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created


root@master1 yaml]#kubectl get pod -n kube-system metrics-server-b79d5c976-hqrct 
NAME                             READY   STATUS    RESTARTS   AGE
metrics-server-b79d5c976-hqrct   1/1     Running   0          60s
[root@master1 yaml]#kubectl top node
NAME      CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
master1   62m          3%     910Mi           49%       
node1     30m          1%     669Mi           36%       
node2     20m          1%     927Mi           50%       
node3     27m          1%     715Mi           39% 
```



##### èµ„æºé™åˆ¶å®ç°

èŒƒä¾‹ï¼šlimitså’Œrequestså€¼å¤§å°

```yaml
# [root@master1 yaml]# cat pod-limit-request.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-limit-request
spec:
  containers:
  - name: pod-limit-request-container
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        memory: "500Mi"
        cpu: "250m"
      limits:
        memory: "500Mi"
        cpu: "250m"

```



##### å‹åŠ›æµ‹è¯•

```yaml
# cat pod-stress.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-stress
spec:
  containers:
  - name: pod-stress
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/stress-ng
    imagePullPolicy: IfNotPresent
    command: ["/usr/bin/stress-ng", "-c 2", "--metrics-brief"]
    resources:
      requests:
        memory: 128Mi
        cpu: 200m
      limits:
        memory: 256Mi
        cpu: 500m

# æŸ¥çœ‹
[root@master1 yaml]#kubectl exec pod-stress -- top
Mem: 1853284K used, 120644K free, 4744K shrd, 55064K buff, 832920K cached
CPU:  24% usr   0% sys   0% nic  74% idle   0% io   0% irq   0% sirq
Load average: 0.35 0.30 0.17 3/513 14
  PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND
    8     1 root     R     6904   0%   1  13% {stress-ng-cpu} /usr/bin/stress-ng
    7     1 root     R     6904   0%   0  12% {stress-ng-cpu} /usr/bin/stress-ng
    1     0 root     S     6264   0%   1   0% /usr/bin/stress-ng -c 2 --metrics-
q   9     0 root     R     1520   0%   0   0% top
```





##### åŸºäºNamespaceçº§åˆ«çš„èµ„æºé™åˆ¶

åœ¨ **Kubernetes ä¸­åŸºäº Namespace çº§åˆ«çš„èµ„æºé™åˆ¶**ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨ **ResourceQuota** å’Œ **LimitRange** æ¥å®ç°å¯¹å‘½åç©ºé—´ä¸­èµ„æºçš„ä½¿ç”¨é™åˆ¶ã€‚



**èµ„æºé™åˆ¶çš„å®ç°æ–¹å¼**

| **æ–¹å¼**          | **å¯¹è±¡**       | **é™åˆ¶ç±»å‹**                   | **å…¸å‹é™åˆ¶å†…å®¹**                             |
| ----------------- | -------------- | ------------------------------ | -------------------------------------------- |
| **ResourceQuota** | **Namespace**  | **å‘½åç©ºé—´çº§åˆ«çš„èµ„æºæ€»é‡é™åˆ¶** | é™åˆ¶ Namespace ä¸­ Podã€CPUã€å†…å­˜ã€å­˜å‚¨çš„æ€»é‡ |
| **LimitRange**    | **Pod å’Œå®¹å™¨** | **å•ä¸ª Pod/å®¹å™¨çš„èµ„æºé™åˆ¶**    | é™åˆ¶æ¯ä¸ª Pod/å®¹å™¨çš„ CPU å’Œå†…å­˜çš„æœ€å°å’Œæœ€å¤§å€¼ |

------



**èµ„æºé™åˆ¶çš„å·¥ä½œæœºåˆ¶**

**1ï¸âƒ£ ResourceQuota (é™åˆ¶ Namespace èµ„æºæ€»é‡)**

- **ä½œç”¨èŒƒå›´**ï¼š
  é™åˆ¶æ•´ä¸ª Namespace ä¸­çš„èµ„æºæ€»é‡ï¼ŒåŒ…æ‹¬ Pod æ•°é‡ã€CPUã€å†…å­˜å’Œå­˜å‚¨ã€‚
- **å¸¸è§çš„é™åˆ¶é¡¹ç›®**ï¼š
  - Pod æ€»æ•° (`pods`)
  - å®¹å™¨çš„æ€» CPU è¯·æ±‚ (`requests.cpu`) å’Œæ€»é™åˆ¶ (`limits.cpu`)
  - å®¹å™¨çš„æ€»å†…å­˜è¯·æ±‚ (`requests.memory`) å’Œæ€»é™åˆ¶ (`limits.memory`)
  - PersistentVolumeClaim (PVC) çš„æ€»å­˜å‚¨ä½¿ç”¨é‡ (`requests.storage`)
- **å…¸å‹åœºæ™¯**ï¼š
  é™åˆ¶ä¸€ä¸ªé¡¹ç›®å›¢é˜Ÿåœ¨å…¶ Namespace ä¸­æœ€å¤šåªèƒ½ä½¿ç”¨ 10 ä¸ª Podï¼ŒCPU æ€»é‡ä¸è¶…è¿‡ 10 æ ¸ï¼Œå†…å­˜æ€»é‡ä¸è¶…è¿‡ 32GiBã€‚



**2ï¸âƒ£ LimitRange (é™åˆ¶å•ä¸ª Pod å’Œå®¹å™¨çš„èµ„æº)**

- **ä½œç”¨èŒƒå›´**ï¼š
  é™åˆ¶ **æ¯ä¸ª Pod æˆ–æ¯ä¸ªå®¹å™¨** çš„ CPU å’Œå†…å­˜çš„æœ€å¤§ã€æœ€å°å€¼ã€‚
- **å¸¸è§çš„é™åˆ¶é¡¹ç›®**ï¼š
  - å®¹å™¨çš„æœ€å° CPU è¯·æ±‚ (`min.cpu`) å’Œæœ€å¤§é™åˆ¶ (`max.cpu`)
  - å®¹å™¨çš„æœ€å°å†…å­˜è¯·æ±‚ (`min.memory`) å’Œæœ€å¤§é™åˆ¶ (`max.memory`)
- **å…¸å‹åœºæ™¯**ï¼š
  æ¯ä¸ª Pod ä¸­çš„å®¹å™¨éƒ½å¿…é¡»è¯·æ±‚æœ€å°‘ 100m çš„ CPUï¼Œä½†æœ€å¤šä¸èƒ½è¶…è¿‡ 2 æ ¸ CPUï¼Œæœ€å°‘ 200Mi çš„å†…å­˜ï¼Œæœ€å¤šä¸èƒ½è¶…è¿‡ 2GiB çš„å†…å­˜ã€‚



**ResourceQuotaç¤ºä¾‹ï¼ˆå‘½åç©ºé—´çš„èµ„æºæ€»é‡é™åˆ¶ï¼‰**

é™åˆ¶ **æ•´ä¸ªå‘½åç©ºé—´ä¸­çš„ Pod æ•°é‡ã€CPU å’Œå†…å­˜ä½¿ç”¨é‡**ã€‚

```yaml
# cat resource-quota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: namespace-quota
  namespace: my-namespace
spec:
  hard:
    pods: "10"                    # é™åˆ¶å‘½åç©ºé—´ä¸­æœ€å¤šæœ‰ 10 ä¸ª Pod
    requests.cpu: "10"            # æ‰€æœ‰ Pod çš„ CPU è¯·æ±‚æ€»å’Œä¸èƒ½è¶…è¿‡ 10 æ ¸
    requests.memory: "32Gi"       # æ‰€æœ‰ Pod çš„å†…å­˜è¯·æ±‚æ€»å’Œä¸èƒ½è¶…è¿‡ 32Gi
    limits.cpu: "20"              # æ‰€æœ‰ Pod ä¸­ CPU é™åˆ¶çš„æ€»å’Œä¸èƒ½è¶…è¿‡ 20 æ ¸
    limits.memory: "64Gi"         # æ‰€æœ‰ Pod ä¸­å†…å­˜é™åˆ¶çš„æ€»å’Œä¸èƒ½è¶…è¿‡ 64Gi
    persistentvolumeclaims: "5"   # é™åˆ¶ Namespace ä¸­çš„ PVC æ•°é‡ä¸º 5 ä¸ª
    requests.storage: "100Gi"     # é™åˆ¶æ‰€æœ‰ PVC è¯·æ±‚çš„å­˜å‚¨æ€»é‡ä¸º 100Gi

```



**LimitRangeç¤ºä¾‹ï¼ˆPodå’Œå®¹å™¨çš„èµ„æºé™åˆ¶ï¼‰**

ä¸º **å•ä¸ª Pod å’Œå®¹å™¨** é™åˆ¶å…¶ CPU å’Œå†…å­˜çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚

```yaml
cat limit-range.yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: container-limit-range
  namespace: my-namespace
spec:
  limits:
  - type: Pod                # ä½œç”¨èŒƒå›´ä¸ºPOd
    max:                     # maxï¼šæŒ‡å®š Pod æ€»çš„ CPU å’Œå†…å­˜ä¸Šé™ï¼ŒCPU ä¸èƒ½è¶…è¿‡ 2 æ ¸ï¼Œå†…å­˜ä¸èƒ½è¶…è¿‡ 4Giã€‚
      cpu: "2"               # æ¯ä¸ª Pod çš„æœ€å¤§ CPU é™åˆ¶ä¸º 2 æ ¸
      memory: "4Gi"          # æ¯ä¸ª Pod çš„æœ€å¤§å†…å­˜é™åˆ¶ä¸º 4 GiB
    min:                     # minï¼šæŒ‡å®š Pod çš„æœ€å°èµ„æºè¯·æ±‚ï¼ŒCPU ä¸ä½äº 250mï¼Œå†…å­˜ä¸ä½äº 128Miã€‚
      cpu: "250m"            # æ¯ä¸ª Pod çš„æœ€å° CPU è¯·æ±‚ä¸º 250m
      memory: "128Mi"        # æ¯ä¸ª Pod çš„æœ€å°å†…å­˜è¯·æ±‚ä¸º 128Mi
  - type: Container          # type: Containerï¼šä½œç”¨èŒƒå›´ä¸º Pod å†…çš„æ¯ä¸ªå®¹å™¨
    default:
      cpu: "500m"            # æ¯ä¸ªå®¹å™¨çš„é»˜è®¤ CPU è¯·æ±‚ä¸º 500m
      memory: "512Mi"        # æ¯ä¸ªå®¹å™¨çš„é»˜è®¤å†…å­˜è¯·æ±‚ä¸º 512Mi
    defaultRequest:
      cpu: "250m"            # å¦‚æœæœªæŒ‡å®šè¯·æ±‚ï¼Œé»˜è®¤ CPU è¯·æ±‚ä¸º 250m
      memory: "256Mi"        # å¦‚æœæœªæŒ‡å®šè¯·æ±‚ï¼Œé»˜è®¤å†…å­˜è¯·æ±‚ä¸º 256Mi
    max:
      cpu: "1"               # æ¯ä¸ªå®¹å™¨çš„æœ€å¤§ CPU é™åˆ¶ä¸º 1 æ ¸
      memory: "2Gi"          # æ¯ä¸ªå®¹å™¨çš„æœ€å¤§å†…å­˜é™åˆ¶ä¸º 2GiB
    min:
      cpu: "100m"            # æ¯ä¸ªå®¹å™¨çš„æœ€å° CPU è¯·æ±‚ä¸º 100m
      memory: "128Mi"        # æ¯ä¸ªå®¹å™¨çš„æœ€å°å†…å­˜è¯·æ±‚ä¸º 128Mi

```





#### Podå®‰å…¨

##### èµ„æºå®‰å…¨å±æ€§

å®¹å™¨ä¸€èˆ¬æ˜¯åŸºäº6ä¸ªå‘½åç©ºé—´å®ç°èµ„æºçš„éš”ç¦»ï¼Œè€Œä¸€ä¸ª Pod å°±æ˜¯ä¸€ä¸ªå®¹å™¨é›†åˆï¼ŒåŒ…å«å¤šä¸ªå®¹å™¨

è¿™ä¸ªå‘½åç©ºé—´æ˜¯æŒ‰ç…§ä¸‹é¢æ–¹å¼æ¥ä½¿ç”¨çš„ï¼š

- å†…éƒ¨çš„æ‰€æœ‰å®¹å™¨å…±äº«åº•å±‚ pauseå®¹å™¨çš„ UTSï¼ŒNetwork ä¸¤ä¸ªåç§°ç©ºé—´èµ„æº
- å¯é€‰å…±äº«å‘½åç©ºé—´ï¼šIPCï¼ŒPID
- MNTå’ŒUSER ä¸¤ä¸ªå‘½åç©ºé—´é»˜è®¤æ²¡æœ‰å…±äº«,ä»è€Œå®ç°åº”ç”¨çš„éš”ç¦»ã€‚



##### å®¹å™¨å®‰å…¨ä¸Šä¸‹æ–‡

podåœ¨å…¶ç”Ÿå‘½å‘¨æœŸä¸­ï¼Œæ¶‰åŠåˆ°å¤šç§åœºæ™¯(å¤šå®¹å™¨çš„å…³è”å…³ç³»)ï¼Œå°†è¿™ç§ç›¸å…³çš„ä½œç”¨å…³ç³»ç§°ä¸ºå®¹å™¨ä¸Šä¸‹æ–‡ï¼Œå…¶ ä¸­æœ‰ä¸€äº›æ¶‰åŠåˆ°æƒé™ã€é™åˆ¶ç­‰å®‰å…¨ç›¸å…³çš„å†…å®¹ï¼Œç§°å…¶ä¸ºå®‰å…¨ä¸Šä¸‹æ–‡ã€‚

å®‰å…¨ä¸Šä¸‹æ–‡æ˜¯ä¸€ç»„ç”¨äºå†³å®šå®¹å™¨æ˜¯å¦‚ä½•åˆ›å»ºå’Œè¿è¡Œçš„çº¦æŸæ¡ä»¶ï¼Œå®ƒä»¬ä»£è¡¨ç€åˆ›å»ºå’Œè¿è¡Œå®¹å™¨æ—¶ä½¿ç”¨çš„è¿è¡Œæ—¶å‚æ•°ã€‚

å®ƒæ ¹æ®çº¦æŸçš„ä½œç”¨èŒƒå›´ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªçº§åˆ«ï¼š

- Podçº§åˆ«ï¼šé’ˆå¯¹podèŒƒå›´å†…çš„æ‰€æœ‰å®¹å™¨
- å®¹å™¨çº§åˆ«ï¼šä»…é’ˆå¯¹podèŒƒå›´å†…çš„æŒ‡å®šå®¹å™¨
- PSPçº§åˆ«ï¼šPodSecurityPolicyï¼Œå…¨å±€çº§åˆ«çš„Podå®‰å…¨ç­–ç•¥ï¼Œæ¶‰åŠåˆ°å‡†å…¥æ§åˆ¶ç›¸å…³çŸ¥è¯†



Podå’Œå®¹å™¨çš„å®‰å…¨ä¸Šä¸‹æ–‡è®¾ç½®ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢

- å®¹å™¨è¿›ç¨‹è¿è¡Œèº«ä»½åŠèµ„æºè®¿é—®æƒé™
- Linux Capabilities
- è‡ªä¸»è®¿é—®æ§åˆ¶DAC
- seccompï¼šsecurecomputing modeï¼Œå®ç°é™åˆ¶ç¨‹åºä½¿ç”¨æŸäº›ç³»ç»Ÿè°ƒç”¨
- AppArmorï¼šApplication Armor ä¸SELinuxç±»ä¼¼ï¼Œå¯ä»¥é™åˆ¶ç¨‹åºçš„åŠŸèƒ½ï¼Œæ¯”å¦‚ç¨‹åºå¯ä»¥è¯»ã€å†™æˆ–è¿ è¡Œå“ªäº›æ–‡ä»¶ï¼Œæ˜¯å¦å¯ä»¥æ‰“å¼€ç«¯å£ç­‰
- SELinux
- Privilege Mode
- Privilege Escalation ç‰¹æƒæå‡



##### å®‰å…¨ä¸Šä¸‹æ–‡ç›¸å…³å±æ€§

```bash
#Podçº§å®‰å…¨ä¸Šä¸‹æ–‡
~]#kubectl explain pod.spec.securityContext
#å®¹å™¨çº§å®‰å…¨ä¸Šä¸‹æ–‡
~]#kubectl explain pod.spec.containers.securityContext
apiVersion: v1
kind: Pod
metadata: {â€¦}
spec:
 securityContext:                        # Podçº§åˆ«çš„å®‰å…¨ä¸Šä¸‹æ–‡ï¼Œå¯¹å†…éƒ¨æ‰€æœ‰å®¹å™¨å‡æœ‰æ•ˆ
   runAsUser <integer>                   # ä»¥æŒ‡å®šçš„ç”¨æˆ·èº«ä»½è¿è¡Œå®¹å™¨è¿›ç¨‹ï¼Œé»˜è®¤ç”±é•œåƒä¸­çš„USERæŒ‡å®š
   runAsGroup <integer>                  # ä»¥æŒ‡å®šçš„ç”¨æˆ·ç»„è¿è¡Œå®¹å™¨è¿›ç¨‹ï¼Œé»˜è®¤ä½¿ç”¨çš„ç»„éšå®¹å™¨è¿è¡Œæ—¶
   supplementalGroups <[]integer>        # ä¸ºå®¹å™¨ä¸­1å·è¿›ç¨‹çš„ç”¨æˆ·æ·»åŠ çš„é™„åŠ ç»„ï¼›
   fsGroup <integer>                     # ä¸ºå®¹å™¨ä¸­çš„1å·è¿›ç¨‹é™„åŠ çš„ä¸€ä¸ªä¸“ç”¨ç»„ï¼Œå…¶åŠŸèƒ½ç±»ä¼¼äºsgid
   runAsNonRoot <boolean>                # æ˜¯å¦ä»¥érootèº«ä»½è¿è¡Œ
   seLinuxOptions <Object>               # SELinuxçš„ç›¸å…³é…ç½®
   sysctls <[]Object>                    # åº”ç”¨åˆ°å½“å‰Podä¸Šçš„åç§°æˆ–ç½‘ç»œç©ºé—´çº§åˆ«çš„sysctlå‚æ•°è®¾ç½®åˆ—è¡¨
   windowsOptions <Object>               # Windowså®¹å™¨ä¸“ç”¨çš„è®¾ç½®
 containers:
  - name: â€¦
   image: â€¦
   securityContext:                      # å®¹å™¨çº§åˆ«çš„å®‰å…¨ä¸Šä¸‹æ–‡ï¼Œä»…ç”Ÿæ•ˆäºå½“å‰å®¹å™¨
     runAsUser <integer>                 # ä»¥æŒ‡å®šçš„ç”¨æˆ·èº«ä»½è¿è¡Œå®¹å™¨è¿›ç¨‹
     runAsGroup <integer>                # ä»¥æŒ‡å®šçš„ç”¨æˆ·ç»„è¿è¡Œå®¹å™¨è¿›ç¨‹
     runAsNonRoot <boolean>              # æ˜¯å¦ä»¥érootèº«ä»½è¿è¡Œ
     allowPrivilegeEscalation <boolean>  # æ˜¯å¦å…è®¸ç‰¹æƒå‡çº§
     readOnlyRootFilesystem <boolean>    # æ˜¯å¦è®¾ç½®rootfsåªè¯»
     capabilities <Object>               # äºå½“å‰å®¹å™¨ä¸Šæ·»åŠ ï¼ˆaddï¼‰æˆ–åˆ é™¤ï¼ˆdropï¼‰çš„æ“ä½œå†…æ ¸æŸäº›èµ„æºçš„èƒ½åŠ›
       add <[]string>                    # æ·»åŠ ç”±åˆ—è¡¨æ ¼å¼å®šä¹‰çš„å„å†…æ ¸èƒ½åŠ›
       drop <[]string>                   # ç§»é™¤ç”±åˆ—è¡¨æ ¼å¼å®šä¹‰çš„å„å†…æ ¸èƒ½åŠ›
     privileged <boolean>                # æ˜¯å¦è¿è¡Œä¸ºç‰¹æƒå®¹å™¨
     procMount <string>                  # è®¾ç½®å®¹å™¨çš„procMountç±»å‹ï¼Œé»˜è®¤ä¸ºDefaultProcMountï¼›
     readOnlyRootFilesystem <boolean>    # æ˜¯å¦å°†æ ¹æ–‡ä»¶ç³»ç»Ÿè®¾ç½®ä¸ºåªè¯»æ¨¡å¼
     seLinuxOptions <Object>             # SELinuxçš„ç›¸å…³é…ç½®
     windowsOptions <Object>             # windowså®¹å™¨ä¸“ç”¨çš„è®¾ç½®   
     
#æ³¨æ„ï¼šä¸Šé¢çš„å±æ€§ä»…æ˜¯æœ€å¸¸ç”¨çš„å±æ€§ï¼Œè€Œä¸æ˜¯æ‰€æœ‰çš„å±æ€§
```



##### èµ„æºç­–ç•¥

**ç”¨æˆ·çº§åˆ«**

é»˜è®¤Podçš„å®¹å™¨è¿›ç¨‹æ˜¯ä»¥rootèº«ä»½è¿è¡Œï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢å±æ€§æŒ‡å®šå…¶å®ƒç”¨æˆ·

ä½†æ­¤rootç”¨æˆ·åªå…·æœ‰å¯¹å®¹å™¨å†…çš„ç›¸å…³èµ„æºæ¯”å¦‚æ–‡ä»¶ç³»ç»Ÿç­‰æœ‰ç®¡ç†æƒé™ï¼Œå¯¹äºå®¿ä¸»æœºçš„å†…æ ¸ä¸å…·æœ‰ç®¡ç†æƒ é™ï¼Œå³æ˜¯ä¸ª**â€œä¼ª"rootç”¨æˆ·**

ç›¸å…³çš„å±æ€§: 

- runAsUser
- runAsGroup



èŒƒä¾‹ï¼šé»˜è®¤rootèº«ä»½è¿è¡ŒPodå†…çš„è¿›ç¨‹

```yaml
# cat pod-test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-test
spec:
  containers:
  - name: pod-test
  image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
  
# kubectl apply -f pod-test.yaml

# æŸ¥çœ‹ç”¨æˆ·
# kubectl exec pod-test -- id
uid=0(root) gid=0(root) 
groups=0(root),1(bin),2(daemon),3(sys),4(adm),6(disk),10(wheel),11(floppy),20(dialout),26(tape),27(video)

# æ³¨æ„ï¼šé»˜è®¤æƒ…å†µä¸‹ä¸€æ—¦Podåˆ›å»ºå¥½åï¼Œæ˜¯ä¸å…è®¸å¯¹ç”¨æˆ·å½’å±æƒé™è¿›è¡Œä»»æ„ä¿®æ”¹çš„ï¼Œæ‰€ä»¥éœ€è¦ä¿®æ”¹çš„è¯ï¼Œå¿…é¡»å…ˆå…³é—­ï¼Œå†å¼€å¯
```



èŒƒä¾‹ï¼šæ·»åŠ å®‰å…¨ä¸Šä¸‹æ–‡å±æ€§å®ç°**æŒ‡å®šç”¨æˆ·èº«ä»½è¿è¡ŒPodå†…è¿›ç¨‹**

```yaml
# cat pod-securitycontext-runasuser.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-securitycontext-runasuser
  namespace: default
spec:
  containers:
  - name: pod-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
    env:
    - name: PORT
      value: "8080"
    securityContext:
      runasuser: 1001     # æŒ‡å®šè¿è¡Œèº«ä»½
      runAsGroup: 1001
```



##### èµ„æºèƒ½åŠ›

åœ¨ Linux ä¸­ï¼Œ**root ç”¨æˆ·ï¼ˆUID 0ï¼‰** é»˜è®¤æ‹¥æœ‰æ‰€æœ‰æƒé™ï¼Œä½†åœ¨å®¹å™¨åŒ–ç¯å¢ƒï¼ˆå¦‚ Kubernetesï¼‰ä¸­ï¼Œä¸ºäº†**å®‰å…¨æ€§**ï¼Œå®¹å™¨é»˜è®¤ä¼šå‰¥å¤ºéƒ¨åˆ† `root` ç”¨æˆ·çš„ç‰¹æƒï¼Œç¡®ä¿å®¹å™¨æ— æ³•å¯¹å®¿ä¸»æœºé€ æˆå¨èƒã€‚

```bash
CAP_CHOWN                  #æ”¹å˜æ–‡ä»¶çš„æ‰€æœ‰è€…å’Œæ‰€å±ç»„   
CAP_MKNOD                  #mknod()ï¼Œåˆ›å»ºè®¾å¤‡æ–‡ä»¶  
CAP_NET_ADMIN              #ç½‘ç»œç®¡ç†æƒé™
CAP_SYS_TIME               #æ›´æ”¹ç³»ç»Ÿçš„æ—¶é’Ÿ
CAP_SYS_MODULE             #è£…è½½å¸è½½å†…æ ¸æ¨¡å—
CAP_NET_BIND_SERVERï¼š      #å…è®¸æ™®é€šç”¨æˆ·ç»‘å®š1024ä»¥å†…çš„ç‰¹æƒç«¯å£
CAP_SYS_ADMIN              #å¤§éƒ¨åˆ†çš„ç®¡ç†æƒé™,åŸºæœ¬ç›¸å½“äºrootæƒ
```



èŒƒä¾‹ï¼šé»˜è®¤èƒ½åŠ›æ— æ³•ç›´æ¥åˆ›å»ºiptablesè§„åˆ™

```yaml
# cat pod-securitycontext-capabailities.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-securitycontext-capabilities
  namespace: default
spec:
  containers:
  - name: pod-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
    command: ["/bin/sh", "-c"]
    args: ["/sbin/iptables -t nat -A PREROUTING -p tcp --dport 8080 -j REDIRECT --to-port 80 && /usr/bin/python3 /usr/local/bin/demo.py"]

# æ³¨æ„ï¼šå¯ä»¥åœ¨å®¹å™¨å†…éƒ¨é€šè¿‡command + argsè¿è¡Œä¸€ä¸ªè‡ªå®šä¹‰çš„å®¹å™¨å¯åŠ¨å‘½ä»¤

# åˆ›å»ºèµ„æº
kubectl apply -f pod-securitycontext-capabilities.yaml

# æ£€æŸ¥æ•ˆæœ
kubectl get pod pod-securitycontext-capabilities
NAME                               READY   STATUS   RESTARTS     AGE
pod-securitycontext-capabilities   0/1     Error    2 (30s ago)   67s

[root@master1 ~]#kubectl logs pod-securitycontext-capabilities 
getsockopt failed strangely: Operation not permitted
#ç»“æœæç¤ºï¼šå½“å®¹å™¨åœ¨å¯åŠ¨çš„æ—¶å€™ï¼Œé»˜è®¤æ˜¯ä»¥linuxç³»ç»Ÿæ™®é€šç”¨æˆ·å¯åŠ¨çš„ï¼Œæ‰€ä»¥æ™®é€šç”¨æˆ·æ˜¯æ²¡æœ‰æƒé™æ›´æ”¹ç³»ç»Ÿçº§åˆ«çš„å†…å®¹çš„ï¼Œæ‰€ä»¥å¯¼è‡´æˆ‘ä»¬æ›´æ”¹å‘½ä»¤æƒé™å¤±è´¥
```



èŒƒä¾‹ï¼šé€šè¿‡æ·»åŠ addæŒ‡ä»¤æ·»åŠ ç‰¹æƒ

```yaml
# cat pod-securitycontext-capabilities.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-securitycontext-capabilities
  namespace: default
spec:
  containers:
  - name: pod-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
    command: ["/bin/sh", "-c"]
    args: ["/sbin/iptables -t nat -A PREROUTING -p tcp --dport 8080 -j REDIRECT --to-port 80 && /usr/bin/python3 /usr/local/bin/demo.py"]
    # æ·»åŠ ä¸‹é¢ä¸‰è¡Œ
    securityContext:
      capailities:
        add: ['NET_ADMIN']
        
# æ³¨æ„ï¼šaddåé¢çš„æƒé™èƒ½åŠ›ä½¿ç”¨å•å¼•å·(''),ä¹Ÿå¯ä»¥ä½¿ç”¨åŒå¼•å·("")
```



èŒƒä¾‹: ä½¿ç”¨ drop æŒ‡ä»¤åˆ é™¤ç‰¹æƒ

```yaml
# cat pod-securitycontext-capabilities.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-securitycontext-capabilities
  namespace: default
spec:
  containers:
  - name: pod-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
    command: ["/bin/sh", "-c"]
    args: ["/sbin/iptables -t nat -A PREROUTING -p tcp --dport 8080 -j REDIRECT --to-port 80 && /usr/bin/python3 /usr/local/bin/demo.py"]
    securityContext:
      capabilities:
        add: ['NET_ADMIN']
        drop: ['CHOWN'] # æ·»åŠ æ­¤è¡Œ
        
# åº”ç”¨é…ç½®
kubectl apply -f pod-securitycontext-capabilities.yaml

# éªŒè¯ç»“æœ
#kubectl exec pod-securitycontext-capabilities   -- chown 1001:1001 /etc/hosts

#kubectl exec pod-securitycontext-capabilities   -- ls -l /etc/hosts
-rw-r--r--    1 root     root           228 Mar 17 07:22 /etc/hosts
#ç»“æœæ˜¾ç¤ºï¼šæ–‡ä»¶æƒé™ä¸èƒ½éšæ„çš„æ›´æ”¹äº†
```



##### æ·»åŠ ç‰¹æƒæ¨¡å¼ï¼šPrivileged æ¨¡å¼

åœ¨æŸäº›åœºæ™¯ä¸‹ï¼Œå¦‚æœéœ€è¦å®¹å™¨å…·å¤‡**å®Œå…¨çš„ root æƒé™**ï¼Œå¯ä»¥å°†å®¹å™¨è¿è¡Œåœ¨**ç‰¹æƒæ¨¡å¼**ä¸‹ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: privileged-pod
spec:
  containers:
  - name: test-container
    image: nginx
    securityContext:
      privileged: true  # è¿è¡Œåœ¨ç‰¹æƒæ¨¡å¼
```

**æ³¨æ„**ï¼š

- `privileged: true` ä¼šæˆäºˆå®¹å™¨ **æ‰€æœ‰ Linux èƒ½åŠ›**ï¼ŒåŒ…æ‹¬ `SYS_ADMIN`ã€`NET_ADMIN` ç­‰ã€‚
- ç‰¹æƒæ¨¡å¼å¯èƒ½ä¼šå¼•å‘**å®‰å…¨é£é™©**ï¼Œåº”è°¨æ…ä½¿ç”¨ã€‚



##### å†…æ ¸å‚æ•°

**Kubernetes å†…æ ¸å‚æ•°ç®¡ç†æœºåˆ¶**

Kubernetes é€šè¿‡ **`sysctl`** æ¥ç®¡ç†å’Œä¿®æ”¹å†…æ ¸å‚æ•°ã€‚ç”±äº `sysctl` ä¿®æ”¹çš„æ˜¯æ“ä½œç³»ç»Ÿå†…æ ¸çš„å…¨å±€é…ç½®ï¼Œä½œç”¨èŒƒå›´æ˜¯æ•´ä¸ª **Linux å‘½åç©ºé—´**ï¼Œå› æ­¤ï¼š

- **Pod å†…çš„æ‰€æœ‰å®¹å™¨å…±äº«ç›¸åŒçš„å†…æ ¸å‘½åç©ºé—´**ã€‚
- **æ— æ³•é’ˆå¯¹å•ä¸ªå®¹å™¨** ä¿®æ”¹ç‹¬ç«‹çš„å†…æ ¸å‚æ•°ï¼Œå› ä¸ºåŒä¸€ Pod å†…çš„å®¹å™¨ä½¿ç”¨ç›¸åŒçš„ **Linux å†…æ ¸å‘½åç©ºé—´**ã€‚



**ä¸ºä»€ä¹ˆåªèƒ½åœ¨ Pod çº§åˆ«ä¿®æ”¹ï¼Ÿ**

**åŸå› ï¼šå‘½åç©ºé—´çš„å…±äº«**

åœ¨ Kubernetes ä¸­ï¼ŒPod æ˜¯ç”±ä¸€ç»„å®¹å™¨ç»„æˆçš„ï¼Œå®ƒä»¬å…±äº«ä»¥ä¸‹èµ„æºï¼š

- **å†…æ ¸å‘½åç©ºé—´ï¼ˆKernel Namespaceï¼‰**ï¼šsysctl å‚æ•°å±äºå…¨å±€æˆ–å‘½åç©ºé—´çº§åˆ«ã€‚
- **ç½‘ç»œå‘½åç©ºé—´ï¼ˆNet Namespaceï¼‰**ï¼šPod çº§åˆ«çš„ç½‘ç»œæ ˆã€‚
- **PID å‘½åç©ºé—´**ï¼šPod å†…çš„æ‰€æœ‰è¿›ç¨‹å…±äº« PID ç©ºé—´ã€‚

**å½±å“**

- å¦‚æœä¿®æ”¹äº†ä¸€ä¸ª Pod çš„å†…æ ¸å‚æ•°ï¼Œé‚£ä¹ˆ Pod å†…çš„æ‰€æœ‰å®¹å™¨éƒ½ä¼šå—åˆ°å½±å“ã€‚
- Kubernetes æ²¡æœ‰ä¸ºå•ä¸ªå®¹å™¨æä¾›ç‹¬ç«‹çš„å†…æ ¸å‘½åç©ºé—´ï¼Œå› æ­¤æ— æ³•é’ˆå¯¹å•ä¸ªå®¹å™¨è¿›è¡Œå†…æ ¸å‚æ•°çš„ä¿®æ”¹ã€‚





**å¦‚ä½•åœ¨ Pod çº§åˆ«ä¿®æ”¹å†…æ ¸å‚æ•°ï¼Ÿ**

Kubernetes æä¾›äº† **`sysctl` æ”¯æŒ** æ¥è®¾ç½® Pod çº§åˆ«çš„å†…æ ¸å‚æ•°ï¼Œå¯ä»¥é€šè¿‡ `securityContext` ä¸­çš„ **`sysctls` å­—æ®µ** è¿›è¡Œé…ç½®ã€‚

**ç¤ºä¾‹ï¼šPod çº§åˆ«ä¿®æ”¹å†…æ ¸å‚æ•°**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sysctl-example
spec:
  securityContext:
    sysctls:                # Pod çº§åˆ«çš„ sysctl é…ç½®
    - name: net.core.somaxconn
      value: "1024"
    - name: net.ipv4.tcp_syncookies
      value: "1"
  containers:
  - name: nginx
    image: nginx
```

**è§£é‡Š**ï¼š

- **`securityContext.sysctls`**ï¼šåœ¨ Pod çº§åˆ«è®¾ç½®å†…æ ¸å‚æ•°ã€‚
- ä¿®æ”¹çš„å†…æ ¸å‚æ•°å¦‚ `net.core.somaxconn` å’Œ `net.ipv4.tcp_syncookies`ï¼Œä¼šä½œç”¨äºæ•´ä¸ª Podï¼Œè€Œéå•ä¸ªå®¹å™¨ã€‚



**æ”¯æŒçš„ sysctl å‚æ•°**

Kubernetes ä¸­çš„ sysctl å‚æ•°åˆ†ä¸º **å®‰å…¨ï¼ˆsafeï¼‰** å’Œ **ä¸å®‰å…¨ï¼ˆunsafeï¼‰** ä¸¤ç±»ï¼š

1. **å®‰å…¨å‚æ•°**ï¼ˆSafe Sysctlsï¼‰ï¼š

   - è¿™äº›å‚æ•°ä½œç”¨èŒƒå›´é™åˆ¶åœ¨ Pod çš„ç½‘ç»œæˆ– IPC å‘½åç©ºé—´å†…ã€‚
   - ç¤ºä¾‹å‚æ•°ï¼š
     - `net.ipv4.tcp_syncookies`
     - `net.ipv4.ip_unprivileged_port_start`
     - `net.core.somaxconn`
     - `net.ipv4.ping_group_range`

2. **ä¸å®‰å…¨å‚æ•°**ï¼ˆUnsafe Sysctlsï¼‰ï¼š

   - è¿™äº›å‚æ•°å¯èƒ½å½±å“æ•´ä¸ªèŠ‚ç‚¹ï¼Œå¯èƒ½ä¼šå¼•å‘å®‰å…¨é£é™©ã€‚

   - éœ€è¦åœ¨ kubelet å¯åŠ¨æ—¶æ·»åŠ å‚æ•°å¯ç”¨ï¼š

     ```bash
     kubelet --allowed-unsafe-sysctls='kernel.*,net.*'
     ```





#### PodæœåŠ¡è´¨é‡QoS

#### æœåŠ¡è´¨é‡åˆ†ç±»

QoSï¼ˆæœåŠ¡è´¨é‡ç­‰çº§ï¼‰æ˜¯ä½œç”¨åœ¨Podä¸Šçš„ä¸€ä¸ªé…ç½®

å½“Kubernetesåˆ›å»ºä¸€ä¸ªPodæ—¶ï¼Œå®ƒå°±ä¼šç»™è¿™ä¸ªPodåˆ†é…ä¸€ä¸ªQoSç­‰çº§



QoSä¸‰ä¸ªç­‰çº§ï¼ˆå›¾ä¾‹ï¼‰

![image-20241219100140277](../markdown_img/image-20241219100140277.png)





- ä½ä¼˜å…ˆçº§BestEffortï¼šæ²¡æœ‰ä»»ä½•ä¸€ä¸ªå®¹å™¨è®¾ç½®äº†requestsæˆ–limitsçš„å±æ€§ã€‚ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
- ä¸­ä¼˜å…ˆçº§Burstableï¼šPodè‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨è®¾ç½®äº†cpuæˆ–å†…å­˜çš„requestså’Œlimitsï¼Œä¸”ä¸ç›¸åŒ

- é«˜ä¼˜å…ˆçº§Guaranteedï¼šPodå†…çš„æ¯ä¸ªå®¹å™¨åŒæ—¶è®¾ç½®äº†CPUå’Œå†…å­˜çš„requestså’Œlimits  è€Œä¸”æ‰€æœ‰å€¼ å¿…é¡»ç›¸ç­‰



**å½“ä¸»æœºå‡ºç°OOMæ—¶,å…ˆåˆ é™¤æœåŠ¡è´¨é‡ä¸ºBestEffortçš„Podï¼Œç„¶ååœ¨åˆ é™¤Burstableï¼ŒQuaranteedæœ€åè¢«åˆ é™¤**





#### Podè®¾è®¡æ¨¡å¼

##### å®¹å™¨è®¾è®¡æ¨¡å¼

åŸºäºå®¹å™¨çš„åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å¸¸ç”¨ä¸‰ç±»è®¾è®¡æ¨¡å¼

- **å•å®¹å™¨æ¨¡å¼**ï¼šå•ä¸€å®¹å™¨å½¢å¼è¿è¡Œçš„åº”ç”¨,æ­¤æ¨¡å¼åº”ç”¨æœ€ä¸ºå¹¿æ³›,ç›¸å½“äºä¸€ä¸ªäºº
- **å•èŠ‚ç‚¹å¤šå®¹å™¨æ¨¡å¼**ï¼šç”±å¼ºè€¦åˆçš„å¤šä¸ªå®¹å™¨ååŒå…±ç”Ÿ,å®¹å™¨ä¹‹é—´å…³ç³»å¯†åˆ‡,é€šå¸¸éœ€è¦å·¥ä½œåœ¨åŒä¸€ä¸ª workerä¸»æœºä¸Š,ç›¸å½“äºä¸€ä¸ªå¤šæˆå‘˜çš„å®¶åº­,**Podå°±æ˜¯æ­¤æ¨¡å¼çš„ä»£è¡¨**
- **å¤šèŠ‚ç‚¹å¤šå®¹å™¨æ¨¡å¼**ï¼šåŸºäºç‰¹å®šéƒ¨ç½²å•å…ƒï¼ˆ Podï¼‰å®ç°åˆ†å¸ƒå¼ç®—æ³•,é€šå¸¸å®¹å™¨é—´éœ€è¦è·¨ç½‘ç»œé€šä¿¡,ç›¸å½“ äºå¤šä¸ªå®¶åº­æ­¤æ¨¡å¼ä¾èµ–äºåº”ç”¨è‡ªèº«çš„å®ç°, ä¾‹å¦‚: MySQLä¸»ä»å¤åˆ¶é›†ç¾¤åˆ†å¸ƒåœ¨ä¸åŒèŠ‚ç‚¹çš„Pod





##### å•èŠ‚ç‚¹å¤šå®¹å™¨æ¨¡å¼



**æ³¨æ„:æ­¤å¤„çš„èŠ‚ç‚¹æŒ‡ä¸€ä¸ªpod,è€ŒéworkerèŠ‚ç‚¹ä¸»æœº**

ä¸€ç§è·¨å®¹å™¨çš„è®¾è®¡æ¨¡å¼ï¼Œç›®çš„æ˜¯åœ¨**å•ä¸ªPodä¹‹ä¸Š**åŒæ—¶**è¿è¡Œå¤šä¸ªå…±ç”Ÿå…³ç³»çš„å®¹å™¨**ï¼Œå› è€Œå®¹å™¨ç®¡ç†ç³»ç»Ÿéœ€è¦ç”±å°†å®ƒä»¬ä½œä¸ºä¸€ä¸ªåŸå­å•ä½è¿›è¡Œç»Ÿä¸€è°ƒåº¦

**Podæ¦‚å¿µå°±æ˜¯è¿™ä¸ªè®¾è®¡æ¨¡å¼çš„å®ç°ä¹‹ä¸€**

ä¸€ä¸ªå®¹å™¨æœ‰å¤šä¸ªå®¹å™¨,åˆ†ä¸ºä¸¤ç±»

- ä¸»å®¹å™¨: å®Œæˆä¸»è¦æ ¸å¿ƒä¸šåŠ¡
- è¾…åŠ©å®¹å™¨: æä¾›è¾…åŠ©åŠŸèƒ½,æ¯”å¦‚ç›‘æ§,å†…æ ¸ä¼˜åŒ–,ä»£ç†ç­‰



**å•èŠ‚ç‚¹å¤šå®¹å™¨æ¨¡å¼çš„å¸¸è§å®ç°**

è¾…åŠ©å®¹å™¨è·Ÿæ®å’Œä¸»å®¹å™¨çš„å…³ç³»,å¯ä»¥ç”±ä¸‹é¢å‡ ç§æ¨¡å¼

- **Init Container æ¨¡å¼**
  - Init Containeræ¨¡å¼åªä¼šå‡ºç°åœ¨å®¹å™¨åˆå§‹åŒ–é˜¶æ®µ
  - Initå®¹å™¨è´Ÿè´£ä»¥ä¸åŒäºä¸»å®¹å™¨çš„ç”Ÿå‘½å‘¨æœŸæ¥å®Œæˆé‚£äº›å¿…è¦çš„åˆå§‹åŒ–ä»»åŠ¡ï¼ŒåŒ…æ‹¬åœ¨æ–‡ä»¶ç³»ç»Ÿä¸Šè®¾ç½®å¿… è¦çš„ç‰¹æ®Šæƒé™ã€æ•°æ®åº“æ¨¡å¼è®¾ç½®æˆ–ä¸ºä¸»åº”ç”¨ç¨‹åºæä¾›åˆå§‹æ•°æ®ç­‰ï¼Œä½†è¿™äº›åˆå§‹åŒ–é€»è¾‘æ— æ³•åŒ…å«åœ¨åº” ç”¨ç¨‹åºçš„é•œåƒæ–‡ä»¶ä¸­ï¼Œæˆ–è€…å‡ºäºå®‰å…¨åŸå› ï¼Œåº”ç”¨ç¨‹åºé•œåƒæ²¡æœ‰æ‰§è¡Œåˆå§‹åŒ–æ´»åŠ¨çš„æƒé™ç­‰ç­‰
  - ä¸€ä¸ªPodä¸­å¯ä»¥åŒæ—¶å®šä¹‰å¤šä¸ªInitå®¹å™¨
  - Initå®¹å™¨éœ€è¦ä¸²è¡Œè¿è¡Œï¼Œä¸”åœ¨**æ‰€æœ‰Initå®¹å™¨å‡æ­£å¸¸ç»ˆæ­¢åï¼Œæ‰èƒ½è¿è¡Œä¸»å®¹å™¨**
  - æ³¨æ„: æ­¤æ¨¡å¼ç”¨`kubectl get pods` æ˜¾ç¤ºä¸€ä¸ªPodåªæœ‰ä¸€ä¸ªå®¹å™¨



- **Sidecar æ¨¡å¼**
  - Sidecaræ¨¡å¼å³è¾¹è½¦(æ‘©æ‰˜è½¦çš„æŒæ–—)æ¨¡å¼
  - Podä¸­çš„åº”ç”¨ç”±ä¸»åº”ç”¨ç¨‹åºï¼ˆé€šå¸¸æ˜¯åŸºäºHTTPåè®®çš„åº”ç”¨ç¨‹åºï¼‰ä»¥åŠä¸€ä¸ªSidecarçš„è¾…åŠ©å®¹å™¨ç»„æˆ Sidecaråšä¸ºè¾…åŠ©å®¹å™¨ç”¨äºä¸ºä¸»å®¹å™¨æä¾›è¾…åŠ©æœåŠ¡ä»¥å¢å¼ºä¸»å®¹å™¨çš„åŠŸèƒ½ï¼Œæ˜¯ä¸»åº”ç”¨ç¨‹åºæ˜¯å¿…ä¸å¯å°‘ çš„ä¸€éƒ¨åˆ†ï¼Œä½†å´æœªå¿…éå¾—è¿è¡Œä¸ºåº”ç”¨çš„ä¸€éƒ¨åˆ†,æ¯”å¦‚ï¼šæœåŠ¡ç½‘æ ¼çš„Envoyä»£ç†, filebeat æ—¥å¿—æ”¶
  - Sidecarå®¹å™¨å¯ä»¥å¯¹å®¢æˆ·ç«¯å’Œä¸»å®¹å™¨ä¹‹é—´çš„æ‰€æœ‰æµé‡è¿›è¡Œå¹²é¢„å’Œç›‘æ§ 
  - å¸¸è§åº”ç”¨åœºæ™¯: ä¸ºä¸»å®¹å™¨æä¾›ä»£ç†æœåŠ¡



- **Ambassador æ¨¡å¼**
  - Ambassadoræ¨¡å¼å³å¤§ä½¿æ¨¡å¼,åŠŸèƒ½ç±»ä¼¼ä¸€å›½çš„å¤§ä½¿
  - Podä¸­çš„åº”ç”¨ç”±**ä¸»åº”ç”¨ç¨‹åºå’Œä¸€ä¸ªAmbassadorå®¹å™¨ç»„æˆ**
  - Ambassadorè¾…åŠ©å®¹å™¨ä»£è¡¨ä¸»å®¹å™¨å‘é€ç½‘ç»œè¯·æ±‚è‡³ç‰¹å®šçš„å¤–éƒ¨ç¯å¢ƒä¸­ï¼Œå› æ­¤å¯ä»¥å°†å…¶è§†ä½œä¸»å®¹å™¨åº” ç”¨çš„â€œå¤§ä½¿â€



- **Adapter æ¨¡å¼**
  - Adapteræ¨¡å¼å³é€‚é…å™¨æ¨¡å¼
  - Podä¸­çš„åº”ç”¨ç”±ä¸»åº”ç”¨ç¨‹åºå’Œä¸€ä¸ªAdapterå®¹å™¨ç»„æˆï¼Œä¸»è¦ä¸ºä»å¤–éƒ¨åº”ç”¨å‘ä¸»åº”ç”¨å®¹å™¨è®¿é—®æä¾›æ”¯ æŒï¼Œå’ŒAmbassador æ¨¡å¼æ–¹å‘ç›¸å
  - Adapterå®¹å™¨ä¸ºä¸»åº”ç”¨ç¨‹åºæä¾›ä¸€è‡´çš„æ¥å£ï¼Œå®ç°æ¨¡å—é‡ç”¨ï¼Œæ”¯æŒä¸»å®¹å™¨åº”ç”¨ç¨‹åºçš„æ ‡å‡†åŒ–å’Œè§„èŒƒ åŒ–è¾“å‡ºä»¥ä¾¿äºä»å¤–éƒ¨æœåŠ¡è¿›è¡Œè®¿é—®
  - Adapterå®¹å™¨å¸®åŠ©ä¸»å®¹å™¨é€šä¿¡è¿‡ç¨‹ä¸­çš„ä¿¡æ¯æ ¼å¼ä¿®æ­£,å°†å®¢æˆ·ç«¯çš„æ•°æ®æ ¼å¼è½¬æ¢æˆä¸»å®¹å™¨èƒ½å¤Ÿè¯†åˆ«çš„ æ•°æ®æ ¼å¼
  - å¸¸è§åº”ç”¨åœºæ™¯: å¤–éƒ¨prometheusæœåŠ¡é€šè¿‡Adapter æ¨¡å¼çš„Exporterå®¹å™¨æŠ“å–nginxå®¹å™¨çš„æ—¥å¿—,ä¸­é—´ Exporteréœ€è¦è½¬æ¢ä¸¤è€…ä¹‹é—´çš„æ ¼å¼   



##### initæ¨¡å¼æ¡ˆä¾‹

```yaml
# cat pod-init-container.yaml

apiVersion: v1
kind: Pod
metadata:
  name: pod-init-container
  namespace: default
spec:
  initContainers:
  - name: iptables-init
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/admin-box:v0.1
    imagePullPolicy: IfNotPresent
    command: ['/bin/bash', '-c']
    args: ['iptables -t nat -A -PREROUTING -p tcp --dport 8000 -j REDIRECT --to-port:80']
    securityContext:
      capabilities:
        add:
        - NET_ADMIN
  containers:
  - name: demo
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    ports:
    - name: http
      containerPort: 80
```



##### sidecaræ¨¡å¼æ¡ˆä¾‹

```yaml
# cat pod-sidecar-test.yaml
apiServer: v1
kind: Pod
metadata:
  name: sidecar-test
spec:
  containers:
  - name: proxy
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/envoy-alpine:v1.14.1
    command: ['sh', '-c', 'sleep 5 && envoy -c /etc/envoy/envoy.yaml']
    lifecycle:
      postStart:
        exec:
          command: ["/bin/sh", "-c", "wget -O /etc/envoy/envoy.yaml http://www.wangxiaochun.com:8888/kubernetes/yaml/envoy.yaml"]
  - name: pod-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    env:
    - name: HOST
      value: "127.0.0.1"
    - name: PORT
      value: "8000"
```









## Kuberneteså·¥ä½œè´Ÿè½½



**æœ¬ç« å†…å®¹**

- **æ§åˆ¶å™¨åŸç†**
- **æ ‡ç­¾å’Œæ ‡ç­¾é€‰æ‹©å™¨**
- **Replica Set**
- **Deployment**
- **DaemonSet**
- **Job**
- **CronJob**



### æ§åˆ¶å™¨åŸç†

#### èµ„æºå¯¹è±¡

![image-20241220154542565](../markdown_img/image-20241220154542565.png)



å¯¹äºKubernetes é›†ç¾¤åº”ç”¨æ¥è¯´ï¼Œæ‰€æœ‰çš„ç¨‹åºåº”ç”¨éƒ½æ˜¯

- è¿è¡Œåœ¨ **Pod èµ„æº**å¯¹è±¡é‡Œé¢
- å€ŸåŠ©äº**serviceèµ„æº**å¯¹è±¡å‘å¤–æä¾›æœåŠ¡è®¿é—®
- å€ŸåŠ©äºå„ç§**å­˜å‚¨èµ„æºå¯¹è±¡**å®ç°æ•°æ®çš„å¯æŒä¹…åŒ–
- å€ŸåŠ©äºå„ç§**é…ç½®èµ„æºå¯¹è±¡**å®ç°é…ç½®å±æ€§ã€æ•æ„Ÿä¿¡æ¯çš„ç®¡ç†æ“ä½œ



#### åº”ç”¨ç¼–æ’

åœ¨å·¥ä½œä¸­ä¸ºäº†å®Œæˆå¤§é‡çš„ä¸šåŠ¡ç›®æ ‡ï¼Œé¦–å…ˆä¼šæ ¹æ®ä¸šåŠ¡åº”ç”¨å†…éƒ¨çš„å…³è”å…³ç³»ï¼Œ**æŠŠä¸šåŠ¡æ‹†åˆ†æˆå¤šä¸ªå­ä»»åŠ¡**ï¼Œ ç„¶å**å¯¹è¿™äº›å­ä»»åŠ¡è¿›è¡Œé¡ºåºç»„åˆ**ï¼Œå½“å­ä»»åŠ¡æŒ‰ç…§æ–¹æ¡ˆæ‰§è¡Œå®Œæ¯•åï¼Œå°±å®Œæˆäº†ä¸šåŠ¡ç›®æ ‡ã€‚

ä»»åŠ¡ç¼–æ’å®ç°å°±æ˜¯å¯¹å¤šä¸ªå­ä»»åŠ¡çš„æ‰§è¡Œé¡ºåºè¿›è¡Œç¡®å®šçš„è¿‡ç¨‹ã€‚

å¯¹äºKubernetes æ¥è¯´:

- å¯¹äº**ç´§å¯†ç›¸å…³**çš„å¤šä¸ªå­ä»»åŠ¡ï¼ŒæŠŠå®ƒä»¬æ”¾åˆ°**åŒä¸€ä¸ªpodå†…éƒ¨**
- å¯¹äº**éç´§å¯†å…³è”**çš„å¤šä¸ªä»»åŠ¡ï¼Œåˆ†åˆ«æ”¾åˆ°**ä¸åŒçš„podä¸­**
- ç„¶åå€ŸåŠ©äº**endpoint+service**çš„æ–¹å¼å®ç°å½¼æ­¤ä¹‹é—´çš„ç›¸äº’è°ƒç”¨

- ä¸ºäº†è®©è¿™äº›çº·ä¹±ç¹æ‚çš„ä»»åŠ¡èƒ½å¤Ÿäº’ç›¸å‘ç°ï¼Œé€šè¿‡é›†ç¾¤çš„ **CoreDNS**ç»„ä»¶å®ç°æœåŠ¡æ³¨å†Œå‘ç°åŠŸèƒ½ã€‚



å¯¹äºKubernetesåœºæ™¯ä¸­çš„åº”ç”¨ä»»åŠ¡ï¼Œä¸»è¦å­˜åœ¨éƒ¨ç½²ã€æ‰©å®¹ã€ç¼©å®¹ã€æ›´æ–°ã€å›æ»šç­‰å¸¸è§ç¼–æ’æ“ä½œã€‚

è™½ç„¶åŸºäºpodçš„æ–¹å¼å®ç°äº†åº”ç”¨ä»»åŠ¡çš„éƒ¨ç½²åŠŸèƒ½æ“ä½œï¼Œä½†æ˜¯å¯¹äºè‡ªä¸»å¼çš„podæ¥è¯´ï¼Œå®ƒå¹¶ä¸èƒ½å®ç°å…¶ä»– çš„æ›´å¤šç¼–æ’ä»»åŠ¡ã€‚

å› æ­¤åœ¨Kubernetesé›†ç¾¤çš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸Šï¼Œæœ‰ä¸€ç¾¤éå¸¸é‡è¦çš„ç»„ä»¶ä¸“ç”¨äºå¯¹podå®ç°æ‰€è°“çš„ä»»åŠ¡ç¼–æ’åŠŸ èƒ½ï¼Œè¿™äº›ç»„ä»¶ç»Ÿç»Ÿå°†å…¶ç§°ä¸º**æ§åˆ¶å™¨Controller**ã€‚



**Kubernetesçš„å£°æ˜å¼API**

- ç”¨æˆ·èƒ½å¤Ÿä»¥å£°æ˜å¼å®šä¹‰èµ„æºå¯¹è±¡çš„ç›®æ ‡çŠ¶æ€ï¼Œå³specå­—æ®µ
- ç”±æ§åˆ¶å™¨ä»£ç ï¼ˆæœºå™¨æ™ºèƒ½ç»„ä»¶ï¼‰è´Ÿè´£ç¡®ä¿å®é™…çŠ¶æ€ï¼Œå³**statuså­—æ®µä¸æœŸæœ›çŠ¶æ€specå­—æ®µä¸€è‡´**
- æ§åˆ¶å™¨ç›¸å½“äºâ€œäººå·¥æ™ºèƒ½æœºå™¨äººâ€ï¼Œè´Ÿè´£ç¡®ä¿å„é¡¹å…·ä½“ä»»åŠ¡å¾—ä»¥è½åœ°ï¼Œè€Œæ§åˆ¶å™¨é€šå¸¸ç”±APIçš„æä¾›è€…è´Ÿ è´£å¼€å‘ç¼–å†™
- ç”¨æˆ·éœ€è¦åšçš„æ˜¯æ ¹æ®èµ„æºç±»å‹åŠå…¶æ§åˆ¶å™¨æä¾›çš„DSLï¼ˆé¢†åŸŸç‰¹å®šè¯­è¨€ï¼‰è¿›è¡Œå£°æ˜å¼ç¼–ç¨‹



**Kubernetesçš„æ§åˆ¶å™¨ç±»å‹**

- Kuberneteså†…ç½®æ§åˆ¶å™¨ï¼š
  - Kubernetesé»˜è®¤å°±æä¾›çš„å®ç°åŸºç¡€å‹ã€æ ¸å¿ƒå‹çš„æ§åˆ¶å™¨
  - Controller Managerä¸­å†…ç½®æä¾›äº†è®¸å¤šçš„æ§åˆ¶å™¨ï¼Œä¾‹å¦‚Service Controllerã€DeploymentControllerç­‰
  - ä»¥kube-controller-managerç»„ä»¶çš„ç¨‹åºæ–¹å¼è¿è¡Œå®ç°
- ç¬¬ä¸‰æ–¹æ§åˆ¶å™¨
  - å®ç°é«˜çº§æ§åˆ¶å™¨ï¼Œé€šå¸¸éœ€è¦å€ŸåŠ©äºåŸºç¡€å‹æ§åˆ¶å™¨å®Œæˆå…¶åŠŸèƒ½
  - ä¾‹å¦‚Ingressæ’ä»¶ingress-nginxçš„Controllerï¼Œç½‘ç»œæ’ä»¶Project Calicoçš„Controllerç­‰
  - é€šå¸¸ä»¥Podå½¢å¼æ‰˜ç®¡è¿è¡ŒäºKubernetesä¹‹ä¸Šï¼Œè€Œä¸”è¿™äº›Podå†ç”±å†…ç½®çš„æ§åˆ¶å™¨æ‰€æ§åˆ¶



**æ§åˆ¶å™¨ç§ç±»**

- èŠ‚ç‚¹æ§åˆ¶å™¨(Node Controller): è´Ÿè´£åœ¨èŠ‚ç‚¹å‡ºç°æ•…éšœæ—¶è¿›è¡Œé€šçŸ¥å’Œå“åº”
- ä»»åŠ¡æ§åˆ¶å™¨(Job controller): ç›‘æµ‹ä»£è¡¨ä¸€æ¬¡æ€§ä»»åŠ¡çš„ Job å¯¹è±¡ï¼Œç„¶ååˆ›å»º Pods æ¥è¿è¡Œè¿™äº›ä»»åŠ¡ç›´è‡³å®Œæˆ
- ç«¯ç‚¹æ§åˆ¶å™¨(Endpoints Controller): å¡«å……ç«¯ç‚¹(Endpoints)å¯¹è±¡(å³åŠ å…¥ Service ä¸ Pod)
- æœåŠ¡å¸æˆ·å’Œä»¤ç‰Œæ§åˆ¶å™¨(Service Account & Token Controllers): ä¸ºæ–°çš„å‘½åç©ºé—´åˆ›å»ºé»˜è®¤å¸æˆ·å’Œ API è®¿é—®ä»¤ç‰Œ



**Kubernetes Controllerçš„æ§åˆ¶å›è·¯æœºåˆ¶**

![image-20241220160056338](../markdown_img/image-20241220160056338.png)



- Controlleræ ¹æ®Specï¼Œæ§åˆ¶Systemsç”Ÿæˆå½“å‰å®é™…Status
- Controllerå€ŸåŠ©äºSensoræŒç»­ç›‘è§†Systemçš„Specå’ŒStatusï¼Œåœ¨æ¯ä¸€æ¬¡æ§åˆ¶å›è·¯ä¸­éƒ½ä¼šå¯¹äºŒè€…è¿›è¡Œ æ¯”è¾ƒ
- ç¡®ä¿Systemçš„Statusä¸æ–­é€¼è¿‘æˆ–å®Œå…¨ç­‰åŒSpec



#### Kubernetes Controller æµç¨‹

![image-20241220160149849](../markdown_img/image-20241220160149849.png)

- ç”¨æˆ·å‘ APIserverä¸­æ’å…¥ä¸€ä¸ªåº”ç”¨èµ„æºå¯¹è±¡çš„è¯·æ±‚
- è¿™ä¸ªè¯·æ±‚åŒ…å«çš„æ•°æ®å½¢æ€ä¸­å®šä¹‰äº†è¯¥èµ„æºå¯¹è±¡çš„ "æœŸæœ›"çŠ¶æ€
- æ•°æ®ç»ç”± APIserver ä¿å­˜åˆ° ETCD ä¸­
- kube-controller-manager ä¸­çš„å„ç§æ§åˆ¶å™¨ä¼šç›‘è§† Apiserverä¸Šä¸è‡ªå·±ç›¸å…³çš„èµ„æºå¯¹è±¡çš„å˜åŠ¨ æ¯”å¦‚ Pod Controlleråªè´Ÿè´£Podèµ„æºçš„æ§åˆ¶ï¼ŒService Controlleråªè´Ÿè´£Serviceèµ„æºçš„æ§åˆ¶ç­‰ã€‚
- ä¸€æ—¦API Serverä¸­çš„èµ„æºå¯¹è±¡å‘ç”Ÿå˜åŠ¨ï¼Œå¯¹åº”çš„Controlleræ‰§è¡Œç›¸å…³çš„é…ç½®ä»£ç ï¼Œåˆ°å¯¹åº”çš„nodeèŠ‚ ç‚¹ä¸Šè¿è¡Œ
- è¯¥èµ„æºå¯¹è±¡ä¼šåœ¨å½“å‰èŠ‚ç‚¹ä¸Šï¼ŒæŒ‰ç…§ç”¨æˆ·çš„"æœŸæœ›"è¿›è¡Œè¿è¡Œ
- è¿™äº›å®ä½“å¯¹è±¡çš„è¿è¡ŒçŠ¶æ€ç§°ä¸º "å®é™…çŠ¶æ€"
- å³æ§åˆ¶å™¨çš„ä½œç”¨å°±æ˜¯ç¡®ä¿ "æœŸæœ›çŠ¶æ€" ä¸ "å®é™…çŠ¶æ€" ç›¸ä¸€è‡´
- Controllerå°†è¿™äº›å®é™…çš„èµ„æºå¯¹è±¡çŠ¶æ€ï¼Œé€šè¿‡APIServerå­˜å‚¨åˆ°ETCDçš„åŒä¸€ä¸ªæ•°æ®æ¡ç›®çš„statusçš„ å­—æ®µä¸­
- èµ„æºå¯¹è±¡åœ¨è¿è¡Œè¿‡ç¨‹ä¸­ï¼ŒController ä¼šå¾ªç¯çš„æ–¹å¼å‘ APIServer ç›‘æ§ spec å’Œ status çš„å€¼æ˜¯å¦ä¸€è‡´
- å¦‚æœä¸¤ä¸ªçŠ¶æ€ä¸ä¸€è‡´ï¼Œé‚£ä¹ˆå°±æŒ‡æŒ¥nodeèŠ‚ç‚¹çš„èµ„æºè¿›è¡Œä¿®æ”¹ï¼Œä¿è¯ä¸¤ä¸ªçŠ¶æ€ä¸€è‡´
- çŠ¶æ€ä¸€è‡´åï¼Œé€šè¿‡APIServeråŒæ­¥æ›´æ–°å½“å‰èµ„æºå¯¹è±¡åœ¨ETCDä¸Šçš„æ•°æ®



### å·¥ä½œè´Ÿè½½èµ„æº

å·¥ä½œè´Ÿè½½æ˜¯åœ¨ Kubernetes ä¸Šè¿è¡Œçš„åº”ç”¨ç¨‹åºã€‚

ä¸ºäº†å‡è½»ç”¨æˆ·çš„ä½¿ç”¨è´Ÿæ‹…ï¼Œé€šå¸¸ä¸éœ€è¦ç”¨æˆ·ç›´æ¥ç®¡ç†æ¯ä¸ª Pod ã€‚ è€Œæ˜¯**ä½¿ç”¨è´Ÿè½½èµ„æºæ¥æ›¿ç”¨æˆ·ç®¡ç† ä¸€ç»„ Pod**ã€‚ è¿™äº›è´Ÿè½½èµ„æºé€šè¿‡å¯¹åº”çš„é…ç½®æ§åˆ¶å™¨æ¥ç¡®ä¿æ­£ç¡®ç±»å‹çš„ã€å¤„äºè¿è¡ŒçŠ¶æ€çš„ Pod ä¸ªæ•°æ˜¯æ­£ç¡® çš„ï¼Œä¸ç”¨æˆ·æ‰€æŒ‡å®šçš„çŠ¶æ€ç›¸ä¸€è‡´ã€‚

ä»¥ç¼–æ’PodåŒ–è¿è¡Œçš„åº”ç”¨ä¸ºæ ¸å¿ƒçš„æ§åˆ¶å™¨ï¼Œé€šå¸¸è¢«ç»Ÿç§°ä¸ºå·¥ä½œè´Ÿè½½å‹æ§åˆ¶å™¨ï¼Œç”¨äºç®¡ç†ä¸ä¹‹åŒåçš„å·¥ä½œè´Ÿè½½å‹èµ„æºç±»å‹çš„èµ„æºå¯¹è±¡



**Kubernetes æä¾›è‹¥å¹²ç§å†…ç½®çš„å·¥ä½œè´Ÿè½½èµ„æºï¼š**

- **æ— çŠ¶æ€åº”ç”¨ç¼–æ’**: Deployment å’Œ ReplicaSet ï¼ˆæ›¿æ¢åŸæ¥çš„èµ„æº ReplicationControllerï¼‰ã€‚ Deployment å¾ˆé€‚åˆç”¨æ¥ç®¡ç†ä½ çš„é›†ç¾¤ä¸Šçš„æ— çŠ¶æ€åº”ç”¨ï¼Œ Deployment ä¸­çš„æ‰€æœ‰ Pod éƒ½æ˜¯ç›¸äº’ç­‰ä»·çš„ï¼Œå¹¶ä¸”åœ¨éœ€è¦çš„æ—¶å€™è¢«æ›¿æ¢ã€‚
- **æœ‰çŠ¶æ€åº”ç”¨ç¼–æ’**:StatefulSet è®©ä½ èƒ½å¤Ÿè¿è¡Œä¸€ä¸ªæˆ–è€…å¤šä¸ªä»¥æŸç§æ–¹å¼è·Ÿè¸ªåº”ç”¨çŠ¶æ€çš„ Podã€‚ ä¾‹å¦‚ï¼Œ å¦‚æœä½ çš„è´Ÿè½½ä¼šå°†æ•°æ®ä½œæŒä¹…å­˜å‚¨ï¼Œä½ å¯ä»¥è¿è¡Œä¸€ä¸ª StatefulSet ï¼Œå°†æ¯ä¸ª Pod ä¸æŸä¸ª PersistentVolume å¯¹åº”èµ·æ¥ã€‚ä½ åœ¨ StatefulSet ä¸­å„ä¸ª Pod å†…è¿è¡Œçš„ä»£ç å¯ä»¥å°†æ•°æ®å¤åˆ¶åˆ° åŒä¸€ StatefulSet ä¸­çš„å…¶å®ƒ Pod ä¸­ä»¥æé«˜æ•´ä½“çš„æœåŠ¡å¯é æ€§ã€‚
- **ç³»ç»Ÿçº§åº”ç”¨**:DaemonSet å®šä¹‰æä¾›èŠ‚ç‚¹æœ¬åœ°æ”¯æ’‘è®¾æ–½çš„ Pod ã€‚è¿™äº› Pod å¯èƒ½å¯¹äºä½ çš„é›†ç¾¤çš„è¿ç»´ æ˜¯ éå¸¸é‡è¦çš„ï¼Œä¾‹å¦‚ä½œä¸ºç½‘ç»œé“¾æ¥çš„è¾…åŠ©å·¥å…·æˆ–è€…ä½œä¸ºç½‘ç»œ æ’ä»¶ çš„ä¸€éƒ¨åˆ†ç­‰ç­‰ã€‚æ¯æ¬¡ä½ å‘é›†ç¾¤ä¸­ æ·»åŠ ä¸€ä¸ªæ–°èŠ‚ç‚¹æ—¶ï¼Œå¦‚æœè¯¥èŠ‚ç‚¹ä¸æŸ DaemonSet çš„è§„çº¦åŒ¹é…ï¼Œåˆ™æ§åˆ¶å¹³é¢ä¼šä¸ºè¯¥ DaemonSet è°ƒåº¦ä¸€ä¸ª Pod åˆ°è¯¥æ–°èŠ‚ç‚¹ä¸Šè¿è¡Œã€‚
- **ä½œä¸šç±»åº”ç”¨:**Job å’Œ CronJobã€‚ å®šä¹‰ä¸€äº›ä¸€ç›´è¿è¡Œåˆ°ç»“æŸå¹¶åœæ­¢çš„ä»»åŠ¡ã€‚ Job ç”¨æ¥æ‰§è¡Œä¸€æ¬¡æ€§ä»» åŠ¡ï¼Œè€Œ CronJob ç”¨æ¥æ‰§è¡Œçš„æ ¹æ®æ—¶é—´è§„åˆ’åå¤è¿è¡Œçš„ä»»åŠ¡ã€‚



| æ§åˆ¶å™¨                | è§£æ                                                         |
| --------------------- | ------------------------------------------------------------ |
| ReplicationController | æœ€æ—©æœŸçš„Podæ§åˆ¶å™¨ï¼Œç›®å‰å·²è¢«åºŸå¼ƒ                              |
| RelicaSet             | å‰¯æœ¬é›†ï¼Œè´Ÿè´£ç®¡ç†ä¸€ä¸ªåº”ç”¨(Pod)çš„å¤šä¸ªå‰¯æœ¬çŠ¶æ€                  |
| Deployment            | å®ƒä¸ç›´æ¥ç®¡ç†Podï¼Œè€Œæ˜¯å€ŸåŠ©äºReplicaSetæ¥ç®¡ç†Podï¼›æœ€å¸¸ç”¨çš„æ— çŠ¶æ€åº”ç”¨æ§åˆ¶å™¨ |
| DaemonSet             | å®ˆæŠ¤è¿›ç¨‹é›†ï¼Œç”¨äºç¡®ä¿åœ¨æ¯ä¸ªèŠ‚ç‚¹ä»…è¿è¡ŒæŸä¸ªåº”ç”¨çš„ä¸€ä¸ªPodå‰¯æœ¬ã€‚ç”¨äºå®Œæˆç³»ç»Ÿçº§ä»»åŠ¡ |
| Job                   | æœ‰ç»ˆæ­¢æœŸé™çš„ä¸€æ¬¡æ€§ä½œä¸šå¼ä»»åŠ¡ï¼Œè€Œéä¸€ç›´å¤„äºè¿è¡ŒçŠ¶æ€çš„æœåŠ¡è¿›ç¨‹ |
| CronJob               | æœ‰ç»ˆæ­¢æœŸé™çš„å‘¨æœŸæ€§ä½œä¸šå¼ä»»åŠ¡                                 |
| StatefulSet           | åŠŸèƒ½ç±»ä¼¼äºDeploymentï¼Œä½†StatefulSetä¸“ç”¨äºç¼–æ’æœ‰çŠ¶æ€åº”ç”¨      |

æ³¨æ„ï¼š

- å½“å‰ä¸»è¦ apps/v1 ç‰ˆæœ¬ä¸‹çš„æ§åˆ¶å™¨
- æ¯ä¸ªæ§åˆ¶å™¨å¯¹è±¡ä¹Ÿéœ€è¦å¯¹åº”çš„controlleræ¥è¿›è¡Œç®¡ç†



#### **æ§åˆ¶å™¨å’ŒPod**

- æ§åˆ¶å™¨ä¸»è¦æ˜¯é€šè¿‡ç®¡ç†podæ¥å®ç°ä»»åŠ¡çš„ç¼–æ’æ•ˆæœ
- æ§åˆ¶å™¨æ˜¯é€šè¿‡**æ ‡ç­¾æˆ–è€…æ ‡ç­¾é€‰æ‹©å™¨**æ‰¾åˆ°pod
- æ§åˆ¶å™¨å¯¹è±¡ä»…è´Ÿè´£ç¡®ä¿API Serverä¸Šæœ‰ç›¸åº”æ•°é‡çš„ç¬¦åˆæ ‡ç­¾é€‰æ‹©å™¨çš„Podå¯¹è±¡çš„å®šä¹‰
- Pod å¯¹è±¡çš„Statuså¦‚ä½•ä¸Specä¿æŒä¸€è‡´ï¼Œåˆ™è¦ç”±ç›¸åº”èŠ‚ç‚¹ä¸Šçš„kubeletè´Ÿè´£ä¿è¯

![image-20241220162927417](../markdown_img/image-20241220162927417.png)



#### èŠ‚ç‚¹æ§åˆ¶å™¨å’ŒWorkerèŠ‚ç‚¹

![image-20241220163315449](../markdown_img/image-20241220163315449.png)

- èŠ‚ç‚¹æ§åˆ¶å™¨**æ¯é—´éš”5ç§’æ£€æŸ¥ä¸€æ¬¡** Worker èŠ‚ç‚¹çš„çŠ¶æ€
- å¦‚æœèŠ‚ç‚¹æ§åˆ¶å™¨æ²¡æœ‰æ”¶åˆ°æ¥è‡ªWorker èŠ‚ç‚¹çš„å¿ƒè·³ï¼Œåˆ™å°†è¯¥Worker èŠ‚ç‚¹è¢«æ ‡è®°ä¸º**ä¸å¯è¾¾**
- å¦‚æœè¯¥WorkerèŠ‚ç‚¹è¢«æ ‡è®°ä¸ºä¸å¯è¾¾å,èŠ‚ç‚¹æ§åˆ¶å™¨å†**ç­‰å¾…40ç§’å**ä»æ— æ³•å¾—åˆ°æ­¤èŠ‚ç‚¹çš„å¿ƒè·³,å°†è¯¥èŠ‚ç‚¹ æ ‡è®°ä¸º**æ— æ³•è®¿é—®**
- å¦‚æœè¯¥Worker èŠ‚ç‚¹è¢«æ ‡è®°ä¸ºæ— æ³•è®¿é—®å,å†**ç­‰å¾…5åˆ†é’Ÿå,**è¿˜æ²¡æœ‰å¿ƒè·³, èŠ‚ç‚¹æ§åˆ¶å™¨ä¼š**åˆ é™¤å½“å‰ WorkerèŠ‚ç‚¹ä¸Šé¢çš„æ‰€æœ‰pod,å¹¶åœ¨å…¶å®ƒå¯ç”¨çš„WorkerèŠ‚ç‚¹é‡å»ºè¿™äº› pod**





### **æ ‡ç­¾å’Œæ ‡ç­¾é€‰æ‹©å™¨**

#### æ ‡ç­¾è¯´æ˜

Kubernetesé€šè¿‡æ ‡ç­¾æ¥ç®¡ç†å¯¹åº”æˆ–è€…ç›¸å…³è”çš„å„ç§èµ„æºå¯¹è±¡ï¼Œ**Label**æ˜¯kubernetesä¸­çš„æ ¸å¿ƒæ¦‚å¿µä¹‹ä¸€ã€‚

Label ä¸æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„API èµ„æºç±»å‹,ä½†Labelå¯¹è±¡å¯ä»¥å…³è”åˆ°å„ç§èµ„æºå¯¹è±¡ä¸Š

é€šè¿‡å¯¹Labelçš„ç®¡ç†ä»è€Œè¾¾åˆ°å¯¹ç›¸åŒLabelçš„èµ„æºè¿›è¡Œåˆ†ç»„ç®¡ç†ã€åˆ†é…ã€è°ƒåº¦ã€é…ç½®ã€éƒ¨ç½²ç­‰ã€‚

æ ‡ç­¾Label æ˜¯å¯ä»¥é™„åŠ åœ¨ä»»ä½•èµ„æºå¯¹è±¡ä¸Šçš„é”®å€¼å‹å…ƒæ•°æ®,å³**Labelæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªkey/valueé”®å€¼å¯¹**ï¼Œå…¶ä¸­ keyä¸valueç”±ç”¨æˆ·è‡ªå·±æŒ‡å®š

keyé”®æ ‡è¯†ç”±é”®å‰ç¼€å’Œé”®åç»„æˆ,æ ¼å¼ä¸º **[key_prefix/]key_name**



**`kubectl label`** å‘½ä»¤å¯ç®¡ç†å¯¹è±¡çš„æ ‡ç­¾

åˆ›å»ºï¼šLabelé€šå¸¸åœ¨èµ„æºå¯¹è±¡å®šä¹‰æ—¶ç¡®å®šï¼Œä¹Ÿå¯ä»¥åœ¨å¯¹è±¡åˆ›å»ºååŠ¨æ€æ·»åŠ æˆ–è€…åˆ é™¤

ä¸€ä¸ªèµ„æºå¯¹è±¡å¯ä»¥å®šä¹‰å¤šä¸ªLabelï¼ŒåŒä¸€ä¸ªLabel ä¹Ÿå¯ä»¥å…³è”å¤šä¸ªèµ„æºå¯¹è±¡ä¸Šå»



**å¸¸ç”¨æ ‡ç­¾ä½¿ç”¨åœºæ™¯ï¼š**

- ç‰ˆæœ¬æ ‡ç­¾ï¼š"release" : "stable"ï¼Œ"release" : "canary"ï¼Œ"release" : "beta"
- ç¯å¢ƒæ ‡ç­¾ï¼š"environment" : "dev"ï¼Œ"environment" : "qa"ï¼Œ"environment" : "prod"
- åº”ç”¨æ ‡ç­¾ï¼š"app" : "ui"ï¼Œ"app" : "as"ï¼Œ"app" : "pc"ï¼Œ"app" : "sc"
- æ¶æ„å±‚çº§æ ‡ç­¾ï¼š"tier" : "frontend"ï¼Œ"tier" : "backend", "tier" : "cache"
- åˆ†åŒºæ ‡ç­¾ï¼š"partition" : "customerA"ï¼Œ"partition" : "customerB"
- å“æ§çº§åˆ«æ ‡ç­¾ï¼š"track" : "daily"ï¼Œ"track" : "weekly"



#### ç®¡ç†æ ‡ç­¾

å…³äºlabelçš„åˆ›å»ºæ“ä½œä¸»è¦æœ‰ä¸¤ç§ï¼š

- å‘½ä»¤è¡Œæ–¹æ³•
- yamlæ–‡ä»¶æ–¹æ³•



#####  å‘½ä»¤è¡Œæ–¹æ³•

**ç®¡ç†æ ‡ç­¾ï¼š**

```bash
# æ·»åŠ æ ‡ç­¾
kubectl label èµ„æºç±»å‹ èµ„æºåç§° label_name=label_value [label_name=label_value] ...

# ä¿®æ”¹æ ‡ç­¾
kubectl label èµ„æºç±»å‹ èµ„æºåç§° label_name=label_value [label_name=label_value] ... --overwrite[=true]

# åˆ é™¤æ ‡ç­¾
kubectl label èµ„æºç±»å‹ èµ„æºåç§° label_name- [label_name-] ...

# å‚æ•°è¯´æ˜
åŒæ—¶å¢åŠ å¤šä¸ªæ ‡ç­¾ï¼Œåªéœ€è¦åœ¨åé¢å¤šå†™å‡ ä¸ªå°±å¯ä»¥äº†ï¼Œä½¿ç”¨ç©ºæ ¼éš”å¼€
é»˜è®¤æƒ…å†µä¸‹ï¼Œå·²å­˜åœ¨çš„æ ‡ç­¾æ˜¯ä¸èƒ½ä¿®æ”¹çš„ï¼Œä½¿ç”¨ --overwrite=true è¡¨ç¤ºå¼ºåˆ¶è¦†ç›–
label_name=label_valueæ ·å¼å†™æˆ label_name- å³è¡¨ç¤ºåˆ é™¤label
```



**æŸ¥çœ‹æ ‡ç­¾å’ŒæŒ‡å®šæ ‡ç­¾çš„èµ„æº**

```bash
#æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾
kubectl get èµ„æºç±»å‹ [èµ„æºåç§°] --show-labels

#ç¤ºä¾‹:
kubectl get pods --show-labels

#æŸ¥çœ‹æŒ‡å®šæ ‡ç­¾çš„èµ„æº
kubectl get pods -l label_name[=label_value]

# å‚æ•°ï¼š
-l #æŒ‡å®šæ ‡ç­¾æ¡ä»¶ï¼Œè·å–æŒ‡å®šèµ„æºå¯¹è±¡ï¼Œ=è¡¨ç¤ºåŒ¹é…ï¼Œ!= è¡¨ç¤ºä¸åŒ¹é…, å¦‚æœåé¢çš„é€‰æ‹©æ ‡ç­¾æœ‰å¤šä¸ªçš„è¯ï¼Œä½¿ç”¨é€—å·éš”å¼€

# å¦‚æœé’ˆå¯¹æ ‡ç­¾çš„å€¼è¿›è¡ŒèŒƒå›´è¿‡æ»¤çš„è¯ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ ¼å¼ï¼š
-l 'label_name in (value1, value2, value3, ...)'      #åŒ…æ‹¬å…¶ä¸­ä¸€ä¸ªlabel
-l 'label_name notin (value1, value2, value3, ...)'   #ä¸åŒ…æ‹¬å…¶ä¸­ä»»ä½•ä¸€ä¸ªlabel
kube
#æ˜¯å¦å­˜åœ¨labelçš„åˆ¤æ–­
-l 'label_name'    #å­˜åœ¨label
-l '!label_name'   #ä¸å­˜åœ¨label,æ³¨æ„ä½¿ç”¨å•å¼•å·.ä¸æ”¯æŒåŒå¼•å·ã€‘
```



ç¤ºä¾‹

```bash
# æ·»åŠ æ ‡ç­¾
[root@master1 yaml]#kubectl label pod pod-startup-exec type=test
pod/pod-startup-exec labeled

# æŸ¥çœ‹æ ‡ç­¾
[root@master1 yaml]#kubectl get pod --show-labels 
NAME               READY   STATUS    RESTARTS   AGE     LABELS
pod-startup-exec   1/1     Running   0          5h51m   app=pod-startup-exec,type=test

# ä¿®æ”¹æ ‡ç­¾
[root@master1 yaml]#kubectl label pod pod-startup-exec type=proc --overwrite
pod/pod-startup-exec labeled

# æŸ¥çœ‹æ ‡ç­¾
[root@master1 yaml]#kubectl get pod --show-labels 
NAME               READY   STATUS    RESTARTS   AGE     LABELS
pod-startup-exec   1/1     Running   0          5h52m   app=pod-startup-exec,type=proc

# åˆ é™¤æ ‡ç­¾
[root@master1 yaml]#kubectl label pod pod-startup-exec type-
pod/pod-startup-exec unlabeled

# æŸ¥çœ‹æ ‡ç­¾
[root@master1 yaml]#kubectl get pod --show-labels 
NAME               READY   STATUS    RESTARTS   AGE     LABELS
pod-startup-exec   1/1     Running   0          5h53m   app=pod-startup-exec
```



##### yamlæ–¹æ³•

èµ„æºå¯¹è±¡ Label ä¸æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„APIèµ„æºï¼Œéœ€è¦ä¾é™„åœ¨æŸäº›èµ„æºå¯¹è±¡ä¸Šæ‰å¯ä»¥

æ¯”å¦‚ï¼šä¾é™„åœ¨Podï¼ŒServiceï¼ŒDeployment ç­‰å¯¹è±¡ä¸Š

åˆå§‹åŒ–Podèµ„æºå¯¹è±¡åº”ç”¨æ—¶å€™ï¼Œåœ¨èµ„æºå¯¹è±¡çš„å…ƒæ•°æ®metadataå±æ€§ä¸‹æ·»åŠ ä¸€æ¡Labelsé…ç½®ï¼š

åœ¨ç‰¹å®šçš„å±æ€§åé¢æŒ‰ç…§æŒ‡å®šæ–¹å¼å¢åŠ å†…å®¹å³å¯ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```YAML
metadata:
  labels:
    key1: value1
    key2: value2
    ......
    
# æ³¨æ„ï¼šlabelså¤æ•°
```



ç¤ºä¾‹ï¼š

```yaml
# Labelåœ¨ä¹‹å‰çš„Podçš„èµ„æºæ–‡ä»¶ä¸­å®šä¹‰,æ ‡ç­¾çš„å†…å®¹æ˜¯ï¼šapp: nginxå’Œ version: v1.20.0
# cat pod-label-nginx.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-label-nginx
  labels:
    app: nginx
    version: v1.20.0
spec:
  containers:
  - name: pod-label-nginx-container
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    
# æŸ¥çœ‹
[root@master1 yaml]#kubectl get pod --show-labels 
NAME              READY   STATUS    RESTARTS   AGE   LABELS
pod-label-nginx   1/1     Running   0          10s   app=nginx,version=v1.20.0

# æ·»åŠ æ–°label
[root@master1 yaml]# kubectl label pod pod-label-nginx arch=frontend role=proxy
pod/pod-label-nginx labeled

[root@master1 yaml]# kubectl get pod --show-labels 
NAME              READY   STATUS    RESTARTS   AGE    LABELS
pod-label-nginx   1/1     Running   0          111s   app=nginx,arch=frontend,role=proxy,version=v1.20.0

```



#### æ ‡ç­¾é€‰æ‹©å™¨

Labelé™„åŠ åˆ°Kubernetesé›†ç¾¤ä¸­çš„å„ç§èµ„æºå¯¹è±¡ä¸Šï¼Œç›®çš„æ˜¯å¯¹è¿™äº›èµ„æºå¯¹è±¡å¯ä»¥è¿›è¡Œ**åç»­çš„åˆ†ç»„ç®¡ç†** è€Œåˆ†ç»„ç®¡ç†çš„æ ¸å¿ƒå°±æ˜¯ï¼š**æ ‡ç­¾é€‰æ‹©å™¨Label Selector**ã€‚

å¯ä»¥é€šè¿‡Label SelectoræŸ¥è¯¢å’Œç­›é€‰æŸäº›ç‰¹å®šLabelçš„èµ„æºå¯¹è±¡ï¼Œè¿›è€Œå¯ä»¥å¯¹ä»–ä»¬è¿›è¡Œç›¸åº”çš„æ“ä½œç®¡ç†



**æ ‡ç­¾é€‰æ‹©å™¨çš„ä¸»è¦åº”ç”¨åœºæ™¯ï¼š**

ç›‘æ§å…·ä½“çš„Podã€è´Ÿè½½å‡è¡¡è°ƒåº¦ã€å®šå‘è°ƒåº¦ï¼Œå¸¸ç”¨äº Podã€Nodeç­‰èµ„æºå¯¹è±¡

**Label Selector**è·ŸLabelä¸€æ ·ï¼Œä¸èƒ½å•ç‹¬å®šä¹‰ï¼Œå¿…é¡»é™„åŠ åœ¨ä¸€äº›èµ„æºå¯¹è±¡çš„å®šä¹‰æ–‡ä»¶ä¸Šã€‚ä¸€èˆ¬é™„åŠ åœ¨RSï¼Œ Deployment å’ŒServiceç­‰èµ„æºå®šä¹‰æ–‡ä»¶ä¸­ã€‚

Label Selectorä½¿ç”¨æ—¶å€™æœ‰ä¸¤ç§å¸¸è§çš„æ ‡ç­¾é€‰æ‹©ç®—ç¬¦è¡¨è¾¾å¼ï¼š**ç­‰å€¼**å’Œ**é›†åˆ**



##### ç­‰å€¼å’Œä¸ç­‰å€¼

```bash
# ç­‰å€¼
name = nginx                                   # åŒ¹é…æ‰€æœ‰å…·æœ‰æ ‡ç­¾name = nginxçš„èµ„æºå¯¹è±¡
name == nginx                                  # åŒä¸Š
name                                           # è¡¨ç¤ºåŒ¹é…å­˜åœ¨nameæ ‡ç­¾çš„èµ„æºå¯¹è±¡

# ä¸ç­‰å€¼
!name                                          # è¡¨ç¤ºåŒ¹é…ä¸å­˜åœ¨nameæ ‡ç­¾çš„èµ„æºå¯¹è±¡
name != nginx                                  # åŒ¹é…æ‰€æœ‰æ²¡æœ‰nameæ ‡ç­¾æˆ–è€…æ ‡ç­¾nameçš„å€¼ä¸ç­‰äºnginxçš„èµ„æºå¯¹è±¡

# ç¤ºä¾‹ï¼špodè°ƒåº¦åˆ°æŒ‡å®šæ ‡ç­¾çš„NodeèŠ‚ç‚¹ä¸Š
apiVersion: v1
kind: Pod
metadata:
  name: cuda-test
spec:
  containers:
  - name: cuda-test
    image: "registry.k8s.io/cuda-vector-add:v0.1"
    resources:
      limits:
        nvidia.com/gpu: 1
  nodeSelector:
    acclerator: nvidia-tesla-p100
    
# å°†æ‰€æœ‰çš„æœ‰app: myappæ ‡ç­¾çš„podç®¡ç†åœ¨serviceä¸‹
apiVersion: v1
kind: Service
metadata:
  name: service-loadbalancer-lbaas
spec:
  type: LoadBalancer
  externalTrafficPolicy: Local
  selector:
    app: myapp
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
```



##### é›†åˆ

```bash
# ç¤ºä¾‹
env in (dev, test)                # åŒ¹é…æ‰€æœ‰å…·æœ‰æ ‡ç­¾ env = dev æˆ–è€… env = testçš„èµ„æºå¯¹è±¡
name notin (frontend, backent)    # åŒ¹é…æ‰€æœ‰ä¸å…·æœ‰æ ‡ç­¾name=frontendæˆ–è€…name=backendæˆ–è€…æ²¡æœ‰nameæ ‡ç­¾çš„èµ„æºå¯¹è±¡
```



åç»­Kubernetes çš„é›†åˆè¡¨è¾¾å¼åˆå¢åŠ äº†ä¸¤ç§æ–°çš„å†™æ³•ï¼šåŒ¹é…æ ‡ç­¾ã€åŒ¹é…è¡¨è¾¾å¼



##### **åŒ¹é…æ ‡ç­¾ï¼šmatchLabels**

```bash
# åŒ¹é…æ ‡ç­¾
matchLabels:
  name: nginx
  app: myapp
  
# å½“ matchLabels ä¸­æœ‰å¤šä¸ªæ ‡ç­¾æ—¶ï¼Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»æ˜¯é€»è¾‘ä¸ï¼ˆANDï¼‰å…³ç³»

#å¦‚ä¸‹æ‰€ç¤ºï¼š
matchLabels:
 app: frontend
 environment: production
#é‚£ä¹ˆåªæœ‰é‚£äº›æ ‡ç­¾ä¸­åŒæ—¶åŒ…å« app=frontend å’Œ environment=production çš„èµ„æºæ‰ä¼šè¢«é€‰ä¸­ã€‚
```



##### **åŒ¹é…è¡¨è¾¾å¼ matchExpressions**

```bash
#åŒ¹é…è¡¨è¾¾å¼ï¼š
   matchExpressions:
      - {key: name, operator: NotIn, values: [frontend]}
#å½“ matchExpressions ä¸­åŒ…å«å¤šä¸ªæ ‡ç­¾è¡¨è¾¾å¼æ—¶ï¼Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»æ˜¯é€»è¾‘ä¸ï¼ˆANDï¼‰å…³ç³»ã€‚

#å¸¸è§çš„operatoræ“ä½œå±æ€§å€¼æœ‰ï¼š
   Inã€NotInã€Existsã€NotExistsç­‰
   Existså’ŒNotExistæ—¶ï¼Œvalueså¿…é¡»ä¸ºç©ºï¼Œå³ { key: environment, opetator: Exists,values:}
#æ³¨æ„ï¼šè¿™äº›è¡¨è¾¾å¼ä¸€èˆ¬åº”ç”¨åœ¨RSã€RCã€Deploymentç­‰å…¶å®ƒç®¡ç†å¯¹è±¡ä¸­ã€‚

#ç¤ºä¾‹
matchExpressions:
  - key: environment
    operator: In
    values:
      - production
      - staging
  - key: app
    operator: NotIn
    values:
      - test
#é‚£ä¹ˆåªæœ‰é‚£äº›æ ‡ç­¾æ»¡è¶³ä»¥ä¸‹ä¸¤ä¸ªæ¡ä»¶çš„èµ„æºæ‰ä¼šè¢«é€‰ä¸­ï¼š
- æ ‡ç­¾ä¸­ environment çš„å€¼æ˜¯ production æˆ– staging
- æ ‡ç­¾ä¸­ app çš„å€¼ä¸æ˜¯ test
```



#### æ ‡ç­¾é€‰æ‹©å™¨æ“ä½œæ–¹å¼

æ ‡ç­¾é€‰æ‹©å™¨ä¸¤ç§æ–¹å¼

- å‘½ä»¤
- æ–‡ä»¶



##### å‘½ä»¤æ–¹å¼

```bash
kubectl get TYPE -l SELECTOR1[,SELECTOR2,...]
kubectl get TYPE -l SELECTOR1 [-l SELECTOR2] ...

# ç¤ºä¾‹ï¼š
[root@master1 yaml]#kubectl get node -l ai
NAME    STATUS   ROLES    AGE    VERSION
node1   Ready    <none>   2d2h   v1.30.8
```



##### é…ç½®æ–‡ä»¶

```yaml
# åŸºäºç­‰å€¼ï¼Œå¤šä¸ªä¸ºä¸å…³ç³»
selector:
  component: reids
  
# åŸºäºé›†åˆ
selector:
  matchLabels:
    component: redis
  matchExpressions:
    - key: tier            # ç­‰ä»· - { key: tier, operator: In, values: [cache] }
      operator: In
      values: [cache]
    - key: environment     # ç­‰ä»· - { key: environment, operator: NotIn, values: [dev] }
      operator: NotIn
      values: [dev]
```





### Replica Set

####  Replica Set å·¥ä½œæœºåˆ¶

Replica Set æ˜¯Pod æœ€å¸¸ç”¨çš„æ§åˆ¶å™¨

Replica Set å…¶å®æ˜¯å®šä¹‰äº†ä¸€ä¸ªæœŸæœ›çš„åœºæ™¯ï¼ŒRSæœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

è´Ÿè´£ç¼–æ’æ— çŠ¶æ€åº”ç”¨çš„åŸºç¡€æ§åˆ¶å™¨æ˜¯ReplicaSetï¼Œå®šä¹‰ç¼–æ’ä¸€ä¸ªæ— çŠ¶æ€åº”ç”¨ç›¸åº”çš„èµ„æºç±»å‹ä¸»è¦çš„**ä¸‰ä¸ªå…³é”®å±**æ€§å¦‚ä¸‹

- **replicas**ï¼šPodæœŸå¾…çš„å‰¯æœ¬æ•°é‡
- **selector**ï¼šç­›é€‰ç›®æ ‡Podçš„æ ‡ç­¾é€‰æ‹©å™¨,æ”¯æŒmatchExpressionså’ŒmatchLabels
- **template**ï¼šå¦‚æœPodæ•°é‡ä¸æ»¡è¶³é¢„æœŸå€¼ï¼Œè‡ªåŠ¨åˆ›å»ºPodæ—¶å€™ç”¨åˆ°çš„æ¨¡æ¿(template)ï¼Œæ¸…å•æ–‡ä»¶æ ¼å¼ å’Œè‡ªä¸»å¼Podä¸€æ ·

æ„ä¹‰ï¼šè‡ªåŠ¨ç›‘æ§Podè¿è¡Œçš„å‰¯æœ¬æ•°ç›®ç¬¦åˆé¢„æœŸï¼Œä¿è¯Podé«˜å¯ç”¨çš„æ ¸å¿ƒç»„ä»¶ï¼Œå¸¸ç”¨äºPodçš„ç”Ÿå‘½å‘¨æœŸç®¡ç†



**å·¥ä½œæœºåˆ¶**

- å½“é€šè¿‡"èµ„æºå®šä¹‰æ–‡ä»¶"å®šä¹‰å¥½äº†ä¸€ä¸ªRSèµ„æºå¯¹è±¡ï¼ŒæŠŠå®ƒæäº¤åˆ°Kubernetesé›†ç¾¤
- MasterèŠ‚ç‚¹ä¸Šçš„Controller Managerç»„ä»¶å°±å¾—åˆ°é€šçŸ¥
- Controller Manager æ ¹æ® ReplicaSet Control Loop ç®¡ç† ReplicaSet Object
- ç”±è¯¥å¯¹è±¡å‘API Serverè¯·æ±‚ç®¡ç†Podå¯¹è±¡(æ ‡ç­¾é€‰æ‹©å™¨é€‰å®šçš„ï¼‰
- å¦‚æœæ²¡æœ‰podï¼šä»¥**Podæ¨¡æ¿**å‘API Serverè¯·æ±‚åˆ›å»ºPodå¯¹è±¡ï¼Œç”±Schedulerè°ƒåº¦å¹¶ç»‘å®šè‡³æŸèŠ‚ç‚¹ï¼Œç”±ç›¸åº”èŠ‚ç‚¹kubeletè´Ÿè´£è¿è¡Œ
- å®šæœŸå·¡æ£€ç³»ç»Ÿä¸­å½“å‰å­˜æ´»çš„Podï¼Œå¹¶ç¡®ä¿Podå®ä¾‹æ•°é‡åˆšåˆ°æ»¡è¶³RCçš„æœŸæœ›å€¼ã€‚
- å¦‚æœPodæ•°é‡å¤§äºRSå®šä¹‰çš„æœŸæœ›å€¼ï¼Œé‚£ä¹ˆå°±æ€æ­»ä¸€äº›Pod
- å¦‚æœPodæ•°é‡å°äºRSå®šä¹‰çš„æœŸæœ›å€¼ï¼Œé‚£ä¹ˆå°±åˆ›å»ºä¸€äº›Pod
- æ‰€ä»¥é€šè¿‡RSèµ„æºå¯¹è±¡ï¼ŒKuberneteså®ç°äº†ä¸šåŠ¡åº”ç”¨é›†ç¾¤çš„é«˜å¯ç”¨æ€§ï¼Œå¤§å¤§å‡å°‘äº†äººå·¥å¹²é¢„ï¼Œæé«˜äº†ç®¡ç† çš„è‡ªåŠ¨åŒ–ã€‚
- å¦‚æœåç»­æƒ³è¦æ‰©å……Podå‰¯æœ¬çš„æ•°é‡ï¼Œå¯ä»¥ç›´æ¥ä¿®æ”¹replicasçš„å€¼å³å¯
- å½“å…¶ä¸­ä¸€ä¸ªNodeçš„Podæ„å¤–ç»ˆæ­¢ï¼Œæ ¹æ®RSçš„å®šä¹‰ï¼ŒPodçš„æœŸæœ›å€¼æ˜¯2ï¼Œæ‰€ä»¥ä¼šéšæœºæ‰¾ä¸€ä¸ªNodeç»“ç‚¹é‡æ–° å†åˆ›å»ºä¸€ä¸ªæ–°çš„Podï¼Œæ¥ä¿è¯æ•´ä¸ªé›†ç¾¤ä¸­å§‹ç»ˆå­˜åœ¨ä¸¤ä¸ªPodè¿è¡Œ



![image-20241221153308297](../markdown_img/image-20241221153308297.png)



æ³¨æ„ï¼š

- åˆ é™¤RSå¹¶ä¸ä¼šå½±å“é€šè¿‡è¯¥RSèµ„æºå¯¹è±¡åˆ›å»ºå¥½çš„Podã€‚
- å¦‚æœè¦åˆ é™¤æ‰€æœ‰çš„Podé‚£ä¹ˆå¯ä»¥è®¾ç½®RSçš„replicasçš„å€¼ä¸º0ï¼Œç„¶åæ›´æ–°è¯¥RSã€‚
- å¦å¤–kubectlæä¾›äº†stopå’Œdeleteå‘½ä»¤æ¥ä¸€æ¬¡æ€§åˆ é™¤RSå’ŒRSæ§åˆ¶çš„Podã€‚
- Podæä¾›çš„å¦‚æœæ— çŠ¶æ€æœåŠ¡ï¼Œä¸ä¼šå½±å“åˆ°å®¢æˆ·çš„è®¿é—®æ•ˆæœã€‚



RSå¯ä»¥å®ç°åº”ç”¨çš„éƒ¨ç½²ï¼Œæ‰©ç¼©å®¹å’Œå¸è½½ï¼Œä½†ä¸€èˆ¬å¾ˆå°‘å•ç‹¬ä½¿ç”¨ï¼Œå®ƒ**ä¸»è¦æ˜¯è¢«Deploymentè¿™ä¸ªæ›´é«˜å±‚çš„èµ„æºå¯¹è±¡æ‰€ä½¿ç”¨**ï¼Œä»è€Œå½¢æˆäº†ä¸€æ•´å¥—Podçš„åˆ›å»ºã€åˆ é™¤ã€æ›´æ–°çš„ç¼–æ’æœºåˆ¶ã€‚



#### Replica Set èµ„æºæ¸…å•æ–‡ä»¶ç¤ºä¾‹

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: ...                                   # ReplicaSetåç§°ï¼Œç”Ÿæˆçš„Podåç§°ä»¥æ­¤å¤„çš„ReplicaSetåç§°ä¸ºå‰ç¼€+éšæœºå­—ç¬¦
  namespace: ...
spec:
  minReadySeconds <integer>                   # Podå°±ç»ªåå¤šå°‘ç§’å†…ï¼ŒPodä»»ä¸€å®¹å™¨æ— crashæ–¹å¯è§†ä¸ºâ€œå°±ç»ªâ€
  replicas <integer>                          # æœŸæœ›çš„Podå‰¯æœ¬æ•°ï¼Œé»˜è®¤ä¸º1
  selector:                                   # æ ‡ç­¾é€‰æ‹©å™¨ï¼Œå¿…é¡»åŒ¹é…templateå­—æ®µä¸­Podæ¨¡ç‰ˆä¸­çš„æ ‡ç­¾
    matchExpressions <[]Object>
    matchLabels <map[string]String>
  template:                                   # podæ¨¡ç‰ˆå¯¹è±¡
    metadata:                                 # podå¯¹è±¡å…ƒæ•°æ®
      labels:                                 # ç”±æ¨¡ç‰ˆåˆ›å»ºå‡ºçš„Podå¯¹è±¡æ‰€æ‹¥æœ‰çš„æ ‡ç­¾ï¼Œå¿…é¡»è¦èƒ½å¤ŸåŒ¹é…å‰é¢å®šä¹‰çš„æ ‡ç­¾é€‰æ‹©å™¨
    spec:                                     # podè§„èŒƒï¼Œæ ¼å¼åŒè‡ªä¸»å¼Pod
```



#### åˆ›å»ºèµ„æºå¯¹è±¡

```yaml
# cat controller-replicaset.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: controller-replicaset-test
spec:
  minReadySeconds: 0
  replicas: 3
  selector:
    matchLabels:
      app: rs-test
      release: stable
      version: v1.0
  template:
    metadata:
      labels:
        app: rs-test
        release: stable
        version: v1.0
    spec:
      containers:
      - name: rs-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
        
# åˆ›å»º
kubectl apply -f controller-replicaset.yaml

# æŸ¥çœ‹
[root@master1 controller]#kubectl get rs
NAME                         DESIRED   CURRENT   READY   AGE
controller-replicaset-test   3         3         3       50s

[root@master1 controller]#kubectl get pod
NAME                               READY   STATUS    RESTARTS   AGE
controller-replicaset-test-27mmp   1/1     Running   0          57s
controller-replicaset-test-2hf65   1/1     Running   0          57s
controller-replicaset-test-jm29c   1/1     Running   0          57s
pod-label-nginx                    1/1     Running   0          78m
pod-label-nginx2                   1/1     Running   0          50m

```



#### æ‰©å®¹å’Œç¼©å®¹

```yaml
# æ‰©å®¹ï¼šè°ƒæ•´Podå‰¯æœ¬æ•°é‡æ›´å¤š
# æ–¹æ³•1ï¼šä¿®æ”¹æ¸…å•æ–‡ä»¶
[root@master1 controller]#cat controller-replicaset.yaml 
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: controller-replicaset-test
spec:
  minReadySeconds: 0
  replicas: 4                                    # ä¿®æ”¹è¿™é‡Œï¼Œå°†å…¶æ”¹ä¸º4
  selector:
    matchLabels:
      app: rs-test
      release: stable
      version: v1.0
  template:
    metadata:
      labels:
        app: rs-test
        release: stable
        version: v1.0
    spec:
      containers:
      - name: rs-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1

# æŸ¥çœ‹ï¼Œæ•°é‡å˜ä¸º4
[root@master1 controller]#kubectl get po
NAME                               READY   STATUS    RESTARTS   AGE
controller-replicaset-test-27mmp   1/1     Running   0          17m
controller-replicaset-test-2hf65   1/1     Running   0          17m
controller-replicaset-test-85dbn   1/1     Running   0          2m11s
controller-replicaset-test-jm29c   1/1     Running   0          17m


# å‘½ä»¤å¼ï¼Œä½¿ç”¨å‘½ä»¤å°†å…¶ç¼©å‡ä¸º3ä¸ª
[root@master1 controller]#kubectl scale --replicas=3 rs/controller-replicaset-test 
replicaset.apps/controller-replicaset-test scaled

# æŸ¥çœ‹
[root@master1 controller]#kubectl get po
NAME                               READY   STATUS    RESTARTS   AGE
controller-replicaset-test-27mmp   1/1     Running   0          18m
controller-replicaset-test-2hf65   1/1     Running   0          18m
controller-replicaset-test-jm29c   1/1     Running   0          18m
```



æ›´æ–°Podé•œåƒç‰ˆæœ¬

```yaml
# å‡çº§é•œåƒç‰ˆæœ¬
# æ–¹æ³•1ï¼šæ¸…å•æ–‡ä»¶
cat controller-replicaset.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: controller-replicaset-test
spec:
  minReadySeconds: 0
  replicas: 6           # ä¿®æ”¹æ­¤è¡Œï¼ŒåŸpodç‰ˆæœ¬ä¸å˜ï¼Œæ–°podçš„ç‰ˆæœ¬å‘ç”Ÿå˜åŒ–ï¼Œæ›´æ–°ä¸ºv0.2
  selector:
    matchLabels:
      app: rs-test
      release: stable
      version: v1.0
  template:
    metadata:
      labels:
        app: rs-test
        release: stable
        version: v1.0
    spec:
      containers:
      - name: rs-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2  # ä¿®æ”¹æ­¤è¡Œ
```



#### Replica Set ç‰ˆæœ¬å‘å¸ƒ

##### æ»šåŠ¨å‘å¸ƒ

```yaml
# å‡†å¤‡service
# cat svc-controller-replicaset.yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-replicaset
spec:
  type: ClusterIP
  selector:
    app: rs-test
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
    
# å‡†å¤‡æ—§ç‰ˆæœ¬çš„replicasetçš„æ¸…å•æ–‡ä»¶
# cat controller-replicaset-1.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: replicaset-test
spec:
  minReadySeconds: 0
  replicas: 3
  selector:
    matchLabels:
      app: rs-test
      release: stable
      version: v0.1
  template:
    metadata:
      labels:
        app: rs-test
        release: stable
        version: v0.1
    spec:
      containers:
      - name: rs-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1

# å‡†å¤‡æ–°ç‰ˆæœ¬çš„replicasetæ¸…å•æ–‡ä»¶
# cat controller-replicaset-2.yaml
apiVersion: apps/v2
kind: ReplicaSet
metadata:
  name: replicaset-test-2
spec:
  minReadySeconds: 0
  replicas: 0                   # æ³¨æ„æ­¤å¤„ä¸º0
  selector:
    matchLabels:
      app: rs-test
      release: stable
      version: v0.2
  template:
    metadata:
      labels:
        app: rs-test
        release: stable
        version: v0.2
    spec:
      containers:
      - name: rs-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2

# å¯åŠ¨èµ„æº
kubectl apply -f svc-controller-replicaset.yaml
kubectl apply -f controller-replicaset-1.yaml
kubectl apply -f controller-replicaset-2.yaml

# å¯¹æ—§ç‰ˆçš„RSç¼©å®¹ï¼Œå¯¹æ–°ç‰ˆæœ¬çš„RSæ‰©å®¹
[root@master1 controller]# kubectl scale --replicas=2 rs/replicaset-test; kubectl scale --replicas=1 rs/replicaset-test-2
replicaset.apps/replicaset-test scaled
replicaset.apps/replicaset-test-2 scaled

# è§‚å¯Ÿç»“æœ
[root@master1 controller]#kubectl get pod --show-labels 
NAME                      READY   STATUS    RESTARTS      AGE   LABELS
pod-label-nginx           1/1     Running   1 (55m ago)   27h   app=nginx,version=v1.20.0
pod-label-nginx2          1/1     Running   1 (57m ago)   27h   app=nginx,version=v1.20.0
replicaset-test-2-ffh5j   1/1     Running   0             68s   app=rs-test,release=stable,version=v0.2
replicaset-test-2pbdk     1/1     Running   0             11m   app=rs-test,release=stable,version=v0.1
replicaset-test-v8967     1/1     Running   0             11m   app=rs-test,release=stable,version=v0.1


# å†æ¬¡å¯¹æ—§ç‰ˆçš„RSç¼©å®¹,å¯¹æ–°ç‰ˆæœ¬çš„RSæ‰©å®¹
[root@master1 controller]#kubectl scale --replicas=1 rs/replicaset-test; kubectl scale --replicas=2 rs/replicaset-test-2
replicaset.apps/replicaset-test scaled
replicaset.apps/replicaset-test-2 scaled

#æœ€åä¸€æ¬¡å¯¹æ—§ç‰ˆçš„RSç¼©å®¹ä¸º0,å¯¹æ–°ç‰ˆæœ¬çš„RSæ‰©å®¹åˆ°3
[root@master1 ~]#kubectl scale --replicas=0 rs/replicaset-test;kubectl scale -- replicas=3 rs/replicaset-test-2

# ä¸Šè¿°æ‰‹åŠ¨å®ç°æ»šåŠ¨å‡çº§
```



##### è“ç»¿å‘å¸ƒ

```yaml
# cat controller-replicaset-blue-green.yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-replicaset-blue-green
spec:
  type: ClusterIP
  selector:
    app: rs-test
    ctr: rs-${DEPLOY}
    version: ${VERSION}
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
---
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: rs-${DEPLOY}
spec:
  minReadySeconds: 3
  replicas: 2
  selector:
    matchLabels:
      app: rs-test
      ctr: rs-${DEPLOY}
      version: ${VERSION}
  template:
    metadata:
      labels:
        app: rs-test
        ctr: rs-${DEPLOY}
        version: ${VERSION}
    spec:
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:${VERSION}
        
        
# å¼€å¯è“è‰²å‘å¸ƒæ—§ç‰ˆæœ¬
[root@master1 controller]#DEPLOY=blue VERSION=v0.1 envsubst < controller-replicaset-blue-green.yaml |kubectl apply -f -
service/svc-replicaset-blue-green created
replicaset.apps/rs-blue created


# å¼€å¯æµ‹è¯•podè®¿é—®Service
[root@master1 controller]#kubectl run pod-$RANDOM --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/admin-box:v0.1 -it --rm --command -- /bin/bash
If you don't see a command prompt, try pressing enter.
root@pod-3326 /# 
root@pod-3326 /# curl svc-replicaset-blue-green
kubernetes pod-test v0.1!! ClientIP: 10.244.2.26, ServerName: rs-blue-qbmlm, ServerIP: 10.244.3.30!
root@pod-3326 /# curl svc-replicaset-blue-green
kubernetes pod-test v0.1!! ClientIP: 10.244.2.26, ServerName: rs-blue-6hkbt, ServerIP: 10.244.1.25!


# åˆ‡æ¢è‡³ç»¿è‰²ç‰ˆæœ¬
[root@master1 ~]#DEPLOY=green VERSION=v0.2 envsubst < ./yaml/controller/controller-replicaset-blue-green.yaml |kubectl apply -f -
service/svc-replicaset-blue-green configured
replicaset.apps/rs-green created

# æ­¤æ—¶åœ¨æµ‹è¯•podä¸Šè¿›è¡Œæµ‹è¯•
root@pod-3326 /# curl svc-replicaset-blue-green
kubernetes pod-test v0.2!! ClientIP: 10.244.2.26, ServerName: rs-green-m5psl, ServerIP: 10.244.3.31!
root@pod-3326 /# curl svc-replicaset-blue-green
kubernetes pod-test v0.2!! ClientIP: 10.244.2.26, ServerName: rs-green-hlmxv, ServerIP: 10.244.1.26!

# å·²æˆåŠŸåˆ‡æ¢è‡³v0.2ï¼Œæ­¤æ—¶å½“å‰k8sä¸Šæœ‰ä¸¤å¥—rs
[root@master1 controller]#kubectl get rs
NAME       DESIRED   CURRENT   READY   AGE
rs-blue    2         2         2       5m20s
rs-green   2         2         2       87s

# ä¸Šè¿°å°±æ˜¯è“ç»¿å‘
```



### Deployment

#### **Deploymentå·¥ä½œæœºåˆ¶**

**Deployment ä»‹ç»**

Deploymentèµ„æºå¯¹è±¡ä¸€èˆ¬ç”¨äºéƒ¨ç½²**æ— çŠ¶æ€æœåŠ¡**,æ¯”å¦‚ javaåº”ç”¨ï¼ŒWebç­‰ï¼Œè¿™ä¹Ÿæ˜¯æœ€å¸¸ç”¨çš„æ§åˆ¶å™¨

å¯ä»¥ç®¡ç†å¤šä¸ªå‰¯æœ¬çš„Pod, å®ç°æ— ç¼è¿ç§»ã€è‡ªåŠ¨æ‰©å®¹ç¼©å®¹ã€è‡ªåŠ¨ç¾éš¾æ¢å¤ã€ä¸€é”®å›æ»šç­‰åŠŸèƒ½

**Deploymentç›¸å¯¹äºRCæˆ–RSçš„ä¸€ä¸ªæœ€å¤§çš„å‡çº§æ˜¯:æ”¯æŒæ»šåŠ¨å‘å¸ƒç­–ç•¥,å…¶å®ƒåŠŸèƒ½å‡ ä¹ä¸€æ ·**

Deploymentèµ„æºå¯¹è±¡åœ¨å†…éƒ¨ä½¿ç”¨Replica Setæ¥å®ç°Podçš„è‡ªåŠ¨åŒ–ç¼–æ’



**Deploymentå·¥ä½œæµç¨‹**

- åˆ›å»ºDeploymentèµ„æºå¯¹è±¡ï¼Œè‡ªåŠ¨ç”Ÿæˆå¯¹åº”çš„Replicas Setå¹¶å®ŒæˆPodçš„è‡ªåŠ¨ç®¡ç†ï¼Œè€Œæ— éœ€äººä¸ºæ˜¾ç¤ºåˆ›å»º Replicas Set
- æ£€æŸ¥Deploymentå¯¹è±¡çŠ¶æ€ï¼Œæ£€æŸ¥Podè‡ªåŠ¨ç®¡ç†æ•ˆæœ
- æ‰©å±•Deploymentèµ„æºå¯¹è±¡ï¼Œä»¥åº”å¯¹åº”ç”¨ä¸šåŠ¡çš„é«˜å¯ç”¨





#### èµ„æºå¯¹è±¡ Deployment å’Œ Replica Set å…³ç³»

**Deployment æœ¬è´¨ä¸Šæ˜¯ä¾èµ–å¹¶è°ƒç”¨ Replica Set çš„å®Œæˆæ¥åŸºæœ¬çš„ç¼–æ’åŠŸèƒ½ï¼Œå¹¶é¢å¤–æä¾›äº†æ»šåŠ¨æ›´æ–°ï¼Œå›æ»šçš„åŠŸèƒ½**

- å…ˆç”±Deployment åˆ›å»º Replica Set èµ„æºå¯¹è±¡å¹¶è¿›è¡Œç¼–æ’
- å†ç”±Replica Set åˆ›å»ºå¹¶å¯¹ Pod çš„ç¼–æ’
- Deploymentæ˜¯å»ºç«‹åœ¨ReplicaSetæ§åˆ¶å™¨ä¸Šå±‚çš„æ›´é«˜çº§çš„æ§åˆ¶å™¨
- Deployment ä½äºReplicaSetæ›´ä¸Šé¢ä¸€å±‚ï¼ŒåŸºäºReplieaSetï¼Œæä¾›äº†æ»šåŠ¨æ›´æ–°ã€å›æ»šç­‰æ›´ä¸ºå¼ºå¤§çš„ åº”ç”¨ç¼–æ’åŠŸèƒ½
- Deploymentæ˜¯ Replica Set çš„ç¼–æ’å·¥å…·ï¼ŒDeploymentç¼–æ’ReplicaSetï¼ŒReplicaSetç¼–æ’Pod
- Replica Setçš„åç§°ç”±Deploymentåç§°-Templateçš„Hashå€¼ç”Ÿæˆ
- **Deployment å¹¶ä¸ç›´æ¥ç®¡ç† Pod**ï¼Œå¿…é¡»é—´æ¥çš„åˆ©ç”¨ Replica Set æ¥å®Œæˆå¯¹Podçš„ç¼–æ’
- é€šå¸¸åº”è¯¥ç›´æ¥é€šè¿‡å®šä¹‰Deploymentèµ„æºæ¥ç¼–æ’Podåº”ç”¨ï¼Œè€ŒReplicaSetæ— é¡»æ˜¾å¼é…ç½®





#### Deployment çš„èµ„æºå®šä¹‰

Deploymentçš„å®šä¹‰ä¸Replica Setçš„å®šä¹‰ç±»ä¼¼ï¼Œé™¤äº†APIå£°æ˜ä¸Kindç±»å‹æœ‰æ‰€åŒºåˆ«ï¼Œå…¶ä»–åŸºæœ¬ä¸Šéƒ½ä¸€æ ·ã€‚

![image-20241222191629314](../markdown_img/image-20241222191629314.png)



**æ³¨æ„ï¼šDeploymentå¯¹æ»šåŠ¨æ›´æ–°å¤šäº†ä¸€äº›æ›´æ–°ç­–ç•¥çš„åŠŸèƒ½**

```yaml
apiVersion: apps/v1                 # APIç¾¤ç»„åŠç‰ˆæœ¬
kind: Deployment                    # èµ„æºç±»å‹ç‰¹æœ‰æ ‡è¯†
metadata: 
  name: <string>                    # èµ„æºåç§°ï¼Œåœ¨ä½œç”¨åŸŸä¸­è¦å”¯ä¸€ï¼Œç”ŸæˆPodåç§°ï¼šDeployment + Podæ¨¡ç‰ˆHash + éšæœºå­—ç¬¦ä¸²
  namespace: <string>               # åç§°ç©ºé—´ï¼šDeploymentéš¶å±åç§°ç©ºé—´çº§åˆ«
spec:
  minReadySeconds: <integer>
  replicas: <integer>
  selector: <object>
    matchLabels:
      app: <string>
  template: <object>
  revisionHistoryLimit: <integer>    # æ»šåŠ¨æ›´æ–°å†å²è®°å½•æ•°é‡ï¼Œé»˜è®¤ä¸º10ï¼Œå¦‚æœä¸º0è¡¨ç¤ºä¸ä¿ç•™å†å²æ•°æ®
  strategy: <object>                 # æ»šåŠ¨æ›´æ–°ç­–ç•¥
    type: <string>                   # æ»šåŠ¨æ›´æ–°ç±»å‹ï¼Œå¯ç”¨å€¼æœ‰Recreateï¼ˆåˆ é™¤æ‰€æœ‰æ—§POdå†åˆ›å»ºæ–°Podï¼‰å’ŒRollingUpdate     
    rollingUpdate: <Object>          # æ»šåŠ¨æ›´æ–°ç±»å‹ï¼Œä¸“ç”¨äºRollingUpdateç±»å‹ï¼Œé€æ­¥æ›´æ–°ï¼Œå…ˆåˆ›å»ºæ–°Podå†é€æ­¥åˆ é™¤æ—§Pod
      maxSurge: <string>             # æ›´æ–°æœŸé—´å¯æ¯”æœŸæœ›çš„POdæ•°é‡èƒ½å¤Ÿå¤šå‡ºçš„æœ€å¤§æ•°é‡æˆ–æ¯”ä¾‹
      maxUnavaiLabel: <String>       # æ›´æ–°æœŸé—´å¯æ¯”æœŸæœ›çš„Podæ•°é‡èƒ½å¤Ÿç¼ºå°‘çš„æœ€å¤§æ•°é‡æˆ–æ¯”ä¾‹
  progressDeadlineSeconds: <integer> # æ»šåŠ¨æ›´æ–°æ•…éšœè¶…æ—¶æ—¶é•¿ï¼Œé»˜è®¤ä¸º600ç§’
  paused: <boolean>                  # æ˜¯å¦æš‚åœéƒ¨ç½²è¿‡ç¨‹
```





#### Deploymentå®ç°



**å‘½ä»¤è¡Œåˆ›å»ºå¯¹è±¡**

```bash
kubectl create deployment NAME --image=image -- [COMMAND] [args...] [options]
```



**ç¤ºä¾‹**

```bash
# åˆ›å»ºå‘½ä»¤
kubectl create deployment deployment-pod-test --image=wangxiaochun/pod-test:v0.1 --replicas=3

# æŸ¥çœ‹æ•ˆæœ
[root@master1 controller]#kubectl get all
NAME                                       READY   STATUS    RESTARTS       AGE
pod/deployment-pod-test-587f5cfffb-btv2w   1/1     Running   0              36s
pod/deployment-pod-test-587f5cfffb-cbkrn   1/1     Running   0              36s
pod/deployment-pod-test-587f5cfffb-ctjvc   1/1     Running   0              36s
......

NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deployment-pod-test   3/3     3            3           36s

NAME                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/deployment-pod-test-587f5cfffb   3         3         3       36s

# æ³¨æ„:åˆ›å»ºdeploymentä¼šè‡ªåŠ¨åˆ›å»ºç›¸åº”çš„RSå’ŒPOD
# RSçš„åç§°=deploymentåç§°+template_hashå€¼
# Podçš„åç§°=deploymentåç§°+replcaset_id+pod_id


# ä½¿ç”¨å‘½ä»¤æŸ¥çœ‹èµ„æºå¯¹è±¡æ ¼å¼
[root@master1 controller]# kubectl create deployment myapp --image registry.cn- beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas 3 --dry-run=client -o yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: myapp
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: myapp
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
        name: pod-test
        resources: {}
status: {}
```



**èµ„æºå®šä¹‰æ–‡ä»¶åˆ›å»ºå¯¹è±¡**

ç¤ºä¾‹

```yaml
# cat controller-deployment-test.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-test
spec:
  replicas: 3
  selector: 
    matchLabels:
      app: rs-test
  template:
    metadata:
      labels:
        app: rs-test
    spec:
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
        
# å¯åŠ¨èµ„æºæ¸…å•
[root@master1 controller]#kubectl apply -f controller-deployment-test.yaml 
deployment.apps/deployment-test created

# æŸ¥çœ‹
[root@master1 controller]#kubectl get deploy
NAME              READY   UP-TO-DATE   AVAILABLE   AGE
deployment-test   3/3     3            3           53s

# è‡ªåŠ¨ç”Ÿæˆrs
[root@master1 controller]#kubectl get rs
NAME                         DESIRED   CURRENT   READY   AGE
deployment-test-65495d86f9   3         3         3       95s

# åªè¦templateæ¨¡ç‰ˆå†…å®¹å˜é‡ï¼Œå°±ä¼šç”Ÿæˆæ–°çš„rsï¼Œå› ä¸ºhashå€¼ä¼šå˜
[root@master1 controller]#cat controller-deployment-test.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-test
spec:
  replicas: 3
  selector: 
    matchLabels:
      app: rs-test
  template:
    metadata:
      labels:
        app: rs-test
    spec:
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2        # è¿™é‡Œæ”¹ä¸ºv0.2
      
# æŸ¥çœ‹ï¼šå¯ä»¥çœ‹åˆ°2ä¸ªrs      
[root@master1 controller]#kubectl get rs
NAME                         DESIRED   CURRENT   READY   AGE
deployment-test-65495d86f9   0         0         0       10m
deployment-test-79f667698b   3         3         3       18s
```



![image-20241222202019431](../markdown_img/image-20241222202019431.png)





#### Deploymentå®ç°æ‰©å®¹ç¼©å®¹

**åŸºäºDeploymentè°ƒæ•´Podæœ‰ä¸¤ç§æ–¹æ³•**

```bash
# åŸºäºèµ„æºå¯¹è±¡è°ƒæ•´
kubectl scale  [--current-replicas=<å½“å‰å‰¯æœ¬æ•°>] --replicas=<æ–°å‰¯æœ¬æ•°> deployment/deploy_name

# åŸºäºèµ„æºæ–‡ä»¶è°ƒæ•´
kubectl scale --replicas=<æ–°å‰¯æœ¬æ•°> -f deploy_name.yaml
```



ç¤ºä¾‹

```bash
[root@master1 controller]#kubectl scale deployment deployment-test --replicas=5
deployment.apps/deployment-test scaled

[root@master1 controller]#kubectl get pod
NAME                               READY   STATUS    RESTARTS       AGE
deployment-test-65495d86f9-4sl7h   1/1     Running   0              2s
deployment-test-65495d86f9-kk28x   1/1     Running   0              3m33s
deployment-test-65495d86f9-qr2mr   1/1     Running   0              3m30s
deployment-test-65495d86f9-rfspr   1/1     Running   0              2s
deployment-test-65495d86f9-tl7sp   1/1     Running   0              3m32s
pod-label-nginx                    1/1     Running   1 (167m ago)   29h
pod-label-nginx2                   1/1     Running   1 (169m ago)   29h
```



#### DeploymentåŠ¨æ€æ›´æ–°å›æ»š

##### å‘½ä»¤ä»‹ç»

```bash
# æ›´æ–°å‘½ä»¤1
kubectl set SUBCOMMAND [options] èµ„æºç±»å‹ èµ„æºåç§°
SUBCOMMANDï¼šå­å‘½ä»¤ï¼Œå¸¸ç”¨çš„å­å‘½ä»¤å°±æ˜¯image

# å‚æ•°è¯¦è§£
--record=true       # æ›´æ”¹æ—¶ï¼Œä¼šå°†ä¿¡æ¯å¢åŠ åˆ°å†å²è®°å½•ä¸­

#æ›´æ–°å‘½ä»¤2ï¼šï¼ˆç”¨çš„å¾ˆå°‘ï¼‰
kubectl patch (-f FILENAME | TYPE NAME) -p PATCH [options]

#å‚æ•°è¯¦è§£ï¼š
--patch='' #è®¾å®šå¯¹è±¡å±æ€§å†…å®¹

#å›æ»šå‘½ä»¤ï¼š
kubectl rollout SUBCOMMAND [options] èµ„æºç±»å‹ èµ„æºåç§°

SUBCOMMAND å­å‘½ä»¤ï¼š
history         #æ˜¾ç¤º rollout å†å²,é»˜è®¤åªä¿ç•™æœ€è¿‘çš„10ä¸ªç‰ˆæœ¬
pause           #æ ‡è®°resourceä¸ºä¸­æ­¢çŠ¶æ€ï¼Œé…åˆresumeå¯å®ç°ç°åº¦å‘å¸ƒï¼Œpauseç›®å‰ä»…æ”¯æŒdeployment,å¯é…åˆkubectl setå®ç°æ‰¹é‡æ›´æ–°
restart         #é‡å¯ä¸€ä¸ª resource
resume          #ç»§ç»­ä¸€ä¸ªåœæ­¢çš„ resource
status          #æ˜¾ç¤º rollout çš„çŠ¶æ€
undo            #æ’¤é”€ä¸Šä¸€æ¬¡çš„ rollout
--revision=n    #æŸ¥çœ‹æŒ‡å®šç‰ˆæœ¬çš„è¯¦ç»†ä¿¡æ¯
--to-revision=0 #rollbackè‡³æŒ‡å®šç‰ˆæœ¬,é»˜è®¤ä¸º0,è¡¨ç¤ºå‰ä¸€ä¸ªç‰ˆæœ¬
```



##### æ¡ˆä¾‹ï¼šå‘½ä»¤å¼æ›´æ–°å’Œå›æ»š

```bash
# åˆ›å»ºdeployment
[root@master1 controller]# kubectl create deployment nginx --image registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.18.0
deployment.apps/nginx created


# ä¿®æ”¹ç‰ˆæœ¬ä¸¤ç§æ ¼å¼
#kubectl set image deployment/nginx nginx='registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0' --record=true

# æŸ¥çœ‹å†å²kubectl rollout history
[root@master1 controller]#kubectl rollout history deployment nginx
deployment.apps/nginx 
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment/nginx nginx=registry.cnbeijing.aliyuncs.com/wangxiaochun/nginx:1.20.0 --record=true

# æ’¤é”€/å›é€€ä¸Šæ¬¡çš„æ›´æ”¹ï¼šæ³¨æ„ï¼šåªèƒ½å›é€€ä¸€æ¬¡
kubectl rollout undo deployment nginx

# å›é€€åˆ°æŒ‡å®šç‰ˆæœ¬
kubectl rollout undo --to-revision=2 deployment nginx
```



##### æ¡ˆä¾‹: åŸºäºå£°æ˜æ¸…å•æ–‡ä»¶å®ç°å‡çº§å’Œé™çº§

```yaml
# cat controller-deployment-test.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-test
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rs-test
  template:
    metadata:
      labels:
        app: rs-test
    spec:
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2        # ç›´æ¥æ”¹è¿™é‡Œ

# å®Œæˆå‡çº§
kubectl apply -f controller-deployment-test.yaml
```



##### æ‰¹é‡æ›´æ–°

é»˜è®¤åªæ›´æ”¹ä¸€æ¬¡å°±ä¼šè§¦å‘é‡æ–°ç”Ÿæˆæ–°Podå¯èƒ½ä¼šå½±å“ä¸šåŠ¡çš„ç¨³å®š,å¯ä»¥å°†å¤šæ¬¡æ‰¹é‡æ›´æ–°åˆå¹¶ä¸ºåªè§¦å‘ä¸€æ¬¡ é‡æ–°åˆ›å»ºPod,ä»è€Œä¿è¯ä¸šåŠ¡çš„ç¨³å®š

```bash
# æš‚åœæ›´æ–°
kubectl rollout pause deployment pod-test

# ç¬¬ä¸€æ¬¡æ›´æ”¹
kubectl set image deployment pod-test pod-test=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2 --record

# ç¬¬äºŒæ¬¡æ›´æ”¹
kubectl set resources deployment nginx --limits=cpu=200m,memory=128Mi --requests=cpu=100m,memory=64Mi


# æ¢å¤æ‰¹é‡æ›´æ–°
kubectl rollout resume deployment nginx
```





#### Deploymentæ»šåŠ¨æ›´æ–°ç­–ç•¥

Deployment æ§åˆ¶å™¨æ”¯æŒä¸¤ç§æ›´æ–°ç­–ç•¥

- **é‡å»ºå¼æ›´æ–° recreate**
  - å½“ä½¿ç”¨Recreateç­–ç•¥æ—¶ï¼ŒDeploymentä¼šç›´æ¥**åˆ é™¤å…¨éƒ¨çš„æ—§çš„Pod**ï¼Œç„¶ååˆ›å»ºæ–°çš„Podã€‚
  - è¿™æ„å‘³ç€åœ¨éƒ¨ç½²æ–°ç‰ˆæœ¬æ—¶ï¼Œæ•´ä¸ªåº”ç”¨ä¼šåœæ­¢æœåŠ¡ä¸€æ®µæ—¶é—´ï¼Œç›´åˆ°æ‰€æœ‰æ—§çš„Podéƒ½è¢«åˆ é™¤å¹¶ä¸”æ–°çš„ Podè¢«åˆ›å»ºå¹¶è¿è¡Œèµ·æ¥ã€‚
  - è¿™å¯èƒ½ä¼šå¯¼è‡´ä¸€æ®µæ—¶é—´å†…çš„æœåŠ¡ä¸­æ–­ï¼Œå› ä¸ºæ—§ç‰ˆæœ¬çš„Podè¢«ç›´æ¥æ›¿æ¢æ‰äº†ã€‚
  - **æ­¤æ–¹å¼å¯ä»¥é˜²æ­¢ç«¯å£å†²çª**

- **æ»šåŠ¨å¼æ›´æ–° rolling updates** 
  - æ­¤ä¸ºé»˜è®¤ç­–ç•¥
  - RollingUpdateç­–ç•¥å…è®¸åœ¨éƒ¨ç½²æ–°ç‰ˆæœ¬æ—¶é€æ­¥æ›´æ–°Podã€‚
  - å®ƒä¼šå…ˆåˆ›å»ºæ–°ç‰ˆæœ¬çš„Podï¼Œç„¶åé€æ­¥æ›¿æ¢æ—§ç‰ˆæœ¬çš„Podï¼Œç›´åˆ°æ‰€æœ‰Podéƒ½å·²ç»æ›´æ–°ä¸ºæ–°ç‰ˆæœ¬ã€‚
  - è¿™ç§æ–¹å¼å¯ä»¥ç¡®ä¿åº”ç”¨ä¸€ç›´å¤„äºå¯ç”¨çŠ¶æ€ï¼Œå› ä¸ºåœ¨æ•´ä¸ªæ›´æ–°è¿‡ç¨‹ä¸­ï¼Œè‡³å°‘æœ‰ä¸€éƒ¨åˆ†Podä¸€ç›´åœ¨è¿è¡Œã€‚
  - é€æ‰¹æ¬¡æ›´æ–°Podçš„æ–¹å¼ï¼Œæ”¯æŒæŒ‰ç™¾åˆ†æ¯”æˆ–å…·ä½“çš„æ•°é‡å®šä¹‰æ‰¹æ¬¡è§„æ¨¡
  - è§¦å‘æ¡ä»¶:
    - **podTemplateçš„hashç **å˜åŠ¨ï¼Œå³ä»…podTemplateçš„é…ç½®å˜åŠ¨æ‰ä¼šå¯¼è‡´hashç æ”¹å˜
    - replicaså’Œselectorçš„å˜æ›´ä¸ä¼šå¯¼è‡´podTemplateçš„hashå˜åŠ¨



**å­˜åœ¨çš„é—®é¢˜**:å¿…é¡»ä»¥Podä¸ºæœ€å°å•ä½æ¥è°ƒæ•´è§„æ¨¡æ¯”ä¾‹ï¼Œè€Œæ— æ³•å®ç°æµé‡è·¯ç”±æ¯”ä¾‹çš„æ§åˆ¶ï¼Œæ¯”å¦‚: å…±3ä¸ªPod å®ç°20%æµé‡æ¯”ä¾‹

è¦å®ç°æµé‡è·¯ç”±æ¯”ä¾‹çš„æ§åˆ¶ï¼Œå°±éœ€è¦ä½¿ç”¨æ›´é«˜çº§çš„å·¥å…·æ¯”å¦‚: Ingress æ‰èƒ½å®ç°



**å±æ€§è§£æ**

```bash
kubectl explain deployment.spec.strategy

type <string> #ä¸»è¦æœ‰ä¸¤ç§ç±»å‹ï¼š"Recreate"ã€"RollingUpdate-é»˜è®¤"
Recreate            #é‡å»º,å…ˆåˆ é™¤æ—§Pod,å†åˆ›å»ºæ–°Pod,æ¯”å¦‚å¯ä»¥é˜²æ­¢ç«¯å£å†²çª

kubectl explain deployment.spec.strategy.rollingUpdate
rollingUpdate       <Object>
 maxSurge   <string>#æ›´æ–°æ—¶å…è®¸è¶…è¿‡æœŸæœ›å€¼çš„æœ€å¤§Podæ•°é‡æˆ–ç™¾åˆ†æ¯”,é»˜è®¤ä¸º25%,å¦‚æœä¸º0,è¡¨ç¤ºå…ˆå‡,å†åŠ ï¼Œæ­¤æ—¶maxUnavaibleä¸èƒ½ä¸º0
 maxUnavailabel <string> #æ›´æ–°æ—¶å…è®¸æœ€å¤§å¤šå°‘ä¸ªæˆ–ç™¾åˆ†æ¯”çš„Podä¸å¯ç”¨,é»˜è®¤ä¸º25%,å¦‚æœä¸º0,è¡¨ç¤ºå…ˆåŠ åå‡ï¼Œæ­¤æ—¶maxSurgeä¸èƒ½ä¸º0
#å¦‚æœmaxSurgeä¸ºæ­£æ•´æ•°, maxUnavailabelä¸º0,è¡¨ç¤ºå…ˆæ·»åŠ æ–°ç‰ˆæœ¬çš„Pod,å†åˆ é™¤æ—§ç‰ˆæœ¬çš„Podï¼Œå³å…ˆåŠ å†å‡
#å¦‚æœmaxSurgeä¸º0, maxUnavaiLabelä¸ºæ­£æ•´æ•°,è¡¨ç¤ºå…ˆåˆ é™¤æ—§ç‰ˆæœ¬çš„Pod,å†æ·»åŠ æ–°ç‰ˆæœ¬çš„Podï¼Œå³å…ˆå‡å†åŠ 
#å¦‚æœmaxSurgeä¸º100%ï¼ŒmaxUnavaiLabelä¸º100%ï¼Œå®ç°è“ç»¿å‘å¸ƒï¼Œæ³¨æ„ï¼šèµ„æºè¦è¶³å¤Ÿ
```



| å±æ€§            | è§£æ                                                         |
| --------------- | ------------------------------------------------------------ |
| minReadySeconds | Kubernetesåœ¨ç­‰å¾…è®¾ç½®çš„æ—¶é—´åæ‰è¿›è¡Œå‡çº§<br />å¦‚æœæ²¡æœ‰è®¾ç½®è¯¥å€¼ï¼ŒKubernetesä¼šå‡è®¾è¯¥å®¹å™¨å¯åŠ¨èµ·æ¥åå°±æä¾›æœåŠ¡äº†<br />å¦‚æœæ²¡æœ‰è®¾ç½®è¯¥å€¼ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½ä¼šé€ æˆæœåŠ¡ä¸æ­£å¸¸è¿è¡Œ |
| maxSurge        | å‡çº§è¿‡ç¨‹ä¸­Podæœ€å¤šå¯æ¯”é¢„æœŸå€¼å¤šå‡ºçš„Podæ•°é‡ï¼Œå…¶å€¼å¯ä»¥æ˜¯0æˆ–æ­£æ•´æ•°,æˆ– è€…ç›¸å¯¹é¢„æœŸå€¼çš„ç™¾åˆ†æ¯”<br />é»˜è®¤æ˜¯25%<br />ä¾‹å¦‚ï¼šmaxSurage=1ï¼Œreplicas=5,åˆ™è¡¨ç¤ºKubernetesä¼šå…ˆå¯åŠ¨1ä¸€ä¸ªæ–°çš„ Podåæ‰åˆ æ‰ä¸€ä¸ªæ—§çš„PODï¼Œæ•´ä¸ªå‡çº§è¿‡ç¨‹ä¸­æœ€å¤šä¼šæœ‰5+1ä¸ªPodã€‚ |
| maxUnavailabel  | å‡çº§è¿‡ç¨‹ä¸­æœ€å¤šæœ‰å¤šå°‘ä¸ªPodå¤„äºæ— æ³•æä¾›æœåŠ¡çš„çŠ¶æ€<br />é»˜è®¤æ˜¯25%<br />å½“maxSurgeä¸ä¸º0æ—¶ï¼Œè¯¥å€¼ä¹Ÿä¸èƒ½ä¸º0<br />ä¾‹å¦‚ï¼šmaxUnavaible=1ï¼Œåˆ™è¡¨ç¤ºKubernetesæ•´ä¸ªå‡çº§è¿‡ç¨‹ä¸­æœ€å¤šä¼šæœ‰1ä¸ª PODå¤„äºæ— æ³•æœåŠ¡çš„çŠ¶æ€ã€‚ |



**èµ„æºæ¸…å•æ–‡ä»¶åŸºæœ¬æ ·å¼**

```yaml
#åŸºæœ¬å±æ€§æ ·å¼ï¼š
minReadySeconds: 5
strategy:
 type: RollingUpdate
 rollingUpdate:
   maxSurge: 1
   maxUnavaiLabel: 1
```





##### æ¡ˆä¾‹ï¼šå®šåˆ¶æ»šåŠ¨æ›´æ–°æ–‡ä»¶

```yaml
# cat controller-deployment-rollupdate.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-rolling-update
spec:
  replicas: 6
  selector:
    matchLabels:
      app: pod-test
  template:
    metadata:
      labels:
        app: pod-test
    spec:
      containers:
      - name: pod-rolling-update
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    minReadySeconds: 5
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 1
# å±æ€§è§£æ
minReadySeconds: 5 #è¡¨ç¤ºåœ¨æ›´æ–°çš„æ—¶å€™ï¼Œéœ€è¦å…ˆç­‰å¾…5ç§’ï¼Œè€Œä¸æ˜¯ä¸€æ—¦å‘ç”Ÿå˜åŒ–å°±æ»šåŠ¨æ›´æ–°
maxSurge: 1 #å®šä¹‰äº†åœ¨æ›´æ–°æœŸé—´å…è®¸è¶…è¿‡æœŸæœ›æ•°é‡çš„ Pod å®ä¾‹,æ­¤å¤„è¡¨ç¤ºå…è®¸è¶…è¿‡æœŸæœ›æ•°é‡çš„ä¸€ä¸ªé¢å¤–çš„ Pod å®ä¾‹ã€‚
maxUnavaiLabel: 1 #å®šä¹‰äº†åœ¨æ›´æ–°æœŸé—´å…è®¸ä¸å¯ç”¨çš„æœ€å¤§ Pod æ•°é‡ã€‚æ­¤å¤„è¡¨ç¤ºåœ¨æ›´æ–°æœŸé—´å…è®¸æœ€å¤šä¸€ä¸ª Pod ä¸å¯ç”¨ã€‚
```



##### æ¡ˆä¾‹ï¼šé‡‘ä¸é›€å‘å¸ƒ

```yaml
# cat controller-deployment-rollupdate-canary.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-rolling-update-canary
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pod-test
  template:
    metadata:
      labels:
        app: pod-test
    spec:
      containers:
      - name: pod-rolling-update-canary
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1         # å…ˆåŠ åå‡
      maxUnavailable: 0
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: pod-test
  name: pod-test
spec:
  ports:
  - name: "80"
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: pod-test
  type: ClusterIP
 
 
# å¯åŠ¨èµ„æºæ¸…å•
[root@master1 controller] # kubectl apply -f controller-deployment-rollupdate-canary.yaml 
deployment.apps/deployment-rolling-update-canary created
service/pod-test created

# å½“å‰çŠ¶æ€
[root@master1 controller] # kubectl get pod
NAME                                                READY   STATUS    RESTARTS        AGE
deployment-rolling-update-canary-6794cd6c97-6ljcw   1/1     Running   0               45s
deployment-rolling-update-canary-6794cd6c97-dmsgg   1/1     Running   0               45s
deployment-rolling-update-canary-6794cd6c97-xmjnh   1/1     Running   0               45s

# å‡çº§ç‰ˆæœ¬
[root@master1 controller]#sed -i 's/pod-test:v0.1/pod-test:v0.2/' controller-deployment-rollupdate-canary.yaml

# é‡‘ä¸é›€å‘å¸ƒ
[root@master1 controller] # kubectl apply -f controller-deployment-rollupdate-canary.yaml && kubectl rollout pause deployment deployment-rolling-update-canary
deployment.apps/deployment-rolling-update-canary configured
service/pod-test unchanged
deployment.apps/deployment-rolling-update-canary paused
[root@master1 controller] # kubectl get pod
NAME                                                READY   STATUS    RESTARTS        AGE
deployment-rolling-update-canary-65687cb7cb-b9ghp   1/1     Running   0               4s
deployment-rolling-update-canary-6794cd6c97-6ljcw   1/1     Running   0               3m34s
deployment-rolling-update-canary-6794cd6c97-dmsgg   1/1     Running   0               3m34s
deployment-rolling-update-canary-6794cd6c97-xmjnh   1/1     Running   0               3m34s

# æ›´æ–°
[root@master1 controller] # kubectl rollout status deployment deployment-rolling-update-canary 
Waiting for deployment "deployment-rolling-update-canary" rollout to finish: 1 out of 3 new replicas have been updated...

# è§‚å¯Ÿ
[root@master1 ~]#while true;do curl 10.103.158.212; sleep 1;done
87cb7cb-b9ghp, ServerIP: 10.244.3.41!
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: deployment-rolling-update-canary-6794cd6c97-6ljcw, ServerIP: 10.244.3.40!
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: deployment-rolling-update-canary-6794cd6c97-6ljcw, ServerIP: 10.244.3.40!
kubernetes pod-test v0.2!! ClientIP: 10.244.0.0, ServerName: deployment-rolling-update-canary-65687cb7cb-b9ghp, ServerIP: 10.244.3.41!
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: deployment-rolling-update-canary-6794cd6c97-dmsgg, ServerIP: 10.244.2.32!
kubernetes pod-test v0.2!! ClientIP: 10.244.0.0, ServerName: deployment-rolling-update-canary-65687cb7cb-b9ghp, ServerIP: 10.244.3.41!
kubernetes pod-test v0.2!! ClientIP: 10.244.0.0, ServerName: deployment-rolling-update-canary-65687cb7cb-b9ghp, ServerIP: 10.244.3.41!
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: deployment-rolling-update-canary-6794cd6c97-6ljcw, ServerIP: 10.244.3.40!


# ç¡®ä¿¡æ²¡é—®é¢˜ä¹‹åï¼Œç»§ç»­å®Œæˆä¸€éƒ¨åˆ†æ›´æ–°
[root@master1 controller] # kubectl rollout resume deployment deployment-rolling-update-canary && kubectl rollout pause deployment deployment-rolling-update-canary
deployment.apps/deployment-rolling-update-canary resumed
deployment.apps/deployment-rolling-update-canary paused
```



##### æ¡ˆä¾‹ï¼š**æ¨¡æ‹Ÿè“ç»¿å‘å¸ƒ**

```yaml
# cat controller-deployment-rollupdate-bluegreen.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-rolling-update-bluegreen
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pod-test
  template:
    metadata:
      labels:
        app: pod-test
    spec:
      containers:
      - name: pod-rolling-update-bluegreen
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 100%
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: pod-test
  name: pod-test
spec:
  ports:
  - name: "80"
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: pod-test
  type: ClusterIP
  
  
# å¯åŠ¨èµ„æºæ¸…å•
[root@master1 controller]#kubectl apply -f controller-deployment-rollupdate-bluegreen.yaml 
deployment.apps/deployment-rolling-update-bluegreen created
service/pod-test unchanged

# æŸ¥çœ‹
[root@master1 controller]#kubectl get pod
NAME                                                   READY   STATUS    RESTARTS        AGE
deployment-rolling-update-bluegreen-854d466b88-d2fk4   1/1     Running   0               4s
deployment-rolling-update-bluegreen-854d466b88-dmpfg   1/1     Running   0               4s
deployment-rolling-update-bluegreen-854d466b88-nmkc4   1/1     Running   0               4s

# ä¿®æ”¹ç‰ˆæœ¬
[root@master1 controller]#sed -i 's/pod-test:v0.1/pod-test:v0.2/' controller-deployment-rollupdate-bluegreen.yaml 

# å¯åŠ¨å¹¶è§‚å¯Ÿç»“æœ
[root@master1 controller]#kubectl apply -f controller-deployment-rollupdate-bluegreen.yaml 
deployment.apps/deployment-rolling-update-bluegreen configured
service/pod-test unchanged

# å…¨éƒ¨åˆ é™¤ï¼Œå…¨éƒ¨æ¢æˆæ–°ç‰ˆæœ¬
[root@master1 controller]#kubectl get pod
NAME                                                   READY   STATUS        RESTARTS        AGE
deployment-rolling-update-bluegreen-5dcf45995c-6srwf   1/1     Running       0               6s
deployment-rolling-update-bluegreen-5dcf45995c-bmcr7   1/1     Running       0               6s
deployment-rolling-update-bluegreen-5dcf45995c-xr5ds   1/1     Running       0               6s
deployment-rolling-update-bluegreen-854d466b88-d2fk4   1/1     Terminating   0               115s
deployment-rolling-update-bluegreen-854d466b88-dmpfg   1/1     Terminating   0               115s
deployment-rolling-update-bluegreen-854d466b88-nmkc4   1/1     Terminating   0               115

# å›é€€
[root@master1 controller]#kubectl rollout undo deployment deployment-rolling-update-bluegreen 
deployment.apps/deployment-rolling-update-bluegreen rolled back

# æŸ¥çœ‹çŠ¶æ€
[root@master1 controller]#kubectl get pod
NAME                                                   READY   STATUS        RESTARTS        AGE
deployment-rolling-update-bluegreen-5dcf45995c-6srwf   1/1     Terminating   0               70s
deployment-rolling-update-bluegreen-5dcf45995c-bmcr7   1/1     Terminating   0               70s
deployment-rolling-update-bluegreen-5dcf45995c-xr5ds   1/1     Terminating   0               70s
deployment-rolling-update-bluegreen-854d466b88-b2nmw   1/1     Running       0               2s
deployment-rolling-update-bluegreen-854d466b88-nvprx   1/1     Running       0               2s
deployment-rolling-update-bluegreen-854d466b88-rq7nw   1/1     Running       0               2s
```





### DaemonSet



![image-20241223092340014](../markdown_img/image-20241223092340014.png)



æœ‰äº›æƒ…å†µä¸‹ï¼Œ**éœ€è¦åœ¨æ‰€æœ‰èŠ‚ç‚¹éƒ½è¿è¡Œä¸€ä¸ªPod**ï¼Œå› ä¸ºNodeæ•°é‡ä¼šå˜åŒ–ï¼Œæ‰€ä»¥æŒ‡å®šPodçš„å‰¯æœ¬æ•°å°±ä¸åˆé€‚ äº†

DaemonSetèƒ½å¤Ÿè®©æ‰€æœ‰ï¼ˆæˆ–è€…ç‰¹å®šï¼‰çš„èŠ‚ç‚¹"ç²¾ç¡®çš„"è¿è¡ŒåŒä¸€ä¸ªpod

å½“èŠ‚ç‚¹åŠ å…¥åˆ°kubernetesé›†ç¾¤ä¸­ï¼ŒPodä¼šè¢«DaemonSet æ§åˆ¶å™¨è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ä¸Šè¿è¡Œ

å½“èŠ‚ç‚¹ä»Kubrenetesé›†ç¾¤ä¸­è¢«ç§»é™¤ï¼Œè¢«DaemonSetè°ƒåº¦çš„podä¹Ÿä¼šè¢«ç§»é™¤

å¦‚æœåˆ é™¤DaemonSetï¼Œæ‰€æœ‰è·Ÿè¿™ä¸ªDaemonSetç›¸å…³çš„podséƒ½ä¼šè¢«åˆ é™¤

åœ¨æŸç§ç¨‹åº¦ä¸Šï¼ŒDaemonSetæ‰¿æ‹…äº†RSçš„éƒ¨åˆ†åŠŸèƒ½ï¼Œå®ƒä¹Ÿèƒ½ä¿è¯ç›¸å…³podsæŒç»­è¿è¡Œ



**DaemonSet çš„ä¸€äº›å…¸å‹ç”¨æ³•**

- åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œé›†ç¾¤å®ˆæŠ¤è¿›ç¨‹
- åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œæ—¥å¿—æ”¶é›†å®ˆæŠ¤è¿›ç¨‹
- åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œç›‘æ§å®ˆæŠ¤è¿›ç¨‹



**å¸¸ç”¨äºåå°æ”¯æ’‘æœåŠ¡**

- Kubernetesé›†ç¾¤çš„ç³»ç»Ÿçº§åº”ç”¨: kube-proxy,flannel,calico
- é›†ç¾¤å­˜å‚¨å®ˆæŠ¤è¿›ç¨‹ï¼Œå¦‚ï¼šcephï¼Œglusterd
- æ—¥å¿—æ”¶é›†æœåŠ¡ï¼Œå¦‚ï¼šfluentdï¼Œlogstash
- ç›‘æ§æœåŠ¡ï¼Œå¦‚ï¼šPrometheusï¼Œcollectd
- æš´éœ²æœåŠ¡: å¦‚: Ingress nginx



DaemonSetå±æ€§è§£æ

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: <string>
  namespace: <string>
spec:
  minReadySeconds: <integer>
  selector: <object>
  template: <object>
  revisionHistoryLimit: <integer>
  updateStrategy: <object>          # æ»šåŠ¨æ›´æ–°ç­–ç•¥
    type: <string>                  # æ»šåŠ¨æ›´æ–°ç±»å‹ï¼ŒOnDelete(åˆ é™¤æ—¶æ›´æ–°ï¼Œæ‰‹åŠ¨è§¦å‘)å’ŒRollingUpdate(é»˜è®¤å€¼ï¼Œæ»šåŠ¨æ›´æ–°)
    rollingUpdate: <object>
      maxSurge
      maxUnavailable: <string>
```



å®˜æ–¹ç¤ºä¾‹

```yaml
#https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/daemonset/
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-elasticsearch
  namespace: kube-system
  labels:
    k8s-app: fluentd-logging
spec:
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  template:
    metadata:
      labels:
        name: fluentd-elasticsearch
    spec:
      tolerations:
      # è¿™äº›å®¹å¿åº¦è®¾ç½®æ˜¯ä¸ºäº†è®©è¯¥å®ˆæŠ¤è¿›ç¨‹é›†åœ¨æ§åˆ¶å¹³é¢èŠ‚ç‚¹ä¸Šè¿è¡Œ
      # å¦‚æœä½ ä¸å¸Œæœ›è‡ªå·±çš„æ§åˆ¶å¹³é¢èŠ‚ç‚¹è¿è¡ŒPodï¼Œå¯ä»¥åˆ é™¤å®ƒä»¬
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      containers:
      - name: fluentd-elasticsearch
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
```





**æŸ¥çœ‹å½“å‰æ‰€æœ‰åç§°ç©ºé—´å†…çš„DaemonSet**

```bash
kubectl get ds -A    # -Aè¡¨ç¤ºæ‰€æœ‰åç§°ç©ºé—´
```



##### DaemonSetæ¡ˆä¾‹

```yaml
# cat controller-daemonset-test.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: controller-daemonset-test
spec:
  selector:
    matchLabels:
      app: pod-test
  template:
    metadata:
      labels:
        app: pod-test
    spec:
      # hostNetwork: true #ä½¿ç”¨å®¿ä¸»æœºçš„ç½‘ç»œå’Œç«¯å£,å¯ä»¥é€šè¿‡å®¿ä¸»æœºç›´æ¥è®¿é—®Pod,æ€§èƒ½å¥½,ä½†è¦é˜²æ­¢ç«¯å£å†²çª
      #hostPID: true #ç›´æ¥ä½¿ç”¨å®¿ä¸»æœºçš„PID
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1


# æŸ¥çœ‹ï¼Œæ¯ä¸ªèŠ‚ç‚¹æœ‰ä¸€ä¸ª
[root@master1 controller]#kubectl get pod -o wide
NAME                                                   READY   STATUS    RESTARTS      AGE   IP            NODE    NOMINATED NODE   READINESS GATES
controller-daemonset-test-hb2w4                        1/1     Running   0             16s   10.244.2.41   node2   <none>           <none>
controller-daemonset-test-q5zgl                        1/1     Running   0             16s   10.244.3.48   node3   <none>           <none>
controller-daemonset-test-wz55z                        1/1     Running   0             16s   10.244.1.43   node1   <none>           <none>

# daemonsetå¯¹è±¡ä¹Ÿæ”¯æŒæ»šåŠ¨æ›´æ–°
kubectl set image daemonsets controller-daemonset-test pod-test='wangxiaochun/pod-test:v0.2' --record=true && kubectl rollout status daemonset controller-daemonset-test

# æ³¨æ„ï¼šdaemonsetå¯¹è±¡ä¸æ”¯æŒpauseåŠ¨ä½œ
```



##### æ¡ˆä¾‹ï¼š: åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šéƒ¨ç½²ç›‘æ§è½¯ä»¶prometheusé‡‡é›†æŒ‡æ ‡æ•°æ®

```yaml
# cat controller-daemonset-prometheus.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: daemonset-demo
  namespace: default
  labels:
    app: prometheus
    component: node-exporter
spec:
  selector:
    matchLabels:
      app: prometheus
      component: node-exporter
  template:
    metadata:
      name: prometheus-node-exporter
      labels:
        app: prometheus
        component: node-exporter
    spec:
      #tolerations:
      #- key: node-role.kubernetes.io/control-plane
      #  operator: Exists
      #  effect: NoSchedule
      #- key: node-role.kubernetes.io/master
      #  operator: Exists
      #  effect: NoSchedule
      containers:
      - image: prom/node-exporter:v1.2.2
        name: prometheus-node-exporter
        ports:
        - name: prom-node-exp
          containerPort: 9100
          #hostPort: 9100
        livenessProbe:
          tcpSocket:
            port: prom-node-exp
          initialDelaySeconds: 3
        readinessProbe:
          httpGet:
            path: '/metrics'
            port: prom-node-exp
            scheme: HTTP
          initialDelaySeconds: 5
      hostNetwork: true
      hostPID: true
```

![image-20241223104118377](../markdown_img/image-20241223104118377.png)



**æ¡ˆä¾‹ï¼šä»…åœ¨æŒ‡å®šæ ‡ç­¾çš„æ¯ä¸ªä¸»æœºä¸Šè¿è¡Œä¸€ä¸ªPod**

```bash
# åœ¨æŒ‡å®šçš„èŠ‚ç‚¹ä¸Šæ‰“ä¾¿ç­¾
[root@master1 yaml]#kubectl label node node1.wang.org node2.wang.org ds=true
node/node1.wang.org labeled
node/node2.wang.org labeled

[root@master1 yaml]#cat controller-daemonset-label-test.yaml 
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: controller-daemonset-label-test
spec:
  selector:
    matchLabels:
      app: pod-test
  template:
    metadata:
      labels:
        app: pod-test
    spec:
      nodeSelector:      # ä½¿ç”¨èŠ‚ç‚¹æ ‡ç­¾é€‰æ‹©å™¨
        ds: "true"       #æŒ‡å®šæ¡ä»¶
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
```





### Job



#### Jobå·¥ä½œæœºåˆ¶

åœ¨æ—¥å¸¸çš„å·¥ä½œä¸­ï¼Œç»å¸¸ä¼šé‡åˆ°ä¸´æ—¶æ‰§è¡Œä¸€ä¸ªä»»åŠ¡ï¼Œä½†æ˜¯è¿™ä¸ªä»»åŠ¡å¿…é¡»åœ¨æŸä¸ªæ—¶é—´ç‚¹æ‰§è¡Œæ‰å¯ä»¥

å‰é¢çš„Deploymentå’ŒDaemonSetä¸»è¦è´Ÿè´£ç¼–æ’å§‹ç»ˆ**æŒç»­è¿è¡Œçš„å®ˆæŠ¤è¿›ç¨‹ç±»çš„åº”ç”¨**ï¼Œå¹¶ä¸é€‚åˆæ­¤åœºæ™¯

é’ˆå¯¹äºè¿™ç§åœºæ™¯ï¼Œä¸€èˆ¬ä½¿ç”¨jobçš„æ–¹å¼æ¥å®Œæˆä»»åŠ¡ã€‚



**Jobè´Ÿè´£ç¼–æ’è¿è¡Œæœ‰ç»“æŸæ—¶é—´çš„â€œä¸€æ¬¡æ€§â€ä»»åŠ¡**

- æ§åˆ¶å™¨è¦ç¡®ä¿Podå†…çš„è¿›ç¨‹â€œæ­£å¸¸ï¼ˆæˆåŠŸå®Œæˆä»»åŠ¡)â€é€€å‡º
- **éæ­£å¸¸é€€å‡ºçš„Podå¯ä»¥æ ¹æ®éœ€è¦é‡å¯ï¼Œå¹¶åœ¨é‡è¯•æŒ‡å®šçš„æ¬¡æ•°åç»ˆæ­¢**
- Job å¯ä»¥æ˜¯å•æ¬¡ä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥æ˜¯åœ¨å¤šä¸ªPodåˆ†åˆ«å„è‡ªè¿è¡Œä¸€æ¬¡ï¼Œå®ç°è¿è¡Œå¤šæ¬¡ï¼ˆæ¬¡æ•°é€šå¸¸å›ºå®š)
- Job æ”¯æŒåŒæ—¶åˆ›å»ºåŠå¹¶è¡Œè¿è¡Œå¤šä¸ªPodä»¥åŠ å¿«ä»»åŠ¡å¤„ç†é€Ÿåº¦ï¼ŒJobæ§åˆ¶å™¨æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰å…¶å¹¶è¡Œåº¦



**å…³äºjobçš„æ‰§è¡Œä¸»è¦æœ‰ä¸¤ç§å¹¶è¡Œåº¦çš„ç±»å‹ï¼š**

- **ä¸²è¡Œ job**ï¼šå³æ‰€æœ‰çš„jobä»»åŠ¡éƒ½åœ¨ä¸Šä¸€ä¸ªjobæ‰§è¡Œå®Œæ¯•åï¼Œå†å¼€å§‹æ‰§è¡Œ
- **å¹¶è¡Œ job**ï¼šå¦‚æœå­˜åœ¨å¤šä¸ª jobï¼Œå¯ä»¥è®¾å®šå¹¶è¡Œæ‰§è¡Œçš„ job æ•°é‡ã€‚



Jobèµ„æºåŒæ ·éœ€è¦æ ‡ç­¾é€‰æ‹©å™¨å’ŒPodæ¨¡æ¿ï¼Œä½†å®ƒä¸éœ€è¦æŒ‡å®šreplicasï¼Œä¸”éœ€è¦ç»™å®š**completions**ï¼Œå³éœ€è¦å®Œæˆçš„ä½œä¸šæ¬¡æ•°ï¼Œé»˜è®¤ä¸º1æ¬¡

- Jobèµ„æºä¼šä¸ºå…¶Podå¯¹è±¡è‡ªåŠ¨æ·»åŠ â€œjob-name=JOB_NAMEâ€å’Œâ€œcontroller-uid=UIDâ€æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨æ ‡ ç­¾é€‰æ‹©å™¨å®Œæˆå¯¹controller-uidæ ‡ç­¾çš„å…³è”ï¼Œå› æ­¤ï¼Œselectorå¹¶éå¿…é€‰å­—æ®µ
- Podçš„å‘½åæ ¼å¼ï¼š$(job-name)-$(index)-$(random-string)ï¼Œå…¶ä¸­çš„$(index)å­—æ®µå–å€¼ä¸ completionså’ŒcompletionModeæœ‰å…³



**æ³¨æ„**ï¼š

- Job èµ„æºæ˜¯æ ‡å‡†çš„APIèµ„æºç±»å‹
- Job èµ„æºæ‰€åœ¨ç¾¤ç»„ä¸ºâ€œbatch/v1â€
- Job èµ„æºä¸­ï¼ŒPodçš„RestartPolicyçš„å–å€¼åªèƒ½ä¸º**Never**æˆ–**OnFailure**



#### jobå±æ€§è§£æ

```yaml
apiVersion: batch/v1                   # APIç¾¤ç»„åŠç‰ˆæœ¬
kind: Job
metadata:
  name: <string>             
  namespace: <string>                  # åç§°ç©ºé—´ï¼šJobèµ„æºéš¶å±åç§°ç©ºé—´çº§åˆ«
spec:
  selector: <object>                   # æ ‡ç­¾é€‰æ‹©å™¨ï¼Œå¿…é¡»åŒ¹é…templateå­—æ®µä¸­Podæ¨¡ç‰ˆä¸­çš„æ ‡ç­¾
  suspend: <boolean>                   # æ˜¯å¦æŒ‚èµ·å½“å‰Jobçš„æ‰§è¡Œï¼ŒæŒ‚èµ·ä½œä¸šä¼šé‡ç½®StartTimeå­—æ®µçš„å€¼
  template: <object>                   # Podæ¨¡ç‰ˆå¯¹è±¡
  completions: <integer>               # æœŸæœ›çš„æˆåŠŸå®Œæˆçš„ä½œä¸šæ¬¡æ•°ï¼ŒæˆåŠŸè¿è¡Œç»“æŸçš„Podæ•°é‡ï¼Œé»˜è®¤1æ¬¡
  completionMode: <string>             # è¿½è¸ªPodå®Œæˆæ¨¡å¼ï¼Œæ”¯æŒæœ‰åºçš„Indexedå’Œæ— åºçš„NonIndexedï¼ˆé»˜è®¤ï¼‰ä¸¤ç§
  ttlSecondsAfterFinished: <integer>   # Completedç»ˆæ­¢çŠ¶æ€ä½œä¸šçš„ç”Ÿå­˜æ—¶é•¿ï¼Œè¶…æ—¶å°†è¢«åˆ é™¤
  parallelism: <integer>               # ä½œä¸šçš„æœ€å¤§å¹¶è¡Œåº¦ï¼Œé»˜è®¤ä¸º1
  backoffLimit: <integer>              # å°†ä½œä¸šæ ‡è®°ä¸ºFailedä¹‹å‰çš„é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä¸º6
  activeDeadlineSeconds: <integer>     # ä½œä¸šå¯åŠ¨åå¯å¤„äºæ´»åŠ¨çŠ¶æ€çš„æ—¶é•¿
```



**å¹¶è¡Œé…ç½®ç¤ºä¾‹**

```yaml
#ä¸²è¡Œè¿è¡Œå…±5æ¬¡ä»»åŠ¡
spec
  parallelism: 1
  completion: 5
 
#å¹¶è¡Œ2ä¸ªé˜Ÿåˆ—ï¼Œæ€»å…±è¿è¡Œ6æ¬¡ä»»åŠ¡
spec
  parallelism: 2
  completion: 6
```



#### Jobæ¡ˆä¾‹

##### ç¤ºä¾‹ï¼šå•ä¸ªä»»åŠ¡

```yaml
# cat controller-job-single.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-single
spec:
  template:
    metadata:
      name: job-single
    spec:
      restartPolicy: Never
      containers:
      - name: job-single
        image: busybox:1.30.0
        command: ["/bin/sh", "-c", "for i in `seq 10 -1 1`; do echo $i; sleep 2; done"]
# å±æ€§è§£æï¼šjobé‡å¯ç­–ç•¥åªæœ‰ä¸¤ç§ï¼Œä»…æ”¯æŒNeverå’ŒOnFailureä¸¤ç§ï¼Œä¸æ”¯æŒAlways,å¦åˆ™çš„è¯å°±æˆæ­»å¾ªç¯äº†

# æŸ¥çœ‹
[root@master1 loadBalancer]#kubectl logs job-single-t58q9 -f --timestamps=true
2024-12-23T03:08:42.128553849Z 10
2024-12-23T03:08:44.131895308Z 9
2024-12-23T03:08:46.132162071Z 8
2024-12-23T03:08:48.132344330Z 7
2024-12-23T03:08:50.132757393Z 6
2024-12-23T03:08:52.133286967Z 5
2024-12-23T03:08:54.133431930Z 4
2024-12-23T03:08:56.134113681Z 3
2024-12-23T03:08:58.134510385Z 2
2024-12-23T03:09:00.134875367Z 1

# ç»“æœæ˜¾ç¤ºï¼šjobä»»åŠ¡æ‰§è¡Œå®Œæ¯•åï¼ŒçŠ¶æ€æ˜¯Completed
[root@master1 loadBalancer]#kubectl get pod
NAME                                                   READY   STATUS      RESTARTS       AGE
job-single-t58q9                                       0/1     Completed   0              13m

```



##### ç¤ºä¾‹ï¼šå¤šä¸ªä¸²è¡Œä»»åŠ¡

```yaml
# cat controller-job-multi-serial.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-multi-serial
spec:
  completions: 5
  parallelism: 1              # parallelismä¸º1è¡¨ç¤ºä¸²è¡Œ
  # completionMode: Indexed
  template:
    spec:
      containers:
      - name: job-multi-serial
        image: busybox:1.30.0
        command: ["/bin/sh", "-c", "echo serial job; sleep 3"]
      restartPolicy: OnFailure

# éªŒè¯æ˜¯å¦ä¸²è¡Œ
# job_list=$(kubectl get pod |sort -k5 | awk '!/^NAME/{print $1}')
[root@master1 loadBalancer] # for i in $job_list ;do kubectl logs $i --timestamps;done
2024-12-23T03:36:53.978861730Z serial job
2024-12-23T03:37:19.492071239Z serial job
2024-12-23T03:37:12.968879900Z serial job
2024-12-23T03:37:06.853185566Z serial job
2024-12-23T03:37:00.775452672Z serial job
#ç»“æœæ˜¾ç¤ºï¼šè¿™äº›ä»»åŠ¡ï¼Œç¡®å®æ˜¯ä¸²è¡Œçš„æ–¹å¼æ¥æ‰§è¡Œï¼Œç”±äºæ¶‰åŠåˆ°ä»»åŠ¡æœ¬èº«æ˜¯å¯åŠ¨å’Œåˆ é™¤ï¼Œæ‰€ä»¥æ—¶é—´é—´éš”è¦å¤§äº3s
```



##### ç¤ºä¾‹ï¼šå¹¶è¡Œä»»åŠ¡

```yaml
# cat controller-job-multi-parallel.yaml 
apiVersion: batch/v1
kind: Job
metadata:
  name: job-multi-parallel
spec:
  completions: 6
  parallelism: 2   # #completions/parallelism å¦‚æœä¸èƒ½æ•´é™¤,æœ€åä¸€æ¬¡ä¸ºå‰©ä½™çš„ç¬¦åŠ¡æ•°
  ttlSecondsAfterFinished: 3600
  backoffLimit: 3
  activeDeadlineSeconds: 1200
  template:
    spec:
      containers:
      - name: job-multi-parallel
        image: busybox:1.30.0
        command: ["/bin/sh", "-c", "echo parallel job; sleep 3"]
      restartPolicy: OnFailure
      
[root@master1 loadBalancer] # kubectl apply -f controller-job-multi-parallel.yaml 
job.batch/job-multi-parallel created

# æŸ¥çœ‹Pod
[root@master1 loadBalancer] # kubectl get pod
NAME                       READY   STATUS      RESTARTS   AGE
job-multi-parallel-9mcfj   0/1     Completed   0          42s
job-multi-parallel-cmgjq   0/1     Completed   0          54s
job-multi-parallel-n9kc2   0/1     Completed   0          48s
job-multi-parallel-t7hrz   0/1     Completed   0          54s
job-multi-parallel-vzrrp   0/1     Completed   0          42s
job-multi-parallel-z2bsl   0/1     Completed   0          48s

# éªŒè¯ç»“æœ
[root@master1 loadBalancer] # job_list=$(kubectl get pod |sort -k5 | awk '!/^NAME/{print $1}')
[root@master1 loadBalancer] # for i in $job_list ;do kubectl logs $i --timestamps;done
2024-12-23T03:45:54.982398422Z parallel job
2024-12-23T03:45:54.921097939Z parallel job
2024-12-23T03:45:48.912076981Z parallel job
2024-12-23T03:45:48.908837334Z parallel job
2024-12-23T03:45:42.743753059Z parallel job
2024-12-23T03:45:42.739638339Z parallel job
#ç»“æœæ˜¾ç¤ºï¼šè¿™6æ¡ä»»åŠ¡ç¡®å®æ˜¯ä¸¤ä¸¤å¹¶è¡Œæ‰§è¡Œçš„
```



### CronJob

#### CronJobå·¥ä½œæœºåˆ¶

![image-20241223114903445](../markdown_img/image-20241223114903445.png)



å¯¹äº**å‘¨æœŸæ€§çš„å®šæ—¶ä»»åŠ¡**ï¼Œkubernetesæä¾›äº† Cronjobæ§åˆ¶å™¨å®ç°ä»»åŠ¡çš„ç¼–æ’

CronJob å»ºç«‹åœ¨Jobçš„åŠŸèƒ½ä¹‹ä¸Šï¼Œæ˜¯æ›´é«˜å±‚çº§çš„æ§åˆ¶å™¨

å®ƒä»¥Jobæ§åˆ¶å™¨å®Œæˆå•æ‰¹æ¬¡çš„ä»»åŠ¡ç¼–æ’ï¼Œè€Œåä¸ºè¿™ç§Jobä½œä¸šæä¾›éœ€è¦è¿è¡Œçš„å‘¨æœŸå®šä¹‰

CronJobå…¶å®å°±æ˜¯åœ¨Jobçš„åŸºç¡€ä¸ŠåŠ ä¸Šäº†æ—¶é—´è°ƒåº¦ï¼Œå¯ä»¥åœ¨ç»™å®šçš„æ—¶é—´ç‚¹å¯åŠ¨ä¸€ä¸ªPod æ¥è¿è¡Œä»»åŠ¡ï¼Œä¹Ÿå¯ ä»¥å‘¨æœŸæ€§åœ°åœ¨ç»™å®šæ—¶é—´ç‚¹å¯åŠ¨Podè¿è¡Œä»»åŠ¡ã€‚

CronJob è¢«è°ƒç”¨çš„æ—¶é—´æ˜¯æ¥è‡ªäºcontroller-managerçš„æ—¶é—´,éœ€è¦ç¡®ä¿controller-managerå‡†ç¡®

å¦å¤–CronJobæ‰§è¡Œæ—¶,éœ€è¦æ‹‰å–é•œåƒä¹Ÿéœ€è¦ä¸€å®šçš„æ—¶é—´,æ‰€ä»¥å¯èƒ½ä¼šå¯¼è‡´çœŸæ­£æ‰§è¡Œçš„æ—¶é—´ä¸å‡†ç¡® å¯¹äºæ²¡æœ‰æŒ‡å®šæ—¶åŒºçš„ CronJobï¼Œkube-controller-manager åŸºäºæœ¬åœ°æ—¶åŒºè§£é‡Šæ’æœŸè¡¨ï¼ˆScheduleï¼‰

**åˆ é™¤CronJobï¼ŒåŒæ—¶ä¼šçº§è”åˆ é™¤ç›¸å…³çš„Jobå’ŒPod**

ä¸€ä¸ªCronJobå¯¹è±¡å…¶å®å°±å¯¹åº”ä¸­crontabæ–‡ä»¶ä¸­çš„ä¸€è¡Œï¼Œå®ƒæ ¹æ®é…ç½®çš„æ—¶é—´æ ¼å¼å‘¨æœŸæ€§åœ°è¿è¡Œä¸€ä¸ªJobï¼Œ æ ¼å¼å’Œcrontabä¹Ÿæ˜¯ç›¸åŒçš„

æ³¨æ„ï¼šåœ¨CronJobä¸­ï¼Œé€šé…ç¬¦â€œ?â€å’Œâ€œ*â€çš„æ„ä¹‰ç›¸åŒï¼Œå®ƒä»¬éƒ½è¡¨ç¤ºä»»ä½•å¯ç”¨çš„æœ‰æ•ˆå€¼



**Cron æ—¶é—´è¡¨è¯­æ³•**

```bash
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆ†é’Ÿ (0 - 59)
# â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å°æ—¶ (0 - 23)
# â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æœˆçš„æŸå¤© (1 - 31)
# â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æœˆä»½ (1 - 12)
# â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å‘¨çš„æŸå¤© (0 - 6)ï¼ˆå‘¨æ—¥åˆ°å‘¨ä¸€ï¼›åœ¨æŸäº›ç³»ç»Ÿä¸Šï¼Œ7 ä¹Ÿæ˜¯æ˜ŸæœŸæ—¥ï¼‰
# â”‚ â”‚ â”‚ â”‚ â”‚                         æˆ–è€…æ˜¯ sunï¼Œmonï¼Œtueï¼Œwebï¼Œthuï¼Œfriï¼Œsat
# â”‚ â”‚ â”‚ â”‚ â”‚
# â”‚ â”‚ â”‚ â”‚ â”‚
# * * * * *
```



| è¾“å…¥                   | æè¿°                         | ç›¸å½“äº    |
| ---------------------- | ---------------------------- | --------- |
| @yearly (or @annually) | æ¯å¹´ 1 æœˆ 1 æ—¥çš„åˆå¤œè¿è¡Œä¸€æ¬¡ | 0 0 1 1 * |
| @monthly               | æ¯æœˆç¬¬ä¸€å¤©çš„åˆå¤œè¿è¡Œä¸€æ¬¡     | 0 0 1 * * |
| @weekly                | æ¯å‘¨çš„å‘¨æ—¥åˆå¤œè¿è¡Œä¸€æ¬¡       | 0 0 * * 0 |
| @daily (or @midnight)  | æ¯å¤©åˆå¤œè¿è¡Œä¸€æ¬¡             | 0 0 * * * |
| @hourly                | æ¯å°æ—¶çš„å¼€å§‹ä¸€æ¬¡             | 0 * * * * |



#### CronJobå±æ€§è§£æ

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: <string>
  namespace: <string>
spec:
  jobTemplate: <object>
    metadata: <object>
    spec: <object>
  schedule: <string>                   # è°ƒåº¦æ—¶é—´è®¾å®šï¼Œå¿…é€‰å­—æ®µï¼Œæ ¼å¼å’ŒLinuxçš„cronjobç›¸åŒ
  concurrencyPolicy: <string>          # å¤šä¸ªCronjobæ˜¯å¦è¿è¡Œå¹¶å‘ç­–ç•¥ï¼Œå¯ç”¨å€¼æœ‰Allow,Forbidå’ŒReplace
                                       # Allow å…è®¸ä¸Šä¸€ä¸ªCronJobæ²¡æœ‰å®Œæˆï¼Œå¼€å§‹æ–°çš„ä¸€ä¸ªCronJobå¼€å§‹æ‰§è¡Œ
                                       # Forbid ç¦æ­¢åœ¨ä¸Šä¸€ä¸ªCronJobè¿˜æ²¡å®Œæˆï¼Œå°±å¼€å§‹æ–°çš„ä»»åŠ¡
                                       # Replace å½“ä¸Šä¸€ä¸ªCronJobæ²¡æœ‰å®Œæˆæ—¶ï¼Œæ€æ‰æ—§ä»»åŠ¡ï¼Œç”¨æ–°çš„ä»»åŠ¡ä»£æ›¿
  failedJobsHistoryLimit: <integer>    # å¤±è´¥ä½œä¸šçš„å†å²è®°å½•æ•°ï¼Œé»˜è®¤ä¸º1ï¼Œå»ºè®®è®¾ç½®æ­¤å€¼ç¨å¤§ä¸€äº›ï¼Œæ–¹ä¾¿æŸ¥çœ‹åŸå› 
  successfulDeadlineSeconds: <integer> # æˆåŠŸä½œä¸šçš„å†å²è®°å½•æ•°ï¼Œé»˜è®¤ä¸º3
  startingDeadlineSeconds: <integer>   # å› é”™è¿‡æ—¶é—´ç‚¹è€Œæœªæ‰§è¡Œçš„ä½œä¸šçš„å¯è¶…æœŸæ—¶é•¿ï¼Œä»å¯ç»§ç»­æ‰§è¡Œ
  suspend: <boolean>                   # æ˜¯å¦æŒ‚èµ·åç»­çš„ä½œä¸šï¼Œä¸å½±å“å½“å‰çš„ä½œä¸šï¼Œé»˜è®¤ä¸ºfalse
  

# å®˜æ–¹ç¤ºä¾‹
apiVersion: batch/v1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "* * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox:1.28
            imagePullPolicy: IfNotPresent
            command:
            - /bin/sh
            - -c
            - date; echo Hello from the kubernetes cluster
          restartPolicy: OnFailure
```



#### CronJobæ¡ˆä¾‹

##### ç¤ºä¾‹ï¼šå•å‘¨æœŸä»»åŠ¡

```yaml
# cat controller-cronjob-simple.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cronjob
spec:
  schedule: "*/2 * * * *"   # æ¯2åˆ†é’Ÿæ‰§è¡Œ1æ¬¡
  jobTemplate:
    spec:
      #parallelism: 2       # ä¸¤è·¯å¹¶è¡Œ
      #completions: 2
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: cronjob
            image: busybox:1.30.0
            command: ["/bin/sh", "-c", "echo Cron Job"]
            
# å¯åŠ¨
[root@master1 loadBalancer]#kubectl apply -f controller-cronjob-simple.yaml 
cronjob.batch/cronjob created

# æŸ¥çœ‹cronjob
[root@master1 loadBalancer]#kubectl get cronjobs.batch 
NAME      SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob   */2 * * * *   <none>     False     0        <none>          13s

# å¯ä»¥è§‚å¯Ÿåˆ°cronjobæ˜¯å‘¨æœŸæ€§åˆ›å»ºjob
[root@master1 loadBalancer]#kubectl get job
NAME               STATUS     COMPLETIONS   DURATION   AGE
cronjob-28915564   Complete   1/1           3s         2m14s
cronjob-28915566   Complete   1/1           3s         14s

[root@master1 loadBalancer]#kubectl get pod
NAME                     READY   STATUS      RESTARTS   AGE
cronjob-28915564-zx5vh   0/1     Completed   0          2m50s
cronjob-28915566-trj2l   0/1     Completed   0          50s
```





## KubernetesæœåŠ¡å‘ç°



**æœ¬ç« å†…å®¹**

- **æœåŠ¡è®¿é—®**
- **æœåŠ¡å‘ç°**
- **åŸŸåè§£æ**
- **æ— å¤´æœåŠ¡**





### æœåŠ¡è®¿é—®

Kubernetesé›†ç¾¤æä¾›äº†è¿™æ ·çš„ä¸€ä¸ªèµ„æºå¯¹è±¡Serviceï¼Œå®ƒå®šä¹‰äº†ä¸€ç»„Podçš„é€»è¾‘é›†åˆå’Œä¸€ä¸ªç”¨äºè®¿é—®å®ƒä»¬ çš„å…¥å£ç­–ç•¥

Service å¯ä»¥**åŸºäºæ ‡ç­¾çš„æ–¹å¼**è‡ªåŠ¨æ‰¾åˆ°å¯¹åº”çš„podåº”ç”¨ï¼Œè€Œæ— éœ€å…³å¿ƒpodçš„ipåœ°å€å˜åŒ–ä¸å¦ï¼Œä»è€Œå®ç°äº† ç±»ä¼¼è´Ÿè½½å‡è¡¡çš„æ•ˆæœ

Service æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ª**å››å±‚çš„åå‘ä»£ç†**ï¼Œé›†ç¾¤å†…å’Œå¤–çš„å®¢æˆ·ç«¯å¯ä»¥é€šè¿‡å¦‚ä¸‹æµç¨‹æœ€ç»ˆå®ç°è®¿é—®Podåº”ç”¨

```ABAP
é›†ç¾¤å†…éƒ¨Client --> serviceç½‘ç»œ --> Podç½‘ç»œ --> å®¹å™¨åº”ç”¨
é›†ç¾¤å¤–éƒ¨Client --> é›†ç¾¤å†…èŠ‚ç‚¹ç½‘ç»œ --> serviceç½‘ç»œ --> Podç½‘ç»œ --> å®¹å™¨åº”ç”¨

Kubernetesç½‘ç»œ
Podç½‘ç»œ     ----  cni
Serviceç½‘ç»œ ----  kubeproxy
nodeç½‘ç»œ    ----  å®¿ä¸»æœºç½‘ç»œ
```



Service èµ„æºåœ¨masterç«¯çš„Controllerç»„ä»¶ä¸­ï¼Œç”± Service Controller æ¥è¿›è¡Œç»Ÿä¸€ç®¡ç†ã€‚

serviceæ˜¯Kubernetesé‡Œæœ€æ ¸å¿ƒçš„APIèµ„æºå¯¹è±¡ä¹‹ä¸€ï¼Œå®ƒæ˜¯ç”±corednsæˆ–è€…kube-dnsç»„ä»¶æä¾›çš„åŠŸèƒ½ã€‚

Service æ˜¯åŸºäºåç§°ç©ºé—´çš„èµ„æº



Kubernetes çš„ Serviceå®šä¹‰äº†ä¸€ä¸ªæœåŠ¡çš„è®¿é—®å…¥å£åœ°å€ï¼Œå‰ç«¯çš„åº”ç”¨Podé€šè¿‡Serviceè®¿é—®å…¶èƒŒåä¸€ç»„æœ‰ Podå‰¯æœ¬ç»„æˆçš„é›†ç¾¤å®ä¾‹ï¼ŒServiceé€šè¿‡**Label Selector**è®¿é—®æŒ‡å®šçš„åç«¯Podï¼ŒRCä¿è¯Serviceçš„æœåŠ¡èƒ½åŠ›å’ŒæœåŠ¡è´¨é‡å¤„äºé¢„æœŸçŠ¶æ€ã€‚



æ¯ä¸ªPodéƒ½æœ‰ä¸€ä¸ªä¸“ç”¨çš„IPåœ°å€ï¼ŒåŠ ä¸ŠPodå†…éƒ¨å®¹å™¨çš„Portç«¯å£ï¼Œå°±ç»„æˆäº†ä¸€ä¸ªè®¿é—®Podä¸“ç”¨çš„ EndPoint(Pod IP+Container Port)ï¼Œä»è€Œå®ç°äº†ç”¨æˆ·å¤–éƒ¨èµ„æºè®¿é—®Podå†…éƒ¨åº”ç”¨çš„æ•ˆæœã€‚

è¿™ä¸ªEndPointèµ„æºåœ¨masterç«¯çš„Controllerç»„ä»¶ä¸­ï¼Œç”±EndPoint Controller æ¥è¿›è¡Œç»Ÿä¸€ç®¡ç†ã€‚

å½“å¤šä¸ªPodç»„æˆäº†ä¸€ä¸ªä¸šåŠ¡é›†ç¾¤æ¥æä¾›å¤–éƒ¨æœåŠ¡ï¼Œé‚£ä¹ˆå¤–éƒ¨å®¢æˆ·ç«¯æ€ä¹ˆæ‰èƒ½è®¿é—®ä¸šåŠ¡é›†ç¾¤æœåŠ¡å‘¢ï¼Ÿ

![image-20241223144004352](../markdown_img/image-20241223144004352.png)

æ ¹æ®Podæ‰€å¤„çš„Nodeåœºæ™¯ï¼Œæœ‰ä¸¤ç§æƒ…å†µï¼š

- æ‰€æœ‰Podå‰¯æœ¬éƒ½åœ¨åŒä¸€NodeèŠ‚ç‚¹ä¸Šï¼šå¯¹äºè¿™ç§æƒ…å†µï¼Œå°†Nodeç‰©ç†èŠ‚ç‚¹ä¸“ç”¨çš„IPï¼Œä½œä¸ºè´Ÿè½½å‡è¡¡å™¨ çš„VIPï¼Œå³å¯å®ç°è´Ÿè½½å‡è¡¡åç«¯æœåŠ¡çš„æ•ˆæœã€‚
- æ‰€æœ‰Podå‰¯æœ¬ä¸åœ¨åŒä¸€NodeèŠ‚ç‚¹ä¸Šï¼šNodeèŠ‚ç‚¹çš„ç‰©ç†ipå°±æ²¡æœ‰åŠæ³•ä½œä¸ºè´Ÿè½½å‡è¡¡å™¨çš„VIPäº†ï¼Œè¿™ä¹Ÿ æ˜¯æ›´ä¸ºå¸¸è§çš„æƒ…å†µã€‚



Kuberneteså‘æ˜äº†ä¸€ç§è®¾è®¡ï¼Œç»™Serviceåˆ†é…ä¸€ä¸ªå…¨å±€å”¯ä¸€çš„è™šæ‹Ÿipåœ°å€--**cluster IP**ï¼Œå®ƒä¸å­˜åœ¨ä»»ä½•ç½‘ç»œ è®¾å¤‡ä¸Šï¼ŒServiceé€šè¿‡å†…éƒ¨çš„**æ ‡ç­¾é€‰æ‹©å™¨**ï¼ŒæŒ‡å®šç›¸åº”è¯¥Serviceçš„Podèµ„æºï¼Œå½“è¯·æ±‚å‘ç»™cluster IPï¼Œåç«¯ çš„Podèµ„æºæ”¶åˆ°è¯·æ±‚åï¼Œå°±ä¼šå“åº”è¯·æ±‚ã€‚

è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯ä¸ªServiceéƒ½æœ‰ä¸€ä¸ªå…¨å±€å”¯ä¸€é€šä¿¡åœ°å€ï¼Œæ•´ä¸ªç³»ç»Ÿçš„å†…éƒ¨æœåŠ¡é—´è°ƒç”¨å°±å˜æˆäº†æœ€åŸºç¡€çš„ TCP/IPç½‘ç»œé€šä¿¡é—®é¢˜ã€‚å¦‚æœæˆ‘ä»¬çš„é›†ç¾¤å†…éƒ¨çš„æœåŠ¡æƒ³è¦å’Œå¤–éƒ¨çš„ç½‘ç»œè¿›è¡Œé€šä¿¡ï¼Œå¯ä»¥æœ‰å¤šç§æ–¹æ³•ï¼Œæ¯” å¦‚ï¼š

- NodePortç±»å‹ï¼Œé€šè¿‡åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå¢åŠ ä¸€ä¸ªå¯¹å¤–çš„ç«¯å£ï¼Œç”¨äºæ¥å…¥é›†ç¾¤å¤–éƒ¨è¯·æ±‚
- ingressç±»å‹ï¼Œé€šè¿‡é›†ç¾¤é™„åŠ æœåŠ¡åŠŸèƒ½ï¼Œå°†å¤–éƒ¨çš„åŸŸåæµé‡è½¬äº¤åˆ°é›†ç¾¤å†…éƒ¨ã€‚



**Service æ ¸å¿ƒåŠŸèƒ½**

- æœåŠ¡å‘ç°: åˆ©ç”¨æ ‡ç­¾é€‰æ‹©å™¨ï¼Œåœ¨åŒä¸€ä¸ªnamespaceä¸­ç­›é€‰ç¬¦åˆçš„æ¡ä»¶çš„Pod, ä»é¢å®ç°å‘ç°ä¸€ç»„æä¾› äº†ç›¸åŒæœåŠ¡çš„Pod
- è´Ÿè½½å‡è¡¡: Serviceä½œä¸ºæµé‡å…¥å£å’Œè´Ÿè½½å‡è¡¡å™¨ï¼Œå…¶å…¥å£ä¸ºClusterIP, è¿™ç»„ç­›é€‰å‡ºçš„Podçš„IPåœ°å€ï¼Œå°† ä½œä¸ºè¯¥Serviceçš„åç«¯æœåŠ¡å™¨
- åç§°è§£æ: åˆ©ç”¨Cluster DNSï¼Œä¸ºè¯¥ç»„Podæ‰€ä»£è¡¨çš„æœåŠ¡æä¾›ä¸€ä¸ªåç§°, åœ¨DNSä¸­ å¯¹äºæ¯ä¸ªServiceï¼Œ è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªAã€PTRå’ŒSRVè®°å½•



```ABAP
[root@master1 loadBalancer]#kubectl get svc -A
NAMESPACE     NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
default       kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP                  4d1h
kube-system   kube-dns     ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   4d1h

# ä½¿ç”¨10.96.0.1æ¥è®¿é—®api-server
# ä½¿ç”¨10.96.0.10æ¥è®¿é—®dnsï¼Œè¿›è¡ŒåŸŸåè§£æ
# å› ä¸ºåœ¨k8sä¸­ï¼Œcore-dnså’Œapi-serveréƒ½æ˜¯ä»¥å®¹å™¨æ–¹å¼å­˜åœ¨ï¼Œæœ¬èº«åœ°å€ä¸å›ºå®šï¼Œå› æ­¤éœ€è¦å€ŸåŠ©serviceè¿›è¡Œè®¿é—®
```



#### Endpoints

å½“åˆ›å»º Serviceèµ„æºçš„æ—¶å€™ï¼Œæœ€é‡è¦çš„å°±æ˜¯ä¸ºServiceæŒ‡å®šèƒ½å¤Ÿæä¾›æœåŠ¡çš„æ ‡ç­¾é€‰æ‹©å™¨

Service Controllerå°±ä¼šæ ¹æ®æ ‡ç­¾é€‰æ‹©å™¨ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªåŒåçš„**Endpoint**èµ„æºå¯¹è±¡ï¼ŒKubernetesæ–°ç‰ˆä¸­è¿˜å¢åŠ äº†**endpointslices**èµ„æº

- Endpoint Controllerä½¿ç”¨Endpointçš„æ ‡ç­¾é€‰æ‹©å™¨(ç»§æ‰¿è‡ªServiceæ ‡ç­¾é€‰æ‹©å™¨)ï¼Œç­›é€‰ç¬¦åˆæ¡ä»¶(åŒ…æ‹¬ ç¬¦åˆæ ‡ç­¾é€‰æ‹©å™¨æ¡ä»¶å’Œå¤„äºReady çŠ¶æ€)çš„podèµ„æº
- Endpoint Controller å°†ç¬¦åˆè¦æ±‚çš„podèµ„æºç»‘å®šåˆ°Endpointä¸Šï¼Œå¹¶å‘ŠçŸ¥ç»™Serviceèµ„æºè°å¯ä»¥æ­£å¸¸æä¾›æœåŠ¡
- Service ä¼šè‡ªåŠ¨è·å–ä¸€ä¸ªå›ºå®šçš„ **cluster IP**å‘å¤–æä¾›ç”±Endpointæä¾›çš„æœåŠ¡èµ„æº
- Service å…¶å®å°±æ˜¯ä¸ºåŠ¨æ€çš„ä¸€ç»„ pod èµ„æºå¯¹è±¡æä¾›ä¸€ä¸ªå›ºå®šçš„è®¿é—®å…¥å£ã€‚å³ Serviceå®ç°äº†åç«¯Pod åº”ç”¨æœåŠ¡çš„å‘ç°åŠŸèƒ½ 





![image-20241223151136366](../markdown_img/image-20241223151136366.png)



- æ¯åˆ›å»ºä¸€ä¸ªService ,è‡ªåŠ¨åˆ›å»ºä¸€ä¸ªå’Œä¹‹åŒåçš„API èµ„æºç±»å‹ Endpoints
- Endpointsè´Ÿè´£ç»´æŠ¤ç”±ç›¸å…³Serviceæ ‡ç­¾é€‰æ‹©å™¨åŒ¹é…çš„Podå¯¹è±¡
- Endpointså¯¹è±¡ä¸Šä¿å­˜ServiceåŒ¹é…åˆ°çš„æ‰€æœ‰Podçš„IPå’ŒPortä¿¡æ¯,ç§°ä¹‹ä¸ºç«¯ç‚¹
- ETCDæ˜¯K/Væ•°æ®åº“, è€Œä¸€ä¸ª**Endpointså¯¹è±¡å¯¹åº”ä¸€ä¸ªKey**,æ‰€æœ‰**åç«¯Podç«¯ç‚¹ä¿¡æ¯ä¸ºå…¶Value**
- å½“ä¸€ä¸ªEndpointså¯¹è±¡å¯¹åº”åç«¯æ¯ä¸ªPodçš„æ¯æ¬¡å˜åŠ¨ï¼Œéƒ½éœ€æ›´æ–°æ•´ä¸ªEndpointså¯¹è±¡ï¼Œå¹¶å°†æ–°çš„ Endpointså¯¹è±¡é‡æ–°ä¿å­˜è‡³API Serverå’ŒETCD
- æ­¤å¤–è¿˜éœ€è¦å°†è¯¥å¯¹è±¡åŒæ­¥è‡³æ¯ä¸ªèŠ‚ç‚¹çš„kube-proxy
- åœ¨ETCDä¸­çš„å¯¹è±¡é»˜è®¤æœ€å¤§ä¸º1.5MB,ä¸€ä¸ªEndpointså¯¹è±¡è‡³å¤šå¯ä»¥å­˜å‚¨5000ä¸ªå·¦å³çš„ç«¯ç‚¹ä¿¡æ¯,è¿™æ„ å‘³ç€å¹³å‡æ¯ç«¯ç‚¹å 300KB



#### EndpointSlice

æ–°ç‰ˆKubernetesä¸ºä»€ä¹ˆéœ€è¦å¼•ç”¨EndpointSliceå‘¢?

![image-20241223151352710](../markdown_img/image-20241223151352710.png)

- åŸºäºEndpointsæœºåˆ¶ï¼Œå³ä¾¿åªæœ‰ä¸€ä¸ªPodçš„IPç­‰ä¿¡æ¯å‘ç”Ÿå˜åŠ¨ï¼Œå°±éœ€è¦å‘é›†ç¾¤ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ kube-proxyå‘é€æ•´ä¸ªendpointså¯¹è±¡
- æ¯”å¦‚: ä¸€ä¸ªç”±2000ä¸ªèŠ‚ç‚¹ç»„æˆçš„é›†ç¾¤ä¸­ï¼Œæ›´æ–°ä¸€ä¸ªæœ‰5000ä¸ªPod IPå ç”¨1.5MBç©ºé—´çš„Endpoints å¯¹ è±¡ï¼Œå°±éœ€è¦å‘é€3GBçš„æ•°æ®
  - è‹¥ä»¥æ»šåŠ¨æ›´æ–°æœºåˆ¶ï¼Œä¸€æ¬¡åªå‡çº§æ›´æ–°ä¸€ä¸ªPodçš„ä¿¡æ¯ï¼Œè¿™å°†å¯¼è‡´æ›´æ–°è¿™ä¸ªEndpointså¯¹è±¡éœ€è¦å‘é€ 15Tçš„æ•°æ®
- EndpointSliceèµ„æºé€šè¿‡å°†Endpointsåˆ‡åˆ†ä¸ºå¤šç‰‡æ¥è§£å†³ä¸Šè¿°é—®é¢˜
- è‡ªKubernetes v1.16å¼•å…¥EndpointSlice
- æ¯ä¸ªç«¯ç‚¹ä¿¡æ¯çš„å˜åŠ¨ï¼Œä»…éœ€è¦æ›´æ–°å’Œå‘é€ä¸€ä¸ª**EndpontSliceå¯¹è±¡**,è€Œéæ•´ä¸ªEndpointså¯¹è±¡
- æ¯ä¸ªEndpointSliceé»˜è®¤å­˜å‚¨100ä¸ªç«¯ç‚¹ä¿¡æ¯ï¼Œä¸ä¼šè¶…è¿‡ etcdå¯¹å•ä¸ªå¯¹è±¡çš„å­˜å‚¨é™åˆ¶
- å¯åœ¨kube-controller-managerç¨‹åºä¸Šä½¿ç”¨ **--max-endpoints-per-slice** é€‰é¡¹è¿›è¡Œé…ç½®
- EndpointSliceå¹¶æœªå–ä»£Endpointsï¼ŒäºŒè€…åŒæ—¶å­˜åœ¨



```bash
# æŸ¥çœ‹endpointå’Œendpointslices
[root@master1 loadBalancer]#kubectl get endpointslices -A
NAMESPACE     NAME             ADDRESSTYPE   PORTS        ENDPOINTS                 AGE
default       kubernetes       IPv4          6443         10.0.0.201                4d2h
kube-system   kube-dns-5zfkl   IPv4          9153,53,53   10.244.2.40,10.244.2.38   4d2h
[root@master1 loadBalancer]#kubectl get ep -A
NAMESPACE     NAME         ENDPOINTS                                                  AGE
default       kubernetes   10.0.0.201:6443                                            4d2h
kube-system   kube-dns     10.244.2.38:53,10.244.2.40:53,10.244.2.38:53 + 3 more...   4d2h
```





#### Serviceè®¿é—®è¿‡ç¨‹

![image-20241223153657945](../markdown_img/image-20241223153657945.png)



#### endpointsæ‰©å±•æ€è·¯

```ABAP
å¯ä»¥æ‰‹åŠ¨åˆ›å»ºendpointsï¼Œå¹¶å°†é›†ç¾¤å¤–èµ„æºåŠ å…¥endpointsçš„é˜Ÿåˆ—ä¸­ï¼Œå®ç°é›†ç¾¤å†…çš„podè®¿é—®é›†ç¾¤å¤–èµ„æºçš„æ•ˆæœ
```



#### Service å·¥ä½œæ¨¡å‹

ä¸€ä¸ªServiceå¯¹è±¡æœ€ç»ˆä½“ç°ä¸ºå·¥ä½œèŠ‚ç‚¹ä¸Šçš„ä¸€äº›**iptablesæˆ–ipvsè§„åˆ™**ï¼Œè¿™äº›è§„åˆ™æ˜¯ç”±kube-proxyè¿›è¡Œå®æ—¶ç”Ÿæˆå’Œç»´æŠ¤\



**é’ˆå¯¹æŸä¸€ç‰¹å®šæœåŠ¡ï¼Œå¦‚ä½•å°†é›†ç¾¤ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½å˜æˆå…¶å‡è¡¡å™¨ï¼š**

- åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œä¸€ä¸ªkube-proxyï¼Œç”±kube-proxyæ³¨å†Œç›‘è§†API Serverçš„Serviceèµ„æºçš„åˆ›å»ºã€ä¿® æ”¹å’Œåˆ é™¤
- å°†Serviceçš„å®šä¹‰ï¼Œè½¬ä¸ºæœ¬åœ°è´Ÿè½½å‡è¡¡åŠŸèƒ½çš„è½åœ°å®ç°



**kube-proxyå°†è¯·æ±‚ä»£ç†è‡³ç›¸åº”ç«¯ç‚¹çš„å®ç°æ–¹å¼æœ‰å››ç§ï¼š**

- userspaceï¼ˆåœ¨kubernetes  v1.2ä»¥åæ·˜æ±°ï¼‰
- **iptables**ï¼š iptableså·¥å…·ï¼Œé»˜è®¤æ¨¡å¼
- **ipvs**
- nftables: ä»kubernetes-v1.29.0 ä¹‹åç‰ˆæœ¬æ”¯æŒ,nft å·¥å…·
- kernelspace: ä»…Windowsä½¿ç”¨



è¿™äº›æ–¹æ³•çš„ç›®çš„æ˜¯ï¼škube-proxyå¦‚ä½•ç¡®ä¿serviceèƒ½åœ¨æ¯ä¸ªèŠ‚ç‚¹å®ç°å¹¶æ­£å¸¸å·¥ä½œ

æ³¨æ„: ä¸€ä¸ªé›†ç¾¤åªèƒ½é€‰æ‹©ä½¿ç”¨ä¸€ç§Modeï¼Œå³é›†ç¾¤ä¸­æ‰€æœ‰èŠ‚ç‚¹è¦ä½¿ç”¨ç›¸åŒçš„æ–¹å¼



#### Serviceå’Œkube-proxyå…³è”å…³ç³»

![image-20241223160711007](../markdown_img/image-20241223160711007.png)

- Serviceä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„APIèµ„æºå¯¹è±¡ï¼Œå®ƒä¼šåœ¨API ServiceæœåŠ¡ä¸­å®šä¹‰å‡ºæ¥çš„
- åœ¨åˆ›å»ºä»»ä½•å­˜åœ¨æ ‡ç­¾é€‰æ‹©å™¨çš„Serviceæ—¶ï¼Œéƒ½ä¼šè¢«è‡ªåŠ¨åˆ›å»ºä¸€ä¸ªåŒåçš„Endpointsèµ„æºï¼ŒEndpoints  å¯¹è±¡ä¼šä½¿ç”¨Label Selectorè‡ªåŠ¨å‘ç°åç«¯ç«¯ç‚¹ï¼Œå¹¶å„ç«¯ç‚¹çš„IPé…ç½®ä¸ºå¯ç”¨åœ°å€åˆ—è¡¨çš„å…ƒç´ 
- Service Controller è§¦å‘æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„kube-proxyï¼Œç”±kube-proxyå®æ—¶çš„è½¬æ¢ä¸ºæœ¬åœ°èŠ‚ç‚¹ä¸Šé¢çš„ ipvs/iptablesè§„åˆ™ã€‚
- é»˜è®¤æƒ…å†µä¸‹ï¼Œå†…æ ¸ä¸­çš„ipvsæˆ–iptablesè§„åˆ™ï¼Œä»…ä»…æ˜¯è´Ÿè´£æœ¬åœ°èŠ‚ç‚¹ç”¨æˆ·ç©ºé—´podå®¢æˆ·ç«¯å‘å‡ºè¯·æ±‚æ—¶ çš„æ‹¦æˆªæˆ–è€…è½¬å‘è§„åˆ™
- å¦‚æœPodå®¢æˆ·ç«¯å‘Serviceå‘å‡ºè¯·æ±‚,å®¢æˆ·ç«¯å‘å†…æ ¸å‘å‡ºè¯·æ±‚ï¼Œæ ¹æ®ipvsæˆ–iptablesè§„åˆ™ï¼ŒåŒ¹é…ç›®æ ‡ service
- å¦‚æœserviceåŒ¹é…ï¼Œä¼šè¿”å›å½“å‰serviceéšå¯¹åº”çš„åç«¯endpointæœ‰å“ªäº›
- iptablesæˆ–ipvsä¼šæ ¹æ®æƒ…å†µæŒ‘é€‰ä¸€ä¸ªåˆé€‚çš„endpointåœ°å€
  - å¦‚æœendpointæ˜¯æœ¬æœºä¸Šçš„ï¼Œåˆ™ä¼šè½¬å‘ç»™æœ¬æœºçš„endpoint
  - å¦‚æœendpointæ˜¯å…¶ä»–ä¸»æœºä¸Šçš„ï¼Œåˆ™è½¬å‘ç»™å…¶ä»–ä¸»æœºä¸Šçš„endpoint



#### Serviceç±»å‹

å¯¹äºKubernetes å¯ä»¥å®ç°å†…éƒ¨æœåŠ¡çš„è‡ªç”±é€šä¿¡,ä¹Ÿå¯ä»¥å°†å¹³å°å†…éƒ¨çš„æœåŠ¡å‘å¸ƒåˆ°å¤–éƒ¨ç¯å¢ƒ

Serviceä¸»è¦æœ‰å››ç§ç±»å‹ï¼Œå®ç°ä¸åŒçš„ç½‘ç»œé€šä¿¡åŠŸèƒ½

- ClusterIP
- NodePort
- LoadBalancer
- ExternalName



| ç±»å‹         | è§£æ                                                         |
| ------------ | ------------------------------------------------------------ |
| ClusterIP    | æ­¤ä¸ºServiceçš„é»˜è®¤ç±»å‹<br />ä¸º**é›†ç¾¤å†…éƒ¨çš„å®¢æˆ·ç«¯è®¿é—®**,åŒ…æ‹¬èŠ‚ç‚¹å’ŒPodç­‰ï¼Œ**å¤–éƒ¨ç½‘ç»œæ— æ³•è®¿é—®**<br />In client --> clusterIP: ServicePort (Service) --> PodIP: PodPort |
| NodePort     | æœ¬è´¨ä¸Š**åœ¨ClusterIPæ¨¡å¼åŸºç¡€ä¸Š,å†å¤šåŠ äº†ä¸€å±‚ç«¯å£æ˜ å°„çš„å°è£…**,ç›¸å½“äºå¢å¼ºç‰ˆçš„ ClusterIP<br />é€šè¿‡NodeIP:NodePortå¯¹å¤–éƒ¨ç½‘ç»œæä¾›æœåŠ¡ï¼Œé»˜è®¤**éšæœºç«¯å£èŒƒå›´30000~32767**, å¯æŒ‡å®šä¸ºå›ºå®šç«¯å£<br />NodePortæ˜¯ä¸€ä¸ªéšæœºçš„ç«¯å£ï¼Œä»¥é˜²æ­¢ç«¯å£å†²çª,åœ¨**æ‰€æœ‰å®‰è£…kube-proxyçš„èŠ‚ç‚¹ ä¸Šéƒ½ä¼šæ‰“å¼€æ­¤ç›¸åŒçš„ç«¯å£**<br />å¯é€šè¿‡è®¿é—®ClusterIPå®ç°é›†ç¾¤å†…éƒ¨è®¿é—®,ä¹Ÿå¯ä»¥é€šè¿‡NodeIP:NortPortçš„æ–¹å¼å® ç°ä»é›†ç¾¤å¤–éƒ¨è‡³å†…éƒ¨çš„è®¿é—®<br />Ex Client --> NodeIP:NodePort (Service) --> PodIP:PodPort |
| LoadBalancer | åŸºäºNodePortåŸºç¡€ä¹‹ä¸Š**ï¼Œä½¿ç”¨é›†ç¾¤å¤–éƒ¨çš„è¿è¥å•†è´Ÿè½½å‡è¡¡å™¨æ–¹å¼å®ç°å¯¹å¤–æä¾›** æœåŠ¡,å¢å¼ºç‰ˆçš„NodePort<br/>åŸºäºäº‘è¿è¥å•†IaaSäº‘åˆ›å»ºä¸€ä¸ªKubernetesäº‘ï¼Œäº‘å¹³å°ä¹Ÿæ”¯æŒLBaaS(Load Balance as a Service)äº§å“æœåŠ¡<br/>Masterå€ŸåŠ©cloud-managerå‘LBaaSçš„APIè¯·æ±‚åŠ¨æ€åˆ›å»ºè½¯ä»¶LB,å³æ”¯æŒå’ŒKubernetes API Server è¿›è¡Œäº¤äº’<br/>å¦‚æœæ²¡æœ‰äº‘æœåŠ¡,å°†æ— æ³•è·å–EXTERNAL-IP,æ˜¾ç¤ºPendingçŠ¶æ€,åˆ™é™çº§ä¸º NodePortç±»å‹<br/>Ex Client --> LB_IP:LB_PORT --> NodeIP:NodePort(Service)--> PodIP:PodPort |
| ExternalName | å½“Kubernetesé›†ç¾¤éœ€è¦è®¿é—®é›†ç¾¤å¤–éƒ¨æœåŠ¡æ—¶ï¼Œéœ€è¦é€šè¿‡externalName**å°†å¤–éƒ¨ä¸»æœºå¼•å…¥åˆ°é›†ç¾¤å†…éƒ¨**<br />å¤–éƒ¨ä¸»æœºåä»¥ DNSæ–¹å¼è§£æä¸ºä¸€ä¸ª CNAMEè®°å½•ç»™Kubernetesé›†ç¾¤çš„å…¶ä»–ä¸»æœºæ¥ä½¿ç”¨<br />**è¿™ç§Serviceæ—¢æ²¡æœ‰ClusterIPï¼Œä¹Ÿæ²¡æœ‰NodePort.è€Œä¸”ä¾èµ–äºå†…éƒ¨çš„CoreDNSåŠŸèƒ½**<br />In client -->Cluster ServiceName --> CName --> External Service Name |





### ExternalIP

å¦‚æœæœ‰å¤–éƒ¨ IP èƒ½å¤Ÿè·¯ç”±åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªé›†ç¾¤èŠ‚ç‚¹ä¸Šï¼Œåˆ™ Kubernetes å¯ä»¥é€šè¿‡ externalIPs å°†Service  å…¬å¼€å‡ºå»ã€‚

å½“ç½‘ç»œæµé‡è¿›å…¥é›†ç¾¤æ—¶ï¼Œå¦‚æœ externalIPs ä½œä¸ºç›®çš„ IP åœ°å€å’Œç«¯å£éƒ½ä¸è¯¥ Service åŒ¹é…ï¼Œ Kubernetes  æ‰€é…ç½®çš„è§„åˆ™å’Œè·¯ç”±ä¼šç¡®ä¿æµé‡è¢«è·¯ç”±åˆ°è¯¥ Service çš„ç«¯ç‚¹ä¹‹ä¸€ã€‚

Serviceå¯é€šè¿‡ä½¿ç”¨èŠ‚ç‚¹ä¸Šé…ç½®çš„è¾…åŠ©IPåœ°å€æ¥å…¥é›†ç¾¤å¤–éƒ¨å®¢æˆ·ç«¯æµé‡

æµé‡å…¥å£ä»…èƒ½æ˜¯é…ç½®æœ‰è¯¥IPåœ°å€çš„èŠ‚ç‚¹ï¼Œå…¶å®ƒèŠ‚ç‚¹æ— æ•ˆï¼Œå› è€Œæ­¤æ—¶åœ¨èŠ‚ç‚¹é—´æ— è´Ÿè½½å‡è¡¡çš„æ•ˆæœ

external IPæ‰€åœ¨çš„èŠ‚ç‚¹æ•…éšœåï¼Œè¯¥æµé‡å…¥å£å¤±æ•ˆï¼Œé™¤éå°†è¯¥IPåœ°å€è½¬ç§»é…ç½®åˆ°å…¶å®ƒèŠ‚ç‚¹

å®šä¹‰ Service æ—¶ï¼Œä½ å¯ä»¥ä¸ºä»»ä½•æœåŠ¡ç±»å‹externalIPsã€‚

ç”±äº externalIPs æ˜¯ç»‘å®šåœ¨æŸä¸€ä¸ªèŠ‚ç‚¹ä¸Š,è€Œæ­¤èŠ‚ç‚¹å­˜åœ¨å•ç‚¹é—®é¢˜,å¯ä»¥é€šè¿‡Keepalivedç­‰æ–¹å¼å®ç°é«˜å¯ç”¨

**é«˜å¯ç”¨å¯¹å¤–è§£å†³æ–¹æ¡ˆ**

```ABAP
ExternalIP + VRRP Keepalived -----> Service -----> Pod
```



#### ExternalIPå®ç°

```yaml
# åˆ›å»ºå¸¦externalIPsçš„service
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
  externalIPs:
    - 10.0.0.88   

# æŸ¥çœ‹
[root@master1 ExternalIP]#kubectl get svc
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP   4d4h
my-service   ClusterIP   10.108.156.228   10.0.0.88     80/TCP    60s

# åˆ›å»ºdeployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-test
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rs-test
  template:
    metadata:
      labels:
        app: rs-test
        app.kubernetes.io/name: MyApp
    spec:
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1


[root@master1 loadBalancer] #kubectl apply -f controller-deployment-test.yaml 
deployment.apps/deployment-test created

# æŸ¥çœ‹ep
[root@master1 loadBalancer]#kubectl get ep
NAME         ENDPOINTS                                      AGE
kubernetes   10.0.0.201:6443                                4d4h
my-service   10.244.1.88:80,10.244.2.44:80,10.244.3.99:80   11m

# åœ¨å…¶ä¸­ä¸€ä¸ªèŠ‚ç‚¹ä¸Šæ·»åŠ ip
ip a a 10.0.0.88 dev eth0:1

# éªŒè¯æ•ˆæœ
[root@master1 ExternalIP]#curl 10.0.0.88
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: deployment-test-74b7f7d459-j4fx6, ServerIP: 10.244.2.44!
```



### Serviceç®¡ç†



#### åˆ›å»º Service æ–¹å¼è¯´æ˜

å¯¹äºServiceçš„åˆ›å»ºæœ‰ä¸¤ç§æ–¹æ³•ï¼š

- å‘½ä»¤è¡Œæ–¹æ³•
- YAML æ–‡ä»¶æ–¹æ³•



##### å‘½ä»¤è¡Œçš„æ–¹å¼

```bash
# åˆ›å»ºå‘½ä»¤1ï¼šï¼ˆå•ç‹¬åˆ›å»ºä¸€ä¸ªserviceæœåŠ¡ï¼‰
kubectl create service [flags] NAME [--tcp=port:targetPort] [--dry-run]

# flagså‚æ•°è¯¦è§£ï¼š
clusterip   Create a ClusterIP service.å°†é›†ç¾¤ä¸“ç”¨æœåŠ¡æ¥å£
nodeport     åˆ›å»ºä¸€ä¸ª NodePort service.å°†é›†ç¾¤å†…éƒ¨æœåŠ¡ä»¥ç«¯å£å½¢å¼å¯¹å¤–æä¾›
loadbalancer åˆ›å»ºä¸€ä¸ª LoadBalancer service.ä¸»è¦é’ˆå¯¹å…¬æœ‰äº‘æœåŠ¡
externalname Create an ExternalName service.å°†é›†ç¾¤å¤–éƒ¨æœåŠ¡å¼•å…¥é›†ç¾¤å†…éƒ¨

# åˆ›å»ºå‘½ä»¤2ï¼šï¼ˆé’ˆå¯¹ä¸€ä¸ªå·²å­˜åœ¨çš„deploymentã€podã€ReplicaSetç­‰åˆ›å»ºä¸€ä¸ªserviceï¼‰
kubectl expose (-f FILENAME | TYPE NAME) [--port=port] [--protocol=TCP|UDP|SCTP] [--target-port=number-or-name] [--name=name] [--external-ip=external-ip-of-service] [--type=type] [options]

# å‚æ•°è¯¦è§£
--port=''            #è®¾å®šserviceå¯¹å¤–çš„ç«¯å£ä¿¡æ¯
--target-port=''     #è®¾å®šå®¹å™¨çš„ç«¯å£,é»˜è®¤å’Œserviceçš„ç«¯å£ç›¸åŒ    
--type=''            #è®¾å®šç±»å‹ï¼Œæ”¯æŒå››ç§ï¼šClusterIP(é»˜è®¤), NodePort, LoadBalancer,ExternalName    
--cluster-ip=''      #è®¾å®šå¯¹å¤–çš„ClusterIPåœ°å€
--name=''            #åˆ›å»ºserviceå¯¹å¤–çš„svcåç§°

# åˆ›å»ºå‘½ä»¤3ï¼šï¼ˆåˆ›å»ºè‡ªä¸»å¼Podæ—¶åŠ¨åˆ›å»ºServiceï¼‰
kubectl run <Pod_name> --image é•œåƒ --expose --port <å®¹å™¨ç«¯å£>

# æŸ¥çœ‹å‘½ä»¤
kubectl get svc

# åˆ é™¤service
kubectl delete svc <svc_name> [ -n <namespace>[] [--all]
```





##### æ–‡ä»¶æ–¹å¼

è¯­æ³•è§£æ

```yaml
apiVersion: v1
kind: Service
metadata:
  name: ...
  namespace: ...
  labels:
    key1: value1
    key2: value2
spec:
  type: <string>                    # serviceç±»å‹ï¼Œé»˜è®¤ä¸ºClusterIP
  selector: <map[string]string>     # æŒ‡å®šç”¨äºè¿‡æ»¤å‡ºserviceæ‰€ä»£ç†çš„åç«¯podçš„æ ‡ç­¾ï¼ŒæŒ‡æ”¯æŒç­‰å€¼ç±»å‹çš„æ ‡ç­¾é€‰æ‹©å™¨
  ports:                            # Serviceçš„ç«¯å£å¯¹è±¡åˆ—è¡¨
  - name: <string>                  # ç«¯å£åç§°ï¼Œéœ€è¦ä¿è¯å”¯ä¸€æ€§
    protocol: <string>              # åè®®ï¼Œç›®å‰ä»…æ”¯æŒTCPã€UDPå’ŒSCTPï¼Œé»˜è®¤ä¸ºTCP
    port: <integer>                 # Serviceç«¯å£å·
    targetPort: <string>            # åç«¯Podçš„ç«¯å£å·æˆ–åç§°ï¼Œåç§°éœ€ç”±Podä¸­çš„è§„èŒƒå®šä¹‰ï¼Œå¦‚æœä¸å†™ï¼Œé»˜è®¤å’Œportä¸€è‡´
    nodePort: <integer>             # èŠ‚ç‚¹ç«¯å£å·ï¼Œä»…ä½¿ç”¨NodePortå’ŒLoadBalancerlç±»å‹ï¼ŒèŒƒå›´ï¼š30000-32768ï¼Œå»ºè®®ç³»ç»Ÿåˆ†é…
  - name: <string>
    ...
  clusterIP: <string>               # æŒ‡å®šServiceçš„é›†ç¾¤IPï¼Œå»ºè®®ä¸æŒ‡å®šè€Œç”±ç³»ç»Ÿåˆ†é…
  internalTrafficPolicy: <string>   # å†…éƒ¨æµé‡ç­–ç•¥å¤„ç†æ–¹å¼ï¼ŒLocalè¡¨ç¤ºç”±å½“å‰èŠ‚ç‚¹å¤„ç†ï¼ŒClusterè¡¨ç¤ºå‘é›†ç¾¤èŒƒå›´è°ƒåº¦ï¼Œé»˜è®¤                                         Cluster
  externalTrafficPolicy: <string>   # å¤–éƒ¨æµé‡ç­–ç•¥å¤„ç†æ–¹å¼ï¼Œé»˜è®¤ä¸ºClusterï¼Œå½“ä¸ºLocalæ—¶ï¼Œè¡¨ç¤ºç”±å½“å‰èŠ‚ç‚¹å¤„ç†ï¼Œæ€§èƒ½å¥½ï¼Œä½†æ—                                        è´Ÿè½½å‡è¡¡åŠŸèƒ½ï¼Œä¸”å¯ä»¥çœ‹åˆ°å®¢æˆ·ç«¯çœŸå®IPï¼ŒClusterè¡¨ç¤ºå‘é›†ç¾¤èŒƒå›´è°ƒåº¦ï¼Œå’ŒLocalç›¸åï¼ŒåŸºäº                                       æ€§èƒ½åŸå› ï¼Œç”Ÿäº§æ›´å»ºè®®Localï¼Œæ­¤æ–¹å¼åªæ”¯æŒtypeæ˜¯NodePortå’ŒLoadBalancerç±»å‹æˆ–è€…                                         ExternalIps
  loadBalancerIP: <string>          # å¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨ä½¿ç”¨çš„IPåœ°å€ï¼Œä»…é€‚ç”¨äºLoadBalancerï¼Œæ­¤å­—æ®µæœªæ¥å¯èƒ½åˆ é™¤
  externalName: <string>            # å¤–éƒ¨æœåŠ¡åç§°ï¼Œè¯¥åç§°å°†ä½œä¸ºServiceçš„DNS CNAMEå€¼
  externalIPs: <[]string>           # ç¾¤é›†ä¸­çš„èŠ‚ç‚¹å°†æ¥å—æ­¤æœåŠ¡çš„æµé‡çš„IPåœ°å€åˆ—è¡¨ã€‚è¿™äº›IPä¸ç”±Kubernetesç®¡ç†ã€‚ç”¨æˆ·è´Ÿè´£ç¡®ä¿                                       æµé‡åˆ°è¾¾å…·æœ‰æ­¤ IP çš„èŠ‚ç‚¹ã€‚å¸¸è§çš„æ˜¯ä¸å±äº Kubernetes ç³»ç»Ÿçš„å¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨ï¼Œæ³¨æ„ï¼š                                       æ­¤IPå’ŒTypeç±»å‹æ— å…³
```



#### è¡¥å……ï¼šDeployment.Name å’Œ Service.Name ç›¸åŒæ—¶ä¼šè‡ªåŠ¨åŒ¹é…çš„åŸç†

```bash
[root@master1 manifests]#kubectl create deployment pod-test1 --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas=3
deployment.apps/pod-test1 created

[root@master1 manifests]# kubectl create service clusterip pod-test1 --tcp=80:80
service/pod-test1 created

[root@master1 manifests]#kubectl get svc
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP   36d
pod-test1    ClusterIP   10.109.224.115   <none>        80/TCP    4s

[root@master1 manifests]#kubectl get ep pod-test1 
NAME        ENDPOINTS                                                 AGE
pod-test1   192.168.123.238:80,192.168.22.134:80,192.168.253.172:80   26s
```

- **Service å¹¶ä¸ä¼šç›´æ¥åŒ¹é… Deployment çš„ name**ï¼Œå®ƒåŒ¹é…çš„æ˜¯ **Pod çš„ labels**ã€‚

- **`kubectl create deployment` é»˜è®¤ä¼šç»™ Pod åŠ ä¸Š `app: <name>` ä½œä¸º label**ã€‚

- **`kubectl create service` ä¹Ÿé»˜è®¤ä½¿ç”¨ `app: <name>` ä½œä¸º `selector`ï¼Œä»è€Œå®ç°â€œè‡ªåŠ¨åŒ¹é…â€**ã€‚

- **å¦‚æœä½  `kubectl create service` æ—¶åŠ  `--selector` æŒ‡å®šä¸åŒçš„ labelï¼Œå°±ä¸ä¼šåŒ¹é…æˆåŠŸ**ã€‚



#### ClusterIP Serviceå®ç°

#####  å•ç«¯å£åº”ç”¨

```yaml
# å¦‚æœåŸºäºèµ„æºé…ç½®æ–‡ä»¶åˆ›å»ºèµ„æºï¼Œä¾èµ–äºåç«¯podçš„æ ‡ç­¾ï¼Œæ‰å¯ä»¥å…³è”åç«¯çš„èµ„æº
# å‡†å¤‡å¤šä¸ªåç«¯Podå¯¹è±¡
[root@master1 loadBalancer] # kubectl create deployment myweb --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas=3
deployment.apps/myweb created

# æŸ¥çœ‹æ•ˆæœ
[root@master1 service] # kubectl get pod --show-labels 
NAME                     READY   STATUS    RESTARTS   AGE     LABELS
myweb-565cb68445-6c928   1/1     Running   0          5m49s   app=myweb,pod-template-hash=565cb68445
myweb-565cb68445-fc6xg   1/1     Running   0          5m49s   app=myweb,pod-template-hash=565cb68445
myweb-565cb68445-rsbs6   1/1     Running   0          5m49s   app=myweb,pod-template-hash=565cb68445


# åˆ›å»ºserviceå¯¹è±¡
[root@master1 service] # vim service-clusterip-test.yaml
apiVersion: v1
kind: Service
metadata: 
  name: service-clusterip-test
spec:
  #type: ClusterIP            # é»˜è®¤å³ä¸ºClusterIPï¼Œæ­¤è¡Œå¯çœç•¥
  #clusterIP: 192.168.64.100  #å¯ä»¥æ‰‹åŠ¨æŒ‡å®šIPï¼Œä½†ä¸€èˆ¬éƒ½æ˜¯ç³»ç»Ÿè‡ªåŠ¨æŒ‡å®šè€Œæ— éœ€æ·»åŠ æ­¤è¡Œ
  selector:
    app: myweb                # å¼•ç”¨ä¸Šé¢deploymentçš„åç§°ï¼ŒåŒæ—¶ä¹Ÿæ˜¯Podçš„Lableä¸­çš„appå€¼
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80

[root@master1 service] # kubectl apply -f service-clusterip-test.yaml 
service/service-clusterip-test created

# æŸ¥çœ‹
[root@master1 service] # kubectl get svc
NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
kubernetes               ClusterIP   10.96.0.1        <none>        443/TCP   4d7h
my-service               ClusterIP   10.108.156.228   10.0.0.88     80/TCP    158m
service-clusterip-test   ClusterIP   10.102.58.175    <none>        80/TCP    4s

# æµ‹è¯•
[root@master1 service]# curl 10.102.58.175
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: myweb-565cb68445-rsbs6, ServerIP: 10.244.1.89!

```



##### å¤šç«¯å£å®ç°

æœ‰å¾ˆå¤šæœåŠ¡éƒ½ä¼šåŒæ—¶å¼€å¯å¤šä¸ªç«¯å£ï¼Œå…¸å‹çš„æ¯”å¦‚ï¼štomcatä¸‰ä¸ªç«¯å£ï¼Œæ¥ä¸‹æ¥å®ç°åˆ›å»ºå¤šç«¯å£çš„Service

```yaml
# åˆ›å»ºå¤šç«¯å£Service
[root@master1 service] # vim service-clusterip-multi-port.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-clusterip-multi-port
spec:
  selector:
    app: myweb
  ports:
  - name: http
    protocol: TCP
    port: 80
  - name: https
    protocol: TCP
    port: 443
#å…³é”®ç‚¹ï¼šåªèƒ½æœ‰ä¸€ä¸ªportså±æ€§ï¼Œå¤šäº†ä¼šè¦†ç›–,æ¯ä¸€ä¸ªå­portå¿…é¡»æœ‰ä¸€ä¸ªnameå±æ€§,ç”±äºserviceæ˜¯åŸºäºæ ‡ç­¾çš„æ–¹å¼æ¥ç®¡ç†podçš„ï¼Œæ‰€ä»¥å¿…é¡»æœ‰æ ‡ç­¾é€‰æ‹©å™¨ 
```



#### NodePort Serviceå®ç°

NodePortä¼šåœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸»æœºä¸Šï¼Œå‘å¤–æš´éœ²ä¸€ä¸ªæŒ‡å®šæˆ–è€…éšæœºçš„ç«¯å£ï¼Œä¾›é›†ç¾¤å¤–éƒ¨çš„åº”ç”¨èƒ½å¤Ÿè®¿é—®

æ³¨æ„ï¼šnodePort å±æ€§èŒƒå›´ä¸º 30000-32767ï¼Œä¸”type ç±»å‹åªæ”¯æŒ NodePortæˆ–LoadBalancer

**æ³¨æ„: æ­¤æ–¹å¼æœ‰å®‰å…¨é£é™©ï¼Œç«¯å£ä¸ºéæ ‡ç«¯å£,è€Œä¸”æ€§èƒ½ä¸€èˆ¬,ç”Ÿäº§ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨**

**ç”Ÿäº§ä¸­å»ºè®®ä½¿ç”¨Ingressæ–¹å¼å‘å¤–æš´éœ²é›†ç¾¤å†…çš„æœåŠ¡**



##### externaltrafficpolicy çš„ä¸¤ç§ç­–ç•¥

![image-20241223203921088](../markdown_img/image-20241223203921088.png)

- **clusteræ¨¡å¼**
  - æ­¤ä¸ºé»˜è®¤æ¨¡å¼
  - é›†ç¾¤å¤–çš„è¯·æ±‚æŠ¥æ–‡ä»æŸèŠ‚ç‚¹çš„NodePortè¿›å…¥ï¼Œè¯¥èŠ‚ç‚¹çš„Serviceå¯ä»¥å°†è¯·æ±‚æµé‡è°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹ä¸Šçš„Podï¼Œæ— éœ€å…³å¿ƒPodåœ¨å“ªä¸ªèŠ‚ç‚¹ä¸Š
  - **Kube-proxyè½¬å‘å¤–éƒ¨è¯·æ±‚æ—¶ä¼šæ›¿æ¢æ‰æŠ¥æ–‡çš„æºIPå’Œç›®æ ‡IP,ç›¸å½“äºFULLNAT**
  - è¿”å›æ—¶éœ€è¦ä»åŸè·¯è¿”å›,å¯èƒ½ä¼šäº§ç”Ÿè·¨èŠ‚ç‚¹çš„è·ƒç‚¹è½¬å‘æµé‡
  - æ­¤æ¨¡å¼è´Ÿè½½å‡è¡¡æ•ˆæœå¥½ï¼Œå› ä¸ºæ— è®ºå®¹å™¨å®ä¾‹æ€ä¹ˆåˆ†å¸ƒåœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šï¼Œå®ƒéƒ½ä¼šè½¬å‘è¿‡å»ã€‚
  - ä½†æ˜¯ç”±äºå¤šäº†ä¸€æ¬¡è½¬å‘ï¼Œæ€§èƒ½ä¼šæŸå¤±
  - å¦‚æœæ˜¯NodePortç±»å‹,Podæ— æ³•è·å–å¤–éƒ¨å®¢æˆ·ç«¯çœŸå®å®¢æˆ·ç«¯IP

![image-20241223204317595](../markdown_img/image-20241223204317595.png)



- **localæ¨¡å¼**
  - é›†ç¾¤å¤–çš„è¯·æ±‚æŠ¥æ–‡ä»æŸèŠ‚ç‚¹çš„NodePortè¿›å…¥,è¯¥èŠ‚ç‚¹çš„Service åªä¼šå°†è¯·æ±‚æµé‡è°ƒåº¦åˆ°å½“å‰èŠ‚ç‚¹ä¸Š çš„Pod
  - **å¤–éƒ¨è¯·æ±‚æµé‡åªå‘ç»™æœ¬æœºçš„Pod, Kube-proxyè½¬å‘æ—¶åªä¼šæ›¿æ¢æ‰æŠ¥æ–‡çš„ç›®æ ‡IP,å³åªå®ç°DNAT**
  - å³ï¼šå®¹å™¨æ”¶åˆ°çš„æŠ¥æ–‡ï¼Œçœ‹åˆ°æºIPåœ°å€è¿˜æ˜¯ç”¨æˆ·çš„åŸæœ‰ IP  
  - æ­¤æ¨¡å¼çš„è´Ÿè½½å‡è¡¡æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œå› ä¸ºä¸€æ—¦å®¹å™¨å®ä¾‹åˆ†å¸ƒåœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šï¼Œå®ƒåªè½¬å‘ç»™æœ¬æœºï¼Œä¸äº§ç”Ÿ è·¨èŠ‚ç‚¹çš„è·ƒç‚¹è½¬å‘æµé‡ã€‚
  - ä½†æ˜¯å°‘äº†ä¸€æ¬¡è½¬å‘ï¼Œæ€§èƒ½ä¼šç›¸å¯¹å¥½
  - ç”±äºæœ¬æœºä¸ä¼šè·¨èŠ‚ç‚¹è½¬å‘æŠ¥æ–‡ï¼Œæ‰€ä»¥è¦æƒ³å¯¹æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„å®¹å™¨å®ç°è´Ÿè½½å‡è¡¡ï¼Œå°±éœ€è¦å€ŸåŠ©å¤–éƒ¨çš„ Loadbalanceræ¥å®ç°
  - å› æ­¤ä½¿ç”¨Local æ¨¡å¼,ä¸€èˆ¬ä¼šä½¿ç”¨ LoadBalancer Service ç±»å‹ç»“åˆ Loadbalancer å®ç°





##### nodePortå®ç°

```yaml
[root@master1 service] # vim service-nodeport.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-nodeport
spec:
  type: NodePort
  #externalTrafficPolicy: Local # é»˜è®¤å€¼ä¸ºCluster,å¦‚æœæ˜¯Localåªèƒ½è¢«å½“å‰è¿è¡ŒPodçš„èŠ‚ç‚¹å¤„ç†æµé‡ï¼Œå¹¶ä¸”å¯ä»¥è·å–å®¢æˆ·ç«¯çœŸå®IP
  selector:
    app: myweb
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30066   # æŒ‡å®šå›ºå®šç«¯å£(30000-32767)ï¼Œä½¿ç”¨NodePortç±»å‹ä¸”ä¸æŒ‡å®šnodeportï¼Œä¼šè‡ªåŠ¨åˆ†é…éšæœºç«¯å£å‘å¤–æš´éœ²

[root@master1 service] # kubectl apply -f service-nodeport.yaml 
service/service-nodeport created

# æŸ¥çœ‹
[root@master1 service] # kubectl get svc
NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service-nodeport         NodePort    10.104.196.234   <none>        80:30066/TCP   33s

# é»˜è®¤externalTrafficPolicy: Clusterï¼Œæ‰€ä»¥ä½¿ç”¨è®¿é—®é›†ç¾¤ä¸­ä»»æ„ä¸€ä¸ªç‰©ç†èŠ‚ç‚¹çš„åœ°å€éƒ½å¯ä»¥ï¼Œä½†æ˜¯Podä¸Šçœ‹ä¸åˆ°çœŸå®å®¢æˆ·ç«¯åœ°å€
[root@master1 service]#curl 10.0.0.202:30066
kubernetes pod-test v0.1!! ClientIP: 10.244.1.0, ServerName: myweb-565cb68445-6c928, ServerIP: 10.244.2.46!
[root@master1 service]#curl 10.0.0.202:30066
kubernetes pod-test v0.1!! ClientIP: 10.244.1.1, ServerName: myweb-565cb68445-rsbs6, ServerIP: 10.244.1.90!
[root@master1 service]#curl 10.0.0.202:30066
kubernetes pod-test v0.1!! ClientIP: 10.244.1.0, ServerName: myweb-565cb68445-fc6xg, ServerIP: 10.244.3.101!
[root@master1 

# æŒ‡å®šexternalTrafficPolicy: Localï¼ŒPodèƒ½çœ‹åˆ°å®¢æˆ·ç«¯çœŸå®IPï¼ŒåŒæ—¶æ¯ä¸ªèŠ‚ç‚¹åªèƒ½è°ƒåº¦è¯¥èŠ‚ç‚¹ä¸Šçš„Pod
[root@master1 service] #curl 10.0.0.202:30066
kubernetes pod-test v0.1!! ClientIP: 10.0.0.201, ServerName: myweb-565cb68445-rsbs6, ServerIP: 10.244.1.90!
[root@master1 service] #curl 10.0.0.202:30066
kubernetes pod-test v0.1!! ClientIP: 10.0.0.201, ServerName: myweb-565cb68445-rsbs6, ServerIP: 10.244.1.90!
[root@master1 service] #curl 10.0.0.202:30066
kubernetes pod-test v0.1!! ClientIP: 10.0.0.201, ServerName: myweb-565cb68445-rsbs6, ServerIP: 10.244.1.90!
[root@master1 service] #curl 10.0.0.203:30066
kubernetes pod-test v0.1!! ClientIP: 10.0.0.201, ServerName: myweb-565cb68445-6c928, ServerIP: 10.244.2.46!
[root@master1 service] #curl 10.0.0.203:30066
kubernetes pod-test v0.1!! ClientIP: 10.0.0.201, ServerName: myweb-565cb68445-6c928, ServerIP: 10.244.2.46!
[root@master1 service] #curl 10.0.0.203:30066
kubernetes pod-test v0.1!! ClientIP: 10.0.0.201, ServerName: myweb-565cb68445-6c928, ServerIP: 10.244.2.46!

# å°†deployç¼©å®¹è‡³1
[root@master1 service] #kubectl scale deployment myweb --replicas=1
deployment.apps/myweb scaled

# æŸ¥çœ‹
[root@master1 service]#kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS      AGE   IP             NODE    NOMINATED NODE   READINESS GATES
myweb-565cb68445-fc6xg   1/1     Running   1 (17m ago)   13h   10.244.3.101   node3   <none>           <none>

# è®¿é—®node1ä¸Šçš„ç«¯å£
[root@master1 service]#curl 10.0.0.202:30066
é˜»å¡...
```



#### LoadBalancer Serviceå®ç°

![image-20241224093229587](../markdown_img/image-20241224093229587.png)

åªæœ‰Kubernetesé›†ç¾¤æ˜¯éƒ¨ç½²åœ¨ä¸€ä¸ªLBaaSå¹³å°ä¸Šä¸”æŒ‡ä¾›æœ‰ä¸€ä¸ªé›†ç¾¤å¤–éƒ¨çš„LBæ‰é€‚åˆä½¿ç”¨LoadBalancer 

ä¸€èˆ¬çš„å…¬æœ‰äº‘éƒ½æä¾›äº†æ­¤åŠŸèƒ½,ä½†å¯èƒ½ä¼šæœ‰è´¹ç”¨äº§ç”Ÿ

å¦‚æœåœ¨ä¸€ä¸ªéå…¬ç”¨äº‘çš„æ™®é€šçš„Kubernetesé›†ç¾¤ä¸Šï¼Œåˆ›å»ºäº†ä¸€ä¸ªLoadBalancerç±»å‹çš„Serviceï¼Œä¸€èˆ¬æƒ…å†µ é»˜è®¤ç¯å¢ƒä¸­æ˜¯æ²¡æœ‰LBaaSçš„ï¼Œæ‰€ä»¥ä¼šå¯¼è‡´ç”±äºæ‰¾ä¸åˆ°æŒ‡å®šçš„æœåŠ¡ï¼ŒçŠ¶æ€ä¼šä¸€ç›´å¤„äº Pending çŠ¶æ€

å¦‚æœåœ¨ç§æœ‰äº‘ç¯å¢ƒä¸­ä½¿ç”¨ LoadBalancer Serviceï¼Œå¯ä»¥ä½¿ç”¨äº‘åŸç”Ÿçš„å¼€æºé¡¹ç›®å®ç°è´Ÿè½½å‡è¡¡å™¨ï¼Œæ¯”å¦‚ **OpenELB, MetalLB** å®ç°

Loadbalancer å¯ä»¥è·å–ç”¨æˆ·è®¿é—®çš„Serviceå¯¹åº”çš„Podåœ¨å“ªä¸ªèŠ‚ç‚¹ä¸Š,å› æ­¤æ”¯æŒexternaltrafficpolicyä¸º Localæ¨¡å¼çš„æµé‡è½¬å‘



##### OpenElBå®ç°LBaasæœåŠ¡



OpenELB æ˜¯ä¸€ä¸ªå¼€æºçš„äº‘åŸç”Ÿè´Ÿè½½å‡è¡¡å™¨å®ç°

å¯ä»¥åœ¨åŸºäºè£¸é‡‘å±æœåŠ¡å™¨ã€è¾¹ç¼˜ä»¥åŠè™šæ‹ŸåŒ–çš„ Kubernetes ç¯å¢ƒä¸­ä½¿ç”¨ LoadBalancer ç±»å‹çš„ Service å¯¹ å¤–æš´éœ²æœåŠ¡ã€‚

OpenELB é¡¹ç›®æœ€åˆç”±å›½å†…é’äº‘çš„ KubeSphere ç¤¾åŒºå‘èµ·ï¼Œç›®å‰å·²ä½œä¸º CNCF æ²™ç®±é¡¹ç›®åŠ å…¥ CNCF åŸºé‡‘ ä¼šï¼Œç”± OpenELB å¼€æºç¤¾åŒºç»´æŠ¤ä¸æ”¯æŒã€‚

å®˜ç½‘: 

```ABAP
https://openelb.io/
https://github.com/openelb/openelb
```



OpenELB ä¹Ÿæ‹¥æœ‰ä¸¤ç§ä¸»è¦å·¥ä½œæ¨¡å¼ï¼š**Layer2** æ¨¡å¼å’Œ **BGP** æ¨¡å¼ã€‚OpenELB çš„ BGP æ¨¡å¼ç›®å‰æš‚ä¸æ”¯æŒ IPv6ã€‚

å› ä¸º OpenELB æ˜¯é’ˆå¯¹è£¸é‡‘å±æœåŠ¡å™¨è®¾è®¡çš„ï¼Œå› æ­¤å¦‚æœæ˜¯åœ¨äº‘ç¯å¢ƒä¸­éƒ¨ç½²ï¼Œéœ€è¦æ³¨æ„æ˜¯å¦æ»¡è¶³æ¡ä»¶ã€‚

æ ¸å¿ƒåŠŸèƒ½

- BGPæ¨¡å¼å’ŒäºŒå±‚ç½‘ç»œæ¨¡å¼ä¸‹çš„è´Ÿè½½å‡è¡¡
- ECMPè·¯ç”±å’Œè´Ÿè½½å‡è¡¡
- IPåœ°å€æ± ç®¡ç†
- åŸºäºCRDæ¥ç®¡ç†BGPé…ç½®

**æ³¨æ„: æ­¤åº”ç”¨å¯èƒ½ä¸æ”¯æŒ Openstack ç­‰äº‘ç¯å¢ƒ**



##### OpenELB å®ç°

éƒ¨ç½²å’Œä½¿ç”¨OpenELB

```bash
[root@master1 ~]#wget https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml

# å¯ç”¨
[root@master1 openelb] #kubectl apply -f openelb.yaml 
namespace/openelb-system created
customresourcedefinition.apiextensions.k8s.io/bgpconfs.network.kubesphere.io created
customresourcedefinition.apiextensions.k8s.io/bgppeers.network.kubesphere.io created
customresourcedefinition.apiextensions.k8s.io/eips.network.kubesphere.io created
serviceaccount/openelb-admission created
serviceaccount/openelb-controller created
serviceaccount/openelb-speaker created
role.rbac.authorization.k8s.io/openelb-admission created
clusterrole.rbac.authorization.k8s.io/openelb-admission created
clusterrole.rbac.authorization.k8s.io/openelb-controller created
clusterrole.rbac.authorization.k8s.io/openelb-speaker created
rolebinding.rbac.authorization.k8s.io/openelb-admission created
clusterrolebinding.rbac.authorization.k8s.io/openelb-admission created
clusterrolebinding.rbac.authorization.k8s.io/openelb-controller created
clusterrolebinding.rbac.authorization.k8s.io/openelb-speaker created
secret/memberlist created
service/openelb-controller created
deployment.apps/openelb-controller created
daemonset.apps/openelb-speaker created
job.batch/openelb-admission-create created
job.batch/openelb-admission-patch created
validatingwebhookconfiguration.admissionregistration.k8s.io/openelb-admission created

# æŸ¥çœ‹åˆ›å»ºçš„CRDè‡ªå®šä¹‰èµ„æºç±»å‹
[root@master1 openelb]#kubectl get crd
NAME                             CREATED AT
bgpconfs.network.kubesphere.io   2024-12-24T01:49:36Z
bgppeers.network.kubesphere.io   2024-12-24T01:49:36Z
eips.network.kubesphere.io       2024-12-24T01:49:36Z

# ç¡®è®¤openelb-manager Podå·²ç»å¤„äºRunningçŠ¶æ€ï¼Œä¸”å®¹å™¨å·²ç»Ready
[root@master1 openelb]#kubectl get pods -n openelb-system 
NAME                                  READY   STATUS      RESTARTS   AGE
openelb-admission-create-r28c5        0/1     Completed   0          69s
openelb-admission-patch-h8g6n         0/1     Completed   2          69s
openelb-controller-7f8788f446-22j7d   1/1     Running     0          69s
openelb-speaker-f462b                 1/1     Running     0          69s
openelb-speaker-mzhpb                 1/1     Running     0          69s
openelb-speaker-phzd8                 1/1     Running     0          69s
openelb-speaker-tb2ms                 1/1     Running     0          69s

#åˆ›å»ºäº†ä¸€ä¸ªEipèµ„æºå¯¹è±¡ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªåœ°å€æ± ç»™LoadBalancer Serviceä½¿ç”¨
[root@master1 openelb] #vim service-loadbalancer-eip-pool.yaml
apiVersion: network.kubesphere.io/v1alpha2
kind: Eip
metadata:
  name: eip-pool
  annotations:
    eip.openelb.kubesphere.io/is-default-eip: "true" #æŒ‡å®šå½“å‰EIPä½œä¸ºå‘LoadBalancer Serveråˆ†ç‰‡åœ°>å€æ—¶ä½¿ç”¨çš„é»˜è®¤çš„eipå¯¹è±¡
spec:
  address: 10.0.0.10-10.0.0.50 #æŒ‡å®šæ’é™¤ä¸»æœºèŠ‚ç‚¹ä¹‹å¤–çš„åœ°å€èŒƒå›´ï¼Œå¯ä»¥ä½¿ç”¨å•ä¸ªIPæˆ–è€…å¸¦æœ‰æ©ç é•¿åº¦çš„>ç½‘ç»œåœ°å€
  protocol: layer2 #æŒ‡å®šOpenELBæ¨¡å¼ï¼Œæ”¯æŒbgp,layer2å’Œvipä¸‰ç§ï¼Œé»˜è®¤bgp
  interface: eth0 #OpenELBä¾¦å¬ARPæˆ–NDPè¯·æ±‚æ—¶ä½¿ç”¨çš„ç½‘ç»œæ¥å£åç§°ï¼Œä»…layer2æ¨¡å¼ä¸‹æœ‰æ•ˆ
  disable: false
  
  
# åˆ›å»ºèµ„æº
[root@master1 openelb]#kubectl apply -f service-loadbalancer-eip-pool.yaml 
eip.network.kubesphere.io/eip-pool created

# æŸ¥çœ‹ç»“æœ
[root@master1 openelb]#kubectl get eip
NAME       CIDR                  USAGE   TOTAL
eip-pool   10.0.0.10-10.0.0.50           41

# åˆ›å»ºDeploymentå’ŒLoadBalancerç±»å‹çš„Serviceï¼Œæµ‹è¯•åœ°å€æ± æ˜¯å¦èƒ½ç»™Serviceåˆ†é…LoadBalancerIP
[root@master1 openelb] #kubectl create deployment myapp --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas=3
deployment.apps/myapp created

[root@master1 openelb]#vim service-loadbalancer-lbaas.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-loadbalancer-lbaas
spec:
  type: LoadBalancer
  externalTrafficPolicy: Local
  selector:
    app: myapp
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80

# åº”ç”¨
[root@master1 openelb ]#kubectl apply -f service-loadbalancer-lbaas.yaml 
service/service-loadbalancer-lbaas created

# æŸ¥çœ‹serviceèµ„æºå¯¹è±¡myappæ˜¯å¦è‡ªåŠ¨è·å¾—äº†EXTERNAL IPï¼Œè·å–å¤±è´¥...
[root@master1 openelb]#kubectl get svc service-loadbalancer-lbaas 
NAME                         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service-loadbalancer-lbaas   LoadBalancer   10.97.215.163   <pending>     80:30214/TCP   8m41s
```





##### metalLBå®ç°LBaaSæœåŠ¡



![image-20241224101508876](../markdown_img/image-20241224101508876.png)



å®˜ç½‘

```ABAP
https://github.com/metallb/metallb
https://metallb.universe.tf/
```

MetalLB æ˜¯ç”± Google å¼€æºæä¾›

MetalLB åŠŸèƒ½å®ç°ä¾èµ–äºä¸¤ç§æœºåˆ¶

- Address Allocation åœ°å€åˆ†é…ï¼šåŸºäºç”¨æˆ·é…ç½®çš„åœ°å€æ± ï¼Œä¸ºç”¨æˆ·åˆ›å»ºçš„LoadBalanceråˆ†é…IPåœ°å€, å¹¶é…ç½®åœ¨èŠ‚ç‚¹ä¸Š
- External Announcement å¯¹å¤–å…¬å‘Šï¼šè®©é›†ç¾¤å¤–éƒ¨çš„ç½‘ç»œäº†è§£æ–°åˆ†é…çš„Påœ°å€ï¼ŒMetalLBä½¿ç”¨ARPã€ NDPæˆ–BGPå®ç°



MetallB å¯é…ç½®ä¸ºåœ¨äºŒå±‚æ¨¡å¼æˆ–BGPæ¨¡å¼ä¸‹è¿è¡Œ

- äºŒå±‚æ¨¡å¼(ARP/NDP)
  - LoadBalancer IPåœ°å€é…ç½®åœ¨æŸä¸€ä¸ªèŠ‚ç‚¹ä¸Šï¼Œå¹¶ä½¿ç”¨ARP(IPv4)æˆ–NDP(IPv6)å¯¹å¤–å…¬å‘Š
  - æ‹¥æœ‰LoadBalancer IP åœ°å€çš„èŠ‚ç‚¹å°†æˆä¸ºServiceæµé‡çš„æƒŸä¸€å…¥å£ï¼Œå¹¶åœ¨èŠ‚ç‚¹æ•…éšœæ—¶è‡ªåŠ¨è¿›è¡Œæ•…éšœè½¬ ç§»
  - å¹¶æœªçœŸæ­£å®ç°è´Ÿè½½å‡è¡¡ï¼Œå­˜åœ¨æ€§èƒ½ç“¶é¢ˆï¼Œä¸”æ•…éšœè½¬ç§»å­˜åœ¨ç§’çº§çš„å»¶è¿Ÿ
- BGPæ¨¡å¼
  - é›†ç¾¤ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹ä¸æœ¬åœ°ç½‘ç»œä¸­çš„BGP Routerå»ºç«‹BGPå¯¹ç­‰ä¼šè¯ï¼Œé€šå‘ŠLoadBalancer IPï¼Œä»è€Œå‘ŠçŸ¥Routerå¦‚ä½•è¿›è¡Œæµé‡è·¯ç”±
  - å¯ä»¥å®ç°è·¨å¤šä¸ªèŠ‚ç‚¹çš„çœŸæ­£æ„ä¹‰ä¸Šçš„è´Ÿè½½å‡è¡¡



**æ³¨æ„: æ­¤åº”ç”¨å¯èƒ½ä¸æ”¯æŒ Openstack ç­‰äº‘ç¯å¢ƒ**



##### MetalLB å®ç°

```bash
# éƒ¨ç½²MetalLBè‡³Kubernetesé›†ç¾¤
METALLB_VERSION='v0.14.7'
wget https://raw.githubusercontent.com/metallb/metallb/${METALLB_VERSION}/config/manifests/metallb-native.yaml

# åº”ç”¨
[root@master1 metalLB]# kubectl apply -f metallb-native.yaml 
namespace/metallb-system created
customresourcedefinition.apiextensions.k8s.io/bfdprofiles.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bgpadvertisements.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bgppeers.metallb.io created
customresourcedefinition.apiextensions.k8s.io/communities.metallb.io created
customresourcedefinition.apiextensions.k8s.io/ipaddresspools.metallb.io created
customresourcedefinition.apiextensions.k8s.io/l2advertisements.metallb.io created
customresourcedefinition.apiextensions.k8s.io/servicel2statuses.metallb.io created
serviceaccount/controller created
serviceaccount/speaker created
role.rbac.authorization.k8s.io/controller created
role.rbac.authorization.k8s.io/pod-lister created
clusterrole.rbac.authorization.k8s.io/metallb-system:controller created
clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created
rolebinding.rbac.authorization.k8s.io/controller created
rolebinding.rbac.authorization.k8s.io/pod-lister created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created
configmap/metallb-excludel2 created
secret/metallb-webhook-cert created
service/metallb-webhook-service created
deployment.apps/controller created
daemonset.apps/speaker created
validatingwebhookconfiguration.admissionregistration.k8s.io/metallb-webhook-configuration created

# æŸ¥çœ‹CRDèµ„æºç±»å‹
[root@master1 metalLB]#kubectl get crd
NAME                           CREATED AT
bfdprofiles.metallb.io         2024-12-24T02:27:38Z
bgpadvertisements.metallb.io   2024-12-24T02:27:38Z
bgppeers.metallb.io            2024-12-24T02:27:38Z
communities.metallb.io         2024-12-24T02:27:38Z
ipaddresspools.metallb.io      2024-12-24T02:27:38Z
l2advertisements.metallb.io    2024-12-24T02:27:38Z
servicel2statuses.metallb.io   2024-12-24T02:27:38Z

# åˆ›å»ºåœ°å€æ± 
# æ³¨æ„: IPAddressPool å¿…é¡»ä½¿ç”¨Kuberetesé›†ç¾¤èŠ‚ç‚¹çš„IPåœ°å€æ®µ
[root@master1 metalLB]#vim service-metallb-IPAddressPool.yaml
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: localip-pool
  namespace: metallb-system
spec:
  addresses:
  - 10.0.0.10-10.0.0.50
  autoAssign: true
  avoidBuggyIPs: true
  
# åº”ç”¨
[root@master1 metalLB]#kubectl apply -f service-metallb-IPAddressPool.yaml
ipaddresspool.metallb.io/localip-pool created

# åˆ›å»ºäºŒå±‚å…¬å‘Šæœºåˆ¶
[root@master1 metalLB]#vim service-metallb-L2Advertisement.yaml
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: localip-pool-l2a
  namespace: metallb-system
spec:
  ipAddressPools:
  - localip-pool
  interfaces:
  - eth0 # ç”¨äºå‘é€å…è´¹ARPå…¬å‘Š

[root@master1 metalLB]#kubectl apply -f service-metallb-L2Advertisement.yaml 
l2advertisement.metallb.io/localip-pool-l2a created

# åˆ›å»ºServiceå’ŒDeploymentï¼Œæµ‹è¯•åœ°å€æ± æ˜¯å¦èƒ½ç»™Serviceåˆ†é…LoadBalancer IP
[root@master1 ~]#kubectl create deployment myapp --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas=3

[root@master1 metalLB]# vim service-loadbalancer-lbaas.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-loadbalancer-lbaas
spec:
  type: LoadBalancer
  externalTrafficPolicy: Local
  selector:
    app: myapp
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
    
# åº”ç”¨
[root@master1 metalLB]#kubectl apply -f service-loadbalancer-lbaas.yaml 
service/service-loadbalancer-lbaas created

# æŸ¥çœ‹
[root@master1 metalLB]#kubectl get svc service-loadbalancer-lbaas 
NAME                         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service-loadbalancer-lbaas   LoadBalancer   10.111.219.193   10.0.0.10     80:32248/TCP   7s

# ä»å¤–éƒ¨è®¿é—®æµ‹è¯•
[root@master1 metalLB]#curl 10.0.0.10
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: myapp-547df679bb-57pnm, ServerIP: 10.244.2.51!
```



##### å®é™…ç”Ÿäº§ç¯å¢ƒ

- é€šå¸¸ä½¿ç”¨å…¬æœ‰äº‘æä¾›çš„LBaaSï¼Œè€Œä¸æ˜¯è¿™ç§å¼€æºçš„è´Ÿè½½å‡è¡¡å™¨ï¼ŒMetalLBæœ‰Bugï¼Œåœ¨Localæ¨¡å¼ä¸‹ï¼Œæ²¡æœ‰è´Ÿè½½å‡è¡¡æ•ˆæœ
- æ›´å¤šçš„æ˜¯ä½¿ç”¨ingressè¿›è¡Œå¯¹å¤–æš´éœ²







#### ExternalName Serviceå®ç°

Service ä¸ä»…å¯ä»¥å®ç°Kubernetesé›†ç¾¤å†…Podåº”ç”¨ä¹‹é—´çš„ç›¸äº’è®¿é—®ä»¥åŠä»é›†ç¾¤å¤–éƒ¨è®¿é—®é›†ç¾¤ä¸­çš„Pod

è¿˜å¯ä»¥æ”¯æŒåšä¸ºå¤–éƒ¨æœåŠ¡çš„ä»£ç†å®ç°é›†ç¾¤ä¸­Podè®¿é—®é›†ç¾¤å¤–çš„æœåŠ¡

```ABAP
Pod --> Service_name --> External Name --> å¤–éƒ¨DNS --> å¤–éƒ¨æœåŠ¡IP
```



**Serviceä»£ç†Kuberneteså¤–éƒ¨åº”ç”¨çš„ä½¿ç”¨åœºæ™¯**

- åœ¨ç”Ÿäº§ç¯å¢ƒä¸­Pod å¸Œæœ›ä½¿ç”¨æŸä¸ªå›ºå®šçš„åç§°è€ŒéIPåœ°å€è¿›è¡Œè®¿é—®é›†ç¾¤å¤–éƒ¨çš„æœåŠ¡
- ä½¿ç”¨ServiceæŒ‡å‘å¦ä¸€ä¸ªNamespaceä¸­æˆ–å…¶å®ƒKubernetesé›†ç¾¤ä¸­çš„æœåŠ¡
- æŸä¸ªé¡¹ç›®æ­£åœ¨è¿ç§»è‡³Kubernetesé›†ç¾¤ï¼Œä½†æ˜¯ä¸€éƒ¨åˆ†æœåŠ¡ä»ç„¶åœ¨é›†ç¾¤å¤–éƒ¨ï¼Œæ­¤æ—¶å¯ä»¥ä½¿ç”¨serviceä»£ç†è‡³k8sé›†ç¾¤å¤–éƒ¨çš„æœåŠ¡



**ä½¿ç”¨ExternalName Serviceå®ç°ä»£ç†å¤–éƒ¨æœåŠ¡ï¼ˆå…¬ç½‘IPçš„æœåŠ¡ï¼‰**

```bash
[root@master1 service]# vim service-externalname-web.yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-externalname-web
  namespace: default
spec:
  type: ExternalName
  externalName: www.mysticalrecluse.com
  ports:                      # å¯é€‰å­—æ®µï¼ˆoptionalï¼‰ï¼Œè€Œä¸”åŸºæœ¬æ˜¯ å ä½ä½œç”¨ï¼Œä¸ä¼šå®é™…å‚ä¸æµé‡è½¬å‘æˆ–ç›‘å¬ç«¯å£ã€‚
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 0
  selector: {}

# åº”ç”¨
[root@master1 service]#kubectl apply -f service-externalname-web.yaml 
service/svc-externalname-web created

# æŸ¥çœ‹
#æ³¨æ„: serviceæ²¡æœ‰Cluster-IP,å³ä¸ºæ— å¤´æœåŠ¡Headless Service
[root@master1 service]#kubectl get svc
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP               PORT(S)   AGE
svc-externalname-web   ExternalName   <none>       www.mysticalrecluse.com   80/TCP    7s

# åˆ›å»ºä¸€ä¸ªæµ‹è¯•podï¼Œè§£æåŸŸå
[root@master1 service]# kubectl run pod-$RANDOM --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/admin-box:v0.1 -it --rm --command -- /bin/bash
If you don't see a command prompt, try pressing enter.
root@pod-18379 /# 
root@pod-18379 /# host svc-externalname-web
svc-externalname-web.default.svc.cluster.local is an alias for www.mysticalrecluse.com.
root@pod-18379 /# ping -c1 svc-externalname-web
PING svc-externalname-web (101.35.250.82): 56 data bytes
64 bytes from 101.35.250.82: seq=0 ttl=127 time=30.567 ms
```



##### ExternalNameæœ¬è´¨

å®ƒæ˜¯ Kubernetes ä¸­çš„ä¸€ç§ç‰¹æ®Š Service ç±»å‹ï¼Œç”¨æ¥**ç»™ä¸€ä¸ªå¤–éƒ¨åŸŸåèµ·åˆ«å**ï¼Œè®©é›†ç¾¤å†…çš„ Pod é€šè¿‡ Kubernetes çš„æœåŠ¡åŸŸåæ¥è®¿é—®è¿™ä¸ªå¤–éƒ¨åœ°å€

**ä¸¾ä¸ªä¾‹å­è¯´æ˜**

æ¯”å¦‚ä½ æœ‰ä¸€ä¸ªå¤–éƒ¨æœåŠ¡ `api.external.com`ï¼Œä½ æƒ³è®© Pod é€šè¿‡ `my-external-svc.default.svc.cluster.local` æ¥è®¿é—®å®ƒï¼š

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-external-svc
  namespace: default
spec:
  type: ExternalName
  externalName: api.external.com
```

é‚£ä¹ˆé›†ç¾¤ä¸­çš„ Pod å°±å¯ä»¥è¿™æ ·è®¿é—®å®ƒ

```bash
curl http://my-external-svc.default.svc.cluster.local
```

DNS ä¼šæŠŠè¿™ä¸ªåœ°å€è§£æä¸º `api.external.com`ã€‚



**å…³é”®ç‰¹æ€§æ€»ç»“**ï¼š

| ç‰¹æ€§                | è¯´æ˜                                                         |
| ------------------- | ------------------------------------------------------------ |
| æ˜¯å¦åˆ›å»º Endpoint   | âŒ ä¸åˆ›å»ºã€‚æ²¡æœ‰ selectorã€æ²¡æœ‰ endpointsã€‚                    |
| æ˜¯å¦è´Ÿè½½å‡è¡¡        | âŒ ä¸ä¼šè½®è¯¢ï¼Œåªæ˜¯ä¸€ä¸ª DNS åˆ«åã€‚                              |
| æ˜¯å¦å¯ä»¥æ˜¯ IP       | âš ï¸ ä¸æ¨èã€‚åº”ä½¿ç”¨ **åˆæ³•çš„ DNS åç§°**ã€‚                       |
| ä½œç”¨æœºåˆ¶            | CoreDNS é€šè¿‡ `CNAME` æŠŠ Service åç§°è§£æä¸º `externalName` æŒ‡å®šçš„åŸŸåã€‚ |
| æ˜¯å¦ä¼šè½¬å‘æµé‡      | âŒ ä¸åšæµé‡è½¬å‘ï¼Œä»… DNS å±‚å¤„ç†ã€‚                              |
| èƒ½å¦ç”¨äº TLS ç­‰åŠŸèƒ½ | âŒ ä¸é€‚åˆåš Ingress æˆ– Gateway çš„åç«¯ï¼Œå› ä¸ºå®ƒä¸æ˜¯ä¸€ä¸ªçœŸæ­£çš„ Endpointã€‚ |



**ä½¿ç”¨è‡ªå»ºçš„Endpointå®ç°åŸºäºClusterIPç±»å‹çš„Serviceä»£ç†é›†ç¾¤å¤–éƒ¨æœåŠ¡**

- æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªEndpointsèµ„æºå¯¹è±¡ï¼Œç›´æ¥æŠŠå¤–éƒ¨ç«¯ç‚¹çš„IPåœ°å€ï¼Œæ”¾å…¥å¯ç”¨åœ°å€åˆ—è¡¨
- é¢å¤–åˆ›å»ºä¸€ä¸ªä¸å¸¦selectorçš„åŒåçš„Serviceå¯¹è±¡

```bash
# åœ¨k8sé›†ç¾¤å¤–å®‰è£…redis
[root@master1 ~]#apt update && apt -y install redis
[root@master1 ~]#vim /etc/redis/redis.conf
bind 0.0.0.0
[root@master1 ~]#systemctl restart redis

[root@master1 service]# vim service-endpoints.yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: service-redis  # å’Œä¸‹é¢çš„serviceå¿…é¡»åŒå
  namespace: default
subsets:
  - addresses:
    - ip: 10.0.0.131  # å¤–éƒ¨æœåŠ¡çš„FQDNæˆ–IP
    ports:
    - name: reids
      port: 6379
      protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  name: service-redis  # å’Œä¸Šé¢çš„endpointså¿…é¡»åŒå
  namespace: default
spec:
  type: ClusterIP
  clusterIP: "None"
  ports:
  - name: redis
    port: 6379
    protocol: TCP
    targetPort: 6379

  
# åº”ç”¨
[root@master1 service]#kubectl apply -f service-endpoints.yaml 
endpoints/service-redis created
service/service-redis created

# æŸ¥çœ‹
[root@master1 service]#kubectl get svc
NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP               PORT(S)    AGE
kubernetes             ClusterIP      10.96.0.1    <none>                    443/TCP    26m
service-redis          ClusterIP      None         <none>                    6379/TCP   38s

[root@master1 service]#kubectl get ep service-redis 
NAME            ENDPOINTS         AGE
service-redis   10.0.0.131:6379   76s

# æµ‹è¯•è®¿é—®ï¼Œä½¿ç”¨serviceååšä¸ºåŸŸåï¼Œè®¿é—®å¤–éƒ¨redis
[root@master1 service]#kubectl run pod-$RANDOM --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/admin-box:v0.1 -it --rm --command -- /bin/bash
If you don't see a command prompt, try pressing enter.
root@pod-28779 /# nc service-redis 6379
info
```





#### ä¼šè¯ç²˜æ»

kubernetesçš„Serviceé»˜è®¤æ˜¯æŒ‰ç…§è½®è¯¢æœºåˆ¶è¿›è¡Œè½¬å‘è‡³åç«¯çš„å¤šä¸ªpod

å¦‚æœç”¨æˆ·è¯·æ±‚æœ‰ä¸€å®šçš„ä¼šè¯è¦æ±‚ï¼Œå³å¸Œæœ›åŒä¸€ä¸ªå®¢æˆ·æ¯æ¬¡æ€»æ˜¯èƒ½è®¿é—®åŒä¸€ä¸ªpodçš„æ—¶å€™ï¼Œå¯ä»¥ä½¿ç”¨ serviceçš„**affinityæœºåˆ¶**æ¥å®ç°

å®ƒèƒ½å°†åŒä¸€ä¸ªå®¢æˆ·ç«¯çš„è¯·æ±‚å§‹ç»ˆè½¬å‘è‡³åŒä¸€ä¸ªåç«¯Podå¯¹è±¡ï¼Œå®ƒæ˜¯ç”±**kube-proxyçš„ipvsæœºåˆ¶**æ¥å®ç°çš„ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œserviceæ‰€æä¾›çš„ä¼šè¯ç²˜æ€§æ•ˆæœé»˜è®¤åœ¨**10800s(3å°æ—¶)**åä¼šé‡æ–°è°ƒåº¦,è€Œä¸”ä»…èƒ½åŸºäºå®¢æˆ·ç«¯IP è¿›è¡Œè¯†åˆ«ï¼Œè°ƒåº¦ç²’åº¦è¾ƒç²—



**å±æ€§è§£æ**

```yaml
# å±æ€§ä¿¡æ¯
service.spec.sessionAffinity  # å®šä¹‰ç²˜æ€§ä¼šè¯çš„ç±»å‹ï¼Œå¯ä¸º None å’Œ ClientIP,é»˜è®¤å€¼ä¸ºNoneå³ä¸å¼€å¯ä¼šè¯æ²¾æ»
service.spec.sessionAffinityConfig.clinetIP.timeoutSeconds # é…ç½®ä¼šè¯ä¿æŒæ—¶é•¿ï¼Œé»˜è®¤10800sï¼ŒèŒƒå›´1-86400

# é…ç½®æ ¼å¼
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
```



**å®ç°ä¼šè¯ç²˜æ»**

```yaml
# åˆ›å»ºdeploymentèµ„æº
[root@master1 service] # kubectl create deployment myweb --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas=3
deployment.apps/myweb created

[root@master1 service] # kubectl get pod
NAME                     READY   STATUS    RESTARTS   AGE
myweb-565cb68445-2sqx9   1/1     Running   0          3s
myweb-565cb68445-8z59d   1/1     Running   0          3s
myweb-565cb68445-nts2b   1/1     Running   0          3s

# åˆ›å»ºServiceèµ„æºå¯¹è±¡
[root@master1 service] # vim service-session.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-session
spec:
  type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: myweb
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 1800 # é»˜è®¤å€¼ä¸º10800ï¼Œå³3å°æ—¶

# åº”ç”¨
[root@master1 service]  #kubectl apply -f service-session.yaml 
service/service-session created

# åŒä¸€ä¸ªå®¢æˆ·ç«¯ï¼Œå¤šæ¬¡è®¿é—®éƒ½æ˜¯è°ƒåº¦åˆ°åŒä¸€ä¸ªPodä¸Š
[root@master1 service] # curl 10.109.193.1
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: myweb-565cb68445-8z59d, ServerIP: 10.244.2.52!
[root@master1 service] # curl 10.109.193.1
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: myweb-565cb68445-8z59d, ServerIP: 10.244.2.52!
[root@master1 service] # curl 10.109.193.1
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: myweb-565cb68445-8z59d, ServerIP: 10.244.2.52!
```



#### ipvsæ¨¡å¼

![image-20241224143822632](../markdown_img/image-20241224143822632.png)



ipvsä¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šåˆ›å»ºä¸€ä¸ªåä¸ºkube-ipvs0çš„è™šæ‹Ÿæ¥å£ï¼Œå¹¶å°†é›†ç¾¤æ‰€æœ‰Serviceå¯¹è±¡çš„ClusterIPå’ŒExternalIPéƒ½é…ç½®åœ¨è¯¥æ¥å£ï¼› æ‰€ä»¥æ¯å¢åŠ ä¸€ä¸ªClusterIP æˆ–è€…ExternalIPï¼Œå°±ç›¸å½“äºä¸º kube-ipvs0 å…³è” äº†ä¸€ä¸ªåœ°å€ç½¢äº†ã€‚

kube-proxyä¸ºæ¯ä¸ªserviceç”Ÿæˆä¸€ä¸ªè™šæ‹ŸæœåŠ¡å™¨( IPVS Virtual Server)çš„å®šä¹‰ã€‚



**åŸºæœ¬æµç¨‹ï¼š**

- å½“å‰èŠ‚ç‚¹æ¥æ”¶åˆ°å¤–éƒ¨æµé‡åï¼Œå¦‚æœè¯¥æ•°æ®åŒ…æ˜¯äº¤ç»™å½“å‰èŠ‚ç‚¹ä¸Šçš„clusterIPï¼Œåˆ™ä¼šç›´æ¥å°†æ•°æ®åŒ…äº¤ç»™ kube-ipvs0ï¼Œè€Œè¿™ä¸ªæ¥å£æ˜¯å†…æ ¸è™šæ‹Ÿå‡ºæ¥çš„ï¼Œè€Œkube-proxyå®šä¹‰çš„VSç›´æ¥å…³è”åˆ°kube-ipvs0ä¸Šã€‚
- å¦‚æœæ˜¯æœ¬åœ°èŠ‚ç‚¹podå‘é€çš„è¯·æ±‚ï¼ŒåŸºæœ¬ä¸Šå±äºæœ¬åœ°é€šä¿¡ï¼Œæ•ˆç‡æ˜¯éå¸¸é«˜çš„ã€‚
- é»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™é‡Œçš„ipvsä½¿ç”¨çš„æ˜¯natè½¬å‘æ¨¡å‹ï¼Œè€Œä¸”æ”¯æŒæ›´å¤šçš„åç«¯è°ƒåº¦ç®—æ³•ã€‚ä»…ä»…åœ¨æ¶‰åŠåˆ°æºåœ°å€è½¬ æ¢çš„åœºæ™¯ä¸­ï¼Œä¼šæ¶‰åŠåˆ°æå°‘é‡çš„iptablesè§„åˆ™(åº”è¯¥ä¸ä¼šè¶…è¿‡20æ¡)
- å¯¹äºKubernetesæ¥è¯´ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œæ”¯æŒçš„è§„åˆ™æ˜¯ iptablesï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼å¯¹ä»£ç†æ¨¡å¼è¿›è¡Œæ›´æ”¹ï¼Œ å› ä¸ºè¿™äº›è§„åˆ™éƒ½æ˜¯**åŸºäºkube-proxy**æ¥å®šåˆ¶çš„ï¼Œæ‰€ä»¥ï¼Œå¦‚æœè¦æ›´æ”¹ä»£ç†æ¨¡å¼çš„è¯ï¼Œå°±éœ€è¦è°ƒæ•´kube-proxy çš„å±æ€§ã€‚



**æ³¨æ„ï¼šKubernetes-v1.29ç‰ˆæœ¬åï¼Œä¸å†ä½¿ç”¨iptablesï¼Œè€Œä½¿ç”¨nftables frameworkï¼Œå·¥å…·ä½¿ç”¨nft  list ruleset æŸ¥çœ‹**



æ›´æ”¹kube-proxyä¸ºIPVSæ¨¡å¼æ–¹æ³•è¯´æ˜

```bash
#æ–¹æ³•1ï¼š åœ¨é›†ç¾¤åˆ›å»ºçš„æ—¶å€™ï¼Œä¿®æ”¹kubeadm-init.yml æ·»åŠ å¦‚ä¸‹é…ç½®ï¼Œæ­¤æ–¹æ³•æ˜¯ç”Ÿäº§ä¸­æ¨è
kubeadm config print init-defaults > kubeadm-init.yaml

# åœ¨æ–‡ä»¶æœ€åé¢æ·»åŠ ä¸€ä¸‹å‡ è¡Œ
---
apiVersion: kubeproxy.config.Kubernetes.io/v1alpha1
kind: KubeProxyConfiguration
featureGates:
  SupportIPVSProxyMode: true
mode: ipvs

# åœ¨åˆå§‹é˜¶æ®µå¯èƒ½ä¿®æ”¹çš„å‚æ•°
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.0.100
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///run/cri-dockerd.sock                  # é…ç½®cri-dockerdæ’æ§½
  name: master1
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane

---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: "v1.30.2"
controlPlaneEndpoint: "master1.mystical.org:6443"            # ä¿®æ”¹æ§åˆ¶å¹³é¢åŸŸå
networking:
  podSubnet: "10.244.0.0/16"                                 # ä¿®æ”¹é›†ç¾¤ç½‘è·¯é…ç½®ï¼Œpodç½‘ç»œ
  serviceSubnet: "10.96.0.0/12"                              # serviceç½‘ç»œ
imageRepository: registry.aliyuncs.com/google_containers     # ä¿®æ”¹é•œåƒä»“åº“ï¼ˆå¦‚ä½¿ç”¨å›½å†…é•œåƒï¼‰
apiServer:
  extraArgs:
    authorization-mode: Node,RBAC


# æ›´æ”¹å¥½é…ç½®æ–‡ä»¶åï¼Œæ‰§è¡Œå‘½ä»¤åˆå§‹åŒ–
kubeadm init --config=kubeadm-init.yaml --token-ttl --upload-certs

# éªŒè¯é›†ç¾¤çŠ¶æ€
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# çœ‹é›†ç¾¤æ˜¯å¦æ­£å¸¸è¿è¡Œ
kubectl get nodes
kubectl get pods -n kube-system


# æ–¹æ³•2ï¼šåœ¨æµ‹è¯•ç¯å¢ƒä¸­ï¼Œä¸´æ—¶ä¿®æ”¹ä¸€ä¸‹configmapä¸­proxyçš„åŸºæœ¬å±æ€§ï¼Œæ­¤æ–¹å¼åœ¨æµ‹è¯•ç¯å¢ƒä¸­æ¨èä½¿ç”¨
[root@master1 ~] # kubectl edit cm  kube-proxy -n kube-system
...
mode: "ipvs"  #ä¿®æ”¹æ­¤è¡Œï¼Œé»˜è®¤ä¸ºç©ºâ€â€œè¡¨ç¤ºiptablesæ¨¡å¼
...

# æ›´æ”¹åï¼Œéœ€è¦ç¨ç­‰ä¸€ä¼šå„¿æ‰èƒ½ç”Ÿæ•ˆ

# å¦‚æœæƒ³ç«‹å³ç”Ÿæ•ˆï¼Œéœ€è¦é‡å¯æ‰€æœ‰çš„kube-proxy podå¯¹è±¡
[root@master1 ~]#kubectl get ds -n kube-system 
NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-proxy   4         4         4       4            4           kubernetes.io/os=linux   5d1h

[root@master1 ~]#kubectl get pod -n kube-system -l k8s-app=kube-proxy
NAME               READY   STATUS    RESTARTS        AGE
kube-proxy-7fc2q   1/1     Running   5 (5h50m ago)   5d1h
kube-proxy-7slb9   1/1     Running   5 (5h49m ago)   5d1h
kube-proxy-n66cg   1/1     Running   5 (5h49m ago)   5d1h
kube-proxy-vkqh5   1/1     Running   5 (5h47m ago)   5d1h

# é‡å¯pod
[root@master1 ~]#kubectl rollout restart daemonset -n kube-system kube-proxy 
daemonset.apps/kube-proxy restarted

# é‡å¯æ–¹å¼2ï¼šåˆ é™¤åŸpodï¼Œä½¿damonsetè‡ªåŠ¨é‡æ–°åˆ›å»º
kubectl delete pod -n kube-system -l k8s-app=kube-proxy

# å®‰è£…ipvsadmæŸ¥çœ‹æ•ˆæœ
[root@master1 ~]#apt update && apt -y install ipvsadm
[root@master1 ~]#ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  172.17.0.1:30433 rr persistent 1800
  -> 10.244.1.99:80               Masq    1      0          0         
  -> 10.244.2.52:80               Masq    1      0          0         
  -> 10.244.3.106:80              Masq    1      0          0         
TCP  10.0.0.201:30433 rr persistent 1800
  -> 10.244.1.99:80               Masq    1      0          0         
  -> 10.244.2.52:80               Masq    1      0          0         
  -> 10.244.3.106:80              Masq    1      0          0 
  ......
```

```ABAP
kube-proxy å¯ç”¨ IPVS åä»ä¿ç•™éƒ¨åˆ† iptables æ˜¯ è®¾è®¡å¦‚æ­¤ï¼Œä¸è¦æ‰‹åŠ¨æ¸…ç†ï¼Œå¦åˆ™å¯èƒ½å½±å“ Service åŠŸèƒ½ã€‚åªè¦ IPVS è§„åˆ™å·²ç”Ÿæ•ˆï¼Œè¯´æ˜ä½ çš„æœåŠ¡æµé‡å·²ç»èµ° IPVSï¼Œiptables æ˜¯è¾…åŠ©å­˜åœ¨çš„ã€‚
```



### ç»¼åˆæ¡ˆä¾‹ï¼šWordpress

```yaml
[root@master1 controller] # vim wordpress-mysql.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: demo
---
apiVersion: v1
kind: Service
metadata:
  name: wordpress
  namespace: demo
spec:
  type: LoadBalancer
  externalTrafficPolicy: Local
  selector:
    app: wordpress
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress
  namespace: demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wordpress
  template:
    metadata:
      labels:
        app: wordpress
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/wordpress:php8.2-apache
        name: wordpress
        env:
        - name: WORDPRESS_DB_HOST
          value: mysql.demo.svc.cluster.local.
        - name: WORDPRESS_DB_USER
          value: wordpress
        - name: WORDPRESS_DB_PASSWORD
          value: "123456"
        - name: WORDPRESS_DB_NAME
          value: wordpress
---
apiVersion: v1
kind: Service
metadata:
  name: mysql
  namespace: demo
spec:
  ports:
  - port: 3306
    protocol: TCP
    targetPort: 3306
  selector:
    app: mysql

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  namespace: demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/mysql:8.0.29-oracle
        name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: "123456"
        - name: MYSQL_DATABASE
          value: "wordpress"
        - name: MYSQL_USER
          value: wordpress
        - name: MYSQL_PASSWORD
          value: "123456"
          
# æŸ¥çœ‹svc
[root@master1 controller]#kubectl get svc -n demo 
NAME        TYPE           CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE
mysql       ClusterIP      10.111.9.21   <none>        3306/TCP       23s
wordpress   LoadBalancer   10.97.65.76   10.0.0.11     80:30371/TCP   23s

# æµè§ˆå™¨è®¿é—®
http://10.0.0.11/
```



![image-20241224154414207](../markdown_img/image-20241224154414207.png)









## KubernetesåŸŸåè§£æ

### æœåŠ¡å‘ç°æœºåˆ¶

åœ¨ä¼ ç»Ÿçš„ç³»ç»Ÿéƒ¨ç½²ä¸­ï¼ŒæœåŠ¡è¿è¡Œåœ¨ä¸€ä¸ªå›ºå®šçš„å·²çŸ¥çš„ IP å’Œç«¯å£ä¸Šï¼Œå¦‚æœä¸€ä¸ªæœåŠ¡éœ€è¦è°ƒç”¨å¦å¤–ä¸€ä¸ªæœ åŠ¡ï¼Œå¯ä»¥é€šè¿‡åœ°å€ç›´æ¥è°ƒç”¨

åœ¨Kubernetes é›†ç¾¤ä¸­ï¼ŒåŸºäºclusteripåœ°å€æ¥è®¿é—®æ¯serviceæ˜¯å¾ˆä¸æ–¹ä¾¿çš„

è™½ç„¶é€šè¿‡é…ç½®DNSå¯ä»¥å®ç°åç§°è§£ææ¥è®¿é—®ï¼Œä½†æ˜¯åœ¨Kubernetesé›†ç¾¤ä¸­ï¼ŒæœåŠ¡å®ä¾‹çš„å¯åŠ¨å’Œé”€æ¯æ˜¯å¾ˆé¢‘ ç¹çš„ï¼ŒæœåŠ¡åœ°å€åœ¨åŠ¨æ€çš„å˜åŒ–ï¼Œæ‰€ä»¥ä¼ ç»Ÿçš„æ–¹å¼é…ç½®DNSè§£æè®°å½•å°±å¾ˆä¸å‹å¥½äº†ã€‚



å°†è¯·æ±‚å‘é€åˆ°åŠ¨æ€å˜åŒ–çš„æœåŠ¡å®ä¾‹ä¸Šï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªæ­¥éª¤æ¥å®ç°ï¼š

- **æœåŠ¡æ³¨å†Œ** â€” åˆ›å»ºæœåŠ¡å®ä¾‹åï¼Œä¸»åŠ¨å°†å½“å‰æœåŠ¡å®ä¾‹çš„ä¿¡æ¯ï¼Œå­˜å‚¨åˆ°ä¸€ä¸ªé›†ä¸­å¼çš„æœåŠ¡ç®¡ç†ä¸­å¿ƒã€‚
- **æœåŠ¡å‘ç°** â€” å½“AæœåŠ¡éœ€è¦æ‰¾æœªçŸ¥çš„BæœåŠ¡æ—¶ï¼Œå…ˆå»æœåŠ¡ç®¡ç†ä¸­å¿ƒæŸ¥æ‰¾BæœåŠ¡åœ°å€ï¼Œç„¶åæ ¹æ®è¯¥åœ°å€æ‰¾åˆ°BæœåŠ¡



**Kubernetesä¸»è¦æœ‰ä¸¤ç§æœåŠ¡å‘ç°æœºåˆ¶ï¼š**

- ç¯å¢ƒå˜é‡
- DNSè§£æ







### ç¯å¢ƒå˜é‡

å¯¹äºç¯å¢ƒå˜é‡æ¥è¯´ï¼Œå®ƒä¸»è¦æœ‰ä¸¤ç§å®ç°æ–¹å¼

- **Kubernetes Serviceç¯å¢ƒå˜é‡**

  - Kubernetesä¸ºæ¯ä¸ªServiceèµ„æºç”ŸæˆåŒ…æ‹¬ä»¥ä¸‹å½¢å¼çš„ç¯å¢ƒå˜é‡åœ¨å†…ä¸€ç³»åˆ—ç¯å¢ƒå˜é‡
  - åœ¨åŒä¸€åç§°ç©ºé—´ä¸­åç»­åˆ›å»ºçš„Podå¯¹è±¡éƒ½ä¼šè‡ªåŠ¨æ‹¥æœ‰è¿™äº›å˜é‡
  - æ³¨æ„ï¼šæ­¤æ–¹å¼ä¸æ”¯æŒServiceçš„åŠ¨æ€å˜åŒ–ï¼Œå³åœ¨åˆ›å»ºPodå¯¹è±¡ä»¥åï¼ŒServiceçš„å˜åŒ–ä¸ä¼šç”Ÿæˆç›¸å…³çš„ ç¯å¢ƒå˜é‡ï¼Œç”Ÿäº§æ­¤æ–¹å¼ä¸å¤ªå¸¸è§
  - Serviceç›¸å…³ç¯å¢ƒå˜é‡å½¢å¼å¦‚ä¸‹

  ```bash
  {SVCNAME}_SERVICE_HOST {SVCNAME}_PORT
  
  # æ¯”å¦‚ï¼šdefaultåç§°ç©ºé—´åˆ›å»ºåä¸ºtestçš„Serviceï¼Œdefaultåç§°ç©ºé—´ä¸‹çš„æ¯ä¸ªPodå†…éƒ¨ä¼šè¢«è‡ªåŠ¨æ³¨å…¥ å’Œserviceç›¸å…³çš„å˜é‡
  TEST_SERVICE_HOST=ClusterIP
  TEST_PORT=tcp://ClusterIP:80
  ```

  ```yaml
  # æ³¨æ„ï¼šå¦‚æœå…ˆåˆ›å»ºPodï¼Œç„¶åå…³è”åˆ°Serviceæ˜¯ä¸ç”Ÿæ•ˆçš„
  # ä¸€å®šè¦å…ˆåˆ›å»ºServiceï¼Œåœ¨åˆ›å»ºServiceä¸‹çš„podèµ„æºç±»å‹æˆ–è€…deployç­‰ï¼Œæ‰ä¼šçœ‹åˆ°ç¯å¢ƒå˜é‡
  
  
  # ç›¸å…³å®éªŒ
  åˆ›å»ºservice
  [root@master1 controller]#kubectl create svc clusterip myweb --tcp=80:80
  service/myweb created
  
  # åˆ›å»ºç›¸å…³svcä¸‹çš„deployment
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      app: myweb                            # å¿…é¡»æ˜¯myweb,å› ä¸ºsvcæ˜¯myweb
    name: myweb
  spec:
    progressDeadlineSeconds: 600
    replicas: 3
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: myweb
    template:
      metadata:
        labels:
          app: myweb
      spec:
        containers:
        - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
          imagePullPolicy: IfNotPresent
          name: pod-test
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
  
  # åº”ç”¨
  [root@master1 controller] # kubectl apply -f myweb-deploy-test1.yaml
  deployment.apps/myweb created
  
  # æŸ¥çœ‹
  [root@master1 controller] # kubectl get pod
  NAME                     READY   STATUS        RESTARTS   AGE
  myweb-565cb68445-btlj8   1/1     Running       0          12s
  myweb-565cb68445-c8drb   1/1     Running       0          12s
  myweb-565cb68445-lj7bq   1/1     Running       0          12s
  
  [root@master1 controller] # kubectl get svc
  NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
  kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP   4h59m
  myweb        ClusterIP   10.104.153.124   <none>        80/TCP    13m
  
  
  # æŸ¥çœ‹podå†…çš„ç¯å¢ƒå˜é‡
  [root@master1 controller] # kubectl exec myweb-565cb68445-btlj8 -it -- /bin/sh
  [root@myweb-565cb68445-btlj8 /]# env
  KUBERNETES_SERVICE_PORT=443
  KUBERNETES_PORT=tcp://10.96.0.1:443
  HOSTNAME=myweb-565cb68445-btlj8
  MYWEB_SERVICE_HOST=10.104.153.124        # MYWEB_SERVICE_HOST
  SHLVL=1
  HOME=/root
  PS1=[\u@\h \w]\$ 
  MYWEB_SERVICE_PORT=80
  MYWEB_PORT=tcp://10.104.153.124:80       # MYWEB_PORT
  TERM=xterm
  MYWEB_PORT_80_TCP_ADDR=10.104.153.124
  KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
  MYWEB_SERVICE_PORT_80_80=80
  PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
  MYWEB_PORT_80_TCP_PORT=80
  
  ```



### COREDNS

#### CoreDNSä»‹ç»

![image-20241224164000953](../markdown_img/image-20241224164000953.png)



ä¸“ç”¨äºkubernetesé›†ç¾¤ä¸­çš„æœåŠ¡æ³¨å†Œå’Œå‘ç°çš„è§£å†³æ–¹æ¡ˆå°±æ˜¯KubeDNSã€‚

kubeDNSè‡ªä»Kubernetesè¯ç”Ÿä»¥æ¥ï¼Œå…¶æ–¹æ¡ˆçš„å…·ä½“å®ç°æ–¹æ¡ˆå‰åç»å†äº†ä¸‰ä»£ï¼Œåˆ†åˆ«æ˜¯ SkyDNSã€ KubeDNSã€CoreDNSã€‚

Kubernetes-v1.3ä¹‹å‰ä½¿ç”¨SkyDNS, ä¹‹ååˆ°Kubernetes-v1.13ä¹‹å‰ä½¿ç”¨KubeDNS,å½“å‰é»˜è®¤ä½¿ç”¨ **CoreDNS**

CoreDNS æ˜¯ä¸€ä¸ªDNSæœåŠ¡å™¨ã€‚Goå®ç°ï¼Œç”±äºå…¶çµæ´»æ€§ï¼Œå®ƒå¯ä»¥åœ¨å¤šç§ç¯å¢ƒä¸­ä½¿ç”¨ã€‚

CoreDNS æ˜¯ä¸€ä¸ªäº‘åŸç”Ÿè®¡ç®—åŸºé‡‘ä¼šæ¯•ä¸šçš„é¡¹ç›®ã€‚CoreDNSé€šè¿‡ Kubernetes æ’ä»¶ä¸ Kubernetes é›† æˆï¼Œæˆ–è€…é€šè¿‡etcdæ’ä»¶ä¸etcd é›†æˆ,å®ç°æœåŠ¡å‘ç°

**CoreDNS å®˜æ–¹ç½‘ç«™**

```ABAP
https://coredns.io/
https://github.com/coredns/coredns
```





#### CoreDNSè§£ææµç¨‹

CoreDNS é€šè¿‡è®¿é—®åä¸º kubernetes çš„ Service,æ‰¾åˆ° API Server è¿›è€Œè¿æ¥åˆ° ETCD, ä»è€Œå®ç° Kubernetessé›†ç¾¤ä¸­çš„Service,Endpoint,Pod ç­‰èµ„æºçš„æŸ¥æ‰¾

![image-20241224164328154](../markdown_img/image-20241224164328154.png)



- Client Pod **æŸ¥è¯¢è‡ªèº«çš„/etc/resolv.conf** æŒ‡å‘çš„DNSæœåŠ¡å™¨åœ°å€,æ­¤åœ°å€ä¸ºkube-dns serviceçš„åœ°å€, å³å°†è§£æè¯·æ±‚è½¬å‘ç»™åä¸º kube-dnsçš„ service

  ```bash
  [root@master1 controller]#kubectl exec myweb-565cb68445-btlj8 -it -- /bin/sh
  [root@myweb-565cb68445-btlj8 /]# cat /etc/resolv.conf 
  nameserver 10.96.0.10      # COREDNSçš„svcåœ°å€
  search default.svc.cluster.local svc.cluster.local cluster.local wang.org
  options ndots:5
  ```

- kube-dns serviceä¼šå°†è¯·æ±‚è½¬å‘åˆ°åç«¯CoreDNS Pod,ä¸ºäº†DNSçš„é«˜å¯ç”¨,é€šå¸¸æœ‰ä¸¤ä¸ªCoreDNS Pod, å¹¶ä½äºkube-systemåç§°ç©ºé—´

  ```bash
  [root@master1 controller]#kubectl get svc -n kube-system
  NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
  kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   5d3h
  ```

- Coredns Pod æ ¹æ®Corefileçš„é…ç½®ä¼šè¿æ¥åˆ°åœ¨defaultåç§°ç©ºé—´çš„åä¸ºkubernetesçš„service,è€Œ kubernetes serviceå¯¹åº”çš„Endpointsä¸ºæ‰€æœ‰kube-apiserver:6443çš„åœ°å€

  ```bash
  [root@master1 controller]#kubectl get svc -n kube-system
  NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
  kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   5d3h
  
  [root@master1 controller]#kubectl get ep
  NAME         ENDPOINTS                                        AGE
  kubernetes   10.0.0.201:6443                                  5h17m
  ```

- kubernetes service ç›‘è§†service IPçš„å˜åŠ¨ï¼Œç»´æŠ¤DNSè§£æè®°å½•,å¹¶å°†å˜åŒ–å‘é€è‡³ETCDå®ç°DNSè®°å½• çš„å­˜å‚¨

- CoreDNSæŸ¥è¯¢åˆ°service nameå¯¹åº”çš„IPåè¿”å›ç»™å®¢æˆ·ç«¯

- å¦‚æœæŸ¥è¯¢çš„æ˜¯å¤–éƒ¨åŸŸåï¼Œ**CoreDNSæ— æ³•è§£æï¼Œå°±è½¬å‘ç»™æŒ‡å®šçš„åŸŸåæœåŠ¡å™¨**ï¼Œ**ä¸€èˆ¬æ˜¯èŠ‚ç‚¹ ä¸Š/etc/resolv.confä¸­çš„æœåŠ¡å™¨è§£æ**

  ```bash
  # è¦ä½¿å…¶ç”Ÿæ•ˆï¼Œéœ€è¦åœ¨æ›´æ”¹corednsæ‰€åœ¨èŠ‚ç‚¹ä¸Šçš„dnsåï¼Œæ›´æ–°corednsPod
  [root@master1 controller]#kubectl rollout restart deployment -n kube-system coredns 
  deployment.apps/coredns restarted
  ```







#### CoreDNSåŸŸåè§£æ

![image-20241224175717162](../markdown_img/image-20241224175717162.png)

Cluster DNSï¼ˆCoreDNSï¼‰æ˜¯Kubernetesé›†ç¾¤çš„å¿…å¤‡é™„ä»¶ï¼Œè´Ÿè´£ä¸ºKubernetesæä¾›åç§°è§£æå’ŒæœåŠ¡å‘ç°

æ¯ä¸ªServiceèµ„æºå¯¹è±¡ï¼Œåœ¨**CoreDNSä¸Šéƒ½ä¼šè‡ªåŠ¨ç”Ÿæˆå¦‚ä¸‹æ ¼å¼çš„åç§°ï¼Œç»“åˆè¯¥åç§°ä¼šç”Ÿæˆå¯¹åº”çš„ä¸€äº›ä¸åŒ ç±»å‹çš„DNSèµ„æºè®°å½•**

```bash
<service>.<ns>.svc.<zone>
<service>ï¼š #å½“å‰Serviceå¯¹è±¡çš„åç§°
<ns>ï¼š      #å½“å‰Serviceå¯¹è±¡æ‰€å±çš„åç§°ç©ºé—´
<zone>ï¼š    #å½“å‰Kubernetesé›†ç¾¤ä½¿ç”¨çš„åŸŸååç¼€ï¼Œé»˜è®¤ä¸ºâ€œcluster.localâ€pass
```

èŒƒä¾‹ï¼škubeadmå®‰è£…æ–¹å¼æ—¶æŸ¥çœ‹é»˜è®¤Zoneåç§°

```bash
[root@master1 ~]#kubeadm config print init-defaults |grep dns
dns: {}
  dnsDomain: cluster.local
```

CoreDNSä¼šæŒç»­ç›‘è§†API Serverä¸Šçš„Serviceèµ„æºå¯¹è±¡çš„å˜åŠ¨ï¼Œå¹¶å®æ—¶åæ˜ åˆ°ç›¸å…³çš„DNSèµ„æºè®°å½•ä¸­

Podä¸­å„å®¹å™¨å†…éƒ¨é»˜è®¤ä¼šåœ¨å…¶ /etc/resolv.confä¸­ï¼Œå°†nameserveræŒ‡å‘CoreDNSç›¸å…³çš„Serviceçš„ ClusterIPï¼Œé»˜è®¤ä¸ºserviceç½‘æ®µçš„ç¬¬10ä¸ªIPï¼Œæ¯”å¦‚ï¼š10.96.0.10ï¼Œå…¶åé¢çš„Endpointæ˜¯corednså¯¹åº”çš„ Podçš„IPï¼Œæ­¤é…ç½®ç”±kubeletåˆ›å»ºPodæ—¶æ ¹æ®æŒ‡å®šçš„é…ç½®è‡ªåŠ¨æ³¨å…¥



èŒƒä¾‹ï¼šé›†ç¾¤ä¸Šçš„ä¸€ä¸ªéšæœºé€‰æ‹©çš„Podä¸­çš„å®¹å™¨æŸ¥çœ‹DNSå®¢æˆ·ç«¯é…ç½®

```bash
[root@master1 ~]#kubectl exec myweb-5d78b4dcbd-6rgv4 -- cat /etc/resolv.conf
nameserver 10.96.0.10
search default.svc.cluster.local svc.cluster.local cluster.local wang.org
options ndots:5

#ä¸Šè¿°searchå‚æ•°ä¸­æŒ‡å®šçš„DNSå„æœç´¢åŸŸï¼Œæ˜¯ä»¥æ¬¡åºæŒ‡å®šçš„å‡ ä¸ªåŸŸååç¼€ï¼Œå®ƒä»¬å„è‡ªçš„å¦‚ä¸‹æ‰€ç¤ºã€‚
#<ns>.svc.<zone>ï¼šé™„å¸¦æœ‰ç‰¹å®šåç§°ç©ºé—´çš„åŸŸåï¼Œä¾‹å¦‚default.svc.cluster.local
#svc. <zone>ï¼šé™„å¸¦äº†Kubernetesæ ‡è¯†Serviceä¸“ç”¨å­åŸŸsvcçš„åŸŸåï¼Œä¾‹å¦‚svc.cluster.localï¼›
<zone>ï¼šé›†ç¾¤æœ¬åœ°åŸŸåï¼Œä¾‹å¦‚cluster.localã€‚
#ndots:5ï¼Œè¡¨ç¤ºå¦‚æœæ‰‹å·¥æŸ¥è¯¢æ—¶å€™ç»™çš„åŸŸååŒ…å«çš„ç‚¹â€œ.â€ä¸è¶…è¿‡5ä¸ªï¼Œé‚£ä¹ˆè¿›è¡ŒDNSæŸ¥æ‰¾æ—¶å°†ä½¿ç”¨éå®Œå…¨é™å®š
åç§°ï¼Œå³ç”¨searchæŒ‡å®šçš„åŸŸåè¡¥å…¨
å³ <æ‰‹å·¥è¾“å…¥åŸŸå> æˆ–è€… <æ‰‹å·¥è¾“å…¥åŸŸå>.<search éƒ¨åˆ†ç»™å®šçš„åŸŸååç¼€>
å¦‚æœä½ æŸ¥è¯¢çš„åŸŸååŒ…å«ç‚¹æ•°å¤§äºç­‰äº5ï¼Œé‚£ä¹ˆDNSæŸ¥è¯¢ï¼Œé»˜è®¤ä¼šä½¿ç”¨ç»å¯¹åŸŸåè¿›è¡ŒæŸ¥è¯¢ã€‚
å³ <æ‰‹å·¥è¾“å…¥åŸŸå>
```



#### Service èµ„æºå¯¹åº”çš„DNSèµ„æºè®°å½•

åŸºäºDNSçš„æœåŠ¡å‘ç°ï¼Œå¯¹äºæ¯ä¸ªServiceå¯¹è±¡ï¼Œéƒ½ä¼šå…·æœ‰ä»¥ä¸‹3ä¸ªç±»å‹çš„DNSèµ„æºè®°å½•**A/AAAA**ï¼Œ**PTR**å’Œ **SRV**

- æ ¹æ®ClusterIPçš„åœ°å€ç±»å‹ï¼Œä¸ºIPv4ç”Ÿæˆå›ºå®šæ ¼å¼çš„ Aè®°å½•ï¼Œä¸ºIPv6ç”ŸæˆAAAAè®°å½•

```bash
<service>.<ns>.svc.<zone>. <ttl> IN A <cluster-ip>
<service>.<ns>.svc.<zone>. <ttl> IN AAAA <cluster-ip>
#ç¤ºä¾‹ï¼š
testapp.default.svc.cluster.local.
#æ³¨æ„ï¼šcluster.local æ˜¯é»˜è®¤zoneåç§°ï¼Œåœ¨åˆå§‹åŒ–Kubernetesé›†ç¾¤ä¸­ï¼Œè‡ªå·±é€šè¿‡dnsDomainå±æ€§å®šåˆ¶çš„ã€‚
```

- å¯¹äºæ¯ä¸ªç»™å®šçš„Aè®°å½•æˆ–AAAAè®°å½•éƒ½è¦ç”ŸæˆPTRè®°å½•ï¼Œæ ¼å¼å¦‚ä¸‹æ‰€ç¤º

```bash
<d>.<c>.<b>.<a>.in-addr.arpa. <ttl> IN PTR <service>.<ns>.svc.<zone>.
h4.h3.h2.h1.g4.g3.g2.g1.f4.f3.f2.f1.e4.e3.e2.e1.d4.d3.d2.d1.c4.c3.c2.c1.b4.b3.b2
.b1.a4.a3.a2.a1.ip6.arpa <ttl> IN PTR <service>.<ns>.svc.<zone>.
```

- ä¸ºæ¯ä¸ªå®šä¹‰äº†åç§°çš„ç«¯å£ç”Ÿæˆä¸€ä¸ªSRVè®°å½•ï¼Œæœªå‘½åçš„ç«¯å£å·åˆ™ä¸å…·æœ‰è¯¥è®°å½•

```bash
_<port_name>._<proto>.<service>.<ns>.svc.<zone>. <ttl> IN SRV <weight> 
<priority> <port-number> <service>.<ns>.svc.<zone>.
```





#### Podçš„DNSè§£æç­–ç•¥å’Œé…ç½®

Kubernetesæ”¯æŒåœ¨å•ä¸ªPodèµ„æºè§„èŒƒä¸Šè‡ªå®šä¹‰DNSè§£æç­–ç•¥å’Œé…ç½®ï¼Œå¹¶ç»„åˆç”Ÿæ•ˆ

- **pod.spec.dnsPolicy**ï¼šè§£æç­–ç•¥
  - **Default**ï¼šä»è¿è¡Œåœ¨çš„èŠ‚ç‚¹/etc/resolv.confç»§æ‰¿DNSåç§°è§£æç›¸å…³çš„é…ç½®
  - **ClusterFirst**ï¼š**æ­¤ä¸ºé»˜è®¤å€¼**ï¼Œä¼˜å…ˆä½¿ç”¨é›†ç¾¤å†…DNSæœåŠ¡ä¸Šè§£æé›†ç¾¤åŸŸå†…çš„åç§°ï¼Œå…¶ä»–åŸŸåçš„è§£æåˆ™ äº¤ç”±ä»èŠ‚ç‚¹/etc/resolv.confç»§æ‰¿çš„åç§°æœåŠ¡å™¨ å³ä½¿ç”¨Defaultç­–ç•¥
  - **ClusterFirstWithHostNet**ï¼šä¸“ç”¨äºåœ¨è®¾ç½®äº†hostNetworkï¼ˆä½¿ç”¨å®¿ä¸»æœºçš„ç½‘ç»œï¼‰çš„Podå¯¹è±¡ä¸Šå¹¶ä¸ä¼šä½¿ç”¨èŠ‚ç‚¹ç½‘ç»œçš„DNSï¼Œä»ç„¶ä½¿ç”¨çš„ClusterFirstç­–ç•¥
  - **None**ï¼šç”¨äºå¿½ç•¥Kubernetesé›†ç¾¤çš„é»˜è®¤è®¾å®šï¼Œè€Œä»…ä½¿ç”¨ç”±dnsConfigè‡ªå®šä¹‰çš„é…ç½®
- **pod.spec.dnsConfig**ï¼šåç§°è§£ææœºåˆ¶
  - **nameservers <[]string>**ï¼šDNSåç§°æœåŠ¡å™¨åˆ—è¡¨ï¼Œé™„åŠ äºç”±dnsPolicyç”Ÿæˆçš„DNSåç§°æœåŠ¡å™¨ä¹‹å
  - **searches <[]string>**ï¼šDNSåç§°è§£ææ—¶çš„æœç´¢åŸŸï¼Œé™„åŠ ç”±äºdnsPolicyç”Ÿæˆçš„æœç´¢åŸŸä¹‹å
  - **options <[]Object>**ï¼šDNSè§£æé€‰é¡¹åˆ—è¡¨ï¼ŒåŒdnsPolicyç”Ÿæˆçš„è§£æé€‰é¡¹åˆå¹¶æˆæœ€ç»ˆç”Ÿæ•ˆçš„å®šä¹‰



èŒƒä¾‹ï¼šdnsPolicy çš„ None çš„è§£æç­–ç•¥

```yaml
# cat service-pod-with-dnspolicy.yaml
apiVersion: v1
kind: Pod
metadata:
  name: service-pod-with-dnspolicy
  namespace: default
spec:
  containers:
  - name: demo
    image: wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
  dnsPolicy: None
  dnsConfig:
    nameservers:
    - 10.96.0.10
    - 180.76.76.76
    - 233.6.6.6
    searches:
    - svc.cluster.local
    - cluster.local
    - wang.org
    options:
    - name: ndots
      value: "5"  #æ„å‘³ç€å¦‚æœåŸŸåä¸­åªæœ‰5ä¸ªæˆ–æ›´å°‘çš„ç‚¹ï¼Œåˆ™ç³»ç»Ÿä¼šå°è¯•åœ¨å…¶æœ«å°¾æ·»åŠ æœç´¢åŸŸã€‚
```





#### CoreDNSé…ç½®

CoreDNSçš„é…ç½®éƒ½å­˜å‚¨åœ¨åä¸º**corednsçš„ConfigMap**å¯¹è±¡ä¸­ï¼Œè¯¥å¯¹è±¡ä½äº**kube-system**åç§°ç©ºé—´ä¸­

æœåŠ¡å™¨é…ç½®æ®µ(Server Blocks)ï¼Œç”¨äºå®šä¹‰è´Ÿè´£è§£æçš„æƒå¨åŒºåŸŸï¼Œé…ç½®æ®µæ”¾ç½®äºå…¶åçš„èŠ±æ‹¬å·{}ä¸­

æœåŠ¡å™¨é…ç½®æ®µä¹Ÿå¯ä»¥æŒ‡å®šè¦ç›‘å¬çš„ç«¯å£å·,ç«¯å£å·ä¹‹å‰éœ€è¦ä½¿ç”¨ä¸€ä¸ªå†’å·ï¼Œé»˜è®¤ä¸º53



**é…ç½®è§£æ**

```bash
# corednsçš„é…ç½®æ˜¯å­˜æ”¾åœ¨ configmapä¸­
[root@master1 ~]#kubectl get cm -n kube-system
NAME                                                   DATA   AGE
coredns                                                1      5d20h

#æŸ¥çœ‹é…ç½®å†…å®¹
apiVersion: v1
data:
  Corefile: |
    .:53 {                               # åŒ…æ‹¬è·ŸåŒºåŸŸçš„æ‰€æœ‰åŒºåŸŸå¯¹åº”çš„ç›‘å¬ç«¯å£è¿›è¡Œè§£æ
        errors                           # å°†é”™è¯¯ä¿¡æ¯è¿›è¡Œè¾“å‡º
        health {                         # LivenessProbeæ£€æµ‹ï¼Œhttp://localhost:8080/healthå®ç°
           lameduck 5s
        }
        ready                            # readinessProbeæ£€æµ‹ï¼Œhttp://localhost:8181/ready corednså°±ç»ªè¿”å›200
        kubernetes cluster.local in-addr.arpa ip6.arpa {  # åŸºäºKubernetesçš„serviceåç§°è¿›è¡ŒæŸ¥è¯¢è¿”å›æŸ¥è¯¢ç»“æœ
           pods insecure
           fallthrough in-addr.arpa ip6.arpa    # å¦‚æœin-addr.arpa ip6.arpaåŒºåŸŸè§£æå¤±è´¥ï¼Œäº¤ç”±åç»­çš„æ’ä»¶è¿›è¡Œè§£æ
           ttl 30
        }
        prometheus :9153                # é…ç½®è®¿é—®ç«¯å£ç»™Prometheuså®ç°ç›‘æ§
        forward . /etc/resolv.conf {    # forward è½¬å‘é…ç½®ï¼Œå¦‚æœé›†ç¾¤å†…éƒ¨æ— æ³•è§£æï¼Œäº¤ç”±å®¿ä¸»æœºçš„æ–‡ä»¶è§£æï¼Œä¹Ÿå¯ä¸ºIPåœ°å€
           max_concurrent 1000          # æœ€å¤§è¿æ¥æ•°ï¼Œæé«˜æ­¤å€¼å¯ä»¥æé«˜å¹¶å‘æ€§
        }
        cache 30                        # å¯ç”¨ç¼“å­˜ï¼Œå•ä½s
        loop                            # æ£€æµ‹å‘ç°ç¯è·¯æ—¶é‡å»ºcorendnså¯¹åº”çš„Podæ˜¾ç¤ºCrashLoopBackOffçŠ¶æ€è€Œåœæ­¢æŸ¥è¯¢ï¼Œæ¯”å¦‚CoreDNSç›´æ¥å°†è¯·æ±‚å‘ç»™ä¸Šæ¸¸æœåŠ¡å™¨ï¼Œåè€…å†å°†è¯·æ±‚è½¬å‘å›CoreDNS
        reload                          # æ£€æµ‹Corefileæ˜¯å¦å˜åŒ–ï¼Œä¿®æ”¹configmapä¼šé»˜è®¤2Måè‡ªåŠ¨åŠ è½½
        loadbalance                     # åŸºäºéšæœºç®—æ³•å®ç°DNSæŸ¥è¯¢è®°å½•è´Ÿè½½å‡è¡¡
    }

...
        # å¯¹äºä¼ä¸šå†…çš„dnsè§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥é€šè¿‡forwardæ¥å®ç°ï¼Œæ ¼å¼å¦‚ä¸‹
        forward <åŸŸå> <è½¬å‘è‡³å¤–éƒ¨DNSçš„åœ°å€> {  # è½¬å‘é…ç½®ï¼Œå¦‚æœé›†ç¾¤å†…éƒ¨æ— æ³•è§£æï¼Œäº¤ç”±å®¿ä¸»æœºæ–‡ä»¶æˆ–å¤–éƒ¨DNSçš„IPè§£æ
            max_concurrent æœ€å¤§è¿æ¥é…ç½®
            except æ’é™¤åŸŸå
        }
        # ç¤ºä¾‹ï¼šè½¬å‘åŸŸåè§£æè‡³é›†ç¾¤å¤–çš„DNSæœåŠ¡å™¨,"."ç‚¹è¡¨ç¤ºæ‰€æœ‰åŸŸå
        forward . 10.0.0.10 10.0.0.20 {
            prefer_udp                   # ä¼˜å…ˆä½¿ç”¨UDP
        }
        #æ³¨æ„ï¼šå¦‚æœä»…ä»…å¯¹æŸä¸ªåŸŸåè¿›è¡Œè½¬å‘çš„è¯ï¼Œåªéœ€è¦å°† <åŸŸå> éƒ¨åˆ†è®¾ç½®ä¸ºæŒ‡å®šçš„åŸŸåå³å¯ã€‚
        #ç”Ÿäº§ä¸­ä¸æ¨èç›´æ¥å°† "." çš„è½¬å‘åœ°å€ä½¿ç”¨å…¬ç½‘çš„dnsåœ°å€ï¼Œæ¨èåœ¨å½“å‰ä¸»æœºçš„/etc/resolv.confä¸­é…ç½®å¤–ç½‘ï¼Œå®ç°é—´æ¥æ•ˆæœ
        
        # æ·»åŠ ç‰¹å®šä¸»æœºçš„æ­£å‘è§£æè®°å½•ï¼Œç±»ä¼¼äº/etc/hostsæ–‡ä»¶åŠŸèƒ½
        hosts {
            192.168.10.100 www.example.com
            10.0.0.101 gitlab.example.org nfs.example.org
            10.0.0.102 jenkins.wang.org
            10.0.0.100 harbor.wang.org
            fallthrough
        }
```

```ABAP
æ’ä»¶çš„å®šä¹‰å’Œæ‰§è¡Œæ˜¯æŒ‰ç…§é…ç½®æ–‡ä»¶çš„é¡ºåºè¿›è¡Œè§£æçš„ï¼Œå¹¶ä¸” CoreDNS ä¼šå¯¹ç¬¬ä¸€ä¸ªåŒ¹é…çš„ forward æ’ä»¶è¿›è¡Œå¤„ç†ã€‚ä¸€æ—¦åŒ¹é…æˆåŠŸï¼Œå°±ä¸ä¼šç»§ç»­å¤„ç†åç»­çš„ forward æ’ä»¶ã€‚

å¦‚æœåŒ¹é…åæ— æ³•è§£æè¯¥åŸŸåï¼ŒCoreDNS å°†è¿”å› NXDOMAIN æˆ– SERVFAILã€‚
å¦‚æœå¸Œæœ›å‰é¢æ— æ³•è§£æçš„æƒ…å†µä¸‹ï¼Œç»§ç»­å°è¯•åç»­çš„é…ç½®ï¼Œå¯ä»¥åœ¨é…ç½®ä¸­æ·»åŠ fallthrough

# ç¤ºä¾‹ï¼š
forward wang.org 10.0.0.200 {
    fallthrough
}
```





èŒƒä¾‹: ä¸ä½¿ç”¨é»˜è®¤çš„è½¬å‘ç­–ç•¥ï¼Œä½¿ç”¨è‡ªå®šä¹‰çš„è½¬å‘ç­–ç•¥

```bash
# ä¿®æ”¹é…ç½®æ–‡ä»¶
[root@master1 ~]#kubectl edit cm coredns -n kube-system 
configmap/coredns edited

# ä¿®æ”¹ä¹‹åé‡å¯CoreDNS
[root@master1 ~]#kubectl rollout restart -n kube-system deployment coredns 
deployment.apps/coredns restarted
```



### Headless Service

#### æ— å¤´æœåŠ¡æœºåˆ¶

æ— å¤´æœåŠ¡åœºæ™¯ä¸‹ï¼ŒKubernetesä¼šå°†ä¸€ä¸ªé›†ç¾¤å†…éƒ¨çš„æ‰€æœ‰Podæˆå‘˜æä¾›å”¯ä¸€çš„DNSåŸŸåæ¥ä½œä¸ºæ¯ä¸ªæˆå‘˜çš„ ç½‘ç»œæ ‡è¯†ï¼Œé›†ç¾¤å†…éƒ¨æˆå‘˜ä¹‹é—´ä½¿ç”¨åŸŸåé€šä¿¡ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œå°±ç‰¹åˆ«ä¾èµ–serviceçš„selectorå±æ€§é…ç½®äº†ã€‚



**å¹¿ä¹‰ä¸ŠHeadless Serviceï¼Œå®ƒä»¬åˆå¯ä»¥ä¸ºåˆ†ä¸¤ç§æƒ…å½¢**

- æœ‰æ ‡ç­¾é€‰æ‹©å™¨ï¼Œæˆ–è€…æ²¡æœ‰æ ‡ç­¾é€‰æ‹©å™¨,ä½†æœ‰ç€ä¸Serviceå¯¹è±¡åŒåçš„Endpointèµ„æº
  - Serviceçš„DNSåç§°ç›´æ¥è§£æä¸ºåç«¯å„å°±ç»ªçŠ¶æ€çš„Podçš„IPåœ°å€
  - è°ƒåº¦åŠŸèƒ½ä¹Ÿå°†ç”±DNSå®Œæˆ
  - å„Pod IPç›¸å…³PTRè®°å½•å°†è§£æè‡³Podåç§°ï¼Œå‡è®¾Pod IPä¸ºa.b.c.dï¼Œåˆ™å…¶Podåç§°ä¸ºa-b-c-d...SVC.
  - è¿™ç§ç±»å‹ä¹Ÿå°±æ˜¯ç‹­ä¹‰ä¸Šçš„Headless Service
  - ä¸»è¦åº”ç”¨äºæœ‰çŠ¶æ€æœåŠ¡çš„**statefulSet**èµ„æºå¯¹è±¡

- æ— æ ‡ç­¾é€‰æ‹©å™¨ä¸”ä¹Ÿæ²¡æœ‰ä¸Serviceå¯¹è±¡åŒåçš„Endpointèµ„æº
  - ç”¨äºé›†ç¾¤å¤–éƒ¨ ExternalName ç±»å‹çš„Service
  - Serviceçš„DNSåç§°å°†ä¼šç”Ÿæˆä¸€æ¡CNAMEè®°å½•ï¼Œå¯¹åº”å€¼ç”±Serviceå¯¹è±¡ä¸Šçš„spec.externalNameå­—æ®µæŒ‡å®š

```ABAP
æ³¨æ„: headless serviceæ˜¯ä¸€ä¸ªå››å±‚è°ƒåº¦ï¼Œå› ä¸ºiptatbles/ipvséƒ½æ˜¯å››å±‚çš„
```



**ä¸»è¦çš„åº”ç”¨åœºæ™¯**

- ServiceName --> (label Selectorï¼ŒPod) --> æ‰€æœ‰Podçš„IPåœ°å€ï¼Œæ­¤æ–¹å¼åˆç§°ä¸ºç‹­ä¹‰çš„Headless  Serviceï¼Œä¸»è¦åº”ç”¨åœ¨ **StatefulSet**
- ServiceName --> CName ï¼ˆ**ExternalName**ï¼‰ --> ExternalService IPï¼Œæ­¤æ–¹å¼ç§°ä¸ºç‹­ä¹‰çš„ External Service



**æ— å¤´æœåŠ¡ç®¡ç†çš„åŸŸåæ˜¯å¦‚ä¸‹çš„æ ¼å¼ï¼š**

```bash
$(service_name).$(Kubernetes_namespace).svc.cluster.local
```



**DNS è§£æè®°å½•**

```bash
#Aè®°å½•
<a>-<b>-<c>-<d>.<service>.<ns>.svc.<zone> A PodIP

#PodIPçš„PTRåè§£æè®°å½•  
<d>.<c>.<b>.<a>.in-addr.arpa IN PTR <ç”¨æ¨ªçº¿åˆ†éš”çš„PodIP>.<service>.<ns>.svc.<zone>

#å…³é”®ç‚¹ï¼š
æ­£å‘è§£æ:svc_nameçš„è§£æç»“æœä»å¸¸è§„Serviceçš„ClusterIPï¼Œè½¬ä¸ºè§£ææˆå„ä¸ªPodçš„IPåœ°å€
åå‘è§£æ:ä»å¸¸è§„çš„clusteripè§£æä¸ºservice nameï¼Œè½¬ä¸ºä»podipåˆ°hostname, <a>-<b>-<c>-<d>.
<service>.<ns>.svc.<zone>
<hostname>æŒ‡çš„æ˜¯a-b-c-dæ ¼å¼ï¼Œè€ŒéPodè‡ªå·±çš„ä¸»æœºåï¼›
```



**æ¡ˆä¾‹ï¼š: Headless Service**

```bash
# å‘½ä»¤è¡Œæ–¹å¼
[root@master1 ~]#kubectl create service clusterip service-headless-cmd --clusterip="None"

# åˆ›å»ºæ–‡ä»¶
[root@master1 headlessService]#vim service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-headless
spec:
  selector:
    app: myweb
  clusterIP: "None"  #æ— å¤´æœåŠ¡
  
# åº”ç”¨
[root@master1 headlessService]#kubectl apply -f service-headless.yaml 
service/service-headless created

# æŸ¥çœ‹
[root@master1 headlessService]#kubectl exec myweb-565cb68445-btlj8 -- host service-headless
service-headless.default.svc.cluster.local has address 10.244.1.104
service-headless.default.svc.cluster.local has address 10.244.2.56
service-headless.default.svc.cluster.local has address 10.244.3.111
```







## Kubernetesæ•°æ®å­˜å‚¨





**æœ¬ç« å†…å®¹**

- **å­˜å‚¨æœºåˆ¶**
- **emptyDir**
- **hostPath**
- **ç½‘ç»œå…±äº«å­˜å‚¨**
- **PVå’ŒPVC**
- **StorageClass**
- **CNSçš„å­˜å‚¨æ–¹æ¡ˆOpenEBS**







### æ•°æ®å­˜å‚¨



#### å­˜å‚¨æœºåˆ¶

Container ä¸­çš„æ–‡ä»¶åœ¨ç£ç›˜ä¸Šæ˜¯ä¸´æ—¶å­˜æ”¾çš„ï¼Œè¿™ç»™ Container ä¸­è¿è¡Œçš„è¾ƒé‡è¦çš„åº”ç”¨ç¨‹åºå¸¦æ¥ä¸€äº›é—®é¢˜ã€‚

- å½“å®¹å™¨å´©æºƒæ—¶ã€‚ kubelet å¯èƒ½ä¼šé‡æ–°åˆ›å»ºå®¹å™¨ï¼Œå¯èƒ½ä¼šå¯¼è‡´å®¹å™¨æ¼‚ç§»è‡³æ–°çš„å®¿ä¸»æœºï¼Œå®¹å™¨ä¼šä»¥å¹²å‡€çš„çŠ¶æ€é‡å»ºã€‚å¯¼è‡´æ•°æ®ä¸¢å¤±
- åœ¨åŒä¸€ Pod ä¸­è¿è¡Œå¤šä¸ªå®¹å™¨éœ€è¦å…±äº«æ•°æ®



Kubernetes å·ï¼ˆVolumeï¼‰ è¿™ä¸€æŠ½è±¡æ¦‚å¿µèƒ½å¤Ÿè§£å†³è¿™ä¸¤ä¸ªé—®é¢˜



Kubernetes é›†ç¾¤ä¸­çš„å®¹å™¨æ•°æ®å­˜å‚¨

![image-20241225142912632](../markdown_img/image-20241225142912632.png)





**Kubernetesæ”¯æŒçš„å­˜å‚¨ç±»å‹**

Kubernetesæ”¯æŒä¸°å¯Œçš„å­˜å‚¨ç±»å‹ï¼Œå¯ä»¥åˆ†ä¸ºæ ‘å†…å’Œæ ‘å¤–ä¸¤ç§



**æ ‘å†… In-Tree å­˜å‚¨å·æ’ä»¶**

| ç±»å‹         | ä¸¾ä¾‹                                                         |
| ------------ | ------------------------------------------------------------ |
| ä¸´æ—¶å­˜å‚¨å·   | emptyDir                                                     |
| æœ¬åœ°æ•°æ®å·   | hostPathã€local                                              |
| æ–‡ä»¶ç³»ç»Ÿ     | NFSã€CephFSã€GlusterFSã€fastdfsã€Cinderã€gitRepo(DEPRECATED) |
| å—è®¾å¤‡       | iSCSIã€FCã€rdb(å—è®¾å¤‡)ã€vSphereVolume                        |
| å­˜å‚¨å¹³å°     | Quobyteã€PortworxVolumeã€StorageOSã€ScaleIO                  |
| äº‘å­˜å‚¨æ•°æ®å· | Aliyun OSSã€Amazon S3ã€AWS Elastic Block Storeã€Google gcePersistentDiskç­‰ |
| ç‰¹æ®Šå­˜å‚¨å·   | ConfigMapã€Secretã€DownwardAPIã€Projectdã€flocker            |



**æ ‘å¤– Out-of_Tree å­˜å‚¨å·æ’ä»¶**

ç»ç”±**å®¹å™¨å­˜å‚¨æ¥å£CSI**æˆ–**FlexVolumeæ¥å£ï¼ˆå·²æ·˜æ±°ï¼‰**æ‰©å±•å‡ºçš„å¤–éƒ¨çš„å­˜å‚¨ç³»ç»Ÿç§°ä¸ºOut-of-Trecç±»çš„å­˜å‚¨æ’ä»¶



- **CSI æ’ä»¶**

  - Container Storage Interface æ˜¯å½“å‰Kubernetesç¤¾åŒºæ¨èçš„æ’ä»¶å®ç°æ–¹æ¡ˆ
  - CSI ä¸ä»…æ”¯æŒKuberneteså¹³å°å­˜å‚¨æ’ä»¶æ¥å£ï¼Œè€Œä¸”ä¹Ÿä½œä¸ºäº‘åŸç”Ÿç”Ÿæ€ä¸­å®¹å™¨å­˜å‚¨æ¥å£çš„æ ‡å‡†,å…¬ç”¨ äº‘å¯¹å…¶æœ‰æ›´å¥½çš„æ”¯æŒ
  - Kubernetes æ”¯æŒ CSI çš„æ¥å£æ–¹å¼å®ç°æ›´å¤§èŒƒå›´çš„å­˜å‚¨åŠŸèƒ½æ‰©å±•,æ›´ä¸ºæ¨èä½¿ç”¨

  ```bash
  https://github.com/container-storage-interface/spec/blob/master/spec.md
  ```

  

CSI ä¸»è¦åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š**CSI Controller Server** ä¸ **CSI Node Server**ï¼Œåˆ†åˆ«å¯¹åº”**Controller Server Pod**å’Œ **Node Server Pod**



![image-20241225145234834](../markdown_img/image-20241225145234834.png)

- **Controller Server**
  - ä¹Ÿç§°ä¸ºCSI Controller
  - åœ¨é›†ç¾¤ä¸­åªéœ€è¦éƒ¨ç½²ä¸€ä¸ª Controller Serverï¼Œä»¥ deployment æˆ–è€… StatefulSet çš„å½¢å¼è¿è¡Œ
  - ä¸»è¦è´Ÿè´£ä¸å­˜å‚¨æœåŠ¡APIé€šä¿¡å®Œæˆåç«¯å­˜å‚¨çš„ç®¡ç†æ“ä½œï¼Œæ¯”å¦‚ provision å’Œ attach å·¥ä½œã€‚



- **Node Server**
  - ä¹Ÿç§°ä¸ºCSI Node æˆ– Node Plugin
  - ä¿è¯æ¯ä¸€ä¸ªèŠ‚ç‚¹ä¼šæœ‰ä¸€ä¸ª Pod éƒ¨ç½²å‡ºæ¥ï¼Œè´Ÿè´£åœ¨èŠ‚ç‚¹çº§åˆ«å®Œæˆå­˜å‚¨å·ç®¡ç†ï¼Œå’Œ CSI Controller ä¸€èµ· å®Œæˆ volume çš„ mount æ“ä½œã€‚
  - Node Server Pod æ˜¯ä¸ª DaemonSetï¼Œå®ƒä¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿›è¡Œæ³¨å†Œã€‚
  - Kubelet ä¼šç›´æ¥é€šè¿‡ Socket çš„æ–¹å¼ç›´æ¥å’Œ CSI Node Server è¿›è¡Œé€šä¿¡ã€è°ƒç”¨ Attach/Detach/Mount/Unmount ç­‰ã€‚



![image-20241225145625234](../markdown_img/image-20241225145625234.png)





**CSI æ’ä»¶åŒ…æ‹¬ä»¥ä¸‹ä¸¤éƒ¨åˆ†**

- **CSI-Plugin**:å®ç°æ•°æ®å·çš„æŒ‚è½½ã€å¸è½½åŠŸèƒ½ã€‚
- **CSI-Provisioner**: åˆ¶å¤‡å™¨ï¼ˆProvisionerï¼‰å®ç°æ•°æ®å·çš„è‡ªåŠ¨åˆ›å»ºç®¡ç†èƒ½åŠ›ï¼Œå³é©±åŠ¨ç¨‹åºï¼Œæ¯”å¦‚: æ”¯ æŒäº‘ç›˜ã€NASç­‰å­˜å‚¨å·åˆ›å»ºèƒ½åŠ›



**Kubernetes å­˜å‚¨æ¶æ„**

å­˜å‚¨çš„ç»„ä»¶ä¸»è¦æœ‰ï¼šattach/detach controllerã€pv controllerã€volume managerã€volume pluginsã€ scheduler

æ¯ä¸ªç»„ä»¶åˆ†å·¥æ˜ç¡®

![image-20241225150025215](../markdown_img/image-20241225150025215.png)

- **ADæ§åˆ¶å™¨**ï¼šè´Ÿè´£å­˜å‚¨è®¾å¤‡çš„Attach/Detachæ“ä½œ
  - Attachï¼šå°†è®¾å¤‡é™„åŠ åˆ°ç›®æ ‡èŠ‚ç‚¹
  - Detachï¼šå°†è®¾å¤‡ä»ç›®æ ‡èŠ‚ç‚¹ä¸Šå¸è½½
- **Volume Manager**ï¼šå­˜å‚¨å·ç®¡ç†å™¨ï¼Œè´Ÿè´£å®Œæˆå·çš„Mount/Umountæ“ä½œï¼Œä»¥åŠè®¾å¤‡çš„æ ¼å¼åŒ–æ“ä½œç­‰
- **PV Controller** ï¼šè´Ÿè´£PV/PVCçš„ç»‘å®šã€ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œä»¥åŠå­˜å‚¨å·çš„Provision/Deleteæ“ä½œ
- **volume plugins**ï¼šåŒ…å«k8såŸç”Ÿçš„å’Œå„å‚å•†çš„çš„å­˜å‚¨æ’ä»¶ï¼Œæ‰©å±•å„ç§å­˜å‚¨ç±»å‹çš„å·ç®¡ç†èƒ½åŠ›
  - åŸç”Ÿçš„åŒ…æ‹¬ï¼šemptydirã€hostpathã€csiç­‰
  - å„å‚å•†çš„åŒ…æ‹¬ï¼šaws-ebsã€azureç­‰
- schedulerï¼šå®ç°Podçš„è°ƒåº¦ï¼Œæ¶‰åŠåˆ°volumeçš„è°ƒåº¦ã€‚æ¯”å¦‚ebsã€csiå…³äºå•nodeæœ€å¤§å¯attachç£ç›˜ æ•°é‡çš„predicateç­–ç•¥ï¼Œschedulerçš„è°ƒåº¦è‡³å“ªä¸ªæŒ‡å®šç›®æ ‡èŠ‚ç‚¹ä¹Ÿä¼šå—åˆ°å­˜å‚¨æ’ä»¶çš„å½±å“





### Podçš„å­˜å‚¨å·Volume

Kubernetes æ”¯æŒåœ¨Podä¸Šåˆ›å»ºä¸åŒç±»å‹çš„ä»»æ„æ•°é‡çš„å·æ¥å®ç°ä¸åŒæ•°æ®çš„å­˜å‚¨



**å•èŠ‚ç‚¹å­˜å‚¨**

![image-20241225151327829](../markdown_img/image-20241225151327829.png)



**å¤šèŠ‚ç‚¹å­˜å‚¨**

![image-20241225151355422](../markdown_img/image-20241225151355422.png)



å­˜å‚¨å·æœ¬è´¨ä¸Šè¡¨ç°ä¸º Podä¸­**æ‰€æœ‰å®¹å™¨å…±äº«è®¿é—®çš„ç›®å½•**

è€Œæ­¤ç›®å½•çš„åˆ›å»ºæ–¹å¼ã€ä½¿ç”¨çš„å­˜å‚¨ä»‹è´¨ä»¥åŠç›®å½•çš„åˆå§‹å†…å®¹æ˜¯ç”±Podè§„èŒƒä¸­å£°æ˜çš„å­˜å‚¨å·ç±»å‹æ¥æºå†³å®š

**kubeletå†…ç½®æ”¯æŒå¤šç§å­˜å‚¨å·æ’ä»¶**ï¼Œ**å­˜å‚¨å·æ˜¯ç”±å„ç§å­˜å‚¨æ’ä»¶(å­˜å‚¨é©±åŠ¨)æ¥æä¾›å­˜å‚¨æœåŠ¡**

å­˜å‚¨å·æ’ä»¶(å­˜å‚¨é©±åŠ¨)å†³å®šäº†æ”¯æŒçš„åç«¯å­˜å‚¨ä»‹è´¨æˆ–å­˜å‚¨æœåŠ¡ï¼Œä¾‹å¦‚hostPathæ’ä»¶ä½¿ç”¨å®¿ä¸»æœºæ–‡ä»¶ç³» ç»Ÿï¼Œè€Œnfsæ’ä»¶åˆ™å¯¹æ¥æŒ‡å®šçš„NFSå­˜å‚¨æœåŠ¡ç­‰

Podåœ¨è§„èŒƒä¸­éœ€è¦æŒ‡å®šå…¶åŒ…å«çš„å·ä»¥åŠè¿™äº›å·åœ¨å®¹å™¨ä¸­çš„æŒ‚è½½è·¯å¾„

**å­˜å‚¨å·éœ€è¦å®šä¹‰åœ¨æŒ‡å®šçš„Podä¹‹ä¸Š**

æœ‰äº›å·æœ¬èº«çš„ç”Ÿå‘½å‘¨æœŸä¸Podç›¸åŒï¼Œä½†å…¶åç«¯çš„å­˜å‚¨åŠç›¸å…³æ•°æ®çš„ç”Ÿå‘½å‘¨æœŸé€šå¸¸è¦å–å†³äºå­˜å‚¨ä»‹è´¨



å­˜å‚¨å·å¯ä»¥åˆ†ä¸ºï¼š**ä¸´æ—¶å·å’ŒæŒä¹…å·**

- **ä¸´æ—¶å·ç±»å‹**çš„ç”Ÿå‘½å‘¨æœŸä¸ Pod ç›¸åŒï¼Œ å½“ Pod ä¸å†å­˜åœ¨æ—¶ï¼ŒKubernetes ä¹Ÿä¼šé”€æ¯ä¸´æ—¶å·
- æŒä¹…å·å¯ä»¥æ¯” Pod çš„å­˜æ´»æœŸé•¿ã€‚å½“ Pod ä¸å†å­˜åœ¨æ—¶ï¼ŒKubernetes ä¸ä¼šé”€æ¯æŒä¹…å·ã€‚
- ä½†å¯¹äºç»™å®š Pod ä¸­ä»»ä½•ç±»å‹çš„å·ï¼Œåœ¨å®¹å™¨é‡å¯æœŸé—´æ•°æ®éƒ½ä¸ä¼šä¸¢å¤±ã€‚



#### Podä¸­å·çš„ä½¿ç”¨

- ä¸€ä¸ªPodå¯ä»¥æ·»åŠ ä»»æ„ä¸ªå·
- åŒä¸€ä¸ªPodå†…æ¯ä¸ªå®¹å™¨å¯ä»¥åœ¨ä¸åŒä½ç½®æŒ‰éœ€æŒ‚è½½Podä¸Šçš„ä»»æ„ä¸ªå·ï¼Œæˆ–è€…ä¸æŒ‚è½½ä»»ä½•å·
- åŒä¸€ä¸ªPodä¸Šçš„æŸä¸ªå·ï¼Œä¹Ÿå¯ä»¥åŒæ—¶è¢«è¯¥Podå†…çš„å¤šä¸ªå®¹å™¨åŒæ—¶æŒ‚è½½ï¼Œä»¥å…±äº«æ•°æ®
- å¦‚æœæ”¯æŒï¼Œå¤šä¸ªPodä¹Ÿå¯ä»¥é€šè¿‡å·æ¥å£è®¿é—®åŒä¸€ä¸ªåç«¯å­˜å‚¨å•å…ƒ

![image-20241225155834088](../markdown_img/image-20241225155834088.png)



**å­˜å‚¨å·çš„é…ç½®ç”±ä¸¤éƒ¨åˆ†ç»„æˆ**

- é€šè¿‡.spec.volumeså­—æ®µå®šä¹‰åœ¨Podä¹‹ä¸Šçš„å­˜å‚¨å·åˆ—è¡¨ï¼Œå®ƒç»ç”±ç‰¹å®šçš„å­˜å‚¨å·æ’ä»¶å¹¶ç»“åˆç‰¹å®šçš„å­˜å‚¨ä¾›ç»™æ–¹çš„è®¿é—®æ¥å£è¿›è¡Œå®šä¹‰
- åµŒå¥—å®šä¹‰åœ¨å®¹å™¨çš„volumeMountså­—æ®µä¸Šçš„å­˜å‚¨å·æŒ‚è½½åˆ—è¡¨ï¼Œå®ƒåªèƒ½æŒ‚è½½å½“å‰Podå¯¹è±¡ä¸­å®šä¹‰çš„å­˜å‚¨å·



**Pod å†…éƒ¨å®¹å™¨ä½¿ç”¨å­˜å‚¨å·æœ‰ä¸¤æ­¥ï¼š**

- åœ¨Podä¸Šå®šä¹‰å­˜å‚¨å·ï¼Œå¹¶å…³è”è‡³ç›®æ ‡å­˜å‚¨æœåŠ¡ä¸Š **volumes**
  - **å®šä¹‰å·**
- åœ¨éœ€è¦ç”¨åˆ°å­˜å‚¨å·çš„å®¹å™¨ä¸Šï¼ŒæŒ‚è½½å…¶æ‰€å±çš„Podä¸­pauseçš„å­˜å‚¨å· **volumesMount**
  - **å¼•ç”¨å·**



**å®¹å™¨å¼•æ“å¯¹å…±äº«å¼å­˜å‚¨è®¾å¤‡çš„æ”¯æŒç±»å‹ï¼š**

- **å•è·¯è¯»å†™** - å¤šä¸ªå®¹å™¨å†…å¯ä»¥é€šè¿‡åŒä¸€ä¸ªä¸­é—´å®¹å™¨å¯¹åŒä¸€ä¸ªå­˜å‚¨è®¾å¤‡è¿›è¡Œè¯»å†™æ“ä½œ
- **å¤šè·¯å¹¶è¡Œè¯»å†™** - å¤šä¸ªå®¹å™¨å†…å¯ä»¥åŒæ—¶å¯¹åŒä¸€ä¸ªå­˜å‚¨è®¾å¤‡è¿›è¡Œè¯»å†™æ“ä½œ
- **å¤šè·¯åªè¯»** - å¤šä¸ªå®¹å™¨å†…å¯ä»¥åŒæ—¶å¯¹åŒä¸€ä¸ªå­˜å‚¨è®¾å¤‡è¿›è¡Œåªè¯»æ“ä½œ



**Podçš„å·èµ„æºå¯¹è±¡å±æ€§**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: <string>
  namespace: <string>
spec:
  volumes:                       # å®šä¹‰å·
  - name: <string>               # å­˜å‚¨å·åç§°æ ‡è¯†ï¼Œä»…å¯ä½¿ç”¨DNSæ ‡ç­¾æ ¼å¼çš„å­—ç¬¦ï¼Œåœ¨å½“å‰Podå¿…é¡»å”¯ä¸€
    VOL_TYPE: <Object>           # å­˜å‚¨å·æ’ä»¶åŠå…·ä½“çš„ç›®æ ‡å­˜å‚¨ä¾›ç»™æ–¹çš„ç›¸å…³é…ç½®
  containers:
  - name: ...
    image: ...
    volumeMounts:                # æŒ‚è½½å·
    - name: <string>             # è¦æŒ‚è½½çš„å­˜å‚¨å·çš„åç§°ï¼Œå¿…é¡»åŒ¹é…å­˜å‚¨å·åˆ—è¡¨ä¸­æŸé¡¹çš„å®šä¹‰
      mountPath: <string>        # å®¹å™¨æ–‡ä»¶ç³»ç»Ÿä¸Šçš„æŒ‚è½½ç‚¹è·¯å¾„
      readOnly: <boolean>        # æ˜¯å¦æŒ‚è½½ä¸ºåªè¯»æ¨¡å¼ï¼Œé»˜è®¤ä¸º"å¦"ï¼Œå³å¯è¯»å¯å†™
      subPath: <string>          # æŒ‚è½½å­˜å‚¨å·ä¸Šçš„ä¸€ä¸ªå­ç›®å½•è‡³æŒ‡å®šæŒ‚è½½ç‚¹
      subPathExpr: <string>      # æŒ‚è½½æœ‰æŒ‡å®šçš„æ¨¡å¼åŒ¹é…åˆ°çš„å­˜å‚¨å·çš„æ–‡ä»¶æˆ–ç›®å½•è‡³æŒ‚è½½ç‚¹
```





### emptyDir

ä¸€ä¸ªemptyDir volumeåœ¨podè¢«è°ƒåº¦åˆ°æŸä¸ªNodeæ—¶å€™è‡ªåŠ¨åˆ›å»ºçš„ï¼Œæ— éœ€æŒ‡å®šå®¿ä¸»æœºä¸Šå¯¹åº”çš„ç›®å½•ã€‚ é€‚ç”¨äºåœ¨ä¸€ä¸ª**Podä¸­ä¸åŒå®¹å™¨é—´çš„ä¸´æ—¶æ•°æ®çš„å…±äº«**



**emptyDir æ•°æ®å­˜æ”¾åœ¨å®¿ä¸»æœºçš„è·¯å¾„å¦‚ä¸‹**

```bash
/var/lib/kubelet/pods/<pod_id>/volumes/kubernetes.io~empty-dir/<volume_name>/<FILE>

#æ³¨æ„ï¼šæ­¤ç›®å½•éšç€Podåˆ é™¤ï¼Œä¹Ÿä¼šéšä¹‹åˆ é™¤ï¼Œä¸èƒ½å®ç°æŒä¹…åŒ–

# æŸ¥çœ‹podæ‰€åœ¨èŠ‚ç‚¹
[root@master1 pods]#kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS        AGE   IP             NODE    NOMINATED NODE   READINESS GATES
myweb-565cb68445-btlj8   1/1     Running   1 (7h25m ago)   24h   10.244.2.56    node2   <none>           <none>
myweb-565cb68445-c8drb   1/1     Running   1 (7h26m ago)   24h   10.244.1.104   node1   <none>           <none>
myweb-565cb68445-lj7bq   1/1     Running   1 (7h25m ago)   24h   10.244.3.111   node3   <none>           <none>

# æŸ¥çœ‹podèŠ‚ç‚¹ä¸ŠemptyDiræ•°æ®å­˜æ”¾çš„è·¯å¾„
[root@master1 pods]#ssh 10.0.0.203 ls /var/lib/kubelet/pods/
242cc64b-4330-4c00-ba80-9228f2186367
4a737c21-36e2-413d-a53f-ce65b9b4698e
9fe61621-a076-4d35-add9-c329ca6b12db
eed8a3fa-73e0-4a1e-b897-4235d77cae66

# æŸ¥çœ‹å¯¹åº”çš„podçš„uid
[root@master1 pods]#kubectl get pod myweb-565cb68445-btlj8 -o yaml|grep -i uid
    uid: 4db8879a-ee0d-48d3-8b7e-675581eb4fa2
  uid: eed8a3fa-73e0-4a1e-b897-4235d77cae66      # -------- åŒ¹é…ä¸Šé¢çš„è·¯å¾„uid
```



**emptyDir ç‰¹ç‚¹å¦‚ä¸‹ï¼š**

- æ­¤ä¸º**é»˜è®¤å­˜å‚¨ç±»å‹**
- æ­¤æ–¹å¼åªèƒ½ä¸´æ—¶å­˜æ”¾æ•°æ®ï¼Œä¸èƒ½å®ç°æ•°æ®æŒä¹…åŒ–
- è·ŸéšPodåˆå§‹åŒ–è€Œæ¥ï¼Œå¼€å§‹æ˜¯ç©ºæ•°æ®å·
- Pod è¢«åˆ é™¤ï¼ŒemptyDirå¯¹åº”çš„å®¿ä¸»æœºç›®å½•ä¹Ÿè¢«åˆ é™¤ï¼Œå½“ç„¶ç›®å½•å†…çš„æ•°æ®éšä¹‹æ°¸ä¹…æ¶ˆé™¤
- emptyDir æ•°æ®å·ä»‹è´¨ç§ç±»è·Ÿå½“å‰ä¸»æœºçš„ç£ç›˜ä¸€æ ·ã€‚
- emptyDir ä¸»æœºå¯ä»¥ä¸ºåŒä¸€ä¸ªPodå†…å¤šä¸ªå®¹å™¨å…±äº«
- emptyDir å®¹å™¨æ•°æ®çš„ä¸´æ—¶å­˜å‚¨ç›®å½•ä¸»è¦ç”¨äºæ•°æ®ç¼“å­˜å’Œ**åŒä¸€ä¸ªPodå†…çš„å¤šä¸ªå®¹å™¨å…±äº«ä½¿ç”¨**



**emptyDirå±æ€§è§£æ**

```bash
kubectl explain pod.spec.volumes.emptyDir
    medium       # æŒ‡å®šåª’ä»‹ç±»å‹ï¼Œä¸»è¦æœ‰defaultå’Œmemoryä¸¤ç§
                 # é»˜è®¤æƒ…å†µä¸‹ï¼ŒemptyDirå·æ”¯æŒèŠ‚ç‚¹ä¸Šçš„ä»»ä½•ä»‹è´¨ï¼ŒSSDã€ç£ç›˜æˆ–ç½‘ç»œå­˜å‚¨ï¼Œå…·ä½“å–å†³äºè‡ªèº«æ‰€åœ¨Nodeçš„ç¯å¢ƒ
                 # å°†å­—æ®µè®¾ç½®ä¸ºMemoryï¼Œè®©K8Sä½¿ç”¨tmpfsï¼Œè™½ç„¶tmpfså¿«ï¼Œä½†æ˜¯Podé‡å¯æ—¶ï¼Œæ•°æ®ä¼šè¢«æ¸…é™¤ï¼Œå¹¶ä¸”è®¾ç½®çš„å¤§å°ä¼šè¢«è®¡å…¥                    # Containerçš„å†…å­˜é™åˆ¶å½“ä¸­
    sizeLimit    # å½“å‰å­˜å‚¨å·çš„ç©ºé—²é™åˆ¶ï¼Œé»˜è®¤å€¼ä¸ºnilè¡¨ç¤ºä¸é™åˆ¶
    
kubectl explain pod.spec.containers.volumeMounts
    mountPath    # æŒ‚è½½åˆ°å®¹å™¨ä¸­çš„è·¯å¾„,æ­¤ç›®å½•ä¼šè‡ªåŠ¨ç”Ÿæˆ
    name         # æŒ‡å®šæŒ‚è½½çš„volumesåç§°
    readOnly     # æ˜¯å¦åªè¯»æŒ‚è½½
    subPath      # æ˜¯å¦æŒ‚è½½å­ç›®å½•çš„è·¯å¾„,é»˜è®¤ä¸æŒ‚è½½å­ç›®å½•
```



**é…ç½®ç¤ºä¾‹**

```yaml
# volumeé…ç½®æ ¼å¼
volumes:
- name: volume_name
  emptyDir: {}
  
# volumeä½¿ç”¨æ ¼å¼
containers:
- volumeMounts:
  - name: volume_name
    mountPath: /path/to/container/  # å®¹å™¨å†…è·¯å¾„


# ç¤ºä¾‹1
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
  - image: registry.k8s.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    emptyDir: {}
    
# ç¤ºä¾‹2ï¼š
apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: registry.k8s.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    emptyDir:
      medium: Memory
      sizeLimit: 500Mi
```



èŒƒä¾‹ï¼šåœ¨ä¸€ä¸ªPodä¸­å®šä¹‰å¤šä¸ªå®¹å™¨é€šè¿‡emptyDirå…±äº«æ•°æ®

```yaml
[root@master1 storage] # vim storage-emptydir-2.yaml
apiVersion: v1
kind: Pod
metadata:
  name: storage-emptydir
spec:
  volumes:
  - name: nginx-data
    emptyDir: {}
  containers:
  - name: storage-emptydir-nginx
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    volumeMounts:
    - name: nginx-data
      mountPath: /usr/share/nginx/html/
  - name: storage-emptydir-busybox
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/busybox:1.32.0
    volumeMounts:
    - name: nginx-data
      mountPath: /data/
    command:
    - "/bin/sh"
    - "-c"
    - "while true; do date > /data/index.html; sleep 1; done"

# åº”ç”¨
[root@master1 storage]#kubectl apply -f storage-emptydir-2.yaml 
pod/storage-emptydir created

# æŸ¥çœ‹Pod
[root@master1 storage] # kubectl get pod -o wide
NAME                     READY   STATUS              RESTARTS      AGE   IP             NODE    NOMINATED NODE   READINESS GATES
myweb-565cb68445-btlj8   1/1     Running             1 (11h ago)   27h   10.244.2.56    node2   <none>           <none>
myweb-565cb68445-c8drb   1/1     Running             1 (11h ago)   27h   10.244.1.104   node1   <none>           <none>
myweb-565cb68445-lj7bq   1/1     Running             1 (11h ago)   27h   10.244.3.111   node3   <none>           <none>
storage-emptydir         0/2     ContainerCreating   0             9s    <none>         node2   <none>           <none>

# æŸ¥çœ‹Podçš„ç½‘ç»œIP
[root@master1 storage] # kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS      AGE   IP             NODE    NOMINATED NODE   READINESS GATES
myweb-565cb68445-btlj8   1/1     Running   1 (11h ago)   27h   10.244.2.56    node2   <none>           <none>
myweb-565cb68445-c8drb   1/1     Running   1 (11h ago)   27h   10.244.1.104   node1   <none>           <none>
myweb-565cb68445-lj7bq   1/1     Running   1 (11h ago)   27h   10.244.3.111   node3   <none>           <none>
storage-emptydir         2/2     Running   0             14s   10.244.2.59    node2   <none>           <none>

# æµ‹è¯•æ•ˆæœ
[root@master1 storage] #curl 10.244.2.59
Wed Dec 25 12:05:05 UTC 2024
[root@master1 storage] #curl 10.244.2.59
Wed Dec 25 12:05:06 UTC 2024
[root@master1 storage] #curl 10.244.2.59
Wed Dec 25 12:05:07 UTC 2024
[root@master1 storage] #curl 10.244.2.59
Wed Dec 25 12:05:08 UTC 2024
[root@master1 storage] #curl 10.244.2.59
Wed Dec 25 12:05:08 UTC 2024
```









### hostPath

hostPath å¯ä»¥å°†**å®¿ä¸»æœºä¸Šçš„ç›®å½•**æŒ‚è½½åˆ° Pod ä¸­ä½œä¸ºæ•°æ®çš„å­˜å‚¨ç›®å½•



**hostPath ä¸€èˆ¬ç”¨åœ¨å¦‚ä¸‹åœºæ™¯ï¼š**

- å®¹å™¨åº”ç”¨ç¨‹åºä¸­æŸäº›æ–‡ä»¶éœ€è¦æ°¸ä¹…ä¿å­˜

- Podåˆ é™¤ï¼ŒhostPathæ•°æ®å¯¹åº”åœ¨å®¿ä¸»æœºæ–‡ä»¶ä¸å—å½±å“,å³hostPathçš„ç”Ÿå‘½å‘¨æœŸå’ŒPodä¸åŒ,è€Œå’ŒèŠ‚ç‚¹ç›¸åŒ
- **å®¿ä¸»æœºå’Œå®¹å™¨çš„ç›®å½•éƒ½ä¼šè‡ªåŠ¨åˆ›å»º**
- æŸäº›å®¹å™¨åº”ç”¨éœ€è¦ç”¨åˆ°å®¹å™¨çš„è‡ªèº«çš„å†…éƒ¨æ•°æ®ï¼Œå¯å°†å®¿ä¸»æœºçš„/var/lib/[docker|containerd]æŒ‚è½½åˆ° Podä¸­



**hostPath ä½¿ç”¨æ³¨æ„äº‹é¡¹ï¼š**

- ä¸åŒå®¿ä¸»æœºçš„ç›®å½•å’Œæ–‡ä»¶å†…å®¹ä¸ä¸€å®šå®Œå…¨ç›¸åŒï¼Œæ‰€ä»¥Podè¿ç§»å‰åçš„è®¿é—®æ•ˆæœä¸ä¸€æ ·
- ä¸é€‚åˆDeploymentè¿™ç§åˆ†å¸ƒå¼çš„èµ„æºï¼Œæ›´é€‚åˆäºDaemonSet
- å®¿ä¸»æœºçš„ç›®å½•ä¸å±äºç‹¬ç«‹çš„èµ„æºå¯¹è±¡çš„èµ„æºï¼Œæ‰€ä»¥**å¯¹èµ„æºè®¾ç½®çš„èµ„æºé…é¢é™åˆ¶å¯¹hostPathç›®å½•æ— æ•ˆ**



**é…ç½®å±æ€§**

```bash
# é…ç½®å±æ€§
kubectl explain pod.spec.volumes.hostPath
path                         # æŒ‡å®šå“ªä¸ªå®¿ä¸»æœºçš„ç›®å½•æˆ–æ–‡ä»¶è¢«å…±äº«ç»™Podä½¿ç”¨
type                         # æŒ‡å®šè·¯å¾„çš„ç±»å‹ï¼Œä¸€å…±æœ‰7ç§ï¼Œé»˜è®¤çš„ç±»å‹æ˜¯æ²¡æœ‰æŒ‡å®š
     ç©ºå­—ç¬¦ä¸²                 # é»˜è®¤é…ç½®ï¼Œåœ¨å…³è”hostPathå­˜å‚¨å·ä¹‹å‰ä¸è¿›è¡Œä»»ä½•æ£€æŸ¥ï¼Œå¦‚æœå®¿ä¸»æœºæ²¡æœ‰å¯¹åº”çš„ç›®å½•ï¼Œä¼šè‡ªåŠ¨åˆ›å»º
     DirectoryCreate         # å®¿ä¸»æœºä¸Šä¸å­˜åœ¨ï¼Œåˆ›å»ºæ­¤0755æƒé™çš„ç©ºç›®å½•ï¼Œå±ä¸»å±ç»„å‡ä¸ºkubelet
     Directory               # å¿…é¡»å­˜åœ¨ï¼ŒæŒ‚è½½å·²å­˜åœ¨ç›®å½•
     FileOrCreate            # å®¿ä¸»æœºä¸Šä¸å­˜åœ¨æŒ‚è½½æ–‡ä»¶ï¼Œå°±åˆ›å»º0644æƒé™çš„ç©ºæ–‡ä»¶ï¼Œå±ä¸»å±ç»„å‡ä¸ºkubelet
     File                    # å¿…é¡»å­˜åœ¨æ–‡ä»¶
     Socket                  # äº‹å…ˆå¿…é¡»å­˜åœ¨Socketæ–‡ä»¶è·¯å¾„
     CharDevice              # äº‹å…ˆå¿…é¡»å­˜åœ¨çš„å­—ç¬¦è®¾å¤‡æ–‡ä»¶è·¯å¾„
     BlockDevice             # äº‹å…ˆå¿…é¡»å­˜åœ¨çš„å—è®¾å¤‡æ–‡ä»¶è·¯å¾„
     
     
# é…ç½®æ ¼å¼ï¼š
  volumes:
  - name: volume_name
    hostPath:
      path: /path/to/host
      
# ç¤ºä¾‹ï¼š
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
  spec:
    containers:
    - image: registry.k8s.io/test-webserver
      name: test-container
      volumeMounts:
      - mountPath: /test-pod
        name: test-volume
    volumes:
    - name: test-volume
      hostPath:
        path: /data           # å®¿ä¸»æœºä¸Šç›®å½•ä½ç½®
        type: Directory       # æ­¤å­—æ®µä¸ºå¯é€‰
```



èŒƒä¾‹ï¼šä½¿ç”¨ä½ ä¸»æœºçš„æ—¶åŒºé…ç½®

```yaml
[root@master1 storage] # vim storage-hostpath-timezone.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-hostpath-timezone
spec:
  volumes:
  - name: timezone
    hostPath:
      path: /etc/timezone        # æ­¤æ–‡ä»¶æ˜¯å½±å“æ—¶åŒº
      type: File
  - name: localtime              # æ­¤æ–‡ä»¶æŒ‚è½½å¤±è´¥ï¼Œä¸å½±å“æ—¶åŒº
    hostPath:
      path: /etc/localtime
      type: File
  containers:
  - name: c01
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    command: ["sh", "-c", "sleep 3600"]
  - name: c02
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    command: ["sh", "-c", "sleep 3600"]
    volumeMounts:
    - name: timezone
      mountPath: /etc/timezone    # å®¹å™¨æ­¤ä¸ºæ–‡ä»¶æ˜¯æ™®é€šæ–‡ä»¶ï¼Œ æŒ‚è½½èŠ‚ç‚¹ç›®å½•æˆåŠŸ
    - name: localtime
      mountPath: /etc/localtime   # å®¹å™¨æ­¤ä¸ºæ–‡ä»¶æ˜¯è½¯è¿æ¥ï¼Œ æŒ‚è½½èŠ‚ç‚¹ç›®å½•å¤±è´¥

# åº”ç”¨
[root@master1 storage] # kubectl apply -f storage-hostpath-timezone.yaml 
pod/pod-hostpath-timezone created

# æŸ¥çœ‹Pod
[root@master1 storage]#kubectl get pod
NAME                     READY   STATUS    RESTARTS      AGE
pod-hostpath-timezone    2/2     Running   0             3s

# æµ‹è¯•æ•ˆæœ
[root@master1 storage] # kubectl exec pod-hostpath-timezone -c c01 -- date
Wed Dec 25 13:19:40 UTC 2024
[root@master1 storage] # kubectl exec pod-hostpath-timezone -c c02 -- date
Wed Dec 25 21:19:46 CST 2024

[root@master1 storage] # kubectl exec pod-hostpath-timezone -c c01 -- cat /etc/timezone
Etc/UTC
[root@master1 storage] # kubectl exec pod-hostpath-timezone -c c02 -- cat /etc/timezone
Asia/Shanghai
```



**èŒƒä¾‹ï¼šå®ç°NFSæœåŠ¡**

```yaml
[root@master1 storage ]# cat storage-nfs-server.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: nfs-server
  labels:
    app: nfs-server
spec:
  type: ClusterIP
  selector: 
    app: nfs-server
  ports:
    - name: tcp-2049            # æœªæ˜¾ç¤ºæŒ‡å®štartPortï¼Œé»˜è®¤å’Œportä¸€è‡´
      port: 2049
      protocol: TCP
    - name: udp-111
      port: 111
      protocol: UDP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nfs-server
  template:
    metadata:
      name: nfs-server
      labels:
        app: nfs-server
    spec:
      nodeSelector:
        "kubernetes.io/os": linux
        "server": nfs
      containers:
      - name: nfs-server
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nfs-server-alpine:12
        env:
        - name: SHARED_DIRECTORY
          value: "/exports"
        volumeMounts:
        - mountPath: /exports
          name: nfs-vol
        securityContext:
          privileged: true
        ports:                       # å£°æ˜æ€§è¯´æ˜ï¼Œæ— ç›´æ¥åŠŸèƒ½ï¼Œé™¤éServiceé…ç½®äº†targetPortåŒ¹é…è¿™äº›ç«¯å£
        - name: tcp-2049
          containerPort: 2049
          protocol: TCP
        - name: udp-111
          containerPort: 111
          protocol: UDP
      volumes:
      - name: nfs-vol
        hostPath:
          path: /nfs-vol
          type: DirectoryOrCreate
```



### ç½‘ç»œå…±äº«å­˜å‚¨

å’Œä¼ ç»Ÿçš„æ–¹å¼ä¸€æ ·, é€šè¿‡ NFS ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿå¯ä»¥å®ç°Kubernetesæ•°æ®çš„ç½‘ç»œå­˜å‚¨å…±äº«

ä½¿ç”¨NFSæä¾›çš„å…±äº«ç›®å½•å­˜å‚¨æ•°æ®æ—¶ï¼Œéœ€è¦åœ¨ç³»ç»Ÿä¸­éƒ¨ç½²ä¸€ä¸ªNFSç¯å¢ƒï¼Œé€šè¿‡volumeçš„é…ç½®ï¼Œå®ç°pod å†…çš„å®¹å™¨é—´å…±äº«NFSç›®å½•ã€‚



**å±æ€§è§£æ**

```bash
# é…ç½®å±æ€§
kubectl explain pod.spec.volumes.nfs
server                                     #æŒ‡å®šnfsæœåŠ¡å™¨çš„åœ°å€
path                                       #æŒ‡å®šnfsæœåŠ¡å™¨æš´éœ²çš„å…±äº«åœ°å€
readOnly                                   #æ˜¯å¦åªèƒ½è¯»ï¼Œé»˜è®¤false

#é…ç½®æ ¼å¼ï¼š
 volumes:
  - name: <å·åç§°>
   nfs:
     server: nfs_server_address           #æŒ‡å®šNFSæœåŠ¡å™¨åœ°å€
     path: "å…±äº«ç›®å½•"                      #æŒ‡å®šNFSå…±äº«ç›®å½•
     readOnly: false                      #æŒ‡å®šæƒé™

# ç¤ºä¾‹
apiVersion: v1
kind: Pod
metadata:
 name: test-pd
spec:
 containers:
  - image: registry.k8s.io/test-webserver
   name: test-container
   volumeMounts:
    - mountPath: /my-nfs-data
     name: test-volume
 volumes:
  - name: test-volume
   nfs:
     server: my-nfs-server.example.com
     path: /my-nfs-volume
     readonly: true
```



èŒƒä¾‹ï¼šä½¿ç”¨é›†ç¾¤å¤–çš„NFSå­˜å‚¨

```bash
#NFSæœåŠ¡å™¨è½¯ä»¶å®‰è£…,10.0.0.131
[root@nfs ~]#apt update && apt install -y nfs-kernel-server æˆ–è€… nfs-server

#é…ç½®å…±äº«ç›®å½•
[root@nfs ~]#mkdir /nfs-data
[root@nfs ~]#echo '/nfs-data *(rw,all_squash,anonuid=0,anongid=0)' >> /etc/exports

#é‡å¯æœåŠ¡
[root@nfs ~]#exportfs -r
[root@nfs ~]#exportfs -v

# åœ¨æ‰€æœ‰kubernetesçš„workerèŠ‚ç‚¹å……å½“NFSå®¢æˆ·ç«¯ï¼Œéƒ½éœ€è¦å®‰è£…NFSå®¢æˆ·ç«¯è½¯ä»¶
[root@node1 ~]#apt update && apt -y install nfs-common æˆ–è€… nfs-client
[root@node2 ~]#apt update && apt -y install nfs-common æˆ–è€… nfs-client
[root@node3 ~]#apt update && apt -y install nfs-common æˆ–è€… nfs-client

#æµ‹è¯•è®¿é—®
[root@node1 ~]#showmount -e 10.0.0.131
Export list for 10.0.0.101:
/nfs-data *

#ç¼–å†™èµ„æºé…ç½®æ–‡ä»¶
[root@master1 storage]#cat storage-nfs-1.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: storage

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-nfs
  namespace: storage
  labels:
    app: nginx-nfs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-nfs
  template:
    metadata:
      labels:
        app: nginx-nfs
    spec:
      volumes:
      - name: html
        nfs:
          server: nfs.mystical.org
          path: /nfs-data/nginx
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
        name: nginx
        volumeMounts:
        - name: html
          mountPath: /usr/share/nginx/html
          
# æ³¨æ„ï¼šnfsä¸­çš„åŸŸåè§£æï¼Œä½¿ç”¨çš„å¼Nodeä¸Šçš„DNSï¼Œè€Œä¸æ˜¯COREDNSï¼Œæ‰€ä»¥éœ€è¦åœ¨NodeèŠ‚ç‚¹ä¸Šå°†DNSæŒ‡å‘ç§æœ‰DNS
```



### **PVå’ŒPVC**

![image-20241228171426884](../markdown_img/image-20241228171426884.png)

#### PV Persistent Volume å®šä¹‰

å·¥ä½œä¸­çš„å­˜å‚¨èµ„æºä¸€èˆ¬éƒ½æ˜¯ç‹¬ç«‹äºPodçš„ï¼Œå°†ä¹‹ç§°ä¸ºèµ„æºå¯¹è±¡Persistent Volume(PV)ï¼Œæ˜¯ç”±ç®¡ç†å‘˜è®¾ç½®çš„å­˜å‚¨ï¼Œå®ƒæ˜¯kubernetesé›†ç¾¤çš„ä¸€éƒ¨åˆ†ï¼ŒPV æ˜¯ Volume ä¹‹ç±»çš„å·æ’ä»¶ï¼Œ**ä½†å…·æœ‰ç‹¬ç«‹äºä½¿ç”¨ PV çš„ Pod  çš„ç”Ÿå‘½å‘¨æœŸ**



**Persistent Volume è·Ÿ Volumeç±»ä¼¼ï¼ŒåŒºåˆ«å°±æ˜¯ï¼š**

- PV æ˜¯é›†ç¾¤çº§åˆ«çš„èµ„æºï¼Œè´Ÿè´£å°†å­˜å‚¨ç©ºé—´å¼•å…¥åˆ°é›†ç¾¤ä¸­ï¼Œé€šå¸¸ç”±ç®¡ç†å‘˜å®šä¹‰
- PV å°±æ˜¯Kubernetesé›†ç¾¤ä¸­çš„ç½‘ç»œå­˜å‚¨ï¼Œä¸å±äºNamespaceã€Nodeã€Podç­‰èµ„æºï¼Œä½†å¯ä»¥è¢«å®ƒä»¬è®¿é—®
- **PV å±äºKubernetes æ•´ä¸ªé›†ç¾¤,å³å¯ä»¥è¢«æ‰€æœ‰é›†ç¾¤çš„Podè®¿é—®**
- **PVæ˜¯ç‹¬ç«‹çš„ç½‘ç»œå­˜å‚¨èµ„æºå¯¹è±¡ï¼Œæœ‰è‡ªå·±çš„ç”Ÿå‘½å‘¨æœŸ**
- PV æ”¯æŒå¾ˆå¤šç§volumeç±»å‹,PVå¯¹è±¡å¯ä»¥æœ‰å¾ˆå¤šå¸¸è§çš„ç±»å‹ï¼šæœ¬åœ°ç£ç›˜ã€NFSã€åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ...



**PVæŒä¹…å·çš„ç±»å‹**

PVæŒä¹…å·æ˜¯ç”¨æ’ä»¶çš„å½¢å¼æ¥å®ç°çš„ã€‚Kubernetesç›®å‰æ”¯æŒä¸€ä¸‹æ’ä»¶ï¼š

- **cephfs** - CephFS volume
- **csi** - å®¹å™¨å­˜å‚¨æ¥å£ï¼ˆCSIï¼‰
- **fc** - Fibre Channelï¼ˆFCï¼‰å­˜å‚¨
- **hostPath** - HostPathå·ï¼ˆä»…ä¾›å•èŠ‚ç‚¹æµ‹è¯•ä½¿ç”¨ï¼Œä¸é€‚ç”¨äºå¤šèŠ‚ç‚¹é›†ç¾¤ï¼›è¯·å°è¯•ä½¿ç”¨lcoalä½œä¸ºæ›¿ä»£ï¼‰
- **iscsi** = iSCSIï¼ˆSCSI over IPï¼‰å­˜å‚¨
- **local** - èŠ‚ç‚¹ä¸ŠæŒ‚è½½çš„æœ¬åœ°å­˜å‚¨è®¾å¤‡
- **nfs** - ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿï¼ˆNFSï¼‰å­˜å‚¨
- **rbd** - Radoså—è®¾å¤‡ï¼ˆRBDï¼‰å·



#### PVC Persistent Volume Claimå®šä¹‰

Persistent Volume Claim(PVC) æ˜¯ä¸€ä¸ªç½‘ç»œå­˜å‚¨æœåŠ¡çš„**è¯·æ±‚**ã€‚

**PVC å±äºåç§°ç©ºé—´çº§åˆ«çš„èµ„æº**ï¼Œåªèƒ½è¢«åŒä¸€ä¸ªåç§°ç©ºé—´çš„Podå¼•ç”¨

ç”±ç”¨æˆ·å®šä¹‰ï¼Œç”¨äºåœ¨ç©ºé—²çš„PVä¸­ç”³è¯·ä½¿ç”¨ç¬¦åˆè¿‡æ»¤æ¡ä»¶çš„PVä¹‹ä¸€ï¼Œä¸é€‰å®šçš„PVæ˜¯â€œä¸€å¯¹ä¸€â€çš„å…³ç³»

ç”¨æˆ·åœ¨Podä¸Š**é€šè¿‡pvcæ’ä»¶**è¯·æ±‚ç»‘å®šä½¿ç”¨å®šä¹‰å¥½çš„PVCèµ„æº

Podèƒ½å¤Ÿç”³è¯·ç‰¹å®šçš„CPUå’ŒMEMèµ„æºï¼Œä½†æ˜¯Podåªèƒ½é€šè¿‡PVCåˆ°PVä¸Šè¯·æ±‚ä¸€å—ç‹¬ç«‹å¤§å°çš„ç½‘ç»œå­˜å‚¨ç©º é—´ï¼Œè€ŒPVC å¯ä»¥åŠ¨æ€çš„æ ¹æ®ç”¨æˆ·è¯·æ±‚å»ç”³è¯·PVèµ„æºï¼Œä¸ä»…ä»…æ¶‰åŠåˆ°å­˜å‚¨ç©ºé—´ï¼Œè¿˜æœ‰å¯¹åº”èµ„æºçš„è®¿é—®æ¨¡ å¼ï¼Œå¯¹äºçœŸæ­£ä½¿ç”¨å­˜å‚¨çš„ç”¨æˆ·ä¸éœ€è¦å…³å¿ƒåº•å±‚çš„å­˜å‚¨å®ç°ç»†èŠ‚ï¼Œåªéœ€è¦ç›´æ¥ä½¿ç”¨ PVC å³å¯ã€‚



#### Podã€PVã€PVC å…³ç³»

![image-20241228172519330](../markdown_img/image-20241228172519330.png)



**å‰æï¼š**

- å­˜å‚¨ç®¡ç†å‘˜é…ç½®å„ç§ç±»å‹çš„PVå¯¹è±¡
- Podã€PVC å¿…é¡»åœ¨åŒä¸€ä¸ªå‘½åç©ºé—´



**ç”¨æˆ·éœ€è¦å­˜å‚¨èµ„æºçš„æ—¶å€™ï¼š**

- ç”¨æˆ·æ ¹æ®èµ„æºéœ€æ±‚åˆ›å»ºPVCï¼Œç”±PVCè‡ªåŠ¨åŒ¹é…(æƒé™ã€å®¹é‡)åˆé€‚çš„PVå¯¹è±¡
- PVC å…è®¸ç”¨æˆ·æŒ‰éœ€æŒ‡å®šæœŸæœ›çš„å­˜å‚¨ç‰¹æ€§ï¼Œå¹¶ä»¥ä¹‹ä¸ºæ¡ä»¶ï¼ŒæŒ‰ç‰¹å®šçš„æ¡ä»¶é¡ºåºè¿›è¡ŒPVçš„è¿‡æ»¤ 
  - VolumeMode â†’ LabelSelector â†’ StorageClassName â†’ AccessMode â†’ Size 
- åœ¨Podå†…éƒ¨é€šè¿‡ PVC å°† PV ç»‘å®šåˆ°å½“å‰çš„ç©ºé—´ï¼Œè¿›è¡Œä½¿ç”¨
- å¦‚æœç”¨æˆ·ä¸å†ä½¿ç”¨å­˜å‚¨èµ„æºï¼Œè§£ç»‘ PVC å’Œ Pod å³å¯



**PVå’ŒPVCçš„ç”Ÿå‘½å‘¨æœŸ**

![image-20241229204228667](../markdown_img/image-20241229204228667.png)





**PVå’ŒPVCçš„é…ç½®æµç¨‹**

![image-20241229204254515](../markdown_img/image-20241229204254515.png)



- ç”¨æˆ·åˆ›å»ºäº†ä¸€ä¸ªåŒ…å« PVC çš„ Podï¼Œè¯¥ PVC è¦æ±‚ä½¿ç”¨åŠ¨æ€å­˜å‚¨å·
- Scheduler æ ¹æ® Pod é…ç½®ã€èŠ‚ç‚¹çŠ¶æ€ã€PV é…ç½®ç­‰ä¿¡æ¯ï¼ŒæŠŠ Pod è°ƒåº¦åˆ°ä¸€ä¸ªåˆé€‚çš„ Worker èŠ‚ç‚¹ä¸Š
- PV æ§åˆ¶å™¨ watch åˆ°è¯¥ Pod ä½¿ç”¨çš„ PVC å¤„äº Pending çŠ¶æ€ï¼Œäºæ˜¯è°ƒç”¨ Volume Plugin(in-tree)åˆ› å»ºå­˜å‚¨å·ï¼Œå¹¶åˆ›å»º PV å¯¹è±¡(out-of-tree ç”± External Provisioner æ¥å¤„ç†)
- AD æ§åˆ¶å™¨å‘ç° Pod å’Œ PVC å¤„äºå¾…æŒ‚æ¥çŠ¶æ€ï¼Œäºæ˜¯è°ƒç”¨ Volume Plugin æŒ‚æ¥å­˜å‚¨è®¾å¤‡åˆ°ç›®æ ‡ Worker èŠ‚ç‚¹ä¸Š
- åœ¨ Worker èŠ‚ç‚¹ä¸Šï¼ŒKubelet ä¸­çš„ Volume Manager ç­‰å¾…å­˜å‚¨è®¾å¤‡æŒ‚æ¥å®Œæˆï¼Œå¹¶é€šè¿‡ Volume  Plugin å°†è®¾å¤‡æŒ‚è½½åˆ°å…¨å±€ç›®å½•ï¼š**/var/lib/kubelet/pods/[pod_uid]/volumes/kubernetes.io~iscsi/[PVname] (ä»¥iscsiä¸ºä¾‹)**
- Kubelet é€šè¿‡ Docker å¯åŠ¨ Pod çš„ Containersï¼Œç”¨ bind mount æ–¹å¼å°†å·²æŒ‚è½½åˆ°æœ¬åœ°å…¨å±€ç›®å½•çš„å· æ˜ å°„åˆ°å®¹å™¨ä¸­



![image-20241229204525669](../markdown_img/image-20241229204525669.png)





#### PVå’ŒPVCç®¡ç†

**PVçš„Provison ç½®å¤‡ï¼ˆåˆ›å»ºï¼‰æ–¹æ³•**

- **é™æ€**ï¼šé›†ç¾¤ç®¡ç†å‘˜é¢„å…ˆæ‰‹åŠ¨åˆ›å»ºä¸€äº› PVã€‚å®ƒä»¬å¸¦æœ‰å¯ä¾›ç¾¤é›†ç”¨æˆ·ä½¿ç”¨çš„å®é™…å­˜å‚¨çš„ç»†èŠ‚
- **åŠ¨æ€**ï¼šé›†ç¾¤å°è¯•æ ¹æ®ç”¨æˆ·è¯·æ±‚åŠ¨æ€åœ°è‡ªåŠ¨å®Œæˆåˆ›å»ºå·ã€‚æ­¤é…ç½®åŸºäº StorageClassesï¼šPVC å¿…é¡»è¯· æ±‚å­˜å‚¨ç±»ï¼Œå¹¶ä¸”ç®¡ç†å‘˜å¿…é¡»é¢„å…ˆåˆ›å»ºå¹¶é…ç½®è¯¥ StorageClassesæ‰èƒ½è¿›è¡ŒåŠ¨æ€åˆ›å»ºã€‚å£°æ˜è¯¥ç±»ä¸ºç©ºå­— ç¬¦ä¸² ""ï¼Œ å¯ä»¥æœ‰æ•ˆåœ°ç¦ç”¨å…¶åŠ¨æ€é…ç½®ã€‚



##### PVå±æ€§

```bash
# PVä½œä¸ºå­˜å‚¨èµ„æºï¼Œä¸»è¦åŒ…æ‹¬å­˜å‚¨èƒ½åŠ›ï¼Œè®¿é—®æ¨¡å¼ï¼Œå­˜å‚¨ç±»å‹ï¼Œå›æ”¶ç­–ç•¥ç­‰å…³é”®ä¿¡æ¯ï¼Œæ³¨æ„ï¼šPVçš„åç§°ä¸æ”¯æŒå¤§å†™
kubectl explain pv.spec
    capacity                            # å®šä¹‰pvä½¿ç”¨å¤šå°‘èµ„æºï¼Œä»…é™äºç©ºé—´çš„è®¾å®š
    accessModes                         # è®¿é—®æ¨¡å¼,æ”¯æŒå•è·¯è¯»å†™ï¼Œå¤šè·¯è¯»å†™ï¼Œå¤šè·¯åªè¯»ï¼Œå•Podè¯»å†™ï¼Œå¯åŒæ—¶æ”¯æŒå¤šç§æ¨¡å¼
    volumeMode                          # æ–‡ä»¶ç³»ç»Ÿæˆ–å—è®¾å¤‡,é»˜è®¤æ–‡ä»¶ç³»ç»Ÿ
    mountOptions                        # æŒ‚è½½é€‰é¡¹,æ¯”å¦‚:["ro", "soft"]    
    persistentVolumeReclaimPolicy       # èµ„æºå›æ”¶ç­–ç•¥ï¼Œä¸»è¦ä¸‰ç§Retainã€Deleteã€Recycle 
    storageClassName                    # å­˜å‚¨ç±»çš„åç§°,å¦‚æœé…ç½®å¿…é¡»å’ŒPVCçš„storageClassNameç›¸åŒæ‰èƒ½ç»‘å®š
    
#æ³¨æ„:PersistentVolume å¯¹è±¡çš„åç§°å¿…é¡»æ˜¯åˆæ³•çš„ DNS å­åŸŸå

# ç¤ºä¾‹
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv0003
  labels:
    release: "stable"    # ä¾¿ç­¾å¯ä»¥æ”¯æŒåŒ¹é…è¿‡æ»¤PVC
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: slow  # å¿…é¡»å’ŒPVCç›¸åŒ
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /tmp
    server: 172.17.0.2  
```



##### PVCå±æ€§

```bash
#PVCå±æ€§ä¿¡æ¯,ä¸æ‰€æœ‰ç©ºé—´éƒ½èƒ½ä½¿ç”¨çš„PVä¸ä¸€æ ·ï¼ŒPVCæ˜¯å±äºåç§°ç©ºé—´çº§åˆ«çš„èµ„æºå¯¹è±¡ï¼Œå³åªæœ‰ç‰¹å®šçš„èµ„æºæ‰èƒ½ä½¿ç”¨
kubectl explain pvc.spec
    accessModes            # è®¿é—®æ¨¡å¼  
    resources              # èµ„æºé™åˆ¶
    volumeMode             # åç«¯å­˜å‚¨å·çš„æ¨¡å¼,æ–‡ä»¶ç³»ç»Ÿæˆ–å—,é»˜è®¤ä¸ºæ–‡ä»¶ç³»ç»Ÿ
    volumeName             # æŒ‡å®šç»‘å®šçš„å·(pv)çš„åç§°

kubectl explain pod.spec.volumes.persistentVolumeClaim
    claimName              # å®šä¹‰pvcçš„åç§°,PersistentVolumeClaim å¯¹è±¡çš„åç§°å¿…é¡»æ˜¯åˆæ³•çš„ DNS å­åŸŸå
    readOnly               # è®¾å®špvcæ˜¯å¦åªè¯»
    storageClassName       # å­˜å‚¨ç±»çš„åç§°,å¦‚æœé…ç½®å¿…é¡»å’ŒPVçš„storageClassNameç›¸åŒæ‰èƒ½ç»‘å®š
    selector                # æ ‡ç­¾é€‰æ‹©å™¨å®ç°é€‰æ‹©ç»‘å®šPV
    
# storageClassNameç±»
PVCå¯ä»¥é€šè¿‡ä¸ºstorageClassNameå±æ€§è®¾ç½®StorageClassçš„åç§°æ¥è¯·æ±‚ç‰¹å®šçš„å­˜å‚¨ç±»ã€‚åªæœ‰æ‰€è¯·æ±‚çš„ç±»çš„PVçš„StorageClasså€¼ä¸PVCè®¾ç½®ç›¸åŒï¼Œæ‰èƒ½ç»‘å®š

# selectoré€‰æ‹©ç®—ç¬¦
PVCå¯ä»¥è®¾ç½®æ ‡ç­¾é€‰æ‹©ç®—ç¬¦,æ¥è¿›ä¸€æ­¥è¿‡æ»¤å·é›†åˆã€‚åªæœ‰æ ‡ç­¾ä¸é€‰æ‹©ç®—ç¬¦ç›¸åŒ¹é…çš„å·èƒ½å¤Ÿç»‘å®šåˆ°PVCä¸Šã€‚é€‰æ‹©ç®—ç¬¦åŒ…å«ä¸¤ä¸ªå­—æ®µï¼š

matchLabels - å·å¿…é¡»åŒ…å«å¸¦æœ‰æ­¤å€¼çš„æ ‡ç­¾
 
matchExpressions - é€šè¿‡è®¾å®šé”®ï¼ˆkeyï¼‰ã€å€¼åˆ—è¡¨å’Œæ“ä½œç¬¦ï¼ˆoperatorï¼‰ æ¥æ„é€ çš„éœ€æ±‚ã€‚åˆæ³•çš„æ“ä½œç¬¦
æœ‰ Inã€NotInã€Exists å’Œ DoesNotExistã€‚
æ¥è‡ª matchLabels å’Œ matchExpressions çš„æ‰€æœ‰éœ€æ±‚éƒ½æŒ‰é€»è¾‘ä¸çš„æ–¹å¼ç»„åˆåœ¨ä¸€èµ·ã€‚ è¿™äº›éœ€æ±‚éƒ½å¿…é¡»è¢«æ»¡è¶³æ‰è¢«è§†ä¸ºåŒ¹é…ã€‚

# ç¤ºä¾‹ï¼š
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myclaim
spec:
  accessModes:
  - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 8Gi
  storageClassName: slow  # å¿…é¡»å’ŒPVç›¸åŒ
  selectorï¼š
    matchLabels:
      release: "stable"
    matchExpressions:
    - {key: environment, operator: In, values: [dev]}
```





##### å±æ€§è¿›é˜¶

**PVçŠ¶æ€**

PV æœ‰ç”Ÿå‘½å‘¨æœŸ,è‡ªç„¶ä¹Ÿæœ‰è‡ªå·±ç‰¹å®šçš„çŠ¶æ€

æ³¨æ„ï¼šè¿™ä¸ªè¿‡ç¨‹æ˜¯å•å‘è¿‡ç¨‹ï¼Œä¸èƒ½é€†å‘

![image-20241229210212463](../markdown_img/image-20241229210212463.png)

| çŠ¶æ€       | è§£æ                                                  |
| ---------- | ----------------------------------------------------- |
| Availabled | ç©ºé—²çŠ¶æ€ï¼Œè¡¨ç¤ºPVæ²¡æœ‰è¢«å…¶ä»–PVCå¯¹è±¡ä½¿ç”¨                 |
| Bound      | ç»‘å®šçŠ¶æ€ï¼Œè¡¨ç¤ºPVå·²ç»è¢«å…¶ä»–PVCå¯¹è±¡ä½¿ç”¨                 |
| Released   | æœªå›æ”¶çŠ¶æ€ï¼Œè¡¨ç¤ºPVCå·²ç»è¢«åˆ é™¤äº†ï¼Œä½†æ˜¯èµ„æºè¿˜æ²¡æœ‰è¢«å›æ”¶ |
| Faild      | èµ„æºå›æ”¶å¤±è´¥                                          |



![image-20241229210316627](../markdown_img/image-20241229210316627.png)





**AccessMode è®¿é—®æ¨¡å¼**

AccessModes æ˜¯ç”¨æ¥å¯¹ PV è¿›è¡Œè®¿é—®æ¨¡å¼çš„è®¾ç½®ï¼Œç”¨äºæè¿°ç”¨æˆ·åº”ç”¨å¯¹å­˜å‚¨èµ„æºçš„è®¿é—®æƒé™ï¼Œè®¿é—®æƒé™åŒ…æ‹¬

| ç±»å‹                   | è§£æ                                                         |
| ---------------------- | ------------------------------------------------------------ |
| ReadWriteOnceï¼ˆRWOï¼‰   | å•èŠ‚ç‚¹è¯»å†™,å·å¯ä»¥è¢«ä¸€ä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ–¹å¼æŒ‚è½½ã€‚ <br />ReadWriteOnce è®¿é—®æ¨¡å¼ä»ç„¶å¯ä»¥åœ¨åŒä¸€èŠ‚ç‚¹ä¸Šè¿è¡Œçš„å¤šä¸ª Pod <br />è®¿é—®è¯¥å·å³ä¸æ”¯æŒå¹¶è¡Œ(éå¹¶å‘)å†™å…¥ |
| ReadOnlyManyï¼ˆROXï¼‰    | å¤šèŠ‚ç‚¹åªè¯»                                                   |
| ReadWriteManyï¼ˆRWXï¼‰   | å¤šèŠ‚ç‚¹è¯»å†™                                                   |
| ReadWriteOncePod(RWOP) | å·å¯ä»¥è¢«å•ä¸ª Pod ä»¥è¯»å†™æ–¹å¼æŒ‚è½½ã€‚ å¦‚æœä½ æƒ³ç¡®ä¿æ•´ä¸ªé›†ç¾¤ä¸­åª æœ‰ä¸€ä¸ª Pod å¯ä»¥è¯»å–æˆ–å†™å…¥è¯¥ PVCï¼Œ è¯·ä½¿ç”¨ ReadWriteOncePod è®¿é—®æ¨¡å¼ã€‚å•Podè¯»å†™,v1.22ç‰ˆä»¥åæ‰æ”¯ æŒ,v1.29ç‰ˆstableå¯ç”¨ |



æ³¨æ„ï¼š

- ä¸åŒçš„åç«¯å­˜å‚¨æ”¯æŒä¸åŒçš„è®¿é—®æ¨¡å¼ï¼Œæ‰€ä»¥è¦æ ¹æ®åç«¯å­˜å‚¨ç±»å‹æ¥è®¾ç½®è®¿é—®æ¨¡å¼ã€‚
- ä¸€äº› PV å¯èƒ½æ”¯æŒå¤šç§è®¿é—®æ¨¡å¼ï¼Œä½†æ˜¯åœ¨æŒ‚è½½çš„æ—¶å€™åªèƒ½ä½¿ç”¨ä¸€ç§è®¿é—®æ¨¡å¼ï¼Œå¤šç§è®¿é—®æ¨¡å¼æ˜¯ä¸ä¼š ç”Ÿæ•ˆçš„



**PVèµ„æºå›æ”¶ç­–ç•¥**

PV ä¸‰ç§èµ„æºå›æ”¶ç­–ç•¥

å½“ Pod ç»“æŸ volume åå¯ä»¥å›æ”¶èµ„æºå¯¹è±¡åˆ é™¤PVCï¼Œè€Œç»‘å®šå…³ç³»å°±ä¸å­˜åœ¨äº†ï¼Œå½“ç»‘å®šå…³ç³»ä¸å­˜åœ¨åè¿™ä¸ª PVéœ€è¦æ€ä¹ˆå¤„ç†ï¼Œè€ŒPersistentVolume çš„å›æ”¶ç­–ç•¥å‘Šè¯‰é›†ç¾¤åœ¨å­˜å‚¨å·å£°æ˜é‡Šæ”¾ååº”å¦‚ä½•å¤„ç†è¯¥PVå·ã€‚ ç›®å‰ï¼Œvolume çš„å¤„ç†ç­–ç•¥æœ‰ä¿ç•™ã€å›æ”¶æˆ–åˆ é™¤ã€‚

å½“PVCè¢«åˆ é™¤å, Kubernetes ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªrecycler-for-çš„Podå®ç°å›æ”¶å·¥ä½œ,ä½†Retainç­– ç•¥é™¤å¤–

å›æ”¶å®Œæˆå,PVçš„çŠ¶æ€å˜ä¸ºAvailabled,å¦‚æœå…¶å®ƒå¤„äºPendingçŠ¶æ€çš„PVCå’Œæ­¤PVæ¡ä»¶åŒ¹é…,åˆ™å¯ä»¥å†æ¬¡æ­¤ PVè¿›è¡Œç»‘å®š

| ç±»å‹    | è§£æ                                                         |
| ------- | ------------------------------------------------------------ |
| Retain  | ä¿ç•™PVå’Œå­˜å‚¨ç©ºé—´æ•°æ®ï¼Œåç»­æ•°æ®çš„åˆ é™¤éœ€è¦äººå·¥å¹²é¢„ï¼Œ**ä¸€èˆ¬æ¨èä½¿ç”¨æ­¤é¡¹**ï¼Œå¯¹äº**æ‰‹åŠ¨åˆ›å»ºçš„PVæ­¤ä¸ºé»˜è®¤å€¼** |
| Delete  | ç›¸å…³çš„å­˜å‚¨å®ä¾‹PVå’Œæ•°æ®éƒ½ä¸€èµ·åˆ é™¤ã€‚éœ€è¦æ”¯æŒåˆ é™¤åŠŸèƒ½çš„å­˜å‚¨æ‰èƒ½å®ç°ï¼Œ**åŠ¨æ€å­˜å‚¨ ä¸€èˆ¬ä¼šé»˜è®¤é‡‡ç”¨æ­¤æ–¹å¼** |
| Recycle | **å½“å‰æ­¤é¡¹å·²åºŸå¼ƒ**ï¼Œä¿ç•™PVï¼Œä½†æ¸…ç©ºå­˜å‚¨ç©ºé—´çš„æ•°æ®ï¼Œä»…æ”¯æŒNFSå’ŒhostPath |



##### PVå’ŒPVCçš„ä½¿ç”¨æµç¨‹

å®ç°æ–¹æ³•

- å‡†å¤‡å­˜å‚¨
- åŸºäºå­˜å‚¨åˆ›å»ºPV
- æ ¹æ®éœ€æ±‚åˆ›å»ºPVC: PVCä¼šæ ¹æ®capacityå’ŒaccessModesåŠå…¶å®ƒæ¡ä»¶è‡ªåŠ¨æ‰¾åˆ°ç›¸åŒ¹é…çš„PVè¿›è¡Œç»‘å®š, ä¸€ä¸ªPVCå¯¹åº”ä¸€ä¸ªPV
- åˆ›å»ºPod
  - åœ¨Podä¸­çš„ volumes æŒ‡å®šè°ƒç”¨ä¸Šé¢åˆ›å»ºçš„ PVC åç§°
  - åœ¨Podä¸­çš„å®¹å™¨ä¸­çš„volumeMountsæŒ‡å®šPVCæŒ‚è½½å®¹å™¨å†…çš„ç›®å½•è·¯å¾„





##### æ¡ˆä¾‹

**PVå’ŒPVCä½¿ç”¨**

```yaml
[root@master1 storage] # cat storage-mysql-pv-pvc.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mysql-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 20Gi
  accessModes:
  - ReadWriteOnce
  hostPath:
    path: "/mnt/data"

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pv-claim
spec:
  storageClassName: manual
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi

---
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  ports:
  - port: 3306
  selector:
    app: mysql
  clusterIP: None
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
spec:
  selector:
    matchLabels:
      app: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/mysql:8.0.29-oracle
        name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: "123456"
        ports:
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: mysql-persistent-storage
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentVolumeClaim:
          claimName: mysql-pv-claim

# å®‰è£…mysqlå®¢æˆ·ç«¯
[root@master1 storage] #apt install -y mysql-client

# é€šè¿‡svcåŸŸåï¼Œè§£æå‡ºmysqlçš„podçš„IP
[root@master1 storage]#nslookup mysql.default.svc.cluster.local 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10#53

Name:	mysql.default.svc.cluster.local
Address: 10.244.2.73

# æµ‹è¯•è®¿é—®
[root@master1 storage] # mysql -h10.244.2.73 -p123456 -uroot

# æŸ¥çœ‹Mysqlçš„Podæ‰€åœ¨ä¸»æœº
[root@master1 storage] # kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS   AGE     IP            NODE    NOMINATED NODE   READINESS GATES
mysql-7ffdfbdf6f-fsv6c   1/1     Running   0          7m34s   10.244.2.73   node2   <none>           <none>

# æŸ¥çœ‹node2èŠ‚ç‚¹çš„/mnt/dataï¼Œè‡ªåŠ¨åˆ›å»º/mnt/dataç›®å½•
[root@node2 ~] # cd /mnt/data/
[root@node2 data]#ls
 auto.cnf        client-cert.pem      ib_logfile0     mysql.sock           sys
 binlog.000001   client-key.pem       ib_logfile1     performance_schema   undo_001
 binlog.000002  '#ib_16384_0.dblwr'   ibtmp1          private_key.pem      undo_002
 binlog.index   '#ib_16384_1.dblwr'  '#innodb_temp'   public_key.pem
 ca-key.pem      ib_buffer_pool       mysql           server-cert.pem
 ca.pem          ibdata1              mysql.ibd       server-key.pem
```



èŒƒä¾‹ï¼šä»¥NFSç±»å‹åˆ›å»ºä¸€ä¸ª3Gå¤§å°çš„å­˜å‚¨èµ„æºå¯¹è±¡PV

```yaml
# å‡†å¤‡NFSå…±äº«å­˜å‚¨
[root@master1 ~] #mkdir /nfs-data
[root@master1 ~] #apt -y install nfs-server
[root@master1 ~] #echo "/nfs-data *(rw,no_root_squash)" >> /etc/exports
[root@master1 ~] #exportfs -r
[root@master1 ~] #exportfs -v
/nfs-data     <world>
(rw,wdelay,no_root_squash,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_a
ll_squash)

#åœ¨æ‰€æœ‰workerèŠ‚ç‚¹å®‰è£…nfsè½¯ä»¶
[root@node1 ~] #apt -y install nfs-common

# å‡†å¤‡PVï¼Œå®šåˆ¶ä¸€ä¸ªå…·ä½“ç©ºé—´å¤§å°çš„å­˜å‚¨å¯¹è±¡
[root@master1 ~] #cat storage-pv.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-test
spec:
  capacity:
    storage: 3Gi
  accessModes:
    - ReadWriteOnce
    - ReadWriteMany
    - ReadOnlyMany
  nfs:
    path: /nfs-data
    server: nfs.mystical.org # éœ€è¦åç§°è§£æ

# åº”ç”¨
[root@master1 ~] #kubectl apply -f storage-pv.yaml
persistentvolume/pv-test created

# æŸ¥çœ‹
[root@master1 ~] #kubectl get pv
NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM   
STORAGECLASS   REASON   AGE
pv-test   3Gi       RWO,ROX,RWX   Retain           Available                   
                7s
# ç»“æœæ˜¾ç¤ºï¼šè™½ç„¶æˆ‘ä»¬åœ¨åˆ›å»ºpvçš„æ—¶å€™æ²¡æœ‰æŒ‡å®šå›æ”¶ç­–ç•¥ï¼Œè€Œå…¶ç­–ç•¥è‡ªåŠ¨å¸®æˆ‘ä»¬é…ç½®äº†Retain

# å‡†å¤‡PVCï¼Œå®šä¹‰ä¸€ä¸ªèµ„æºå¯¹è±¡ï¼Œè¯·æ±‚ç©ºé—´1Gi
[root@master1 ~] #cat storage-pvc.yaml 
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-test
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
#æ³¨æ„ï¼šè¯·æ±‚çš„èµ„æºå¤§å°å¿…é¡»åœ¨ pvèµ„æºçš„èŒƒå›´å†…

[root@master1 ~] #kubectl apply -f storage-pvc.yaml

#ç»“æœæ˜¾ç¤ºï¼šä¸€æ—¦å¯åŠ¨pvcä¼šè‡ªåŠ¨å»æœå¯»åˆé€‚çš„å¯ç”¨çš„pvï¼Œç„¶åç»‘å®šåœ¨ä¸€èµ·
#å¦‚æœpvcæ‰¾ä¸åˆ°å¯¹åº”çš„pvèµ„æºï¼ŒçŠ¶æ€ä¼šä¸€ç›´å¤„äºpending

# å‡†å¤‡Pod
[root@master1 ~] #cat storage-nginx-pvc.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: Pod-nginx
spec:
  volumes:
  - name: volume-nginx
    persistentVolumeClaim:
      claimName: pvc-test
  containers:
  - name: pvc-nginx-container
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    volumeMounts:
    - name: volume-nginx
      mountPath: "/usr/share/nginx/html"
      
#å±æ€§è§£æï¼š
#spec.volumes æ˜¯é’ˆå¯¹podèµ„æºç”³è¯·çš„å­˜å‚¨èµ„æºæ¥è¯´çš„ï¼Œè¿™é‡Œä½¿ç”¨çš„ä¸»è¦æ˜¯pvcçš„æ–¹å¼ã€‚
#spec.containers.volumeMounts æ˜¯é’ˆå¯¹podèµ„æºå¯¹ç”³è¯·çš„å­˜å‚¨èµ„æºçš„ä¿¡æ¯ã€‚å°†pvcæŒ‚è½½çš„å®¹å™¨ç›®å½• 
```



**æ¡ˆä¾‹ï¼š PVCè‡ªåŠ¨ç»‘å®šç›¸åŒ¹é…çš„PV,PVCå’Œ PV æ˜¯è‡ªåŠ¨å…³è”çš„ï¼Œè€Œä¸”ä¼šåŒ¹é…å®¹é‡å’Œæƒé™**

```yaml
[root@master1 ~] # mkdir /nfs-data/data{1..3}
[root@master1 ~] # cat /etc/exports
/nfs-data *(rw,no_root_squash)

# PVæ¸…å•æ–‡ä»¶
[root@master1 ~] # cat storage-multi-pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs-1
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeclaimPolicy: Retain
  nfs:
    path: "/nfs-data/data1"
    server: nfs.mystical.org
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs-2
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
  - ReadOnlyMany
  persistentVolumeReclaimPolicy: Retain
  nfs:
    path: "/nfs-data/data2"
    server: nfs.mystical.org
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs-3
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  nfs:
    path: "/nfs-data/data3"
    server: nfs.mystical.org

# åº”ç”¨
[root@master1 ~] # kubectl apply -f storage-multi-pv.yaml

# kubectl get pv
[root@master1 storage] # kubectl get pv
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-nfs-1   5Gi        RWX            Retain           Available                          <unset>                          3s
pv-nfs-2   5Gi        ROX            Retain           Available                          <unset>                          2m13s
pv-nfs-3   1Gi        RWO            Retain           Available                          <unset>                          2m13s


# PVCæ¸…å•æ–‡ä»¶
[root@master1 ~] # cat storage-multi-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-demo-1
  namespace: default
spec:
  accessModes: ["ReadWriteMany"]
  volumeMode: Filesystem
  resources:
    requests:
      storage: 3Gi
    limits:
      storage: 10Gi
      
# åº”ç”¨
[root@master1 storage] # kubectl apply -f storage-multi-pvc.yaml 
persistentvolumeclaim/pvc-demo-1 created

# æŸ¥çœ‹PVC
[root@master1 storage] # kubectl get pvc
NAME         STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
pvc-demo-1   Bound    pv-nfs-1   5Gi        RWX                           <unset>                 14s

# è‡ªåŠ¨ç»‘å®šPVCè‡³å®¹å™¨å’Œæƒé™éƒ½åŒ¹é…çš„PV
[root@master1 storage]#kubectl get pv
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-nfs-1   5Gi        RWX            Retain           Bound       default/pvc-demo-1                  <unset>                          3m7s
pv-nfs-2   5Gi        ROX            Retain           Available                                       <unset>                          5m17s
pv-nfs-3   1Gi        RWO            Retain           Available                                       <unset>                          5m17s
```



##### å¼ºåˆ¶åˆ é™¤

ç”Ÿäº§ä¸­ï¼Œå¯¹äºå­˜å‚¨èµ„æºçš„é‡Šæ”¾ï¼Œæœ€å¥½æŒ‰ç…§æµç¨‹æ¥ï¼Œå³å…ˆæ¸…ç©ºåº”ç”¨ï¼Œç„¶ååœ¨æ¸…ç©ºpvcï¼Œä½†æ˜¯ç”Ÿäº§ä¸­ï¼Œç»å¸¸é‡ åˆ°åº”ç”¨èµ„æºæ„å¤–ç»ˆæ­¢æˆ–è€…å…¶ä»–æƒ…å†µï¼Œå¯¼è‡´æˆ‘ä»¬çš„pvcèµ„æºæ²¡æœ‰ä½¿ç”¨ï¼Œè€Œä¸”ä¹Ÿæ²¡æœ‰æ¸…ç©º

æœ‰å¤šç§æ–¹å¼è§£å†³ï¼Œæœ€å¸¸ç”¨çš„ä¸€ç§æ–¹å¼å°±æ˜¯ï¼Œåœ¨æ‰€æœ‰çš„åº”ç”¨podä¸­å¢åŠ ä¸€ä¸ªprestopçš„é’©å­å‡½æ•°ï¼Œä»è€Œè®©æˆ‘ä»¬çš„åº”ç”¨èµ„æºåˆç†çš„æ¸…ç©º

**è€Œå¯¹äºç‰¹æ®Šçš„å¼‚å¸¸æƒ…å†µï¼Œæˆ‘ä»¬è¿˜æœ‰å¦å¤–ä¸€ç§ç­–ç•¥ï¼Œå³å¼ºåˆ¶æ¸…ç©º,ä½†æ˜¯ä¸€èˆ¬ä¸æ¨èä½¿ç”¨ã€‚**

```yaml
#å¯¹äºè¿™ç§æ— è®ºä½•ç§æ–¹æ³•éƒ½æ— æ³•åˆ é™¤çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¿®æ”¹é…ç½®å±æ€§çš„æ–¹å¼ï¼Œä»è®°å½•ä¸­åˆ é™¤è¯¥ä¿¡æ¯
[root@master1 ~]#kubectl patch pv pv-nfs-1 -p '{"metadata":{"finalizers":null}}'
persistentvolume/pv-nfs-1 patched
```



##### subPath

ä¸Šé¢èŒƒä¾‹ä¸­çš„nginxé¦–é¡µå­˜æ”¾åœ¨/nfs-dataçš„ä¸€çº§ç›®å½•ä¸­ï¼Œä½†æ˜¯ç”Ÿäº§ä¸­ï¼Œä¸€ä¸ªNFSå…±äº«èµ„æºé€šå¸¸æ˜¯ç»™å¤šä¸ªåº” ç”¨æ¥ä½¿ç”¨çš„ï¼Œæ¯”å¦‚éœ€è¦å®šåˆ¶æ¯ä¸ªappçš„åˆ†é…å•ç‹¬çš„å­ç›®å½•å­˜æ”¾é¦–é¡µèµ„æºï¼Œä½†æ˜¯å¦‚æœæˆ‘ä»¬é‡‡ç”¨PVå®ç°å®šåˆ¶ çš„æ–¹å¼ï¼Œå°±éœ€è¦å¤šä¸ªPV,æ­¤æ–¹å¼æœ‰äº›å¤ªç¹çäº† 

**å¯ä»¥é€šè¿‡subPathå®ç°é’ˆå¯¹ä¸åŒçš„åº”ç”¨å¯¹åº”å­ç›®å½•çš„æŒ‚è½½**

volumeMounts.subPath å±æ€§å¯ç”¨äºæŒ‡å®šæ‰€å¼•ç”¨çš„å·å†…çš„å­è·¯å¾„ï¼Œè€Œä¸æ˜¯å…¶æ ¹è·¯å¾„ã€‚

ä¸‹é¢ä¾‹å­å±•ç¤ºäº†å¦‚ä½•é…ç½®æŸåŒ…å« LAMP å †æ ˆï¼ˆLinux Apache MySQL PHPï¼‰çš„ Pod ä½¿ç”¨åŒä¸€å…±äº«å·ã€‚ **æ­¤ç¤ºä¾‹ä¸­çš„ subPath é…ç½®ä¸å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨**ã€‚ PHP åº”ç”¨çš„ä»£ç å’Œç›¸å…³æ•°æ®æ˜ å°„åˆ°å·çš„ html æ–‡ ä»¶å¤¹ï¼ŒMySQL æ•°æ®åº“å­˜å‚¨åœ¨å·çš„ mysql æ–‡ä»¶å¤¹ä¸­ï¼š

```yaml
[root@master1 storage] # cat storage-nginx-pvc-subdir.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-nginx-1
spec:
  volume:
  - name: nginx-volume
    persistentVolumeClaim:
      claimName: pvc-test
  containers:
  - name: nginx-pv
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    volumeMounts:
    - name: nginx-volume
      mountPath: "/usr/share/nginx/html"
      subPath: web1
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-nginx-2
spec:
  volumes:
  - name: nginx-volume
    persistentVolumeClaim:
      claimName: pvc-test
  containers:
  - name: nginx-flask
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    volumeMounts:
    - name: nginx-volume
      mountPath: "/usr/share/nginx/html"
      subPath: web2
```



##### subPath äººè¯ç‰ˆ

**`subPath` æ˜¯ä»€ä¹ˆï¼Ÿ**

åœ¨ Kubernetes çš„ `volumeMounts` ä¸­ï¼Œ`subPath` è¡¨ç¤ºï¼š

**åªæŒ‚è½½æŒ‡å®š Volume çš„å­ç›®å½•** åˆ°å®¹å™¨ä¸­ï¼Œè€Œä¸æ˜¯æ•´ä¸ª Volumeã€‚

**ç¤ºä¾‹è§£æ**

```yaml
volumeMounts:
  - name: data
    mountPath: /var/lib/mysql
    subPath: mysql
```

è¿™æ®µçš„å«ä¹‰æ˜¯ï¼š

- å°† `data` è¿™ä¸ª Volume ä¸­çš„ **`mysql/` å­ç›®å½•**ï¼ŒæŒ‚è½½åˆ°å®¹å™¨å†…çš„ `/var/lib/mysql` è·¯å¾„ã€‚
- å®¹å™¨å†…éƒ¨çœ‹åˆ°çš„æ˜¯ `/var/lib/mysql`ï¼Œä½†å®é™…ä¸Šåªè®¿é—® Volume ä¸­çš„ `mysql` è¿™ä¸ªå­ç›®å½•ã€‚
- å¦‚æœ `data` Volume æŒä¹…åŒ–çš„æ˜¯ `/mnt/data/`ï¼Œé‚£ä¹ˆå®¹å™¨ä¸­ `/var/lib/mysql` å®é™…å¯¹åº”çš„å°±æ˜¯ `/mnt/data/mysql`ã€‚



**ä½¿ç”¨åœºæ™¯ä¸¾ä¾‹**

**âœ…å¤šä¸ªå®¹å™¨æˆ–è·¯å¾„å…±äº«ä¸€ä¸ª Volumeï¼Œä½†éœ€è¦ä¸åŒå­ç›®å½•ï¼š**

```yaml
volumeMounts:
- name: shared-data
  mountPath: /var/log/nginx
  subPath: nginx-logs

- name: shared-data
  mountPath: /var/log/mysql
  subPath: mysql-logs
```

- ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œ`nginx` å’Œ `mysql` è®¿é—®çš„æ˜¯åŒä¸€ä¸ª PVCï¼Œä½†åˆ†å±ä¸åŒå­ç›®å½•ï¼Œäº’ä¸å¹²æ‰°ã€‚

**âœ…é…åˆ `emptyDir` åˆ›å»ºå¤šä¸ªæŒ‚è½½ç‚¹ï¼š**

```yaml
volumes:
- name: data
  emptyDir: {}
```

ç„¶åç”¨ä¸åŒå®¹å™¨æŒ‚ä¸åŒçš„å­ç›®å½•ï¼š

```yaml
containers:
- name: web
  volumeMounts:
  - name: data
    mountPath: /app/cache
    subPath: web-cache
- name: worker
  volumeMounts:
  - name: data
    mountPath: /worker/cache
    subPath: worker-cache
```

âš ï¸ **æ³¨æ„äº‹é¡¹**

- **`subPath` æ˜¯å•ç‹¬ç›®å½•**ï¼Œæ— æ³•åœ¨å®¹å™¨å†…åŠ¨æ€åˆ›å»ºå¤šçº§ç›®å½•ï¼ˆæ¯”å¦‚ `a/b/c` è¿™æ ·ä¸è¡Œï¼Œé™¤é `a/b` å·²å­˜åœ¨ï¼‰ã€‚
- å¦‚æœä½¿ç”¨ `subPath` å†™å…¥æ•°æ®åï¼Œåˆ é™¤ PVCï¼Œå¹¶é‡æ–°ä½¿ç”¨è¿™ä¸ª PVCï¼Œ**å­ç›®å½•æ•°æ®ä»ä¼šä¿ç•™**ã€‚
- `subPath` ä¸é€‚åˆæŒ‚è½½åªè¯» ConfigMap æˆ– Secretï¼Œè¿™ç±»æŒ‚è½½æ¨èç”¨ `subPathExpr` æˆ– `items` ç²¾ç¡®è·¯å¾„ã€‚





### StorageClass

#### storageClassè¯´æ˜

å¯¹äº PV å’Œ PVC çš„ä½¿ç”¨æ•´ä¸ªè¿‡ç¨‹æ˜¯æ¯”è¾ƒç¹ççš„ï¼Œä¸ä»…éœ€è¦è‡ªå·±å®šä¹‰PVå’ŒPVCè¿˜éœ€è¦å°†å…¶ä¸Podè¿›è¡Œå…³ è”ï¼Œè€Œä¸”å¯¹äºPVå’ŒPVCçš„é€‚é…æˆ‘ä»¬ä¹Ÿè¦åšå¥½å‰æè§„åˆ’ï¼Œè€Œç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™ç§ç¹ççš„äº‹æƒ…æ˜¯æœ‰æ‚–äºæˆ‘ä»¬ä½¿ ç”¨kubernetesçš„åŸåˆ™çš„ï¼Œè€Œä¸”è¿™ç§æ–¹å¼åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¹¶ä¸èƒ½æ»¡è¶³æˆ‘ä»¬çš„éœ€æ±‚ï¼Œè€Œä¸”ä¸åŒçš„åº”ç”¨ç¨‹åºå¯¹äº å­˜å‚¨æ€§èƒ½çš„è¦æ±‚å¯èƒ½ä¹Ÿä¸å°½ç›¸åŒï¼Œæ¯”å¦‚è¯»å†™é€Ÿåº¦ã€å¹¶å‘æ€§èƒ½ç­‰ï¼Œæ¯”å¦‚æˆ‘ä»¬æœ‰ä¸€ä¸ªåº”ç”¨éœ€è¦å¯¹å­˜å‚¨çš„å¹¶å‘ åº¦è¦æ±‚æ¯”è¾ƒé«˜ï¼Œè€Œå¦å¤–ä¸€ä¸ªåº”ç”¨å¯¹è¯»å†™é€Ÿåº¦åˆè¦æ±‚æ¯”è¾ƒé«˜ï¼Œç‰¹åˆ«æ˜¯å¯¹äº StatefulSet ç±»å‹çš„åº”ç”¨ç®€å•çš„æ¥ ä½¿ç”¨é™æ€çš„ PV å°±å¾ˆä¸åˆé€‚äº†ï¼Œè¿™ç§æƒ…å†µä¸‹å°±éœ€è¦ç”¨åˆ°**åŠ¨æ€ PV**ã€‚



Kubernetes å¼•å…¥äº†ä¸€ä¸ª**æ–°çš„èµ„æºå¯¹è±¡ï¼šStorageClass**ï¼Œé€šè¿‡ StorageClass çš„å®šä¹‰ï¼Œç®¡ç†å‘˜å¯ä»¥å°†å­˜å‚¨èµ„æºå®šä¹‰ä¸ºæŸç§ç±»å‹çš„èµ„æºï¼Œæ¯”å¦‚å­˜å‚¨è´¨é‡ã€å¿«é€Ÿå­˜å‚¨ã€æ…¢é€Ÿå­˜å‚¨ç­‰ï¼Œä¸ºäº†æ»¡è¶³ä¸åŒç”¨æˆ·çš„å¤šç§å¤šæ ·çš„ éœ€æ±‚ï¼Œç”¨æˆ·æ ¹æ® StorageClass çš„æè¿°å°±å¯ä»¥éå¸¸ç›´è§‚çš„çŸ¥é“å„ç§å­˜å‚¨èµ„æºçš„å…·ä½“ç‰¹æ€§äº†ï¼Œè¿™æ ·å°±å¯ä»¥æ ¹æ®åº”ç”¨çš„ç‰¹æ€§å»ç”³è¯·åˆé€‚çš„å­˜å‚¨èµ„æºäº†ã€‚

æ‰€ä»¥,StorageClassæä¾›äº†ä¸€ç§èµ„æºä½¿ç”¨çš„æè¿°æ–¹å¼ï¼Œä½¿å¾—ç®¡ç†å‘˜èƒ½å¤Ÿæè¿°æä¾›çš„å­˜å‚¨çš„æœåŠ¡è´¨é‡å’Œç­‰çº§ï¼Œè¿›è€Œåšå‡ºä¸åŒçº§åˆ«çš„å­˜å‚¨æœåŠ¡å’Œåç«¯ç­–ç•¥ã€‚

StorageClass ç”¨äºå®šä¹‰ä¸åŒçš„å­˜å‚¨é…ç½®å’Œå±æ€§ï¼Œä»¥ä¾› PersistentVolumeï¼ˆPVï¼‰çš„åŠ¨æ€åˆ›å»ºå’Œç®¡ç†ã€‚å®ƒ ä¸ºå¼€å‘äººå‘˜å’Œç®¡ç†å‘˜æä¾›äº†ä¸€ç§åœ¨ä¸åŒçš„å­˜å‚¨æä¾›å•†ä¹‹é—´æŠ½è±¡å‡ºå­˜å‚¨é…ç½®çš„æ–¹å¼ã€‚

**åœ¨ Kubernetes ä¸­ï¼ŒStorageClass æ˜¯é›†ç¾¤çº§åˆ«çš„èµ„æºï¼Œè€Œä¸æ˜¯åç§°ç©ºé—´çº§åˆ«ã€‚**

PVCå’ŒPVå¯ä»¥å±äºæŸä¸ªSCï¼Œä¹Ÿå¯ä»¥ä¸å±äºä»»ä½•SC,PVCåªèƒ½å¤Ÿåœ¨åŒä¸€ä¸ªstorageClassä¸­è¿‡æ»¤PV



**èƒ½å»ºç«‹ç»‘å®šå…³ç³»çš„PVCå’ŒPVä¸€å®šæ»¡è¶³å¦‚ä¸‹æ¡ä»¶ï¼š**

- äºŒè€…éš¶å±äºåŒä¸ªSC
- äºŒè€…éƒ½ä¸å±äºä»»ä½•SC



**StorageClassè¿™ä¸ªAPIå¯¹è±¡å¯ä»¥è‡ªåŠ¨åˆ›å»ºPVçš„æœºåˆ¶,å³:Dynamic Provisioning**



**StorageClasså¯¹è±¡ä¼šå®šä¹‰ä¸‹é¢ä¸¤éƒ¨åˆ†å†…å®¹:**

- PVçš„å±æ€§.æ¯”å¦‚,å­˜å‚¨ç±»å‹,Volumeçš„å¤§å°ç­‰
- åˆ›å»ºè¿™ç§PVéœ€è¦ç”¨åˆ°çš„å­˜å‚¨æ’ä»¶

æä¾›ä»¥ä¸Šä¸¤ä¸ªä¿¡æ¯,Kuberneteså°±èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æäº¤çš„PVC,æ‰¾åˆ°ä¸€ä¸ªå¯¹åº”çš„StorageClass,ä¹‹å Kuberneteså°±ä¼šè°ƒç”¨è¯¥StorageClasså£°æ˜çš„å­˜å‚¨æ’ä»¶,è¿›è€Œåˆ›å»ºå‡ºéœ€è¦çš„PV.



è¦ä½¿ç”¨ StorageClassï¼Œå°±å¾—**å®‰è£…å¯¹åº”çš„è‡ªåŠ¨é…ç½®ç¨‹åº**ï¼Œæ¯”å¦‚å­˜å‚¨åç«¯ä½¿ç”¨çš„æ˜¯ nfsï¼Œé‚£ä¹ˆå°±éœ€è¦ä½¿ç”¨åˆ° ä¸€ä¸ª nfs-client çš„è‡ªåŠ¨é…ç½®ç¨‹åºï¼Œä¹Ÿç§°ä¸º Provisionerï¼Œè¿™ä¸ªç¨‹åºä½¿ç”¨å·²ç»é…ç½®å¥½çš„ nfs æœåŠ¡å™¨ï¼Œæ¥è‡ªåŠ¨ åˆ›å»ºæŒä¹…å· PVã€‚



#### storageClass API

æ¯ä¸ª StorageClass éƒ½åŒ…å« **provisioner** ã€ **parameters** å’Œ **reclaimPolicy** å­—æ®µï¼Œ è¿™äº›å­—æ®µä¼šåœ¨ StorageClass éœ€è¦åŠ¨æ€åˆ¶å¤‡ PersistentVolume æ—¶ä¼šä½¿ç”¨åˆ°ã€‚

StorageClass å¯¹è±¡çš„å‘½åå¾ˆé‡è¦ï¼Œç”¨æˆ·ä½¿ç”¨è¿™ä¸ªå‘½åæ¥è¯·æ±‚ç”Ÿæˆä¸€ä¸ªç‰¹å®šçš„ç±»ã€‚ å½“åˆ›å»º StorageClass  å¯¹è±¡æ—¶ï¼Œç®¡ç†å‘˜è®¾ç½® StorageClass å¯¹è±¡çš„å‘½åå’Œå…¶ä»–å‚æ•°ã€‚

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
reclaimPolicy: Retain
# å…è®¸ PVC è¿›è¡Œåœ¨çº¿æ‰©å®¹ï¼Œå³åœ¨ä¸åˆ é™¤ PVC çš„æƒ…å†µä¸‹ï¼Œè°ƒæ•´å­˜å‚¨å¤§å°
# é€‚ç”¨äºæ”¯æŒåœ¨çº¿æ‰©å®¹çš„å­˜å‚¨æä¾›ç¨‹åºï¼Œå¦‚ AWS EBSã€GCE Persistent Diskã€Ceph RBD ç­‰ã€‚
# ä»…é€‚ç”¨äº æ”¯æŒåŠ¨æ€å­˜å‚¨æ‰©å®¹çš„å­˜å‚¨æä¾›å•†ã€‚
# æŸäº›å­˜å‚¨ï¼ˆå¦‚æœ¬åœ°å­˜å‚¨ï¼‰ä¸æ”¯æŒæ‰©å±•ï¼Œå³ä½¿è®¾ç½® allowVolumeExpansion: true ä¹Ÿæ— æ•ˆã€‚
# æ‰©å®¹åï¼ŒPod å¯èƒ½éœ€è¦é‡æ–°æŒ‚è½½ PVC æ‰èƒ½ç”Ÿæ•ˆã€‚
allowVolumeExpansion: true
mountOptions:
- discard   # discard é€‰é¡¹ç”¨äº TRIM æ“ä½œï¼Œé€‚ç”¨äºæ”¯æŒ SSD ç¡¬ç›˜ çš„å­˜å‚¨ç³»ç»Ÿã€‚
            # å½“ Kubernetes é‡Šæ”¾å—å­˜å‚¨ä¸Šçš„ç©ºé—´æ—¶ï¼Œdiscard å…è®¸æ“ä½œç³»ç»Ÿé€šçŸ¥å­˜å‚¨è®¾å¤‡ï¼Œé‡Šæ”¾å·²åˆ é™¤çš„æ•°æ®å—ï¼Œä»è€Œæé«˜å­˜å‚¨æ•ˆç‡å’Œ               æ€§èƒ½ã€‚
            # âœ… é€‚ç”¨äº SSD å­˜å‚¨ï¼ˆå¦‚ AWS EBS gp3ã€GCE PD SSDã€Ceph RBDï¼‰
            # âŒ ä¸é€‚ç”¨äºæœºæ¢°ç¡¬ç›˜ï¼ˆHDDï¼‰ï¼ŒHDD ä¸æ”¯æŒ TRIMã€‚
volumeBindingMode: Immediate | WaitForFirstConsumerï¼ˆå»¶è¿Ÿç»‘å®šï¼Œåªæœ‰Podå‡†å¤‡å¥½æ‰ç»‘å®šï¼‰
# å¦‚æœä½¿ç”¨ SSD å­˜å‚¨ï¼Œå»ºè®® discard é€‰é¡¹ã€‚
# å¦‚æœéœ€è¦ä¿è¯å­˜å‚¨æ€§èƒ½ï¼Œä½¿ç”¨ guaranteedReadWriteLatency: "true"ã€‚



# ç®¡ç†å‘˜å¯ä»¥ä¸ºæ²¡æœ‰ç”³è¯·ç»‘å®šåˆ°ç‰¹å®šStorageClassçš„PVCæŒ‡å®šä¸€ä¸ªé»˜è®¤çš„å­˜å‚¨ç±»
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myclaim
spec:
  accessModes:
  - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 8Gi
  storageClassName: standard
  selector:
    matchLabels:
      release: "stable"
    matchExpressions:
      - {key: environment, operator: In, values: [dev]}
```



##### è¡¥å……ï¼šKubernetes **Persistent Volume (PV) ç»‘å®šæ¨¡å¼ (`volumeBindingMode`)** 

**volumeBindingMode: Immediate**

**å·¥ä½œæœºåˆ¶**

- **PV å’Œ PVC ä¼šç«‹å³ç»‘å®š**ï¼Œæ— è®º Pod æ˜¯å¦å·²åˆ›å»ºã€‚
- **PVC ç»‘å®šåï¼ŒPV å¯èƒ½ä¼šè¢«è°ƒåº¦åˆ°ä¸ Pod è¿è¡Œçš„èŠ‚ç‚¹ä¸åŒ¹é…çš„å­˜å‚¨ä¸Š**ã€‚
- é€‚ç”¨äº **å…±äº«å­˜å‚¨ï¼ˆNetworked Storageï¼‰ï¼Œå¦‚ NFSã€Cephã€EBSï¼ˆéæœ¬åœ°å­˜å‚¨ï¼‰**ï¼Œå› ä¸ºè¿™äº›å­˜å‚¨ä¸ä¾èµ–ç‰¹å®šèŠ‚ç‚¹ã€‚

**ä½¿ç”¨åœºæ™¯**

âœ… **ç½‘ç»œå­˜å‚¨ (NFS, Ceph, AWS EBS, GCE Persistent Disk)**

- è¿™äº›å­˜å‚¨å¯ä»¥è·¨å¤šä¸ªèŠ‚ç‚¹è®¿é—®ï¼Œå› æ­¤ PVC ç«‹å³ç»‘å®šåï¼Œä¸ä¼šå½±å“ Pod çš„è°ƒåº¦ã€‚

âŒ **æœ¬åœ°å­˜å‚¨ (HostPath, Local SSD, Node-specific Storage)**

- ç”±äº PVC å¯èƒ½ç»‘å®šåˆ°ä¸åˆé€‚çš„ PVï¼Œå¯¼è‡´ Pod æ— æ³•æ­£ç¡®è°ƒåº¦ã€‚



**volumeBindingMode: WaitForFirstConsumer**

**å·¥ä½œæœºåˆ¶**

- **PVC ä¸ä¼šç«‹å³ç»‘å®š PVï¼Œç›´åˆ° Pod è¢«è°ƒåº¦åˆ°æŸä¸ªèŠ‚ç‚¹ã€‚**
- **å­˜å‚¨è°ƒåº¦ä¼šåœ¨ Pod ç»‘å®šèŠ‚ç‚¹åè¿›è¡Œ**ï¼Œç¡®ä¿å­˜å‚¨å’Œè®¡ç®—èŠ‚ç‚¹åŒ¹é…ã€‚
- é€‚ç”¨äº **æœ¬åœ°å­˜å‚¨ï¼ˆLocal Storage, SSD, Node-specific Storage, EBS GP3/IO2ç­‰ï¼‰**ã€‚

**ä½¿ç”¨åœºæ™¯**

âœ… **æœ¬åœ°å­˜å‚¨ (Local SSD, Local Persistent Volumes)**

- åªæœ‰åœ¨ Pod ç¡®å®šè¿è¡Œåœ¨å“ªä¸ªèŠ‚ç‚¹åï¼ŒPVC æ‰ç»‘å®šåˆ°è¯¥èŠ‚ç‚¹çš„ PVï¼Œé˜²æ­¢å­˜å‚¨å’Œè®¡ç®—ä¸åŒ¹é…çš„é—®é¢˜ã€‚

âœ… **Kubernetes èµ„æºè°ƒåº¦ä¼˜åŒ–**

- å…è®¸ Kubernetes **åœ¨è°ƒåº¦ Pod æ—¶ç»¼åˆè€ƒè™‘å­˜å‚¨ä½ç½®**ï¼Œå‡å°‘æ•°æ®ä¼ è¾“å»¶è¿Ÿã€‚

âŒ **å…±äº«å­˜å‚¨ (NFS, Ceph, AWS EBS)**

- è¿™äº›å­˜å‚¨æ²¡æœ‰èŠ‚ç‚¹é™åˆ¶ï¼Œä¸éœ€è¦å»¶è¿Ÿç»‘å®š



**`Immediate` vs `WaitForFirstConsumer` å¯¹æ¯”æ€»ç»“**

| ç»‘å®šæ¨¡å¼               | ç»‘å®šæ—¶é—´                             | é€‚ç”¨å­˜å‚¨ç±»å‹                          | é€‚ç”¨åœºæ™¯                                         | ä¸»è¦é—®é¢˜                                |
| ---------------------- | ------------------------------------ | ------------------------------------- | ------------------------------------------------ | --------------------------------------- |
| `Immediate`            | PVC ç«‹å³ç»‘å®š PV                      | å…±äº«å­˜å‚¨ (NFS, Ceph, AWS EBS, GCE PD) | **äº‘å­˜å‚¨ã€ç½‘ç»œå­˜å‚¨**ï¼ŒPVC å¯ä»¥æå‰ç»‘å®š           | **æœ¬åœ°å­˜å‚¨å¯èƒ½å¯¼è‡´ PVC ç»‘å®šåˆ°é”™è¯¯èŠ‚ç‚¹** |
| `WaitForFirstConsumer` | **Pod è¿è¡Œåœ¨å“ªä¸ªèŠ‚ç‚¹ï¼ŒPVC æ‰ä¼šç»‘å®š** | æœ¬åœ°å­˜å‚¨ (Local SSD, NVMe, EBS GP3)   | **æœ¬åœ°å­˜å‚¨æˆ–é«˜æ€§èƒ½ SSD**ï¼Œç¡®ä¿å­˜å‚¨ä¸è®¡ç®—èŠ‚ç‚¹ä¸€è‡´ | **Pod éœ€è¦å…ˆè°ƒåº¦ï¼ŒPVC æ‰èƒ½ç»‘å®š**        |



#### å­˜å‚¨åˆ¶å¤‡å™¨

æ¯ä¸ª StorageClass éƒ½æœ‰**ä¸€ä¸ªåˆ¶å¤‡å™¨ï¼ˆProvisionerï¼‰**ï¼Œç”¨äºæä¾›å­˜å‚¨é©±åŠ¨ï¼Œç”¨æ¥å†³å®šä½¿ç”¨å“ªä¸ªå·æ’ä»¶åˆ¶å¤‡ PVã€‚ **è¯¥å­—æ®µå¿…é¡»æŒ‡å®š**

| å·æ’ä»¶         | å†…ç½®åˆ¶å¤‡å™¨ |                           é…ç½®ç¤ºä¾‹                           |
| :------------- | :--------: | :----------------------------------------------------------: |
| AzureFile      |     âœ“      | [Azure File](https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/#azure-file) |
| CephFS         |     -      |                              -                               |
| FC             |     -      |                              -                               |
| FlexVolume     |     -      |                              -                               |
| iSCSI          |     -      |                              -                               |
| Local          |     -      | [Local](https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/#local) |
| NFS            |     -      | [NFS](https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/#nfs) |
| PortworxVolume |     âœ“      | [Portworx Volume](https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/#portworx-volume) |
| RBD            |     âœ“      | [Ceph RBD](https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/#ceph-rbd) |
| VsphereVolume  |     âœ“      | [vSphere](https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/#vsphere) |





#### Local Volume



#####  hostPathå­˜åœ¨çš„é—®é¢˜

è¿‡å»æˆ‘ä»¬ç»å¸¸ä¼šé€šè¿‡hostPath volumeè®©Podèƒ½å¤Ÿä½¿ç”¨æœ¬åœ°å­˜å‚¨ï¼Œå°†Nodeæ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶æˆ–è€…ç›®å½•æŒ‚ è½½åˆ°å®¹å™¨å†…ï¼Œä½†æ˜¯hostPath volumeçš„ä½¿ç”¨æ˜¯å¾ˆéš¾å—çš„ï¼Œå¹¶ä¸é€‚åˆåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ã€‚

- ç”±äºé›†ç¾¤å†…æ¯ä¸ªèŠ‚ç‚¹çš„å·®å¼‚åŒ–ï¼Œè¦ä½¿ç”¨hostPath Volumeï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡**NodeSelector**ç­‰æ–¹å¼è¿›è¡Œç²¾ç¡®è°ƒåº¦ï¼Œè¿™ç§äº‹æƒ…å¤šäº†ï¼Œä½ å°±ä¼šä¸è€çƒ¦äº†ã€‚

- æ³¨æ„DirectoryOrCreateå’ŒFileOrCreateä¸¤ç§ç±»å‹çš„hostPathï¼Œå½“Nodeä¸Šæ²¡æœ‰å¯¹åº”çš„ File/Directoryæ—¶ï¼Œä½ éœ€è¦ä¿**è¯kubeletæœ‰åœ¨ Nodeä¸ŠCreate File/Directoryçš„æƒé™**ã€‚
- å¦å¤–ï¼Œå¦‚æœNodeä¸Šçš„æ–‡ä»¶æˆ–ç›®å½•æ˜¯ç”±rootåˆ›å»ºçš„ï¼ŒæŒ‚è½½åˆ°å®¹å™¨å†…ä¹‹åï¼Œä½ é€šå¸¸è¿˜è¦ä¿è¯å®¹å™¨å†…è¿›ç¨‹æœ‰æƒé™å¯¹è¯¥æ–‡ä»¶æˆ–è€…ç›®å½•è¿›è¡Œå†™å…¥ï¼Œæ¯”å¦‚ä½ éœ€è¦ä»¥rootç”¨æˆ·å¯åŠ¨è¿›ç¨‹å¹¶è¿è¡Œäºprivilegedå®¹å™¨ï¼Œ æˆ–è€…ä½ éœ€è¦äº‹å…ˆä¿®æ”¹å¥½Nodeä¸Šçš„æ–‡ä»¶æƒé™é…ç½®ã€‚
- **Schedulerå¹¶ä¸ä¼šè€ƒè™‘hostPath volumeçš„å¤§å°ï¼ŒhostPathä¹Ÿä¸èƒ½ç”³æ˜éœ€è¦çš„storagesize**ï¼Œè¿™æ ·è°ƒåº¦æ—¶å­˜å‚¨çš„è€ƒè™‘ï¼Œå°±éœ€è¦äººä¸ºæ£€æŸ¥å¹¶ä¿è¯ã€‚



#####  Local PV ä½¿ç”¨åœºæ™¯

Local Persistent Volume å¹¶ä¸é€‚ç”¨äºæ‰€æœ‰åº”ç”¨ã€‚å®ƒçš„é€‚ç”¨èŒƒå›´éå¸¸å›ºå®šï¼Œæ¯”å¦‚ï¼šé«˜ä¼˜å…ˆçº§çš„ç³»ç»Ÿåº”ç”¨ï¼Œ éœ€è¦åœ¨å¤šä¸ªä¸åŒèŠ‚ç‚¹ä¸Šå­˜å‚¨æ•°æ®ï¼Œè€Œä¸”å¯¹ I/O è¦æ±‚è¾ƒé«˜ã€‚Kubernetes ç›´æ¥ä½¿ç”¨å®¿ä¸»æœºçš„æœ¬åœ°ç£ç›˜ç›®å½• ï¼Œæ¥æŒä¹…åŒ–å­˜å‚¨å®¹å™¨çš„æ•°æ®ã€‚å®ƒçš„**è¯»å†™æ€§èƒ½ç›¸æ¯”äºå¤§å¤šæ•°è¿œç¨‹å­˜å‚¨æ¥è¯´ï¼Œè¦å¥½å¾—å¤šï¼Œå°¤å…¶æ˜¯ SSD ç›˜**ã€‚

å…¸å‹çš„åº”ç”¨åŒ…æ‹¬ï¼šåˆ†å¸ƒå¼æ•°æ®å­˜å‚¨æ¯”å¦‚ MongoDBï¼Œåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿæ¯”å¦‚ GlusterFSã€Ceph ç­‰ï¼Œä»¥åŠéœ€ è¦åœ¨æœ¬åœ°ç£ç›˜ä¸Šè¿›è¡Œå¤§é‡æ•°æ®ç¼“å­˜çš„åˆ†å¸ƒå¼åº”ç”¨ï¼Œå…¶æ¬¡ä½¿ç”¨ Local Persistent Volume çš„åº”ç”¨å¿…é¡»å…·å¤‡ æ•°æ®å¤‡ä»½å’Œæ¢å¤çš„èƒ½åŠ›ï¼Œå…è®¸ä½ æŠŠè¿™äº›æ•°æ®å®šæ—¶å¤‡ä»½åœ¨å…¶ä»–ä½ç½®ã€‚



#####  Local PV çš„å®ç°

LocalPV çš„å®ç°å¯ä»¥ç†è§£ä¸ºæˆ‘ä»¬å‰é¢ä½¿ç”¨çš„ hostpath åŠ ä¸Š nodeAffinity ï¼Œæ¯”å¦‚ï¼šåœ¨å®¿ä¸»æœº NodeA ä¸Š æå‰åˆ›å»ºå¥½ç›®å½• ï¼Œç„¶ååœ¨å®šä¹‰ Pod æ—¶æ·»åŠ  nodeAffinity=NodeA ï¼ŒæŒ‡å®š Pod åœ¨æˆ‘ä»¬æå‰åˆ›å»ºå¥½ç›®å½•çš„ ä¸»æœºä¸Šè¿è¡Œã€‚ä½†æ˜¯**æˆ‘ä»¬ç»ä¸åº”è¯¥æŠŠä¸€ä¸ªå®¿ä¸»æœºä¸Šçš„ç›®å½•å½“ä½œ PV ä½¿ç”¨**ï¼Œå› ä¸ºæœ¬åœ°ç›®å½•çš„ç£ç›˜éšæ—¶éƒ½å¯èƒ½ è¢«åº”ç”¨å†™æ»¡ï¼Œç”šè‡³é€ æˆæ•´ä¸ªå®¿ä¸»æœºå®•æœºã€‚è€Œä¸”ï¼Œä¸åŒçš„æœ¬åœ°ç›®å½•ä¹‹é—´ä¹Ÿç¼ºä¹å“ªæ€•æœ€åŸºç¡€çš„ I/O éš”ç¦»æœº åˆ¶ã€‚æ‰€ä»¥ï¼Œ**ä¸€ä¸ª Local Persistent Volume å¯¹åº”çš„å­˜å‚¨ä»‹è´¨ï¼Œä¸€å®šæ˜¯ä¸€å—é¢å¤–æŒ‚è½½åœ¨å®¿ä¸»æœºçš„ç£ç›˜æˆ–è€… å—è®¾å¤‡**ï¼ˆâ€œé¢å¤–â€ çš„æ„æ€æ˜¯ï¼Œå®ƒä¸åº”è¯¥æ˜¯å®¿ä¸»æœºæ ¹ç›®å½•æ‰€ä½¿ç”¨çš„ä¸»ç¡¬ç›˜ï¼‰ã€‚è¿™ä¸ªåŸåˆ™ï¼Œæˆ‘ä»¬å¯ä»¥ç§°ä¸º â€œ**ä¸€ä¸ª PV ä¸€å—ç›˜**â€ã€‚





#####  Local PV å’Œå¸¸è§„ PV çš„åŒºåˆ«

å¯¹äºå¸¸è§„çš„ PVï¼ŒKubernetes éƒ½æ˜¯å…ˆè°ƒåº¦ Pod åˆ°æŸä¸ªèŠ‚ç‚¹ä¸Šï¼Œç„¶åå†æŒä¹…åŒ– è¿™å°æœºå™¨ä¸Šçš„ Volume ç›® å½•ã€‚è€Œ Local PVï¼Œåˆ™éœ€è¦è¿ç»´äººå‘˜æå‰å‡†å¤‡å¥½èŠ‚ç‚¹çš„ç£ç›˜ã€‚å®ƒä»¬åœ¨ä¸åŒèŠ‚ç‚¹ä¸Šçš„æŒ‚è½½æƒ…å†µå¯ä»¥å®Œå…¨ä¸ åŒï¼Œç”šè‡³æœ‰çš„èŠ‚ç‚¹å¯ä»¥æ²¡è¿™ç§ç£ç›˜ã€‚æ‰€ä»¥è°ƒåº¦å™¨å°±å¿…é¡»èƒ½å¤ŸçŸ¥é“æ‰€æœ‰èŠ‚ç‚¹ä¸ Local Persistent Volume  å¯¹åº”çš„ç£ç›˜çš„å…³è”å…³ç³»ï¼Œç„¶åæ ¹æ®è¿™ä¸ªä¿¡æ¯æ¥è°ƒåº¦ Podã€‚ä¹Ÿå°±æ˜¯åœ¨è°ƒåº¦çš„æ—¶å€™è€ƒè™‘ Volume åˆ†å¸ƒã€‚



k8s v1.10+ä»¥ä¸Šçš„ç‰ˆæœ¬ä¸­æ¨å‡ºlocal pvæ–¹æ¡ˆã€‚Local volume å…è®¸ç”¨æˆ·é€šè¿‡æ ‡å‡† PVC æ¥å£ä»¥ç®€å•ä¸”å¯ç§»æ¤ çš„æ–¹å¼è®¿é—® node èŠ‚ç‚¹çš„æœ¬åœ°å­˜å‚¨ã€‚ PV çš„å®šä¹‰ä¸­éœ€è¦åŒ…å«æè¿°èŠ‚ç‚¹äº²å’Œæ€§çš„ä¿¡æ¯ï¼Œk8s ç³»ç»Ÿåˆ™ä½¿ç”¨è¯¥ä¿¡ æ¯å°†å®¹å™¨è°ƒåº¦åˆ°æ­£ç¡®çš„ node èŠ‚ç‚¹ã€‚

åœ¨ Kubernetes ä¸­ï¼ŒHostPath å’Œ Local Volume éƒ½å¯ä»¥ç”¨äºå°†ä¸»æœºä¸Šçš„æ–‡ä»¶ç³»ç»ŸæŒ‚è½½åˆ°å®¹å™¨å†…éƒ¨ã€‚è™½ç„¶ å®ƒä»¬æœ‰ä¸€äº›ç›¸ä¼¼ä¹‹å¤„ï¼Œä½†æ˜¯å®ƒä»¬ä¹‹é—´ä¹Ÿæœ‰ä¸€äº›é‡è¦çš„åŒºåˆ«ã€‚

HostPathå·ç±»å‹ä¼šç›´æ¥æŒ‚è½½ä¸»æœºçš„æ–‡ä»¶ç³»ç»Ÿåˆ°Podä¸­ï¼Œè¿™ä¸ªæ–‡ä»¶ç³»ç»Ÿå¯ä»¥æ˜¯ä¸€ä¸ªæ–‡ä»¶æˆ–è€…æ˜¯ä¸€ä¸ªç›®å½•ã€‚ å½“Podè¢«è°ƒåº¦åˆ°ä¸€ä¸ªèŠ‚ç‚¹ä¸Šæ—¶ï¼Œè¯¥èŠ‚ç‚¹ä¸Šçš„æ–‡ä»¶ç³»ç»Ÿå°±ä¼šè¢«æŒ‚è½½åˆ°Podä¸­ã€‚è¿™ä½¿å¾—å¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨å®¹å™¨ å†…éƒ¨è®¿é—®ä¸»æœºä¸Šçš„æ–‡ä»¶ï¼Œä¾‹å¦‚ä¸»æœºä¸Šçš„æ—¥å¿—æˆ–é…ç½®æ–‡ä»¶ã€‚ä½†æ˜¯ï¼Œä½¿ç”¨ HostPath å·ç±»å‹å¯èƒ½ä¼šå­˜åœ¨å®‰å…¨ é£é™©ï¼Œå› ä¸ºå®¹å™¨å¯ä»¥è®¿é—®ä¸»æœºä¸Šçš„æ‰€æœ‰æ–‡ä»¶å’Œç›®å½•ï¼ŒåŒ…æ‹¬å…¶ä»–å®¹å™¨çš„æ–‡ä»¶ã€‚

ç›¸æ¯”ä¹‹ä¸‹ï¼ŒLocal Volume å·ç±»å‹åªèƒ½å°†èŠ‚ç‚¹ä¸Šçš„ä¸€ä¸ªç›®å½•æŒ‚è½½åˆ°å®¹å™¨å†…éƒ¨ã€‚å½“Podè¢«è°ƒåº¦åˆ°ä¸€ä¸ªèŠ‚ç‚¹ä¸Š æ—¶ï¼ŒKubernetes ä¼šä¸ºè¯¥èŠ‚ç‚¹åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„ç›®å½•ï¼Œå¹¶å°†è¯¥ç›®å½•æŒ‚è½½åˆ° Pod ä¸­ã€‚å› ä¸ºæ¯ä¸ª Pod åªèƒ½è®¿é—® å…¶æœ¬åœ°çš„ Local Volume ç›®å½•ï¼Œæ‰€ä»¥è¿™ç§å·ç±»å‹æ›´åŠ å®‰å…¨ã€‚ä½†æ˜¯ï¼Œå¦‚æœèŠ‚ç‚¹æ•…éšœæˆ–è¢«åˆ é™¤ï¼ŒLocal  Volume ä¸­çš„æ•°æ®å°†ä¼šä¸¢å¤±ã€‚å› æ­¤ï¼Œä½¿ç”¨ Local Volume å·ç±»å‹éœ€è¦è°¨æ…ï¼Œéœ€è¦ç¡®ä¿æœ‰å¤‡ä»½æœºåˆ¶æˆ–æŒä¹…åŒ– å­˜å‚¨ã€‚



**local Volume é»˜è®¤ä¸æ”¯æŒåŠ¨æ€é…ç½®ï¼Œåªèƒ½ç”¨ä½œé™æ€åˆ›å»ºçš„æŒä¹…å·å›½ã€‚ä½†å¯ä»¥é‡‡æœ‰ç¬¬ä¸‰æ–¹æ–¹æ¡ˆå®ç°åŠ¨æ€é…ç½®**

local ç±»å‹çš„PVæ˜¯ä¸€ç§æ›´é«˜çº§çš„æœ¬åœ°å­˜å‚¨æŠ½è±¡ï¼Œå®ƒå¯ä»¥**å…è®¸é€šè¿‡StorageClassæ¥è¿›è¡Œç®¡ç†**ã€‚

ä¸ hostPath å·ç›¸æ¯”ï¼Œ local å·èƒ½å¤Ÿä»¥æŒä¹…å’Œå¯ç§»æ¤çš„æ–¹å¼ä½¿ç”¨ï¼Œè€Œæ— éœ€æ‰‹åŠ¨å°† Pod è°ƒåº¦åˆ°èŠ‚ç‚¹ã€‚

åŒæ ·ä½¿ç”¨èŠ‚ç‚¹ä¸Šçš„æœ¬åœ°å­˜å‚¨ï¼Œä½†ç›¸æ¯”äº hostPath ï¼Œ l**ocal Volumeå¯ä»¥å£°æ˜ä¸ºåŠ¨æ€ä¾›åº”ï¼Œå¹¶ä¸”å¯ä»¥åˆ© ç”¨èŠ‚ç‚¹æ ‡ç­¾ï¼ˆnodeAffinityï¼‰å®ç°å­˜å‚¨äº²å’Œæ€§ï¼Œç¡®ä¿Podè°ƒåº¦åˆ°åŒ…å«æ‰€éœ€æ•°æ®çš„èŠ‚ç‚¹ä¸Š**ã€‚è€ŒhostPathå· åœ¨Podé‡å»ºåå¯èƒ½ä¼šè°ƒåº¦è‡³æ–°çš„èŠ‚ç‚¹ï¼Œè€Œå¯¼è‡´æ—§çš„æ•°æ®æ— æ³•ä½¿ç”¨



ç„¶è€Œï¼Œ local å·ä»ç„¶å–å†³äºåº•å±‚èŠ‚ç‚¹çš„å¯ç”¨æ€§ï¼Œå¹¶ä¸é€‚åˆæ‰€æœ‰åº”ç”¨ç¨‹åºã€‚ å¦‚æœèŠ‚ç‚¹å˜å¾—ä¸å¥åº·ï¼Œé‚£ä¹ˆ local å·ä¹Ÿå°†å˜å¾—ä¸å¯è¢« Pod è®¿é—®ã€‚ä½¿ç”¨å®ƒçš„ Pod å°†ä¸èƒ½è¿è¡Œã€‚ ä½¿ç”¨ local å·çš„åº”ç”¨ç¨‹åºå¿…é¡»èƒ½å¤Ÿ å®¹å¿è¿™ç§å¯ç”¨æ€§çš„é™ä½ï¼Œä»¥åŠå› åº•å±‚ç£ç›˜çš„è€ç”¨æ€§ç‰¹å¾è€Œå¸¦æ¥çš„æ½œåœ¨çš„æ•°æ®ä¸¢å¤±é£é™©



##### åˆ›å»ºLocal PV

ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨ local å·å’Œ nodeAffinity çš„æŒä¹…å·ç¤ºä¾‹ï¼š

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner #è¡¨ç¤ºè¯¥å­˜å‚¨ç±»ä¸ä½¿ç”¨ä»»ä½• provisionerï¼Œå³ä¸æ”¯æŒåŠ¨æ€åˆ†é…æŒä¹…å·ã€‚è¿™æ„å‘³ç€ç®¡ç†å‘˜éœ€è¦æ‰‹åŠ¨åˆ›å»ºå¹¶ç®¡ç†æŒä¹…å·ã€‚
volumeBindingMode: WaitForFirstConsumer #å»¶è¿Ÿç»‘å®šï¼Œåªæœ‰Podå‡†å¤‡å¥½æ‰ç»‘å®šPVè‡³PVCï¼Œå¦åˆ™PVCå¤„äºPendingçŠ¶æ€

---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: example-pv
spec:
  capacity:
    storage: 100Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  sotrageClassName: local-storage
  local:
    path: /mnt/disks/ssd1
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - example-node
```

ä½¿ç”¨ local å·æ—¶ï¼Œä½ éœ€è¦è®¾ç½® PersistentVolume å¯¹è±¡çš„ nodeAffinity å­—æ®µã€‚ Kubernetes è°ƒåº¦å™¨ ä½¿ç”¨ PersistentVolume çš„ nodeAffinity ä¿¡æ¯æ¥å°†ä½¿ç”¨ local å·çš„ Pod è°ƒåº¦åˆ°æ­£ç¡®çš„èŠ‚ç‚¹ã€‚

ä½¿ç”¨ local å·æ—¶ï¼Œ**å»ºè®®åˆ›å»ºä¸€ä¸ª StorageClass å¹¶å°†å…¶ volumeBindingMode è®¾ç½®ä¸º WaitForFirstConsumer** ã€‚è¦äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è€ƒ local StorageClass ç¤ºä¾‹ã€‚ å»¶è¿Ÿå·ç»‘å®šçš„æ“ä½œ å¯ä»¥ç¡®ä¿ Kubernetes åœ¨ä¸º PersistentVolumeClaim ä½œå‡ºç»‘å®šå†³ç­–æ—¶ï¼Œä¼šè¯„ä¼° Pod å¯èƒ½å…·æœ‰çš„å…¶ä»–èŠ‚ç‚¹ çº¦æŸï¼Œä¾‹å¦‚ï¼šå¦‚èŠ‚ç‚¹èµ„æºéœ€æ±‚ã€èŠ‚ç‚¹é€‰æ‹©å™¨ã€Pod äº²å’Œæ€§å’Œ Pod åäº²å’Œæ€§ã€‚



**ä½¿ç”¨Localå·æµç¨‹**

- åˆ›å»ºPVï¼Œä½¿ç”¨ nodeAffinity æŒ‡å®šç»‘å®šçš„èŠ‚ç‚¹æä¾›å­˜å‚¨
- åˆ›å»º PVCï¼Œç»‘å®šPVçš„å­˜å‚¨æ¡ä»¶
- åˆ›å»ºPodï¼Œå¼•ç”¨å‰é¢çš„PVCå’ŒPVå®ç°Local å­˜å‚¨



##### æ¡ˆä¾‹ï¼šåŸºäºStorageClasså®ç°Localå·

```yaml
#äº‹å…ˆå‡†å¤‡ç›®æ ‡èŠ‚ç‚¹å‡†å¤‡ç›®å½•ï¼Œå¯¹äºæœ¬åœ°å­˜å‚¨Kubernetes æœ¬èº«å¹¶ä¸ä¼šè‡ªåŠ¨åˆ›å»ºè·¯å¾„ï¼Œè¿™æ˜¯å› ä¸ºKubernetes ä¸èƒ½æ§åˆ¶èŠ‚ç‚¹ä¸Šçš„æœ¬åœ°å­˜å‚¨ï¼Œå› æ­¤æ— æ³•è‡ªåŠ¨åˆ›å»ºè·¯å¾„ã€‚
[root@node2 ~] # mkdir -p /data/www

#å¦‚æœæ²¡æœ‰å‡†å¤‡ç›®å½•ï¼Œä¼šå‡ºç°ä¸‹é¢æç¤ºé”™è¯¯
[root@master1 yaml]#kubectl describe pod pod-sc-local-demo
Events:
 Type     Reason           Age               From               Message
  ----     ------            ----              ----               -------
 Warning FailedScheduling 2m2s             default-scheduler  0/4 nodes are 
available: pod has unbound immediate PersistentVolumeClaims. preemption: 0/4 
nodes are available: 4 No preemption victims found for incoming pod..
 Normal   Scheduled         2m1s             default-scheduler Successfully 
assigned default/pod-sc-local-demo to node2.wang.org
 Warning FailedMount       56s (x8 over 2m) kubelet           
MountVolume.NewMounter initialization failed for volume "example-pv" : path 
"/data/www" does not exist

#å‡†å¤‡æ¸…å•æ–‡ä»¶, #kuberneteså†…ç½®äº†Localçš„ç½®å¤‡å™¨ï¼Œæ‰€ä»¥ä¸‹é¢StorageClassèµ„æºå¯ä»¥ä¸åˆ›å»º
[root@master1 yaml] # cat storage-sc-local-pv-pvc-pod.yaml
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: waitForFirstConsumer #å»¶è¿Ÿç»‘å®šï¼Œåªæœ‰Podå¯åŠ¨åå†ç»‘å®šPVåˆ°Podæ‰€åœ¨èŠ‚ç‚¹ï¼Œå¦åˆ™PVCå¤„äºPendingçŠ¶æ€

---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-sc-local
spec:
  capacity:
    storage: 100Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-storage
  local:
    path: /data/www/
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node2.mystical.org
          
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-sc-local
spec:
  storageClassName: local-storage
  accessModes: ["ReadWriteOnce"]
  resources:
    requests:
      storage: 100Mi

---
apiVersion: v1
kind: Pod
metadata:
  name: pod-sc-local-demo
spec:
  containers:
  - name: pod-sc-local-demo
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    volumeMounts:
    - name: pvc-sc-local
      mountPath: "/usr/share/nginx/html"
  restartPolicy: "Nerver"
  volumes:
  - name: pvc-sc-local
    persistentVolumeClaim:
      claimName: pvc-sc-local
      
#åº”ç”¨æ¸…å•æ–‡ä»¶
[root@master1 yaml] # kubectl apply -f storage-sc-local-pv-pvc-pod.yaml
persistentvolume/pv-sc-local created
persistentvolumeclaim/pvc-sc-local created
pod/pod-sc-local-demo created

# è¿™é‡ŒPodçš„èŠ‚ç‚¹è°ƒåº¦å–å†³äºPVå®šä¹‰çš„èŠ‚ç‚¹ä½ç½®ï¼Œæ˜¯ç”±äºPVä¸Šå®šä¹‰äº†node2èŠ‚ç‚¹ï¼Œå› æ­¤Podå¿…ç„¶è°ƒåº¦åˆ°node2èŠ‚ç‚¹
# è€ŒhostPathæ˜¯å…ˆç¡®å®šPodï¼Œç„¶ååœ¨æ ¹æ®Podè°ƒåº¦åˆ°çš„èŠ‚ç‚¹æ¥ç¡®å®šè·¯å¾„ã€‚
# è€Œä¸”PVå¯ä»¥é™å®šå¤§å°ï¼Œè€ŒPVæ— æ³•é™å®š
```



#### NFS StorageClass

##### NFSçš„å­˜å‚¨åˆ¶å¤‡å™¨æ–¹æ¡ˆ

NFS çš„è‡ªåŠ¨é…ç½®ç¨‹åº Provisioner å¯ä»¥é€šè¿‡ä¸åŒçš„é¡¹ç›®å®ç°,æ¯”å¦‚ï¼š

- **csi-driver-nfs**

  ```http
  https://github.com/kubernetes-csi/csi-driver-nfs
  ```

  

- **nfs-client-provisioner**

  - nfs-client-provisioner æ˜¯ä¸€ä¸ªè‡ªåŠ¨é…ç½®å·ç¨‹åºï¼Œå®ƒä½¿ç”¨ç°æœ‰çš„å’Œå·²é…ç½®çš„ NFS æœåŠ¡å™¨æ¥æ”¯æŒé€šè¿‡ PVCåŠ¨æ€é…ç½® PV
  - nfs-client-provisioner **ç›®å‰å·²ç»ä¸æä¾›æ›´æ–°**ï¼Œnfs-client-provisioner çš„ Github ä»“åº“å½“å‰å·²ç»è¿ç§» åˆ° NFS-Subdir-External-Provisionerçš„ä»“åº“

  ```http
  https://github.com/kubernetes-retired/external-storage/tree/master/nfs-client
  https://github.com/kubernetes-sigs/sig-storage-lib-external-provisioner
  ```



- **NFS-Subdir-External-Provisionerï¼ˆå®˜æ–¹æ¨èï¼‰**

  - æ­¤ç»„ä»¶æ˜¯ç”±Kubernetes SIGs ç¤¾åŒºå¼€å‘,ä¹Ÿæ˜¯Kuberneteså®˜æ–¹æ¨èå®ç°
  - æ˜¯å¯¹ nfs-client-provisioner ç»„ä»¶çš„æ‰©å±•

  ```http
  https://kubernetes.io/docs/concepts/storage/storage-classes/#nfs
  ```

  - NFS-Subdir-External-Provisioner æ˜¯ä¸€ä¸ªè‡ªåŠ¨é…ç½®å·ç¨‹åºï¼Œå¯ä»¥åœ¨ NFS æœåŠ¡å™¨ä¸Šé€šè¿‡PVCåŠ¨æ€åˆ› å»ºå’Œé…ç½® Kubernetes æŒä¹…å·
  - PVå‘½åè§„åˆ™å¦‚ä¸‹

  ```bash
  è‡ªåŠ¨åˆ›å»ºçš„ PV ä»¥${namespace}-${pvcName}-${pvName} å‘½åæ ¼å¼åˆ›å»ºåœ¨ NFS æœåŠ¡å™¨ä¸Šçš„å…±äº«æ•°æ®ç›®å½•ä¸­
  å½“è¿™ä¸ª PV è¢«å›æ”¶åä¼šä»¥ archieved-${namespace}-${pvcName}-${pvName} å‘½åæ ¼å¼å­˜åœ¨NFS æœåŠ¡å™¨ä¸­
  ```



- **NFS Ganesha server and external provisioner**

  ```http
  https://github.com/kubernetes-sigs/nfs-ganesha-server-and-external-provisioner
  ```

  - nfs-ganesha-server-and-external-provisioner æ˜¯ Kubernetes 1.14+ çš„æ ‘å¤–åŠ¨æ€é…ç½®ç¨‹åºã€‚ æ‚¨å¯ä»¥ä½¿ç”¨å®ƒå¿«é€Ÿè½»æ¾åœ°éƒ¨ç½²å‡ ä¹å¯ä»¥åœ¨ä»»ä½•åœ°æ–¹ä½¿ç”¨çš„å…±äº«å­˜å‚¨ã€‚



##### æ¡ˆä¾‹: åŸºäº nfs-subdir-external-provisione åˆ›å»º NFS å…±äº«å­˜å‚¨çš„ storageclass

éƒ¨ç½²ç›¸å…³æ–‡ä»¶

```http
https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner
https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner/tree/master/deploy
https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner?tab=readme-ov-file#manuall
```



åˆ›å»ºNFSå…±äº«å­˜å‚¨çš„storageclassæ­¥éª¤å¦‚ä¸‹

- åˆ›å»º NFS å…±äº«
- åˆ›å»º **Service Account** å¹¶æˆäºˆç®¡æ§NFS provisioneråœ¨k8sé›†ç¾¤ä¸­è¿è¡Œçš„æƒé™
- éƒ¨ç½² NFS-Subdir-External-Provisioner å¯¹åº”çš„ **Deployment**
- åˆ›å»º StorageClass è´Ÿè´£å»ºç«‹PVCå¹¶è°ƒç”¨NFS provisionerè¿›è¡Œé¢„å®šçš„å·¥ä½œ,å¹¶è®©PVä¸PVCå»ºç«‹è”ç³»
- åˆ›å»º PVC æ—¶è‡ªåŠ¨è°ƒç”¨SCåˆ›å»ºPV



**åˆ›å»ºNFSæœåŠ¡**

```bash
[root@master1 ~] # apt update && apt -y install nfs-server
[root@master1 ~] # systemctl status nfs-server.service 
â— nfs-server.service - NFS server and services
     Loaded: loaded (/lib/systemd/system/nfs-server.service; enabled; vendor 
preset: enabled)
     Active: active (exited) since Thu 2021-09-29 09:28:41 CST; 5min ago
   Main PID: 64029 (code=exited, status=0/SUCCESS)
     Tasks: 0 (limit: 2236)
     Memory: 0B
     CGroup: /system.slice/nfs-server.service
9æœˆ 29 09:28:40 master1.wang.org systemd[1]: Starting NFS server and services...
9æœˆ 29 09:28:41 master1.wang.org systemd[1]: Finished NFS server and services.


[root@master1 ~]#mkdir -pv /data/sc-nfs 
[root@master1 ~]#chown 777 /data/sc-nfs
[root@master1 ~]#vim /etc/exports
#æˆæƒworkerèŠ‚ç‚¹çš„ç½‘æ®µå¯ä»¥æŒ‚è½½
#/data/sc-nfs *(rw,no_root_squash,all_squash,anonuid=0,anongid=0) 
/data/sc-nfs *(rw,no_root_squash)

[root@master1 ~]#exportfs -r
[root@master1 ~]#exportfs -v
/data/sc-nfs <world>
(sync,wdelay,hide,no_subtree_check,anonuid=0,anongid=0,sec=sys,rw,secure,no_root_squash,all_squash)

#å¹¶åœ¨æ‰€æœ‰workerèŠ‚ç‚¹å®‰è£…NFSå®¢æˆ·ç«¯ 
[root@nodeX ~]#apt update && apt -y install nfs-common æˆ–è€… nfs-client
```



**åˆ›å»ºServiceAccountå¹¶æˆæƒ**

```yaml
[root@master1 yaml] # cat rbac.yaml 
# åˆ›å»ºç‹¬ç«‹çš„åç§°ç©ºé—´
apiVersion: v1
kind: Namespace
metadata:
  name: nfs-provisioner-demo
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  # replace with namespace where provisioner is deployed æ ¹æ®ä¸šåŠ¡éœ€è¦ä¿®æ”¹æ­¤å¤„åç§°ç©ºé—´
  namespace: nfs-provisioner-demo
  
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
  - apiGroups: [""]
    resources: ["services", "endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "delete"]
    
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: nfs-provisioner-demo
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
  
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: nfs-provisioner-demo
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
    
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: nfs-provisioner-demo
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: nfs-provisioner-demo
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io


# åº”ç”¨
[root@master1 yaml] # kubectl apply -f rbac.yaml
serviceaccount/nfs-client-provisioner created
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner created
clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner created
role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created
rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created

# æŸ¥çœ‹ç³»ç»Ÿç”¨æˆ·
[root@master1 yaml]#kubectl get sa
NAME                     SECRETS   AGE
default                  0         34d
nfs-client-provisioner   0         9s
```



**éƒ¨ç½² NFS-Subdir-External-Provisioner å¯¹åº”çš„ Deployment**

```yaml
[root@master1 nsf-provisioner] #vim nfs-client-provisioner.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  labels:
    app: nfs-client-provisioner
  namespace: nfs-provisioner-demo
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
      - name: nfs-client-provisioner     
        image: k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2 #æ­¤é•œåƒå›½å†…å¯èƒ½æ— æ³•è®¿é—®
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: nfs-client-root
          mountPath: /persistentvolumes
        env:
        - name: PROVISIONER_NAME
          value: k8s-sigs.io/nfs-subdir-external-provisioner # åç§°ç¡®ä¿ä¸nfs-StorageClass.yamlæ–‡ä»¶ä¸­çš„provisioneråç§°ä¿æŒä¸€è‡´
        - name: NFS_SERVER
          value: nfs.mystical.org
        - name: NFS_PATH
          value: /nfs-data/sc-nfs
      volumes:
      - name: nfs-client-root
        nfs:
          server: nfs.mystical.org
          path: /nfs-data/sc-nfs
          
# åº”ç”¨
[root@master1 nsf-provisioner]# kubectl apply -f nfs-client-provisioner.yaml 
deployment.apps/nfs-client-provisioner created

# æŸ¥çœ‹
[root@master1 nsf-provisioner]#kubectl get pod -n nfs-provisioner-demo 
NAME                                      READY   STATUS    RESTARTS   AGE
nfs-client-provisioner-74d7c6bf46-kkpmd   1/1     Running   0          4m9s
```



**åˆ›å»ºNFSèµ„æºçš„storageClass**

```yaml
[root@master1 nsf-provisioner] # vim nfs-storageClass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-nfs
  annotations:
    storageclass.kubernetes.io/is-default-class: "false" # æ˜¯å¦è®¾ç½®ä¸ºé»˜è®¤çš„storageClass
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner # or choose another name, must match deployment's env PROVISIONER_NAME
parameters:
  archiveOnDelete: "true" # è®¾ç½®ä¸ºfalseæ—¶åˆ é™¤PVCä¸ä¼šä¿ç•™æ•°æ®ï¼Œ"true"åˆ™ä¿ç•™æ•°æ®ï¼ŒåŸºäºå®‰å…¨åŸå› å»ºè®®è®¾ä¸º"true"


# åº”ç”¨
[root@master1 nsf-provisioner] # kubectl apply -f nfs-storageClass.yaml 
storageclass.storage.k8s.io/sc-nfs created

# æŸ¥çœ‹
[root@master1 nsf-provisioner]#kubectl get sc -n nfs-provisioner-demo 
NAME     PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
sc-nfs   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  15s
```



**åˆ›å»ºPVC**

```yaml
[root@master1 nsf-provisioner] # vim pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-nfs-sc
spec:
  storageClassName: sc-nfs # éœ€è¦å’Œå‰é¢åˆ›å»ºçš„storageClassåç§°ç›¸åŒ
  accessModes: ["ReadWriteMany", "ReadOnlyMany"]
  resources:
    requests:
      storage: 100Mi


# åº”ç”¨
[root@master1 nsf-provisioner] # kubectl apply -f pvc.yaml 
persistentvolumeclaim/pvc-nfs-sc created

# æŸ¥çœ‹pvc
[root@master1 nsf-provisioner] # kubectl get pvc
NAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
pvc-nfs-sc   Bound    pvc-a77fd2d8-3f14-475c-8e81-b5c0b24c4358   100Mi      ROX,RWX        sc-nfs         <unset>                 9m46s

# è‡ªåŠ¨ç”Ÿæˆpv
[root@master1 nsf-provisioner]#kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pvc-a77fd2d8-3f14-475c-8e81-b5c0b24c4358   100Mi      ROX,RWX        Delete           Bound    default/pvc-nfs-sc   sc-nfs         <unset>                          10m


# å¦‚æœpvæ²¡æœ‰åˆ›å»ºå‡ºæ¥ï¼Œå¯èƒ½çš„é—®é¢˜æŸ¥çœ‹ä¸‹rbacçš„æƒé™ï¼Œæ˜¯å¦ServiceAccountç»™äºˆçš„æƒé™ä¸å¤Ÿ
# å¯ä»¥é€šè¿‡logså‘½ä»¤æŸ¥çœ‹ï¼Œæ ¹æ®è¾“å‡ºçš„æ—¥å¿—è¿›è¡Œæ’é”™
[root@master1 nsf-provisioner] # kubectl logs pod/nfs-client-provisioner-649b64df96-sb7sg -n nfs-provisioner-demo
```



**åˆ›å»ºPod**

```yaml
[root@master1 nsf-provisioner] # cat pod-test.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-nfs-sc-test
spec:
  containers:
  - name: pod-nfs-sc-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    volumeMounts:
    - name: nfs-pvc
      mountPath: "/usr/share/nginx/html/"
  restartPolicy: "Never"
  volumes:
  - name: nfs-pvc
    persistentVolumeClaim:
      claimName: pvc-nfs-sc

# åº”ç”¨
[root@master1 nsf-provisioner] # kubectl apply -f pod-test.yaml                          
pod/pod-nfs-sc-test created

# æŸ¥çœ‹
[root@master1 nsf-provisioner] # kubectl get pod -o wide
NAME              READY   STATUS    RESTARTS   AGE   IP             NODE    NOMINATED NODE   READINESS GATES
pod-nfs-sc-test   1/1     Running   0          11s   10.244.1.125   node1   <none>           <none>

# curlIP
[root@master1 nsf-provisioner] # curl 10.244.1.125
<html>
<head><title>403 Forbidden</title></head>
<body>
<center><h1>403 Forbidden</h1></center>
<hr><center>nginx/1.20.0</center>
</body>
</html>

# å› ä¸ºæ ¹ç›®å½•ä¸‹æ²¡æœ‰å†…å®¹ï¼Œå› æ­¤è¿”å›403
# åœ¨nfsç›®å½•ä¸‹ï¼Œæ·»åŠ index.htmlæ–‡ä»¶
[root@ubuntu2204 ~] # echo web1 > /nfs-data/sc-nfs/default-pvc-nfs-sc-pvc-a77fd2d8-3f14-475c-8e81-b5c0b24c4358/index.html

# ç­‰ä¸€æ®µæ—¶é—´åï¼ˆæœ‰çŸ­æ—¶é—´çš„å»¶è¿Ÿï¼‰ï¼Œå†æ¬¡æŸ¥çœ‹ï¼Œ
[root@master1 nsf-provisioner] # curl 10.244.1.125
web1
```



### CAS å’Œ OpenEBS

#### Kuberneteså­˜å‚¨æ¶æ„

å­˜å‚¨å·çš„å…·ä½“çš„ç®¡ç†æ“ä½œç”±ç›¸å…³çš„æ§åˆ¶å™¨å‘**å·æ’ä»¶**å‘èµ·è°ƒç”¨è¯·æ±‚å®Œæˆ

è¿™é‡Œçš„å·æ’ä»¶æŒ‡çš„å°±æ˜¯CSIæ’ä»¶ï¼Œä¹Ÿå°±æ˜¯å­˜å‚¨åˆ¶å¤‡å™¨ï¼Œæ¯”å¦‚ï¼šprovisioner

- ADæ§åˆ¶å™¨ï¼šè´Ÿè´£å­˜å‚¨è®¾å¤‡çš„Attach/Detachæ“ä½œ
  - Attachï¼šå°†è®¾å¤‡é™„åŠ åˆ°ç›®æ ‡èŠ‚ç‚¹
  - Detachï¼šå°†è®¾å¤‡ä»ç›®æ ‡èŠ‚ç‚¹ä¸Šæ‹†é™¤
- å­˜å‚¨å·ç®¡ç†å™¨ï¼šè´Ÿè´£å®Œæˆå·çš„Mount/Umountæ“ä½œï¼Œä»¥åŠè®¾å¤‡çš„æ ¼å¼åŒ–æ“ä½œç­‰
- PVæ§åˆ¶å™¨ï¼šè´Ÿè´£PV/PVCçš„ç»‘å®šã€ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œä»¥åŠå­˜å‚¨å·çš„Provision/Deleteæ“ä½œ



##### **ä¸‰å¤§ç»„æˆç»„ä»¶ï¼ˆé€»è¾‘ä¸Šï¼‰**

| ç»„ä»¶å                                          | èŒè´£                                               | ä¸¾ä¾‹                                                         |
| ----------------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| **AD æ§åˆ¶å™¨**ï¼ˆAttach/Detach Controllerï¼‰       | æ§åˆ¶å™¨ç»„ä»¶ï¼Œè´Ÿè´£å°†è¿œç«¯å·æŒ‚è½½åˆ°èŠ‚ç‚¹ï¼ˆå¦‚æœæ˜¯ç½‘ç»œç›˜ï¼‰ | æŠŠé˜¿é‡Œäº‘çš„äº‘ç›˜ attach åˆ°æŸä¸ª node ä¸Š                         |
| **å­˜å‚¨å·ç®¡ç†å™¨**ï¼ˆNode Plugin / Mount Managerï¼‰ | è¿è¡Œåœ¨æ¯ä¸ª Node ä¸Šï¼Œå®ŒæˆçœŸæ­£çš„æŒ‚è½½ã€æ ¼å¼åŒ–ç­‰æ“ä½œ   | åœ¨æŸèŠ‚ç‚¹ä¸Šå°†æŒ‚è½½å¥½çš„äº‘ç›˜æ ¼å¼åŒ–ä¸º ext4 å¹¶ mount åˆ° Pod çš„è·¯å¾„ |
| **PV æ§åˆ¶å™¨**ï¼ˆVolume Provisioner Controllerï¼‰  | åˆ›å»º / åˆ é™¤ Volumeï¼ˆProvision å’Œ Delete æ“ä½œï¼‰     | æ ¹æ® PVC çš„è¯·æ±‚ï¼Œå»é˜¿é‡Œäº‘ API åˆ›å»ºäº‘ç›˜                       |



##### **å®ƒä»¬åœ¨ Kubernetes ä¸­çš„ä½“ç°**

**AD æ§åˆ¶å™¨ï¼šAttach/Detach Controller**

- **æ˜¯ä¸€ä¸ªé›†ç¾¤çº§åˆ«çš„æ§åˆ¶å™¨**ï¼Œè¿è¡Œåœ¨ kube-controller-manager é‡Œã€‚
- åœ¨ CSI æ¨¡å‹ä¸­ï¼Œç”± **external-attacher** Sidecar å®¹å™¨å®ç°ã€‚
- ä½œç”¨ï¼š
  - è´Ÿè´£åœ¨éœ€è¦æ—¶å°† Volume é™„åŠ ï¼ˆattachï¼‰åˆ°å¯¹åº”çš„èŠ‚ç‚¹ã€‚
  - å¦‚æœæ˜¯æœ¬åœ°ç›˜ï¼Œåˆ™ä¸éœ€è¦è¯¥ç»„ä»¶ï¼ˆä¸æ”¯æŒ attachï¼‰ã€‚

ğŸ§  ä¸¾ä¾‹ï¼š

> Pod è®¡åˆ’åœ¨ Node1 ä¸Šè¿è¡Œï¼Œä½¿ç”¨äº†ä¸€å—é˜¿é‡Œäº‘ç›˜ï¼Œè¿™ä¸ªç»„ä»¶å°±ä¼šè®©è¿™å—äº‘ç›˜å…ˆ attach åˆ° Node1ã€‚



**å­˜å‚¨å·ç®¡ç†å™¨ï¼šNode Plugin**

- é€šå¸¸å°±æ˜¯ CSI æ’ä»¶éƒ¨ç½²åœ¨æ¯ä¸ª Node ä¸Šçš„ `DaemonSet`ã€‚
- ä½œç”¨ï¼š
  - å®é™…æ‰§è¡ŒæŒ‚è½½åŠ¨ä½œï¼ˆmount/umountï¼‰
  - æ ¼å¼åŒ–å·ï¼ˆmkfsï¼‰
  - ç¡®ä¿æŒ‚è½½ç‚¹å¯ç”¨

ğŸ§  ä¸¾ä¾‹ï¼š

> Pod åœ¨ Node1 ä¸Šå¯åŠ¨åï¼ŒNode Plugin ä¼šæŠŠåˆšåˆš attach è¿‡æ¥çš„äº‘ç›˜ `/dev/vdb` æ ¼å¼åŒ–ï¼Œç„¶åæŒ‚è½½åˆ° `/var/lib/kubelet/pods/<uuid>/volumes/...`ï¼Œå† bind mount åˆ° Pod å†…ã€‚



**Væ§åˆ¶å™¨ï¼šexternal-provisioner**

- ç”± CSI æ’ä»¶é™„å¸¦çš„ Sidecar å®ç°ï¼ˆexternal-provisionerï¼‰ã€‚
- å½“ä½ åˆ›å»º PVC æ—¶ï¼ŒKubernetes ä¼šè°ƒç”¨è¿™ä¸ªç»„ä»¶å»åˆ›å»ºå®é™…çš„ Volumeã€‚
- é€šå¸¸è¿è¡Œåœ¨æ§åˆ¶å™¨ç»„ä»¶çš„ Deployment ä¸­ã€‚

ğŸ§  ä¸¾ä¾‹ï¼š

> å½“ä½ åˆ›å»ºä¸€ä¸ª PVCï¼Œè¯·æ±‚ 10Gi äº‘ç›˜æ—¶ï¼Œè¿™ä¸ª controller ä¼šè°ƒç”¨äº‘å‚å•† API åˆ›å»ºå¯¹åº”èµ„æºï¼Œå¹¶ç”Ÿæˆä¸€ä¸ª PVã€‚



**ä¸¾ä¸ªçœŸå®ä¾‹å­ï¼ˆä»¥é˜¿é‡Œäº‘ç›˜ä¸ºä¾‹ï¼‰**

é˜¿é‡Œäº‘ç›˜ CSI æ’ä»¶é€šå¸¸åŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š

| Pod/å®¹å™¨            | ä½œç”¨                                   |
| ------------------- | -------------------------------------- |
| **csi-provisioner** | å®ç° PV Controllerï¼ˆprovision/deleteï¼‰ |
| **csi-attacher**    | å®ç° AD Controllerï¼ˆattach/detachï¼‰    |
| **csi-plugin**      | èŠ‚ç‚¹ä¸Šçš„ NodePluginï¼ŒæŒ‚è½½äº‘ç›˜          |

å½“ä½ åˆ›å»ºä¸€ä¸ª PVC çš„æµç¨‹å¦‚ä¸‹ï¼š

1. `external-provisioner` ç›‘å¬ PVC äº‹ä»¶ï¼Œå¹¶è°ƒç”¨é˜¿é‡Œäº‘ API åˆ›å»ºä¸€å—ç›˜ã€‚
2. åˆ›å»º PV èµ„æºï¼Œå¹¶æ ‡æ³¨å…¶ VolumeHandleã€‚
3. å½“ Pod è¢«è°ƒåº¦åˆ°æŸä¸ª Node ä¸Šï¼Œ`external-attacher` è´Ÿè´£å°†äº‘ç›˜ attach åˆ°è¯¥èŠ‚ç‚¹ã€‚
4. Node ä¸Šçš„ `csi-plugin`ï¼ˆDaemonSetï¼‰æ¥æ”¶åˆ°è¯·æ±‚ï¼Œæ‰§è¡Œæ ¼å¼åŒ–å’ŒæŒ‚è½½åŠ¨ä½œã€‚
5. Pod ä¸­çš„è·¯å¾„æŒ‚è½½å®Œæˆï¼Œæ•°æ®å¯è¯»å†™ã€‚

```ABAP
é€šå¸¸CSI çš„ attachã€provision å’Œ node plugin éƒ½ä¸æ˜¯å†…ç½®çš„ï¼Œå®ƒä»¬éƒ½æ˜¯ ç”±å„ä¸ª CSI æ’ä»¶å‚å•†æä¾›çš„ç»„ä»¶ï¼Œéœ€è¦æˆ‘ä»¬ æ‰‹åŠ¨éƒ¨ç½²ï¼ˆé€šå¸¸ä½œä¸ºä¸€ç»„ Helm Chart æˆ– YAML æ–‡ä»¶éƒ¨ç½²ï¼‰ã€‚
```



Schedulerï¼šç‰¹å®šè°ƒåº¦æ’ä»¶çš„è°ƒåº¦å†³ç­–ä¼šå—åˆ°ç›®æ ‡èŠ‚ç‚¹ä¸Šçš„å­˜å‚¨å·çš„å½±å“



##### CSI ç®€ä»‹

- å®¹å™¨å­˜å‚¨æ¥å£è§„èŒƒï¼Œä¸å¹³å°æ— å…³
- é©±åŠ¨ç¨‹åºç»„ä»¶
  - **CSI Controller**ï¼šè´Ÿè´£ä¸å­˜å‚¨æœåŠ¡çš„APIé€šä¿¡ï¼Œä»è€Œå®Œæˆåç«¯å­˜å‚¨çš„ç®¡ç†æ“ä½œ
  - **Node Plugin**ï¼šä¹Ÿç§°ä¸ºCSI-Nodeï¼Œè´Ÿè´£åœ¨èŠ‚ç‚¹çº§åˆ«å®Œæˆå­˜å‚¨å·çš„ç®¡ç†

```ABAP
CSI æ’ä»¶ç”± æ§åˆ¶å¹³é¢çš„ Controllerï¼ˆå¦‚ Provisioner å’Œ Attacherï¼‰ å’Œ æ•°æ®å¹³é¢çš„ Node Plugin ç»„æˆï¼Œå‰è€…é€šå¸¸ç”± Deployment æˆ– StatefulSet ç®¡ç†ï¼Œåè€…ä½œä¸º DaemonSet è¿è¡Œåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šï¼Œè´Ÿè´£å®é™…çš„å­˜å‚¨æ“ä½œã€‚
```



#### CAS  (Container Attached Storage)

##### CAS ç®€ä»‹

**å®¹å™¨é™„åŠ å­˜å‚¨ï¼ˆContainer Attached Storageï¼‰**

Kubernetesçš„å·é€šå¸¸æ˜¯åŸºäºå¤–éƒ¨æ–‡ä»¶ç³»ç»Ÿæˆ–å—å­˜å‚¨å®ç°çš„ï¼Œè¿™ç§å­˜å‚¨æ–¹æ¡ˆç§°ä¸ºå…±äº«å­˜å‚¨ï¼ˆShared Storageï¼‰

CASåˆ™æ˜¯å°†å­˜å‚¨ç³»ç»Ÿè‡ªèº«éƒ¨ç½²ä¸ºKubernetesé›†ç¾¤ä¸Šçš„ä¸€ç§è¾ƒæ–°çš„å­˜å‚¨è§£å†³æ–¹æ¡ˆ

- å­˜å‚¨ç³»ç»Ÿè‡ªèº«ï¼ˆåŒ…æ‹¬å­˜å‚¨æ§åˆ¶å™¨ï¼‰åœ¨Kubernetesä¸Šä»¥å®¹å™¨åŒ–å¾®æœåŠ¡çš„æ–¹å¼è¿è¡Œ

- ä½¿å¾—å·¥ä½œè´Ÿè½½æ›´æ˜“äºç§»æ¤ï¼Œä¸”æ›´å®¹å™¨æ ¹æ®åº”ç”¨ç¨‹åºçš„éœ€æ±‚æ”¹åŠ¨ä½¿ç”¨çš„å­˜å‚¨

- é€šå¸¸åŸºäºå·¥ä½œè´Ÿè½½æˆ–è€…æŒ‰é›†ç¾¤éƒ¨ç½²ï¼Œå› æ­¤æ¶ˆé™¤äº†å…±äº«å­˜å‚¨çš„è·¨å·¥ä½œè´Ÿè½½ç”šè‡³æ˜¯è·¨é›†ç¾¤çš„çˆ†ç‚¸åŠå¾„

  ```ABAP
  CAS é€šè¿‡åœ¨æ¯ä¸ªèŠ‚ç‚¹éƒ¨ç½² å®¹å™¨åŒ–çš„å­˜å‚¨ç»„ä»¶ï¼ˆå¦‚ä»£ç†ã€å­˜å‚¨å¼•æ“ï¼‰ï¼ŒèšåˆèŠ‚ç‚¹ä¸Šçš„æœ¬åœ°ç£ç›˜èµ„æºï¼Œæ„å»ºèµ·ä¸€ä¸ªå…·å¤‡åˆ†å¸ƒå¼ç‰¹æ€§ã€é«˜å¯ç”¨èƒ½åŠ›ã€K8s æ·±åº¦é›†æˆçš„å­˜å‚¨ç³»ç»Ÿã€‚
  ```

å­˜å‚¨åœ¨CASä¸­çš„æ•°æ®å¯ä»¥ç›´æ¥ä»é›†ç¾¤å†…çš„å®¹å™¨è®¿é—®ï¼Œä»è€Œèƒ½æ˜¾è‘—è¾ƒå°‘è¯»/å†™æ—¶é—´

OpenEBSæ˜¯CASå­˜å‚¨æœºåˆ¶çš„è‘—åå®ç°ä¹‹ä¸€ï¼Œç”±CNCFå­µåŒ–



**åŸºäºCASçš„å­˜å‚¨è§£å†³æ–¹æ¡ˆï¼Œé€šå¸¸åŒ…å«ä¸¤ç±»ç»„ä»¶**

**æ§åˆ¶å¹³é¢**

- è´Ÿè´£é…ç½®å·ä»¥åŠå…¶ä»–åŒå­˜å‚¨ç›¸å…³çš„ä»»åŠ¡
- ç”±å­˜å‚¨æ§åˆ¶å™¨ï¼Œå­˜å‚¨ç­–ç•¥ä»¥åŠå¦‚ä½•é…ç½®æ•°æ®å¹³é¢çš„æŒ‡ä»¤ç»„æˆ

**æ•°æ®å¹³é¢**

- æ¥å—å¹¶æ‰§è¡Œæ¥è‡ªæ§åˆ¶å¹³é¢çš„æœ‰å…³å¦‚ä½•ä¿å­˜å’Œè®¿é—®å®¹å™¨ä¿¡æ¯çš„æŒ‡ä»¤
- ä¸»è¦ç»„ä»¶æ˜¯å®ç°æ± åŒ–å­˜å‚¨çš„å­˜å‚¨å¼•æ“ï¼Œè¿™ç±»å¼•æ“æœ¬è´¨ä¸Šè´Ÿè´£è¾“å…¥/è¾“å‡ºå·è·¯å¾„
- OpenEBSæ”¯æŒå­˜å‚¨å¼•æ“åŒ…æ‹¬Mayastorã€cStorã€Jivaå’Œ OpenEBS LocalPV ç­‰



#### OpenEBS

##### openEBS ç®€ä»‹

OpenEBSèƒ½å¤Ÿå°†Kuberneteså·¥ä½œèŠ‚ç‚¹ä¸Šå¯ç”¨çš„ä»»ä½•å­˜å‚¨è½¬æ¢ä¸ºæœ¬åœ°å·æˆ–åˆ†å¸ƒå¼å¤åˆ¶å·

æœ€åˆç”±MayaDataæ„å»ºï¼Œåæèµ ç»™äº†CNCFï¼Œç›®å‰æ˜¯CNCFçš„æ²™ç®±çº§é¡¹ç›®



![image-20250330103916823](../markdown_img/image-20250330103916823.png)



##### OpenEBS æ¶æ„

- **æ•°æ®å¼•æ“**

- **æ§åˆ¶å¹³é¢**

![image-20250330105920486](../markdown_img/image-20250330105920486.png)



###### OpenEBS æ•°æ®å¼•æ“

**æ•°æ®å¼•æ“çš„åŠŸèƒ½**

æ•°æ®å¼•æ“ç±»ä¼¼äºå­˜å‚¨æ§åˆ¶å™¨ï¼Œä¹Ÿå¯å°†å…¶æ¯”ä½œæ˜¯ä¸€ç§SDSçš„å®ç°

OpenEBSæä¾›äº†ä¸€ç³»åˆ—çš„æ•°æ®å¼•æ“ï¼Œæ‰€æœ‰å¼•æ“éƒ½æ”¯æŒPVçš„åŠ¨æ€ç½®å¤‡å’Œæ•°æ®çš„å¼ºä¸€è‡´æ€§



**æ•°æ®å¼•æ“çš„åˆ†ç±»**

**æœ¬åœ°å¼•æ“**

- æœ¬åœ°å¼•æ“å¯ä»¥ä»æœ¬åœ°ç£ç›˜è®¾å¤‡ï¼ˆä¾èµ–NDMã€Node Disk Managerï¼Œåç»­è¯¦è§£ã€‘ï¼‰æˆ–ä¸»æœºè·¯å¾„åˆ›å»ºPVï¼Œä¹Ÿå¯ä»¥åŸºäºé›†ç¾¤èŠ‚ç‚¹ä¸Šçš„LVMæˆ–ZFSåˆ›å»ºPV
- é€‚åˆå†…ç½®å¯ç”¨æ€§å’Œå¯æ‰©å±•æ€§åŠŸèƒ½çš„åº”ç”¨ç¨‹åºï¼Œæˆ–è€…ä½œä¸šç±»çš„æœ‰çŠ¶æ€å·¥ä½œè´Ÿè½½
- åŸºäºèŠ‚ç‚¹ä¸Šæ”¯æŒçš„å­˜å‚¨æœºåˆ¶ï¼Œå¯é€‰çš„åŠ¨æ€ Local PV åŒ…æ‹¬ Local PV hostpathã€Local PV deviceã€ZFS Local PVã€LVM Local PV å’Œ Rawfile Local PV è¿™äº”ç§

âœ… ä»€ä¹ˆæ˜¯ Node Disk Managerï¼Ÿ

**NDM æ˜¯ OpenEBS é¡¹ç›®ä¸­çš„ä¸€ä¸ªå…³é”®ç»„ä»¶ï¼Œä¸“é—¨ç”¨äº**ï¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè‡ªåŠ¨å‘ç°ã€ç®¡ç†ã€ç›‘æ§å¯ç”¨çš„ç‰©ç†å­˜å‚¨è®¾å¤‡ï¼ˆå¦‚è£¸ç›˜ã€å—è®¾å¤‡ï¼‰ã€‚

âœ… NDM çš„èŒè´£åŒ…æ‹¬ï¼š

| åŠŸèƒ½           | æè¿°                                                         |
| -------------- | ------------------------------------------------------------ |
| ğŸ§­ è‡ªåŠ¨å‘ç°     | è‡ªåŠ¨æ‰«æèŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰å—è®¾å¤‡ï¼ˆä¾‹å¦‚ `/dev/sdb`, `/dev/nvme0n1`ï¼‰ |
| ğŸ” è¿‡æ»¤å’Œæ ‡è®°   | æ’é™¤ç³»ç»Ÿç›˜ã€æ­£åœ¨è¢«ä½¿ç”¨çš„ç›˜ï¼Œåªæš´éœ²çœŸæ­£å¯ç”¨çš„è£¸è®¾å¤‡           |
| ğŸ§± å­˜å‚¨èµ„æºæ³¨å†Œ | æŠŠæ¯ä¸ªç›˜æ³¨å†Œä¸º Kubernetes CRï¼ˆå¦‚ BlockDeviceï¼‰               |
| ğŸ§© å·è°ƒåº¦æ”¯æŒ   | å¸®åŠ© CSI æ§åˆ¶å™¨æ ¹æ®ç£ç›˜æƒ…å†µè°ƒåº¦ LocalPV æˆ– cStor Pool        |
| ğŸ“Š å¥åº·ç›‘æ§     | ç›‘æ§ç›˜çš„å®¹é‡ã€çŠ¶æ€ã€I/O é”™è¯¯ç­‰ä¿¡æ¯                           |

âœ… å·¥ä½œæµç¨‹ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼š

1. æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œä¸€ä¸ª NDM DaemonSet
2. å¯åŠ¨åæ‰«ææœ¬åœ° `/dev/` ä¸‹çš„å—è®¾å¤‡
3. åˆ¤æ–­è¯¥è®¾å¤‡æ˜¯å¦ç©ºé—² & éç³»ç»Ÿç›˜ï¼ˆé€šè¿‡ udev è§„åˆ™ã€æŒ‚è½½ç‚¹æ£€æµ‹ç­‰ï¼‰
4. ç”Ÿæˆä¸€ä¸ªå¯¹åº”çš„ **`BlockDevice` CRD**
5. æ§åˆ¶é¢é€šè¿‡è¿™äº› CRD è°ƒåº¦å’Œç»‘å®šè®¾å¤‡
6. ç”¨æˆ·è¯·æ±‚ PVC æ—¶ï¼ŒCSI Plugin ç»“åˆ BlockDevice åˆ›å»º Local PV

âœ… è¡¥å……ï¼šNDM å‘ç°åä¼šç”Ÿæˆå“ªäº›èµ„æºï¼Ÿ

NDM ä¼šåˆ›å»ºè¿™äº› CRD èµ„æºï¼š

- `BlockDevice`ï¼šæ¯å—è£¸ç›˜éƒ½ä¼šå¯¹åº”ä¸€ä¸ª BlockDevice èµ„æº
- `BlockDeviceClaim`ï¼šè¯·æ±‚ä½¿ç”¨ BlockDevice æ—¶åˆ›å»ºçš„å£°æ˜
- `BD` æ ‡ç­¾ï¼šä¼šæ ‡è®°è®¾å¤‡æ˜¯ â€œActiveâ€, â€œInUseâ€, â€œUnclaimedâ€ ç­‰çŠ¶æ€



**å¤åˆ¶å¼•æ“**

- å¤åˆ¶å·ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯é‚£äº›å¯ä»¥å°†æ•°æ®åŒæ­¥å¤åˆ¶åˆ°å¤šä¸ªèŠ‚ç‚¹çš„å·
- å¤åˆ¶å¼•æ“å…è®¸ä»å¤åˆ¶èŠ‚ç‚¹èŒƒå›´å†…çš„ä»»ä¸€èŠ‚ç‚¹ä¸Šè¿›è¡Œæ•°æ®è®¿é—®ï¼Œå¹¶æ”¯æŒè·¨å¯ç”¨åŒºè¿›è¡Œå¤åˆ¶
- å¤åˆ¶å·é€šå¸¸è¿˜æ”¯æŒå¿«ç…§ã€å…‹éš†ã€æ‰©å±•ç­‰åŠŸèƒ½
- åŸºäºèŠ‚ç‚¹ä¸Šæ”¯æŒçš„å­˜å‚¨æœºåˆ¶ï¼Œå¯é€‰çš„å¤åˆ¶å¼•æ“åŒ…æ‹¬Mayastorã€cStor å’Œ Jiva



###### **æ•°æ®å¼•æ“ å’Œ NDM**

**å¦‚ä½•é€‰æ‹©æ•°æ®å¼•æ“**

- åº”ç”¨ç¨‹åºå¤„äºç”ŸæˆçŠ¶æ€ä¸”ä¸éœ€è¦å­˜å‚¨çº§å¤åˆ¶ï¼Œåˆ™é¦–å…ˆLocalPV
- åº”ç”¨ç¨‹åºå¤„äºç”Ÿäº§çŠ¶æ€å¹¶ä¸”éœ€è¦å­˜å‚¨çº§å¤åˆ¶ï¼Œåˆ™é¦–å…ˆcStor
- åº”ç”¨ç¨‹åºè¾ƒå°ï¼Œéœ€è¦å­˜å‚¨çº§å¤åˆ¶ä½†ä¸éœ€è¦å¿«ç…§å’Œå…‹éš†ï¼Œåˆ™é¦–å…ˆJiva
- åº”ç”¨ç¨‹åºéœ€è¦ä½å»¶è¿Ÿå’Œæ¥è¿‘ç£ç›˜çš„ååé‡ï¼Œéœ€è¦å­˜å‚¨çº§å¤åˆ¶ï¼Œå¹¶ä¸”å·¥ä½œèŠ‚ç‚¹å…·æœ‰æ€§èƒ½è¾ƒé«˜çš„CPUï¼ŒRAMå’ŒNVMEï¼Œé‚£ä¹ˆMayastoré¦–é€‰

**NDMï¼ˆNode Disk Managerï¼‰**

- éƒ¨ç½²OpenEBSçš„è¿‡ç¨‹ä¸­ï¼ŒNDMç”±ä¸“ç”¨DaemonSetç¼–æ’è¿è¡Œäºæ¯ä¸ªèŠ‚ç‚¹ä¸Š
  - è´Ÿè´£å‘ç°è£¸è®¾åˆ«å¹¶è¿‡æ»¤ä¸æ”¯æŒä½¿ç”¨çš„è®¾å¤‡ï¼Œæ¯”å¦‚å·²ç»å¸¦æœ‰æ–‡ä»¶ç³»ç»Ÿçš„ç£ç›˜
  - éœ€è¦ç‰¹æƒæ¨¡å¼ï¼Œè®¿é—®/devï¼Œ/proc å’Œ /sys ç›®å½•æ¥ç›‘è§†è¿æ¥çš„è®¾å¤‡ï¼Œå¹¶ä½¿ç”¨å„ç§æ¢æµ‹å™¨è·å–è¿™äº›è®¾å¤‡çš„è¯¦ç»†ä¿¡æ¯
- æ ¹æ®è¿‡æ»¤å™¨ï¼ˆfilterï¼‰æ£€æµ‹é™„åŠ åˆ°èŠ‚ç‚¹ä¸Šçš„è£¸ç£ç›˜è®¾å¤‡ï¼Œå¹¶å°†å®ƒä»¬è¯†åˆ«ä¸ºâ€œå—è®¾å¤‡CRDâ€
  - NDM æ”¯æŒä½¿ç”¨include filter æˆ– exclude filter
  - filter çš„é…ç½®ä¿å­˜äº ConfigMap ä¸­
- åŸºäºèŠ‚ç‚¹ä¸Šçš„ç½—ç£ç›˜è®¾å¤‡æä¾›PVçš„å­˜å‚¨å¼•æ“ï¼Œä¼šä¾èµ–äºNDMå®ç°å…¶åŠŸèƒ½ï¼Œè¿™åŒ…æ‹¬LocalPV device å’Œ cStor



##### é…ç½®ä½¿ç”¨OpenEBS

**openEBSå®˜ç½‘**

```http
https://openebs.io/docs/quickstart-guide/installation
```

![image-20250330112734046](../markdown_img/image-20250330112734046.png)



**éƒ¨ç½²ä½¿ç”¨OpenEBSçš„åŸºæœ¬æµç¨‹**

- åœ¨å„èŠ‚ç‚¹ä¸Šéƒ¨ç½² **iSCSI client**
- åœ¨Kubernetesé›†ç¾¤ä¸Šéƒ¨ç½²OpenEBS
- é€‰æ‹©è¦ä½¿ç”¨çš„æ•°æ®å¼•æ“
- ä¸ºé€‰æ‹©çš„æ•°æ®å¼•æ“å‡†å¤‡StorageClass



```bash
# ä¸‹è½½yamlæ–‡ä»¶
[root@master1 OpenEBS]#wget https://openebs.github.io/charts/openebs-operator.yaml
[root@master1 OpenEBS]#ls
openebs-operator.yaml

# å¯ç”¨
[root@master1 OpenEBS]#kubectl apply -f openebs-operator.yaml 
namespace/openebs created
serviceaccount/openebs-maya-operator created
clusterrole.rbac.authorization.k8s.io/openebs-maya-operator created
clusterrolebinding.rbac.authorization.k8s.io/openebs-maya-operator created
customresourcedefinition.apiextensions.k8s.io/blockdevices.openebs.io created
customresourcedefinition.apiextensions.k8s.io/blockdeviceclaims.openebs.io created
configmap/openebs-ndm-config created
daemonset.apps/openebs-ndm created
deployment.apps/openebs-ndm-operator created
deployment.apps/openebs-ndm-cluster-exporter created
service/openebs-ndm-cluster-exporter-service created
daemonset.apps/openebs-ndm-node-exporter created
service/openebs-ndm-node-exporter-service created
deployment.apps/openebs-localpv-provisioner created
storageclass.storage.k8s.io/openebs-hostpath created
storageclass.storage.k8s.io/openebs-device created

# ä¼šåˆ›å»ºä¸€ä¸ªOpenEBSçš„ä¸“ç”¨åç§°ç©ºé—´
[root@master1 OpenEBS]#kubectl get ns openebs 
NAME      STATUS   AGE
openebs   Active   58s

# æŸ¥çœ‹openebs-hostpath
[root@master1 OpenEBS]#kubectl get sc openebs-hostpath -o yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    # å¯ä»¥åœ¨ä¸‹é¢æ·»åŠ ä¸€è¡Œï¼Œå°†å…¶è®¾ç½®ä¸ºé»˜è®¤çš„ç›®å½•
    storageclass.kubernetes.io/is-default-class: "true" # æ˜¯å¦è®¾ç½®ä¸ºé»˜è®¤çš„storageClass
    cas.openebs.io/config: "#hostpath type will create a PV by \n# creating a sub-directory
      under the\n# BASEPATH provided below.\n- name: StorageType\n  value: \"hostpath\"\n#Specify
      the location (directory) where\n# where PV(volume) data will be saved. \n# A
      sub-directory with pv-name will be \n# created. When the volume is deleted,
      \n# the PV sub-directory will be deleted.\n#Default value is /var/openebs/local\n-
      name: BasePath\n  value: \"/var/openebs/local/\"\n"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"storage.k8s.io/v1","kind":"StorageClass","metadata":{"annotations":{"cas.openebs.io/config":"#hostpath type will create a PV by \n# creating a sub-directory under the\n# BASEPATH provided below.\n- name: StorageType\n  value: \"hostpath\"\n#Specify the location (directory) where\n# where PV(volume) data will be saved. \n# A sub-directory with pv-name will be \n# created. When the volume is deleted, \n# the PV sub-directory will be deleted.\n#Default value is /var/openebs/local\n- name: BasePath\n  value: \"/var/openebs/local/\"\n","openebs.io/cas-type":"local"},"name":"openebs-hostpath"},"provisioner":"openebs.io/local","reclaimPolicy":"Delete","volumeBindingMode":"WaitForFirstConsumer"}  # å¯ä»¥çœ‹åˆ°ä¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šåˆ›å»º/var/openebs/localä½œä¸ºå­˜å‚¨åç«¯ï¼Œ
    openebs.io/cas-type: local
  creationTimestamp: "2025-03-30T03:37:03Z"
  name: openebs-hostpath
  resourceVersion: "284993"
  uid: f67224f9-6542-4003-8c3d-ec4661b6465b
provisioner: openebs.io/local
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer

# æ³¨æ„openebs-hostpathåªæ”¯æŒå•è·¯è¯»å†™ï¼Œå³ReadWriteOnceï¼Œä¸æ”¯æŒå¤šè·¯è¯»å†™
```



###### æ”¯æŒå¤šè·¯è¯»å†™çš„è§£å†³æ–¹æ¡ˆ

```bash
[root@master1 OpenEBS]#wget https://openebs.github.io/charts/nfs-operator.yaml

# å¯ç”¨
[root@master1 OpenEBS]#kubectl apply -f nfs-operator.yaml 
namespace/openebs unchanged
serviceaccount/openebs-maya-operator unchanged
clusterrole.rbac.authorization.k8s.io/openebs-maya-operator configured
clusterrolebinding.rbac.authorization.k8s.io/openebs-maya-operator unchanged
deployment.apps/openebs-nfs-provisioner created
storageclass.storage.k8s.io/openebs-rwx created

# æŸ¥çœ‹
[root@master1 OpenEBS]#kubectl get sc openebs-rwx 
NAME          PROVISIONER         RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
openebs-rwx   openebs.io/nfsrwx   Delete          Immediate           false                  50s

# æµ‹è¯•
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: "openebs-rwx"
  resources:
    requests:
      storage: 1Gi
```



#### OpenEBS Jiva å¤åˆ¶å·éƒ¨ç½²

OpenEBS ç®¡ç†æ¯ä¸ª Kubernetes èŠ‚ç‚¹ä¸Šå¯ç”¨çš„å­˜å‚¨ï¼Œå¹¶ä½¿ç”¨è¯¥å­˜å‚¨ä¸ºæœ‰çŠ¶æ€å·¥ä½œè´Ÿè½½æä¾›æœ¬åœ°æˆ–åˆ†å¸ƒå¼ï¼ˆä¹Ÿç§°ä¸ºå¤åˆ¶ï¼‰æŒä¹…å·ã€‚

å¦‚æœæ˜¯æœ¬åœ°å·ï¼š

- OpenEBS å¯ä»¥ä½¿ç”¨åŸå§‹å—è®¾å¤‡æˆ–åˆ†åŒºï¼Œæˆ–ä½¿ç”¨ä¸»æœºè·¯å¾„ä¸Šçš„å­ç›®å½•ï¼Œæˆ–ä½¿ç”¨ LVMã€ZFS æˆ–ç¨€ç–æ–‡ä»¶æ¥åˆ›å»ºæŒä¹…å·ã€‚
- æœ¬åœ°å·ç›´æ¥å®‰è£…åˆ° Stateful Pod ä¸­ï¼Œæ•°æ®è·¯å¾„ä¸­æ²¡æœ‰æ¥è‡ª OpenEBS çš„ä»»ä½•é¢å¤–å¼€é”€ï¼Œä»è€Œå‡å°‘äº†å»¶è¿Ÿã€‚
- OpenEBS ä¸ºæœ¬åœ°å·æä¾›äº†é¢å¤–çš„å·¥å…·ï¼Œç”¨äºç›‘æ§ã€å¤‡ä»½/æ¢å¤ã€ç¾éš¾æ¢å¤ã€ZFS æˆ– LVM æ”¯æŒçš„å¿«ç…§ã€åŸºäºå®¹é‡çš„è°ƒåº¦ç­‰ã€‚



åœ¨åˆ†å¸ƒå¼ï¼ˆåˆåå¤åˆ¶ï¼‰å·çš„æƒ…å†µä¸‹ï¼š

- OpenEBS ä½¿ç”¨å…¶å¼•æ“ä¹‹ä¸€ï¼ˆMayastorã€cStor æˆ– Jivaï¼‰ä¸ºæ¯ä¸ªåˆ†å¸ƒå¼æŒä¹…å·åˆ›å»ºå¾®æœåŠ¡ã€‚
- Stateful Pod å°†æ•°æ®å†™å…¥ OpenEBS å¼•æ“ï¼Œè¿™äº›å¼•æ“å°†æ•°æ®åŒæ­¥å¤åˆ¶åˆ°é›†ç¾¤ä¸­çš„å¤šä¸ªèŠ‚ç‚¹ã€‚OpenEBS å¼•æ“æœ¬èº«éƒ¨ç½²ä¸º podï¼Œç”± Kubernetes ç¼–æ’ã€‚å½“è¿è¡Œæœ‰çŠ¶æ€ pod çš„èŠ‚ç‚¹å‘ç”Ÿæ•…éšœæ—¶ï¼Œè¯¥ pod å°†è¢«é‡æ–°è°ƒåº¦åˆ°é›†ç¾¤ä¸­çš„å¦ä¸€ä¸ªèŠ‚ç‚¹ï¼ŒOpenEBS ä½¿ç”¨å…¶ä»–èŠ‚ç‚¹ä¸Šçš„å¯ç”¨æ•°æ®å‰¯æœ¬æä¾›å¯¹æ•°æ®çš„è®¿é—®ã€‚
- Stateful Pod ä½¿ç”¨ iSCSIï¼ˆcStor å’Œ Jivaï¼‰æˆ– NVMeoFï¼ˆMayastorï¼‰è¿æ¥åˆ° OpenEBS åˆ†å¸ƒå¼æŒä¹…å·ã€‚
- OpenEBS cStor å’Œ Jiva ä¸“æ³¨äºå­˜å‚¨çš„æ˜“ç”¨æ€§å’Œè€ç”¨æ€§ã€‚è¿™äº›å¼•æ“åˆ†åˆ«ä½¿ç”¨å®šåˆ¶ç‰ˆæœ¬çš„ ZFS å’Œ Longhorn æŠ€æœ¯å°†æ•°æ®å†™å…¥å­˜å‚¨ã€‚
- OpenEBS Mayastor æ˜¯æœ€æ–°çš„å¼•æ“ï¼Œä»¥è€ç”¨æ€§å’Œæ€§èƒ½ä¸ºè®¾è®¡ç›®æ ‡è€Œå¼€å‘ï¼›OpenEBS Mayastor æœ‰æ•ˆåœ°ç®¡ç†è®¡ç®—ï¼ˆhugepagesã€å†…æ ¸ï¼‰å’Œå­˜å‚¨ï¼ˆNVMe é©±åŠ¨å™¨ï¼‰ä»¥æä¾›å¿«é€Ÿçš„åˆ†å¸ƒå¼å—å­˜å‚¨ã€‚



OpenEBS è´¡çŒ®è€…æ›´å–œæ¬¢å°†åˆ†å¸ƒå¼å—å­˜å‚¨å·ç§°ä¸º**å¤åˆ¶å·**ï¼Œä»¥é¿å…ä¸ä¼ ç»Ÿçš„åˆ†å¸ƒå¼å—å­˜å‚¨æ··æ·†ï¼ŒåŸå› å¦‚ä¸‹ï¼š

- åˆ†å¸ƒå¼å—å­˜å‚¨å€¾å‘äºå°†å·çš„æ•°æ®å—åˆ†ç‰‡åˆ°é›†ç¾¤ä¸­çš„å¤šä¸ªèŠ‚ç‚¹ä¸Šã€‚å¤åˆ¶å·å°†å·çš„æ‰€æœ‰æ•°æ®å—ä¿å­˜åœ¨èŠ‚ç‚¹ä¸Šï¼Œå¹¶ä¸”ä¸ºäº†æŒä¹…æ€§å°†æ•´ä¸ªæ•°æ®å¤åˆ¶åˆ°é›†ç¾¤ä¸­çš„å…¶ä»–èŠ‚ç‚¹ã€‚
- åœ¨è®¿é—®å·æ•°æ®æ—¶ï¼Œåˆ†å¸ƒå¼å—å­˜å‚¨ä¾èµ–äºå…ƒæ•°æ®å“ˆå¸Œç®—æ³•æ¥å®šä½å—æ‰€åœ¨çš„èŠ‚ç‚¹ï¼Œè€Œå¤åˆ¶å·å¯ä»¥ä»ä»»ä½•æŒä¹…ä¿å­˜æ•°æ®çš„èŠ‚ç‚¹ï¼ˆä¹Ÿç§°ä¸ºå‰¯æœ¬èŠ‚ç‚¹ï¼‰è®¿é—®æ•°æ®ã€‚
- ä¸ä¼ ç»Ÿçš„åˆ†å¸ƒå¼å—å­˜å‚¨ç›¸æ¯”ï¼Œå¤åˆ¶å·çš„çˆ†ç‚¸åŠå¾„æ›´å°ã€‚
- å¤åˆ¶å·ä¸“ä¸ºäº‘åŸç”Ÿæœ‰çŠ¶æ€å·¥ä½œè´Ÿè½½è€Œè®¾è®¡ï¼Œè¿™äº›å·¥ä½œè´Ÿè½½éœ€è¦å¤§é‡å®¹é‡çš„å·ï¼Œè¿™äº›å®¹é‡é€šå¸¸å¯ä»¥ä»å•ä¸ªèŠ‚ç‚¹æä¾›æœåŠ¡ï¼Œè€Œä¸æ˜¯æ•°æ®åœ¨é›†ç¾¤ä¸­çš„å¤šä¸ªèŠ‚ç‚¹ä¹‹é—´åˆ†ç‰‡çš„å•ä¸ªå¤§å·ã€‚
- å¤åˆ¶å·æ˜¯å°†å…¶æ•°æ®åŒæ­¥å¤åˆ¶åˆ°å¤šä¸ªèŠ‚ç‚¹çš„å·ã€‚å¤åˆ¶å·å¯ä»¥æ‰¿å—èŠ‚ç‚¹æ•…éšœã€‚è¿˜å¯ä»¥è·¨å¯ç”¨æ€§åŒºåŸŸè®¾ç½®å¤åˆ¶ï¼Œå¸®åŠ©åº”ç”¨ç¨‹åºè·¨å¯ç”¨æ€§åŒºåŸŸç§»åŠ¨ã€‚



##### **å‚¨å­˜å¼•æ“**

OpenEBS æœ‰ä¸‰ç§å‚¨å­˜å¼•æ“ï¼Œä¸åŒçš„å¼•æ“èƒ½æä¾›ä¸åŒçš„åŠŸèƒ½ã€‚

- [Mayastor](https://wiki.pha.pub/Mayastor)
- [cStor](https://openebs.io/docs/concepts/cstor)
- [Jiva](https://openebs.io/docs/concepts/jiva)

è¶…é“¾æ¥å†…æœ‰è¯¦ç»†ä»‹ç»ã€‚

é™¤äº†è¿™ä¸‰ç§å¼•æ“ï¼Œè¿˜æœ‰ Local PVï¼Œä¸å¤ªç®—å­˜å‚¨å¼•æ“ã€‚
Local PV æ„å‘³ç€å­˜å‚¨åªèƒ½ä»å•ä¸ªèŠ‚ç‚¹ä½¿ç”¨ã€‚Local PV è¡¨ç¤ºå·²æŒ‚è½½çš„æœ¬åœ°å­˜å‚¨è®¾å¤‡ï¼Œä¾‹å¦‚ç£ç›˜ã€åˆ†åŒºæˆ–ç›®å½•ã€‚

ä»¥ä¸‹è¡¨æ ¼éƒ¨åˆ†æ‘˜è‡ª https://zhuanlan.zhihu.com/p/519172233

| ç‰¹æ€§                 | Jiva  | cStor    | Local PV | Mayastor |
| -------------------- | ----- | -------- | -------- | -------- |
| è½»é‡çº§è¿è¡Œäºç”¨æˆ·ç©ºé—´ | Yes   | Yes      | Yes      | æµ‹è¯•ä¸­   |
| åŒæ­¥å¤åˆ¶             | Yes   | Yes      | No       |          |
| é€‚åˆä½å®¹é‡å·¥ä½œè´Ÿè½½   | Yes   | Yes      | Yes      |          |
| æ”¯æŒå¿«ç…§ï¼Œå…‹éš†       | Basic | Advanced | No       |          |
| æ•°æ®ä¸€è‡´æ€§           | Yes   | Yes      | NA       |          |
| ä½¿ç”¨ Velero æ¢å¤å¤‡ä»½ | Yes   | Yes      | Yes      |          |
| é€‚åˆé«˜å®¹é‡å·¥ä½œè´Ÿè½½   | No    | Yes      | Yes      |          |
| è‡ªåŠ¨ç²¾ç®€é…ç½®         |       | Yes      | No       |          |
| ç£ç›˜æ± æˆ–èšåˆæ”¯æŒ     |       | Yes      | No       |          |
| åŠ¨æ€æ‰©å®¹             |       | Yes      | Yes      |          |
| æ•°æ®å¼¹æ€§ (RAID æ”¯æŒ) |       | Yes      | No       |          |
| æ¥è¿‘åŸç”Ÿç£ç›˜æ€§èƒ½     | No    | No       | Yes      |          |

| åº”ç”¨éœ€æ±‚                                         | å­˜å‚¨ç±»å‹                          | OpenEBS å·ç±»å‹                                               |
| ------------------------------------------------ | --------------------------------- | ------------------------------------------------------------ |
| ä½æ—¶å»¶ã€é«˜å¯ç”¨æ€§ã€åŒæ­¥å¤åˆ¶ã€å¿«ç…§ã€å…‹éš†ã€ç²¾ç®€é…ç½® | æœªæ ¼å¼åŒ–çš„å—è®¾å¤‡ (SSD/HDD/äº‘ç¡¬ç›˜) | OpenEBS Mayastor                                             |
| é«˜å¯ç”¨æ€§ã€åŒæ­¥å¤åˆ¶ã€å¿«ç…§ã€å…‹éš†ã€ç²¾ç®€é…ç½®         | æœªæ ¼å¼åŒ–çš„å—è®¾å¤‡ (SSD/HDD/äº‘ç¡¬ç›˜) | OpenEBS cStor                                                |
| é«˜å¯ç”¨æ€§ã€åŒæ­¥å¤åˆ¶ã€ç²¾ç®€é…ç½®                     | ä¸»æœºè·¯å¾„æˆ–å¤–éƒ¨æŒ‚è½½å­˜å‚¨            | OpenEBS Jiva                                                 |
| ä½æ—¶å»¶ã€æœ¬åœ° PV                                  | ä¸»æœºè·¯å¾„æˆ–å¤–éƒ¨æŒ‚è½½å­˜å‚¨            | Dynamic Local PV - Hostpath, Dynamic Local PV - Rawfile      |
| ä½æ—¶å»¶ã€æœ¬åœ° PV                                  | æœªæ ¼å¼åŒ–çš„å—è®¾å¤‡ (SSD/HDD/äº‘ç¡¬ç›˜) | Dynamic Local PV - Device                                    |
| ä½å»¶è¿Ÿï¼Œæœ¬åœ° PVï¼Œå¿«ç…§ï¼Œå…‹éš†                      | æœªæ ¼å¼åŒ–çš„å—è®¾å¤‡ (SSD/HDD/äº‘ç¡¬ç›˜) | OpenEBS Dynamic Local PV - ZFS , OpenEBS Dynamic Local PV - LVM |

å¯¹äºæˆ‘çš„éœ€æ±‚æ¥è¯´ï¼ŒJiva å¯ä»¥ç›´æ¥ä½¿ç”¨ä¸»æœºä¸Šçš„å·²æœ‰è·¯å¾„ï¼Œè€Œå…¶ä»–ä¸¤ä¸ªåˆ™éœ€è¦ä½¿ç”¨ç©ºçš„å—è®¾å¤‡ã€‚
æˆ‘ä¸éœ€è¦éå¸¸é«˜æ€§èƒ½çš„å‚¨å­˜ï¼Œæ·»åŠ æ–°ç¡¬ç›˜ä¹Ÿä¸æ˜¯æƒ³å°±èƒ½æœ‰çš„ï¼Œæ‰€ä»¥é€‰æ‹© Jiva æ˜¯ä¸é”™çš„é€‰æ‹©ã€‚



##### **å…ˆå†³æ¡ä»¶**

- Kubernetes 1.18 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼›
- æ‰€æœ‰å·¥ä½œèŠ‚ç‚¹å®‰è£…å¹¶è¿è¡Œ iscsi-initiator-utils æˆ– open-iscsiï¼›
- æœ‰æƒå°† RBAC ç»„ä»¶å®‰è£…åˆ° kube-system å‘½åç©ºé—´ä¸­ï¼›
- OpenEBS localpv-hostpath 2.6.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼›



##### **å®‰è£… iSCSI initiator utils**

###### **RHEL/CentOS ç³»åˆ—**

åœ¨æ‰€æœ‰å·¥ä½œèŠ‚ç‚¹æ‰§è¡Œ

```bash
sudo yum install iscsi-initiator-utils
sudo systemctl enable --now iscsid
modprobe iscsi_tcp
echo iscsi_tcp >/etc/modules-load.d/iscsi-tcp.conf
```

###### Ubuntu/Debian ç³»åˆ—

åœ¨æ‰€æœ‰å·¥ä½œèŠ‚ç‚¹æ‰§è¡Œ

```bash
# 1. å®‰è£… iscsi initiator å·¥å…·åŒ…
sudo apt update
sudo apt install -y open-iscsi

# 2. å¯ç”¨å¹¶å¯åŠ¨ iscsid æœåŠ¡
sudo systemctl enable --now iscsid

# 3. åŠ è½½å†…æ ¸æ¨¡å— iscsi_tcpï¼ˆå¦‚æœæœªè‡ªåŠ¨åŠ è½½ï¼‰
sudo modprobe iscsi_tcp

# 4. è®¾ç½®å¼€æœºè‡ªåŠ¨åŠ è½½è¯¥æ¨¡å—
echo iscsi_tcp | sudo tee /etc/modules-load.d/iscsi-tcp.conf
```



**é€šè¿‡ Helm å®‰è£…**

æ·»åŠ æºï¼š

```bash
helm repo add openebs https://openebs.github.io/charts
helm repo update
```

ä½¿ç”¨ CSI é©±åŠ¨ç¨‹åºå®‰è£… Jivaï¼š

```bash
helm install openebs openebs/openebs --namespace openebs --create-namespace \
--set legacy.enabled=false \
--set jiva.enabled=true \
--set openebs-ndm.enabled=true \
--set localpv-provisioner.enabled=true \
--set jiva.defaultStoragePath=/var/openebs \
--set image.repository=k8s-gcr.m.daocloud.io
```

- `legacy.enabled=false` ç¦ç”¨æ—§çš„ out-of-tree æ ‘å¤–ç»„ä»¶ï¼›
- `jiva.enabled=true` å¯ç”¨ Jivaï¼›
- `openebs-ndm.enabled=true` å¯ç”¨ ndmï¼›
- `localpv-provisioner.enabled=true` å¯ç”¨Local PV provisionerï¼›
- `jiva.defaultStoragePath=<å‚¨å­˜è·¯å¾„>` è‡ªå®šä¹‰ Jiva å‚¨å­˜ç›®å½•ï¼Œé»˜è®¤ /var/openebsï¼›
- `image.repository=<æºåœ°å€>` è‡ªå®šä¹‰æºåœ°å€ï¼Œé»˜è®¤ä¸º k8s.gcr.ioï¼Œæ­¤å¤„è®¾ç½®ä¸º Daocloud é•œåƒï¼›

æ­¤å‘½ä»¤ä¼šåœ¨ openebs å‘½åç©ºé—´å†…å®‰è£… OpenEBS Jiva å’Œ Local PV ç»„ä»¶ã€‚



##### **éªŒè¯ OpenEBS å®‰è£…**

ä½¿ç”¨ `kubectl get pods -n openebs -o wide` ä½ åº”è¯¥èƒ½çœ‹åˆ°æœ‰ä»¥ä¸‹å‡ ç§ pod æ­£åœ¨å…¨æ•°æ­£å¸¸è¿è¡Œã€‚

```bash
[root@master-01 ~]#kubectl get pods -n openebs -o wide
NAME                                           READY   STATUS    RESTARTS      AGE   IP              NODE             NOMINATED NODE   READINESS GATES
openebs-jiva-csi-controller-0                  5/5     Running   8 (30m ago)   93m   10.200.129.17   k8s-10-0-0-213   <none>           <none>
openebs-jiva-csi-node-582gn                    3/3     Running   3 (55m ago)   93m   10.0.0.203      k8s-10-0-0-203   <none>           <none>
openebs-jiva-csi-node-j97w8                    3/3     Running   0             19m   10.0.0.201      master-01        <none>           <none>
openebs-jiva-csi-node-l2v9x                    3/3     Running   3 (50m ago)   93m   10.0.0.212      worker-02        <none>           <none>
openebs-jiva-csi-node-p9k64                    3/3     Running   3 (58m ago)   93m   10.0.0.202      master-02        <none>           <none>
openebs-jiva-csi-node-qwlz5                    3/3     Running   3 (50m ago)   93m   10.0.0.213      k8s-10-0-0-213   <none>           <none>
openebs-jiva-csi-node-tx4n8                    3/3     Running   3 (51m ago)   93m   10.0.0.211      worker-01        <none>           <none>
openebs-jiva-operator-6f9649578b-vzgq9         1/1     Running   2 (49m ago)   93m   10.200.171.28   worker-01        <none>           <none>
openebs-localpv-provisioner-574c44f48c-zfnpq   1/1     Running   5 (30m ago)   93m   10.200.37.204   worker-02        <none>           <none>
openebs-ndm-9p2dg                              1/1     Running   2 (52m ago)   93m   10.0.0.202      master-02        <none>           <none>
openebs-ndm-g9tp6                              1/1     Running   1 (50m ago)   93m   10.0.0.212      worker-02        <none>           <none>
openebs-ndm-m7jjs                              1/1     Running   1 (50m ago)   93m   10.0.0.213      k8s-10-0-0-213   <none>           <none>
openebs-ndm-mrbdl                              1/1     Running   1 (55m ago)   93m   10.0.0.203      k8s-10-0-0-203   <none>           <none>
openebs-ndm-operator-6c5cb7b544-8kcjw          1/1     Running   2 (49m ago)   93m   10.200.171.30   worker-01        <none>           <none>
openebs-ndm-z6zh2                              1/1     Running   1 (51m ago)   93m   10.0.0.211      worker-01        <none>           <none>
openebs-ndm-z8dmr                              1/1     Running   2 (64m ago)   93m   10.0.0.201      master-01        <none>           <none>
```

å¦‚æœä¸€ç›´ ContainerCreatingï¼Œå¤§æ¦‚ç‡æ˜¯é•œåƒé—®é¢˜ã€‚
å®‰è£…æ—¶åˆ«å¿˜äº†è®¾ç½®é•œåƒï¼Œé»˜è®¤çš„ k8s.gcr.io å¤§é™†æ— æ³•è®¿é—®ã€‚

**éªŒè¯å‚¨å­˜ç±»**

ä½¿ç”¨ `kubectl get sc` ä½ åº”è¯¥èƒ½çœ‹åˆ°ä¸€ä¸‹å‡ ç§ StorageClasses

```bash
[root@master-01 ~]#kubectl get sc
NAME                       PROVISIONER           RECLAIMPOLICY   VOLUMEBINDINGMODE
openebs-device             openebs.io/local      Delete          WaitForFirstConsu
openebs-hostpath           openebs.io/local      Delete          WaitForFirstConsu
openebs-jiva-csi-default   jiva.csi.openebs.io   Delete          Immediate
```

- `openebs-jiva-csi-default` ç”¨äºé…ç½® jiva å·ï¼Œæ­¤ç±»é»˜è®¤å°±ä¼šå¤åˆ¶ï¼›
- `openebs-hostpath` ç”¨äºåœ¨ä¸»æœºè·¯å¾„ä¸Šé…ç½®æœ¬åœ° PVï¼Œä¸ä¼šå¤åˆ¶ï¼›
- `openebs-device` ç”¨äºåœ¨è®¾å¤‡ä¸Šé…ç½®æœ¬åœ° PVï¼Œä¸ä¼šå¤åˆ¶ï¼›



##### **ç®€å•æµ‹è¯•**

åˆ›å»ºä¸€ä¸ª PVC

```yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: example-jiva-csi-pvc
spec:
  storageClassName: openebs-jiva-csi-default
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 4Gi
```

```ABAP
Pod ä¸€å¾‹é€šè¿‡ Target Pod æ¥è®¿é—®å·æ•°æ®ï¼Œæ•°æ®ä¸ä¼šç›´æ¥ä»å‰¯æœ¬ä¸­â€œå°±è¿‘æå–â€ï¼›
```



##### å·ç­–ç•¥

å¦‚æœä½ ä¸æƒ³ç”¨é»˜è®¤çš„å·å¤åˆ¶ç­–ç•¥ï¼Œæˆ–æ˜¯éœ€è¦è°ƒæ•´èµ„æºé™åˆ¶ã€å®¹å¿è¯»ã€èŠ‚ç‚¹é€‰æ‹©å™¨ç­‰ï¼Œä½ å¯ä»¥åˆ›å»º JivaVolumePolicyï¼ˆJVPï¼‰ã€‚

```yaml
apiVersion: openebs.io/v1alpha1
kind: JivaVolumePolicy
metadata:
  name: example-jivavolumepolicy
  namespace: openebs
spec:
  replicaSC: openebs-hostpath
  target:
    # This sets the number of replicas for high-availability
    # replication factor <= no. of (CSI) nodes
    replicationFactor: 3
    # disableMonitor: false
    # auxResources:
    # tolerations:
    # resources:
    # affinity:
    # nodeSelector:
    # priorityClassName:
  # replica:
    # tolerations:
    # resources:
    # affinity:
    # nodeSelector:
    # priorityClassName:
```

ç„¶åä½¿ç”¨ JVP åˆ›å»ºæ–°çš„å‚¨å­˜ç±»ï¼š

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: openebs-jiva-csi-sc
provisioner: jiva.csi.openebs.io
allowVolumeExpansion: true
parameters:
  cas-type: "jiva"
  policy: "example-jivavolumepolicy"
```



##### æŸ¥çœ‹é»˜è®¤jvp

```yaml
[root@master1 ~] # kubectl get jivavolumepolicies.openebs.io openebs-jiva-default-policy  -n openebs -o yaml
apiVersion: openebs.io/v1
kind: JivaVolumePolicy
metadata:
  annotations:
    meta.helm.sh/release-name: openebs
    meta.helm.sh/release-namespace: openebs
  creationTimestamp: "2025-04-10T13:06:17Z"
  generation: 1
  labels:
    app.kubernetes.io/managed-by: Helm
  name: openebs-jiva-default-policy
  namespace: openebs
  resourceVersion: "209691"
  uid: 0d7baeb1-1e12-4225-aad1-41d445fa42b2
spec:
  replicaSC: openebs-hostpath
  target:
    replicationFactor: 3       # é»˜è®¤å‰¯æœ¬æ•°
```

**ä¹Ÿå¯ä»¥åœ¨åˆ›å»ºpvcçš„æ—¶å€™æŒ‡å®šå‰¯æœ¬æ•°**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: example-jiva-csi-pvc
  annotations:
    openebs.io/capacity: "2Gi"
    openebs.io/replica-count: "3"
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: openebs-jiva-csi-default
  resources:
    requests:
      storage: 2Gi
```







## Kubernetesé…ç½®ç®¡ç†



**æ–‡ç« å†…å­˜**

- **é…ç½®è¯´æ˜**
- **ConfigMap**
- **Secret**
- **downwardAPI**
- **Projected**





### é…ç½®è¯´æ˜

kubernetesæä¾›äº†å¯¹ Pod å®¹å™¨åº”ç”¨å¯ä»¥å®ç°é›†ä¸­å¼çš„é…ç½®ç®¡ç†åŠŸèƒ½çš„ç›¸å…³èµ„æºï¼š

- ConfigMap
- Secret
- downwardAPI
- Projected 



é€šè¿‡è¿™äº›ç»„ä»¶æ¥å®ç°å‘podä¸­çš„å®¹å™¨åº”ç”¨ä¸­æ³¨å…¥é…ç½®ä¿¡æ¯çš„æœºåˆ¶ï¼Œä»è€Œé¿å…äº†å¼€å‘è€…å‚ä¸

æ³¨æ„ï¼š**å¯¹äºè¿è¡Œä¸­å®¹å™¨çš„é…ç½®æ”¹å˜ï¼Œè¿˜éœ€è¦é€šè¿‡åº”ç”¨ç¨‹åºé‡è½½ç›¸å…³é…ç½®æ‰èƒ½ç”Ÿæ•ˆ**





#### é…ç½®ç»„ä»¶ç®€ä»‹

**configMap**

Configmapæ˜¯Kubernetesé›†ç¾¤ä¸­éå¸¸é‡è¦çš„ä¸€ç§é…ç½®ç®¡ç†èµ„æºå¯¹è±¡ã€‚

å€ŸåŠ©äºConfigMap APIå¯ä»¥å‘podä¸­çš„å®¹å™¨ä¸­æ³¨å…¥é…ç½®ä¿¡æ¯ã€‚

ConfigMapä¸ä»…å¯ä»¥ä¿å­˜ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°ç­‰å±æ€§ï¼Œä¹Ÿå¯ä»¥ç”¨æ¥ä¿å­˜æ•´ä¸ªé…ç½®æ–‡ä»¶æˆ–è€…JSONæ ¼å¼çš„ æ–‡ä»¶ã€‚

å„ç§é…ç½®å±æ€§å’Œæ•°æ®ä»¥ k/væˆ–åµŒå¥—k/v æ ·å¼ å­˜åœ¨åˆ°Configmapä¸­

æ³¨æ„ï¼šæ‰€æœ‰çš„é…ç½®ä¿¡æ¯éƒ½æ˜¯**ä»¥æ˜æ–‡çš„æ–¹å¼**æ¥è¿›è¡Œä¿å­˜ï¼Œå®ç°èµ„æºé…ç½®çš„å¿«é€Ÿè·å–æˆ–è€…æ›´æ–°ã€‚



**Secret**

Kubernetesé›†ç¾¤ä¸­ï¼Œæœ‰ä¸€äº›é…ç½®å±æ€§ä¿¡æ¯æ˜¯éå¸¸æ•æ„Ÿçš„ï¼Œæ‰€ä»¥è¿™äº›ä¿¡æ¯åœ¨ä¼ é€’çš„è¿‡ç¨‹ä¸­ï¼Œæ˜¯ä¸å¸Œæœ›å…¶ä»–äººèƒ½å¤Ÿçœ‹åˆ°çš„

Kubernetesæä¾›äº†ä¸€ç§åŠ å¯†åœºæ™¯ä¸­çš„é…ç½®ç®¡ç†èµ„æºå¯¹è±¡Secretã€‚

å®ƒåœ¨è¿›è¡Œæ•°æ®ä¼ è¾“ä¹‹å‰ï¼Œä¼šå¯¹æ•°æ®è¿›è¡Œç¼–ç ï¼Œåœ¨æ•°æ®è·å–çš„æ—¶å€™ï¼Œä¼šå¯¹æ•°æ®è¿›è¡Œè§£ç ã€‚ä»è€Œä¿è¯æ•´ä¸ªæ•° æ®ä¼ è¾“è¿‡ç¨‹çš„å®‰å…¨ã€‚

**æ³¨æ„ï¼šè¿™äº›æ•°æ®é€šå¸¸é‡‡ç”¨Base64æœºåˆ¶ä¿å­˜ï¼Œæ‰€ä»¥å®‰å…¨æ€§ä¸€èˆ¬**



**DownwardAPI**

downwardAPI ä¸ºè¿è¡Œåœ¨podä¸­çš„åº”ç”¨å®¹å™¨æä¾›äº†ä¸€ç§åå‘å¼•ç”¨ã€‚è®©å®¹å™¨ä¸­çš„åº”ç”¨ç¨‹åºäº†è§£æ‰€å¤„podæˆ– Nodeçš„ä¸€äº›åŸºç¡€å¤–éƒ¨å±æ€§ä¿¡æ¯ã€‚

ä»ä¸¥æ ¼æ„ä¹‰ä¸Šæ¥è¯´ï¼ŒdownwardAPIä¸æ˜¯å­˜å‚¨å·ï¼Œå®ƒè‡ªèº«å°±å­˜åœ¨

ç›¸è¾ƒäºconfigmapã€secretç­‰èµ„æºå¯¹è±¡éœ€è¦åˆ›å»ºåæ‰èƒ½ä½¿ç”¨ï¼Œè€ŒdownwardAPIå¼•ç”¨çš„æ˜¯Podè‡ªèº«çš„è¿è¡Œç¯å¢ƒä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯åœ¨Podå¯åŠ¨çš„æ—¶å€™å°±å­˜åœ¨



 **Projected**

ä¸€ä¸ª projected Volumes æŠ•å°„å·å¯ä»¥å°†è‹¥å¹²ç°æœ‰çš„å·æºæ˜ å°„åˆ°åŒä¸€ä¸ªç›®å½•ä¹‹ä¸Šã€‚







### ConfigMap



#### ConfigMapè¯´æ˜

Kubernetesæä¾›äº†å¯¹podä¸­å®¹å™¨åº”ç”¨çš„é›†ä¸­é…ç½®ç®¡ç†ç»„ä»¶ï¼šConfigMapã€‚

é€šè¿‡ConfigMapæ¥å®ç°å‘podä¸­çš„å®¹å™¨ä¸­æ³¨å…¥é…ç½®ä¿¡æ¯çš„æœºåˆ¶ã€‚

å¯ä»¥æŠŠconfigmapç†è§£ä¸ºLinuxç³»ç»Ÿä¸­çš„/etcç›®å½•ï¼Œä¸“é—¨ç”¨æ¥å­˜å‚¨é…ç½®æ–‡ä»¶çš„ç›®å½•

Kuberneteså€ŸåŠ©äºConfigMapå¯¹è±¡å®ç°äº†å°†é…ç½®ä¿¡æ¯ä»å®¹å™¨é•œåƒä¸­è§£è€¦ï¼Œä»è€Œå¢å¼ºäº†å·¥ä½œè´Ÿè½½çš„å¯ç§»æ¨Ÿ æ€§ã€ä½¿å…¶é…ç½®æ›´æ˜“äºæ›´æ”¹å’Œç®¡ç†å¹¶é¿å…äº†å°†é…ç½®æ•°æ®ç¡¬ç¼–ç åˆ°Podé…ç½®æ¸…å•ä¸­

**ConfigMapä¸ä»…ä»…å¯ä»¥ä¿å­˜å•ä¸ªå±æ€§ï¼Œä¹Ÿå¯ä»¥ç”¨æ¥ä¿å­˜æ•´ä¸ªé…ç½®æ–‡ä»¶ã€‚**

ä»Kubernetes v1.19ç‰ˆæœ¬å¼€å§‹ï¼ŒConfigMapå’ŒSecretæ”¯æŒä½¿ç”¨**immutableå­—æ®µ**åˆ›å»ºä¸å¯å˜å®ä¾‹ï¼Œå®ç°ä¸ å¯å˜åŸºç¡€è®¾æ–½æ•ˆæœ



##### åŸºæœ¬å±æ€§

```bash
# kubectl explain cm
    binaryData              # äºŒè¿›åˆ¶æ•°æ®
    data                    # æ–‡æœ¬æ•°æ®ï¼Œæ”¯æŒå˜é‡å’Œæ–‡ä»¶
    immutable <boolean>     # è®¾ä¸ºtrueï¼Œä¸èƒ½è¢«ä¿®æ”¹åªèƒ½åˆ é™¤ï¼Œé»˜è®¤ä¸ºnilå¯ä»¥éšæ—¶è¢«ä¿®æ”¹
    
#æ³¨æ„ï¼šåŸºäºdataçš„æ–¹å¼ä¼ é€’ä¿¡æ¯çš„è¯ï¼Œä¼šåœ¨podçš„å®¹å™¨å†…éƒ¨ç”Ÿæˆä¸€ä¸ªå•ç‹¬çš„æ•°æ®æ–‡ä»¶    
```



##### æ•°æ®é…ç½®çš„æ ¼å¼

```bash
#å•è¡Œé…ç½®æ•°æ®æ ¼å¼
å±æ€§åç§°key: å±æ€§å€¼value   #å•è¡Œé…ç½®å†…å®¹ï¼Œä¸€èˆ¬ä¿å­˜å˜é‡ï¼Œå‚æ•°ç­‰
æ–‡ä»¶åï¼šå•è¡Œå†…å®¹            #é…ç½®æ–‡ä»¶å¦‚æœåªæœ‰ä¸€è¡Œï¼Œä¹Ÿä½¿ç”¨æ­¤æ–¹å¼ï¼Œkeyä¸ºæ–‡ä»¶åï¼Œvalueä¸ºæ–‡ä»¶å†…å®¹


#å¤šè¡Œæ–‡ä»¶æ•°æ®æ ¼å¼     
æ–‡ä»¶åç§°1: |     #æ³¨æ„ï¼š| æ˜¯"å¤šè¡Œé”®å€¼"çš„æ ‡è¯†ç¬¦
 æ–‡ä»¶å†…å®¹è¡Œ1    #å†…å®¹å¤§å°ä¸èƒ½è¶…è¿‡1M
 æ–‡ä»¶å†…å®¹è¡Œ2
 ......
æ–‡ä»¶åç§°2: |     #æ³¨æ„ï¼š| æ˜¯"å¤šè¡Œé”®å€¼"çš„æ ‡è¯†ç¬¦
 æ–‡ä»¶å†…å®¹è¡Œ1    #å†…å®¹å¤§å°ä¸èƒ½è¶…è¿‡1M
 æ–‡ä»¶å†…å®¹è¡Œ2
 ......
```

configmapèµ„æºç±»å‹çš„åˆ›å»ºï¼Œä¸Kubernetesçš„å…¶ä»–å¾ˆå¤šèµ„æºå¯¹è±¡çš„åˆ›å»ºæ–¹å¼ä¸€æ ·ï¼Œä¸»è¦æ¶‰åŠåˆ°ä¸¤ç§æ–¹å¼ï¼š

- **å‘½ä»¤è¡Œå·¥å…·**ï¼šé…ç½®ä¸­æœ‰å¤§é‡ç®€å•çš„é”®å€¼å¯¹æ—¶å»ºè®®ä½¿ç”¨
- **èµ„æºå®šä¹‰æ–‡ä»¶**ï¼šé…ç½®ä¸ºå¤§é‡æ–‡æœ¬å†…å®¹æ—¶å»ºè®®ä½¿ç”¨ï¼Œæ­¤æ–¹å¼éœ€è¦äº‹å…ˆå‡†å¤‡åœ¨èµ„æºæ¸…å•å…ƒæ–‡ä»¶ä¸­åŠ å…¥é…ç½®æ–‡ä»¶å†…å®¹





é€šå¸¸ä¸ºäº†é¿å…é…ç½®æ›´æ–°åæ²¡æœ‰ç”Ÿæ•ˆçš„é—®é¢˜ï¼Œå¯ä»¥åœ¨æ›´æ–° ConfigMap ä¹‹åï¼Œæ‰‹åŠ¨é‡åˆ›å»ºç›¸å…³çš„ Pod æˆ–è€… Deployment

- è¿ç»´æ–¹å¼ï¼šå¯ä»¥é€šè¿‡ **é‡å¯** æˆ– **é‡å»º** çš„æ–¹å¼ 
  - ä½¿ç”¨ kubectl rollout restart å‘½ä»¤æ¥é‡å¯ Deployment 
  - ä½¿ç”¨ kubectl delete pod å‘½ä»¤æ¥åˆ é™¤ Podï¼Œä»è€Œè§¦å‘ Pod çš„é‡å¯



#### ConfigMapåˆ›å»ºå’Œæ›´æ–°

##### å‘½ä»¤è¡Œåˆ›å»ºæ–¹å¼

```bash
# åˆ›å»ºå‘½ä»¤æ ¼å¼
kubectl create configmap NAME [--from-file=[key=]source] [--from-literal=key1=value1] [--dry-run=server|client|none] [-n <namespace>] [options]

# å‚æ•°è¯¦è§£ï¼š
--from-literal=key1=value1          #ä»¥è®¾ç½®é”®å€¼å¯¹çš„æ–¹å¼å®ç°å˜é‡é…ç½®æ•°æ®
--from-env-file=/PATH/TO/FILE       #ä»¥ç¯å¢ƒå˜é‡ä¸“ç”¨æ–‡ä»¶çš„æ–¹å¼å®ç°é…ç½®æ•°æ®
--from-file=[key=]/PATH/TO/FILE     #ä»¥é…ç½®æ–‡ä»¶çš„æ–¹å¼åˆ›å»ºé…ç½®æ–‡ä»¶æ•°æ®ï¼Œå¦‚ä¸æŒ‡å®škeyï¼ŒFILEåç§°ä¸ºkeyå
--from-file=/PATH/TO/DIR            #ä»¥é…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„æ–¹å¼åˆ›å»ºé…ç½®æ–‡ä»¶æ•°æ®

--dry-run=client -o yaml            #æµ‹è¯•è¿è¡Œå¹¶æ˜¾ç¤ºcmå†…å®¹


#æŸ¥çœ‹configmap
kubectl create configmap <cm_name> -n <namespace> [-o yaml] --dry-run=client
kubectl get configmap <cm_name> -n <namespace>
kubectl describe configmap <cm_name> -n <namespace>


#åˆ é™¤configmap
kubectl delete configmap <cm_name> [-n <namespace>]
```



##### **å‘½ä»¤è¡Œåˆ›å»ºæ–¹å¼æ¡ˆä¾‹**



**èŒƒä¾‹ï¼šå‘½ä»¤è¡Œåˆ›å»ºåŸºäºkey/valueå½¢å¼çš„å˜é‡é…ç½®**

```bash
# åœ¨ä½¿ç”¨kubectlåˆ›å»ºçš„æ—¶å€™ï¼Œé€šè¿‡åœ¨å‘½ä»¤è¡Œç›´æ¥ä¼ é€’é”®å€¼å¯¹åˆ›å»º
[root@master1 ~]#kubectl create configmap cm-test1 --from-literal=key1='value1' --from-literal=key2='value2'

# æŸ¥çœ‹
[root@master1 nsf-provisioner]#kubectl get cm
NAME               DATA   AGE
cm-test1           2      7s
kube-root-ca.crt   1      3d1h

# æŸ¥çœ‹yamlæ¸…å•
[root@master1 nsf-provisioner]#kubectl get cm cm-test1 -o yaml
apiVersion: v1
data:
  key1: value1
  key2: value2
kind: ConfigMap
metadata:
  creationTimestamp: "2024-12-31T09:27:23Z"
  name: cm-test1
  namespace: default
  resourceVersion: "165446"
  uid: 8f831d4c-3b2d-4058-ae76-342c819f38a3

# æŸ¥çœ‹describe
[root@master1 nsf-provisioner]#kubectl describe cm cm-test1 
Name:         cm-test1
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
key1:
----
value1
key2:
----
value2

BinaryData
====

Events:  <none>

# åˆ é™¤cm
[root@master1 nsf-provisioner]#kubectl delete cm cm-test1 
configmap "cm-test1" deleted
```



**èŒƒä¾‹: å‘½ä»¤è¡Œåˆ›å»ºåŸºäºkey/valueå½¢å¼çš„å˜é‡é…ç½®**

```bash
[root@master1 ~]# kubectl create configmap pod-test-config --from-literal=host="127.0.0.1" --from-literal=port="8888"
configmap/pod-test-config created

# æŸ¥çœ‹
[root@master1 ~]# kubectl get cm
NAME               DATA   AGE
kube-root-ca.crt   1      3d22h
pod-test-config    2      5s

# è¾“å‡ºæ¸…å•
[root@master1 ~]# kubectl get cm pod-test-config -o yaml;
apiVersion: v1
data:
  host: 127.0.0.1
  port: "8888"
kind: ConfigMap
metadata:
  creationTimestamp: "2025-01-01T06:27:29Z"
  name: pod-test-config
  namespace: default
  resourceVersion: "197278"
  uid: 297b056b-8fa0-42e3-8394-93470a208147
```



**èŒƒä¾‹: å‘½ä»¤è¡Œåˆ›å»ºåŸºäºç¯å¢ƒå˜é‡æ–‡ä»¶çš„å˜é‡é…ç½®**

```bash
# å¦‚æœå˜é‡è¾ƒå¤šï¼Œä½¿ç”¨ä¸Šé¢æ–¹å¼ä¸€ä¸ªä¸ªçš„è®¾å®šç¯å¢ƒå˜é‡å¤ªç¹çï¼Œå¯ä»¥å…¨éƒ¨æ·»åŠ åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸­ç„¶ååŸºäºå®ƒæ¥åˆ›å»ºCM
# å®šåˆ¶ç¯å¢ƒå˜é‡æ–‡ä»¶
[root@master1 conf.d]#cat env
key1=value1
key2=value2

# æ³¨æ„ï¼šenvæ–‡ä»¶ä¸­æ‰€æœ‰çš„é…ç½®é¡¹ä»¥â€œå±æ€§å=å±æ€§å€¼â€æ ¼å¼å®šåˆ¶

# å°†æ‰€æœ‰ç¯å¢ƒå˜é‡æ·»åŠ åˆ°configmapä¸­
[root@master1 conf.d]# kubectl create configmap cm-test2 --from-env-file=./env 
configmap/cm-test2 created

# æŸ¥çœ‹æ¸…å•æ–‡ä»¶
[root@master1 conf.d]# kubectl get cm cm-test2 -o yaml
apiVersion: v1
data:
  key1: value1
  key2: value2
kind: ConfigMap
metadata:
  creationTimestamp: "2025-01-01T06:32:42Z"
  name: cm-test2
  namespace: default
  resourceVersion: "197783"
  uid: e3a193ae-5093-4822-9c34-3b212fafc473

# åˆ é™¤cm
[root@master1 conf.d]# kubectl delete cm pod-test-config 
configmap "pod-test-config" deleted
```



**èŒƒä¾‹ï¼šå‘½ä»¤è¡Œåˆ›å»ºåŸºäºé…ç½®æ–‡ä»¶çš„æ–‡ä»¶å½¢å¼CM**

```bash
# ç›´æ¥å°†å¤šä¸ªé…ç½®æ–‡ä»¶åˆ›å»ºä¸ºä¸€ä¸ªConfigMap
[root@master1 ~]# ls conf.d/
app1.conf app2.conf app3.conf

[root@master1 ~]# cat conf.d/app1.conf
[app1]
config1

[root@master1 ~]# cat conf.d/app2.conf
[app2]
config2

#æ–‡ä»¶åè‡ªåŠ¨æˆä¸ºkeyå
[root@master1 conf.d]#kubectl create configmap cm-test3 --from-file=./app1.conf --from-file=./app2.conf 
configmap/cm-test3 created

# æŸ¥çœ‹
[root@master1 conf.d]#kubectl get cm cm-test3 -o yaml
apiVersion: v1
data:
  app1.conf: |
    [app1]
    config1
  app2.conf: |
    [app2]
    config2
kind: ConfigMap
metadata:
  creationTimestamp: "2025-01-01T06:36:45Z"
  name: cm-test3
  namespace: default
  resourceVersion: "198174"
  uid: ee772063-dd7d-4ed5-acab-74423104695b
  
# åˆ é™¤CM
[root@master1 conf.d]#kubectl delete cm cm-test3 
configmap "cm-test3" deleted
```



**èŒƒä¾‹: å‘½ä»¤è¡Œåˆ›å»ºåŸºäºç›®å½•çš„CM**

```bash
[root@master1 conf.d]# ls
app1.conf  app2.conf  app3.conf

[root@master1 conf.d]#cat *
[app1]
config1
[app2]
config2
[app3]
config3

#ç›´æ¥å°†ä¸€ä¸ªç›®å½•ä¸‹çš„æ‰€æœ‰é…ç½®æ–‡ä»¶åˆ›å»ºä¸ºä¸€ä¸ªConfigMap
[root@master1 cm]#kubectl create cm cm-test4 --from-file=./conf.d/
configmap/cm-test4 created

#ç»“æœæ˜¾ç¤ºï¼šå¤šä¸ªæ–‡ä»¶ä¹‹é—´ï¼Œå±æ€§åæ˜¯æ–‡ä»¶åï¼Œå±æ€§å€¼æ˜¯æ–‡ä»¶å†…å®¹
[root@master1 cm]#kubectl get cm cm-test4 -o yaml;
apiVersion: v1
data:
  app1.conf: |
    [app1]
    config1
  app2.conf: |
    [app2]
    config2
  app3.conf: |
    [app3]
    config3
kind: ConfigMap
metadata:
  creationTimestamp: "2025-01-01T06:40:19Z"
  name: cm-test4
  namespace: default
  resourceVersion: "198521"
  uid: 4c83e7d6-b191-46a5-b0f4-a1c8b14f905a

# åˆ é™¤CM
[root@master1 ~]#kubectl delete cm cm-test4
```



##### èµ„æºæ¸…å•æ–‡ä»¶åˆ›å»ºæ–¹å¼

**èµ„æºæ¸…å•æ–‡ä»¶å‘½ä»¤æ ¼å¼è¯´æ˜**

```yaml
# æ¸…å•æ–‡ä»¶æ ¼å¼
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm_name
  namespace: default
data:
  key: value          # é…ç½®ä¿¡æ¯å¦‚æœåªæœ‰ä¸€è¡Œï¼Œä¹Ÿä½¿ç”¨æ­¤æ–¹å¼ï¼Œä½¿ç”¨å·æŒ‚è½½æ—¶ï¼Œkeyå³ä¸ºæ–‡ä»¶åï¼Œvalueä¸ºæ–‡ä»¶å†…å®¹
  æ–‡ä»¶åï¼š |
    æ–‡ä»¶å†…å®¹è¡Œ1
    æ–‡ä»¶å†…å®¹è¡Œ2
    ......
# æ³¨æ„ï¼šCMçš„æ¸…å•æ–‡ä»¶æ²¡æœ‰specä¿¡æ¯ï¼Œè€Œæ˜¯data

# å‘½ä»¤å¼ï¼š
kubectl create -f /path/file
# å£°æ˜å¼
kubectl apply -f /path/file
```

æ³¨æ„ï¼šæ­¤æ–¹å¼éœ€è¦äº‹å…ˆå°†é…ç½®æ–‡ä»¶çš„å†…å®¹å…¨éƒ¨å†™å…¥æ¸…å•æ–‡ä»¶ï¼Œè€Œä¸”é…ç½®æ–‡ä»¶çš„æ ¼å¼éœ€è¦è°ƒæ•´æ‰èƒ½åŒ¹é…ï¼Œ æ‰€ä»¥å¾ˆä¸æ–¹ä¾¿ï¼Œæ¨èå¦‚ä¸‹æ–¹å¼è§£å†³

- å…ˆåœ¨å‘½ä»¤è¡Œæ‰§è¡Œæ—¶æŒ‡å®šé…ç½®æ–‡ä»¶çš„æ–¹å¼åˆ›å»º CM
- é€šè¿‡ kubectl get cm  -o yaml > cm.yaml æ–¹å¼å¯¼å‡ºèµ„æºæ¸…å•æ–‡ä»¶
- æˆ–è€… kubectl create configmap NAME --dry-run=client -o yaml > cm.yaml æ–¹å¼å¯¼å‡ºèµ„æºæ¸…å•æ–‡ä»¶
- æœ€åè°ƒæ•´å’Œä¿®æ”¹ä¸Šé¢ç”Ÿæˆçš„ yamlèµ„æºæ¸…å•æ–‡ä»¶



##### èµ„æºæ¸…å•æ–‡ä»¶åˆ›å»ºæ–¹å¼æ¡ˆä¾‹

```yaml
# èµ„æºå®šä¹‰æ–‡ä»¶
[root@master1 cm] # vim storage-configmap-test.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-test
data:
  author: wangxiaochun
  file.conf: |
    [class]
    linux
    go
    java
    
    
# åˆ›å»ºèµ„æºå¯¹è±¡
[root@master1 cm] # kubectl apply -f storage-configmap-test.yaml 
configmap/config-test created

# æŸ¥çœ‹
[root@master1 cm] # kubectl describe cm config-test 
Name:         config-test
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
author:
----
wangxiaochun
file.conf:
----
[class]
linux
go
java


BinaryData
====

Events:  <none>

# å¯ä»¥åœ¨çº¿ä¿®æ”¹
[root@master1 cm] # kubectl edit cm config-test

# åˆ é™¤
[root@master1 cm]#kubectl delete cm config-test 
configmap "config-test" deleted
```



**èŒƒä¾‹: åªè¯»çš„configmap**

```yaml
[root@master1 cm] # vim storage-configmap-immutable-test.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-immutable-test
data:
  author: wangxiaochun
  file.conf: |
    [class]
    linux
    go
    java
immutable: true  # åªè¯»

# åº”ç”¨
[root@master1 cm]#kubectl apply -f storage-configmap-immutable-test.yaml 
configmap/cm-immutable-test created

# æŸ¥çœ‹
[root@master1 cm]#kubectl get cm cm-immutable-test 
NAME                DATA   AGE
cm-immutable-test   2      31s

# åœ¨çº¿ä¿®æ”¹configmapæç¤ºå‡ºé”™
[root@master1 cm]#kubectl edit cm cm-immutable-test 
error: configmaps "cm-immutable-test" is invalid

# å¯ä»¥åˆ é™¤
[root@master1 cm]#kubectl delete cm cm-immutable-test 
configmap "cm-immutable-test" deleted
```



##### åœ¨çº¿æ›´æ–°configmap

æ³¨æ„ï¼šconfigmapè™½ç„¶æ”¯æŒåœ¨çº¿æ›´æ–°ï¼Œä½†æ˜¯configmapæ›´æ–°åå¯èƒ½ä¸ä¼šå¯¹å·²æœ‰çš„Podçš„åº”ç”¨ç”Ÿæ•ˆï¼Œå¯èƒ½ è¿˜éœ€è¦é‡å»ºPodæ‰èƒ½ç”Ÿæ•ˆ

```bash
#åˆ›å»º configmap
[root@master1 ~]#kubectl create cm cm-nginx-conf --from-file=nginx.conf

#ä¿®æ”¹configmap
#æ–¹æ³•1,æ—§ç‰ˆä¸­å¦‚æœé…ç½®å†…å®¹å¦‚æœä¸å¤§,å¤šè¡Œå†…å®¹å¯ä»¥æ˜¾ç¤ºåœ¨ä¸€è¡Œ,ä½†æ­¤æ–¹å¼ä¸æ–¹ä¾¿ä¿®æ”¹,ä½†å¦‚æœè¿‡å¤§,æ­¤æ–¹å¼åª
èƒ½æ˜¾ç¤ºå¤§å°,è€Œéå†…å®¹,æ‰€ä»¥ä¸èƒ½ä¿®æ”¹,æ–°ç‰ˆæ— æ­¤é—®é¢˜
[root@master1 ~]#kubectl edit cm cm-nginx-conf


#æ–¹æ³•2
[root@master1 ~]#kubectl get cm cm-nginx-conf -o yaml > cm-config-conf.yaml
[root@master1 ~]#vim cm-config-conf.yaml
[root@master1 ~]#kubectl apply -f cm-config-conf.yaml


#æ–¹æ³•3
#ä¿®æ”¹é…ç½®
[root@master1 ~]#vim nginx.conf
[root@master1 ~]#kubectl create cm cm-nginx-conf --from-file=nginx.conf --dry-run=client -oyaml |kubectl apply -f -
```



#### ConfigMapä½¿ç”¨

**ä½¿ç”¨ConfigMapä¸»è¦æœ‰ä¸¤ç§æ–¹å¼ï¼š**

- é€šè¿‡ç¯å¢ƒå˜é‡çš„æ–¹å¼ç›´æ¥ä¼ é€’pod
- ä½¿ç”¨volumeçš„æ–¹å¼æŒ‚è½½å…¥åˆ°podå†…çš„æ–‡ä»¶ä¸­



**æ³¨æ„ï¼š**

- ConfigMapå¿…é¡»åœ¨Podä¹‹å‰åˆ›å»º
- ä¸ConfigMapåœ¨åŒä¸€ä¸ªnamespaceå†…çš„podæ‰èƒ½ä½¿ç”¨ConfigMap**ï¼Œå³ConfigMapä¸èƒ½è·¨å‘½åç©ºé—´è°ƒç”¨ã€‚**
- ConfigMapé€šå¸¸å­˜æ”¾çš„æ•°æ®ä¸è¦è¶…è¿‡1M
- CM å¯ä»¥æ”¯æŒå®æ—¶æ›´æ–°ï¼Œåœ¨åŸæ¥çš„podé‡Œé¢ç›´æ¥çœ‹åˆ°æ•ˆæœ



#####  é€šè¿‡ç¯å¢ƒå˜é‡çš„æ–¹å¼ç›´æ¥ä¼ é€’ Pod

å¼•ç”¨ConfigMapå¯¹è±¡ä¸Šç‰¹å®šçš„keyï¼Œä»¥**valueFrom**èµ‹å€¼ç»™Podä¸ŠæŒ‡å®šçš„ç¯å¢ƒå˜é‡

ä¹Ÿå¯ä»¥åœ¨Podä¸Šä½¿ç”¨**envFrom**ä¸€æ¬¡æ€§å¯¼å…¥ConfigMapå¯¹è±¡ä¸Šçš„æ‰€æœ‰çš„key-value,key(å¯ä»¥ç»Ÿä¸€é™„åŠ ç‰¹å®šå‰ ç¼€ï¼‰å³ä¸ºç¯å¢ƒå˜é‡,valueè‡ªåŠ¨æˆä¸ºç›¸åº”çš„å˜é‡å€¼

ç¯å¢ƒå˜é‡æ˜¯å®¹å™¨å¯åŠ¨æ—¶æ³¨å…¥çš„ï¼Œå®¹å™¨å¯åŠ¨åå˜é‡çš„å€¼ä¸ä¼šéšCMæ›´æ”¹è€Œå‘ç”Ÿå˜åŒ–,å³ä¸€æ¬¡æ€§åŠ è½½ configmap,é™¤éåˆ é™¤å®¹å™¨é‡å»º



**æ–¹å¼1ï¼šenv å¯¹æŒ‡å®šçš„å˜é‡ä¸€ä¸ªä¸€ä¸ªèµ‹å€¼**

```bash
kubectl explain pod.spec.containers.env
    name          # æ‰‹å·¥å®šåˆ¶ç¯å¢ƒå˜é‡æ—¶ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡çš„åç§°ï¼Œå¿…é€‰å­—æ®µ
    value         # æ‰‹å·¥å®šåˆ¶ç¯å¢ƒå˜é‡æ—¶ï¼Œç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡çš„å±æ€§å€¼ï¼Œä¸é€šè¿‡CMè·å–é…ç½®ï¼Œå¯é€‰å­—æ®µ
    valueFrom     # #æ‰‹å·¥å®šåˆ¶ç¯å¢ƒå˜é‡æ—¶ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡çš„å±æ€§æ¥æºï¼Œå¯ä»¥æ”¯æŒä»CM,Secret,downwordAPIè·å–

kubectl explain pod.spec.containers.env.valueFrom.configMapKeyRef
    name          # å¼•ç”¨æŒ‡å®šçš„configmap
    key           # å¼•ç”¨æŒ‡å®šçš„configmapä¸­çš„å…·ä½“å“ªä¸ªkey
    optional      # å¦‚æœè®¾ç½®ä¸ºfalseï¼Œæ ‡è¯†è¯¥é¡¹æ˜¯å¿…é€‰é¡¹ï¼Œå¦‚æœè®¾ç½®ä¸ºtrueæ ‡è¯†è¿™ä¸ªkeyæ˜¯å¯é€‰çš„ã€‚é»˜è®¤false

#æ­¤æ–¹å¼å®ç°è¿‡ç¨‹
1ï¼‰å®¹å™¨ä¸­è‡ªå®šä¹‰ç¯å¢ƒå˜é‡å
2ï¼‰æ ¹æ®CMçš„åç§°å’ŒKeyåï¼Œæ‰¾åˆ°å¯¹åº”çš„value
3) å†å°†valueèµ‹å€¼ç»™å®¹å™¨çš„ç¯å¢ƒå˜é‡
```



**æ–¹å¼2ï¼šenvFrom ä½¿ç”¨CMçš„æ‰€æœ‰å˜é‡å®ç°å¯¹å˜é‡çš„æ‰¹é‡èµ‹å€¼ï¼Œæ­¤æ–¹å¼ç”Ÿäº§æ›´ä¸ºæ¨è**

```bash
kubectl explain pod.spec.containers.envFrom
    configMapRef     # ConfigMapå¯¹è±¡ä¸­çš„æ‰€æœ‰Key
    secretKeyRef     # Secretå¯¹è±¡ä¸­çš„æ‰€æœ‰Key
    prefix           # #ä¸ºConfigMapä¸­çš„æ¯ä¸ªå±æ€§éƒ½æ·»åŠ å‰ç¼€æ ‡è¯†

#æ­¤æ–¹å®ç°è¿‡ç¨‹
1ï¼‰å®¹å™¨ä¸­è‡ªå®šä¹‰ç¯å¢ƒå˜é‡åï¼Œå¹¶ä¸”å’ŒCMçš„keyåŒå
2ï¼‰æ‰¾åˆ°æŒ‡å®šçš„CMä¸­æ‰€æœ‰Keyåï¼Œå°†å€¼æ‰¹é‡ç›´æ¥èµ‹å€¼ç»™å®¹å™¨ä¸­ç›¸åŒåç§°çš„å˜é‡
```



##### ä½¿ç”¨volumeçš„æ–¹å¼æŒ‚è½½å…¥åˆ°podå†…çš„æ–‡ä»¶ä¸­

åœ¨Podä¸Šå°† configMapå¯¹è±¡å¼•ç”¨ä¸ºå­˜å‚¨å·ï¼Œè€Œåæ•´ä½“ç”±å®¹å™¨mountè‡³æŸä¸ªç›®å½•ä¸‹ï¼Œkeyè½¬ä¸ºæ–‡ä»¶åï¼Œ valueå³ä¸ºç›¸åº”çš„æ–‡ä»¶å†…å®¹

åœ¨Podä¸Šå®šä¹‰configMapå·æ—¶ï¼Œä»…å¼•ç”¨å…¶ä¸­çš„éƒ¨åˆ†keyï¼Œè€Œåç”±å®¹å™¨mountè‡³ç›®å½•ä¸‹

åœ¨å®¹å™¨ä¸Šä»…mount configMapå·ä¸ŠæŒ‡å®šçš„key

å®¹å™¨ä¸­æŒ‚è½½çš„Volumeæ•°æ®å¯ä»¥**æ ¹æ®æ—¶é—´æˆ³æœºåˆ¶å’ŒConfigMap åŒæ­¥æ›´æ–°**ï¼Œå³configmapå˜æ›´åä¼šè‡ªåŠ¨åŠ è½½ï¼Œä½†æ›´æ–°æ—¶é—´æ˜¯ä¸ç¡®å®šçš„ï¼Œ

æ‰€ä»¥ä¸€èˆ¬å»ºè®®å½“æ›´æ–°configmapçš„é…ç½®åï¼Œå¯ä»¥é€šè¿‡é‡æ–°Podä½¿ä¹‹ç”Ÿæ•ˆï¼Œç¬¦åˆä¸å¯å˜åŸºç¡€è®¾æ–½çš„ç†å¿µ 

æ¨èæ»šåŠ¨å‡çº§podçš„æ–¹å¼æ¥è®©ConfigMapå†…å®¹å˜åŒ–ç”Ÿæ•ˆ



##### ConfigMapå®æˆ˜æ¡ˆä¾‹

**èŒƒä¾‹ï¼šenv å˜é‡**

```yaml
# èµ„æºæ¸…å•æ–‡ä»¶
[root@master1 cm] # vim storage-configmap-simple-env.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-nginx-config
data:
  port: "10086"  # æ³¨æ„ï¼šåªæ”¯æŒå­—ç¬¦ä¸²ï¼Œéœ€è¦ç”¨å¼•å·å¼•èµ·æ¥
  user: "www"
---
apiVersion: v1
kind: Pod
metadata:
  name: configmap-env-test
spec:
  containers:
  - name: configmap-env-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    env:
    - name: NGINX_HOST
      value: "10.0.0.100"  #ç›´æ¥å˜é‡èµ‹å€¼
    - name: NGINX_PORT
      valueFrom:
        configMapKeyRef:
          name: cm-nginx-config
          key: port
          optional: true  # å³ä½¿æ‰¾ä¸åˆ°å¯¹åº”çš„ ConfigMap æˆ– Keyï¼Œä¹Ÿä¸ä¼šè®© Pod å¯åŠ¨å¤±è´¥ï¼Œè€Œæ˜¯å¿½ç•¥è¿™ä¸ªå˜é‡ï¼ŒPod ç…§å¸¸å¯åŠ¨ã€‚
    - name: NGINX_USER
      valueFrom:
        configMapKeyRef:
          name: cm-nginx-config
          key: user
          optional: false
#é…ç½®è§£æï¼šè¿™é‡Œé¢æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸¤ç§æ–¹å¼åœ¨podä¸­ä¼ é€’å˜é‡

# èµ„æºåˆ›å»º
[root@master1 cm] # kubectl apply -f storage-configmap-simple-env.yaml 
configmap/cm-nginx-config created
pod/configmap-env-test created

# æŸ¥çœ‹
[root@master1 cm] # kubectl get pod
NAME                 READY   STATUS    RESTARTS   AGE
configmap-env-test   1/1     Running   0          9s
[root@master1 cm] # kubectl get cm
NAME               DATA   AGE
cm-nginx-config    2      32s

# éªŒè¯å˜é‡
[root@master1 cm] # kubectl exec configmap-env-test -- env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=configmap-env-test
NGINX_HOST=10.0.0.100 
NGINX_PORT=10086   # ---------------------- ConfigMapä¼ å…¥å˜é‡
NGINX_USER=www     # ---------------------- ConfigMapä¼ å…¥å˜é‡
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
KUBERNETES_SERVICE_HOST=10.96.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
NGINX_VERSION=1.20.0
NJS_VERSION=0.5.3
PKG_RELEASE=1~buster
HOME=/root

# èµ„æºåˆ é™¤
[root@master1 cm] # kubectl delete -f storage-configmap-simple-env.yaml 
configmap "cm-nginx-config" deleted
pod "configmap-env-test" deleted
```



**èŒƒä¾‹ï¼šenv å˜é‡**

```yaml
# åˆ›å»ºé…ç½®æ–‡ä»¶
[root@master1 cm] # vim storage-configmap-valueFrom-env.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-pod-test
  namespace: default
data:
  host: 0.0.0.0
  port: "8888"

---
apiVersion: v1
kind: Pod
metadata:
  name: configmap-env-demo
spec:
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    name: pod-test
    env:
    - name: HOST
      valueFrom:
        configMapKeyRef:
          name: cm-pod-test
          key: host
          optional: true  #trueæ—¶,å¦‚æœconfigmapä¸­çš„keyå³ä½¿ä¸å­˜åœ¨,ä¹Ÿä¸ä¼šå¯¼è‡´å®¹å™¨æ— æ³•åˆå§‹

    - name: PORT
      valueFrom:
        configMapKeyRef:
          name: cm-pod-test
          key: port
          optional: false # falseæ—¶ï¼Œå¦‚æœconfigmapä¸­çš„keyä¸å­˜åœ¨ï¼Œä¼šå¯¼è‡´å®¹å™¨æ— æ³•åˆå§‹åŒ–


# åº”ç”¨
[root@master1 cm] # kubectl apply -f storage-configmap-valueFrom-env.yaml 
configmap/cm-pod-test created
pod/configmap-env-demo created

# æŸ¥çœ‹
[root@master1 cm] # kubectl exec configmap-env-demo -- env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=configmap-env-demo
HOST=0.0.0.0
PORT=8888
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
KUBERNETES_SERVICE_HOST=10.96.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.96.0.1:443
DEPLOYENV=Production
RELEASE=Stable
PS1=[\u@\h \w]\$ 
HOME=/root

# åˆ é™¤èµ„æº
[root@master1 cm]#kubectl delete -f storage-configmap-valueFrom-env.yaml 
configmap "cm-pod-test" deleted
pod "configmap-env-demo" deleted
```



**èŒƒä¾‹ï¼šenv å˜é‡**

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 cm] # vim storage-configmap-simple-envargs.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-command-arg
data:
  time: "3600"
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-cm-command-arg
spec:
  containers:
  - name: pod-cm-command-arg-container
    image: busybox:1.32.0
    command: ["/bin/sh", "-c", "sleep ${SPECIAL_TIME}"]
    env:
    - name: SPECIAL_TIME
      valueFrom:
        configMapKeyRef:
          name: cm-command-arg
          key: time
    - name: NAME
      value: "wangxiaochun"
  restartPolicy: Never

# åº”ç”¨
[root@master1 cm] # kubectl apply -f storage-configmap-simple-envargs.yaml 
configmap/cm-command-arg created
pod/pod-cm-command-arg created

# æŸ¥çœ‹
[root@master1 cm] # kubectl get pod
NAME                 READY   STATUS    RESTARTS   AGE
pod-cm-command-arg   1/1     Running   0          3s

[root@master1 cm] # kubectl exec pod-cm-command-arg -- ps aux
PID   USER     TIME  COMMAND
    1 root      0:00 sleep 3600
    8 root      0:00 ps aux

# åˆ é™¤
[root@master1 cm]#kubectl delete -f storage-configmap-simple-envargs.yaml 
configmap "cm-command-arg" deleted
pod "pod-cm-command-arg" deleted
```



**èŒƒä¾‹ï¼šenvFrom æ‰¹é‡å¯¼å…¥æ‰€æœ‰å˜é‡**

```yaml
# é…ç½®æ–‡ä»¶èµ„æºå®šä¹‰æ–‡ä»¶
[root@master1 cm] # vim storage-configmap-simple-envfrom.yaml
[root@master1 cm]#cat storage-configmap-simple-envfrom.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-nginx
data:
  NGINX_PORT: "10086"
  NGINX_USER: "www"
---
apiVersion: v1
kind: Pod
metadata:
  name: configmap-envfrom-test
spec:
  containers:
  - name: configmap-envfrom-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    envFrom:
    - configMapRef:
        name: cm-nginx  # æ‰€æœ‰å˜é‡ä»cmä¸­è¯»å–
        
# åº”ç”¨
[root@master1 cm] # kubectl apply -f storage-configmap-simple-envfrom.yaml 
configmap/cm-nginx unchanged
pod/configmap-envfrom-test created

# æŸ¥çœ‹
[root@master1 cm] # kubectl get pod
NAME                     READY   STATUS    RESTARTS   AGE
configmap-envfrom-test   1/1     Running   0          2s

[root@master1 cm] # kubectl exec configmap-envfrom-test -- env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=configmap-envfrom-test
NGINX_PORT=10086
NGINX_USER=www
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
KUBERNETES_SERVICE_HOST=10.96.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
NGINX_VERSION=1.20.0
NJS_VERSION=0.5.3
PKG_RELEASE=1~buster
HOME=/root

# åˆ é™¤
[root@master1 cm]#kubectl delete -f storage-configmap-simple-envfrom.yaml 
configmap "cm-nginx" deleted
pod "configmap-envfrom-test" deleted
```



 **èŒƒä¾‹ï¼švolume ç”Ÿæˆé…ç½®æ–‡ä»¶å¹¶æ›´æ–°ç”Ÿæ•ˆ**

```yaml
# configmapèµ„æºå®šä¹‰
[root@master1 cm] # vim storage-configmap-simple-volume.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-volume
data:
  author: wangxiaochun
  file.conf: |
    [app]
    config1
    config2

---
apiVersion: v1
kind: Pod
metadata:
  name: pod-volume-test
spec:
  volumes:
  - name: volume-config  # æŒ‡å®šå·å
    configMap:
      name: cm-volume    # æŒ‡å®šå·æ¥è‡ªcm
  containers:
  - name: nginx
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    volumeMounts:
    - name: volume-config # è°ƒç”¨å‰é¢å®šä¹‰çš„å·å
      mountPath: /cmap/   # æŒ‡å®šPodä¸­çš„æŒ‚è½½ç‚¹ç›®å½•
      
# åº”ç”¨
[root@master1 cm] # kubectl apply -f storage-configmap-simple-volume.yaml 
configmap/cm-volume created
pod/pod-volume-test created

# æŸ¥çœ‹
[root@master1 cm] # kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
pod-volume-test   1/1     Running   0          4s

[root@master1 cm] # kubectl exec pod-volume-test -- ls /cmap/
author
file.conf

# è¿›å…¥å®¹å™¨æŸ¥çœ‹
[root@master1 cm] # kubectl exec -it pod-volume-test -- sh
# cd /cmap     
# ls
author	file.conf
# ls -al
total 12
drwxrwxrwx 3 root root 4096 Jan  1 09:26 .
drwxr-xr-x 1 root root 4096 Jan  1 09:26 ..
drwxr-xr-x 2 root root 4096 Jan  1 09:26 ..2025_01_01_09_26_31.673800736
lrwxrwxrwx 1 root root   31 Jan  1 09:26 ..data -> ..2025_01_01_09_26_31.673800736
lrwxrwxrwx 1 root root   13 Jan  1 09:26 author -> ..data/author
lrwxrwxrwx 1 root root   16 Jan  1 09:26 file.conf -> ..data/file.conf
# cd ..2025*        
# ls
author	file.conf

# ç»“æœæ˜¾ç¤ºï¼š
# è¿™äº›æ–‡ä»¶è™½ç„¶çœ‹èµ·æ¥æ˜¯æŒ‚è½½åœ¨ç›®å½•ä¸‹ï¼Œå®é™…ä¸Šï¼Œå®ƒæ˜¯ç»è¿‡ä¸¤å±‚çš„è½¯é“¾æ¥æ‰èƒ½æ‰¾åˆ°çœŸæ­£çš„æŒ‚è½½çš„æ–‡ä»¶ï¼Œå®¹å™¨å†…æŒ‚è½½ç›®å½•çš„ç”Ÿæˆçš„æ–‡ä»¶
# ..2025_01_01_09_26_31.673800736
# ..data -> ..2025_01_01_09_26_31.673800736
# author -> ..data/author
# file.conf -> ..data/file.conf
# é€šè¿‡è¿™ç§åŒå±‚è½¯è¿æ¥çš„æ–¹å¼ï¼Œåªè¦å®¹å™¨æ”¯æŒé‡è½½æŠ€æœ¯ï¼Œé‚£ä¹ˆåªéœ€è¦æ›´æ”¹é…ç½®æ–‡ä»¶å°±å¯ä»¥å®ç°å®¹å™¨åº”ç”¨çš„å˜åŠ¨

# ä¿®æ”¹cm
[root@master1 cm] # kubectl edit cm cm-volume 
apiVersion: v1
data:
 author: wang  #ä¿®æ”¹æ­¤è¡Œ
 file.conf: |
   [app]
   config1
   config2
   config3  #åŠ æ­¤è¡Œ
kind: ConfigMap
.....
configmap/cm-volume edited

# ç­‰ä¸€ä¼šå„¿è¿›å…¥podå¯ä»¥çœ‹åˆ°é…ç½®æ–‡ä»¶å˜åŒ–
[root@master1 cm] # kubectl exec -it pod-volume-test -- sh
# cd /cmap
# ls -al
total 12
drwxrwxrwx 3 root root 4096 Jan  1 09:33 .
drwxr-xr-x 1 root root 4096 Jan  1 09:26 ..
drwxr-xr-x 2 root root 4096 Jan  1 09:33 ..2025_01_01_09_33_42.2079151602
lrwxrwxrwx 1 root root   32 Jan  1 09:33 ..data -> ..2025_01_01_09_33_42.2079151602
lrwxrwxrwx 1 root root   13 Jan  1 09:26 author -> ..data/author
lrwxrwxrwx 1 root root   16 Jan  1 09:26 file.conf -> ..data/file.conf
# cat file.conf                     
[app]
config1
config2
config3
# exit

#åˆ é™¤
[root@master1 cm] # kubectl delete -f storage-configmap-simple-volume.yaml 
configmap "cm-volume" deleted
pod "pod-volume-test" deleted
```



**èŒƒä¾‹ï¼švolume æŒ‚è½½å…¨éƒ¨å†…å®¹**

```yaml
# å‘½ä»¤è¡Œåˆ›å»ºCMï¼Œåˆ›å»ºNginxçš„é…ç½®ä¿¡æ¯
[root@master1 nginx.conf.d] # vim default.conf
server {
    listen 8080;
    server_name localhost;
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
    error_page 500 502 503 504 /50x.html;
    location /50x.html {
        root /usr/share/nginx/html;
    }
}

# å‘½ä»¤è¡Œåˆ›å»ºCM
[root@master1 cm] # kubectl create configmap cm-nginx-conf-files --from-file=nginx.conf.d/
configmap/cm-nginx-conf-files created

# æŸ¥çœ‹
[root@master1 cm]#kubectl get cm
NAME                  DATA   AGE
cm-nginx-conf-files   1      87s

# æ¸…å•æ–‡ä»¶
[root@master1 cm] # vim storage-configmap-nginx-file.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-nginx-index
data:
  index.html: "Nginx Configmap Page!" # å•è¡Œå†…å®¹ç”Ÿæˆconfigmap
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-nginx-conf-configmap
spec:
  volumes:
  - name: nginx-conf
    configMap:
      name: cm-nginx-conf-files
      optional: false
  - name: nginx-index
    configMap:
      name: cm-nginx-index
      optional: false
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    name: nginx
    volumeMounts:
    - name: nginx-conf
      mountPath: /etc/nginx/conf.d/
      readOnly: true
    - name: nginx-index
      mountPath: /usr/share/nginx/html/
      readOnly: true
      
      
# åº”ç”¨
[root@master1 cm] # kubectl apply -f storage-configmap-nginx-file.yaml 
configmap/cm-nginx-index created
pod/pod-nginx-conf-configmap created

# æŸ¥çœ‹
[root@master1 cm] # kubectl get cm
NAME                  DATA   AGE
cm-nginx-conf-files   1      7m31s
cm-nginx-index        1      55s

# æµ‹è¯•æ•ˆæœ
[root@master1 cm] # kubectl get pod -o wide
NAME                       READY   STATUS    RESTARTS   AGE   IP             NODE    NOMINATED NODE   READINESS GATES
pod-nginx-conf-configmap   1/1     Running   0          77s   10.244.3.138   node3   <none>           <none>

[root@master1 cm] # curl 10.244.3.138
curl: (7) Failed to connect to 10.244.3.138 port 80 after 0 ms: æ‹’ç»è¿æ¥

# è¯»å–äº†configmapä¼ å…¥çš„é…ç½®æ–‡ä»¶
[root@master1 cm] # curl 10.244.3.138:8080
Nginx Configmap Page!

# åˆ é™¤
[root@master1 cm] # kubectl delete -f storage-configmap-nginx-file.yaml 
configmap "cm-nginx-index" deleted
pod "pod-nginx-conf-configmap" deleted

[root@master1 cm] # kubectl delete cm cm-nginx-conf-files 
configmap "cm-nginx-conf-files" deleted
```



**èŒƒä¾‹ï¼švolume æŒ‚è½½ CM ä¸­éƒ¨åˆ†æ–‡ä»¶**

```yaml
# å‡†å¤‡é…ç½®æ–‡ä»¶
[root@master1 nginx.conf.d] #ls
default.conf  myserver.conf  myserver-gzip.cfg  myserver-status.cfg

# é…ç½®æ–‡ä»¶
[root@master1 cm] #cat nginx.conf.d/myserver.conf 
server {
    listen 8888;
    server_name www.wang.org;
    include /etc/nginx/conf.d/myserver-*.cfg
    location / {
        root /usr/share/nginx/html;
    }
}

# å­é…ç½®æ–‡ä»¶,æ³¨æ„:æ–‡ä»¶æ˜¯ä»¥cfgä¸ºåç¼€,ä¸èƒ½ä»¥confæ–‡ä»¶åç¼€,ä¼šå¯¼è‡´å†²çª
[root@master1 cm] # cat nginx.conf.d/myserver-gzip.cfg 
gzip on;
gzip_comp_level 5;
gzip_proxied     expired no-cache no-store private auth;
gzip_types text/plain text/css application/xml text/javascript;

[root@master1 cm] # cat nginx.conf.d/myserver-status.cfg 
location /nginx-status {
   stub_status on;
   access_log off;
}

# åˆ›å»ºcm
[root@master1 cm] # kubectl create cm cm-nginx-conf-files --from-file=nginx.conf.d/
configmap/cm-nginx-conf-files created

# æ¸…å•æ–‡ä»¶
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-nginx-index
data:
  index.html: "Nginx Sub Configmap Page\n"
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-cm-nginx-conf
spec:
  volumes:
  - name: nginx-conf
    configMap:
      name: cm-nginx-conf-files
      items:                            # æŒ‡å®šcmä¸­çš„key
      - key: myserver.conf              # cmä¸­çš„keyåç§°
        path: myserver.conf             # Podä¸­çš„æ–‡ä»¶å
        mode: 0644                      # Podä¸­çš„æ–‡ä»¶æƒé™
      - key: myserver-status.cfg
        path: myserver-status.cfg
        mode: 0644
      - key: myserver-gzip.cfg
        path: myserver-gzip.cfg
        mode: 0644
      optional: false
  - name: nginx-index
    configMap:
      name: cm-nginx-index
      optional: false
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    name: pod-cm-nginx-conf-container
    volumeMounts:
    - name: nginx-conf
      mountPath: /etc/nginx/conf.d/
      readOnly: true
    - name: nginx-index
      mountPath: /usr/share/nginx/html/
      readOnly: true

# åº”ç”¨
[root@master1 cm] # kubectl apply -f storage-configmap-nginx-subfile.yaml 
configmap/cm-nginx-index created
pod/pod-cm-nginx-conf created

# æŸ¥çœ‹
[root@master1 cm]#kubectl exec pod-cm-nginx-conf -- ls /etc/nginx/conf.d
myserver-gzip.cfg
myserver-status.cfg
myserver.conf

# æŸ¥çœ‹èµ„æº
[root@master1 cm]#kubectl get cm cm-nginx-conf-files -o yaml
apiVersion: v1
data:
  default.conf: |
    server {
        listen 8080;
        server_name localhost;
        location / {
            root /usr/share/nginx/html;
            index index.html index.htm;
        }
        error_page 500 502 503 504 /50x.html;
        location /50x.html {
            root /usr/share/nginx/html;
        }
    }
  myserver-gzip.cfg: |
    gzip on;
    gzip_comp_level 5;
    gzip_proxied     expired no-cache no-store private auth;
    gzip_types text/plain text/css application/xml text/javascript;
  myserver-status.cfg: |+
    location /nginx-status {
       stub_status on;
       access_log off;
    }

  myserver.conf: |
    server {
        listen 8888;
        server_name www.wang.org;
        include /etc/nginx/conf.d/myserver-*.cfg;
        location / {
            root /usr/share/nginx/html;
        }
    }
kind: ConfigMap
metadata:
  creationTimestamp: "2025-01-01T10:54:52Z"
  name: cm-nginx-conf-files
  namespace: default
  resourceVersion: "224964"
  uid: 80862286-fb45-4dc2-ba8a-4d886f88e015
  
# æŸ¥çœ‹æ•ˆæœ
[root@master1 cm] # curl 10.244.3.140:8888
Nginx Sub Configmap Page

# åˆ é™¤èµ„æº
#åˆ é™¤èµ„æº
[root@master1 yaml] #kubectl delete -f storage-configmap-nginx-subfile.yaml
[root@master1 yaml] #kubectl delete cm cm-nginx-conf-files
```



**èŒƒä¾‹ï¼švolume åŸºäºsubpathå®ç°æŒ‚è½½CMéƒ¨åˆ†æ–‡ä»¶å¹¶ä¿®æ”¹é…ç½®æ–‡ä»¶åç§°**

```yaml
kubectl explain pod.spec.volumes.configMap.items

FIELDS:
   key <string> -required-
     key is the key to project.
     
   mode <integer>
     mode is Optional: mode bits used to set permissions on this file. Must be
     an octal value between 0000 and 0777 or a decimal value between 0 and 511.
     YAML accepts both octal and decimal values, JSON requires decimal values
     for mode bits. If not specified, the volume defaultMode will be used. This
     might be in conflict with other options that affect the file mode, like
     fsGroup, and the result can be other mode bits set.
     
   path <string> -required-
     path is the relative path of the file to map the key to. May not be an
     absolute path. May not contain the path element '..'. May not start with
     the string '..'.
     
kubectl explain pod.spec.containers.volumeMounts
FIELDS:
   mountPath <string> -required-
     Path within the container at which the volume should be mounted. Must not
     contain ':'.
     
   mountPropagation <string>
     mountPropagation determines how mounts are propagated from the host to
     container and the other way around. When not set, MountPropagationNone is
     used. This field is beta in 1.10.
     
   name <string> -required-
     This must match the Name of a Volume.
     
   readOnly <boolean>
     Mounted read-only if true, read-write otherwise (false or unspecified).
     Defaults to false.
     
   subPath <string>
     Path within the volume from which the container's volume should be mounted.
     Defaults to "" (volume's root).

   subPathExpr <string>
     Expanded path within the volume from which the container's volume should be
     mounted. Behaves similarly to SubPath but environment variable references
     $(VAR_NAME) are expanded using the container's environment. Defaults to ""
     (volume's root). SubPathExpr and SubPath are mutually exclusive
```

**èŒƒä¾‹**

```yaml
# å‡†å¤‡é…ç½®æ–‡ä»¶åŒä¸Šä¸€æ ·
[root@master1 cm] #ls nginx.conf.d/
default.conf  myserver.conf  myserver-gzip.cfg  myserver-status.cfg

# å°†ä¸Šé¢çš„é…ç½®æ–‡ä»¶éƒ½åŠ å…¥cm
[root@master1 cm] # kubectl create cm cm-nginx-conf-files --from-file=nginx.conf.d/
configmap/cm-nginx-conf-files created

# æ¸…å•æ–‡ä»¶
[root@master1 cm] # vim storage-configmap-nginx-usesubfile.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-nginx-index
data:
  index.html: "Nginx Use Sub Configmap Page\n"
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-cm-nginx-conf
spec:
  volumes:
  - name: nginx-conf
    configMap:
      name: cm-nginx-conf-files
      optional: false
  - name: nginx-index
    configMap:
      name: cm-nginx-index
      optional: false
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    name: pod-cm-nginx-conf-container
    volumeMounts:
    - name: nginx-conf
      mountPath: /etc/nginx/conf.d/myserver2.conf   # ä¿®æ”¹ç”Ÿæˆçš„é…ç½®æ–‡ä»¶å
      subPath: myserver.conf                        # æŒ‡å®šnginx-confä¸­çš„ç‰¹å®šæ–‡ä»¶ï¼Œè€Œéæ‰€æœ‰æ–‡ä»¶
      readOnly: true
    - name: nginx-conf
      mountPath: /etc/nginx/conf.d/myserver-gzip2.cfg   # ä¿®æ”¹ç”Ÿæˆçš„é…ç½®æ–‡ä»¶å
      subPath: myserver-gzip.cfg                        # æŒ‡å®šnginx-confä¸­çš„ç‰¹å®šæ–‡ä»¶ï¼Œè€Œéæ‰€æœ‰æ–‡ä»¶
      readOnly: true
    - name: nginx-index
      mountPath: /usr/share/nginx/html/
      readOnly: true


[root@master1 cm] # kubectl apply -f storage-configmap-nginx-usesubfile.yaml 
configmap/cm-nginx-index created
pod/pod-cm-nginx-conf created

[root@master1 cm] # kubectl get pod
NAME                READY   STATUS    RESTARTS   AGE
pod-cm-nginx-conf   1/1     Running   0          2s

[root@master1 cm] # kubectl get pod -o wide
NAME                READY   STATUS    RESTARTS   AGE   IP             NODE    NOMINATED NODE   READINESS GATES
pod-cm-nginx-conf   1/1     Running   0          15s   10.244.3.142   node3   <none>           <none>

[root@master1 cm] # kubectl exec pod-cm-nginx-conf -- ls /etc/nginx/conf.d
default.conf
myserver-gzip2.cfg
myserver2.conf

# åˆ é™¤

```



**èŒƒä¾‹ï¼švolume åŸºäºsubPath æŒ‚è½½CM éƒ¨åˆ†æ–‡ä»¶å¹¶ä¿ç•™åŸç›®å½•ä¸­çš„å…¶å®ƒæ–‡ä»¶**

```yaml
# æŸ¥çœ‹å®¹å™¨å†…çš„æ–‡ä»¶åˆ—è¡¨
[root@master1 cm] # docker run --rm --name nginx wangxiaochun/nginx:1.20.0 ls /etc/nginx/
conf.d
fastcgi_params
mime.types
modules
nginx.conf
scgi_params
uwsgi_params

# å¯¼å‡ºé…ç½®æ–‡ä»¶
[root@master1 cm] # docker run --rm --name nginx wangxiaochun/nginx:1.20.0 cat /etc/nginx/nginx.conf > nginx.conf

# åˆ›å»ºconfigmap
[root@master1 cm] # kubectl create cm cm-nginx-conf --from-file=nginx.conf
configmap/cm-nginx-conf created

# æŸ¥çœ‹é…ç½®å†…å®¹
[root@master1 cm] # kubectl describe cm cm-nginx-conf 
Name:         cm-nginx-conf
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
nginx.conf:
----

user  nginx;
worker_processes  auto;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
}


BinaryData
====

Events:  <none>


# å‡†å¤‡é…ç½®æ–‡ä»¶
[root@master1 cm] # vim storage-configmap-subPath-nginx-1.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-cn-nginx-conf
spec:
  volumes:
  - name: volume-nginx-conf
    configMap:
      name: cm-nginx-conf
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    name: pod-cm-nginx-conf-container
    command: ["sh", "-c", "sleep 3600"]
    volumeMounts:
    - name: volume-nginx-conf
      mountPath: /etc/nginx/

# åº”ç”¨
[root@master1 cm] # kubectl apply -f storage-configmap-subPath-nginx-1.yaml 
pod/pod-cn-nginx-conf created

# æŸ¥çœ‹
[root@master1 cm] # kubectl get pod
NAME                READY   STATUS    RESTARTS   AGE
pod-cn-nginx-conf   1/1     Running   0          3s

# ç›´æ¥å°†æ•´ä¸ªç›®å½•è¦†ç›–äº†
[root@master1 cm] # kubectl exec pod-cn-nginx-conf -- ls /etc/nginx
nginx.conf

# åˆ é™¤
[root@master1 cm] # kubectl delete -f storage-configmap-subPath-nginx-1.yaml 
pod "pod-cn-nginx-conf" deleted

# ä¿®æ”¹æ¸…å•æ–‡ä»¶
[root@master1 cm] # cat storage-configmap-subPath-nginx-2.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-cm-nginx-conf
spec:
  volumes:
  - name: volume-nginx-conf
    configMap:
      name: cm-nginx-conf
      items:
      - key: nginx.conf
        path: etc/nginx/nginx.conf       # å¿…é¡»æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œä¸”å’Œä¸‹é¢subPathè·¯å¾„ç›¸åŒ
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    name: pod-cm-nginx-conf-container
    command: ["sh", "-c", "sleep 3600"]
    volumeMounts:
    - name: volume-nginx-conf
      mountPath: /etc/nginx/nginx.conf
      subPath: etc/nginx/nginx.conf     # å¿…é¡»æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œä¸”å’Œvolumesçš„pathè·¯å¾„ç›¸åŒ
      
[root@master1 cm] # kubectl apply -f storage-configmap-subPath-nginx-2.yaml 
pod/pod-cm-nginx-conf created

[root@master1 cm] # kubectl get pod
NAME                READY   STATUS    RESTARTS   AGE
pod-cm-nginx-conf   1/1     Running   0          3s

[root@master1 cm] # kubectl exec -it pod-cm-nginx-conf -- ls /etc/nginx/
conf.d		mime.types  nginx.conf	 uwsgi_params
fastcgi_params	modules     scgi_params
```



**å…³äºä¸Šé¢æ¡ˆä¾‹ä¸­ï¼Œvolumes.configMap.items.pathç›¸å¯¹è·¯å¾„è¡¥å……è¯´æ˜ï¼š**

åœ¨ `ConfigMap` ä¸­ï¼Œ`path` æ˜¯ç”¨æ¥æŒ‡å®šè¯¥é”®å€¼å¯¹åœ¨ **`volume` æ ¹ç›®å½•ä¸‹çš„ç›¸å¯¹è·¯å¾„**ã€‚

- **å¿…é¡»æ˜¯ç›¸å¯¹è·¯å¾„çš„åŸå› **ï¼š Kubernetes çš„è®¾è®¡ä¸­ï¼Œ`ConfigMap` çš„ `items` æ˜¯å°†é”®å€¼å¯¹æ˜ å°„ä¸ºæ–‡ä»¶ï¼Œå¹¶å­˜å‚¨åˆ° `volume` çš„ä¸´æ—¶æ–‡ä»¶ç›®å½•ä¸­ã€‚è¿™ä¸ªç›®å½•æ˜¯åŠ¨æ€åˆ›å»ºçš„ï¼Œæ— æ³•æå‰ç¡®å®šä¸€ä¸ªå…·ä½“çš„ç»å¯¹è·¯å¾„ã€‚å› æ­¤ï¼Œ`path` æ˜¯ç›¸å¯¹äº **`volume` çš„æ ¹ç›®å½•** çš„ç›¸å¯¹è·¯å¾„



**è¯¦ç»†è§£é‡Šï¼šå®ƒç›¸å¯¹äºè°çš„è·¯å¾„ï¼Ÿ**

**å·ï¼ˆ`volume`ï¼‰çš„æ ¹ç›®å½•**ï¼š

- `ConfigMap` æ•°æ®è¢«æŒ‚è½½åˆ°å®¹å™¨ä¹‹å‰ï¼ŒKubernetes ä¼šå°†æ•°æ®æ”¾åœ¨ä¸€ä¸ªä¸´æ—¶ç›®å½•ä¸­ï¼Œæ¯”å¦‚ï¼š

  ```js
  /var/lib/kubelet/pods/<pod-id>/volumes/kubernetes.io~configmap/<volume-name>/
  ```

- åœ¨ `path` ä¸­æŒ‡å®šçš„è·¯å¾„æ˜¯ **ç›¸å¯¹äºè¿™ä¸ªä¸´æ—¶ç›®å½•** çš„ç›¸å¯¹è·¯å¾„ã€‚

- å‡è®¾ `ConfigMap` ä¸­æœ‰ä¸€æ¡å®šä¹‰ï¼š

  ```yaml
  items:
    - key: nginx.conf
      path: etc/nginx/nginx.conf
  ```

- Kubernetes ä¼šå°†é”®`nginx.conf`çš„å€¼å†™å…¥æ–‡ä»¶ï¼š

  ```js
  /var/lib/kubelet/pods/<pod-id>/volumes/kubernetes.io~configmap/<volume-name>/etc/nginx/nginx.conf
  ```

**æŒ‚è½½ç‚¹çš„å±‚æ¬¡åŒ–è®¾è®¡:**

- `path` æ˜¯ç›¸å¯¹äº `volume` å†…å®¹çš„æ ¹è·¯å¾„ï¼Œè€Œä¸æ˜¯å®¹å™¨å†…çš„ `mountPath`ã€‚
- å¦‚æœå…è®¸ `path` æ˜¯ç»å¯¹è·¯å¾„ï¼ˆå¦‚ `/etc/nginx/nginx.conf`ï¼‰ï¼Œåˆ™ Kubernetes æ— æ³•å°†å®ƒæŒ‚è½½åˆ° `volume` çš„ä¸´æ—¶ç›®å½•ä¸­ï¼Œå› ä¸ºè¿™æ ·ä¼šå’Œæ–‡ä»¶ç³»ç»Ÿç»“æ„å†²çªã€‚



**`mountPath` å’Œ `subPath` çš„å…³ç³»**

- **`mountPath`**ï¼šæ˜¯å®¹å™¨ä¸­æŒ‚è½½ç‚¹çš„ç»å¯¹è·¯å¾„ï¼Œè¡¨ç¤ºæŒ‚è½½ç‚¹åœ¨å®¹å™¨æ–‡ä»¶ç³»ç»Ÿä¸­çš„ä½ç½®ã€‚
- **`subPath`**ï¼šè¡¨ç¤ºæŒ‚è½½ç‚¹å†…éƒ¨ï¼ˆ`volume` å†…éƒ¨ï¼‰çš„ç›¸å¯¹è·¯å¾„ï¼Œå®ƒä» `volumes` æŒ‡å®šçš„èµ„æºï¼ˆå¦‚ `ConfigMap` æˆ– `PersistentVolume`ï¼‰çš„æ ¹ç›®å½•å¼€å§‹ã€‚



**æŒ‚è½½è·¯å¾„çš„é€»è¾‘**

- `mountPath` å®šä¹‰äº†å®¹å™¨ä¸­çš„æ–‡ä»¶/ç›®å½•æŒ‚è½½ä½ç½®ï¼Œæ¯”å¦‚ `/etc/nginx/nginx.conf`ã€‚
- `subPath` å®šä¹‰äº†åœ¨å·ä¸­é€‰æ‹©å…·ä½“çš„æ–‡ä»¶æˆ–è·¯å¾„ï¼Œæ¯”å¦‚ `etc/nginx/nginx.conf`ã€‚
- **`subPath` æ˜¯ç›¸å¯¹äº `volumes` æŒ‚è½½å†…å®¹çš„è·¯å¾„ï¼Œè€Œä¸æ˜¯ `mountPath` çš„è·¯å¾„ã€‚**



### ConfigMapçš„é—®é¢˜ä¸ç”Ÿäº§ä¸­çš„æ‰©å±•

#### ConfigMap/Secret çš„å¤§å°é™åˆ¶

Kubernetes ä¸­å¯¹å•ä¸ªå¯¹è±¡ï¼ˆåŒ…æ‹¬ `ConfigMap` å’Œ `Secret`ï¼‰çš„å¤§å°æœ‰é™åˆ¶ï¼š

- **å•ä¸ª ConfigMap/Secret çš„å¤§å°ä¸Šé™ä¸º 1MiB**
- ä¸” **å»ºè®®è¿œä½äºæ­¤å€¼**ï¼Œå¦åˆ™ä¼šå½±å“ apiserver æ€§èƒ½ã€ETCD å­˜å‚¨æ•ˆç‡ç­‰

åŸå› ï¼šæ‰€æœ‰èµ„æºéƒ½å­˜åœ¨ etcd ä¸­ï¼Œå¤§å¯¹è±¡ä¼šå¯¼è‡´ etcd æ€§èƒ½ä¸‹é™ã€‚



#### é…ç½®æ–‡ä»¶è¶…è¿‡1MiBçš„åœºæ™¯

å¸¸è§åœºæ™¯å¦‚ä¸‹ï¼š

- å‰ç«¯ SPA é¡¹ç›®æ‰“åŒ…äº§ç‰©ï¼ˆå¦‚ index.htmlï¼‰
- å„ç§è¯ä¹¦ï¼ˆå¦‚å¤§å‹ CA é“¾ï¼‰
- è‡ªå®šä¹‰è¯­è¨€æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚ tokenizerã€embeddingï¼‰
- å¤§å‹ YAML/JSON é…ç½®ï¼ˆå¦‚å¤æ‚çš„ä¸šåŠ¡è§„åˆ™ï¼‰



#### è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨Nacosè§£å†³k8sä¸Šçš„é…ç½®ç®¡ç†

**åœ¨å…¬å¸ä¸­å°† Nacos éƒ¨ç½²åœ¨ Kubernetes ä¸­ç”¨äºé…ç½®ç®¡ç†ï¼Œæ˜¯ä¸€ç§éå¸¸å¸¸è§ä¸”æˆç†Ÿçš„æ–¹å¼**ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨å¾®æœåŠ¡æ¶æ„ï¼ˆå¦‚ Spring Clo

### Secret



#### Secretä»‹ç»

![image-20250101212836061](../markdown_img/image-20250101212836061.png)

Secret å’Œ Configmap ç›¸ä¼¼ï¼Œä¹Ÿå¯ä»¥æä¾›é…ç½®æ•°æ®ï¼Œä½†ä¸»è¦ç”¨äºä¸ºPodæä¾›æ•æ„Ÿéœ€è¦åŠ å¯†çš„ä¿¡æ¯

Secret ä¸»è¦ç”¨äºå­˜å‚¨å¯†ç ã€è¯ä¹¦ç§é’¥ï¼ŒSSH å¯†é’¥ï¼ŒOAuthä»¤ç‰Œç­‰æ•æ„Ÿä¿¡æ¯ï¼Œè¿™äº›æ•æ„Ÿä¿¡æ¯é‡‡ç”¨base64ç¼– ç ä¿å­˜ï¼Œç›¸å¯¹æ˜æ–‡å­˜å‚¨æ›´å®‰å…¨

ç›¸æ¯”äºç›´æ¥å°†æ•æ„Ÿæ•°æ®é…ç½®åœ¨Podçš„å®šä¹‰æˆ–è€…é•œåƒä¸­ï¼ŒSecretæä¾›äº†æ›´åŠ å®‰å…¨çš„æœºåˆ¶ï¼Œå°†éœ€è¦å…±äº«çš„æ•° æ®è¿›è¡ŒåŠ å¯†ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²ã€‚

Secretçš„å¯¹è±¡éœ€è¦å•ç‹¬å®šä¹‰å¹¶åˆ›å»ºï¼Œé€šå¸¸ä»¥æ•°æ®å·çš„å½¢å¼æŒ‚è½½åˆ°Podä¸­ï¼ŒSecretçš„æ•°æ®å°†ä»¥æ–‡ä»¶çš„å½¢å¼ ä¿å­˜ï¼Œå®¹å™¨é€šè¿‡è¯»å–æ–‡ä»¶å¯ä»¥è·å–éœ€è¦çš„æ•°æ®

Secret volumeæ˜¯é€šè¿‡tmpfsï¼ˆå†…å­˜æ–‡ä»¶ç³»ç»Ÿï¼‰å®ç°çš„ï¼Œæ‰€ä»¥**è¿™ç§ç±»å‹çš„volumeä¸æ˜¯æ°¸ä¹…å­˜å‚¨çš„ã€‚**

**æ¯ä¸ªSecretçš„æ•°æ®ä¸èƒ½è¶…è¿‡1MB**ï¼Œæ”¯æŒé€šè¿‡èµ„æºé™é¢æ§åˆ¶æ¯ä¸ªåç§°ç©ºé—´çš„Secretçš„æ•°é‡

**æ³¨æ„: Secret å±äºåç§°ç©ºé—´çº§åˆ«ï¼Œåªèƒ½è¢«åŒä¸€ä¸ªåç§°ç©ºé—´çš„Podå¼•ç”¨**



**Secret åˆ†æˆä»¥ä¸‹å¸¸è§å¤§çš„åˆ†ç±»**

| ç±»å‹            | è§£æ                                                         |
| --------------- | ------------------------------------------------------------ |
| generic         | é€šç”¨ç±»å‹ï¼ŒåŸºäº**base64ç¼–ç **ç”¨æ¥å­˜å‚¨å¯†ç ï¼Œå…¬é’¥ç­‰ã€‚<br />å¸¸è§çš„å­ç±»å‹æœ‰ï¼š Opaque,kubernetes.io/service-account-token,kubernetes.io/basicauth,kubernetes.io/ssh-auth,bootstrap.kubernetes.io/token,kubernetes.io/rbd |
| tls             | ä¸“é—¨ç”¨äºä¿å­˜tls/sslç”¨åˆ°è¯ä¹¦å’Œé…å¯¹çš„ç§é’¥,å¸¸è§çš„å­ç±»å‹:kubernetes.io/tls |
| docker-registry | ä¸“ç”¨äºè®©kubeletå¯åŠ¨Podæ—¶ä»ç§æœ‰é•œåƒä»“åº“pullé•œåƒæ—¶ï¼Œé¦–å…ˆè®¤è¯åˆ°ä»“åº“Registryæ—¶ä½¿ç”¨ <br />å¸¸è§çš„å­ç±»å‹:kubernetes.io/dockercfg,kubernetes.io/dockerconfigjson |



**Secret ç»†åŒ–ä¸ºçš„å­ç±»å‹(Type)**

| å¤§ç±»å‹          | Builtin Type                       | è¯´æ˜                                        |
| --------------- | ---------------------------------- | ------------------------------------------- |
| generic         | opaque                             | arbitrary user-defined data                 |
| generic         | kubernetes.io/service-accounttoken | service account token                       |
| generic         | kubernetes.io/basic-auth           | credentials for basic authentication        |
| generic         | kubernetes.io/ssh-auth             | credentials for SSH authentication          |
| generic         | bootstrap.kubernetes.io/token      | bootstrap token data åˆå§‹åŒ–                 |
| tls             | kubernetes.io/tls                  | data for a TLS client or server             |
| docker-registry | kubernetes.io/dockerconfigjson     | serialized ~/ .docker/config.json file æ–°ç‰ˆ |
| docker-registry | kubernetes.io/dockercfg            | serialized -/ .dockercfg file æ—§ç‰ˆ          |



**æ³¨æ„ï¼š**

ä¸åŒç±»å‹çš„Secretï¼Œåœ¨å®šä¹‰æ—¶æ”¯æŒä½¿ç”¨çš„æ ‡å‡†å­—æ®µä¹Ÿæœ‰æ‰€ä¸åŒ

ä¾‹å¦‚: ssh-authç±»å‹çš„Secretåº”è¯¥ä½¿ç”¨ssh-privatekeyï¼Œè€Œbasic-authç±»å‹çš„Secretåˆ™éœ€è¦ä½¿ç”¨ usernameå’Œpasswordç­‰

å¦å¤–ä¹Ÿå¯èƒ½å­˜åœ¨ä¸€äº›ç‰¹æ®Šçš„ç±»å‹, ç”¨äºæ”¯æ’‘ç¬¬ä¸‰æ–¹éœ€æ±‚ï¼Œä¾‹å¦‚: cephçš„keyringä¿¡æ¯ä½¿ç”¨çš„ kubernetes.io/rbdç­‰



**Secret åˆ›å»ºæ–¹å¼**

- **æ‰‹åŠ¨åˆ›å»º**ï¼šç”¨æˆ·è‡ªè¡Œåˆ›å»ºçš„Secret å¸¸ç”¨æ¥å­˜å‚¨ç”¨æˆ·ç§æœ‰çš„ä¸€äº›ä¿¡æ¯
- **è‡ªåŠ¨åˆ›å»º**ï¼šé›†ç¾¤è‡ªåŠ¨åˆ›å»ºçš„Secret ç”¨æ¥ä½œä¸ºé›†ç¾¤ä¸­å„ä¸ªç»„ä»¶ä¹‹é—´é€šä¿¡çš„èº«ä»½æ ¡éªŒä½¿ç”¨



**æŸ¥çœ‹Secret**

```bash
[root@master1 cm]# kubectl get secrets -A
NAMESPACE     NAME                     TYPE                            DATA   AGE
kube-system   bootstrap-token-8loc6r   bootstrap.kubernetes.io/token   6      4d6h

[root@master1 cm]# kubectl get secrets -n kube-system  bootstrap-token-8loc6r -o yaml
apiVersion: v1
data:
  auth-extra-groups: c3lzdGVtOmJvb3RzdHJhcHBlcnM6a3ViZWFkbTpkZWZhdWx0LW5vZGUtdG9rZW4=
  description: VGhlIGRlZmF1bHQgYm9vdHN0cmFwIHRva2VuIGdlbmVyYXRlZCBieSAna3ViZWFkbSBpbml0Jy4=
  token-id: OGxvYzZy
  token-secret: cjFybWE3dzQ4eG1kdmJudA==
  usage-bootstrap-authentication: dHJ1ZQ==
  usage-bootstrap-signing: dHJ1ZQ==
kind: Secret
metadata:
  creationTimestamp: "2024-12-28T07:55:15Z"
  name: bootstrap-token-8loc6r
  namespace: kube-system
  resourceVersion: "215"
  uid: b50e2dd9-50e8-4f60-879f-89086ff35b2f
type: bootstrap.kubernetes.io/token

# basey64è§£ç æŸ¥çœ‹descriptionå…·ä½“æ•°æ®
[root@master1 cm]#echo -n "VGhlIGRlZmF1bHQgYm9vdHN0cmFwIHRva2VuIGdlbmVyYXRlZCBieSAna3ViZWFkbSBpbml0Jy4="|base64 -d
The default bootstrap token generated by 'kubeadm init'.
```



#### Secretå‘½ä»¤å¼åˆ›å»º



![image-20250101223713630](../markdown_img/image-20250101223713630.png)



**æ ¼å¼**

```bash
 kubectl create secret [flags] [options] [-n <namespace>]
```



**å‘½ä»¤æ ¼å¼**

```bash
# genericç±»å‹
kubectl create secret generic NAME [--type=string] [--from-file=[key=]source] [--from-literal=key1=value1]

--from-literal=key1=value1       #ä»¥å‘½ä»¤è¡Œè®¾ç½®é”®å€¼å¯¹çš„ç¯å¢ƒå˜é‡æ–¹å¼é…ç½®æ•°æ®
--from-env-file=/PATH/FILE       #ä»¥ç¯å¢ƒå˜é‡çš„ä¸“ç”¨æ–‡ä»¶çš„æ–¹å¼é…ç½®æ•°æ®
--from-file=[key=]/PATH/FILE     #ä»¥é…ç½®æ–‡ä»¶çš„æ–¹å¼åˆ›å»ºé…ç½®æ•°æ®ï¼Œå¦‚ä¸æŒ‡å®škeyï¼ŒFILEåç§°ä¸ºkeyå
--from-file=/PATH/DIR            #ä»¥é…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„æ–¹å¼åˆ›å»ºé…ç½®æ•°æ®

#è¯¥å‘½ä»¤ä¸­çš„--typeé€‰é¡¹è¿›è¡Œå®šä¹‰é™¤äº†åé¢docker-registryå’Œtlså‘½ä»¤ä¹‹å¤–çš„å…¶å®ƒå­ç±»å‹ï¼Œæœ‰äº›ç±»å‹æœ‰keyçš„ç‰¹å®šè¦æ±‚
#æ³¨æ„: å¦‚æœvauleä¸­æœ‰ç‰¹æ®Šå­—ç¬¦,æ¯”å¦‚:$,\,*,=,!ç­‰,éœ€è¦ç”¨\è¿›è¡Œè½¬ä¹‰æˆ–ç”¨å•å¼•å·''å¼•èµ·æ¥

#tlsç±»å‹
kubectl create secret tls NAME --cert=/path/file --key=/path/file
#å…¶ä¿å­˜certæ–‡ä»¶å†…å®¹çš„keyåç§°ä¸èƒ½æŒ‡å®šè‡ªåŠ¨ä¸ºtls.crtï¼Œè€Œä¿å­˜private keyçš„keyä¸èƒ½æŒ‡å®šè‡ªåŠ¨tls.key

#docker-registryç±»å‹
#æ–¹å¼1:åŸºäºç”¨æˆ·åå’Œå¯†ç æ–¹å¼å®ç°
kubectl create secret docker-registry NAME --docker-username=user --docker-password=password --docker-email=email [--docker-server=string] [--from-file=[key=]source]

#æ–¹å¼2:åŸºäºdockerconfigæ–‡ä»¶æ–¹å¼å®ç°
kubectl create secret docker-registry KEYNAME --fromfile=.dockerconfigjson=path/to/.docker/config.json
#ä»å·²æœ‰çš„jsonæ ¼å¼çš„æ–‡ä»¶åŠ è½½ç”Ÿæˆçš„å°±æ˜¯dockerconfigjsonç±»å‹ï¼Œå‘½ä»¤è¡Œç›´æ¥ç”Ÿæˆçš„ä¹Ÿæ˜¯è¯¥ç±»å‹
```



**èŒƒä¾‹**

```bash
# åˆ›å»ºgenericç±»å‹
kubectl create secret generic my-secret-generic --from-file=/path/bar

kubectl create secret generic my-secret-generic --from-file=ssh-privatekey=~/.ssh/id_rsa --from-file=ssh-publickey=~/.ssh/id_rsa.pub

kubectl create secret generic my-secret-generic --from-literal=username=admin --from-literal=password=123456

kubectl create secret generic my-secret-generic --from-env-file=path/to/bar.env


# åˆ›å»ºtlsç±»å‹
kubectl create secret tls my-secret-tls --cert=certs/wang.org.cert --key=certs/wang.org.key

#åˆ›å»ºdocker-registryç±»å‹
#å‚è€ƒç¤ºä¾‹ï¼šhttps://Kubernetesmeetup.github.io/docs/tasks/configure-podcontainer/pull-image-private-registry/
#åŸºäºç§æœ‰ä»“åº“çš„ç”¨æˆ·åå’Œå¯†ç 
kubectl create secret docker-registry my-secret-docker-registry --docker-server=harbor.wang.org --docker-username=admin --docker-password=123456 --docker-email=29308620@qq.com

#å…ˆç™»å½•å¹¶è®¤è¯åˆ°ç›®æ ‡ä»“åº“serverä¸Šï¼Œè®¤è¯å‡­æ®è‡ªåŠ¨ä¿å­˜åœ¨dockercfgæ–‡ä»¶ä¸­,åŸºäºdockerconfigæ–‡ä»¶å®ç°
kubectl create secret docker-registry dockerharbor-auth --from-file=.dockerconfigjson=/root/.docker/config.json

kubectl create secret generic dockerharbor-auth --
type='kubernetes.io/dockerconfigjson' --from-file=.dockerconfigjson=/root/.docker/config.json
```





#### Secretå£°æ˜å¼åˆ›å»º

Secret æ•°æ®å­˜æ”¾åœ¨dataæˆ–stringDataå­—æ®µ,å…¶ä¸­**dataå­—æ®µä¸­çš„Key/valueå¿…é¡»ä½¿ç”¨base64ç¼–ç å­˜æ”¾**,è€Œ stringDataä½¿ç”¨æ˜æ–‡å­˜æ”¾

Secret èµ„æºçš„å…ƒæ•°æ®ï¼šé™¤äº†name, namespaceä¹‹å¤–ï¼Œå¸¸ç”¨çš„è¿˜æœ‰labels, annotations

- annotationçš„åç§°éµå¾ªç±»ä¼¼äºlabelsçš„åç§°å‘½åæ ¼å¼ï¼Œä½†å…¶æ•°æ®é•¿åº¦ä¸å—é™åˆ¶
- å®ƒä¸èƒ½ç”¨äºè¢«æ ‡ç­¾é€‰æ‹©å™¨ä½œä¸ºç­›é€‰æ¡ä»¶ï¼›ä½†å¸¸ç”¨äºä¸ºé‚£äº›ä»å¤„äºBetaé˜¶æ®µçš„åº”ç”¨ç¨‹åºæä¾›ä¸´æ—¶çš„é…ç½®æ¥å£
- ç®¡ç†å‘½ä»¤ï¼škubectl annotate TYPE/NAME KEY=VALUE

```bash
[root@master1 ~]#kubectl explain secret
KIND:       Secret
VERSION:    v1

DESCRIPTION:
    Secret holds secret data of a certain type. The total bytes of the values in
    the Data field must be less than MaxSecretSize bytes.
    
FIELDS:
  apiVersion	<string>
    APIVersion defines the versioned schema of this representation of an object.
    Servers should convert recognized schemas to the latest internal value, and
    may reject unrecognized values. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources

  data	<map[string]string>
    Data contains the secret data. Each key must consist of alphanumeric
    characters, '-', '_' or '.'. The serialized form of the secret data is a
    base64 encoded string, representing the arbitrary (possibly non-string) data
    value here. Described in https://tools.ietf.org/html/rfc4648#section-4

  immutable	<boolean>
    Immutable, if set to true, ensures that data stored in the Secret cannot be
    updated (only object metadata can be modified). If not set to true, the
    field can be modified at any time. Defaulted to nil.

  kind	<string>
    Kind is a string value representing the REST resource this object
    represents. Servers may infer this from the endpoint the client submits
    requests to. Cannot be updated. In CamelCase. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds

  metadata	<ObjectMeta>
    Standard object's metadata. More info:
    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata

  stringData	<map[string]string>
    stringData allows specifying non-binary secret data in string form. It is
    provided as a write-only input field for convenience. All keys and values
    are merged into the data field on write, overwriting any existing values.
    The stringData field is never output when reading from the API.

  type	<string>
    Used to facilitate programmatic handling of secret data. More info:
    https://kubernetes.io/docs/concepts/configuration/secret/#secret-types

```





#### Secretå¼•ç”¨

Secretèµ„æºåœ¨Podä¸­å¼•ç”¨çš„æ–¹å¼æœ‰ä¸‰ç§

- **ç¯å¢ƒå˜é‡**
  - å¼•ç”¨Secretå¯¹è±¡ä¸Šç‰¹å®šçš„keyï¼Œä»¥valueFromèµ‹å€¼ç»™Podä¸ŠæŒ‡å®šçš„ç¯å¢ƒå˜é‡
  - åœ¨Podä¸Šä½¿ç”¨envFromä¸€æ¬¡æ€§å¯¼å…¥Secretå¯¹è±¡ä¸Šçš„æ‰€æœ‰key-valueï¼Œkey(ä¹Ÿå¯ä»¥ç»Ÿä¸€é™„åŠ ç‰¹å®šå‰ç¼€ï¼‰ å³ä¸ºç¯å¢ƒå˜é‡å,valueè‡ªåŠ¨æˆ ä¸ºç›¸åº”çš„å˜é‡å€¼
  - æ³¨æ„ï¼šå®¹å™¨å¾ˆå¯èƒ½ä¼šå°†ç¯å¢ƒå˜é‡æ‰“å°åˆ°æ—¥å¿—ä¸­,åŸºäºå®‰å…¨è€ƒè™‘**ä¸å»ºè®®ä»¥ç¯å¢ƒå˜é‡æ–¹å¼å¼•ç”¨Secretä¸­çš„æ•æ„Ÿæ•°æ®**
- **secretå·**
  - åœ¨Podä¸Šå°†Secretå¯¹è±¡å¼•ç”¨ä¸ºå­˜å‚¨å·ï¼Œè€Œåæ•´ä½“ç”±å®¹å™¨mountè‡³æŸä¸ªç›®å½•ä¸‹,å…¶ä¸­keyåç§°è½¬ä¸ºæ–‡ä»¶ åï¼Œvalueçš„å€¼è½¬ä¸ºç›¸åº”çš„æ–‡ä»¶å†…å®¹
  - åœ¨Podä¸Šå®šä¹‰Secretå·æ—¶ï¼Œä¹Ÿå¯ä»¥ä»…å¼•ç”¨å…¶ä¸­çš„æŒ‡å®šçš„éƒ¨åˆ†keyï¼Œè€Œåç”±å®¹å™¨mountè‡³ç›®å½•ä¸‹
- **æ‹‰å–é•œåƒ**
  - åœ¨Pod ä¸Šä½¿ç”¨ imagePullSecrets æ‹‰å–ç§æœ‰ä»“åº“é•œåƒä½¿ç”¨
  - Podå¼•ç”¨Secretçš„æ–¹å¼ï¼špods.spec.imagePullSecrets





#### Generic æ¡ˆä¾‹

generic ä¸»è¦ç”¨äºå®ç°ç”¨æˆ·åå’Œå¯†ç çš„åŠ å¯†ä¿å­˜

æ³¨æ„: genericåŠ å¯†ä¿å­˜è¦æ³¨æ„æ¢è¡Œé—®é¢˜ `\n `

```bash
#genericç±»å‹
kubectl create secret generic NAME [--type=string] [--from-file=[key=]source] [--from-literal=key1=value1]

--from-literal=key1=value1        #ä»¥å‘½ä»¤è¡Œè®¾ç½®é”®å€¼å¯¹çš„æ–¹å¼é…ç½®æ•°æ®
--from-env-file=/PATH/TO/FILE       #ä»¥ç¯å¢ƒå˜é‡ä¸“ç”¨æ–‡ä»¶çš„æ–¹å¼é…ç½®æ•°æ®
--from-file=[key=]/PATH/TO/FILE #ä»¥é…ç½®æ–‡ä»¶çš„æ–¹å¼åˆ›å»ºé…ç½®æ•°æ®ï¼Œå¦‚ä¸æŒ‡å®škeyï¼ŒFILEåç§°ä¸ºkeyå
--from-file=/PATH/TO/DIR        #ä»¥é…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„æ–¹å¼åˆ›å»ºé…ç½®æ•°æ®

#è¯¥å‘½ä»¤ä¸­çš„--typeé€‰é¡¹è¿›è¡Œå®šä¹‰é™¤äº†åé¢docker-registryå’Œtlså‘½ä»¤ä¹‹å¤–çš„å…¶å®ƒå­ç±»å‹ï¼Œæœ‰äº›ç±»å‹æœ‰keyçš„ç‰¹å®šè¦æ±‚
#æ³¨æ„: å¦‚æœvauleä¸­æœ‰ç‰¹æ®Šå­—ç¬¦,æ¯”å¦‚:$,\,*,=,!ç­‰,éœ€è¦ç”¨\è¿›è¡Œè½¬ä¹‰æˆ–ç”¨å•å¼•å·''å¼•èµ·æ¥
```



##### èŒƒä¾‹ï¼šå‘½ä»¤å¼åˆ›å»º generic

```bash
# å‘½ä»¤å¼åˆ›å»º
[root@master1 ~]# kubectl create secret generic secret-mysql-root --from-literal=username=root --f
rom-literal=password=123456
secret/secret-mysql-root created

# æŸ¥çœ‹
[root@master1 ~]# kubectl get secrets 
NAME                TYPE     DATA   AGE
secret-mysql-root   Opaque   2      6s

# æŸ¥çœ‹Genericä½¿ç”¨Base64ç¼–ç 
[root@master1 ~]# kubectl get secrets secret-mysql-root -o yaml
apiVersion: v1
data:
  password: MTIzNDU2
  username: cm9vdA==
kind: Secret
metadata:
  creationTimestamp: "2025-01-02T01:19:55Z"
  name: secret-mysql-root
  namespace: default
  resourceVersion: "247070"
  uid: 5e668e52-7990-47ec-93b6-a412649c5417
type: Opaque

# è§£ç 
[root@master1 ~]# echo -n "MTIzNDU2" | base64 -d
123456
[root@master1 ~]# echo -n "cm9vdA==" | base64 -d
root

# åˆ é™¤
[root@master1 ~]# kubectl delete secrets secret-mysql-root 
secret "secret-mysql-root" deleted
```



##### èŒƒä¾‹ï¼šstringDataæ˜æ–‡æ•°æ®

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 secret] # vim storage-secret-opaque-stringData.yaml
apiVersion: v1
kind: Secret
metadata:
  name: secret-stringdata
  namespace: default
type: opaque
stringData:                  # stringDataè¡¨ç¤ºæ˜æ–‡å­˜æ”¾æ•°æ®ï¼Œdataè¡¨ç¤ºå¿…é¡»ä»¥base64ç¼–ç å­˜æ”¾
  user: 'admin'
  password: '123456'


# åº”ç”¨
[root@master1 secret] # kubectl apply -f storage-secret-opaque-stringData.yaml 
secret/secret-stringdata created

# æŸ¥çœ‹
[root@master1 secret] # kubectl get secrets 
NAME                TYPE     DATA   AGE
secret-stringdata   opaque   2      5s

# æŸ¥çœ‹
[root@master1 secret] # kubectl get secrets secret-stringdata -o yaml
apiVersion: v1
data:
  password: MTIzNDU2
  user: YWRtaW4=
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"Secret","metadata":{"annotations":{},"name":"secret-stringdata","namespace":"default"},"stringData":{"password":"123456","user":"admin"},"type":"opaque"}
  creationTimestamp: "2025-01-02T01:27:51Z"
  name: secret-stringdata
  namespace: default
  resourceVersion: "247832"
  uid: 58fa1297-3800-4c02-bfd7-b9a63212f1e3
type: opaque

# åˆ é™¤
[root@master1 secret] # kubectl delete -f storage-secret-opaque-stringData.yaml 
secret "secret-stringdata" deleted
```



#####  èŒƒä¾‹: Secret é€šè¿‡ç¯å¢ƒå˜é‡ä¸ºæä¾›MySQLç¯å¢ƒåˆå§‹åŒ–çš„å¯†ç ä¿¡æ¯

```yaml
# MySQLå®¹å™¨æ”¯æŒMYSQL_ROOT_PASSWORDå˜é‡å­˜æ”¾å¯†ç ,ä½¿ç”¨ç¯å¢ƒå˜é‡åˆ›å»ºMySQLå®¹å™¨
[root@master1 secret] # docker run --name mysql_test -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0

# ç™»å½•éªŒè¯
[root@master1 secret] # docker exec mysql_test mysql -uroot -h127.0.0.1 -p123456 -e status
mysql: [Warning] Using a password on the command line interface can be insecure.
--------------
mysql  Ver 8.0.40 for Linux on x86_64 (MySQL Community Server - GPL)

Connection id:		8
Current database:	
Current user:		root@127.0.0.1
SSL:			Cipher in use is TLS_AES_256_GCM_SHA384
Current pager:		stdout
Using outfile:		''
Using delimiter:	;
Server version:		8.0.40 MySQL Community Server - GPL
Protocol version:	10
Connection:		127.0.0.1 via TCP/IP
Server characterset:	utf8mb4
Db     characterset:	utf8mb4
Client characterset:	latin1
Conn.  characterset:	latin1
TCP port:		3306
Uptime:			48 sec

Threads: 2  Questions: 5  Slow queries: 0  Opens: 119  Flush tables: 3  Open tables: 38  Queries per second avg: 0.104
--------------

# ç”Ÿæˆå¯†ç çš„base64ç¼–ç 
[root@master1 secret] # echo -n root|base64
cm9vdA==
[root@master1 secret] # echo -n 123456|base64
MTIzNDU2

# æ¸…å•æ–‡ä»¶ï¼Œsecret é€šè¿‡ç¯å¢ƒä¸ºæä¾›MySQLç¯å¢ƒåˆå§‹åŒ–çš„å¯†ç ä¿¡æ¯ï¼Œä½†å¾ˆä¸å®‰å…¨
[root@master1 secret]#cat storage-secret-mysql-init.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: secret-mysql
type: kubernetes.io/basic-auth
# type: Opaque  # ä¹Ÿå¯ä»¥ç”¨Opaqueç±»å‹
data:
  username: cm9vdA==
  password: MTIzNDU2
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-secret-mysql-init
spec:
  containers:
  - name: mysql
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/mysql:8.0.29-oracle
    env:
    - name: MYSQL_ROOT_PASSWORD
      valueFrom:
        secretKeyRef:
          name: secret-mysql   # å¼•ç”¨æŒ‡å®šçš„secret
          key: password        # å¼•ç”¨æŒ‡å®šçš„secretä¸­å¯¹åº”çš„key
          optional: false      # å¿…é¡»å­˜åœ¨

# åº”ç”¨
[root@master1 secret] # kubectl apply -f storage-secret-mysql-init.yaml 
secret/secret-mysql created
pod/pod-secret-mysql-init created

# æŸ¥çœ‹ç»“æœ
[root@master1 secret] # kubectl get secrets 
NAME           TYPE                       DATA   AGE
secret-mysql   kubernetes.io/basic-auth   2      28s

[root@master1 secret] # kubectl get pod
NAME                    READY   STATUS    RESTARTS      AGE
pod-secret-mysql-init   1/1     Running   0             47s

# å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æŸ¥çœ‹åˆ°å¯†ç ï¼Œå¾ˆä¸å®‰å…¨
[root@master1 secret]#kubectl exec pod-secret-mysql-init -- env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=pod-secret-mysql-init # -------------- secretå˜é‡
MYSQL_ROOT_PASSWORD=123456     # -------------- secretå˜é‡
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
KUBERNETES_SERVICE_HOST=10.96.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.96.0.1:443
GOSU_VERSION=1.14
MYSQL_MAJOR=8.0
MYSQL_VERSION=8.0.29-1.el8
MYSQL_SHELL_VERSION=8.0.29-1.el8
HOME=/root

# éªŒè¯å¯†ç ç™»å½•MySQL
[root@master1 secret] # kubectl exec pod-secret-mysql-init -- mysql -uroot -p123456 -e status
mysql: [Warning] Using a password on the command line interface can be insecure.
--------------
mysql  Ver 8.0.29 for Linux on x86_64 (MySQL Community Server - GPL)

Connection id:		8
Current database:	
Current user:		root@localhost
SSL:			Not in use
Current pager:		stdout
Using outfile:		''
Using delimiter:	;
Server version:		8.0.29 MySQL Community Server - GPL
Protocol version:	10
Connection:		Localhost via UNIX socket
Server characterset:	utf8mb4
Db     characterset:	utf8mb4
Client characterset:	latin1
Conn.  characterset:	latin1
UNIX socket:		/var/run/mysqld/mysqld.sock
Uptime:			2 min 27 sec

Threads: 2  Questions: 5  Slow queries: 0  Opens: 117  Flush tables: 3  Open tables: 36  Queries per second avg: 0.034
--------------

# æ›´æ”¹å¯†ç 
[root@master1 yaml] # echo -n 654321 | base64 
NjU0MzIx

[root@master1 yaml] # vim storage-secret-mysql-init.yaml
data:
 username: cm9vdAo=
 password: NjU0MzIx   #ä¿®æ”¹å¯†ç 
 
# é‡æ–°åº”ç”¨
[root@master1 secret] # kubectl apply -f storage-secret-mysql-init.yaml 
secret/secret-mysql configured
pod/pod-secret-mysql-init unchanged

# æŸ¥çœ‹æ˜¯å¦å˜åŒ–
[root@master1 secret] # kubectl get secrets secret-mysql -o yaml
apiVersion: v1
data:
  password: NjU0MzIx        # æˆåŠŸæ›´æ–°
  username: cm9vdA==
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"password":"NjU0MzIx","username":"cm9vdA=="},"kind":"Secret","metadata":{"annotations":{},"name":"secret-mysql","namespace":"default"},"type":"kubernetes.io/basic-auth"}
  creationTimestamp: "2025-01-02T01:40:21Z"
  name: secret-mysql
  namespace: default
  resourceVersion: "249464"
  uid: 1ba61d4f-41d6-4f3a-989d-4f572ec08734
type: kubernetes.io/basic-auth

# Podå†…å˜é‡æ²¡æœ‰è‡ªåŠ¨æ›´æ–°
[root@master1 secret] # kubectl exec pod-secret-mysql-init -- env|grep PASSWORD
MYSQL_ROOT_PASSWORD=123456

# åˆ é™¤Podé‡å»º
[root@master1 secret] # kubectl delete pod pod-secret-mysql-init 
pod "pod-secret-mysql-init" deleted

[root@master1 secret] # kubectl apply -f storage-secret-mysql-init.yaml 
secret/secret-mysql unchanged
pod/pod-secret-mysql-init created

# Podå†…å˜é‡æ›´æ–°æˆåŠŸ
[root@master1 secret] # kubectl exec pod-secret-mysql-init -- env|grep PASSWORD
MYSQL_ROOT_PASSWORD=654321

# æ¸…ç†ç¯å¢ƒ
[root@master1 secret] # kubectl delete -f storage-secret-mysql-init.yaml 
secret "secret-mysql" deleted
pod "pod-secret-mysql-init" deleted
```



##### èŒƒä¾‹: é€šè¿‡å·è°ƒç”¨ secret

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 secret] # cat storage-secret-test-pod.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: secret-test
type: kubernetes.io/basic-auth
data:
  username: YWRtaW4=
  password: cGFzc3dvcmQ=

# è¯´æ˜ï¼š
#typeç±»å‹æŒ‡å®šä¸º Opaque æˆ–è€… kubernetes.io/basic-auth,usernameå’Œpasswordæ˜¯åŠ å¯†çš„ä¿¡æ¯
#èµ„æºå®šä¹‰æ–‡ä»¶æ—¶ï¼Œä¸å‘½ä»¤è¡Œåˆ›å»ºsecretçš„--from-literal=username=admin æ•ˆæœæ˜¯ä¸€æ ·çš„,ä½†å‘½ä»¤è¡Œçš„å˜é‡æ— éœ€åŠ å¯†

---
# è°ƒç”¨secretçš„æ¸…å•æ–‡ä»¶
apiVersion: v1
kind: Pod
metadata:
  name: pod-secret-volume
spec:
  volumes:
  - name: secret
    secret:
      secretName: secret-test    # æŒ‡å®šsecretçš„åç§°
  containers:
  - name: secret-test-container
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    volumeMounts:
    - name: secret
      mountPath: /secret/
      readOnly: true

# åˆ›å»ºèµ„æº
[root@master1 secret] # kubectl apply -f  storage-secret-test-pod.yaml 
secret/secret-test unchanged
pod/pod-secret-volume created

# æŸ¥çœ‹
[root@master1 secret] # kubectl get secrets 
NAME          TYPE                       DATA   AGE
secret-test   kubernetes.io/basic-auth   2      56s

# éªŒè¯
[root@master1 secret]#kubectl exec pod-secret-volume  -- ls /secret
password
username

# åœ¨Podè¿è¡Œçš„å®¿ä¸»æœºä¸Šå¯ä»¥çœ‹åˆ°secretå¯¹åº”çš„æ–‡ä»¶
[root@node2 ~] # find /var/lib/kubelet -name password
/var/lib/kubelet/pods/0439bb26-fdfc-4769-9cc9-d47c718fb301/volumes/kubernetes.io~secret/secret/password

[root@node2 ~] # cat /var/lib/kubelet/pods/0439bb26-fdfc-4769-9cc9-d47c718fb301/volumes/kubernetes.io~secret/secret/password
password

# æ¸…ç†ç¯å¢ƒ
[root@master1 secret] # kubectl delete -f storage-secret-test-pod.yaml 
secret "secret-test" deleted
pod "pod-secret-volume" deleted
```



##### èŒƒä¾‹: ä¸º Service Account åˆ›å»º Secret

```yaml
#k8s-v1.24ç‰ˆæœ¬å,åˆ›å»ºSAä¸ä¼šè‡ªåŠ¨åˆ›å»ºsecret,éœ€è¦æ‰‹åŠ¨åˆ›å»ºsecret
[root@master1 secret] # cat storage-secret-sa.yaml 
apiVersion: v1
kind: ServiceAccount
metadata:
  name: testsa
---
apiVersion: v1
kind: Secret
type: kubernetes.io/service-account-token
metadata:
  name: testsa-secret
  namespace: default
  annotations:
    kubernetes.io/service-account.name: "testsa"

# æŸ¥çœ‹
[root@master1 secret] # kubectl get secrets,sa
NAME                   TYPE                                  DATA   AGE
secret/testsa-secret   kubernetes.io/service-account-token   3      29s

NAME                     SECRETS   AGE
serviceaccount/default   0         4d18h
serviceaccount/testsa    0         29s

# æŸ¥çœ‹å¯¹åº”token
[root@master1 secret] # kubectl get secrets testsa-secret -o yaml
apiVersion: v1
data:
  ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJZHhKUmVsbVJDVlF3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRFeU1qZ3dOelV3TURWYUZ3MHpOREV5TWpZd056VTFNRFZhTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUMrdG9oRDcwaUhEVzNxeFhPeVlsaFpveER0bUZFSTRjTk93K0RySDZFcFVxaVdSUDM0TmwxSzNuR3kKdlRJM3BlRkJtQnF4cXFSSGhCV3M3QUNHTUNFM3VJTHdpN21WTTBrOXJrTW9XeDBIL0draTFyQUJRRXhCS0xyUgp3MTJTdE1QNTFKMHJKaUpxU1I3SElCQ1N5b2NSTzFmYmZNY0VQKzRvK2ZLaWxybHZtTVZIS08vb1czSlJBSXA1CjNkSTBlZUNHTytIN1FFV0RDUlZwek10emtRUGg5L2hMM0t2eEVtSFRtcGt5N2NLNFVoc3c5ZVBrOTVxTmgybnoKUExKd0laNTBpRkh0M05VclRjVUJwTUlpN2VKZEZ0T0ZCTXEraEdvLzJRZlIzUTZ1dmpLdFdrTk9tcFcwRmRaYwpvbHlwbjFmZjdUUEFMVFc4eWdlSGIwRnhIR1R6QWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJTWGtXOGRYRVVpanlhRThiZGFRU1pxd2k5UVFUQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQ0FkTTQ3RHNHUApla2VUQXRXdTFFc3NJVlJJWUZ4bzZhNzBPZG8rOGxyQ2xVdjc1SzRHbkxxc3ByaFA5Y2dPN0JZbXpxb0xNazR2Cmwyem1VOFlqbXYrblVpaWVFMkcyekh6dFNZRXZ2RHBoL1FUajl0Yk1LYmpqenRQYWlNTE9RUXB6bXNXR2FIYzIKUTMrMnZlYzNFY3JneTJidCtUOWNDUE9za0ZZemlNTzZaMEVtNXdtRkgxbk9CRkdCSWpwVUJUZmV5TURkMjNwNwp6THB5M0RUMkNTVWkva2NOeWpOd0tZczhTTmNwRjYyc1VCS2h1eUdidG8rSEo2Q3J6UmFTb3hRcW9BeHdtRUl6CjhYZHhnbEFaSm5tY0F2L0lKVW1HOGVTRFhYMTZNdDBsSm5XT0JzTHJXU08rN1BwWkR0UFlnaG5rVGgweHNmNHUKODEydFFWelpnYjFsCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
  namespace: ZGVmYXVsdA==
  token: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkltdERURWRTV0VwNFozbGpTamxMWlhsTFRrTjZMWE5EZUZsQmJsaE5OR1paY1hSelowTkhjelUzVURnaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUprWldaaGRXeDBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpXTnlaWFF1Ym1GdFpTSTZJblJsYzNSellTMXpaV055WlhRaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaWRHVnpkSE5oSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pTURNNVpUZGpNalF0TXpkaVpTMDBNamt4TFRneE9HTXRNemxqWWpKaFkyVmhOekkySWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tUmxabUYxYkhRNmRHVnpkSE5oSW4wLkI3SFQtQWx5MWt2Wk1TTGFfSTREWHBGM0lkZ2JVaHJXWkczZXBQdVprcTQtWkpfcGN5MTJabkVCTUttLVRTbTFwNWhrQ3gzQm5NQzJ6QmF0VHJIRmp5TkhQSWRuZFJwMk9NMzZHeHNKOGNna0tOU21FMVg3bmM4R2w0ZkxYcDJXSWdUQVN2ZWFVOFI3UWFlZWhXaXdpNzNLNjVpMjNqNEtFYW9YRHhyS2hmb1RIWkdhVG5hVFdTTFZPNW5aRTBZNjg4VnVvem9rcEtrX21Qa1RteUpYUFhPanJKTGNBbHNkSGw2enVhaklJSlkyOGhUQTdCR2NyRnRGSzN3Nm1SLUdTSWpra2pzUmRkQW1mR1lsSVhlci1UMkItZ2Z0eWVaeElvM214OVJzRWhNdzY0Z2V6LUh6NmR6cC1JUVNqMHZwNmtHME1pbTR0WDdRZHpiOWhZaWNtQQ==
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"Secret","metadata":{"annotations":{"kubernetes.io/service-account.name":"testsa"},"name":"testsa-secret","namespace":"default"},"type":"kubernetes.io/service-account-token"}
    kubernetes.io/service-account.name: testsa
    kubernetes.io/service-account.uid: 039e7c24-37be-4291-818c-39cb2acea726
  creationTimestamp: "2025-01-02T02:16:03Z"
  name: testsa-secret
  namespace: default
  resourceVersion: "252537"
  uid: 61a2410e-06eb-4222-ba61-df9a4589db5e
type: kubernetes.io/service-account-token

# è·å–ä¸Šé¢çš„Tokenå€¼å¹¶è§£ç ç”Ÿæˆå˜é‡TOKEN
[root@master1 secret]#TOKEN=$(echo ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkltdERURWRTV0VwNFozbGpTamxMWlhsTFRrTjZMWE5EZUZsQmJsaE5OR1paY1hSelowTkhjelUzVURnaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUprWldaaGRXeDBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpXTnlaWFF1Ym1GdFpTSTZJblJsYzNSellTMXpaV055WlhRaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaWRHVnpkSE5oSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXpaWEoyYVdObExXRmpZMjkxYm5RdWRXbGtJam9pTURNNVpUZGpNalF0TXpkaVpTMDBNamt4TFRneE9HTXRNemxqWWpKaFkyVmhOekkySWl3aWMzVmlJam9pYzNsemRHVnRPbk5sY25acFkyVmhZMk52ZFc1ME9tUmxabUYxYkhRNmRHVnpkSE5oSW4wLkI3SFQtQWx5MWt2Wk1TTGFfSTREWHBGM0lkZ2JVaHJXWkczZXBQdVprcTQtWkpfcGN5MTJabkVCTUttLVRTbTFwNWhrQ3gzQm5NQzJ6QmF0VHJIRmp5TkhQSWRuZFJwMk9NMzZHeHNKOGNna0tOU21FMVg3bmM4R2w0ZkxYcDJXSWdUQVN2ZWFVOFI3UWFlZWhXaXdpNzNLNjVpMjNqNEtFYW9YRHhyS2hmb1RIWkdhVG5hVFdTTFZPNW5aRTBZNjg4VnVvem9rcEtrX21Qa1RteUpYUFhPanJKTGNBbHNkSGw2enVhaklJSlkyOGhUQTdCR2NyRnRGSzN3Nm1SLUdTSWpra2pzUmRkQW1mR1lsSVhlci1UMkItZ2Z0eWVaeElvM214OVJzRWhNdzY0Z2V6LUh6NmR6cC1JUVNqMHZwNmtHME1pbTR0WDdRZHpiOWhZaWNtQQ==|base64 -d)

# ä½¿ç”¨ä¸Šé¢TOKENè®¿é—®ï¼ŒéªŒè¯ç”¨æˆ·èº«ä»½ï¼Œä½†æƒé™ä¸è¶³
[root@master1 secret] # curl -s --cacert /etc/kubernetes/pki/ca.crt -H "Authorization:Bearer ${TOKEN}" https://10.0.0.201:6443 
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "forbidden: User \"system:serviceaccount:default:testsa\" cannot get path \"/\"",
  "reason": "Forbidden",
  "details": {},
  "code": 403
}

# åˆ é™¤
[root@master1 secret] # kubectl delete -f storage-secret-sa.yaml 
serviceaccount "testsa" deleted
```



#### TLSæ¡ˆä¾‹

TLS ç±»å‹çš„ Secret ä¸»è¦ç”¨äºå¯¹**httpsåœºæ™¯**çš„è¯ä¹¦å’Œå¯†é’¥æ–‡ä»¶æ¥è¿›è¡ŒåŠ å¯†ä¼ è¾“

```bash
#tlsç±»å‹æ ¼å¼
kubectl create secret tls NAME --cert=/path/file --key=/path/file

#æ³¨æ„ï¼š
#ä¿å­˜certæ–‡ä»¶å†…å®¹çš„keyåç§°ä¸èƒ½æŒ‡å®šï¼Œè‡ªåŠ¨ä¸ºtls.crtï¼Œå·æŒ‚è½½åç”Ÿæˆçš„æ–‡ä»¶åä¹Ÿä¸ºtls.crt
#ä¿å­˜private keyæ–‡ä»¶å†…å®¹çš„keyä¸èƒ½æŒ‡å®š,è‡ªåŠ¨ä¸ºtls.keyï¼Œå·æŒ‚è½½åç”Ÿæˆçš„æ–‡ä»¶åä¹Ÿä¸ºtls.key

```

![image-20250102102801681](../markdown_img/image-20250102102801681.png)



ä¸‹é¢æ¡ˆä¾‹å®ç°ä¸€ä¸ªåŸºäºhttps çš„nginxçš„webæœåŠ¡

#####  åˆ›å»º TLS è¯ä¹¦æ–‡ä»¶

```bash
# ç”Ÿæˆç§é’¥
[root@master1 tls]# openssl genrsa -out nginx-certs/mystical.org.key 2048

# ç”Ÿæˆè‡ªç­¾è¯ä¹¦
[root@master1 tls]# openssl req -new -x509 -key nginx-certs/mystical.org.key -days 3650 -out nginx-certs/mystical.org.crt -subj /C=CN/ST=Beijing/L=Beijing/O=DevOps/CN=www.mystical.org
#æ³¨æ„ï¼šCNæŒ‡å‘çš„åŸŸåå¿…é¡»æ˜¯nginxé…ç½®ä¸­ä½¿ç”¨çš„åŸŸåä¿¡æ¯

# æŸ¥çœ‹æ–‡ä»¶
[root@master1 tls]# ls nginx-certs/
mystical.org.crt  mystical.org.key
```



##### åŸºäº TLS è¯ä¹¦æ–‡ä»¶åˆ›å»ºå¯¹åº”çš„ Secret

```yaml
[root@master1 tls] # kubectl create secret tls secret-nginx-ssl --cert=nginx-certs/mystical.org.crt  --key=nginx-certs/mystical.org.key 
secret/secret-nginx-ssl created

# æŸ¥çœ‹ç»“æœ
[root@master1 tls] # kubectl get secrets 
NAME               TYPE                DATA   AGE
secret-nginx-ssl   kubernetes.io/tls   2      23s

# æŸ¥çœ‹å†…å®¹
[root@master1 tls]#kubectl get secrets secret-nginx-ssl -o yaml
apiVersion: v1
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURtekNDQW9PZ0F3SUJBZ0lVTjJtZHRnQU1obHNvdlRhbkxaK2F5M29oNW9jd0RRWUpLb1pJaHZjTkFRRUwKQlFBd1hURUxNQWtHQTFVRUJoTUNRMDR4RURBT0JnTlZCQWdNQjBKbGFXcHBibWN4RURBT0JnTlZCQWNNQjBKbAphV3BwYm1jeER6QU5CZ05WQkFvTUJrUmxkazl3Y3pFWk1CY0dBMVVFQXd3UWQzZDNMbTE1YzNScFkyRnNMbTl5Clp6QWVGdzB5TlRBeE1ESXdNak14TlRsYUZ3MHpOREV5TXpFd01qTXhOVGxhTUYweEN6QUpCZ05WQkFZVEFrTk8KTVJBd0RnWURWUVFJREFkQ1pXbHFhVzVuTVJBd0RnWURWUVFIREFkQ1pXbHFhVzVuTVE4d0RRWURWUVFLREFaRQpaWFpQY0hNeEdUQVhCZ05WQkFNTUVIZDNkeTV0ZVhOMGFXTmhiQzV2Y21jd2dnRWlNQTBHQ1NxR1NJYjNEUUVCCkFRVUFBNElCRHdBd2dnRUtBb0lCQVFEaVVZUjVacFoxY2NML0wydVNTZTB0aU5RMVpCVzRFaHN2YVdweHJTbncKeENac3NWb0pnbzV3eExmeTV6dTY1QmFLOTJsR29xbWRUWFYxbG54UTJERWQ0S3JXVmNDQnhlaHNDRGx1bVZUVgpIRGF0QkFpeWtzRWd4bmszNzdma2FHbGtKSmp0dWlCalRNdlNFUnlMYWlWbGI4Y1BjWDFyNzdNNXJMQ3lhdkZDCm5yM21JWWxYQi9POE42N21zdHI3TlNVNkN4ZFgzVkdXVzdRYzFLVFJ4SGhmQ1o0aHd3RTBFOFNZeHZuTTRsUkIKNitidThZbEpsb0JUZGFOQko3NkpaOE5CbzJpcEc0VTZSMmhMNEVPdnkyOGJBOWlCdisyc2RmM3NzQ0F3U1pqUgpab1RoTlQyaXU2cG5sTXR5Nzg5WmFpSTBPMThWZ2hVQ0swYU4zRmRnTE9VN0FnTUJBQUdqVXpCUk1CMEdBMVVkCkRnUVdCQlRGTGhreDFCQTJEMHNTUG1jVnhPNktDSWF0b3pBZkJnTlZIU01FR0RBV2dCVEZMaGt4MUJBMkQwc1MKUG1jVnhPNktDSWF0b3pBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFDZwoxTmhtZlcrOTRHTFBuNXE4QlFqcXpzL1ZSSlBGMTNYbXBDVTREczJFdm5ya0JXb0NRYXJlSmdiUjZzMi82R1dKCjVud0Ewbjd4VnBiYk1UV2U0bVdrd3N0STJPRXJhYnhlQml2NVdBeGF5ZzMzOXQ3WkhCQkJpdzFqZU14d28yNm4KMnlJUFkxU0dYMVdoY2RqL21FNVQyZnRYb3RLUHFrUk5lNFBpdDdXRlBEOUlWd3FJdWM3Q3QwSjFDaFpQVWZONgpxdGhaTUd4S2RQbVc4TnZaeU5GUDV6Q2JheXVXQmJFZjc0WE9tQ0Jqa0x4a0NIcHFkTjRwVkhQb3QxUkxRQ3pkCjlhWCsyUS9XMWdkS3pGMzNucnJLSTMzd3Jpclo3UVp5QjVBaHplOUxwMFBiQjRlTFkyUzgvRkxiaWhSZm90SEMKREJaQzltckFsNWNHK0pIeE42OFoKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
  tls.key: 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
kind: Secret
metadata:
  creationTimestamp: "2025-01-02T02:35:26Z"
  name: secret-nginx-ssl
  namespace: default
  resourceVersion: "254403"
  uid: e4c5eeac-23a3-4412-8f7e-c07dbf5dc837
type: kubernetes.io/tls
```



å‡†å¤‡Nginxé…ç½®æ–‡ä»¶

```bash
# nginxä¸»é…ç½®æ–‡ä»¶ myserver.conf
[root@master1 tls]#vim myserver.conf
server {
    listen 80;
    server_name www.mystical.org;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl;
    server_name www.mystical.org;
    
     ssl_certificate /etc/nginx/certs/tls.crt; 
     ssl_certificate_key /etc/nginx/certs/tls.key;
     ssl_session_timeout 5m;
     ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; 
     ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; 
     ssl_prefer_server_ciphers on;
     include /etc/nginx/conf.d/myserver-*.cfg;

     location / {
         root /usr/share/nginx/html;
     }
}

# nginxçš„å‹ç¼©é…ç½®æ–‡ä»¶:myserver-gzip.cfg
[root@master1 tls]#vim myserver-gzip.cfg
gzip on;
gzip_comp_level 5;
gzip_proxied     expired no-cache no-store private auth;
gzip_types text/plain text/css application/xml text/javascript;


# nginxçš„çŠ¶æ€é¡µé…ç½®æ–‡ä»¶myserver-status.cfg
[root@master1 tls]#vim myserver-status.cfg
location /status {
   stub_status on;
   access_log off;
}
```



#####  åˆ›å»ºé…ç½®æ–‡ä»¶å¯¹åº”çš„ Configmap

```bash
# æŸ¥çœ‹é…ç½®æ–‡ä»¶
[root@master1 tls]# ls nginx-ssl-conf.d/
myserver.conf  myserver-gzip.cfg  myserver-status.cfg

# åˆ›å»ºcm
[root@master1 tls]# kubectl create configmap cm-nginx-ssl-conf --from-file=nginx-ssl-conf.d/
configmap/cm-nginx-ssl-conf created

# æŸ¥çœ‹
[root@master1 tls]# kubectl get cm
NAME                DATA   AGE
cm-nginx-ssl-conf   3      42s
kube-root-ca.crt    1      4d18h
```



##### åˆ›å»ºå¼•ç”¨Secretå’Œconfigmapèµ„æºé…ç½®æ–‡ä»¶

```yaml
# åˆ›å»ºèµ„æºé…ç½®æ–‡ä»¶
[root@master1 tls] # cat storage-secret-nginx-ssl.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: pod-nginx-ssl
  namespace: default
spec:
  volumes:
  - name: nginx-certs
    secret:
      secretName: secret-nginx-ssl
  - name: nginx-confs
    configMap:
      name: cm-nginx-ssl-conf
      optional: false
  containers:
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
    name: nginx-ssl-server
    volumeMounts:
    - name: nginx-certs
      mountPath: /etc/nginx/certs/  # å…¶ä¿å­˜certæ–‡ä»¶è‡ªåŠ¨å‘½åä¸ºtls.crtï¼Œè€Œprivate keyæ–‡ä»¶ä¼šè‡ªåŠ¨å‘½åä¸ºtls.key
      readOnly: true
    - name: nginx-confs
      mountPath: /etc/nginx/conf.d/
      readOnly: true


# åº”ç”¨
[root@master1 tls] # kubectl apply -f storage-secret-nginx-ssl.yaml 
pod/pod-nginx-ssl created

# éªŒè¯ç»“æœ
[root@master1 tls] # kubectl get pod pod-nginx-ssl -o wide
NAME            READY   STATUS    RESTARTS   AGE   IP             NODE    NOMINATED NODE   READINESS GATES
pod-nginx-ssl   1/1     Running   0          24s   10.244.3.150   node3   <none>           <none>

# æŸ¥çœ‹ç”Ÿæˆçš„è¯ä¹¦æ–‡ä»¶ï¼Œè¡¨ç¤ºä¸ºå…³è”æ—¶é—´æˆ³ç›®å½•ä¸‹çš„ä¸¤ä¸ªåŒå±‚è½¯é“¾æ¥æ–‡ä»¶tls.crtå’Œtls.key,ä¿å­˜è¯ä¹¦çš„åŸå§‹æ–‡ä»¶,è€Œébase64æ ¼å¼
[root@master1 tls] # kubectl exec -it pod-nginx-ssl -- ls -l /etc/nginx/certs/
total 0
lrwxrwxrwx 1 root root 14 Jan  2 02:47 tls.crt -> ..data/tls.crt
lrwxrwxrwx 1 root root 14 Jan  2 02:47 tls.key -> ..data/tls.key

# è®¿é—®Pod
[root@master1 tls]#curl -H'host: www.mystical.org' http://10.244.3.150 -I
HTTP/1.1 301 Moved Permanently
Server: nginx/1.20.0
Date: Thu, 02 Jan 2025 02:59:02 GMT
Content-Type: text/html
Content-Length: 169
Connection: keep-alive
Location: https://www.mystical.org/

[root@master1 tls] # curl 10.244.3.150 -kL
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>

# æ¸…ç†ç¯å¢ƒ
[root@master1 tls] # kubectl delete -f storage-secret-nginx-ssl.yaml 
pod "pod-nginx-ssl" deleted
[root@master1 tls] # kubectl delete cm cm-nginx-ssl-conf 
configmap "cm-nginx-ssl-conf" deleted
[root@master1 tls] # kubectl delete secrets tls secret-nginx-ssl 
secret "secret-nginx-ssl" deleted
```



#### Docker-registryæ¡ˆä¾‹

æœ‰æ—¶Dockerçš„ä»“åº“æ˜¯ç§æœ‰çš„,å¦‚æœæƒ³ä¸‹è½½é•œåƒ,å°±éœ€è¦åœ¨ä¸‹è½½é•œåƒçš„ä¸»æœºä¸Šç™»å½•ä»“åº“å¹¶è®¤è¯åæ‰èƒ½å®ç°

ä½†æ˜¯åœ¨Kubernetesé›†ç¾¤ä½¿ç”¨ç§æœ‰ä»“åº“é•œåƒå°±æ¯”è¾ƒç¹ç,å› ä¸ºè¿è¡ŒPod çš„å®¿ä¸»æœºå¹¶ä¸å›ºå®š,å¦‚æœåœ¨æ¯ä¸ª workerèŠ‚ç‚¹ç™»å½•éªŒè¯æ˜¾ç„¶æ˜¯ä¸æ–¹ä¾¿çš„

dockercfgåŠdockerconfigjsonç±»å‹çš„Secret é€‚ç”¨äºå®ç°è®©kubeletä»ç§æœ‰Image Registryä¸­ä¸‹è½½å®¹å™¨é•œåƒ

å…¶å¼•ç”¨å®šä¹‰åœ¨pod.spec.imagePullSecretså­—æ®µä¸Šçš„åˆ—è¡¨,å³æ”¯æŒå¤šä¸ªdocker-registryç±»å‹çš„Secret,ä»ä¸Šè‡³ä¸‹é€ä¸ªè¿›è¡ŒåŒ¹é…



**åˆ›å»ºæ­¤ç§secret å¯ä»¥é€šè¿‡ä¸‹é¢æ–¹å¼å®ç°**

**æ–¹æ³•1: é€šè¿‡å‘½ä»¤åˆ›å»º**

```bash
kubectl create secret docker-registry KEYNAME --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=EMAIL
```



**æ–¹å¼äºŒ: é€šè¿‡dockerè®¤è¯æ–‡ä»¶åˆ›å»º**

```bash
# å…ˆç™»å½•å¹¶è®¤è¯åˆ°ç›®æ ‡ä»“åº“serverä¸Šï¼Œè®¤è¯å‡­æ®è‡ªåŠ¨ä¿å­˜åœ¨~/.docker/config.jsonæ–‡ä»¶ä¸­
docker login --username=DOCKER_USER DOCKER_REGISTRY_SERVER

#åŸºäºconfig.jsonæ–‡ä»¶ç”Ÿæˆsecret
kubectl create secret docker-registry KEYNAME --from-file=.dockerconfigjson=path/to/.docker/config.json

kubectl create secret generic KEYNAME --type='kubernetes.io/dockerconfigjson' --from-file=.dockerconfigjson=/root/.docker/config.json

# ç¤ºä¾‹
kubectl create secret docker-registry my-secret --from-file=.dockerconfigjson=path/to/.docker/config.json

kubectl create secret generic dockerharbor-auth --
type='kubernetes.io/dockerconfigjson' --from-file=.dockerconfigjson=/root/.docker/config.json
```





##### é€šè¿‡å‘½ä»¤åˆ›å»ºç§æœ‰ä»“åº“ç™»å½•è®¤è¯ä¿¡æ¯



**å®‰è£…å¹¶åˆ›å»ºHarborçš„ç§æœ‰ä»“åº“å’Œé¡¹ç›®**

```bash
# ä¸‹è½½harborçš„åŒ…
wget https://www.mysticalrecluse.com/script/tools/harbor-offline-installer-v2.11.0.tgz
# ä½¿ç”¨è„šæœ¬ä¸‹è½½å¹¶éƒ¨ç½²harbor
wget https://www.mysticalrecluse.com/script/Shell/install_harbor.sh
bash install_harbor.sh
......
Harbor å®‰è£…å®Œæˆ

Harborå®‰è£…å®Œæˆ!                                            [  OK  ]
-------------------------------------------------------------------
è¯·è®¿é—®é“¾æ¥: http://10.0.0.131/
ç”¨æˆ·å’Œå¯†ç : admin/123456
```

![image-20250102141543930](../markdown_img/image-20250102141543930.png)



##### åˆ›å»ºHarborç”¨æˆ·

![image-20250102141832106](../markdown_img/image-20250102141832106.png)



##### ç»™libraryé¡¹ç›®æ·»åŠ æˆå‘˜

![image-20250102141948806](../markdown_img/image-20250102141948806.png)



##### å°†harborçš„åŸŸåè§£ææ·»åŠ åˆ°åŸŸåæœåŠ¡å™¨ä¸Š

```bash
[root@ubuntu2204 ~]#cat /etc/bind/db.mystical.org 
$TTL 86400

@ IN  SOA dns1 msticalrecluse.gmail.com (123 12H 10M 3D 1D)

  IN  NS dns1

dns1 A 10.0.0.131
harbor A 10.0.0.131
feng A 11.11.11.11
nfs A 10.0.0.131

# ä¹‹å‰åœ¨CoreDNSä¸Šå·²ç»æŒ‡å®šäº†è½¬å‘çš„DNSæœåŠ¡å™¨ä¸º10.0.0.131
# éšä¾¿åˆ›å»ºä¸€ä¸ªPodæµ‹è¯•
[root@master1 yaml]# kubectl apply -f myapp.yaml 
deployment.apps/myapp created

# æˆåŠŸè§£æ
[root@master1 yaml]#kubectl exec myapp-7b94444f8d-7zqjv -- ping harbor.mystical.org
PING harbor.mystical.org. (10.0.0.131): 56 data bytes
64 bytes from 10.0.0.131: seq=0 ttl=63 time=0.755 ms
64 bytes from 10.0.0.131: seq=1 ttl=63 time=0.190 ms

# æ›´æ”¹harborçš„yamlæ–‡ä»¶ï¼ŒæŒ‡å®šåŸŸåè®¿é—®
[root@ubuntu2204 ~]#vim /usr/local/harbor/harbor.yml
hostname: harbor.mystical.org  # ---è¿™é‡Œæ›´æ”¹ä¸ºæŒ‡å®šåŸŸåï¼Œåç»­ä½¿ç”¨åŸŸåè®¿é—®harbor

# ä½¿ç”¨prepareé‡æ–°ç”Ÿæˆè„šæœ¬
[root@ubuntu2204 harbor]# ls
common     docker-compose.yml     harbor.yml       install.sh  prepare
common.sh  harbor.v2.11.0.tar.gz  harbor.yml.tmpl  LICENSE
[root@ubuntu2204 harbor]# ./prepare 
prepare base dir is set to /usr/local/harbor
WARNING:root:WARNING: HTTP protocol is insecure. Harbor will deprecate http protocol in the future. Please make sure to upgrade to https
Clearing the configuration file: /config/nginx/nginx.conf
Clearing the configuration file: /config/registryctl/config.yml
Clearing the configuration file: /config/registryctl/env
Clearing the configuration file: /config/db/env
Clearing the configuration file: /config/log/rsyslog_docker.conf
Clearing the configuration file: /config/log/logrotate.conf
Clearing the configuration file: /config/registry/config.yml
Clearing the configuration file: /config/registry/root.crt
Clearing the configuration file: /config/registry/passwd
Clearing the configuration file: /config/core/env
Clearing the configuration file: /config/core/app.conf
Clearing the configuration file: /config/portal/nginx.conf
Clearing the configuration file: /config/jobservice/config.yml
Clearing the configuration file: /config/jobservice/env
Generated configuration file: /config/portal/nginx.conf
Generated configuration file: /config/log/logrotate.conf
Generated configuration file: /config/log/rsyslog_docker.conf
Generated configuration file: /config/nginx/nginx.conf
Generated configuration file: /config/core/env
Generated configuration file: /config/core/app.conf
Generated configuration file: /config/registry/config.yml
Generated configuration file: /config/registryctl/env
Generated configuration file: /config/registryctl/config.yml
Generated configuration file: /config/db/env
Generated configuration file: /config/jobservice/env
Generated configuration file: /config/jobservice/config.yml
loaded secret from file: /data/secret/keys/secretkey
Generated configuration file: /compose_location/docker-compose.yml
Clean up the input dir

# åˆ é™¤ä¹‹å‰çš„docker composeèµ·çš„harborï¼Œé‡æ–°åˆ›å»ºharbor
[root@ubuntu2204 harbor]# docker-compose down
Stopping harbor-jobservice ... done
Stopping nginx             ... done
Stopping harbor-core       ... done
Stopping redis             ... done
Stopping harbor-db         ... done
Stopping harbor-portal     ... done
Stopping registry          ... done
Stopping registryctl       ... done
Stopping harbor-log        ... done
Removing harbor-jobservice ... done
Removing nginx             ... done
Removing harbor-core       ... done
Removing redis             ... done
Removing harbor-db         ... done
Removing harbor-portal     ... done
Removing registry          ... done
Removing registryctl       ... done
Removing harbor-log        ... done
Removing network harbor_harbor

# é‡æ–°ä½¿ç”¨serviceå¯åŠ¨harbor
[root@ubuntu2204 harbor]# systemctl start harbor.service 
```



##### æ›´æ”¹å®¿ä¸»æœºä¸Šçš„hostæ–‡ä»¶åï¼Œä½¿ç”¨åŸŸåç™»å½•harbor

![image-20250102145733724](../markdown_img/image-20250102145733724.png)



##### ä½¿dockerä¿¡ä»»harborï¼Œä¿®æ”¹æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„dockeré…ç½®

```bash
# ä¿®æ”¹æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹çš„Dockeré…ç½®æ”¯æŒç§æœ‰ä»“åº“
[root@node1 ~]# vim /etc/docker/daemon.json 
{
      "registry-mirrors": ["https://si7y70hh.mirror.aliyuncs.com"],
      "insecure-registries": ["harbor.mystical.org"], # æ·»åŠ æ­¤è¡Œ
      "no-proxy": "127.0.0.0/8,172.17.0.0/16,10.0.0.0/24,10.244.0.0/16,192.168.0.0/16,wang.org,cluster.local,harbor.mystical.org" # å¦‚æœé…äº†ä»£ç†ï¼Œåœ¨ä»£ç†ä¸­å°†harbor.mystical.orgæ’é™¤ï¼Œä¹Ÿå°±æ˜¯æ·»åŠ harbor.mystical.orgåœ¨noproxyå­—æ®µ
     }

# æ›´æ”¹ä»£ç†é…ç½®ï¼Œä¿®æ”¹ /etc/systemd/system/docker.service.d/http-proxy.conf æ–‡ä»¶
[root@node1 ~]# vim /etc/systemd/system/docker.service.d/http-proxy.conf
[Service]
Environment="NO_PROXY=127.0.0.0/8,172.17.0.0/16,10.0.0.0/24,10.244.0.0/16,192.168.0.0/16,wang.org,cluster.local,harbor.mystical.org" # ä¿®æ”¹è¿™è¡Œ


# é‡å¯docker
[root@node1 ~]#systemctl daemon-reload
[root@node1 ~]# systemctl restart docker

# æŸ¥çœ‹
[root@node1 ~]#docker info
......
 HTTP Proxy: http://10.0.0.1:10809/
 HTTPS Proxy: http://10.0.0.1:10809/
 # åœ¨noproxyä¸­æ·»åŠ harbor.mystical.org
 No Proxy: 127.0.0.0/8,172.17.0.0/16,10.0.0.0/24,10.244.0.0/16,192.168.0.0/16,wang.org,cluster.local,harbor.mystical.org
 Experimental: false
 # æ·»åŠ ä¿¡ä»»
 Insecure Registries:
  harbor.mystical.org
  127.0.0.0/8
 Registry Mirrors:
  https://si7y70hh.mirror.aliyuncs.com/
 Live Restore Enabled: false
 Product License: Community Engine


# ç™»å½•æµ‹è¯•
[root@node1 ~]# docker login harbor.mystical.org -u mystical -p 'Zyf646130..'
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
```



##### ä½¿ç”¨å‘½ä»¤è¡Œæ–¹å¼åˆ›å»ºdocker-registryç±»å‹çš„secret

```bash
[root@master1 yaml]# kubectl create secret docker-registry harbor-docker-registry-secret --docker-server=harbor.mystical.org --docker-username=mystical --docker-password=Zyf646130..
secret/harbor-docker-registry-secret created

# æŸ¥çœ‹
[root@master1 yaml]# kubectl get secret
NAME                            TYPE                             DATA   AGE
harbor-docker-registry-secret   kubernetes.io/dockerconfigjson   1      21s

```



##### ä½¿ç”¨adminè´¦å·ï¼Œåˆ›å»ºä¸€ä¸ªç§æœ‰é¡¹ç›®exampleï¼Œå¹¶æ·»åŠ æˆå‘˜mystical

![image-20250102153457019](../markdown_img/image-20250102153457019.png)

![image-20250102153558659](../markdown_img/image-20250102153558659.png)



##### åœ¨nodeèŠ‚ç‚¹æµ‹è¯•ç§æœ‰ä»“èƒ½å¦ä¸Šä¼ ä¸‹è½½é•œåƒ

```bash
# ç™»å½•
[root@node3 ~]#docker login harbor.mystical.org -u mystical -p 'Zyf646130..'
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded

# æŸ¥çœ‹dockeré•œåƒï¼Œé€‰ä¸€ä¸ªä¸Šä¼ åˆ°harborä»“åº“
[root@node3 ~]#docker images

# æ›´æ”¹é•œåƒtagåç§°
[root@node3 ~]#docker tag registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0 harbor.mystical.org/example/nginx:1.20.0

# ä¸Šä¼ æˆåŠŸ
[root@node3 ~]#docker push harbor.mystical.org/example/nginx:1.20.0
The push refers to repository [harbor.mystical.org/example/nginx]
272bc57d3405: Pushed 
f7141923aaa3: Pushed 
9b63e6289fbe: Pushed 
a2f4f809e04e: Pushed 
1839f9962bd8: Pushed 
02c055ef67f5: Pushed 
1.20.0: digest: sha256:598057a5c482d2fb42092fd6f4ba35ea4cc86c41f5db8bb68d1ab92c4c40db98 size: 1570
```



##### ä½¿ç”¨åˆ›å»ºçš„secretè®©k8sä»ç§æœ‰ä»“ä¸­æ‹‰å–é•œåƒ

```bash
[root@master1 yaml]#cat storage-secret-docker-registry-harbor.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-harbor-docker-registry-secret
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pod-test-harbor-docker-registry-secret
  template:
    metadata:
      labels:
        app: pod-test-harbor-docker-registry-secret
    spec:
      containers:
      - name: pod-test-harbor-docker-registry-secret
        image: harbor.mystical.org/example/nginx:1.20.0
      imagePullSecrets:
      - name: harbor-docker-registry-secret  # æŒ‡å®šdocker-registryç±»å‹çš„secretï¼Œå¦‚æœæœ‰å¤šä¸ªä¼šé€ä¸ªéªŒè¯

# åº”ç”¨
[root@master1 yaml]# kubectl apply -f storage-secret-docker-registry-harbor.yaml 
deployment.apps/deployment-harbor-docker-registry-secret created

# æŸ¥çœ‹
[root@master1 yaml]#kubectl get pod -o wide
NAME                                                       READY   STATUS    RESTARTS      AGE   IP             NODE    NOMINATED NODE   READINESS GATES
deployment-harbor-docker-registry-secret-97787d89c-fbw8v   1/1     Running   0             22s   10.244.1.143   node1   <none>           <none>
deployment-harbor-docker-registry-secret-97787d89c-plcdx   1/1     Running   0             22s   10.244.2.88    node2   <none>           <none>
deployment-harbor-docker-registry-secret-97787d89c-tgzmx   1/1     Running   0             22s   10.244.3.154   node3   <none>           <none>
myapp-7b94444f8d-7zqjv                                     1/1     Running   2 (20m ago)   88m   10.244.2.86    node2   <none>           <none>
myapp-7b94444f8d-9x8xk                                     1/1     Running   1 (20m ago)   88m   10.244.3.152   node3   <none>           <none>
myapp-7b94444f8d-dh7jd                                     1/1     Running   4 (28m ago)   88m   10.244.1.140   node1   <none>           <none>
```



##### ä¸åŒåç§°ç©ºé—´ Pod ä½¿ç”¨ Secret æ‹‰å–ç§æœ‰é•œåƒè§£å†³æ–¹æ¡ˆ

åœ¨ Kubernetes ä¸­ï¼Œ**ä¸åŒå‘½åç©ºé—´çš„ Pod ä¸èƒ½ç›´æ¥ä½¿ç”¨å…¶ä»–å‘½åç©ºé—´ä¸‹çš„ Secret**ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒSecret çš„ä½œç”¨èŒƒå›´**ä»…é™äºå…¶æ‰€åœ¨çš„å‘½åç©ºé—´**ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä½ ä¸èƒ½åœ¨ `my-namespace` ä¸‹çš„ Pod ç›´æ¥ä½¿ç”¨ `default` å‘½åç©ºé—´çš„ Secret æ¥æ‹‰å– Harbor é•œåƒã€‚



1ï¸âƒ£ **å¤åˆ¶ Secret åˆ°ç›®æ ‡å‘½åç©ºé—´ï¼ˆæ¨èï¼‰**

æœ€ç®€å•çš„æ–¹æ³•æ˜¯**å¤åˆ¶ `default` å‘½åç©ºé—´çš„ Secret åˆ°å…¶ä»–å‘½åç©ºé—´**ï¼š

```bash
kubectl get secret my-secret -n default -o yaml | sed 's/namespace: default/namespace: my-namespace/g' | kubectl apply -f -
```

ç„¶ååœ¨ Pod é…ç½®ï¼š

```yaml
spec:
  imagePullSecrets:
    - name: my-secret
```

âœ… **é€‚ç”¨äºå¤šä¸ªå‘½åç©ºé—´éœ€è¦å…±ç”¨ Secret çš„æƒ…å†µ**ã€‚



2ï¸âƒ£ **ä½¿ç”¨ Mutating Admission Webhook è‡ªåŠ¨æ³¨å…¥ Secret**

å¦‚æœä½ ä¸æƒ³æ‰‹åŠ¨å¤åˆ¶ Secretï¼Œå¯ä»¥ä½¿ç”¨ Kubernetes **Mutating Admission Webhook**ï¼Œè‡ªåŠ¨åœ¨åˆ›å»º Pod æ—¶**æ³¨å…¥ `imagePullSecrets`**ã€‚

```ABAP
è¯¦ç»†è§£å†³æ–¹æ¡ˆï¼šæŸ¥çœ‹çŸ¥è¯†æ‰©å±•ï¼Œå…³äºMutating Admission Webhookçš„å®Œæ•´æ•™å­¦
```



3ï¸âƒ£ **ä½¿ç”¨ `kubelet` çš„ `dockercfg` å…±äº«**

å¦‚æœé›†ç¾¤è§„æ¨¡è¾ƒå¤§ï¼Œ**å¯ä»¥å°† Harbor è®¤è¯ä¿¡æ¯æ”¾å…¥ `/var/lib/kubelet/config.json`**ï¼Œè¿™æ ·æ‰€æœ‰ `namespace` çš„ Pod éƒ½å¯ä»¥æ‹‰å–ç§æœ‰é•œåƒï¼š

```bash
cp ~/.docker/config.json /var/lib/kubelet/
systemctl restart kubelet
```

ä½†è¿™ç§æ–¹å¼é€‚ç”¨äº **æ—  RBAC é™åˆ¶çš„ç¯å¢ƒ**



**âœ… æœ€ä½³å®è·µ**

| æ–¹æ¡ˆ                        | é€‚ç”¨åœºæ™¯               | å¤æ‚åº¦ | é€‚é…æ€§         |
| --------------------------- | ---------------------- | ------ | -------------- |
| **å¤åˆ¶ Secret**             | é€‚åˆå°‘é‡å‘½åç©ºé—´       | ä½     | æ¨è           |
| **Webhook è‡ªåŠ¨æ³¨å…¥ Secret** | é€‚åˆå¤§è§„æ¨¡é›†ç¾¤         | é«˜     | é€‚åˆä¼ä¸š       |
| **å…±äº« `dockercfg`**        | é€‚åˆæ—  RBAC é™åˆ¶çš„é›†ç¾¤ | ä¸­     | é€‚ç”¨äºéƒ¨åˆ†ç¯å¢ƒ |

å¦‚æœä½ çš„éœ€æ±‚æ˜¯ **Pod è·¨å‘½åç©ºé—´å…±ç”¨ Secret**ï¼Œæ¨è **ç›´æ¥å¤åˆ¶ Secret**ï¼ˆæ–¹æ¡ˆ 1ï¼‰ï¼Œæˆ–è€…**ä½¿ç”¨ Admission Webhook** è¿›è¡Œè‡ªåŠ¨æ³¨å…¥ï¼ˆæ–¹æ¡ˆ 2ï¼‰ã€‚



#### External Secrets Operator (ESO) â€” Vault



### downwardAPI

#### dockerwardAPIä»‹ç»

åœ¨Kubernetesä¸­ å¯ä»¥åŸºäºä¸€ç§ downwardAPI çš„å¯¹è±¡ï¼Œ**å°†å®¿ä¸»æœºç›¸å…³çš„ä¿¡æ¯ä»¥å­˜å‚¨å·çš„æ ·å¼åŠ è½½åˆ°podå†…éƒ¨**ã€‚

ç›¸è¾ƒäºconfigmapã€secretç­‰èµ„æºå¯¹è±¡éœ€è¦åˆ›å»ºåæ‰èƒ½ä½¿ç”¨ï¼ŒdownwardAPI ä¸æ˜¯å­˜å‚¨å·ï¼Œæ— éœ€äººä¸ºåˆ› å»ºï¼Œå®ƒè‡ªèº«ä¸€ç›´å°±å­˜åœ¨ã€‚

downwardAPI ä¸æ˜¯ä¸€ç§ç‹¬ç«‹çš„APIèµ„æºç±»å‹ï¼Œåªæ˜¯ä¸€ç§å¼•ç”¨Podè‡ªèº«çš„è¿è¡Œç¯å¢ƒä¿¡æ¯

downwardAPI åŒ…æ‹¬Podçš„metadata,spectæˆ–statuså­—æ®µå€¼ï¼Œå°†è¿™äº›ä¿¡æ¯æ³¨å…¥åˆ°å®¹å™¨å†…éƒ¨çš„æ–¹å¼

downwardAPI ä¸ºè¿è¡Œåœ¨podä¸­çš„åº”ç”¨å®¹å™¨æä¾›äº†ä¸€ç§åå‘å¼•ç”¨ã€‚è®©å®¹å™¨ä¸­çš„åº”ç”¨ç¨‹åºäº†è§£æ‰€å¤„podæˆ– Nodeçš„ä¸€äº›åŸºç¡€å±æ€§ä¿¡æ¯ã€‚



![image-20250102155831373](../markdown_img/image-20250102155831373.png)



ä¸è¿‡ï¼Œ**é€šå¸¸åªæœ‰å¸¸é‡ç±»å‹çš„å±æ€§**æ‰èƒ½å¤Ÿé€šè¿‡ç¯å¢ƒå˜é‡æ³¨å…¥åˆ°å®¹å™¨ä¸­ï¼Œæ¯•ç«Ÿï¼Œåœ¨è¿›ç¨‹å¯åŠ¨å®Œæˆåæ— æ³•å†å‘ å…¶å‘ŠçŸ¥å˜é‡å€¼çš„å˜åŠ¨ï¼Œäºæ˜¯ï¼Œç¯å¢ƒå˜é‡ä¹Ÿå°±ä¸æ”¯æŒä¸­é€”çš„æ›´æ–°æ“ä½œã€‚



**DownwardAPIæä¾›äº†ä¸¤ç§æ–¹å¼ç”¨äºå°† Pod çš„ä¿¡æ¯æ³¨å…¥åˆ°å®¹å™¨å†…éƒ¨**

- **ç¯å¢ƒå˜é‡**ï¼šç”¨äºå•ä¸ªå˜é‡ï¼Œå¯ä»¥å°† Pod ä¿¡æ¯å’Œå®¹å™¨ä¿¡æ¯ç›´æ¥æ³¨å…¥å®¹å™¨å†…éƒ¨
- **VolumeæŒ‚è½½**ï¼šå°† Pod ä¿¡æ¯ç”Ÿæˆä¸ºæ–‡ä»¶ï¼Œå†æŒ‚è½½åˆ°å®¹å™¨å†…éƒ¨ä¸­



ç±»ä¼¼äºConfigMapæˆ–Secretèµ„æºï¼Œå®¹å™¨èƒ½å¤Ÿåœ¨ç¯å¢ƒå˜é‡ä¸­**valueFromå­—æ®µ**ä¸­åŸºäº**ä¸¤ä¸ªå­—æ®µ**æ¥å¼•ç”¨å…¶æ‰€å± Podå¯¹è±¡çš„å…ƒæ•°æ®ä¿¡æ¯

- **fieldRef**ï¼šå¼•ç”¨å¸¸è§„æ€§çš„å…ƒæ•°æ®
- **resourceFieldRef**ï¼šå¼•ç”¨å’Œèµ„æºé™åˆ¶å’Œèµ„æºè¯·æ±‚ç›¸å…³çš„å…ƒæ•°æ®



**Downward API fields injected via the fieldRef field**

| Field                       | Description                                                  | Allowed in env | Allowed in volume |
| --------------------------- | ------------------------------------------------------------ | -------------- | ----------------- |
| metadata.name               | The podâ€™s name.                                              | Yes            | Yes               |
| metadata.namespace          | The podâ€™s namespace.                                         | Yes            | Yes               |
| metadata.uid                | The podâ€™s UID.                                               | Yes            | Yes               |
| metadata.labels             | All the podâ€™s labels, one label per line, formatted as key=â€ valueâ€ . | No             | Yes               |
| metadata.labels['key']      | The value of the specified label.                            | Yes            | Yes               |
| metadata.annotations        | All the podâ€™s annotations, one per line, formatted as key=â€ valueâ€ . | No             | Yes               |
| metadata.annotations['key'] | The value of the specified annotation.                       | Yes            | Yes               |
| spec.nodeName               | The name of the worker node the pod runs on.                 | Yes            | No                |
| spec.serviceAccountName     | The name of the podâ€™s service account.                       | Yes            | No                |
| status.podIP                | The podâ€™s IP address                                         | Yes            | No                |
| status.hostIP               | The worker nodeâ€™s IP address.                                | Yes            | No                |



**Table 9.6 Downward API resource fields injected via the resourceFieldRef field**

| Resource field             | Description                                | Allowed in env | Allowed in vol |
| -------------------------- | ------------------------------------------ | -------------- | -------------- |
| requests.cpu               | The containerâ€™s CPU request.               | Yes            | Yes            |
| requests.memory            | The containerâ€™s memory request.            | Yes            | Yes            |
| requests.ephemeral-storage | The containerâ€™s ephemeral storage request. | Yes            | Yes            |
| limits.cpu                 | The containerâ€™s CPU limit.                 | Yes            | Yes            |
| limits.memory              | The containerâ€™s memory limit.              | Yes            | Yes            |
| limits.ephemeral-storage   | The containerâ€™s ephemeral storage limit.   | Yes            | Yes            |



#### downwardAPIæ¡ˆä¾‹

##### èŒƒä¾‹ï¼šè·å–åŸºæœ¬çš„å˜é‡ä¿¡æ¯é€šè¿‡å˜é‡æ–¹å¼å¼•ç”¨

```yaml
# å®šåˆ¶çš„èµ„æºå¯¹è±¡
[root@master1 yaml] # vim storage-downwardapi-env-test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: downwardapi-env-test
  labels:
    app: downwardapi-env
spec:
  containers:
  - name: downwardapi-env-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    resources:
      requests:
        memory: "32Mi"
        cpu: "250m"
      limits:
        memory: "64Mi"
        cpu: "500m"
    env:
    - name: THIS_POD_NAME
      valueFrom:
        fieldRef:                 
          fieldPath: metadata.name 
          # "fieldPath"æŒ‡å®šçš„æ˜¯ Pod çš„æŸäº›å…ƒæ•°æ®å­—æ®µçš„è·¯å¾„ï¼Œå®ƒå‘Šè¯‰ Kubernetes è¦ä» Pod çš„å“ªäº›éƒ¨åˆ†æå–å€¼ã€‚
    - name: THIS_POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: THIS_APP_LABEL
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['app']
    - name: THIS_CPU_LIMIT
      valueFrom:
        resourceFieldRef:
          resource: limits.cpu
    - name: THIS_MEM_REQUEST
      valueFrom:
        resourceFieldRef:
          resource: requests.memory
          divisor: 1Mi
    - name: VAR_REF
      value: $(THIS_POD_NAMESPACE).wang.org  # å˜é‡å¼•ç”¨æ ¼å¼:$(VAR_NAME)


[root@master1 yaml] # kubectl apply -f storage-downwardapi-env-test.yaml 
pod/downwardapi-env-test created

[root@master1 yaml] # kubectl get pod
NAME                   READY   STATUS    RESTARTS   AGE
downwardapi-env-test   1/1     Running   0          2m36s

# æŸ¥çœ‹ç¯å¢ƒå˜é‡
[root@master1 yaml] # kubectl exec -it downwardapi-env-test -- env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=downwardapi-env-test
TERM=xterm
THIS_APP_LABEL=downwardapi-env
THIS_CPU_LIMIT=1
THIS_MEM_REQUEST=32
VAR_REF=default.wang.org
THIS_POD_NAME=downwardapi-env-test
THIS_POD_NAMESPACE=default
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
KUBERNETES_SERVICE_HOST=10.96.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
DEPLOYENV=Production
RELEASE=Stable
PS1=[\u@\h \w]\$ 
HOME=/root

# åˆ é™¤
[root@master1 yaml]#kubectl delete pod downwardapi-env-test 
pod "downwardapi-env-test" deleted
```



##### èŒƒä¾‹ï¼šå­˜å‚¨å·æ–¹å¼ä½¿ç”¨

```yaml
[root@master1 yaml] # vim storage-downwardapi-volume-test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: downwardapi-volume-test
  labels:
    zone: Beijing
    rack: zhongguancun
    app: redis-master
  annotations:
    region: Asia-China
spec:
  volumes:
  - name: podinfo
    downwardAPI:
      defaultMode: 0420  # æ–‡ä»¶æƒé™ï¼Œé»˜è®¤0644
      items:
      - fieldRef:
          fieldPath: metadata.namespace
        path: pod_namespace
      - fieldRef:
          fieldPath: metadata.labels
        path: pod_labels
      - fieldRef:
          fieldPath: metadata.annotations
        path: pod_annotations
      - resourceFieldRef:
          containerName: downwardapi-volume-test
          resource: limits.cpu
        path: "cpu_limit"
      - resourceFieldRef:
          containerName: downwardapi-volume-test
          resource: requests.memory
          divisor: "1Mi"              # å°†èµ„æºå€¼è¿›è¡Œæ•´é™¤æ“ä½œï¼Œä»è€Œå°†èµ„æºå€¼è½¬æ¢ä¸ºä»¥æŒ‡å®šå•ä½ä¸ºåŸºå‡†çš„æ•´æ•°å€¼ã€‚
        path: "mem_request"
  containers:
  - name: downwardapi-volume-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    resources:
      requests:
        memory: "32Mi"
        cpu: "250m"
      limits:
        memory: "64Mi"
        cpu: "500m"
    volumeMounts:
    - name: podinfo
      mountPath: /etc/podinfo
      readOnly: false

# åº”ç”¨
[root@master1 yaml] # kubectl apply -f storage-downwardapi-volume-test.yaml 
pod/downwardapi-volume-test created

# æŸ¥çœ‹
[root@master1 yaml]#kubectl get pod
NAME                      READY   STATUS    RESTARTS   AGE
downwardapi-volume-test   1/1     Running   0          3s

# æŸ¥çœ‹å®¹å™¨å†…æŒ‚è½½çš„æ–‡ä»¶åŠå…¶å†…å®¹
[root@master1 yaml] # kubectl exec downwardapi-volume-test -- ls /etc/podinfo -l
total 0
lrwxrwxrwx    1 root     root            16 Jan  2 09:31 cpu_limit -> ..data/cpu_limit
lrwxrwxrwx    1 root     root            18 Jan  2 09:31 mem_request -> ..data/mem_request
lrwxrwxrwx    1 root     root            22 Jan  2 09:31 pod_annotations -> ..data/pod_annotations
lrwxrwxrwx    1 root     root            17 Jan  2 09:31 pod_labels -> ..data/pod_labels
lrwxrwxrwx    1 root     root            20 Jan  2 09:31 pod_namespace -> ..data/pod_namespace

[root@master1 yaml] # kubectl exec downwardapi-volume-test -- cat /etc/podinfo/pod_labels
app="redis-master"
rack="zhongguancun"
zone="Beijing"

# åˆ é™¤
[root@master1 yaml] # kubectl delete pod downwardapi-volume-test 
pod "downwardapi-volume-test" deleted
```





### Projected

#### Projectedè¯´æ˜

ä¹‹å‰çš„CM,Secretç­‰å·èµ„æºåœ¨Podå†…çš„ä¸€ä¸ªç›®å½•åŒæ—¶åªèƒ½æŒ‚è½½ä¸€ä¸ªå·ï¼Œè€Œæˆ‘ä»¬æœ‰æ—¶å¸Œæœ›åœ¨ä¸€ä¸ªç›®å½•å†…ç”Ÿæˆ æ¥è‡ªå¤šä¸ªå·çš„å¤šä¸ªæ–‡ä»¶

**Projected volumes æ˜¯ä¸€ç§ç‰¹æ®Šçš„å·ç±»å‹ï¼Œæ”¯æŒåŒæ—¶æŠ•å°„å¤šä¸ªå·è‡³åŒä¸€ä¸ªæŒ‚è½½ç‚¹**

Projected ä¸æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„API èµ„æºç±»å‹ï¼Œä½†å…¶å¯ä»¥å¼•ç”¨ç°æœ‰çš„configmapã€secretèµ„æºå¯¹è±¡ï¼Œæˆ– downwardAPIä¸­çš„å…ƒæ•°æ®ä¿¡æ¯

æ­¤ç±»çš„å·ä¸€èˆ¬ç”¨äºä¸ºå®¹å™¨æä¾›é¢„å…ˆå®šä¹‰å¥½çš„æ•°æ®

![image-20250102174640664](../markdown_img/image-20250102174640664.png)



**Projected Volumeä»…æ”¯æŒå¯¹å¦‚ä¸‹å››ç§ç±»å‹çš„å·ï¼ˆæ•°æ®æºï¼‰è¿›è¡ŒæŠ•å°„æ“ä½œ**

- **Secret**ï¼šæŠ•å°„Secretå¯¹è±¡
- **ConfigMap**ï¼šæŠ•å°„ConfgMapå¯¹è±¡
- **DownwardAPI**ï¼šæŠ•å°„Podå…ƒæ•°æ®
- **ServiceAccountToken**ï¼šæŠ•å°„ServiceAccountToken



#### Projectedæ¡ˆä¾‹

##### èŒƒä¾‹ï¼šExample configuration with a secret, a downwardAPI, and a configMap

```yaml
# èµ„æºæ¸…å•æ–‡ä»¶
[root@master1 yaml] # vim storage-projected-demo.yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
  namespace: default
data:
  username: d2FuZ3hpYW9jaHVu
type: Opaque
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: myconfigmap
  namespace: default
data:
  myconfig: Hello, Myconfig
---
apiVersion: v1
kind: Pod
metadata:
  name: projected-volume-demo
spec:
  containers:
  - name: container-test
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    volumeMounts:
    - name: all-in-one
      mountPath: "/projected-volume"
      readOnly: true
  volumes:
  - name: all-in-one
    projected:
      sources:
      - secret:
          name: mysecret
          items:
          - key: username
            path: my-group/my-username
      - downwardAPI:
          items:
          - path: "labels"
            fieldRef:
              fieldPath: metadata.labels
          - path: "cpu_limit"
            resourceFieldRef:
              containerName: container-test
              resource: limits.cpu
      - configMap:
          name: myconfigmap
          items:
          - key: myconfig
            path: my-group/my-config

# åº”ç”¨
[root@master1 yaml] # kubectl apply -f storage-projected-demo.yaml 
secret/mysecret unchanged
configmap/myconfigmap unchanged
pod/projected-volume-demo created

# æŸ¥çœ‹
[root@master1 yaml] # kubectl get pod
NAME                    READY   STATUS    RESTARTS   AGE
projected-volume-demo   1/1     Running   0          7s

# æŸ¥çœ‹æŒ‚è½½æ–‡ä»¶
[root@master1 yaml] # kubectl exec projected-volume-demo -- ls /projected-volume -l
total 0
lrwxrwxrwx    1 root     root            16 Jan  2 10:03 cpu_limit -> ..data/cpu_limit
lrwxrwxrwx    1 root     root            13 Jan  2 10:03 labels -> ..data/labels
lrwxrwxrwx    1 root     root            15 Jan  2 10:03 my-group -> ..data/my-group

[root@master1 yaml] # kubectl exec projected-volume-demo -- ls /projected-volume/my-group/  -l
total 8
-rw-r--r--    1 root     root            15 Jan  2 10:03 my-config
-rw-r--r--    1 root     root            12 Jan  2 10:03 my-username

```



### ç»¼åˆæ¡ˆä¾‹ï¼šä½¿ç”¨æŒä¹…å·éƒ¨ç½²WordPresså’ŒMySQL

åœ¨kuberneteséƒ¨ç½² wordpressï¼Œè¦æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

- éƒ¨ç½²ä¸€ä¸ªç‹¬ç«‹çš„nginx Podå®ä¾‹ï¼Œä¸ºwordpressæä¾›åå‘ä»£ç†ï¼›åŒæ—¶æä¾›httpså’Œhttpè™šæ‹Ÿä¸»æœºï¼Œå…¶ä¸­å‘å¾€httpçš„è¯·æ±‚éƒ½é‡å®šå‘ç»™httpsï¼›ä»¥ConfigMapå’ŒSecretæä¾›å¿…è¦çš„é…ç½®
- ç‹¬ç«‹éƒ¨ç½²ä¸¤ä¸ªwordpress Podå®ä¾‹ï¼Œå®ƒä»¬ä½¿ç”¨NFS StorageClass å­˜å‚¨å·å­˜å‚¨ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡æˆ–æ–‡ ä»¶ç­‰æ•°æ®ï¼›ä»¥ConfigMapå’ŒSecretæä¾›å¿…è¦çš„é…ç½®
- éƒ¨ç½²ä¸€ä¸ªMySQLæ•°æ®åº“ï¼›ä»¥ConfigMapå’ŒSecretæä¾›å¿…è¦çš„é…ç½®
- service æš´éœ² nginxçš„æœåŠ¡ï¼Œç„¶åä»¥åå‘ä»£ç†çš„æ–¹å¼è¿›è¡Œè®¿é—®
- åŠ¨æ€çš„è“ç»¿å‘å¸ƒå’Œæ»šåŠ¨å‘å¸ƒ
  - å¯¹äºwordpress æ¥è¯´ï¼Œæ²¡æœ‰æœ¬è´¨çš„åŒºåˆ«
  - nginxçš„æ›´æ–°ï¼Œä¾èµ–configmapå’Œsecretçš„å†…å®¹



**ç®€å•ç‰ˆï¼šæ— nginxåå‘ä»£ç†**

```yaml
# æå‰å‡†å¤‡å¥½åŠ¨æ€ç½®å¤‡ç¨‹åºçš„Podï¼Œsa
# æå‰å‡†å¤‡åä¸ºsc-nfsçš„storageClass
[root@master1 yaml] # kubectl get sc
NAME     PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
sc-nfs   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  2d8h

[root@master1 nsf-provisioner] # kubectl get pod -n nfs-provisioner-demo 
NAME                                      READY   STATUS    RESTARTS   AGE
nfs-client-provisioner-649b64df96-tq8hq   1/1     Running   0          7m29s

[root@master1 nsf-provisioner] # kubectl get sa -n nfs-provisioner-demo 
NAME                     SECRETS   AGE
default                  0         8m27s
nfs-client-provisioner   0         8m27s

# æ¸…å•æ–‡ä»¶
[root@master1 yaml] # cat mysql-wordpress-persistent-volume.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: mysql-pass
type: kubernetes.io/basic-auth
data:
  password: MTIzNDU2

---
apiVersion: v1
kind: Service
metadata:
  name: wordpress-mysql
  labels: 
    app: wordpress
spec:
  ports:
  - port: 3306
  selector:
    app: wordpress
    tier: mysql
  clusterIP: None

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pv-claim
  labels:
    app: wordpress
spec:
  storageClassName: sc-nfs
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  selector:
    matchLabels:
      app: wordpress
      tier: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: mysql
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/mysql:8.0.29-oracle
        name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        - name: MYSQL_DATABASE
          value: wordpress
        - name: MYSQL_USER
          value: wordpress
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        ports:  # ports æœ¬èº«ä¸å¯¹å®¹å™¨çš„ç«¯å£ç›‘å¬äº§ç”Ÿå®é™…ä½œç”¨ï¼Œåªæ˜¯ä¸€ä¸ªå£°æ˜ã€‚ä½†æ˜¯ï¼Œå®ƒåœ¨ Kubernetes èµ„æºåä½œã€æ–‡æ¡£åŒ–ã€ä»¥åŠæŸäº›å·¥å…·ä¸­ï¼Œé—´æ¥å…·æœ‰é‡è¦æ„ä¹‰ã€‚
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: mysql-persistent-storage
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentVolumeClaim:
          claimName: mysql-pv-claim
---
apiVersion: v1
kind: Service
metadata:
  name: wordpress
  labels:
    app: wordpress
spec:
  ports:
  - port: 80
  selector:
    app: wordpress
    tier: frontend
  type: LoadBalancer
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wp-pv-claim
  labels:
    app: wordpress
spec:
  storageClassName: sc-nfs
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress
  labels:
    app: wordpress
spec:
  selector:
    matchLabels:
      app: wordpress
      tier: frontend
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: frontend
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/wordpress:php8.2-apache
        name: wordpress
        env:
        - name: WORDPRESS_DB_HOST
          value: wordpress-mysql
        - name: WORDPRESS_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        - name: WORDPRESS_DB_USER
          value: wordpress
        ports:
        - containerPort: 80
          name: wordpress
        volumeMounts:
        - name: wordpress-persistent-storage
          mountPath: /var/www/html
      volumes:
      - name: wordpress-persistent-storage
        persistentVolumeClaim:
          claimName: wp-pv-claim

#åº”ç”¨
[root@master1 yaml] # kubectl apply -f mysql-wordpress-persistent-volume.yaml 
secret/mysql-pass created
service/wordpress-mysql created
persistentvolumeclaim/mysql-pv-claim created
deployment.apps/wordpress-mysql created
service/wordpress created
persistentvolumeclaim/wp-pv-claim created
deployment.apps/wordpress created

# æŸ¥çœ‹
[root@master1 yaml] # kubectl get svc
NAME              TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
kubernetes        ClusterIP      10.96.0.1      <none>        443/TCP        5d4h
wordpress         LoadBalancer   10.102.38.58   <pending>     80:31889/TCP   31s
wordpress-mysql   ClusterIP      None           <none>        3306/TCP       31s

# æµè§ˆå™¨è®¿é—®10.0.0.202:31889
```



![image-20250102204154945](../markdown_img/image-20250102204154945.png)





**è¿›é˜¶ï¼šå®Œå…¨æŒ‰è¦æ±‚é…ç½®**

![image-20250103172728642](../markdown_img/image-20250103172728642.png)



```yaml
# ç›®å½•ç»“æ„
[root@master1 lnmp] # ls
mysql  nginx  nginx.conf.d  plugin  wordpress

[root@master1 lnmp] # tree .
.
â”œâ”€â”€ mysql
â”‚Â Â  â”œâ”€â”€ lnmp-mysql.yaml
â”‚Â Â  â””â”€â”€ service-mysql.yaml
â”œâ”€â”€ nginx
â”‚Â Â  â”œâ”€â”€ lnmp-nginx-deloyment.yaml
â”‚Â Â  â”œâ”€â”€ service-nginx.yaml
â”‚Â Â  â””â”€â”€ tls
â”‚Â Â      â”œâ”€â”€ mystical.org.crt
â”‚Â Â      â””â”€â”€ mystical.org.key
â”œâ”€â”€ nginx.conf.d
â”‚Â Â  â””â”€â”€ wordpress.mystical.org.conf
â”œâ”€â”€ plugin
â”‚Â Â  â”œâ”€â”€ metalLB
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ metallb-native.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ service-metallb-IPAddressPool.yaml
â”‚Â Â  â”‚Â Â  â””â”€â”€ service-metallb-L2Advertisement.yaml
â”‚Â Â  â””â”€â”€ nfc-sc
â”‚Â Â      â”œâ”€â”€ nfs-client-provisioner.yaml
â”‚Â Â      â”œâ”€â”€ nfs-storageClass.yaml
â”‚Â Â      â””â”€â”€ rbac.yaml
â””â”€â”€ wordpress
    â”œâ”€â”€ lnmp-wordpress.yaml
    â”œâ”€â”€ service-wordpress-loadbalancer.yaml
    â””â”€â”€ service-wordpress.yaml


# æ’ä»¶æ¸…å• -- MetalLB
[root@master1 lnmp] # METALLB_VERSION='v0.14.7'
[root@master1 lnmp] # wget https://raw.githubusercontent.com/metallb/metallb/${METALLB_VERSION}/config/manifests/metallb-native.yaml

# åº”ç”¨
[root@master1 metalLB]# kubectl apply -f metallb-native.yaml 
namespace/metallb-system created
customresourcedefinition.apiextensions.k8s.io/bfdprofiles.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bgpadvertisements.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bgppeers.metallb.io created
customresourcedefinition.apiextensions.k8s.io/communities.metallb.io created
customresourcedefinition.apiextensions.k8s.io/ipaddresspools.metallb.io created
customresourcedefinition.apiextensions.k8s.io/l2advertisements.metallb.io created
customresourcedefinition.apiextensions.k8s.io/servicel2statuses.metallb.io created
serviceaccount/controller created
serviceaccount/speaker created
role.rbac.authorization.k8s.io/controller created
role.rbac.authorization.k8s.io/pod-lister created
clusterrole.rbac.authorization.k8s.io/metallb-system:controller created
clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created
rolebinding.rbac.authorization.k8s.io/controller created
rolebinding.rbac.authorization.k8s.io/pod-lister created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created
configmap/metallb-excludel2 created
secret/metallb-webhook-cert created
service/metallb-webhook-service created
deployment.apps/controller created
daemonset.apps/speaker created
validatingwebhookconfiguration.admissionregistration.k8s.io/metallb-webhook-configuration created

# åˆ›å»ºåœ°å€æ± 
# æ³¨æ„: IPAddressPool å¿…é¡»ä½¿ç”¨Kuberetesé›†ç¾¤èŠ‚ç‚¹çš„IPåœ°å€æ®µ
[root@master1 metalLB]#vim service-metallb-IPAddressPool.yaml
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: localip-pool
  namespace: metallb-system
spec:
  addresses:
  - 10.0.0.10-10.0.0.50
  autoAssign: true
  avoidBuggyIPs: true
  
# åº”ç”¨
[root@master1 metalLB]#kubectl apply -f service-metallb-IPAddressPool.yaml
ipaddresspool.metallb.io/localip-pool created

# åˆ›å»ºäºŒå±‚å…¬å‘Šæœºåˆ¶
[root@master1 metalLB]#vim service-metallb-L2Advertisement.yaml
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: localip-pool-l2a
  namespace: metallb-system
spec:
  ipAddressPools:
  - localip-pool
  interfaces:
  - eth0 # ç”¨äºå‘é€å…è´¹ARPå…¬å‘Š

# åº”ç”¨
[root@master1 metalLB] # kubectl apply -f service-metallb-L2Advertisement.yaml 
l2advertisement.metallb.io/localip-pool-l2a created

####################################################################################################

# å­˜å‚¨åˆ¶å¤‡å™¨
[root@master1 nfc-sc]#cat rbac.yaml 
apiVersion: v1
kind: Namespace
metadata:
  name: nfs-provisioner-demo
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  # replace with namespace where provisioner is deployed æ ¹æ®ä¸šåŠ¡éœ€è¦ä¿®æ”¹æ­¤å¤„åç§°ç©ºé—´
  namespace: nfs-provisioner-demo
  
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
  - apiGroups: [""]
    resources: ["services", "endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "delete"]
    
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: nfs-provisioner-demo
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
  
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: nfs-provisioner-demo
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
    
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: nfs-provisioner-demo
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: nfs-provisioner-demo
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
  
# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f rbac.yaml

[root@master1 nfc-sc] # cat nfs-client-provisioner.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  labels:
    app: nfs-client-provisioner
  namespace: nfs-provisioner-demo
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
      - name: nfs-client-provisioner     
        image: k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2 #æ­¤é•œåƒå›½å†…å¯èƒ½æ— æ³•è®¿é—®
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: nfs-client-root
          mountPath: /persistentvolumes
        env:
        - name: PROVISIONER_NAME
          value: k8s-sigs.io/nfs-subdir-external-provisioner # åç§°ç¡®ä¿ä¸nfs-StorageClass.yamlæ–‡ä»¶ä¸­çš„provisioneråç§°ä¿æŒä¸€è‡´
        - name: NFS_SERVER
          value: nfs.mystical.org
        - name: NFS_PATH
          value: /nfs-data/sc-nfs
      volumes:
      - name: nfs-client-root
        nfs:
          server: nfs.mystical.org
          path: /nfs-data/sc-nfs

# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f nfs-client-provisioner.yaml

[root@master1 nfc-sc] # cat nfs-storageClass.yaml 
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-nfs
  annotations:
    storageclass.kubernetes.io/is-default-class: "false" # æ˜¯å¦è®¾ç½®ä¸ºé»˜è®¤çš„storageClass
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner # or choose another name, must match deployment's env PROVISIONER_NAME
parameters:
  archiveOnDelete: "true"

# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f nfs-storageClass.yaml 

####################################################################################################

# MySQLæ¸…å•èµ„æº
[root@master1 lnmp] # cat mysql/lnmp-mysql.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: mysql-pass
type: kubernetes.io/basic-auth
data:
  password: MTIzNDU2

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pv-claim
  labels:
    app: wordpress
spec:
  storageClassName: sc-nfs
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  selector:
    matchLabels:
      app: wordpress
      tier: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: mysql
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/mysql:8.0.29-oracle
        name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        - name: MYSQL_DATABASE
          value: wordpress
        - name: MYSQL_USER
          value: wordpress
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        ports:
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: mysql-persistent-storage
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentVolumeClaim:
          claimName: mysql-pv-claim

# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f mysql/lnmp-mysql.yaml

[root@master1 lnmp] # cat mysql/service-mysql.yaml 
apiVersion: v1
kind: Service
metadata:
  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  ports:
  - port: 3306
  selector:
    app: wordpress
    tier: mysql
  clusterIP: None

# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f mysql/service-mysql.yaml 

######################################################################################################

# wordpressèµ„æºæ¸…å•
[root@master1 lnmp] # cat wordpress/lnmp-wordpress.yaml 
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wp-pv-claim
  labels:
    app: wordpress
spec:
  storageClassName: sc-nfs
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress
  labels:
    app: wordpress
spec:
  replicas: 2
  selector:
    matchLabels:
      app: wordpress
      tier: frontend
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: frontend
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/wordpress:php8.2-apache
        name: wordpress
        env:
        - name: WORDPRESS_DB_HOST
          value: wordpress-mysql
        - name: WORDPRESS_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        - name: WORDPRESS_DB_USER
          value: wordpress
        ports:
        - containerPort: 80
          name: wordpress
        volumeMounts:
        - name: wordpress-persistent-storage
          mountPath: /var/www/html
      volumes:
      - name: wordpress-persistent-storage
        persistentVolumeClaim:
          claimName: wp-pv-claim
          
# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f wordpress/lnmp-wordpress.yaml

[root@master1 lnmp] # cat wordpress/service-wordpress.yaml 
apiVersion: v1
kind: Service
metadata:
  name: wordpress
  labels:
    app: wordpress
spec:
  ports:
  - port: 80
  selector:
    app: wordpress
    tier: frontend
  clusterIP: None

# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f wordpress/service-wordpress.yaml
#########################################################################################################

# nginxèµ„æºæ¸…å•
# nginxé…ç½®æ–‡ä»¶
[root@master1 lnmp] # cat nginx.conf.d/wordpress.mystical.org.conf 
server {
    listen 80;
    server_name wordpress.mystical.org;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl;
    server_name www.mystical.org;
    
    ssl_certificate /etc/nginx/certs/tls.crt; 
    ssl_certificate_key /etc/nginx/certs/tls.key;
    ssl_session_timeout 5m;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; 
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; 
    ssl_prefer_server_ciphers on;
    include /etc/nginx/conf.d/myserver-*.cfg;

    location / {
        proxy_pass http://wordpress;                       # wordpressçš„svcåç§°
        proxy_set_header Host $host;                       # å¿…é¡»å†™ï¼Œå°†ç”¨æˆ·çš„hostsä¼ ç»™wordpress
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}


# ç”Ÿæˆcm
[root@master1 lnmp] #kubectl create cm cm-nginx-conf --from-file=./wordpress.mystical.org.conf

# nginxçš„deployment
[root@master1 lnmp] # cat nginx/lnmp-nginx-deloyment.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: lnmp-nginx-deploy
  labels:
    app: wordpress
spec:
  replicas: 2
  selector:
    matchLabels:
      app: wordpress
      tier: nginx
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: nginx
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
        name: nginx
        env:
        - name: UPSTREAM_URL
          value: "http://wordpress"
        volumeMounts:
        - name: nginx-config-volume
          mountPath: /etc/nginx/conf.d
        - name: nginx-certs
          mountPath: /etc/nginx/certs/
      volumes:
      - name: nginx-config-volume
        configMap:
          name: cm-nginx-conf
      - name: nginx-certs
        secret:
          secretName: secret-nginx-ssl

# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f nginx/lnmp-nginx-deloyment.yaml 

# nginxå¯¹å¤–çš„Service
[root@master1 lnmp] # cat nginx/service-nginx.yaml 
apiVersion: v1
kind: Service
metadata:
  name: server-nodeport-nginx
spec:
  type: LoadBalancer
  selector:
    app: wordpress
    tier: nginx
  ports:                         # æ³¨æ„æš´éœ²ä¸¤ä¸ªç«¯å£
  - name: https
    protocol: TCP
    port: 443  
    targetPort: 443
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80

# åº”ç”¨
[root@master1 nfc-sc] # kubectl apply -f nginx/service-nginx.yaml
```





## Kubernetesæµé‡è°ƒåº¦-Ingress



**æœ¬ç« å†…å®¹**

- **IngressåŸç†**
- **Ingress-nginxå®‰è£…å’Œé…ç½®**
- **Ingress-nginxå®ç°**
- **Ingress-nginx å®ç°è“ç»¿å’Œç°åº¦å‘å¸ƒ**





### IngressåŸç†

Ingressæœ¬è´¨å°±æ˜¯**ä¸ƒå±‚ä»£ç†**, æ‰€ä»¥å¯ä»¥åŸºäºhttp/httpsçš„æ–¹å¼ï¼Œå°†é›†ç¾¤å¤–éƒ¨çš„æµé‡ç»Ÿä¸€çš„å¼•å…¥åˆ°é›†ç¾¤å†…éƒ¨

é€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„æµé‡å…¥å£ï¼Œé¿å…å°†é›†ç¾¤å†…éƒ¨å¤§é‡çš„ç«¯å£ç›´æ¥æš´éœ²ç»™å¤–éƒ¨

Ingress å¯ä¸º Service æä¾›å¤–éƒ¨å¯è®¿é—®çš„ URLã€è´Ÿè½½å‡è¡¡æµé‡ã€ç»ˆæ­¢ SSL/TLSï¼Œä»¥åŠåŸºäºåç§°çš„è™šæ‹Ÿæ‰˜ç®¡ã€‚ Ingress æ§åˆ¶å™¨ é€šå¸¸è´Ÿè´£é€šè¿‡è´Ÿè½½å‡è¡¡å™¨æ¥å®ç° Ingressï¼Œå°½ç®¡å®ƒä¹Ÿå¯ä»¥é…ç½®è¾¹ç¼˜è·¯ç”±å™¨æˆ–å…¶ä»–å‰ç«¯æ¥å¸®åŠ©å¤„ç†æµé‡ã€‚

Ingress ä¸ä¼šå…¬å¼€ä»»æ„ç«¯å£æˆ–åè®®ã€‚ å°† HTTP å’Œ HTTPS ä»¥å¤–çš„æœåŠ¡å…¬å¼€åˆ° Internet æ—¶ï¼Œé€šå¸¸ä½¿ç”¨ Service.Type=NodePort æˆ– Service.Type=LoadBalancer ç±»å‹çš„ Serviceã€‚

Ingressè¿™ç§åˆ©ç”¨åº”ç”¨å±‚åè®®æ¥è¿›è¡Œæµé‡çš„è´Ÿè½½å‡è¡¡æ•ˆæœï¼Œå®ƒå¯ä»¥å®ç°è®©ç”¨æˆ·é€šè¿‡åŸŸåæ¥è®¿é—®ç›¸åº”çš„ serviceå°±å¯ä»¥äº†ï¼Œæ— éœ€å…³å¿ƒNode IPåŠPortæ˜¯ä»€ä¹ˆï¼Œé¿å…äº†ä¿¡æ¯çš„æ³„éœ²ã€‚



**ingress ä¸»è¦åŒ…å«ä¸¤ä¸ªç»„ä»¶Ingress APIå’ŒIngress Controller**

ingress å…¶å…·å¤‡äº†åŠ¨æ€æ›´æ–°å¹¶åŠ è½½æ–°é…ç½®çš„ç‰¹æ€§ã€‚è€Œä¸”ingressæœ¬èº«æ˜¯ä¸å…·å¤‡å®ç°é›†ç¾¤å†…å¤–æµé‡é€šä¿¡çš„åŠŸèƒ½çš„ï¼Œè¿™ä¸ªåŠŸèƒ½æ˜¯é€šè¿‡ controlleræ¥å®ç°çš„ã€‚**Ingress Controlleræœ¬èº«æ˜¯è¿è¡Œäºé›†ç¾¤ä¸­çš„Podèµ„æºå¯¹è±¡**

| ç»„ä»¶               | è§£æ                                                         |
| ------------------ | ------------------------------------------------------------ |
| Ingress API        | Kubernetesä¸Šçš„æ ‡å‡†APIèµ„æºç±»å‹ä¹‹ä¸€ ä»…å®šä¹‰äº†æŠ½è±¡è·¯ç”±é…ç½®ä¿¡æ¯ï¼Œåªæ˜¯å…ƒæ•°æ®ï¼Œéœ€è¦ç”±ç›¸åº”çš„æ§åˆ¶å™¨åŠ¨æ€åŠ è½½ å°†ä»£ç†é…ç½®æŠ½è±¡æˆä¸€ä¸ªIngresså¯¹è±¡ï¼Œæ¯ä¸ªæœåŠ¡å¯¹åº”ä¸€ä¸ªyamlé…ç½®æ–‡ä»¶ è´Ÿè´£ä»¥k8sæ ‡å‡†çš„èµ„æºæ ¼å¼å®šä¹‰æµé‡è°ƒåº¦ã€è·¯ç”±ç­‰è§„åˆ™ å±äºåç§°ç©ºé—´çº§èµ„æº,å®Œæˆå°†åŒä¸€ä¸ªåç©ºé—´çš„serviceèµ„æºè¿›è¡Œæš´éœ² |
| Ingress Controller | ä¸ƒå±‚åå‘ä»£ç†æœåŠ¡ç¨‹åº éœ€è¦ç›‘è§†ï¼ˆwatchï¼‰API Serverä¸Š Ingressèµ„æºçš„å˜åŠ¨ï¼Œå¹¶ç”Ÿæˆå…·ä½“åº”ç”¨çš„è‡ªèº«çš„é… ç½®æ–‡ä»¶æ ¼å¼ï¼Œå³å°†æ–°åŠ å…¥çš„Ingressè½¬åŒ–æˆåå‘ä»£ç†çš„é…ç½®æ–‡ä»¶å¹¶åŠ¨æ€åŠ è½½ä½¿ä¹‹ç”Ÿæ•ˆï¼Œæœ€ç»ˆå¹¶æ®æ­¤å®Œæˆæµé‡è½¬å‘ <br />Ingress Controlleréä¸ºå†…ç½®çš„æ§åˆ¶å™¨ï¼Œéœ€è¦é¢å¤–è‡ªè¡Œéƒ¨ç½² <br />é€šå¸¸ä»¥Podå½¢å¼è¿è¡ŒäºKubernetesé›†ç¾¤ä¹‹ä¸Š ä¸€èˆ¬åº”è¯¥ç”±ä¸“ç”¨çš„LB Serviceè´Ÿè´£ä¸ºå…¶æ¥å…¥é›†ç¾¤å¤–éƒ¨æµé‡ |



**å› ä¸ºingress Controlleræ˜¯ä»¥podçš„æ–¹å¼éƒ¨ç½²çš„,æ‰€ä»¥éœ€è¦è§£å†³å¦‚ä¸‹é—®é¢˜**

- ingressçš„podå¦‚ä½•å¼•å…¥å¤–éƒ¨æµé‡
  - é€šè¿‡ä¸€ä¸ªä¸“ç”¨çš„service å³å¯å®ç°
- å¦‚ä½•å®ç°ingressçš„Podçš„æµé‡è´Ÿè½½å‡è¡¡
  - å…³äºpodè´Ÿè½½å‡è¡¡çš„æµé‡ï¼Œç›´æ¥é€šè¿‡deployment/daemonsetç­‰controllerè½¬å‘ç»™åç«¯podå³å¯ã€‚
- åç«¯åº”ç”¨çš„ Pod å¾ˆå¤šï¼Œå¦‚ä½•æ‰¾åˆ°è¦è½¬å‘çš„ç›®æ ‡ï¼Ÿ
  - é€šè¿‡k8sçš„serviceå¯¹æ‰€æœ‰çš„podè¿›è¡Œåˆ†ç»„ç®¡ç†ï¼Œå†ç”¨controllerå†…éƒ¨çš„è´Ÿè½½å‡è¡¡é…ç½®ï¼Œæ‰¾åˆ°å¯¹åº”çš„ç›®æ ‡ã€‚
  - å³åç«¯åº”ç”¨çš„Podå¯¹åº”çš„service åªæ˜¯èµ·åˆ°æœåŠ¡å‘ç°Podçš„åŠŸèƒ½ï¼Œè€Œä»å¤–éƒ¨è®¿é—®åº”ç”¨çš„Podçš„æµé‡è½¬å‘è¿‡ç¨‹ä¸­ä¸éœ€è¦å†ç»è¿‡æ­¤service 



#### Ingress è®¿é—®è¿‡ç¨‹

- ä»å¤–éƒ¨æµé‡è°ƒåº¦åˆ°kubernetesä¸­Ingress serviceï¼Œæœ‰å¤šç§å®ç°æ–¹æ¡ˆï¼Œæ¯”å¦‚ä½¿ç”¨èŠ‚ç‚¹ç½‘ç»œä¸­çš„ EXTERNAL-IPæˆ–è€…NodePortæ–¹å¼
- ä»serviceè°ƒåº¦åˆ°ingress-controller
- ingress-controlleræ ¹æ®ingress Pod ä¸­çš„å®šä¹‰ï¼Œæ¯”å¦‚è™šæ‹Ÿä¸»æœºæˆ–è€…åç«¯çš„url
- æ ¹æ®è™šæ‹Ÿä¸»æœºåç›´æ¥è°ƒåº¦åˆ°åç«¯çš„ä¸€ç»„åº”ç”¨podä¸­



![image-20250104101257362](../markdown_img/image-20250104101257362.png)

æ³¨æ„ï¼š

- æ•´ä¸ªæµç¨‹ä¸­æ¶‰åŠåˆ°äº†ä¸¤å¤„serviceå†…å®¹
- service ingress-nginx æ˜¯å¸®åŠ© ingress controller Pod æ¥å…¥å¤–éƒ¨æµé‡çš„
- **åç«¯çš„æœåŠ¡å¯¹åº”çš„service**åªèµ·åˆ°å¸®åŠ© ingress controller Pod æ‰¾åˆ°å…·ä½“çš„æœåŠ¡çš„Podï¼Œå³**åªç”¨äºæœåŠ¡å‘ç°** ï¼Œè€Œ**æµé‡ä¸éœ€è¦ç»è¿‡åç«¯æœåŠ¡çš„Service**ï¼Œç›´æ¥ä»ingress controller Podè½¬åˆ°è‡³å…·ä½“çš„Pod
- è™šçº¿è¡¨ç¤ºserviceå¯¹åç«¯çš„åº”ç”¨è¿›è¡Œåˆ†ç»„ï¼Œå®çº¿è¡¨ç¤ºingresså®é™…çš„è®¿é—®æµå‘







###  Ingress controller å¸¸è§çš„è§£å†³æ–¹æ¡ˆ

å¯¹äºIngress controllerçš„è½¯ä»¶å®ç°ï¼Œå…¶å®æ²¡æœ‰ç‰¹æ®Šçš„è¦æ±‚ï¼Œåªè¦èƒ½å¤Ÿå®ç°ä¸ƒå±‚çš„è´Ÿè½½å‡è¡¡åŠŸèƒ½æ•ˆæœå³å¯

Ingress controller æ”¯æŒç”±ä»»ä½•å…·æœ‰åå‘ä»£ç†åŠŸèƒ½çš„ç¨‹åºå®ç°ï¼Œå¦‚Nginxã€Traefikã€Envoyã€HAProxyã€ Vulcandç­‰

Kubernetesæ”¯æŒåŒæ—¶éƒ¨ç½²äºŒä¸ªæˆ–ä»¥ä¸Šçš„æ•°é‡çš„Ingress Controller

**Ingressèµ„æºé…ç½®æŒ‡å®šIngress Controllerç±»å‹çš„æ–¹æ³•**

- ä¸“ç”¨çš„**annotation**ï¼škubernetes.io/ingress.classï¼Œè€ç‰ˆæœ¬ç”¨æ³•
- Ingressèµ„æºçš„specçš„ä¸“æœ‰å­—æ®µï¼š**ingressClassName**ï¼Œå¼•ç”¨çš„IngressClassæ˜¯ä¸€ç§ç‰¹å®šçš„èµ„æºç±» å‹ï¼Œæ­¤æ–¹å¼v1.18ç‰ˆæœ¬èµ·ä½¿ç”¨ï¼Œæ–°ç‰ˆæœ¬æ¨è





### Ingress-nginx Controller å®‰è£…å’Œé…ç½®

![image-20250104103640034](../markdown_img/image-20250104103640034.png)

#### åŸºäºYAMLéƒ¨ç½²

åŸºäºkubectl apply éƒ¨ç½²

```bash
#è·å–é…ç½®æ–‡ä»¶,å¯èƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘æ‰èƒ½ä¸‹è½½
https://kubernetes.github.io/ingress-nginx/deploy/

# æ–°ç‰ˆ
[root@master1 ~]#wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.11.1/deploy/static/provider/cloud/deploy.yaml

[root@master1 ~]#wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml

[root@master1 ~]#wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.0/deploy/static/provider/cloud/deploy.yaml

# æŸ¥çœ‹èµ„æº
[root@master1 ~]#cat deploy-v1.11.1.yaml |grep "^kind"
kind: Namespace
kind: ServiceAccount
kind: ServiceAccount
kind: Role
kind: Role
kind: ClusterRole
kind: ClusterRole
kind: RoleBinding
kind: RoleBinding
kind: ClusterRoleBinding
kind: ClusterRoleBinding
kind: ConfigMap
kind: Service
kind: Service
kind: Deployment
kind: Job
kind: Job
kind: IngressClass
kind: ValidatingWebhookConfiguration

# ç¼–è¾‘deploy-v1.11.1.yaml
# 1ï¼‰é»˜è®¤é•œåƒå¯èƒ½éœ€è¦ç¿»å¢™ï¼Œéœ€è¦ä¿®æ”¹åŸºç¡€é•œåƒï¼ˆå…±æ”¹3å¤„ï¼Œå…¶ä¸­2å¤„ç›¸åŒï¼‰
[root@master1 ~]#vim deploy.yaml
        # image: registry.k8s.io/ingress-nginx/controller:v1.11.1@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
          image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.11.1
        # image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366  
          image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v20230407
        # image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366  
          image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v20230407
          
#2ï¼‰å¼€æ”¾å¤–éƒ¨è®¿é—®å…¥å£åœ°å€
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.11.1
  name: ingress-nginx-controller
  namespace: ingress-nginx
  annotations:                       # æ·»åŠ å¦‚ä¸‹ä¸‰è¡Œï¼Œç”¨äºæ”¯æŒPrometheusç›‘æ§ï¼Œå¯é€‰
    prometheus.io/scrape: "true"
    prometheus.io/port: "10254"
spec:
  externalTrafficPolicy: Local
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - appProtocol: http
    name: http
    port: 80
    protocol: TCP
    targetPort: http
  - appProtocol: https
    name: https
    port: 443
    protocol: TCP
    targetPort: https
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  type: LoadBalancer             # è¿™é‡Œä½¿ç”¨LoadBalancerï¼Œå› æ­¤éœ€è¦éƒ¨ç½²MetalLB
  
#3ï¼‰é»˜è®¤ingress-nginx-controlleråªæœ‰ä¸€ä¸ªPodå‰¯æœ¬çš„,
#æ–¹æ³•1: æŒ‡å®š2ä¸ªå‰¯æœ¬å®ç°é«˜å¯ç”¨ï¼ˆæ­¤æ­¥å¯é€‰ï¼‰
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  replicas: 2  # æ·»åŠ å‰¯æœ¬æ•°
  
# é…ç½®MetalLB
[root@master1 metalLB]#kubectl apply -f metallb-native.yaml 
namespace/metallb-system created
customresourcedefinition.apiextensions.k8s.io/bfdprofiles.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bgpadvertisements.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bgppeers.metallb.io created
customresourcedefinition.apiextensions.k8s.io/communities.metallb.io created
customresourcedefinition.apiextensions.k8s.io/ipaddresspools.metallb.io created
customresourcedefinition.apiextensions.k8s.io/l2advertisements.metallb.io created
customresourcedefinition.apiextensions.k8s.io/servicel2statuses.metallb.io created
serviceaccount/controller created
serviceaccount/speaker created
role.rbac.authorization.k8s.io/controller created
role.rbac.authorization.k8s.io/pod-lister created
clusterrole.rbac.authorization.k8s.io/metallb-system:controller created
clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created
rolebinding.rbac.authorization.k8s.io/controller created
rolebinding.rbac.authorization.k8s.io/pod-lister created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created
configmap/metallb-excludel2 created
secret/metallb-webhook-cert created
service/metallb-webhook-service created
deployment.apps/controller created
daemonset.apps/speaker created
validatingwebhookconfiguration.admissionregistration.k8s.io/metallb-webhook-configuration created

[root@master1 metalLB]#kubectl apply -f service-metallb-IPAddressPool.yaml 
ipaddresspool.metallb.io/localip-pool created

[root@master1 metalLB]#kubectl apply -f service-metallb-L2Advertisement.yaml 
l2advertisement.metallb.io/localip-pool-l2a created

# åº”ç”¨Ingress-nginxèµ„æºé…ç½®æ–‡ä»¶
[root@master1 ~]#kubectl apply -f deploy-v1.11.1.yaml 
namespace/ingress-nginx created
serviceaccount/ingress-nginx created
serviceaccount/ingress-nginx-admission created
role.rbac.authorization.k8s.io/ingress-nginx created
role.rbac.authorization.k8s.io/ingress-nginx-admission created
clusterrole.rbac.authorization.k8s.io/ingress-nginx created
clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created
rolebinding.rbac.authorization.k8s.io/ingress-nginx created
rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created
clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created
clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created
configmap/ingress-nginx-controller created
service/ingress-nginx-controller created
service/ingress-nginx-controller-admission created
deployment.apps/ingress-nginx-controller created
job.batch/ingress-nginx-admission-create created
job.batch/ingress-nginx-admission-patch created
ingressclass.networking.k8s.io/nginx created
validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created

# æŸ¥çœ‹
[root@master1 ~]# kubectl get all -n ingress-nginx 
NAME                                        READY   STATUS      RESTARTS   AGE
pod/ingress-nginx-admission-create-lx764    0/1     Completed   0          91s
pod/ingress-nginx-admission-patch-vqttt     0/1     Completed   1          91s
pod/ingress-nginx-controller-666487-9cvb7   1/1     Running     0          91s
pod/ingress-nginx-controller-666487-z24f8   1/1     Running     0          91s

NAME                                         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/ingress-nginx-controller             LoadBalancer   10.100.252.99    10.0.0.10     80:30529/TCP,443:31050/TCP   91s
service/ingress-nginx-controller-admission   ClusterIP      10.110.228.129   <none>        443/TCP                      91s

NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/ingress-nginx-controller   2/2     2            2           91s

NAME                                              DESIRED   CURRENT   READY   AGE
replicaset.apps/ingress-nginx-controller-666487   2         2         2       91s

NAME                                       STATUS     COMPLETIONS   DURATION   AGE
job.batch/ingress-nginx-admission-create   Complete   1/1           20s        91s
job.batch/ingress-nginx-admission-patch    Complete   1/1           22s        91s

```



### Ingresså‘½ä»¤å¼å®ç°

#### å‘½ä»¤å¼å®ç°è¯´æ˜

```bash
# ç±»æ¯”nginxåå‘ä»£ç†é…ç½®æ–‡ä»¶
http {
    upstream service_name {
        server xxxx: port
        server xxxx: port
    }
    server {
        listen 80;
        server_name domain;
        location /url {
            proxy_pass http://upstream_name;
        }
    }
}

# åˆ›å»ºIngresså‘½ä»¤
kubectl create ingress NAME --rule=domain/url=service:port[, tls[=secret]] [option]

# å¸¸ç”¨option
--annotation=[]  # æ³¨è§£ä¿¡æ¯ï¼šæ ¼å¼"annotation=value"
--rule=[]        # ä»£ç†è§„åˆ™ï¼Œæ ¼å¼"host/path=service:port[,tls=secretname]",,æ³¨æ„:ruleä¸­å¤–éƒ¨åŸŸåè¦åœ¨æ‰€æœ‰çš„åç§°ç©ºé—´å”¯ä¸€
--class=''       # æ­¤Ingressé€‚é…çš„Ingress Class Controller

# åŸºäºURIæ–¹å¼ä»£ç†ä¸åŒåº”ç”¨çš„è¯·æ±‚æ—¶ï¼Œåç«¯åº”ç”¨çš„URIè‹¥ä¸ä»£ç†æ—¶ä½¿ç”¨çš„URIä¸åŒï¼Œåˆ™éœ€è¦å¯ç”¨URL Rewriteå®ŒæˆURIçš„é‡å†™
# Ingress-Nginxæ”¯æŒä½¿ç”¨â€œannotation nginx.ingress.kubernetes.io/rewrite-targetâ€æ³¨è§£è¿›è¡Œ
```



#### å‘½ä»¤å¼å®ç°æ¡ˆä¾‹

**å‡†å¤‡ç¯å¢ƒå®ç°ä¸¤ä¸ªserviceåº”ç”¨ pod-test1å’Œpod-test2**

```bash
# å‡†å¤‡åç«¯çš„åº”ç”¨pod-test v0.1å’Œç›¸åº”çš„service
[root@master1 ~]# kubectl create deployment pod-test1 --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas=3
deployment.apps/pod-test1 created

[root@master1 ~]# kubectl create service clusterip pod-test1 --tcp=80:80
service/pod-test1 created

# å‡†å¤‡åç«¯çš„åº”ç”¨pod-test v0.2å’Œç›¸åº”çš„service
[root@master1 ~]# kubectl create deployment pod-test2 --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2 --replicas=3
deployment.apps/pod-test2 created

[root@master1 ~]#kubectl create service clusterip pod-test2 --tcp=80:80
service/pod-test2 created

[root@master1 ~]#kubectl get ep
NAME         ENDPOINTS                                         AGE
kubernetes   10.0.0.201:6443                                   4h47m
pod-test1    10.244.1.159:80,10.244.2.107:80,10.244.3.173:80   3m10s
pod-test2    10.244.1.160:80,10.244.2.108:80,10.244.3.174:80   13s
```



##### å•åŸŸåå•URL

**å®ç°å•åŸŸåä¸æ”¯æŒå­URL**

èŒƒä¾‹ï¼šå‘½ä»¤å¼å®ç°å•åŸŸåä¸æ”¯æŒå­URLï¼Œå­URLæ— æ³•è®¿é—®ï¼Œè¿”å›404

```bash
#è·¯å¾„ç²¾ç¡®åŒ¹é…,å¯¹äºå‘å¾€www.wang.orgçš„è¯·æ±‚ï¼Œä»£ç†è‡³service/pod-test1ï¼Œå…¶å®ƒçš„URLåˆ™æ— æ³•ä»£ç†
[root@master1 ~]# kubectl create ingress demo-ingress --rule="www.mystical.org/=pod-test1:80" --class=nginx -o yaml --dry-run=client
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  creationTimestamp: null
  name: demo-ingress
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test1
            port:
              number: 80
        path: /
        pathType: Exact    # #è¡¨ç¤ºç²¾ç¡®åŒ¹é…ï¼Œ--rule="www.wang.org/*=pod-test1:80",åˆ™ä¸ºprefix
status:
  loadBalancer: {}

# åˆ›å»º
[root@master1 ~]#kubectl create ingress demo-ingress --rule="www.mystical.org/=pod-test1:80" --class=nginx
ingress.networking.k8s.io/demo-ingress created

# æŸ¥çœ‹ç”Ÿæˆçš„yamlæ–‡ä»¶
[root@master1 ~]#kubectl get ingress demo-ingress -o yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  creationTimestamp: "2025-01-04T06:37:06Z"
  generation: 1
  name: demo-ingress
  namespace: default
  resourceVersion: "30734"
  uid: a87cc2f4-3755-45fd-ab85-36a800869698
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test1
            port:
              number: 80
        path: /
        pathType: Exact
status:
  loadBalancer: {}


# æŸ¥çœ‹ingressèµ„æº
[root@master1 ~]#kubectl get ingress
NAME           CLASS   HOSTS              ADDRESS     PORTS   AGE
demo-ingress   nginx   www.mystical.org   10.0.0.10   80      2m37s


# æŸ¥çœ‹ingress-nginx-controllerå¯¹åº”çš„Podä¸­Nginxé…ç½®æ–‡ä»¶çš„å˜åŒ–
[root@master1 ~]# kubectl exec -it -n ingress-nginx ingress-nginx-controller-666487-9cvb7  -- grep mystical.org /etc/nginx/nginx.conf
	## start server www.mystical.org
		server_name www.mystical.org ;
	## end server www.mystical.org


# é›†ç¾¤å¤–è®¿é—®
[root@master1 ~]#curl -H"host: www.mystical.org" http://10.0.0.10
kubernetes pod-test v0.1!! ClientIP: 10.244.1.158, ServerName: pod-test1-cd487559d-pmf2j, ServerIP: 10.244.3.173!
[root@master1 ~]#curl -H"host: www.mystical.org" http://10.0.0.10
kubernetes pod-test v0.1!! ClientIP: 10.244.1.158, ServerName: pod-test1-cd487559d-v6pl7, ServerIP: 10.244.1.159!


# è®¿é—®å­URLå¤±è´¥ï¼ŒåŸå› æ˜¯åªå‘å¸ƒäº†www.wang.orgçš„æ ¹ç›®å½•ï¼Œå…¶å®ƒURLæ²¡æœ‰å‘å¸ƒ
[root@master1 ~]#curl -H"host: www.mystical.org" http://10.0.0.10/hostname
<html>
<head><title>404 Not Found</title></head>
<body>
<center><h1>404 Not Found</h1></center>
<hr><center>nginx</center>
</body>
</html>


#æ¸…ç†
[root@master1 ~]#kubectl delete ingress demo-ingress 
ingress.networking.k8s.io "demo-ingress" deleted
```



**å®ç°å•åŸŸåæ”¯æŒå­URL**

```bash
#æ·»åŠ /*ï¼Œæ”¯æŒå­URLï¼Œå¦‚æœæœ‰URLåˆ™è½¬å‘è‡³Podå¯¹åº”ç›¸åŒçš„URL
[root@master1 ~]# kubectl create ingress demo-ingress --class=nginx --rule="www.mystical.org/*=pod-test1:80" -o yaml --dry-run=client
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  creationTimestamp: null
  name: demo-ingress
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test1
            port:
              number: 80
        path: /
        pathType: Prefix
status:
  loadBalancer: {}


# åˆ›å»º
[root@master1 ~]#kubectl create ingress demo-ingress --rule="www.mystical.org/*=pod-test1:80" --class=nginx
ingress.networking.k8s.io/demo-ingress created

# æŸ¥çœ‹
[root@master1 ~]#kubectl get ingress
NAME           CLASS   HOSTS              ADDRESS   PORTS   AGE
demo-ingress   nginx   www.mystical.org             80      5s

# æµ‹è¯•è®¿é—®ï¼Œä¸”æ”¯æŒå­URL
[root@master1 ~]#curl -H"host: www.mystical.org" 10.0.0.10/hostname
ServerName: pod-test1-cd487559d-gs725

# æ¸…ç†
[root@master1 ~]#kubectl delete ingress demo-ingress 
ingress.networking.k8s.io "demo-ingress" deleted
```



##### å•åŸŸåå¤šURL

![image-20250104152617359](../markdown_img/image-20250104152617359.png)

åœ¨åŒä¸€ä¸ªFQDNä¸‹é€šè¿‡ä¸åŒçš„URLå®Œæˆä¸åŒåº”ç”¨é—´çš„æµé‡åˆ†å‘



**å•åŸŸåå¤šURLä¸æ”¯æŒå­URL**

èŒƒä¾‹: å‘½ä»¤å¼å®ç°å•åŸŸåå¤šURLï¼Œä¸æ”¯æŒå­URLï¼Œå¦‚æœå­URLè®¿é—®ï¼Œä¹Ÿå…¨éƒ¨è½¬å‘è‡³åç«¯Podçš„æ ¹è·¯å¾„ / 

```bash
#è·¯å¾„ç²¾ç¡®åŒ¹é…,å¯¹äºå‘å¾€www.wang.org/v1å’Œwww.wang.org/v2çš„è¯·æ±‚ï¼Œåˆ†åˆ«ä»£ç†è‡³service/pod-test1å’Œservice/pod-test2çš„å¯¹åº”çš„å­URL
[root@master1 ~]# kubectl create ingress demo-ingress1 --rule="www.mystical.org/v1=pod-test1:80" --rule="www.mystical.org/v2=pod-test2:80" --class=nginx
ingress.networking.k8s.io/demo-ingress1 created

# é›†ç¾¤å¤–è®¿é—®å¤±è´¥ï¼ŒåŸå› æ˜¯åç«¯æœåŠ¡æ²¡æœ‰å¯¹åº”çš„/v1è¿™æ ·çš„å­URLèµ„æº
[root@master1 ~]# curl -H"host: www.mystical.org" 10.0.0.10/v1/
<html>
<head><title>404 Not Found</title></head>
<body>
<center><h1>404 Not Found</h1></center>
<hr><center>nginx</center>
</body>
</html>
[root@mas

[root@master1 ~]# curl -H"host: www.mystical.org" 10.0.0.10/v2/
<html>
<head><title>404 Not Found</title></head>
<body>
<center><h1>404 Not Found</h1></center>
<hr><center>nginx</center>
</body>
</html>

# è·¯å¾„ç²¾ç¡®åŒ¹é…,å¯¹äºå‘å¾€www.wang.org/v1å’Œ/v2çš„è¯·æ±‚ï¼Œåˆ†åˆ«ä»£ç†è‡³service/pod-test1å’Œservice/pod-test2çš„æ ¹
[root@master1 ~]# kubectl create ingress demo-ingress1 --rule="www.mystical.org/v1=pod-test1:80" --rule="www.mystical.org/v2=pod-test2:80" --class=nginx --annotation nginx.ingress.kubernetes.io/rewrite-target="/"

# --annotation nginx.ingress.kubernetes.io/rewrite-target="/" è¡¨ç¤ºä»£ç†è‡³åç«¯æœåŠ¡çš„æ ¹/ï¼Œè€Œéé»˜è®¤ä»£ç†è‡³åç«¯æœåŠ¡çš„å­URL/v1å’Œ/v2

# æŸ¥çœ‹å¯¹åº”çš„yamlæ–‡ä»¶
[root@master1 ~]# kubectl get ingress demo-ingress1 -o yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  creationTimestamp: "2025-01-04T07:49:12Z"
  generation: 1
  name: demo-ingress1
  namespace: default
  resourceVersion: "38353"
  uid: 822e0bb2-0ae3-4b17-acc2-13db0bfe5499
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test1
            port:
              number: 80
        path: /v1
        pathType: Exact
      - backend:
          service:
            name: pod-test2
            port:
              number: 80
        path: /v2
        pathType: Exact
status:
  loadBalancer:
    ingress:
    - ip: 10.0.0.10


# æµ‹è¯•
[root@master1 ~]#curl -H"host: www.mystical.org" 10.0.0.10/v2/
kubernetes pod-test v0.2!! ClientIP: 10.244.3.172, ServerName: pod-test2-6fb54b5db8-jkvjx, ServerIP: 10.244.1.160!
[root@master1 ~]#curl -H"host: www.mystical.org" 10.0.0.10/v1
kubernetes pod-test v0.1!! ClientIP: 10.244.1.158, ServerName: pod-test1-cd487559d-pmf2j, ServerIP: 10.244.3.173!

# å¦‚æœæœ‰URLï¼Œåˆ™è®¿é—®çš„èµ„æºä»ç„¶æ˜¯æ ¹ç›®å½•ï¼Œä¸æ”¯æŒå¯¹åº”çš„å­URL
[root@master1 ~]#curl -H"host: www.mystical.org" 10.0.0.10/v1/hostname
kubernetes pod-test v0.1!! ClientIP: 10.244.1.158, ServerName: pod-test1-cd487559d-v6pl7, ServerIP: 10.244.1.159!

# æ¸…ç†
[root@master1 ~]#kubectl delete ingress demo-ingress1 
ingress.networking.k8s.io "demo-ingress1" deleted
```



**å•åŸŸåå¤šURLæ”¯æŒå­URL**

èŒƒä¾‹ï¼šå‘½ä»¤å¼å®ç°å•åŸŸåå¤šURLï¼Œæ”¯æŒå­URL

```bash
# ä½¿ç”¨URIçš„å‰ç¼€åŒ¹é…ï¼Œè€Œéç²¾ç¡®åŒ¹é…ï¼Œä¸”åŸºäºæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼è¿›è¡Œurl rewrite
[root@master1 ~]# kubectl create ingress demo-ingress2 --rule='www.mystical.org/v1(/|$)(.*)=pod-test1:80' --rule='www.mystical.org/v2(/|$)(.*)=pod-test2:80' --class=nginx --annotation nginx.ingress.kubernetes.io/rewrite-target='/$2'
Warning: path /v1(/|$)(.*) cannot be used with pathType Exact
Warning: path /v2(/|$)(.*) cannot be used with pathType Exact
ingress.networking.k8s.io/demo-ingress2 created


# æŸ¥çœ‹
[root@master1 ~]#kubectl get ingress
NAME            CLASS   HOSTS              ADDRESS     PORTS   AGE
demo-ingress2   nginx   www.mystical.org   10.0.0.10   80      75s


# æŸ¥çœ‹yamlæ–‡ä»¶
[root@master1 ~]# kubectl get ingress demo-ingress2 -o yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  creationTimestamp: "2025-01-04T07:58:21Z"
  generation: 1
  name: demo-ingress2
  namespace: default
  resourceVersion: "39303"
  uid: de4a2bb8-e2aa-4458-ba39-3660dc46ed5f
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test1
            port:
              number: 80
        path: /v1(/|$)(.*)
        pathType: Exact
      - backend:
          service:
            name: pod-test2
            port:
              number: 80
        path: /v2(/|$)(.*)
        pathType: Exact
status:
  loadBalancer:
    ingress:
    - ip: 10.0.0.10


# æµ‹è¯•
[root@master1 ~]# curl -H"host: www.mystical.org" 10.0.0.10/v1/hostname
ServerName: pod-test1-cd487559d-v6pl7
[root@master1 ~]# curl -H"host: www.mystical.org" 10.0.0.10/v2/hostname
ServerName: pod-test2-6fb54b5db8-p6bwc
 
# æ¸…ç†
[root@master1 ~]# kubectl delete ingress demo-ingress2 
ingress.networking.k8s.io "demo-ingress2" deleted
```



##### å¤šåŸŸå

![image-20250104160408264](../markdown_img/image-20250104160408264.png)



èŒƒä¾‹ï¼šå‘½ä»¤å¼å®ç°åŸºäºä¸»æœºå¤´çš„å¤šè™šæ‹Ÿä¸»æœº

```bash
# ç¯å¢ƒå‡†å¤‡ï¼š
# åŸºäºFQDNåç§°ä»£ç†ä¸åŒåº”ç”¨çš„è¯·æ±‚æ—¶ï¼Œéœ€è¦äº‹å…ˆå‡†å¤‡å¥½å¤šä¸ªåŸŸåï¼Œä¸”ç¡®ä¿å¯¹è¿™äº›åŸŸåçš„è§£æèƒ½å¤Ÿè¾¾åˆ°Igress Controller

# å¯¹test1.wang.orgçš„è¯·æ±‚ä»£ç†è‡³service/pod-test1ï¼Œå¯¹test2.wang.orgè¯·æ±‚ä»£ç†è‡³service/pod-test2
[root@master1 ~]# kubectl create ingress demo-ingress3 --rule="test1.mystical.org/*=pod-test1:80" --rule="test2.mystical.org/*=pod-test2:80" --class=nginx
ingress.networking.k8s.io/demo-ingress3 created


# æŸ¥çœ‹
[root@master1 ~]# kubectl get ingress
NAME            CLASS   HOSTS                                  ADDRESS   PORTS   AGE
demo-ingress3   nginx   test1.mystical.org,test2.mytical.org             80      25s

[root@master1 ~]# kubectl get ingress demo-ingress3 -o yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  creationTimestamp: "2025-01-04T08:11:21Z"
  generation: 1
  name: demo-ingress3
  namespace: default
  resourceVersion: "40668"
  uid: af274e94-7c95-4ee3-9dd3-4da09fcd0937
spec:
  ingressClassName: nginx
  rules:
  - host: test1.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test1
            port:
              number: 80
        path: /
        pathType: Prefix
  - host: test2.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test2
            port:
              number: 80
        path: /
        pathType: Prefix
status:
  loadBalancer:
    ingress:
    - ip: 10.0.0.10


# æµ‹è¯•
[root@master1 ~]#curl -H'host: test1.mystical.org' 10.0.0.10
kubernetes pod-test v0.1!! ClientIP: 10.244.3.172, ServerName: pod-test1-cd487559d-gs725, ServerIP: 10.244.2.107!

[root@master1 ~]#curl -H'host: test2.mystical.org' 10.0.0.10
kubernetes pod-test v0.2!! ClientIP: 10.244.1.158, ServerName: pod-test2-6fb54b5db8-jkvjx, ServerIP: 10.244.1.160!

# æ¸…ç†
[root@master1 ~]#kubectl delete ingress demo-ingress3 
ingress.networking.k8s.io "demo-ingress3" deleted
```



##### HTTPS

èŒƒä¾‹ï¼šå‘½ä»¤å¼å®ç°HTTPS

```bash
# åŸºäºTLSçš„Ingressè¦æ±‚äº‹å…ˆå‡†å¤‡å¥½ä¸“ç”¨çš„â€œkubernetes.io/tlsâ€ç±»å‹çš„Secretèµ„æºå¯¹è±¡
[root@master1 tls]#ls
mystical.org.crt  mystical.org.key

#åˆ›å»ºSecret
[root@master1 tls]#kubectl create secret tls tls-mystical --cert=./mystical.org.crt --key=./mystical.org.key 
secret/tls-mystical created

# æŸ¥çœ‹
[root@master1 tls]#kubectl get secrets
NAME           TYPE                DATA   AGE
tls-mystical   kubernetes.io/tls   2      45s

#åˆ›å»ºè™šæ‹Ÿä¸»æœºä»£ç†è§„åˆ™ï¼ŒåŒæ—¶å°†è¯¥ä¸»æœºå®šä¹‰ä¸ºTLSç±»å‹ï¼Œé»˜è®¤HTTPè‡ªåŠ¨è·³è½¬è‡³HTTPS
[root@master1 tls]#kubectl create ingress tls-demo-ingress --rule='www.mystical.org/*=pod-test1:80, tls=tls-mystical' --class=nginx
ingress.networking.k8s.io/tls-demo-ingress created

# æ³¨æ„ï¼šå¯ç”¨tlsåï¼Œè¯¥åŸŸåä¸‹çš„æ‰€æœ‰URIé»˜è®¤ä¸ºå¼ºåˆ¶å°†httpè¯·æ±‚åˆ©ç”¨308è·³è½¬è‡³httpsï¼Œè‹¥ä¸å¸Œæœ›ä½¿ç”¨è¯¥è·³è½¬åŠŸèƒ½ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ³¨è§£é€‰é¡¹
--annotation nginx.ingress.kubernetes.io/ssl-redirect=falseï¼Œå³å¦‚ä¸‹å½¢å¼
[root@master1 ~]# kubectl create ingress tls-demo-ingress -- rule='www.wang.org/*=pod-test1:80,tls=tls-wang' --class=nginx --annotation nginx.ingress.kubernetes.io/ssl-redirect=false

# æŸ¥çœ‹
[root@master1 tls]#kubectl get ingress tls-demo-ingress -o yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  creationTimestamp: "2025-01-04T08:47:00Z"
  generation: 1
  name: tls-demo-ingress
  namespace: default
  resourceVersion: "44442"
  uid: 42e90245-143b-4f74-a128-8216da28b839
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test1
            port:
              number: 80
        path: /
        pathType: Prefix
  tls:
  - hosts:
    - www.mystical.org
    secretName: tls-mystical
status:
  loadBalancer:
    ingress:
    - ip: 10.0.0.10


#é›†ç¾¤å¤–å®¢æˆ·ç«¯æµ‹è¯•è®¿é—®
https://www.mystical.org/
```



![image-20250104165007749](../markdown_img/image-20250104165007749.png)





##### è¯ä¹¦æ›´æ–°

HTTPS çš„è¯ä¹¦çš„æœ‰æ•ˆæœŸä¸€èˆ¬ä¸º1å¹´,åˆ°æœŸå‰éœ€è¦æå‰æ›´æ–°è¯ä¹¦

```bash
#é‡æ–°é¢å‘è¯ä¹¦
[root@master1 ~]# (umask 077; openssl genrsa -out wang.key 2048)
[root@master1 ~]# openssl req -new -x509 -key wang.key -out wang.crt -subj /C=CN/ST=Beijing/L=Beijing/O=SRE/CN=www.wang.org -days 3650

# æ–¹æ³•1ï¼š
#åœ¨çº¿ä¿®æ”¹è¯ä¹¦é…ç½®,éœ€è¦æå‰å…ˆå°†æ–°è¯ä¹¦æ–‡ä»¶ç”¨base64ç¼–ç å¹¶åˆ é™¤æ¢è¡Œç¬¦
[root@master1 ~]# cat wang.crt |base64 | tr -d '\n' 
[root@master1 ~]# cat wang.key |base64 | tr -d '\n'

#ä¸Šé¢ç”Ÿæˆçš„å†…å®¹æ›¿æ¢ä¸‹é¢å‘½ä»¤çš„å†…å®¹,ç«‹å³ç”Ÿæ•ˆ
[root@master1 ~]# kubectl edit secrets tls-wang 

# æ–¹æ³•2ï¼š
#æ–¹æ³•2
#åˆ é™¤æ—§è¯ä¹¦é…ç½®
[root@master1 ~]#kubectl delete secrets tls-wang 

#åˆ›å»ºæ–°è¯ä¹¦é…ç½®
[root@master1 ~]# kubectl create secret tls tls-wang --cert=./wang.crt --key=./wang.key
```



### Ingresså£°æ˜å¼å®ç°

#### å£°æ˜å¼å®ç°è¯´æ˜

åŸºäºå‘½ä»¤æ–¹å¼æ ¼å¼åŠŸèƒ½æœ‰é™ï¼Œä¸”ä¸åˆ©äºåç»­çš„é‡å¤ä½¿ç”¨ï¼Œ**å·¥ä½œä¸­æ›´å¤šçš„ä½¿ç”¨å£°æ˜å¼å®ç°Ingress**

åœ¨å®é™…çš„å·¥ä½œä¸­ï¼Œå¯èƒ½ä¼šåŸºäºåŸŸåè®¿é—®,ä¹Ÿå¯èƒ½ä¼šåŸºäºä¸åŒçš„åŠŸèƒ½æœåŠ¡ä»¥å­è·¯å¾„çš„æ–¹å¼æ¥è¿›è¡Œè®¿é—®ï¼Œä»¥åŠ ä¸httpsç›¸å…³çš„è®¿é—®ã€‚



**é…ç½®æ–‡ä»¶è§£æ**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: <string>
  annotations:                                 # èµ„æºæ³¨è§£ï¼Œv1beta1ä½¿ç”¨ä¸‹é¢çš„æ³¨è§£æ¥æŒ‡å®šè¦è§£æè¯¥èµ„æºçš„æ§åˆ¶å™¨ç±»å‹
    kubernetes.io/ingress.class: <string>      # é€‚é…çš„Ingressæ§åˆ¶å™¨ç±»åˆ«ï¼Œä¾¿äºå¤šingressç»„ä»¶åœºæ™¯ä¸‹ï¼ŒæŒ‘é€‰é’ˆå¯¹çš„ç±»å‹
    # ç”¨äºURLé‡å†™
    nginx.ingress.kubernetes.io/rewrite-target: /   
  namespace: <string>
spec:
  rules: <[]object>                            # Ingressè§„åˆ™åˆ—è¡¨ï¼Œä¹Ÿå°±æ˜¯httpè½¬å‘æ—¶å€™ç”¨åˆ°çš„ urlå…³é”®å­—
  - host: <string>                             # è™šæ‹Ÿä¸»æœºçš„FQDNï¼Œæ”¯æŒ"*"å‰ç¼€é€šé…ï¼Œä¸æ”¯æŒIPï¼Œä¸æ”¯æŒæŒ‡å®šç«¯å£
    http: <object>
      paths: <[]object>                        # è™šæ‹Ÿä¸»æœºPATHå®šä¹‰çš„åˆ—è¡¨ï¼Œç”±pathå’Œbackendç»„æˆ
      - path: <string>                         # æµé‡åŒ¹é…çš„HTTP PATHï¼Œå¿…é¡»ä»¥/å¼€å¤´
        pathType: <string>                     # æ”¯æŒExactã€Prefixå’ŒImplementationSpecific, å¿…é¡»
        backend: <object>                      # åŒ¹é…åˆ°çš„æµé‡è½¬å‘åˆ°çš„ç›®æ ‡åç«¯
          resource: <object>                   # å¼•ç”¨çš„åŒä¸€åç§°ç©ºé—´ä¸‹çš„èµ„æºï¼Œä¸ä¸‹é¢ä¸¤ä¸ªå­—æ®µäº’æ–¥
          service: <object>                    # å…³è”çš„åç«¯Serviceå¯¹è±¡
            name: <string>                     # åç«¯Serviceçš„åç§°
            port: <string>                     # åç«¯Serviceä¸Šçš„ç«¯å£å¯¹è±¡
              name: <string>                   # ç«¯å£åç§°
              number: <integer>                # åç«¯Serviceçš„ç«¯å£å·cat
  tls: <[]Object>                              # TLSé…ç½®ï¼Œç”¨äºæŒ‡å®šä¸Šrulesä¸­å®šä¹‰çš„å“ªäº›hostéœ€è¦å·¥ä½œhttpsæ¨¡å¼
  - hosts: <[]string>                          # ä½¿ç”¨åŒä¸€ç»„è¯ä¹¦çš„ä¸»æœºåç§°åˆ—è¡¨
    secretName: <string>                       # ä¿å­˜äºæ•°å­—è¯ä¹¦å’Œç§é’¥ä¿¡æ¯çš„Secretèµ„æºåç§°ï¼Œç”¨äºä¸»æœºè®¤è¯
  backend: <Object>                            # é»˜è®¤backendçš„å®šä¹‰ï¼Œå¯åµŒå¥—å­—æ®µåŠä½¿ç”¨æ ¼å¼è·Ÿruleså­—æ®µä¸­çš„ç›¸åŒ
  ingressClassName: <string>                   # ingressç±»åç§°ï¼Œç”¨äºæŒ‡å®šé€‚é…çš„æ§åˆ¶å™¨ï¼Œç±»ä¼¼äºæ³¨è§£çš„åŠŸèƒ½ï¼Œæœªæ¥ä»£æ›¿                                                        annotations
```



#### è¡¥å……ï¼šä¸‰ç§ `pathType` åŠå…¶å«ä¹‰ä¸ä½¿ç”¨æ–¹å¼

1ï¸âƒ£ `Exact`

- **å«ä¹‰**ï¼šå®Œå…¨åŒ¹é…è·¯å¾„ï¼Œåªæœ‰è¯·æ±‚è·¯å¾„ä¸è§„åˆ™ä¸­çš„è·¯å¾„ **å®Œå…¨ä¸€è‡´** æ‰ä¼šè¢«åŒ¹é…ã€‚
- **åœºæ™¯**ï¼šé€‚ç”¨äºéœ€è¦ç²¾ç¡®æ§åˆ¶çš„ API å…¥å£ç­‰æƒ…å†µã€‚

**ç¤ºä¾‹ï¼š**

```yaml
path: /app
pathType: Exact
```

| è¯·æ±‚è·¯å¾„  | æ˜¯å¦åŒ¹é… |
| --------- | -------- |
| `/app`    | âœ… æ˜¯     |
| `/app/`   | âŒ å¦     |
| `/app/v1` | âŒ å¦     |



2ï¸âƒ£ `Prefix`

- **å«ä¹‰**ï¼šåŒ¹é…ä»¥æŒ‡å®šè·¯å¾„ä¸ºå‰ç¼€çš„è¯·æ±‚è·¯å¾„ï¼Œä¸”è·¯å¾„åˆ†æ®µï¼ˆä»¥ `/` åˆ†éš”ï¼‰å¿…é¡»å®Œæ•´åŒ¹é…ã€‚
- **è¿™æ˜¯ä½¿ç”¨æœ€å¹¿æ³›çš„ç±»å‹**ã€‚

**ç¤ºä¾‹ï¼š**

```yaml
path: /app
pathType: Prefix
```

| è¯·æ±‚è·¯å¾„       | æ˜¯å¦åŒ¹é… |
| -------------- | -------- |
| `/app`         | âœ… æ˜¯     |
| `/app/`        | âœ… æ˜¯     |
| `/app/page`    | âœ… æ˜¯     |
| `/application` | âŒ å¦     |

æ³¨æ„ï¼š**`/app/page`** âœ… æ˜¯å› ä¸ºå®ƒæ˜¯ä»¥ `/app` è¿™ä¸ªæ®µå¼€å¤´ï¼Œè€Œ `/application` âŒ æ˜¯å› ä¸ºæ•´ä¸ªæ®µä¸åŒ¹é…ã€‚



3ï¸âƒ£ `ImplementationSpecific`

- **å«ä¹‰**ï¼šç”± Ingress Controller è‡ªå·±å†³å®šå¦‚ä½•åŒ¹é…è·¯å¾„ï¼Œè¡Œä¸º **å¯èƒ½å› æ§åˆ¶å™¨ä¸åŒè€Œå¼‚**ã€‚
- **ä¸æ¨èç”Ÿäº§ä½¿ç”¨**ï¼Œå®¹æ˜“å‡ºç°ä¸ä¸€è‡´è¡Œä¸ºã€‚

 **ç¤ºä¾‹ï¼š**

```
path: /app
pathType: ImplementationSpecific
```

| è¯·æ±‚è·¯å¾„    | æ˜¯å¦åŒ¹é… |
| ----------- | -------- |
| `/app`      | å¯èƒ½æ˜¯   |
| `/app2`     | å¯èƒ½ä¹Ÿæ˜¯ |
| `/app/test` | å¯èƒ½æ˜¯   |

å–å†³äºä½ ç”¨çš„æ˜¯å“ªä¸ª Ingress Controllerï¼Œä¾‹å¦‚ NGINXã€Traefikã€HAProxy ç­‰éƒ½å®ç°ç•¥æœ‰ä¸åŒã€‚



#### è¡¥å……ï¼šIngressé‡å®šå‘å®ç°

`nginx.ingress.kubernetes.io/rewrite-target: /` è¿™ä¸ª annotation ç”¨äº **URL é‡å†™**ï¼Œå®ƒçš„ä½œç”¨æ˜¯ **å°†è¿›å…¥ Ingress çš„è¯·æ±‚è·¯å¾„â€œä¿®æ”¹åâ€å†è½¬å‘ç»™åç«¯æœåŠ¡**ã€‚

##### ä¾‹å­ï¼šURL é‡å†™

**ç›®æ ‡**

- ç”¨æˆ·è®¿é—® **`http://example.org/app`** æ—¶ï¼Œåç«¯å®é™…æ”¶åˆ°çš„æ˜¯ `/`ã€‚
- é€‚ç”¨äºåç«¯æœåŠ¡ä¸å¸Œæœ›å¤„ç† `app` è¿™ä¸ªå‰ç¼€çš„æƒ…å†µã€‚

**1ï¸âƒ£ åˆ›å»º Service**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: echo-service
  namespace: default
spec:
  selector:
    app: echo
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
```

**2ï¸âƒ£ åˆ›å»º Deployment**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-deployment
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: echo
  template:
    metadata:
      labels:
        app: echo
    spec:
      containers:
      - name: echo-container
        image: hashicorp/http-echo
        args:
        - "-text=Hello from backend!"
        ports:
        - containerPort: 80
```

**3ï¸âƒ£ åˆ›å»º Ingress**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: echo-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: example.org
    http:
      paths:
      - path: /app
        pathType: Prefix
        backend:
          service:
            name: echo-service
            port:
              number: 80
```

**è§£æ**

1. **ç”¨æˆ·è¯·æ±‚**ï¼š`http://example.org/app`
2. Ingress å¤„ç†ï¼š
   - ç”±äº `rewrite-target: /`ï¼Œè¯·æ±‚çš„è·¯å¾„ `/app` ä¼šè¢«**æ›¿æ¢æˆ `/`**ã€‚
   - Nginx Ingress å‘é€è¯·æ±‚ç»™åç«¯æ—¶ï¼Œè·¯å¾„å˜ä¸º `/`ã€‚
3. åç«¯æ”¶åˆ°è¯·æ±‚ï¼š
   - `echo-service` åªæ¥æ”¶ `/`ï¼Œè¿”å› `Hello from backend!`ã€‚



#### è¡¥å……ï¼šIngress è®°å½• `Service` ç«¯å£çš„æ„ä¹‰

##### ä¸ºä»€ä¹ˆ `Ingress` éœ€è¦ `Service` ç«¯å£

**ğŸ”¹ Ingress Controller éœ€è¦æ‰¾åˆ° `Service`**

- `Ingress` ä¸èƒ½ç›´æ¥å®šä¹‰ **Pod** ä½œä¸ºåç«¯ï¼Œè€Œæ˜¯ **å¿…é¡»é€šè¿‡ `Service`**ï¼Œä»¥å®ç°è´Ÿè½½å‡è¡¡å’ŒåŠ¨æ€æ›´æ–°åç«¯ Pod åˆ—è¡¨
- `Service` å¯èƒ½æœ‰å¤šä¸ªç«¯å£ï¼Œè€Œ Ingress Controller **å¿…é¡»çŸ¥é“åº”è¯¥æŠŠæµé‡è½¬å‘åˆ°å“ªä¸ªç«¯å£**ã€‚

**ğŸ”¹ Ingress éœ€è¦åŒ¹é… `Service` çš„ `port`**

- `Ingress` è§„åˆ™æŒ‡å®šçš„æ˜¯ **Service çš„ç«¯å£**ï¼Œè€Œä¸æ˜¯ Pod çš„ç«¯å£

- `Service` å¯èƒ½æ˜ å°„ Pod ä¸Šçš„ä¸åŒç«¯å£ï¼Œæ¯”å¦‚

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: my-service
  spec:
    ports:
      - name: http
        port: 8080        # Service æš´éœ²çš„ç«¯å£
        targetPort: 80    # Pod å†…éƒ¨çš„ç«¯å£
  ```

  æ­¤æ—¶ï¼ŒIngress è§„åˆ™å¿…é¡»æŒ‡å®š `port: 8080`ï¼Œå¦åˆ™æµé‡ä¸ä¼šæ­£ç¡®è½¬å‘ï¼

  ```bash
  apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    name: my-ingress
  spec:
    rules:
    - host: "example.org"
      http:
        paths:
        - path: "/"
          pathType: Prefix
          backend:
            service:
              name: my-service
              port:
                number: 8080  # è¿™é‡Œå¿…é¡»åŒ¹é… Service çš„ç«¯å£
  ```

  **ğŸ”¹ é‡ç‚¹ï¼š**

  - `Ingress` é€šè¿‡ **`Service` ç«¯å£** æŸ¥æ‰¾åç«¯æœåŠ¡ï¼Œå¹¶è½¬å‘æµé‡ã€‚
  - `Service` å†å°†æµé‡è½¬å‘åˆ°å¯¹åº”çš„ `Pod`ï¼ˆ`targetPort`ï¼‰ã€‚



##### Ingress å®é™…ä¸Šå¦‚ä½•å’Œ Pod é€šä¿¡

è™½ç„¶ `Ingress` é…ç½®çš„æ˜¯ `Service` çš„ç«¯å£ï¼Œä½† `Ingress Controller` **æœ€ç»ˆä¼šç»•è¿‡ `Service`ï¼Œç›´æ¥å’Œ Pod é€šä¿¡**ï¼ˆService ä¸»è¦ç”¨äºå‘ç° Podï¼‰ã€‚

**æµç¨‹å¦‚ä¸‹ï¼š**

1. ç”¨æˆ·è¯·æ±‚ `example.org`

   ```bash
   curl http://example.org
   ```

2. DNS è§£æ `example.org`ï¼ŒæŒ‡å‘ `Ingress Controller`

3. `Ingress Controller` æ ¹æ® `Host` å’Œ `Path` è§„åˆ™åŒ¹é…åˆ° `Service`

4. `Ingress Controller` æŸ¥è¯¢ `Service` çš„ `Endpoints`ï¼ˆå®é™…çš„ Pod åˆ—è¡¨ï¼‰

5. `Ingress Controller` ç›´æ¥è½¬å‘æµé‡åˆ°åç«¯`Pod`

   - Ingress Controller **ä¸ä¼šå†ç»è¿‡ `Service` è´Ÿè½½å‡è¡¡ï¼Œè€Œæ˜¯ç›´æ¥é€‰æ‹©ä¸€ä¸ª `Pod` å¹¶è½¬å‘è¯·æ±‚**ã€‚



#### å£°æ˜å¼å®ç°æ¡ˆä¾‹

##### å•åŸŸåæ¡ˆä¾‹

![image-20250104171513550](../markdown_img/image-20250104171513550.png)

èŒƒä¾‹ : å•åŸŸåæ”¯æŒå­URL

```yaml
# å‡†å¤‡åç«¯æœåŠ¡æ‰€éœ€èµ„æº
[root@master1 ingress] # cat ingress-deployment-svc.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-test
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pod-test
  template:
    metadata:
      labels:
        app: pod-test
    spec:
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
          name: http
---
apiVersion: v1
kind: Service
metadata:
  name: deployment-service
spec:
  selector:
    app: pod-test
  ports:
  - name: http
    port: 80
    targetPort: 80
    
# åº”ç”¨
[root@master1 yaml] # kubectl apply -f ingress-deployment-svc.yaml 
deployment.apps/deployment-test created

# è‡ªå®šä¹‰åˆ›å»ºingressèµ„æºæ–‡ä»¶
[root@master1 ingress] # vim ingress-http-test.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-test
  #annotations:
  #  kubernetes.io/ingress.class: "nginx"
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: deployment-service
            port:
              number: 80

# æŸ¥çœ‹ingress
[root@master1 ingress] # kubectl get ingress
NAME           CLASS   HOSTS              ADDRESS     PORTS   AGE
ingress-test   nginx   www.mystical.org   10.0.0.10   80      2m12s

# æµ‹è¯•
# è¿™é‡Œçš„å®¢æˆ·ç«¯æ˜¾ç¤ºçš„æ˜¯ingressçš„Podçš„IPï¼Œè€Œä¸æ˜¯çœŸå®çš„å®¢æˆ·ç«¯IP
[root@master1 ingress] # curl -H"host: www.mystical.org" 10.0.0.10
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: deployment-test-5cc5b8d4cd-bzbnm, ServerIP: 10.244.2.112!
[root@master1 ingress] # curl -H"host: www.mystical.org" 10.0.0.10
kubernetes pod-test v0.1!! ClientIP: 10.244.1.164, ServerName: deployment-test-5cc5b8d4cd-qv78g, ServerIP: 10.244.3.177!

# æ¸…ç†åˆ é™¤
[root@master1 ingress]#kubectl delete -f ingress-http-test.yaml 
ingress.networking.k8s.io "ingress-test" deleted
```



##### è·å–çœŸå®å®¢æˆ·ç«¯IP

```yaml
# ç¯å¢ƒå‡†å¤‡ï¼Œç›´æ¥ä½¿ç”¨ä¸Šè¿°ç¯å¢ƒå³å¯
[root@master1 ingress] # kubectl create deployment myapp --image registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
deployment.apps/myapp created

[root@master1 ingress] # kubectl create svc clusterip myapp --tcp 80
service/myapp created

# Ingressé…ç½®
[root@master1 ingress] # cat ingress-http-real-ip.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-myapp
  annotations:
    nginx.ingress.kubernetes.io/enable-real-ip: "true" # å…è®¸IPé€ä¼ ï¼Œæ­¤ä¸ºé»˜è®¤å€¼
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: myapp
            port:
              number: 80
        path: /
        pathType: Prefix
        
# æŸ¥çœ‹ingress-nginxçš„podé‡Œçš„é…ç½®
[root@master1 ingress] # kubectl exec -n ingress-nginx ingress-nginx-controller-666487-9cvb7 -- nginx -T|grep 'proxy_set_header X-Forwarded-For'
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
			proxy_set_header X-Forwarded-For        $remote_addr;
			proxy_set_header X-Forwarded-For        $remote_addr;
			
# ä»é›†ç¾¤å¤–è®¿é—® 
[root@ubuntu2204 ~] # curl www.mystical.org
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
...

# æŸ¥çœ‹æ—¥å¿—ä¿¡æ¯
[root@master1 ingress] # kubectl logs myapp-56cc856b4-k9hjv 
10.244.3.178 - - [06/Jan/2025:06:28:39 +0000] "GET / HTTP/1.1" 200 612 "-" "curl/7.81.0" "10.0.0.132"
10.244.3.178 - - [06/Jan/2025:06:28:42 +0000] "GET / HTTP/1.1" 200 612 "-" "curl/7.81.0" "10.0.0.132"
```



##### å•åŸŸåå¤šURLæ¡ˆä¾‹

èŒƒä¾‹ï¼šç¯å¢ƒå‡†å¤‡ä¸¤ä¸ªHTTPåº”ç”¨

```yaml
# å¦‚æœå‰é¢çš„èµ„æºå·²åˆ é™¤ï¼Œé‡æ–°åº”ç”¨ä¸Šé¢å°èŠ‚çš„èµ„æºæ–‡ä»¶ç”Ÿæˆdeploymentå’Œå¯¹åº”çš„SVC
#è®¿é—® www.wang.org/flaskçš„æ—¶å€™ï¼Œè¿”å›flaskçš„ç»“æœ
#è®¿é—® www.wang.org/nginxçš„æ—¶å€™ï¼Œè¿”å›nginxçš„ç»“æœ

[root@master1 ingress] # cat ingress-deployment-svc.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-test
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pod-test
  template:
    metadata:
      labels:
        app: pod-test
    spec:
      containers:
      - name: pod-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
          name: http
---
apiVersion: v1
kind: Service
metadata:
  name: deployment-service
spec:
  selector:
    app: pod-test
  ports:
  - name: http
    port: 80
    targetPort: 80


# åº”ç”¨
[root@master1 ingress] # kubectl apply -f ingress-deployment-svc.yaml 
deployment.apps/deployment-test created
service/deployment-service created

# åœ¨æ·»åŠ ä¸€ä¸ªnginxçš„æœåŠ¡ï¼Œå®šä¹‰èµ„æºæ–‡ä»¶
[root@master1 ingress] # cat ingress-deployment-nginx.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-test
  template:
    metadata:
      labels:
        app: nginx-test
    spec:
      containers:
      - name: nginx-test
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
          name: nginx

---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx-test
  ports:
  - name: nginx
    port: 80
    targetPort: 80
    
# åº”ç”¨
[root@master1 ingress] # kubectl apply -f ingress-deployment-nginx.yaml 
deployment.apps/deployment-nginx created
service/nginx-service created

# æŸ¥çœ‹
[root@master1 ingress] # kubectl get deployments,svc
NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deployment-nginx   3/3     3            3           113s
deployment.apps/deployment-test    3/3     3            3           10m
deployment.apps/myapp              1/1     1            1           21m

NAME                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/deployment-service   ClusterIP   10.105.47.74     <none>        80/TCP    10m
service/kubernetes           ClusterIP   10.96.0.1        <none>        443/TCP   2d5h
service/myapp                ClusterIP   10.102.162.246   <none>        80/TCP    21m
service/nginx-service        ClusterIP   10.102.157.212   <none>        80/TCP    113s
```



**å•åŸŸåå¤šURLä¸æ”¯æŒå­URL**

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 ingress] # cat ingress-http-mul-url.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-mul-url
  annotations:
#    kubenetes.io/ingress.class: "nginx"   # æ–°ç‰ˆk8så¥½åƒä¸æ”¯æŒæ³¨è§£çš„ç”¨æ³•
    nginx.ingress.kubernetes.io/rewrite-target: / # é»˜è®¤ä¼šè½¬å‘ç»™åç«¯æ—¶ä¼šå¸¦URLï¼Œæ·»åŠ æ­¤è¡Œï¼Œè¡¨ç¤ºè½¬å‘æ—¶åˆ é™¤åé¢çš„URL
spec:
  ingressClassName: nginx  # æ–°ç‰ˆå»ºè®®ä½¿ç”¨æ­¤é¡¹æŒ‡å®šcontrollerç±»å‹
  rules:
  - host: www.mystical.org
    http:
      paths:
      - path: /flask
        pathType: Prefix # è¡¨ç¤ºä»¥/flaskä¸ºå¼€å§‹å³å¯
        backend:
          service:
            name: deployment-service  # æŒ‡å®šå¯¹åº”Serviceçš„åç§°
            port:
              name: http
      - path: /nginx
        pathType: Prefix
        backend:
          service:
            name: nginx-service
            port:
              name: nginx

# åº”ç”¨
[root@master1 ingress] # kubectl apply -f ingress-http-mul-url.yaml 
ingress.networking.k8s.io/ingress-mul-url created

# æŸ¥çœ‹
[root@master1 ingress] # kubectl get ingress
NAME              CLASS   HOSTS              ADDRESS     PORTS   AGE
ingress-mul-url   nginx   www.mystical.org   10.0.0.10   80      5s

# æµ‹è¯•
[root@ubuntu2204 ~] # curl www.mystical.org/flask
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: deployment-test-5cc5b8d4cd-nrv8t, ServerIP: 10.244.1.166!

[root@ubuntu2204 ~] # curl www.mystical.org/nginx
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
......

#æ³¨æ„äº‹é¡¹ï¼š
#é»˜è®¤è½¬ç»™åç«¯æœåŠ¡æ—¶ä¼šå°†urlä¹ŸåŒæ—¶è½¬å‘ï¼Œè€Œåç«¯æœåŠ¡æœ‰å¯èƒ½ä¸å­˜åœ¨æ­¤URLï¼Œæ‰€ä»¥éœ€è¦åœ¨åç«¯urlè½¬å‘çš„æ—¶å€™ï¼Œå–æ¶ˆè½¬å‘å…³é”®å­—ã€‚
#æ–¹æ³•å°±æ˜¯ï¼Œåœ¨annotationä¸­æ·»åŠ ä¸€ä¸ªé‡å†™çš„è§„åˆ™nginx.ingress.kubernetes.io/rewrite-target: / å³æ‰€æœ‰çš„è¯·æ±‚æŠŠingressåŒ¹é…åˆ°çš„urlå…³é”®å­—æ¸…é™¤æ‰

```



**å•åŸŸåå¤šURLæ”¯æŒå­URL**

```yaml
# å‡†å¤‡åç«¯çš„åº”ç”¨pod-test v0.1å’Œç›¸åº”çš„service
[root@master1 ~]# kubectl create deployment pod-test1 --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas=3
deployment.apps/pod-test1 created

[root@master1 ~]# kubectl create service clusterip pod-test1 --tcp=80:80
service/pod-test1 created

# å‡†å¤‡åç«¯çš„åº”ç”¨pod-test v0.2å’Œç›¸åº”çš„service
[root@master1 ~]# kubectl create deployment pod-test2 --image=registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2 --replicas=3
deployment.apps/pod-test2 created

[root@master1 ~]#kubectl create service clusterip pod-test2 --tcp=80:80
service/pod-test2 created

[root@master1 ~]#kubectl get ep
NAME         ENDPOINTS                                         AGE
kubernetes   10.0.0.201:6443                                   4h47m
pod-test1    10.244.1.159:80,10.244.2.107:80,10.244.3.173:80   3m10s
pod-test2    10.244.1.160:80,10.244.2.108:80,10.244.3.174:80   13s


# èµ„æºæ–‡ä»¶
[root@master1 ingress] # cat ingress-http-mul-suburl.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2  # æ­£åˆ™è¡¨è¾¾å¼
  name: ingress-http-mul-suburl
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test1
            port:
              number: 80
        path: /v1(/|$)(.*)
        pathType: Exact
      - backend:
          service:
            name: pod-test2
            port:
              number: 80
        path: /v2(/|$)(.*)
        pathType: Exact

# åº”ç”¨
[root@master1 ingress] # kubectl apply -f ingress-http-mul-suburl.yaml 
Warning: path /v1(/|$)(.*) cannot be used with pathType Exact
Warning: path /v2(/|$)(.*) cannot be used with pathType Exact
ingress.networking.k8s.io/ingress-http-mul-suburl created

# æŸ¥çœ‹
[root@master1 ingress] # kubectl get ingress
NAME                      CLASS   HOSTS              ADDRESS     PORTS   AGE
ingress-http-mul-suburl   nginx   www.mystical.org   10.0.0.10   80      9s

# æµ‹è¯•
[root@ubuntu2204 ~]#curl www.mystical.org/v1/hostname
ServerName: pod-test1-cd487559d-wfvhs
[root@ubuntu2204 ~]#curl www.mystical.org/v2/hostname
ServerName: pod-test2-6fb54b5db8-mmrjm
```



##### å¤šåŸŸåæ¡ˆä¾‹

```yaml
# è®¿é—®flask.mystical.org/çš„æ—¶å€™ï¼Œè¿”å›flaskçš„ç»“æœ
# è®¿é—®flask.mystical.org/çš„æ—¶å€™ï¼Œè¿”å›nginxçš„ç»“æœ
[root@master1 ingress] # kubectl apply -f ingress-deployment-nginx.yaml 
deployment.apps/deployment-nginx created
service/nginx-service created

[root@master1 ingress] # kubectl apply -f ingress-deployment-svc.yaml
deployment.apps/deployment-test created
service/deployment-service created

# ç¼–è¾‘Ingressèµ„æºå®šä¹‰æ–‡ä»¶
[root@master1 ingress]#cat ingress-http-mul-host.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-mul-url
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"           # æŒ‡å®šåé¢ruleså®šä¹‰çš„pathä½¿ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼
    nginx.ingress.kubernetes.io/proxy-body-size: "100m"     # å®¢æˆ·ç«¯ä¸Šä¼ æ–‡ä»¶æœ€å¤§å€¼ï¼Œé»˜è®¤1m
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "60" # åç«¯æœåŠ¡å™¨çš„è¿æ¥è¶…æ—¶çš„æ—¶é—´ï¼Œé»˜è®¤å€¼ä¸º5s
    nginx.ingress.kubernetes.io/proxy-send-timeout: "120"   # åç«¯æœåŠ¡å™¨æ•°æ®å›ä¼ è¶…æ—¶æ—¶é—´ï¼Œå³è§„å®šæ—¶é—´ä¹‹å†…åç«¯æœåŠ¡å™¨å¿…é¡»ä¼ å®Œæ‰€æœ‰çš„æ•°æ®ï¼Œé»˜è®¤å€¼ä¸º60s
    nginx.ingress.kubernetes.io/proxy-read-timeout: "120"   # åç«¯æœåŠ¡å™¨å“åº”çš„è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤60s
    #nginx.ingress.kubernetes.io/app-root: /index.html      #æŒ‡å®šé»˜è®¤é¡µé¢æ–‡ä»¶
spec:
  ingressClassName: nginx                                   # æ–°ç‰ˆå»ºè®®ä½¿ç”¨æ­¤é¡¹æŒ‡å®šcontrollerlç±»å‹
  rules:
  - host: flask.mystical.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: deployment-service
            port:
              name: http                                  # åŒ¹é…serviceä¸­çš„ç«¯å£ name: http
  - host: nginx.mystical.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx-service
            port:
              name: nginx

# åº”ç”¨
[root@master1 ingress] # kubectl apply -f ingress-http-mul-host.yaml 
ingress.networking.k8s.io/ingress-mul-url created

# æŸ¥çœ‹
[root@master1 ingress]#kubectl get ingress
NAME              CLASS   HOSTS                                   ADDRESS     PORTS   AGE
ingress-mul-url   nginx   flask.mystical.org,nginx.mystical.org   10.0.0.10   80      65s

# æµ‹è¯•
[root@ubuntu2204 ~] # curl flask.mystical.org
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: deployment-test-5cc5b8d4cd-69cgm, ServerIP: 10.244.3.184!

[root@ubuntu2204 ~] # curl nginx.mystical.org
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>

#æ¸…ç†ç¯å¢ƒ
[root@master1 ingress] # kubectl delete -f ingress-http-mul-host.yaml 
ingress.networking.k8s.io "ingress-mul-url" deleted

[root@master1 ingress] # kubectl delete -f ingress-deployment-svc.yaml 
deployment.apps "deployment-test" deleted
service "deployment-service" deleted

[root@master1 ingress] # kubectl delete -f ingress-deployment-nginx.yaml 
deployment.apps "deployment-nginx" deleted
service "nginx-service" deleted
```



#####  HTTPS æ¡ˆä¾‹

```yaml
# å‡†å¤‡å¥½è¯ä¹¦ç›¸å…³çš„secret
[root@master1 ingress] # kubectl get secret
NAME           TYPE                DATA   AGE
tls-mystical   kubernetes.io/tls   2      47h

# å‡†å¤‡å¥½åé¢çš„deploymentå’Œservice
[root@master1 ingress] # kubectl apply -f ingress-deployment-svc.yaml 
deployment.apps/deployment-test created
service/deployment-service created

# å®šä¹‰èµ„æºé…ç½®æ–‡ä»¶ï¼Œå®ç°HTTPè‡ªåŠ¨è·³è½¬è‡³HTTPS
[root@master1 ingress]#cat ingress-http-tls-test.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-test
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: deployment-service
            port:
              number: 80
# - host: m.mystical.org
# ...

# httpsè¯ä¹¦é…ç½®
  tls:
  - hosts:
    - www.mystical.org
    secretName: tls-mystical
 #- hosts:                                             # å¤šä¸ªåŸŸååˆ†åˆ«å¯¹åº”ä¸åŒçš„è¯ä¹¦
 #  - m.mystical.org
 #  secretName: ingress-tls-m


# åº”ç”¨
[root@master1 ingress] # kubectl apply -f ingress-http-tls-test.yaml 
ingress.networking.k8s.io/ingress-test created

# æŸ¥çœ‹
[root@master1 ingress] # kubectl get ingress
NAME           CLASS   HOSTS              ADDRESS     PORTS     AGE
ingress-test   nginx   www.mystical.org   10.0.0.10   80, 443   2m11s


# æµ‹è¯•
[root@ubuntu2204 ~] # curl www.mystical.org -Lk
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: deployment-test-5cc5b8d4cd-ww8fc, ServerIP: 10.244.3.185!
[root@ubuntu2204 ~] # curl www.mystical.org -Lk
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: deployment-test-5cc5b8d4cd-lkf2v, ServerIP: 10.244.2.119!
```





### Ingress Nginx å®ç°è“ç»¿BlueGreen å’Œç°åº¦Canary å‘å¸ƒ



####  Ingress Nginx è¿›è¡ŒBlueGreen å’Œ Canary ç°åº¦å‘å¸ƒè¯´æ˜



Service è™½ç„¶æ”¯æŒæµé‡åˆ†é…,ä½†æ˜¯**åªæ”¯æŒåŸºäºPodçš„æ•°é‡æˆ–æ¯”ä¾‹å®ç°**,è€Œ**ä¸æ”¯æŒåŸºäºHeader,cookie,æƒé‡ç­‰** æ›´ä¸ºæ¸…ç¡®çš„æµé‡å‘é…ç­–ç•¥

**Ingress-Nginxæ”¯æŒé…ç½®Ingress Annotationsæ¥å®ç°ä¸åŒåœºæ™¯ä¸‹çš„ç°åº¦å‘å¸ƒå’Œæµ‹è¯•**ï¼Œå®ƒèƒ½å¤Ÿæ»¡è¶³é‡‘ä¸é›€ å‘å¸ƒã€è“ç»¿éƒ¨ç½²ä¸A/Bæµ‹è¯•ç­‰ä¸åŒçš„ä¸šåŠ¡åœºæ™¯

**æ³¨æ„**ï¼šIngress-Nginx åªèƒ½æ”¯æŒå—åŒ—å‘çš„æµé‡å‘å¸ƒï¼Œè€Œä¸œè¥¿å‘æµé‡çš„å‘å¸ƒå¯ä»¥åˆ©ç”¨å·¥ä½œè´Ÿè½½å‹å¦‚ deploymentçš„æ›´æ–°ç­–ç•¥æˆ–è€…æœåŠ¡ç½‘æ ¼æŠ€æœ¯å®ç°



**Ingress Nginxçš„æµé‡å‘å¸ƒæœºåˆ¶**



![image-20250106163000499](../markdown_img/image-20250106163000499.png)



- **è“ç»¿**ï¼š
  - production: 100%, canary: 0%
  - production: 0%, canary: 100% --> Canaryå˜æˆåé¢çš„Production
- **é‡‘ä¸é›€Canary**ï¼š
  - **æµé‡æ¯”ä¾‹åŒ–åˆ‡åˆ†**: é€æ¸è°ƒæ•´
  - **æµé‡è¯†åˆ«ï¼Œå°†ç‰¹å®šçš„æµé‡åˆ†å‘ç»™Canary**ï¼š
    - By-Headerï¼šåŸºäºç‰¹å®šçš„æ ‡å¤´è¯†åˆ«
      -  Header å€¼é»˜è®¤ï¼šåªæœ‰Always æˆ– Nerver ä¸¤ç§å€¼ 
      - Header å€¼è‡ªå®šä¹‰ 
      - Header å€¼å¯ä»¥åŸºäºæ­£åˆ™è¡¨è¾¾å¼Patternè¿›è¡ŒåŒ¹é…
    - By-Cookie: åŸºäºCookieè¯†åˆ«



**åŸºäºIngress Nginxçš„Canaryè§„åˆ™**

Ingress Nginx çš„ Annotationsæ”¯æŒçš„Canaryè§„åˆ™ï¼Œ Annotations å’Œ Label ç›¸ä¼¼ä¹Ÿæ˜¯ä¿å­˜èµ„æºå¯¹è±¡ä¸Šçš„ å…ƒæ•°æ®ï¼Œä½†ä¸èƒ½è¢«æ ‡ç­¾é€‰æ‹©å™¨é€‰æ‹©ï¼Œä¸”æ²¡æœ‰Labelçš„åç§°æœ€é•¿63ä¸ªå­—ç¬¦çš„é™åˆ¶



- **nginx.ingress.kubernetes.io/canary-weight**ï¼š
  - åŸºäºæœåŠ¡æƒé‡è¿›è¡Œæµé‡åˆ‡åˆ†ï¼Œé€‚ç”¨äºè“ç»¿æˆ–ç°åº¦å‘å¸ƒï¼Œæƒé‡èŒƒå›´0 - 100æŒ‰ç™¾åˆ†æ¯”å°†è¯·æ±‚è·¯ç”±åˆ° Canary Ingressä¸­æŒ‡å®šçš„æœåŠ¡
  - æƒé‡ä¸º 0 æ„å‘³ç€è¯¥é‡‘ä¸é›€è§„åˆ™ä¸ä¼šå‘Canaryå…¥å£çš„æœåŠ¡å‘é€ä»»ä½•è¯·æ±‚
  - æƒé‡ä¸º100æ„å‘³ç€æ‰€æœ‰è¯·æ±‚éƒ½å°†è¢«å‘é€åˆ° Canary å…¥å£

- **nginx.ingress.kubernetes.io/canary-by-cookie**ï¼š
  - åŸºäº cookie çš„æµé‡åˆ‡åˆ†ï¼Œé€‚ç”¨äºç°åº¦å‘å¸ƒä¸ A/B æµ‹è¯•
  - cookie çš„å€¼è®¾ç½®ä¸º always æ—¶ï¼Œå®ƒå°†è¢«è·¯ç”±åˆ°Canaryå…¥å£
  - cookie çš„å€¼è®¾ç½®ä¸º never æ—¶ï¼Œè¯·æ±‚ä¸ä¼šè¢«å‘é€åˆ°Canaryå…¥å£
  - å¯¹äºä»»ä½•å…¶ä»–å€¼ï¼Œå°†å¿½ç•¥ cookie å¹¶å°†è¯·æ±‚ä¸å…¶ä»–é‡‘ä¸é›€è§„åˆ™è¿›è¡Œä¼˜å…ˆçº§çš„æ¯”è¾ƒï¼Œé»˜è®¤è½¬å‘ç»™æ—§ç‰ˆ æœ¬











**è§„åˆ™çš„åº”ç”¨æ¬¡åº**

- Canaryè§„åˆ™ä¼šæŒ‰ç‰¹å®šçš„æ¬¡åºè¿›è¡Œè¯„ä¼°
- ä¼˜å…ˆçº§ä»ä½åˆ°é«˜é¡ºåºï¼š**canary -weight- -> canary-by-cookie --> canary-by-header** 





#### å®æˆ˜æ¡ˆä¾‹

##### èŒƒä¾‹ï¼šåˆå§‹ç¯å¢ƒå‡†å¤‡æ–°æ—§ä¸¤ä¸ªç‰ˆæœ¬åº”ç”¨

```yaml
# å‡†å¤‡æ–°æ—§ç‰ˆæœ¬å¯¹åº”çš„å„è‡ªç‹¬ç«‹çš„ä¸¤å¥—deploymentå’Œservice
[root@master1 project-caray] # cat deploy-pod-test-v1.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: pod-test
  name: pod-test-v1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pod-test
      version: v0.1
  strategy: {}
  template:
    metadata:
      labels:
        app: pod-test
        version: v0.1
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
        name: pod-test

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: pod-test
  name: pod-test-v1
spec:
  ports:
  - name: http-80
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: pod-test
    version: v0.1
  type: ClusterIP

[root@master1 project-caray] # cat deploy-pod-test-v2.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: pod-test
  name: pod-test-v2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pod-test
      version: v0.2
  strategy: {}
  template:
    metadata:
      labels:
        app: pod-test
        version: v0.2
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2
        name: pod-test

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: pod-test
  name: pod-test-v2
spec:
  ports:
  - name: http-80
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: pod-test
    version: v0.2
  type: ClusterIP


# éƒ¨ç½²æ–°æ—§ä¸¤ä¸ªç‰ˆæœ¬
[root@master1 project-caray] # kubectl apply -f deploy-pod-test-v1.yaml 
deployment.apps/pod-test-v1 created
service/pod-test-v1 created

[root@master1 project-caray] # kubectl apply -f deploy-pod-test-v2.yaml 
deployment.apps/pod-test-v2 created
service/pod-test-v2 created

# æµ‹è¯•
[root@master1 project-caray] # kubectl get svc
NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes    ClusterIP   10.96.0.1       <none>        443/TCP   2d7h
pod-test-v1   ClusterIP   10.99.14.10     <none>        80/TCP    84s
pod-test-v2   ClusterIP   10.96.114.114   <none>        80/TCP    81s

[root@master1 project-caray] # curl 10.99.14.10
kubernetes pod-test v0.1!! ClientIP: 10.244.0.0, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!

[root@master1 project-caray] # curl 10.96.114.114
kubernetes pod-test v0.2!! ClientIP: 10.244.0.0, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
```



##### èŒƒä¾‹ï¼šè“ç»¿å‘å¸ƒ

```yaml
# åˆ›å»ºIngressï¼Œä½¿å…¶å¯¹åº”æ—§ç‰ˆæœ¬åº”ç”¨
[root@master1 project-caray] # cat ingress-blue-green.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-blue-green
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test-v1
            port:
              number: 80 
        path: /
        pathType: Prefix

# æŸ¥çœ‹
[root@master1 project-caray] # kubectl get ingress
NAME                 CLASS   HOSTS              ADDRESS     PORTS   AGE
ingress-blue-green   nginx   www.mystical.org   10.0.0.10   80      54s

# æµ‹è¯•
[root@ubuntu2204 ~] # curl www.mystical.org
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!

# ä¿®æ”¹Ingressåˆ‡æ¢æˆv0.2ç‰ˆæœ¬
[root@master1 project-caray]#cat ingress-blue-green.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-blue-green
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test-v2              # ä¿®æ”¹Serviceç‰ˆæœ¬
            port:
              number: 80 
        path: /
        pathType: Prefix

# åº”ç”¨
[root@master1 project-caray] # kubectl apply -f ingress-blue-green.yaml 
ingress.networking.k8s.io/ingress-blue-green configured

# æµ‹è¯•
[root@ubuntu2204 ~] # curl www.mystical.org
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
```





##### èŒƒä¾‹ï¼šåŸºäºæƒé‡çš„é‡‘ä¸é›€å‘å¸ƒ

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 project-caray] # cat canary-by-weight.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-weight: "10"  # æŒ‡å®šä½¿ç”¨é‡‘ä¸é›€æ–°ç‰ˆå ç”¨ç™¾åˆ†æ¯”
  name: pod-test-canary-by-weight
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test-v2
            port:
              number: 80
        path: /
        pathType: Prefix

# åº”ç”¨
[root@master1 project-caray] # kubectl apply -f canary-by-weight.yaml 
ingress.networking.k8s.io/pod-test-canary-by-weight created

# é›†ç¾¤å¤–å®¢æˆ·ç«¯è®¿é—®ï¼Œè§‚å¯Ÿæ–°æ—§ç‰ˆæœ¬çš„æ¯”ä¾‹
[root@ubuntu2204 ~]#while true; do curl www.mystical.org; sleep 1; done
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!

# è°ƒæ•´weightæƒé‡ä¸º90
[root@master1 project-caray]# cat canary-by-weight.yaml 
......
    nginx.ingress.kubernetes.io/canary-weight: "90"
    ......
    
# è§‚å¯Ÿæ¯”ä¾‹å˜åŒ–
[root@ubuntu2204 ~] # while true; do curl www.mystical.org; sleep 1; done
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!

# æ¸…ç†
[root@master1 project-caray] # kubectl delete -f canary-by-weight.yaml 
ingress.networking.k8s.io "pod-test-canary-by-weight" deleted
```



##### èŒƒä¾‹ï¼šåŸºäºCookieå®ç°é‡‘ä¸é›€å‘å¸ƒ

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 project-caray] # cat canary-by-cookie.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-by-cookie: "vip_user"  # cookieä¸­vip_user=alwaysæ—¶æ‰ç”¨é‡‘ä¸é›€å‘å¸ƒä¸‹é¢æ–°ç‰ˆæœ¬
  name: pod-test-canary-by-cookie
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test-v2
            port:
              number: 80
        path: /
        pathType: Prefix

# åº”ç”¨
[root@master1 project-caray] # kubectl apply -f canary-by-cookie.yaml 
ingress.networking.k8s.io/pod-test-canary-by-cookie created

# å¤–éƒ¨æ­£å¸¸è®¿é—®
[root@ubuntu2204 ~] # while true; do curl www.mystical.org; sleep 1; done
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!

# å°†Cookieä¸Šé¢æ·»åŠ ï¼švip_user=alwaysï¼Œæµ‹è¯•æˆåŠŸ
[root@ubuntu2204 ~]#while true; do curl -b "vip_user=always" www.mystical.org; sleep 1; done
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!

# æ¸…ç†

```



##### èŒƒä¾‹ï¼šåŸºäºè¯·æ±‚Headerå›ºå®šå€¼çš„é‡‘ä¸é›€å‘å¸ƒ

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 project-caray ]# cat canary-by-header.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-by-header: "X-Canary" # X-Canaryé¦–éƒ¨å­—æ®µå€¼ä¸ºalwaysæ—¶æ‰ä½¿ç”¨é‡‘ä¸é›€å‘å¸ƒä¸‹é¢æ–°ç‰ˆæœ¬,å¦åˆ™ä¸ºæ—§ç‰ˆæœ¬
  name: pod-test-canary-by-header
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test-v2
            port:
              number: 80
        path: /
        pathType: Prefix
        
# åº”ç”¨
[root@master1 project-caray] # kubectl apply -f canary-by-header.yaml 
ingress.networking.k8s.io/pod-test-canary-by-header created

# æµ‹è¯•
[root@ubuntu2204 ~]#while true; do curl www.mystical.org; sleep 1; done
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!
kubernetes pod-test v0.1!! ClientIP: 10.244.3.178, ServerName: pod-test-v1-5b856c4b5b-g9ltz, ServerIP: 10.244.1.173!

# æ·»åŠ headerï¼Œå®ç°ç‰ˆæœ¬åˆ‡æ¢
[root@ubuntu2204 ~]#while true; do curl -H "X-Canary: always" www.mystical.org; sleep 1; done
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!

# æ¸…ç†

```



##### èŒƒä¾‹: åŸºäºè¯·æ±‚ Header ç²¾ç¡®åŒ¹é…æŒ‡å®šå€¼çš„é‡‘ä¸é›€å‘å¸ƒ

```yaml
# æ¸…å•
[root@master1 project-caray] # cat canary-by-header-value.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-by-header: "IsVIP"
    nginx.ingress.kubernetes.io/canary-by-header-value: "true" #IsVIPé¦–éƒ¨å­—æ®µçš„å€¼ä¸ºtrueå°±ä½¿ç”¨é‡‘ä¸é›€å‘å¸ƒä¸‹é¢æ–°ç‰ˆæœ¬,å¦åˆ™ä¸ºæ—§ç‰ˆæœ¬
  name: pod-test-canary-by-header-value
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test-v2
            port: 
              number: 80
        path: /
        pathType: Prefix


# åº”ç”¨
[root@master1 project-caray] # kubectl apply -f canary-by-header-value.yaml 
ingress.networking.k8s.io/pod-test-canary-by-header-value created

# æµ‹è¯•
[root@ubuntu2204 ~] # while true; do curl -H "IsVIP: true" www.mystical.org; sleep 1; done
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!

# æ¸…ç†
[root@master1 project-caray] # kubectl delete -f canary-by-header-value.yaml 
ingress.networking.k8s.io "pod-test-canary-by-header-value" deleted
```



##### èŒƒä¾‹ï¼šåŸºäºè¯·æ±‚ Header æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼åŒ¹é…çš„æŒ‡å®šå€¼çš„é‡‘ä¸é›€å‘å¸ƒ

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 project-caray] # cat canary-by-header-pattern.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-by-header: "username"
    nginx.ingress.kubernetes.io/canary-by-header-pattern: "(vip|VIP)_.*" #é¦–éƒ¨å­—æ®µçš„å€¼ä¸ºusernameä¸”æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ—¶ä½¿ç”¨æ–°ç‰ˆï¼Œå¦åˆ™ä½¿ç”¨æ—§ç‰ˆ
  name: pod-test-canary-by-header-pattern
spec:
  ingressClassName: nginx
  rules:
  - host: www.mystical.org
    http:
      paths:
      - backend:
          service:
            name: pod-test-v2
            port: 
              number: 80
        path: /
        pathType: Prefix

# åº”ç”¨
[root@master1 project-caray] # kubectl apply -f canary-by-header-pattern.yaml 
ingress.networking.k8s.io/pod-test-canary-by-header-pattern created

# é›†ç¾¤å¤–å®¢æˆ·ç«¯è®¿é—®
[root@ubuntu2204 ~]#while true; do curl -H "username: vip_user" www.mystical.org; sleep 1; done
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!

# æ¢ä¸ªusernameçš„å€¼ï¼Œå¯ä»¥åŒ¹é…æ­£åˆ™ï¼Œå› æ­¤ä»æ˜¯æ–°ç‰ˆ
[root@ubuntu2204 ~]#while true; do curl -H "username: VIP_man" www.mystical.org; sleep 1; done
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!
kubernetes pod-test v0.2!! ClientIP: 10.244.3.178, ServerName: pod-test-v2-54df7d7958-c427f, ServerIP: 10.244.3.186!

# æ¸…ç†
[root@master1 project-caray] # kubectl delete -f canary-by-header-pattern.yaml 
ingress.networking.k8s.io "pod-test-canary-by-header-pattern" deleted
```



**Ingress çš„ä¸è¶³ä¹‹å¤„**

- Ingressåªèƒ½æ ¹æ® **Host** å’Œ **Path** æ¥å¯¹ HTTP/HTTPS è¿›è¡Œè·¯ç”±ï¼Œä½†æ— æ³•æ ¹æ® **Query Parameter** æ¥è·¯ç”±è¯·æ±‚
- Ingress åªèƒ½ç”¨åˆ°äº† **Host è¯·æ±‚å¤´**ï¼Œæ— æ³•å¯¹å…¶ä»– **Request / Reponse å¤´**è¿›è¡Œ **å¢åŠ  / åˆ é™¤ / ä¿®æ”¹** åŠ¨ä½œ 
- Ingress **å¯¹äºä¸€ä¸ªPath**ï¼Œ**ä¸æ”¯æŒå¤šä¸ªServiceä½œä¸ºBackend**ï¼Œåšä¸åˆ°å¤šç‰ˆæœ¬çš„Service
- Ingress ä¸èƒ½æ”¯æŒè·¨åç§°ç©ºé—´çš„Serviceåç«¯
- ä¸æ”¯æŒL4 å’Œ é HTTP/HTTPS ä¸šåŠ¡æµé‡ï¼ˆå¦‚gRPCï¼‰



## Kubernetes Gateway API

 ä¸ºäº†å…‹æœIngressçš„ä¸è¶³ä¹‹å¤„ï¼ŒKubernetesæå‡ºæ¥Gateway API

å®ç°äº†Gateway APIçš„å¼€æºKubernetesç”Ÿæ€è½¯ä»¶æ˜¯ **Istio**



### Gateway API ä»‹ç»

**å®˜æ–¹ç½‘ç«™**

```http
https://gateway-api.sigs.k8s.io/
```

![image-20250320135332678](../markdown_img/image-20250320135332678.png)



å¦‚ä¸Šå›¾ï¼šGateway API æŠŠäººå‘˜è§’è‰²åˆ†ä¸º3ç±»

1. **Infrastructure Provider**ï¼šåŸºç¡€è®¾æ–½æä¾›è€…ï¼Œä¸»è¦è´Ÿè´£GatewayClassï¼ŒæŠŠGateway Controller å’Œ Gateway å…³è”èµ·æ¥ï¼Œè´Ÿè´£æ•´ä¸ªåº•å±‚è®¾æ–½çš„æä¾›ï¼Œç»™Gateway æä¾› gatewayClassName
2. **Cluster Operator**ï¼šé›†ç¾¤æ“ä½œè€…ï¼Œä¸»è¦è´Ÿè´£ Gatewayï¼Œ**ç±»ä¼¼åå‘ä»£ç†çš„å‰ç«¯**
3. **Application Develops**ï¼šåº”ç”¨å¼€å‘è€…ï¼Œè´Ÿè´£å¼€å‘ä¸šåŠ¡ Serviceï¼Œ**ç±»ä¼¼åå‘ä»£ç†çš„åç«¯**



### Gateway API æµé‡åˆ†å‘æµç¨‹

#### A Simple Gateway

![image-20250320141009871](../markdown_img/image-20250320141009871.png)

**1ï¸âƒ£ å®¢æˆ·ç«¯è¯·æ±‚**

å®¢æˆ·ç«¯ï¼ˆä¾‹å¦‚æµè§ˆå™¨æˆ– API è°ƒç”¨ï¼‰å‘æŸä¸ªåŸŸåæˆ– IP å‘èµ· HTTP/S è¯·æ±‚ã€‚

**2ï¸âƒ£ è´Ÿè½½å‡è¡¡ï¼ˆGatewayï¼‰**

**Gateway** ç»„ä»¶å……å½“äº†æ•´ä¸ªç³»ç»Ÿçš„å…¥å£ï¼Œé€šå¸¸å¯¹åº”ä¸€ä¸ª **Load Balancer**ï¼ˆè´Ÿè½½å‡è¡¡å™¨ï¼‰æˆ–è€… Kubernetes å†…éƒ¨çš„ `Gateway` èµ„æºã€‚

- Gateway çš„ä½œç”¨
  - ç›‘å¬å¤–éƒ¨è¯·æ±‚ï¼ˆé€šå¸¸æ˜¯ HTTP æˆ– HTTPSï¼‰
  - å°†åŒ¹é…çš„æµé‡è½¬å‘ç»™é€‚å½“çš„ **HTTPRoute**
  - å¯ç»‘å®šå¤šä¸ª `HTTPRoute` èµ„æºï¼Œå¤„ç†ä¸åŒè·¯å¾„çš„æµé‡

**Gateway é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: foo-gateway
  namespace: default
spec:
  gatewayClassName: nginx
  listeners:
    - protocol: HTTP
      port: 80
      name: http
      allowedRoutes:
        namespaces:
          from: All	
```

- **gatewayClassName: nginx** â†’ è¯´æ˜ä½¿ç”¨ Nginx Gateway Controller å¤„ç†æµé‡

- **listeners.port: 80** â†’ ç›‘å¬ HTTP 80 ç«¯å£

- **allowedRoutes** â†’ å…è®¸æ‰€æœ‰å‘½åç©ºé—´çš„ `HTTPRoute` å…³è”è¯¥ `Gateway`

**3ï¸âƒ£ è·¯ç”±åŒ¹é…ï¼ˆHTTPRouteï¼‰**

**HTTPRoute** è´Ÿè´£å®šä¹‰æµé‡çš„è½¬å‘è§„åˆ™ï¼Œä¾‹å¦‚ï¼š

- **è·¯å¾„åŒ¹é…ï¼ˆPath Matchingï¼‰**
- **ä¸»æœºåŒ¹é…ï¼ˆHost Matchingï¼‰**
- **æµé‡æƒé‡ï¼ˆTraffic Splittingï¼‰**

**HTTPRoute é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: foo-route
  namespace: default
spec:
  parentRefs:
    - name: foo-gateway  # ç»‘å®š Gateway
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: "/"  # åŒ¹é…æ‰€æœ‰æµé‡
      backendRefs:
        - name: foo-svc  # æŒ‡å®š Service
          port: 80
```

- **`parentRefs: foo-gateway`** â†’ è¯´æ˜è¯¥ HTTPRoute ç»‘å®šåˆ° `foo-gateway`
- **`matches: path: "/"`** â†’ è¯´æ˜åŒ¹é…æ‰€æœ‰è¯·æ±‚è·¯å¾„
- **`backendRefs: foo-svc`** â†’ æŒ‡å®šæµé‡è½¬å‘åˆ° `foo-svc` Service

**4ï¸âƒ£ Service å‘ç°**

Gateway å‘ç° `foo-svc` Serviceï¼Œå¹¶å°†æµé‡è½¬å‘ç»™è¯¥ Serviceã€‚

- Service çš„ä½œç”¨
  - è´Ÿè´£è´Ÿè½½å‡è¡¡ï¼Œå°†è¯·æ±‚è½¬å‘ç»™ Pod
  - é€šè¿‡ `selector` é€‰æ‹©åŒ¹é…çš„ Pod

**Service é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: foo-svc
  namespace: default
spec:
  selector:
    app: foo
  ports:
    - port: 80
      targetPort: 8080  # è½¬å‘åˆ° Pod çš„ 8080 ç«¯å£
```

- **selector: app=foo** â†’ é€‰æ‹©æ ‡ç­¾ä¸º `app=foo` çš„ Pod
- **port: 80 â†’ targetPort: 8080** â†’ Service ç›‘å¬ 80 ç«¯å£ï¼Œä½†å®é™…è½¬å‘ç»™ Pod çš„ 8080 ç«¯å£

**5ï¸âƒ£ è¿›å…¥ Pod**

æœ€ç»ˆï¼Œæµé‡ä¼šè¢«è·¯ç”±åˆ° **ç¬¦åˆ `app=foo` é€‰æ‹©å™¨çš„ Pod**ï¼ŒPod ä¸Šçš„åº”ç”¨ç¨‹åºå¤„ç†è¯·æ±‚å¹¶è¿”å›å“åº”ã€‚

```ABAP
æ³¨æ„ï¼šå’ŒIngressç›¸åŒï¼Œä» Gateway API æ¥æ”¶è¯·æ±‚ä¼šç›´æ¥å‘å¾€åç«¯ Podï¼ŒServiceåœ¨è¿™é‡Œç”¨ä½œæœåŠ¡å‘ç°
```



### Gateway å£°æ˜å¼å®ç°

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: prod-web
spec:
  gatewayClassName: example    # ä½¿ç”¨çš„GatewayClassæ˜¯ä»€ä¹ˆ
  listeners:
  - protocol: HTTP
    port: 80
    name: prod-web-gw
    allowedRoutes:
      namespaces:
        from: Same        # è¿™é‡Œè¡¨æ˜Gatewayå¯ä»¥è·¨åç§°ç©ºé—´è·¯ç”±ï¼Œä½†æ˜¯Ingressä¸è¡Œ
```



### HTTPRoute å£°æ˜å¼å®ç°

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: foo
spec:
  parentRefs:
  - name: prod-web          # å…³è”æŒ‡å®šçš„Gatewayçš„Name
  rules:
  - backendRefs:
    - name: foo-svc
      port: 8080
```



#### HTTPRoute å®˜æ–¹ç¤ºä¾‹

![image-20250320144558874](D:\git_repository\cyber_security_learning\markdown_img\image-20250320144558874.png)

##### åˆ›å»º Gateway èµ„æº

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: example-gateway
spec:
  gatewayClassName: example-gateway-class
  listeners:
  - name: http
    protocol: HTTP
    port: 80
    
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: foo-route
spec:
  parentRefs:
  - name: example-gateway
  hostnames:
  - "foo.example.com"
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /login
    backendRefs:
    - name: foo-svc
      port: 8080
      
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: bar-route
spec:
  parentRefs:
  - name: example-gateway
  hostnames:
  - "bar.example.com"
  rules:
  - matches:
    - headers:
      - type: Exact
        name: env
        value: canary
    backendRefs:
    - name: bar-svc-canary
      port: 8080
  - backendRefs:
    - name: bar-svc
      port: 8080
```



#### HTTP redirects and rewrites ( é‡å®šå‘ä¸é‡å†™ )

##### HTTP redirects Http -> Https

é‡å®šå‘ä¼šå°† HTTP 3XX å“åº”è¿”å›ç»™å®¢æˆ·ç«¯ï¼ŒæŒ‡ç¤ºå…¶æ£€ç´¢å…¶ä»–èµ„æºã€‚RequestRedirect è§„åˆ™è¿‡æ»¤å™¨æŒ‡ç¤ºç½‘å…³å¯¹ä¸å·²è¿‡æ»¤ HTTPRoute è§„åˆ™åŒ¹é…çš„è¯·æ±‚å‘å‡ºé‡å®šå‘å“åº”ã€‚

é‡å®šå‘è¿‡æ»¤å™¨å¯ä»¥ç‹¬ç«‹æ›¿æ¢å„ç§ URL ç»„ä»¶ã€‚ä¾‹å¦‚ï¼Œè¦å‘å‡ºä» HTTP åˆ° HTTPS çš„æ°¸ä¹…é‡å®šå‘ (301)ï¼Œè¯·é…ç½®`requestRedirect.statusCode=301` å’Œ  `requestRedirect.scheme="https"`ï¼š

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: http-filter-redirect
spec:
  parentRefs:
  - name: redirect-gateway
    sectionName: http                    # è¿™é‡Œè¦åŒ¹é…Gatewayèµ„æºçš„listeners.name
  hostnames:
  - redirect.example
  rules:
  - filters:                             # ä½¿ç”¨è¿‡æ»¤å™¨é‡å®šå‘
    - type: RequestRedirect              # ç±»å‹ï¼šè¯·æ±‚é‡å®šå‘
      requestRedirect:
        scheme: https                    # é‡å®šå‘åˆ°https
        statusCode: 301                  # æŒ‡å®šé‡å®šå‘çŠ¶æ€ç 
```

å› ä¸ºä¸Šé¢çš„ç¤ºä¾‹æ˜¯ä» http é‡å®šå‘åˆ° httpsï¼Œæ‰€ä»¥ Gateway è‚¯å®šè¦ç›‘å¬ httpsï¼Œä¸‹é¢æ˜¯ Gateway çš„ç¤ºä¾‹

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: redirect-gateway
spec:
  gatewayClassName: foo-lb
  listeners:
  - name: http
    protocol: HTTP
    port: 80
  - name: https
    protocol: HTTPS
    port: 443
    tls:
      mode: Terminate
      certificateRefs:
      - name: redirect-example
```

###### tls.modeè¯¦è§£

åœ¨ **Gateway API** çš„ `HTTPRoute` æˆ– `Gateway` é…ç½®ä¸­ï¼Œ`tls.mode` å†³å®šäº† **TLS ç»ˆç»“æ–¹å¼**ï¼Œå³å¦‚ä½•å¤„ç† HTTPS æµé‡ã€‚

**ğŸ”¹ `tls.mode` å¯é€‰å€¼**

| **å€¼**        | **å«ä¹‰**                                                     |
| ------------- | ------------------------------------------------------------ |
| `Terminate`   | **ç»ˆç»“ TLSï¼ˆTLS Terminationï¼‰**ï¼šGateway ç»ˆç»“ TLS è¿æ¥å¹¶å°†æµé‡è§£å¯†åè½¬å‘ç»™åç«¯ï¼ˆåç«¯ä½¿ç”¨ HTTPï¼‰ |
| `Passthrough` | **é€ä¼  TLSï¼ˆTLS Passthroughï¼‰**ï¼šGateway ä¸ç»ˆç»“ TLSï¼Œç›´æ¥å°†åŠ å¯†æµé‡è½¬å‘ç»™åç«¯ï¼ˆåç«¯å¤„ç† TLS è¯ä¹¦ï¼‰ |
| `Mutual`      | **åŒå‘ TLSï¼ˆmTLSï¼ŒMutual TLSï¼‰**ï¼šé™¤äº†ç»ˆç»“ TLS å¤–ï¼Œè¿˜è¦æ±‚å®¢æˆ·ç«¯æä¾›è¯ä¹¦è¿›è¡ŒåŒå‘è®¤è¯ |

**ç¤ºä¾‹ï¼šTLS ç»ˆç»“ï¼ˆTLS Terminationï¼‰**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: example-gateway
  namespace: default
spec:
  gatewayClassName: nginx
  listeners:
    - protocol: HTTPS
      port: 443
      name: https
      tls:
        mode: Terminate  # åœ¨ Gateway ç»ˆç»“ TLS
        certificateRefs:
          - name: example-tls-secret  # è¿™é‡Œæ˜¯ Kubernetes Secret åç§°
  addresses:
    - type: IPAddress
      value: 192.168.1.100
```

 **è§£é‡Š**

- **`tls.mode: Terminate`** â†’ è¯´æ˜ **TLS ç”± Gateway å¤„ç†**
- **`certificateRefs.name: example-tls-secret`** â†’ è¿™ä¸ª `example-tls-secret` å¿…é¡»æ˜¯ä¸€ä¸ªåŒ…å«è¯ä¹¦çš„ Kubernetes Secret
- **åç«¯ Pod åªéœ€è¦å¤„ç† HTTPï¼ˆä¸éœ€è¦ TLSï¼‰**



**ç¤ºä¾‹ï¼šTLS é€ä¼ ï¼ˆTLS Passthroughï¼‰**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: example-gateway
  namespace: default
spec:
  gatewayClassName: nginx
  listeners:
    - protocol: HTTPS
      port: 443
      name: passthrough-https
      tls:
        mode: Passthrough  # ç›´æ¥å°†åŠ å¯†æµé‡ä¼ é€’ç»™åç«¯
```

**è§£é‡Š**

- **`tls.mode: Passthrough`** â†’ è¯´æ˜ **Gateway ä¸å¤„ç† TLSï¼ŒåŠ å¯†æµé‡ç›´æ¥ä¼ ç»™åç«¯**
- **åç«¯ Service éœ€è¦ç›‘å¬ 443 ç«¯å£ï¼Œå¹¶è‡ªå·±å¤„ç† TLS**



**ç¤ºä¾‹ï¼šmTLSï¼ˆåŒå‘è®¤è¯ï¼‰**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: example-gateway
  namespace: default
spec:
  gatewayClassName: nginx
  listeners:
    - protocol: HTTPS
      port: 443
      name: mutual-tls
      tls:
        mode: Mutual  # å¯ç”¨åŒå‘ TLS
        certificateRefs:
          - name: example-tls-secret  # æœåŠ¡å™¨è¯ä¹¦
        options:
          clientCA: "ca-secret"  # å®¢æˆ·ç«¯ CA è¯ä¹¦ï¼Œç”¨äºéªŒè¯å®¢æˆ·ç«¯è¯ä¹¦
```

**è§£é‡Š**

- **`tls.mode: Mutual`** â†’ Gateway éœ€è¦éªŒè¯å®¢æˆ·ç«¯è¯ä¹¦
- **`certificateRefs.name: example-tls-secret`** â†’ æœåŠ¡å™¨ç«¯ TLS è¯ä¹¦
- **`options.clientCA: ca-secret`** â†’ å®¢æˆ·ç«¯ CA è¯ä¹¦ï¼ˆç”¨äºéªŒè¯å®¢æˆ·ç«¯ï¼‰



###### è¡¥å……ï¼šaddresseså­—æ®µè¯¦è§£

**å®Œæ•´ç¤ºä¾‹**

```bash
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: example-gateway
  namespace: default
spec:
  gatewayClassName: nginx
  listeners:
    - protocol: HTTPS
      port: 443
      name: https
      tls:
        mode: Terminate               # åœ¨ Gateway ç»ˆç»“ TLS
        certificateRefs:
          - name: example-tls-secret  # è¿™é‡Œæ˜¯ Kubernetes Secret åç§°
  addresses:                          # å®¢æˆ·ç«¯è®¿é—® 192.168.1.100 æ—¶ï¼Œæµé‡ä¼šè¿›å…¥ Gateway
    - type: IPAddress                 # æŒ‡å®š Gateway ç»‘å®šä¸€ä¸ªé™æ€ IPï¼ˆ192.168.1.100ï¼‰
      value: 192.168.1.100            # å…·ä½“çš„ IP åœ°å€
```

åœ¨ Gateway API çš„ `Gateway` èµ„æºä¸­ï¼Œ`addresses` ç”¨äºæŒ‡å®š **Gateway ç»‘å®šçš„ç½‘ç»œåœ°å€**ï¼Œå³ç›‘å¬æµé‡çš„ IP åœ°å€æˆ–å…¶ä»–ç½‘ç»œç«¯ç‚¹ã€‚

**`addresses.type` å¯é€‰å€¼**

Gateway API æ”¯æŒå¤šç§ `type`ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

| **å€¼**         | **ä½œç”¨**                                                     |
| -------------- | ------------------------------------------------------------ |
| `IPAddress`    | æŒ‡å®š Gateway ç»‘å®šçš„ **é™æ€ IP**ï¼ˆé€‚ç”¨äº MetalLB æˆ–äº‘æä¾›å•†çš„é™æ€ IPï¼‰ |
| `NamedAddress` | ç»‘å®šä¸€ä¸ª **äº‘æœåŠ¡æä¾›å•†çš„ IP åç§°**ï¼ˆå¦‚ AWS Elastic IPï¼ŒGCP Cloud Load Balancerï¼‰ |
| `Hostname`     | ç»‘å®šåˆ° **ä¸»æœºå**ï¼ˆå¦‚ `example.com`ï¼Œç”¨äº DNS è§£æï¼‰         |
| `Service`      | ç»‘å®šåˆ° **æŸä¸ª Kubernetes Service**ï¼ˆä¸€èˆ¬ç”¨äº LoadBalancer ç±»å‹çš„ Serviceï¼‰ |

**ç¤ºä¾‹ 1ï¼šä½¿ç”¨ `IPAddress` ç»‘å®šé™æ€ IP**

é€‚ç”¨äº **è£¸æœºç¯å¢ƒ**ï¼ˆMetalLB æˆ–æ‰‹åŠ¨åˆ†é… IPï¼‰ã€‚

```yaml
addresses:
  - type: IPAddress
    value: 192.168.1.100
```

**æµé‡ä¼šé€šè¿‡ 192.168.1.100 è¿›å…¥ Gateway**ã€‚



**ç¤ºä¾‹ 2ï¼šä½¿ç”¨ `NamedAddress` ç»‘å®šäº‘è´Ÿè½½å‡è¡¡ IP**

é€‚ç”¨äº **äº‘ç¯å¢ƒï¼ˆAWS/GCP/AlibabaCloudï¼‰**ã€‚

```yaml
addresses:
  - type: NamedAddress
    value: my-cloud-lb-ip  # ç»‘å®šäº‘æä¾›å•†çš„è´Ÿè½½å‡è¡¡ IP åç§°
```

è¿™é‡Œçš„ **`my-cloud-lb-ip`** ç”±äº‘æä¾›å•†ï¼ˆå¦‚ AWS Elastic IPï¼‰ç®¡ç†ã€‚



**ç¤ºä¾‹ 3ï¼šä½¿ç”¨ `Hostname` ç»‘å®š DNS åç§°**

é€‚ç”¨äº **æ‰˜ç®¡ç¯å¢ƒ**ï¼ˆCloudflareã€Cloud Load Balancerï¼‰

```yaml
addresses:
  - type: Hostname
    value: gateway.example.com
```

è¿™ä¸ª **`gateway.example.com`** å¿…é¡»åœ¨ DNS è§£æåˆ° Gateway çš„ IPã€‚



**ç¤ºä¾‹ 4ï¼šä½¿ç”¨ `Service` ç»‘å®š Kubernetes Service**

é€‚ç”¨äº **Kubernetes Service è´Ÿè½½å‡è¡¡**ã€‚

```yaml
addresses:
  - type: Service
    value: my-gateway-service  # Gateway ç»‘å®šåˆ° Service
```

**æµé‡ä¼šé€šè¿‡ `my-gateway-service` è¿›å…¥ Gateway**ã€‚



**ä»€ä¹ˆæ—¶å€™ç”¨ä»€ä¹ˆç±»å‹ï¼Ÿ**

| **åœºæ™¯**                   | **æ¨è `type`** | **è¯´æ˜**                |
| -------------------------- | --------------- | ----------------------- |
| **è£¸æœºé›†ç¾¤ï¼ˆMetalLBï¼‰**    | `IPAddress`     | ç»‘å®šæœ¬åœ° IP             |
| **äº‘ç¯å¢ƒï¼ˆAWS/GCPï¼‰**      | `NamedAddress`  | ç»‘å®šäº‘æä¾›å•†çš„ IP åç§°  |
| **DNS å…¥å£ï¼ˆCloudflareï¼‰** | `Hostname`      | ç»‘å®šåŸŸå                |
| **å†…éƒ¨ Service è´Ÿè½½å‡è¡¡**  | `Service`       | ç»‘å®š Kubernetes Service |



##### Path redirects

è·¯å¾„é‡å®šå‘ä½¿ç”¨ HTTP è·¯å¾„ä¿®é¥°ç¬¦æ¥æ›¿æ¢æ•´ä¸ªè·¯å¾„æˆ–è·¯å¾„å‰ç¼€ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„ HTTPRoute å°†å‘æ‰€æœ‰ä»¥ /cayenne å¼€å¤´çš„ `redirect.example` è¯·æ±‚å‘å‡º 302 é‡å®šå‘åˆ° `/paprika`ï¼š

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: http-filter-redirect
spec:
  hostnames:
    - redirect.example
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /cayenne
      filters:
        - type: RequestRedirect
          requestRedirect:
            path:
              type: ReplaceFullPath             # ReplaceFullPath ä¼šå®Œå…¨æ›¿æ¢è·¯å¾„ï¼Œè€Œä¸æ˜¯ä¿ç•™åç¼€è·¯å¾„
              replaceFullPath: /paprika
            statusCode: 302
```

```ABAP
å¦‚æœå®¢æˆ·ç«¯è¯·æ±‚ redirect.example/cayenneï¼Œå®ƒä¼š 302 é‡å®šå‘ åˆ° redirect.example/paprikaï¼Œè¿™ä¸ªæ˜¯ æ­£ç¡®çš„ âœ…ã€‚
```

**ä¸¾ä¾‹éªŒè¯**

| **åŸè¯·æ±‚**                               | **æ˜¯å¦åŒ¹é… `/cayenne` è§„åˆ™ï¼Ÿ** | **æœ€ç»ˆé‡å®šå‘ URL**         |
| ---------------------------------------- | ------------------------------ | -------------------------- |
| `redirect.example/cayenne`               | âœ… **åŒ¹é…**                     | `redirect.example/paprika` |
| `redirect.example/cayenne/`              | âœ… **åŒ¹é…**                     | `redirect.example/paprika` |
| `redirect.example/cayenne/a/a.txt`       | âœ… **åŒ¹é…**                     | `redirect.example/paprika` |
| `redirect.example/cayenne/a.txt`         | âœ… **åŒ¹é…**                     | `redirect.example/paprika` |
| `redirect.example/cayenne/anything/else` | âœ… **åŒ¹é…**                     | `redirect.example/paprika` |

**æ— è®º `/cayenne` åé¢æ˜¯ä»€ä¹ˆï¼Œéƒ½ä¼šè¢«é‡å®šå‘åˆ° `/paprika`ï¼Œä¸ä¼šä¿ç•™åç¼€è·¯å¾„** ğŸš¨ã€‚



###### `requestRedirect.path.type` çš„å¯é€‰å€¼åŠå…¶å«ä¹‰

åœ¨ `HTTPRoute` èµ„æºä¸­ï¼Œ`requestRedirect.path.type` ç”¨äºæŒ‡å®š **å¦‚ä½•ä¿®æ”¹è·¯å¾„**ï¼Œå®ƒæœ‰ä»¥ä¸‹ **ä¸‰ç§å¯é€‰å€¼**ï¼š

| **å¯é€‰å€¼**           | **å«ä¹‰**                                                     | **ç¤ºä¾‹**                                                     |
| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| `ReplaceFullPath`    | **å®Œæ•´æ›¿æ¢è·¯å¾„**ï¼Œæ— è®ºåŸå§‹è·¯å¾„å¦‚ä½•ï¼Œéƒ½ä¼šè¢«æ›¿æ¢æˆå›ºå®šå€¼       | `/old/path` â†’ `/new/path`                                    |
| `ReplacePrefixMatch` | **æ›¿æ¢å‰ç¼€**ï¼Œä»…æ›¿æ¢åŒ¹é…çš„è·¯å¾„å‰ç¼€ï¼Œä¿ç•™åç¼€éƒ¨åˆ†             | `/old/path/foo` â†’ `/new/path/foo`                            |
| `ReplacePathMatch`   | **ä»…æ›¿æ¢åŒ¹é…éƒ¨åˆ†çš„è·¯å¾„**ï¼Œå¦‚æœåŒ¹é…çš„è·¯å¾„å®Œå…¨ç›¸åŒï¼Œåˆ™æ›¿æ¢ï¼Œå¦åˆ™ä¸å˜ | `/old/path` â†’ `/new/path` ï¼ˆä½† `/old/path/foo` **ä¸ä¼šæ”¹å˜**ï¼‰ |



**`ReplaceFullPath` â€”â€” å®Œå…¨æ›¿æ¢è·¯å¾„**

- **ä½œç”¨**ï¼šæ‰€æœ‰åŒ¹é…åˆ°çš„è¯·æ±‚è·¯å¾„éƒ½ä¼šè¢«å®Œå…¨æ›¿æ¢æˆæ–°çš„è·¯å¾„ï¼Œä¸ç®¡åŸè·¯å¾„åé¢æœ‰æ²¡æœ‰å­è·¯å¾„
- **é€‚ç”¨åœºæ™¯**ï¼š
  - ä½ å¸Œæœ›æ‰€æœ‰åŒ¹é…åˆ°çš„è·¯å¾„éƒ½è·³è½¬åˆ°ä¸€ä¸ª **å›ºå®šçš„ URL**ã€‚
  - ä¾‹å¦‚ï¼š`/cayenne` åŠå…¶æ‰€æœ‰å­è·¯å¾„éƒ½é‡å®šå‘åˆ° `/paprika`ã€‚

**ç¤ºä¾‹**

```yaml
filters:
  - type: RequestRedirect
    requestRedirect:
      path:
        type: ReplaceFullPath
        replaceFullPath: /paprika
      statusCode: 302
```

**ç»“æœ**

| **åŸè¯·æ±‚ URL**     | **æœ€ç»ˆé‡å®šå‘ URL** |
| ------------------ | ------------------ |
| `/cayenne`         | `/paprika`         |
| `/cayenne/foo`     | `/paprika`         |
| `/cayenne/bar/baz` | `/paprika`         |
| `/cayenne/a.txt`   | `/paprika`         |

ğŸ“Œ **æ— è®º `/cayenne` åé¢æ˜¯ä»€ä¹ˆï¼Œéƒ½ä¼šå˜æˆ `/paprika`**ï¼Œåç¼€ä¸ä¼šä¿ç•™ ğŸš¨ã€‚



**`ReplacePrefixMatch` â€”â€” ä»…æ›¿æ¢è·¯å¾„å‰ç¼€**

- **ä½œç”¨**ï¼š**åªæ›¿æ¢åŒ¹é…çš„è·¯å¾„å‰ç¼€ï¼Œä¿ç•™åç¼€éƒ¨åˆ†**ã€‚
- **é€‚ç”¨åœºæ™¯**ï¼š
  - ä½ å¸Œæœ› `/old/path/foo` å˜æˆ `/new/path/foo`ï¼Œè€Œä¸æ˜¯ `/new/path`ã€‚
  - ä¾‹å¦‚ï¼šæŠŠ `/cayenne/xxx` å˜æˆ `/paprika/xxx`ï¼Œä½† `/cayenne` ä»ç„¶å˜æˆ `/paprika`ã€‚

**ç¤ºä¾‹**

```yaml
filters:
  - type: RequestRedirect
    requestRedirect:
      path:
        type: ReplacePrefixMatch
        replacePrefixMatch: /paprika
      statusCode: 302
```

 **ç»“æœ**

| **åŸè¯·æ±‚ URL**     | **æœ€ç»ˆé‡å®šå‘ URL** |
| ------------------ | ------------------ |
| `/cayenne`         | `/paprika`         |
| `/cayenne/foo`     | `/paprika/foo`     |
| `/cayenne/bar/baz` | `/paprika/bar/baz` |
| `/cayenne/a.txt`   | `/paprika/a.txt`   |

ğŸ“Œ **è·¯å¾„åç¼€å¾—åˆ°äº†ä¿ç•™ï¼** âœ…



**`ReplacePathMatch` â€”â€” ä»…æ›¿æ¢å®Œå…¨åŒ¹é…çš„è·¯å¾„**

**ä½œç”¨**ï¼šå¦‚æœè·¯å¾„ **å®Œå…¨åŒ¹é…** è®¾å®šçš„å€¼ï¼Œå°±æ›¿æ¢ï¼Œå¦åˆ™ä¸åšæ”¹å˜ã€‚

**é€‚ç”¨åœºæ™¯**ï¼š

- ä½ åªæƒ³æ›¿æ¢ç‰¹å®šçš„è·¯å¾„ï¼Œè€Œä¸å½±å“å­è·¯å¾„ã€‚
- ä¾‹å¦‚ï¼š`/cayenne` å˜æˆ `/paprika`ï¼Œä½† `/cayenne/foo` **ä¸ä¼šæ”¹å˜**ã€‚

```yaml
filters:
  - type: RequestRedirect
    requestRedirect:
      path:
        type: ReplacePathMatch
        replacePathMatch: /paprika
      statusCode: 302
```

**ç»“æœ**

| **åŸè¯·æ±‚ URL**     | **æœ€ç»ˆé‡å®šå‘ URL** |
| ------------------ | ------------------ |
| `/cayenne`         | `/paprika`         |
| `/cayenne/foo`     | `/cayenne/foo`     |
| `/cayenne/bar/baz` | `/cayenne/bar/baz` |
| `/cayenne/a.txt`   | `/cayenne/a.txt`   |

ğŸ“Œ **åªæœ‰ `/cayenne` è¢«é‡å®šå‘ï¼Œå­è·¯å¾„å®Œå…¨ä¸å˜ï¼** ğŸš€



##### HTTP Rewrite

é‡å†™ä¼šåœ¨å°†å®¢æˆ·ç«¯è¯·æ±‚ä»£ç†åˆ°ä¸Šæ¸¸ä¹‹å‰ä¿®æ”¹å…¶ç»„ä»¶ã€‚URLRewrite è¿‡æ»¤å™¨å¯ä»¥æ›´æ”¹ä¸Šæ¸¸è¯·æ±‚çš„**ä¸»æœºå**å’Œ/**è·¯å¾„**ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹ HTTPRoute å°†æ¥å— `https://rewrite.example/cardamom` çš„è¯·æ±‚ï¼Œå¹¶å°†å…¶ä¸Šæ¸¸å‘é€åˆ° `example-svc`ï¼Œè¯·æ±‚æ ‡å¤´ä¸­çš„ `host: else.example` è€Œä¸æ˜¯ `host: rewrite.example`ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: http-filter-rewrite
spec:
  hostnames:
    - rewrite.example
  rules:
    - filters:
        - type: URLRewrite
          urlRewrite:
            hostname: elsewhere.example
      backendRefs:
        - name: example-svc
          weight: 1                            # æƒé‡
          port: 80
```

è·¯å¾„é‡å†™ä¹Ÿä½¿ç”¨ HTTP è·¯å¾„ä¿®é¥°ç¬¦ã€‚ä¸‹é¢çš„ HTTPRoute å°†æ¥å—` https://rewrite.example/cardamom/smidgen` çš„è¯·æ±‚ï¼Œå¹¶å°†å¯¹ `https://elsewhere.example/fennel` çš„è¯·æ±‚ä»£ç†åˆ° example-svc ä¸Šæ¸¸ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: http-filter-rewrite
spec:
  hostnames:
    - rewrite.example
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /cardamom
      filters:
        - type: URLRewrite
          urlRewrite:
            hostname: elsewhere.example
            path:
              type: ReplaceFullPath
              replaceFullPath: /fennel
      backendRefs:
        - name: example-svc
          weight: 1
          port: 80
```



#### HTTP traffic splitting åˆ†æµ

HTTPRoute èµ„æºå…è®¸æ‚¨æŒ‡å®šæƒé‡ä»¥åœ¨ä¸åŒçš„åç«¯ä¹‹é—´è½¬ç§»æµé‡ã€‚è¿™å¯¹äºåœ¨æ¨å‡ºã€é‡‘ä¸é›€å˜æ›´æˆ–ç´§æ€¥æƒ…å†µä¸‹åˆ†å‰²æµé‡éå¸¸æœ‰ç”¨ã€‚

`HTTPRoutespec.rules.backendRefs` æ¥å—è·¯ç”±è§„åˆ™å°†å‘å…¶å‘é€æµé‡çš„åç«¯åˆ—è¡¨ã€‚è¿™äº›åç«¯çš„ç›¸å¯¹æƒé‡å®šä¹‰äº†å®ƒä»¬ä¹‹é—´çš„æµé‡åˆ†å‰²ã€‚ä»¥ä¸‹ YAML ä»£ç ç‰‡æ®µæ˜¾ç¤ºäº†å¦‚ä½•å°†ä¸¤ä¸ªæœåŠ¡åˆ—ä¸ºå•ä¸ªè·¯ç”±è§„åˆ™çš„åç«¯ã€‚æ­¤è·¯ç”±è§„åˆ™å°†æµé‡çš„ 90% åˆ†å‰²åˆ° foo-v1ï¼Œ10% åˆ†å‰²åˆ° foo-v2ã€‚

![image-20250320161221624](../markdown_img/image-20250320161221624.png)

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: simple-split
spec:
  rules:
  - backendRefs:
    - name: foo-v1
      port: 8080
      weight: 90
    - name: foo-v2
      port: 8080
      weight: 10
```



##### é™åˆ¶ Gateway èƒ½å¤Ÿå¤„ç†çš„ HTTPRoute è§„åˆ™æ¥æº

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: prod-web
spec:
  gatewayClassName: example
  listeners:
  - protocol: HTTP
    port: 80
    name: prod-web-gw
    allowedRoutes:            # ç”¨äºé™åˆ¶ Gateway èƒ½å¤Ÿå¤„ç†çš„ HTTPRoute è§„åˆ™æ¥æº
      namespaces:
        from: Same
```



##### åŸºäº http å¤´éƒ¨å­—æ®µè¿›è¡Œåˆ†æµ

![image-20250320162612677](../markdown_img/image-20250320162612677.png)

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: foo-route
  labels:
    gateway: prod-web-gw
spec:
  hostnames:
  - foo.example.com
  rules:
  - backendRefs:
    - name: foo-v1
      port: 8080
  - matches:
    - headers:
      - name: traffic
        value: test
    backendRefs:
    - name: foo-v2
      port: 8080
```





#### Cross-Namespace routing ä¸åŒåç§°ç©ºé—´ä¹‹é—´çš„è·¯ç”± 

**Gateway -> Route**ï¼šå¯¹åç§°ç©ºé—´æ²¡æœ‰é™åˆ¶ï¼ˆé™¤é **`allowedRoutes` é™åˆ¶**ï¼‰ã€‚

**Route -> Backend:** å¯¹åç§°ç©ºé—´æœ‰é™åˆ¶ï¼Œé»˜è®¤éœ€è¦å†åŒä¸€ä¸ªåç§°ç©ºé—´

![image-20250320170107687](../markdown_img/image-20250320170107687.png)



##### è¡¥å……ï¼š`allowedRoutes.namespaces.from` å­—æ®µçš„å¯é€‰å€¼

`allowedRoutes.namespaces.from` å­—æ®µç”¨äºæ§åˆ¶ **å“ªäº› Namespace çš„ `HTTPRoute` å¯ä»¥ç»‘å®šåˆ° `Gateway`**ã€‚

å®ƒæœ‰ä»¥ä¸‹å¯é€‰å€¼ï¼š

1. **`Same`**ï¼ˆä»…å…è®¸ç›¸åŒ Namespaceï¼‰
2. **`Selector`**ï¼ˆå…è®¸ç‰¹å®š Label é€‰æ‹©çš„ Namespaceï¼‰
3. **`All`**ï¼ˆå…è®¸æ‰€æœ‰ Namespaceï¼‰



###### `Same`ï¼ˆä»…å…è®¸ç›¸åŒ Namespaceï¼‰

**å«ä¹‰ï¼š**

- åªå…è®¸å’Œ `Gateway` **ç›¸åŒ Namespace** çš„ `HTTPRoute` ç»‘å®šã€‚
- **å…¶ä»– Namespace ä¸èƒ½** ç»‘å®šè¿™ä¸ª `Gateway`ã€‚

**ğŸ”¹ é€‚ç”¨åœºæ™¯ï¼š**

- **å•ç§Ÿæˆ·ç¯å¢ƒ**ï¼Œåªå…è®¸å½“å‰ Namespace çš„æœåŠ¡ä½¿ç”¨è¯¥ `Gateway`ã€‚

**ğŸ”¹ é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: web-gateway
  namespace: web
spec:
  gatewayClassName: example
  listeners:
    - protocol: HTTP
      port: 80
      name: web-gateway-listener
  allowedRoutes:
    namespaces:
      from: Same  # âœ… åªå…è®¸ web Namespace ä¸‹çš„ HTTPRoute ç»‘å®š
```

â¡ï¸ `web` Namespace ä¸‹çš„ `HTTPRoute` å¯ä»¥ç»‘å®šï¼Œä½† `default`ã€`app` Namespace ä¸èƒ½ä½¿ç”¨ã€‚



###### `Selector`ï¼ˆå…è®¸ç‰¹å®š Namespaceï¼‰

**å«ä¹‰ï¼š**

- å…è®¸ **ç‰¹å®š Label é€‰æ‹©çš„ Namespace** ç»‘å®š `Gateway`ã€‚
- é€‚ç”¨äº**éƒ¨åˆ†å…±äº« Gateway** çš„åœºæ™¯ã€‚

**ğŸ”¹ é€‚ç”¨åœºæ™¯ï¼š**

- **å¤šç§Ÿæˆ·ç¯å¢ƒ**ï¼Œä¸åŒå›¢é˜Ÿçš„ `Namespace` éœ€è¦å…±äº«åŒä¸€ä¸ª `Gateway`ã€‚

**ğŸ”¹ é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: shared-gateway
  namespace: infra
spec:
  gatewayClassName: example
  listeners:
    - protocol: HTTP
      port: 80
      name: shared-listener
  allowedRoutes:
    namespaces:
      from: Selector  # âœ… å…è®¸ç‰¹å®š Label çš„ Namespace ç»‘å®š
      selector:
        matchLabels:
          team: frontend  # âœ… åªæœ‰å¸¦ team=frontend Label çš„ Namespace æ‰èƒ½ç»‘å®š
```

`web` å’Œ `app` Namespace éœ€è¦æ·»åŠ  Label æ‰èƒ½ä½¿ç”¨

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: web
  labels:
    team: frontend  # âœ… å…è®¸ç»‘å®š Gateway
---
apiVersion: v1
kind: Namespace
metadata:
  name: app
  labels:
    team: frontend  # âœ… å…è®¸ç»‘å®š Gateway
```

**â¡ï¸ åªæœ‰ `web` å’Œ `app` Namespace èƒ½ç»‘å®šè¿™ä¸ª `Gateway`ï¼Œå…¶ä»–ä¸å¸¦ `team=frontend` çš„ä¸èƒ½ç”¨ã€‚**



###### `All`ï¼ˆå…è®¸æ‰€æœ‰ Namespaceï¼‰

**å«ä¹‰ï¼š**

- **ä»»ä½• Namespace** çš„ `HTTPRoute` éƒ½å¯ä»¥ç»‘å®šè¿™ä¸ª `Gateway`ã€‚
- **é»˜è®¤å€¼**ï¼Œå¦‚æœ `allowedRoutes` å­—æ®µçœç•¥ï¼Œåˆ™é»˜è®¤ `All`ã€‚

**ğŸ”¹ é€‚ç”¨åœºæ™¯ï¼š**

- **å…¨å±€å…±äº« Gateway**ï¼Œå…è®¸æ•´ä¸ªé›†ç¾¤çš„ `HTTPRoute` ä½¿ç”¨ã€‚

**ğŸ”¹ é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: global-gateway
  namespace: infra
spec:
  gatewayClassName: example
  listeners:
    - protocol: HTTP
      port: 80
      name: global-listener
  allowedRoutes:
    namespaces:
      from: All  # âœ… å…è®¸æ‰€æœ‰ Namespace
```

**â¡ï¸ `default`ã€`web`ã€`app`ã€`test` ç­‰ Namespace çš„ `HTTPRoute` \**éƒ½å¯ä»¥\** ç»‘å®šè¿™ä¸ª `Gateway`ã€‚**



**æ€»ç»“**

| `from` é€‰é¡¹  | è¯´æ˜                                         | é€‚ç”¨åœºæ™¯         |
| ------------ | -------------------------------------------- | ---------------- |
| **Same**     | ä»…å…è®¸**ç›¸åŒ Namespace** çš„ `HTTPRoute` ç»‘å®š | å•ç§Ÿæˆ·ï¼Œä¸¥æ ¼éš”ç¦» |
| **Selector** | å…è®¸å¸¦**ç‰¹å®š Label** çš„ `Namespace` ç»‘å®š     | å¤šç§Ÿæˆ·ï¼Œéƒ¨åˆ†å…±äº« |
| **All**      | å…è®¸æ‰€æœ‰ `Namespace` ç»‘å®š**ï¼ˆé»˜è®¤å€¼ï¼‰**      | å…¨å±€å…±äº« Gateway |



##### è¡¥å……ï¼šHTTPRoute èµ„æºä¸­ï¼ŒHTTPRoute å’Œ Backendæ˜¯å¦å¿…é¡»åœ¨åŒä¸€åç§°ç©ºé—´

åœ¨ `HTTPRoute` ä¸­ï¼Œ`backendRefs` é»˜è®¤æŒ‡å‘ **ä¸ `HTTPRoute` å¤„äºåŒä¸€ `Namespace`** çš„ `Service`ã€‚

###### é»˜è®¤è¡Œä¸º

å¦‚æœ `backendRefs` æ²¡æœ‰æŒ‡å®š `namespace`ï¼Œå®ƒé»˜è®¤æŒ‡å‘ **`HTTPRoute` æ‰€åœ¨çš„ Namespace`** çš„ `Service`

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: https-route
  namespace: app-ns   # âœ… HTTPRoute åœ¨ app-ns Namespace ä¸‹
spec:
  parentRefs:
  - name: redirect-gateway
    sectionName: https
  hostnames:
  - redirect.example
  rules:
  - backendRefs:
    - name: example-svc  # âœ… é»˜è®¤ app-ns/example-svc
      port: 80
```

â¡ `example-svc` é»˜è®¤ä¼šåœ¨ `app-ns` Namespace é‡ŒæŸ¥æ‰¾ï¼



###### å¦‚æœ `backendRefs` æŒ‡å®šäº† `namespace`

å¯ä»¥æ˜¾å¼æŒ‡å®š `Service` çš„ `namespace`ï¼Œå…è®¸ `HTTPRoute` è®¿é—®å…¶ä»– Namespace ä¸‹çš„ `Service`ï¼ˆ**ä½† `Gateway` éœ€è¦å…è®¸è·¨ Namespace ç»‘å®š**ï¼‰

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: https-route
  namespace: app-ns
spec:
  parentRefs:
  - name: redirect-gateway
    sectionName: https
  hostnames:
  - redirect.example
  rules:
  - backendRefs:
    - name: example-svc
      namespace: backend-ns  # âœ… æ˜ç¡®æŒ‡å®š backend-ns Namespace çš„ Service
      port: 80
```

**â¡ è¿™é‡Œ `HTTPRoute` åœ¨ `app-ns`ï¼Œä½†å®ƒçš„ `backendRefs` ç»‘å®šäº† `backend-ns` ä¸‹çš„ `Service`ï¼**



**å…³é”®ç‚¹**

| **å­—æ®µ**                       | **é»˜è®¤è¡Œä¸º**                                         | **å¯ä»¥æ”¹å—ï¼Ÿ**                                          |
| ------------------------------ | ---------------------------------------------------- | ------------------------------------------------------- |
| `backendRefs.name`             | åªæŸ¥æ‰¾ **`HTTPRoute` åŒå `Namespace`** çš„ `Service` | âœ… å¯ä»¥æŒ‡å®š `namespace`                                  |
| `backendRefs.namespace`        | **é»˜è®¤ä¸è·¨ Namespace**                               | âœ… å¯ä»¥æ‰‹åŠ¨æŒ‡å®š                                          |
| `Gateway` æ˜¯å¦å…è®¸è·¨ Namespace | **é»˜è®¤åªå…è®¸ Same `Namespace`**                      | âœ… éœ€è¦ `allowedRoutes.namespaces.from: All æˆ– Selector` |



##### Route Attachment

ç”±äºè·¯ç”±å’Œ Gateway åœ¨ä¸åŒåç§°ç©ºé—´ï¼Œæ‰€ä»¥åœ¨ parentRefs ä¸­è¦æŒ‡å®š Gateway çš„åç§°ç©ºé—´

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: store
  namespace: store-ns
spec:
  parentRefs:
  - name: shared-gateway
    namespace: infra-ns            # å› ä¸ºGatewayå’ŒHTTPRouteä¸åœ¨åŒä¸€åç§°ç©ºé—´ï¼Œå› æ­¤è¿™é‡Œéœ€è¦æŒ‡å®šå…³è”çš„Gatewayçš„åç§°ç©ºé—´
  rules:
  - matches:
    - path:
        value: /store
    backendRefs:
    - name: store
      port: 8080
```



#### HTTP è¯·æ±‚å¤´éƒ¨å­—æ®µä¿®æ”¹

HTTP æ ‡å¤´ä¿®æ”¹æ˜¯åœ¨ä¼ å…¥è¯·æ±‚ä¸­æ·»åŠ ã€åˆ é™¤æˆ–ä¿®æ”¹ HTTP å¤´éƒ¨å­—æ®µçš„è¿‡ç¨‹ã€‚

è¦é…ç½® HTTP æ ‡å¤´ä¿®æ”¹ï¼Œè¯·ä½¿ç”¨ä¸€ä¸ªæˆ–å¤šä¸ª HTTP è¿‡æ»¤å™¨å®šä¹‰ Gateway å¯¹è±¡ã€‚æ¯ä¸ªè¿‡æ»¤å™¨æŒ‡å®šå¯¹ä¼ å…¥è¯·æ±‚è¿›è¡Œçš„ç‰¹å®šä¿®æ”¹ï¼Œä¾‹å¦‚æ·»åŠ è‡ªå®šä¹‰æ ‡å¤´æˆ–ä¿®æ”¹ç°æœ‰æ ‡å¤´ã€‚

è¦å‘ HTTP è¯·æ±‚æ·»åŠ æ ‡å¤´ï¼Œè¯·ä½¿ç”¨ RequestHeaderModifier ç±»å‹çš„è¿‡æ»¤å™¨ï¼Œå¹¶å¸¦æœ‰æ·»åŠ æ“ä½œä»¥åŠæ ‡å¤´çš„åç§°å’Œå€¼ï¼š

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: header-http-echo
spec:
  parentRefs:
    - name: acme-gw
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /add-a-request-header
      filters:
        - type: RequestHeaderModifier
          requestHeaderModifier:
            add:
              - name: my-header-name
                value: my-header-value
      backendRefs:
        - name: echo
          port: 8080
```

è¦ç¼–è¾‘ç°æœ‰æ ‡é¢˜ï¼Œè¯·ä½¿ç”¨è®¾ç½®æ“ä½œå¹¶æŒ‡å®šè¦ä¿®æ”¹çš„æ ‡é¢˜çš„å€¼å’Œè¦è®¾ç½®çš„æ–°æ ‡é¢˜å€¼ã€‚

```yaml
filters:
    - type: RequestHeaderModifier
      requestHeaderModifier:
        set:
          - name: my-header-name
            value: my-new-header-value
```

Headers can also be removed, by using the `remove` keyword and a list of header names.

```yaml
 filters:
    - type: RequestHeaderModifier
      requestHeaderModifier:
        remove: ["x-request-id"]
```



#### HTTP å“åº”å¤´éƒ¨å­—æ®µä¿®æ”¹

å°±åƒç¼–è¾‘è¯·æ±‚æ ‡å¤´å¾ˆæœ‰ç”¨ä¸€æ ·ï¼Œå“åº”æ ‡å¤´ä¹Ÿå¾ˆæœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œå®ƒå…è®¸å›¢é˜Ÿä»…ä¸ºæŸä¸ªåç«¯æ·»åŠ /åˆ é™¤ cookieï¼Œè¿™æœ‰åŠ©äºè¯†åˆ«ä¹‹å‰é‡å®šå‘åˆ°è¯¥åç«¯çš„æŸäº›ç”¨æˆ·ã€‚

å¦ä¸€ä¸ªæ½œåœ¨çš„ç”¨ä¾‹æ˜¯ï¼Œå½“ä½ çš„å‰ç«¯éœ€è¦çŸ¥é“å®ƒæ­£åœ¨ä¸åç«¯æœåŠ¡å™¨çš„ç¨³å®šç‰ˆæœ¬è¿˜æ˜¯æµ‹è¯•ç‰ˆæœ¬å¯¹è¯æ—¶ï¼Œä»¥ä¾¿å‘ˆç°ä¸åŒçš„ UI æˆ–ç›¸åº”åœ°è°ƒæ•´å…¶å“åº”è§£æ

ä¿®æ”¹ HTTP æ ‡å¤´å“åº”åˆ©ç”¨ä¸ä¿®æ”¹åŸå§‹è¯·æ±‚éå¸¸ç›¸ä¼¼çš„è¯­æ³•ï¼Œå°½ç®¡ä½¿ç”¨äº†ä¸åŒçš„è¿‡æ»¤å™¨ï¼ˆResponseHeaderModifierï¼‰ã€‚

å¯ä»¥æ·»åŠ ã€ç¼–è¾‘å’Œåˆ é™¤æ ‡é¢˜ã€‚å¯ä»¥æ·»åŠ å¤šä¸ªæ ‡é¢˜ï¼Œå¦‚ä¸‹ä¾‹æ‰€ç¤ºï¼š

```yaml
  filters:
    - type: ResponseHeaderModifier
      responseHeaderModifier:
        add:
        - name: X-Header-Add-1
          value: header-add-1
        - name: X-Header-Add-2
          value: header-add-2
        - name: X-Header-Add-3
          value: header-add-3
```





### TCP routing

Gateway API æ—¨åœ¨ä¸å¤šç§åè®®é…åˆä½¿ç”¨ï¼Œè€Œ TCPRoute å°±æ˜¯è¿™æ ·ä¸€ç§è·¯ç”±ï¼Œå®ƒå…è®¸ç®¡ç† TCP æµé‡ã€‚

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ª Gateway èµ„æºå’Œä¸¤ä¸ª TCPRoute èµ„æºï¼Œå®ƒä»¬æŒ‰ç…§ä»¥ä¸‹è§„åˆ™åˆ†é…æµé‡ï¼š

- Gateway ç«¯å£ 8080 ä¸Šçš„æ‰€æœ‰ TCP æµéƒ½è½¬å‘åˆ° my-foo-service Kubernetes æœåŠ¡çš„ç«¯å£ 6000ã€‚
- Gateway ç«¯å£ 8090 ä¸Šçš„æ‰€æœ‰ TCP æµéƒ½è½¬å‘åˆ° my-bar-service Kubernetes æœåŠ¡çš„ç«¯å£ 6000ã€‚

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œå°†å‘ Gateway åº”ç”¨ä¸¤ä¸ª TCP ä¾¦å¬å™¨ï¼Œä»¥ä¾¿å°†å®ƒä»¬è·¯ç”±åˆ°ä¸¤ä¸ªå•ç‹¬çš„åç«¯ TCPRouteï¼Œè¯·æ³¨æ„ï¼ŒGateway ä¸Šä¾¦å¬å™¨çš„åè®®è®¾ç½®ä¸º TCPï¼š

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: my-tcp-gateway
spec:
  gatewayClassName: my-tcp-gateway-class
  listeners:
  - name: foo
    protocol: TCP
    port: 8080
    allowedRoutes:
      kinds:
      - kind: TCPRoute
  - name: bar
    protocol: TCP
    port: 8090
    allowedRoutes:
      kinds:
      - kind: TCPRoute
---
apiVersion: gateway.networking.k8s.io/v1alpha2
kind: TCPRoute
metadata:
  name: tcp-app-1
spec:
  parentRefs:
  - name: my-tcp-gateway
    sectionName: foo
  rules:
  - backendRefs:
    - name: my-foo-service
      port: 6000
---
apiVersion: gateway.networking.k8s.io/v1alpha2
kind: TCPRoute
metadata:
  name: tcp-app-2
spec:
  parentRefs:
  - name: my-tcp-gateway
    sectionName: bar
  rules:
  - backendRefs:
    - name: my-bar-service
      port: 6000
```



#### `allowedRoutes.kinds.kind` å¯é€‰å€¼åŠä½¿ç”¨åœºæ™¯

åœ¨ `Gateway` èµ„æºä¸­ï¼Œ`allowedRoutes.kinds.kind` ç”¨äº **å®šä¹‰ `Gateway` èƒ½æ¥å—çš„è·¯ç”±ç±»å‹**ï¼Œç¡®ä¿ `Gateway` åªèƒ½ç»‘å®šç‰¹å®šç±»å‹çš„ `Route`ï¼ˆå¦‚ `HTTPRoute`ã€`TCPRoute`ã€`TLSRoute` ç­‰ï¼‰ã€‚

```ABAP
é»˜è®¤ allowedRoutes.kinds å…è®¸æ‰€æœ‰ç±»å‹ï¼Œä½†ä¸ºäº†å®‰å…¨æ€§ï¼Œå»ºè®® æ˜¾å¼æŒ‡å®š å…è®¸çš„ Route ç±»å‹ã€‚
```

**âœ… å¯é€‰å€¼**

| **å€¼ (`kind`)** | **ä½œç”¨**                        | **é€‚ç”¨åœºæ™¯**                                 |
| --------------- | ------------------------------- | -------------------------------------------- |
| `HTTPRoute`     | å…è®¸ `Gateway` ç»‘å®š `HTTPRoute` | Web åº”ç”¨ã€API æœåŠ¡                           |
| `TCPRoute`      | å…è®¸ `Gateway` ç»‘å®š `TCPRoute`  | çº¯ TCP æµé‡ï¼Œå¦‚æ•°æ®åº“è¿æ¥ã€MQTT              |
| `TLSRoute`      | å…è®¸ `Gateway` ç»‘å®š `TLSRoute`  | éœ€è¦ L4 TLS é€ä¼ çš„åœºæ™¯ï¼Œå¦‚ `TLS Passthrough` |
| `GRPCRoute`     | å…è®¸ `Gateway` ç»‘å®š `GRPCRoute` | gRPC æœåŠ¡ï¼Œå¦‚å¾®æœåŠ¡ RPC                      |
| `UDPRoute`      | å…è®¸ `Gateway` ç»‘å®š `UDPRoute`  | VoIPã€DNS è§£æç­‰ UDP æœåŠ¡                    |



**é…ç½®ç¤ºä¾‹**

ğŸŸ¢ å…è®¸ `Gateway` åªç»‘å®š `HTTPRoute`

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: web-gateway
spec:
  gatewayClassName: nginx
  listeners:
  - protocol: HTTP
    port: 80
    allowedRoutes:
      kinds:
      - kind: HTTPRoute  # âœ… åªå…è®¸ç»‘å®š HTTPRoute
```

**é€‚ç”¨åœºæ™¯**

- åªå…è®¸ HTTP è·¯ç”±æµé‡
- ç”¨äº Web åº”ç”¨/API æœåŠ¡å™¨



ğŸŸ¢ å…è®¸ `Gateway` ç»‘å®š `TCPRoute` å’Œ `TLSRoute`

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: tcp-gateway
spec:
  gatewayClassName: cilium
  listeners:
  - protocol: TLS
    port: 443
    allowedRoutes:
      kinds:
      - kind: TCPRoute  # âœ… å…è®¸ TCP ä»£ç†
      - kind: TLSRoute  # âœ… å…è®¸ TLS ä»£ç†
```

**é€‚ç”¨åœºæ™¯**

- éœ€è¦ä»£ç† TCP è¿æ¥ï¼Œå¦‚æ•°æ®åº“ï¼ˆMySQLã€PostgreSQLï¼‰
- éœ€è¦ TLS Passthroughï¼Œå¦‚é‚®ä»¶æœåŠ¡å™¨ã€VPN



ğŸŸ¢ å…è®¸ `Gateway` ç»‘å®šæ‰€æœ‰ç±»å‹çš„ `Route`

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: multi-protocol-gateway
spec:
  gatewayClassName: istio
  listeners:
  - protocol: HTTP
    port: 80
    allowedRoutes:
      kinds:
      - kind: HTTPRoute
      - kind: TCPRoute
      - kind: TLSRoute
      - kind: GRPCRoute
      - kind: UDPRoute
```

**é€‚ç”¨åœºæ™¯**

- ä¸€ä¸ª `Gateway` å¤„ç†å¤šç§åè®®ï¼Œå¦‚ Web APIã€æ•°æ®åº“ã€VoIP
- é€‚ç”¨äºå¤šåè®®ä»£ç†ï¼ˆå¦‚ Istioï¼‰



### TLSRoute

#### TLSRoute åœ¨ Downstream ç«¯è§£å¯† å’Œ Upstream ç«¯åŠ å¯†è¯¦è§£

###### Downstream ç«¯è§£å¯† (TLS Termination)

**åœºæ™¯**

- **å®¢æˆ·ç«¯ (browser/curl)** ä½¿ç”¨ `HTTPS` è®¿é—® `Gateway`ã€‚
- `Gateway` **è§£å¯†** TLS æµé‡ï¼Œå¹¶å°† **çº¯ HTTP** å‘é€ç»™åç«¯ `Service` è¿›è¡Œå¤„ç†ã€‚
- é€‚ç”¨äº Web æœåŠ¡å™¨ã€API ä»£ç†ç­‰åœºæ™¯ã€‚

**é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: tls-gateway
spec:
  gatewayClassName: istio
  listeners:
    - protocol: HTTPS
      port: 443
      tls:
        mode: Terminate  # âœ… ç»ˆç»“ TLS
        certificateRefs:
          - name: my-tls-secret  # Kubernetes Secretï¼ŒåŒ…å« TLS è¯ä¹¦
```

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: TLSRoute
metadata:
  name: tls-route
spec:
  parentRefs:
    - name: tls-gateway
  rules:
    - backendRefs:
        - name: my-http-service
          port: 80  # â—ï¸å‘é€çº¯ HTTP
```

**æµé‡è·¯å¾„**

1ï¸âƒ£ **å®¢æˆ·ç«¯** å‘èµ· `HTTPS` è¯·æ±‚ â†’ `curl https://example.com`
2ï¸âƒ£ **`Gateway` ç»ˆç»“ TLS**ï¼Œä½¿ç”¨ `my-tls-secret` è§£å¯†æµé‡
3ï¸âƒ£ **æ˜æ–‡ HTTP** è½¬å‘åˆ° `my-http-service:80` å¤„ç†è¯·æ±‚



###### Upstream ç«¯åŠ å¯† (TLS Passthrough / TLS Origination)

`TLSRoute` ä¹Ÿå¯ä»¥ç”¨äº **é€ä¼  TLS** æˆ– **ä¸ºä¸Šæ¸¸é‡æ–°åŠ å¯† TLS**ã€‚

**åœºæ™¯ 1: TLS é€ä¼  (TLS Passthrough)**

- **å®¢æˆ·ç«¯** ç›´æ¥è¿æ¥åç«¯ `Service`ï¼Œ`Gateway` **ä¸è§£å¯† TLS**ï¼Œç›´æ¥è½¬å‘ã€‚
- é€‚ç”¨äº **é‚®ä»¶æœåŠ¡å™¨ (IMAP, SMTP)**ã€**æ•°æ®åº“ (MySQL, PostgreSQL)** ç­‰åº”ç”¨ã€‚

**é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: passthrough-gateway
spec:
  gatewayClassName: istio
  listeners:
    - protocol: TLS
      port: 443
      tls:
        mode: Passthrough  # âœ… é€ä¼  TLS
```

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: TLSRoute
metadata:
  name: tls-passthrough-route
spec:
  parentRefs:
    - name: passthrough-gateway
  rules:
    - backendRefs:
        - name: my-tls-service
          port: 443  # â—ï¸åç«¯ `Service` ç›´æ¥æ¥æ”¶ TLS
```

**æµé‡è·¯å¾„**

1ï¸âƒ£ **å®¢æˆ·ç«¯** `curl https://example.com`
2ï¸âƒ£ **`Gateway` ä¸è§£å¯† TLS**ï¼Œç›´æ¥é€ä¼ æµé‡
3ï¸âƒ£ **åç«¯ `my-tls-service` å¤„ç† TLS**ï¼Œä½¿ç”¨è‡ªå·±é…ç½®çš„è¯ä¹¦è§£å¯†



**åœºæ™¯ 2: TLS é‡æ–°åŠ å¯† (Upstream TLS Origination)**

- `Gateway` **è§£å¯† TLS**ï¼Œä½†åœ¨è½¬å‘ç»™ `Service` æ—¶ **é‡æ–°åŠ å¯† TLS**ã€‚
- é€‚ç”¨äº **å®‰å…¨è¦æ±‚è¾ƒé«˜çš„å¾®æœåŠ¡ç¯å¢ƒ**ï¼Œé¿å…åœ¨é›†ç¾¤å†…ä¼ è¾“æ˜æ–‡æµé‡ã€‚

**é…ç½®ç¤ºä¾‹**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: tls-reencrypt-gateway
spec:
  gatewayClassName: istio
  listeners:
    - protocol: HTTPS
      port: 443
      tls:
        mode: Terminate  # âœ… ç»ˆç»“ TLS
        certificateRefs:
          - name: my-tls-secret
```

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: TLSRoute
metadata:
  name: tls-frontend-route
spec:
  parentRefs:
    - name: tls-reencrypt-gateway
  rules:
    - backendRefs:
        - name: my-secure-service
          port: 443
          tls:
            mode: Simple  # âœ… é‡æ–°åŠ å¯†
            certificateRefs:
              - name: backend-tls-secret
```

**æµé‡è·¯å¾„**

1ï¸âƒ£ **å®¢æˆ·ç«¯** `curl https://example.com`
2ï¸âƒ£ **`Gateway` ç»ˆç»“ TLS**ï¼Œä½¿ç”¨ `my-tls-secret` è§£å¯†
3ï¸âƒ£ **`Gateway` é‡æ–°åŠ å¯† TLS**ï¼Œä½¿ç”¨ `backend-tls-secret` å‘é€ç»™ `my-secure-service`



**`mode` é€‰é¡¹æ€»ç»“**

| **TLS Mode**            | **æè¿°**                             | **é€‚ç”¨åœºæ™¯**       |
| ----------------------- | ------------------------------------ | ------------------ |
| `Terminate`             | `Gateway` ç»ˆç»“ TLSï¼Œè½¬å‘æ˜æ–‡ HTTP    | æ™®é€š HTTPS ç«™ç‚¹    |
| `Passthrough`           | ç›´æ¥é€ä¼  TLSï¼Œ`Service` è‡ªå·±è§£å¯†     | é‚®ä»¶æœåŠ¡å™¨ã€æ•°æ®åº“ |
| `Simple` (Upstream TLS) | `Gateway` å…ˆè§£å¯†ï¼Œç„¶åé‡æ–°åŠ å¯†åè½¬å‘ | å†…éƒ¨å¾®æœåŠ¡å®‰å…¨åŠ å¯† |

```ABAP
Gatewayæ”¯æŒåŒå‘è®¤è¯
```



#### Wildcardï¼ˆé€šé…ç¬¦è¯ä¹¦ï¼‰ TLS Listeners

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: wildcard-tls-gateway
spec:
  gatewayClassName: example
  listeners:
  - name: foo-https
    protocol: HTTPS
    port: 443
    hostname: foo.example.com
    tls:
      certificateRefs:
      - kind: Secret
        group: ""
        name: foo-example-com-cert
  - name: wildcard-https
    protocol: HTTPS
    port: 443
    hostname: "*.example.com"
    tls:
      certificateRefs:
      - kind: Secret
        group: ""
        name: wildcard-example-com-cert
```

**Wildcard è¯ä¹¦çš„é™åˆ¶**

1. âŒ ä¸èƒ½è·¨çº§åˆ«å­åŸŸ

   ```ini
   CN = *.example.com
   ```

   **âœ… æ”¯æŒ**ï¼š`api.example.com`, `blog.example.com`
   **âŒ ä¸æ”¯æŒ**ï¼š`sub.api.example.com`

   - **å¦‚æœéœ€è¦è·¨å±‚çº§é€šé…ç¬¦è¯ä¹¦**ï¼Œå¯ä»¥ä½¿ç”¨ `*.api.example.com`ã€‚

2. **âŒ ä¸èƒ½ç”¨äº `example.com` (è£¸åŸŸ)**
   - è§£å†³æ–¹æ¡ˆï¼š**ç”³è¯·é¢å¤–çš„ `example.com` è¯ä¹¦** æˆ– **ä½¿ç”¨ SAN è¯ä¹¦**ã€‚





#### è·¨å‘½åç©ºé—´å¼•ç”¨è¯ä¹¦

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œç½‘å…³é…ç½®ä¸ºå¼•ç”¨ä¸åŒå‘½åç©ºé—´ä¸­çš„è¯ä¹¦ã€‚è¿™æ˜¯é€šè¿‡åœ¨ç›®æ ‡å‘½åç©ºé—´ä¸­åˆ›å»ºçš„ **ReferenceGrant** å…è®¸çš„ã€‚å¦‚æœæ²¡æœ‰è¯¥ ReferenceGrantï¼Œè·¨å‘½åç©ºé—´å¼•ç”¨å°†æ— æ•ˆã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: cross-namespace-tls-gateway
  namespace: gateway-api-example-ns1
spec:
  gatewayClassName: example
  listeners:
  - name: https
    protocol: HTTPS
    port: 443
    hostname: "*.example.com"
    tls:
      certificateRefs:
      - kind: Secret
        group: ""       # è¿™é‡Œå¯ä»¥çœç•¥ï¼Œå› ä¸ºé»˜è®¤å°±æ˜¯ core group
        name: wildcard-example-com-cert
        namespace: gateway-api-example-ns2
---
apiVersion: gateway.networking.k8s.io/v1beta1
kind: ReferenceGrant             # ReferenceGrant å’Œ Secret åˆ›å»ºåœ¨åŒä¸€åç§°ç©ºé—´
metadata:
  name: allow-ns1-gateways-to-ref-secrets
  namespace: gateway-api-example-ns2
spec:
  from:
  # ä¸Šé¢çš„ReferenceGrantï¼Œä¸æ˜¯é’ˆå¯¹æŸä¸€ä¸ªGatewayæˆæƒï¼Œè€Œæ˜¯é’ˆå¯¹Gatewayæ‰€åœ¨çš„åç§°ç©ºé—´æˆæƒ
  - group: gateway.networking.k8s.io    # éæ ¸å¿ƒ API ç»„ï¼ˆæ¯”å¦‚ Gatewayã€HTTPRouteã€ReferenceGrant ç­‰ï¼‰ï¼Œå¿…é¡»æ˜¾å¼å£°                                           æ˜ groupï¼Œå¦åˆ™è§£æå¤±è´¥ã€‚
    kind: Gateway
    namespace: gateway-api-example-ns1
  to:
  - group: ""     # è¿™é‡Œå¯ä»¥çœç•¥ï¼Œå› ä¸ºé»˜è®¤å°±æ˜¯ core group
    kind: Secret
```



##### è¡¥å……ï¼š`group` å­—æ®µçš„å«ä¹‰

åœ¨ Kubernetes **Gateway API** ä»¥åŠ **ReferenceGrant** èµ„æºä¸­ï¼Œ`group` å­—æ®µç”¨äºæŒ‡å®š Kubernetes API èµ„æºçš„ **API ç»„** (API Group)ï¼Œä¹Ÿå°±æ˜¯è¯¥èµ„æºæ‰€å±çš„ API ç»„ã€‚

Kubernetes èµ„æºçš„ **å®Œæ•´ API ç»„** ç»“æ„é€šå¸¸æ˜¯ï¼š

```php
<kind>.<group>/<version>
```

**ä¾‹å¦‚**ï¼š

- `Gateway` å±äº `gateway.networking.k8s.io/v1`
- `Secret` å±äº `core` API ç»„ï¼ˆ`""` ä»£è¡¨ `core` ç»„ï¼‰
- `ReferenceGrant` å±äº `gateway.networking.k8s.io/v1beta1`



**ä¸Šè¿°é…ç½®ä¸­çš„ `group` çš„è§£é‡Š**

```yaml
tls:
  certificateRefs:
  - kind: Secret
    group: ""
    name: wildcard-example-com-cert
    namespace: gateway-api-example-ns2
```

- **group: `""`**
  - è¿™é‡Œ `""` ä¸ºç©ºï¼Œè¡¨ç¤º **Secret èµ„æº** æ¥è‡ª Kubernetes **Core API ç»„** (`v1`)ã€‚
  - `Secret` å±äº Kubernetes **æ ¸å¿ƒ API**ï¼Œå› æ­¤ **API ç»„ä¸ºç©º** (`""`)ã€‚
  - å®Œæ•´è·¯å¾„ï¼š`Secret.v1` (å³ `core/v1`)

```yaml
spec:
  from:
  - group: gateway.networking.k8s.io
    kind: Gateway
    namespace: gateway-api-example-ns1
```

- **group: `gateway.networking.k8s.io`**
  - è¡¨ç¤º **Gateway èµ„æº**ï¼Œå®ƒå±äº `gateway.networking.k8s.io/v1` API ç»„ã€‚
  - å…è®¸ `gateway-api-example-ns1` ä¸­çš„ **Gateway è®¿é—®** `gateway-api-example-ns2` é‡Œçš„ Secretã€‚

```yaml
  to:
  - group: ""
    kind: Secret
```

- group: `""`
  - è¡¨ç¤ºç›®æ ‡èµ„æºæ˜¯ **Secret**ï¼Œå±äº Kubernetes **æ ¸å¿ƒ API ç»„** (`core/v1`)ã€‚



**å¦‚ä½•ç¡®å®š `group` å€¼**

å¯ä»¥ä½¿ç”¨ `kubectl api-resources` å‘½ä»¤ï¼ŒæŸ¥çœ‹ API ç»„ä¿¡æ¯ï¼š

```bash
kubectl api-resources
```



#### TargetRefs and TLS

`BackendTLSPolicy` æ˜¯ **Kubernetes Gateway API** ä¸­çš„ä¸€ç§æ‰©å±•èµ„æºï¼Œç”¨äºâ€œ**éªŒè¯åç«¯ TLS æœåŠ¡æ˜¯å¦å¯ä¿¡**â€çš„ï¼

```ABAP
å†å¼ºè°ƒä¸€é: BackendTLSPolicy å¹¶ä¸æ˜¯ç”¨äºâ€œå»ºç«‹ TLS é€šä¿¡â€çš„ï¼Œè€Œæ˜¯ç”¨äºâ€œéªŒè¯åç«¯ TLS æœåŠ¡æ˜¯å¦å¯ä¿¡â€çš„ï¼
ä¹Ÿå°±æ˜¯è¯´ï¼šTLSRoute.backendRefs.tls ç®¡â€œæˆ‘æ€ä¹ˆè¿è¿‡å»â€ï¼ŒBackendTLSPolicy ç®¡â€œæˆ‘ä¿¡ä¸ä¿¡ä½ â€ã€‚
```

##### ç¤ºä¾‹ YAML æ‹†è§£è¯´æ˜

```yaml
apiVersion: gateway.networking.k8s.io/v1alpha3
kind: BackendTLSPolicy
metadata:
  name: tls-upstream-dev
spec:
  targetRefs:
    - kind: Service
      name: dev
      group: ""
  validation:
    wellKnownCACertificates: "System"
    hostname: dev.example.com
```

**ä½œç”¨æ¦‚è¿°ï¼š**

é…ç½® Gateway è®¿é—® `Service/dev` æ—¶ï¼Œä½¿ç”¨ **HTTPS** åè®®ï¼Œ**å¹¶ä¿¡ä»»ç³»ç»Ÿæ ¹ CA**ï¼Œ**å¯¹æœåŠ¡ç«¯è¯ä¹¦çš„åŸŸåè¿›è¡Œæ ¡éªŒ**ã€‚



##### å­—æ®µè¯¦ç»†è¯´æ˜

1. **`targetRefs`**

æŒ‡å®šæ­¤ç­–ç•¥è¦åº”ç”¨åœ¨å“ªä¸ª**åç«¯æœåŠ¡ï¼ˆServiceï¼‰**ä¸Šã€‚

```yaml
targetRefs:
  - kind: Service         # åº”ç”¨äºå“ªä¸ªç±»å‹çš„èµ„æºï¼Œå¿…é¡»æ˜¯ Service
    name: dev             # Service çš„åç§°
    group: ""             # group ä¸ºç©ºè¡¨ç¤º core ç»„ï¼ˆæ ‡å‡† Kubernetes èµ„æºï¼‰
```

ğŸ” **ç”¨é€”**ï¼šæŒ‡æ˜æ˜¯å“ªä¸ª Service ä½¿ç”¨ Upstream TLSã€‚



2. **`validation`**

é…ç½® TLS çš„**éªŒè¯è§„åˆ™**ï¼š

```yaml
validation:
  wellKnownCACertificates: "System"
  hostname: dev.example.com
```

**a) `wellKnownCACertificates: "System"`**

- è¡¨ç¤ºä¿¡ä»»ç³»ç»Ÿé»˜è®¤çš„æ ¹è¯ä¹¦ï¼ˆå¦‚ Ubuntu/RHEL ä¸­ `/etc/ssl/certs` ä¸­çš„æ ¹è¯ä¹¦ï¼‰ã€‚

- ç”¨äºéªŒè¯åç«¯æœåŠ¡çš„ TLS è¯ä¹¦æ˜¯åˆæ³•é¢å‘çš„ã€‚

- æ”¯æŒçš„å€¼ï¼ˆå½“å‰é˜¶æ®µï¼‰ï¼š

  | å€¼             | å«ä¹‰                                                         |
  | -------------- | ------------------------------------------------------------ |
  | `"System"`     | ä½¿ç”¨ **Gateway æ‰€åœ¨èŠ‚ç‚¹æ“ä½œç³»ç»Ÿ** çš„é»˜è®¤ CA ä¿¡ä»»åˆ—è¡¨ï¼ˆé€šå¸¸æ˜¯ `/etc/ssl/certs/ca-certificates.crt` æˆ–ç­‰æ•ˆè·¯å¾„ï¼‰ |
  | `null`ï¼ˆä¸å¡«ï¼‰ | ä¸å¯ç”¨é»˜è®¤ä¿¡ä»» CAã€‚ä½ éœ€è¦é€šè¿‡ `caCertRefs` å­—æ®µè‡ªå·±æŒ‡å®šå¯ä¿¡ CA è¯ä¹¦ Secretã€‚ |

â€‹       ä½œç”¨ï¼šç”¨äº**éªŒè¯åç«¯æœåŠ¡è¯ä¹¦æ˜¯å¦è¢«å¯ä¿¡ CA ç­¾å‘**ï¼Œé˜²æ­¢ä¸­é—´äººæ”»å‡»ï¼Œç¡®ä¿ä½ ä¿¡ä»»çš„æœåŠ¡æ‰è¢«é€šä¿¡ã€‚

- ä½¿ç”¨ä½ è‡ªç­¾çš„ CA æ¥æ ¡éªŒåç«¯è¯ä¹¦ï¼š

  ```yaml
  validation:
    caCertRefs:
      - name: my-root-ca
        kind: Secret
        group: ""
    hostname: dev.internal.svc
  ```

**b) `hostname: dev.example.com`**

- è¡¨ç¤ºè¿æ¥æ—¶éœ€è¦æ ¡éªŒåç«¯æœåŠ¡å™¨ TLS è¯ä¹¦ä¸­çš„ **CN/SAN åŸŸå** æ˜¯å¦åŒ¹é… `dev.example.com`ã€‚

- å®ƒä¼šè¢«éªŒè¯åŒ¹é… **è¯ä¹¦çš„ SANï¼ˆSubject Alternative Nameï¼‰å­—æ®µ**ï¼Œå¦‚æœ SAN æ²¡æœ‰è®¾ç½®ï¼Œæ‰ä¼š fallback åˆ°è¯ä¹¦çš„ **Subject çš„ Common Name (CN)** å­—æ®µã€‚

  | ä¼˜å…ˆçº§                              | åŒ¹é…å­—æ®µ |
  | ----------------------------------- | -------- |
  | 1ï¸âƒ£ SAN (Subject Alternative Name)    |          |
  | 2ï¸âƒ£ CN (Common Name) â€“ å·²è¿‡æ—¶ï¼Œä½†å…¼å®¹ |          |

- ä½ åç«¯è¯ä¹¦é•¿è¿™æ ·ï¼ˆç”¨ `openssl x509 -text` æŸ¥çœ‹ï¼‰ï¼š

  ```ruby
  Subject: CN = dev.example.com
  X509v3 Subject Alternative Name:
      DNS:dev.example.com, DNS:*.example.com
  ```

  é‚£ä¹ˆé…ç½®ï¼š

  ```yaml
  validation:
    hostname: dev.example.com
  ```

  æ˜¯ âœ… åŒ¹é…æˆåŠŸçš„ã€‚

- ç±»ä¼¼äº curl ä¸­çš„ `--resolve` æˆ–æµè§ˆå™¨çš„è¯ä¹¦æ ¡éªŒè¡Œä¸ºã€‚

ğŸ“Œ å¦‚æœè¯ä¹¦çš„ SAN å­—æ®µä¸­æ²¡æœ‰è¿™ä¸ªåŸŸåï¼Œä¼šå¯¼è‡´è¿æ¥å¤±è´¥ã€‚





### å®æˆ˜æ¡ˆä¾‹

#### æŠŠ HTTP è¯·æ±‚é‡å®šå‘ä¸º HTTPS

1ï¸âƒ£ **ç”¨RequestRedirect è¿™ä¸ªFilterå®ç°é‡å®šå‘ï¼ŒGateway è¦æœ‰ HTTP å’Œ HTTPS ä¸¤ä¸ªå‰ç«¯Listener**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: redirect-gateway
spec:
  gatewayClassName: foo-lb
  listeners:
  - name: http
    protocol: HTTP
    port: 80
  - name: https
    protocol: HTTPS
    port: 443
    tls:
      mode: Terminate
      certificateRefs:
      - name: redirect-example
```

**2ï¸âƒ£è¯¥ Route æŠŠ HTTP é‡å®šå‘ä¸º HTTPS**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: http-filter-redirect
spec:
  parentRefs:
  - name: redirect-gateway       # Gateway.name
    sectionName: http            # åŒ¹é… Gateway èµ„æºçš„ Listeners.name
  hostnames:
  - redirect.example
  rules:
  - filters:
    - type: RequestRedirect
      requestRedirect
        scheme: https
        statusCode: 301
```

**3ï¸âƒ£ä¸‹ä¸€ä¸ª Route æŠŠ HTTPS è¯·æ±‚è·¯ç”±åˆ°ç›¸åº”çš„ä¸šåŠ¡ Service**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: https-route
  labels:
    gateway: redirect-gateway
spec:
  parentRefs:
  - name: redirect-gateway
    sectionName: https
  hostname:
  - redirect.example
  rules:
  - backendRefs:
    - name: example-svc
      port: 80                # è¿™é‡Œbackendæ²¡æœ‰æŒ‡å®šåç§°ç©ºé—´ï¼Œé»˜è®¤å’Œgatewayåœ¨åŒä¸€ä¸ªåç§°ç©ºé—´
```





#### Gateway åŒå‘ TLS è®¤è¯ (Mutual TLS, mTLS) 

**åœºæ™¯**

- **å®¢æˆ·ç«¯ (Browser, API Consumer)** éœ€è¦ **æä¾›å®¢æˆ·ç«¯è¯ä¹¦** ä»¥è¯æ˜èº«ä»½ã€‚
- **`Gateway` éªŒè¯å®¢æˆ·ç«¯è¯ä¹¦**ï¼Œå¹¶å†³å®šæ˜¯å¦å…è®¸è®¿é—®ã€‚
- **`Gateway` ç»ˆç»“ TLS** å¹¶å°†è¯·æ±‚è½¬å‘ç»™åç«¯ `Service`ã€‚



**å…·ä½“å®ç°**

##### 1ï¸âƒ£ åˆ›å»º CA è¯ä¹¦ & æœåŠ¡å™¨ã€å®¢æˆ·ç«¯è¯ä¹¦

```bash
# ç”Ÿæˆ CA è¯ä¹¦
openssl req -new -x509 -days 365 -keyout ca.key -out ca.crt -subj "/CN=MyCA"

# ç”ŸæˆæœåŠ¡å™¨è¯ä¹¦ (ç”¨äº Gateway)
openssl req -newkey rsa:2048 -nodes -keyout server.key -out server.csr -subj "/CN=gateway.example.com"
openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 365

# ç”Ÿæˆå®¢æˆ·ç«¯è¯ä¹¦ (ç”¨äº API è°ƒç”¨)
openssl req -newkey rsa:2048 -nodes -keyout client.key -out client.csr -subj "/CN=ClientApp"
openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365
```

##### **2ï¸âƒ£ åˆ›å»º Kubernetes Secret**

```bash
# å­˜å‚¨ Gateway æœåŠ¡å™¨ç«¯è¯ä¹¦
kubectl create secret tls gateway-server-tls --cert=server.crt --key=server.key -n default

# å­˜å‚¨ CA è¯ä¹¦ (ç”¨äºéªŒè¯å®¢æˆ·ç«¯)
kubectl create secret generic gateway-ca-secret --from-file=ca.crt=ca.crt -n default
```

##### 3ï¸âƒ£ é…ç½® `Gateway`

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: mtls-gateway
  namespace: default
spec:
  gatewayClassName: istio
  listeners:
    - name: https-mtls
      protocol: HTTPS
      port: 443
      tls:
        mode: Terminate  # âœ… ç»ˆç»“ TLS
        certificateRefs:
          - name: gateway-server-tls  # æœåŠ¡å™¨è¯ä¹¦
        options:
          clientCertificate: Required  # âœ… å¼ºåˆ¶å®¢æˆ·ç«¯æä¾›è¯ä¹¦
          clientCertificateRefs:
            - name: gateway-ca-secret  # âœ… å®¢æˆ·ç«¯è¯ä¹¦ CA
```

**è§£é‡Š**

- `mode: Terminate` â†’ `Gateway` ç»ˆç»“ TLSï¼Œè§£å¯† HTTPS æµé‡ã€‚
- `clientCertificate: Required` â†’ `Gateway` å¼ºåˆ¶è¦æ±‚å®¢æˆ·ç«¯æä¾›è¯ä¹¦ã€‚
- `clientCertificateRefs: gateway-ca-secret` â†’ é€šè¿‡ **CA è¯ä¹¦** éªŒè¯å®¢æˆ·ç«¯èº«ä»½ã€‚



##### 4ï¸âƒ£ é…ç½® `TLSRoute`

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: TLSRoute
metadata:
  name: secure-api
  namespace: default
spec:
  parentRefs:
    - name: mtls-gateway
  rules:
    - backendRefs:
        - name: my-secure-service
          port: 443  # å‘é€åˆ°åç«¯ HTTPS
          tls:
            mode: Simple  # âœ… é‡æ–°åŠ å¯† TLS
            certificateRefs:
              - name: backend-tls-secret  
              
---
apiVersion: gateway.networking.k8s.io/v1alpha3
kind: BackendTLSPolicy
spec:
  targetRefs:
    - kind: Service
      name: my-secure-service
  validation:
    wellKnownCACertificates: "System"
    hostname: my-service.example.com
```

**è§£é‡Š**

- **`Gateway` ç»ˆç»“ TLS**ï¼Œä½†åç«¯ `Service` **ä»ç„¶ä½¿ç”¨ HTTPS**ã€‚
- **`mode: Simple`** â†’ `Gateway` é‡æ–°åŠ å¯† TLSï¼Œå¹¶å‘é€ç»™åç«¯ã€‚
- **ç›®å‰æ”¯æŒçš„ `mode` å€¼ï¼ˆæ¥è‡ªå®˜æ–¹æ–‡æ¡£ï¼‰ï¼š**

  | å€¼            | å«ä¹‰                                                         |
  | ------------- | ------------------------------------------------------------ |
  | `Terminate`   | Gateway ç»ˆæ­¢ TLSï¼Œå‘åç«¯å‘é€æ˜æ–‡ HTTPï¼ˆå¸¸ç”¨äº HTTPS Terminationï¼‰ |
  | `Passthrough` | Gateway ä¸å¤„ç† TLSï¼Œ**åŸæ ·è½¬å‘ TLS æµé‡**ç»™åç«¯              |
  | `Simple`      | Gateway ä¼š **ä¸»åŠ¨é‡æ–°åŠ å¯†**ï¼Œå³ä¸å®¢æˆ·ç«¯å’Œåç«¯éƒ½ç”¨å„è‡ªçš„ TLS é€šä¿¡ |

- å¼•ç”¨çš„ `backend-tls-secret` æ˜¯ä¸€ä¸ª **TLS ç±»å‹çš„ Kubernetes Secret**ï¼Œé‡Œé¢ä¸€èˆ¬åŒ…å«è¿™å‡ ä¸ªå­—æ®µï¼š

  | å­—æ®µ             | å†…å®¹                             | è¯´æ˜                                                        |
  | ---------------- | -------------------------------- | ----------------------------------------------------------- |
  | `tls.crt`        | å®¢æˆ·ç«¯è¯ä¹¦ï¼ˆClient Certificateï¼‰ | Gateway ç”¨æ¥å‘åç«¯ Pod è¯æ˜è‡ªå·±èº«ä»½                         |
  | `tls.key`        | å®¢æˆ·ç«¯è¯ä¹¦å¯¹åº”çš„ç§é’¥             | Gateway åœ¨ä¸åç«¯è¿›è¡Œ TLS æ¡æ‰‹æ—¶ä½¿ç”¨çš„ç§é’¥                   |
  | `ca.crt`ï¼ˆå¯é€‰ï¼‰ | åç«¯çš„æ ¹è¯ä¹¦æˆ–ä¸­é—´è¯ä¹¦           | ç”¨äºéªŒè¯åç«¯ Pod çš„æœåŠ¡ç«¯è¯ä¹¦æ˜¯å¦åˆæ³•ï¼ˆå±äºå•å‘è®¤è¯ä¸€éƒ¨åˆ†ï¼‰ |



##### 5ï¸âƒ£ å®¢æˆ·ç«¯è®¿é—®æµ‹è¯•

```bash
curl -v --key client.key --cert client.crt https://gateway.example.com
```

âœ… å¦‚æœå®¢æˆ·ç«¯è¯ä¹¦æœ‰æ•ˆï¼Œåˆ™ `Gateway` å…è®¸è¯·æ±‚
âŒ å¦‚æœå®¢æˆ·ç«¯æœªæä¾›è¯ä¹¦ï¼Œåˆ™ `403 Forbidden`



**æ€»ç»“**

| **åŠŸèƒ½**                      | **ä½œç”¨**               |
| ----------------------------- | ---------------------- |
| `mode: Terminate`             | `Gateway` ç»ˆç»“ TLS     |
| `clientCertificate: Required` | å¼ºåˆ¶å®¢æˆ·ç«¯æä¾›è¯ä¹¦     |
| `clientCertificateRefs`       | æŒ‡å®šå®¢æˆ·ç«¯è¯ä¹¦ CA      |
| `mode: Simple`                | `Gateway` é‡æ–°åŠ å¯† TLS |

ğŸš€ **è¿™æ ·å°±å®Œæˆäº† Kubernetes Gateway API çš„åŒå‘ TLS è®¤è¯ï¼** ğŸš€





## Kuberneteså®‰å…¨æœºåˆ¶



**æœ¬ç« å†…å®¹**

- **å®‰å…¨ä½“ç³»**
- **è®¤è¯æœºåˆ¶**
- **æˆæƒæœºåˆ¶**
- **å‡†å…¥æœºåˆ¶**





### å®‰å…¨ä½“ç³»



**ç”¨æˆ·è®¿é—®Kubernetesä¸šåŠ¡åº”ç”¨çš„æµç¨‹**

- æ— éœ€api_serverè®¤è¯
  - ç”¨æˆ· --> Service(ingress-nginx) --> ingress(controller) --> service --> pod
- åŸºäºapi_serverè®¤è¯
  - ç®¡ç†Kuberneteså¹³å°ä¸Šå„ç§åº”ç”¨ç°è±¡

å¯¹äºKuberneteså¹³å°æ¥è¯´ï¼Œå‡ ä¹æ‰€æœ‰çš„æ“ä½œåŸºæœ¬ä¸Šéƒ½æ˜¯é€šè¿‡kube apiserverè¿™ä¸ªç»„ä»¶è¿›è¡Œçš„ï¼Œè¯¥ç»„ä»¶æä¾›HTTP RESTfulå½¢å¼çš„APIé›†ç¾¤å†…å¤–å®¢æˆ·ç«¯è°ƒç”¨

å¯¹äºKubernetesé›†ç¾¤çš„éƒ¨ç½²æ ·å¼ä¸»è¦ç”±ä¸¤ç§ï¼šhttpå½¢å¼å’Œhttpså½¢å¼

é‡‡ç”¨Kuberneteséƒ¨ç½²çš„å½¢å¼é»˜è®¤å¯¹å¤–æ˜¯åŸºäºhttpsçš„æ–¹å¼ï¼Œè€Œå†…éƒ¨ç»„ä»¶çš„é€šä¿¡æ˜¯åŸºäºhttpæ–¹å¼

è€ŒKubernetesçš„è®¤è¯æˆæƒæœºåˆ¶ä»…ä»…å­˜åœ¨äºhttpså½¢å¼çš„apiè®¿é—®ä¸­ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœå®¢æˆ·ç«¯ä½¿ç”¨HTTPè¿æ¥åˆ°kube-apiserver,é‚£ä¹ˆæ˜¯ä¸ä¼šè¿›è¡Œè®¤è¯æˆæƒçš„ï¼Œè¿™æ ·å³å¢åŠ äº†å®‰å…¨æ€§ï¼Œä¹Ÿä¸è‡³äºå¤ªå¤æ‚

Kubeletå’Œkubeapiç±»ä¼¼ï¼Œæä¾›ä¸€ä¸ªç®€å•çš„REST APIæœåŠ¡ï¼Œä¹Ÿç›‘å¬ä¸€äº›TCPçš„å¥—æ¥å­—

- 10250ï¼šå…·æœ‰æ‰€æœ‰èŠ‚ç‚¹ä¸ŠPodç®¡ç†æƒé™çš„è¯»å†™ç«¯å£ï¼Œåº”è°¨æ…ç®¡ç†ï¼ŒKubeletç®¡ç†çš„ç«¯å£
- 10255ï¼šä»…æä¾›åªè¯»æ“ä½œï¼Œæ˜¯REST APIçš„å­é›†ï¼Œæ–°ç‰ˆä¸å†ä½¿ç”¨
- 10248ï¼šæ˜¯æœ¬åœ°healthzç«¯ç‚¹ä½¿ç”¨çš„ç«¯å£ï¼ŒKubeletç®¡ç†çš„ç«¯å£

```bash
[root@master1 project-caray]# ss -ntlp|grep kubelet
LISTEN 0      4096       127.0.0.1:10248      0.0.0.0:*    users:(("kubelet",pid=1256,fd=17))       
LISTEN 0      4096               *:10250            *:*    users:(("kubelet",pid=1256,fd=14))  
```



#### å®‰å…¨åŸºæœ¬æµç¨‹

![image-20250106182043977](../markdown_img/image-20250106182043977.png)



- è®¤è¯ Authentication
- æˆæƒ Authorization
- å‡†å…¥æ§åˆ¶ Admission contro



æ­¤å®‰å…¨æœºåˆ¶åœ¨ä¸€å®šç¨‹åº¦ä¸Šæé«˜å®‰å…¨æ€§ï¼Œä¸è¿‡æ›´å¤šæ˜¯èµ„æºç®¡ç†æ–¹é¢çš„ä½œç”¨ã€‚

è®¤è¯,æˆæƒå’Œå‡†å…¥æ§åˆ¶åŠŸèƒ½éƒ½æ˜¯ä»¥**æ’ä»¶åŒ–çš„æ–¹å¼**æ¥å®ç°çš„ï¼Œè¿™æ ·å¯ä»¥æœ€å¤§åŒ–çš„ç”¨æˆ·è‡ªå®šä¹‰çµæ´»æ€§ã€‚



| æ­¥éª¤                 | è§£æ                                                         |
| -------------------- | ------------------------------------------------------------ |
| è®¤è¯(Authn)          | å¯¹ç”¨æˆ·è¿›è¡Œèº«ä»½è®¤è¯ï¼Œåªå…è®¸è¢«è®¸å¯çš„ç”¨æˆ·æ‰èƒ½è¿›å…¥é›†ç¾¤å†…éƒ¨ï¼Œè®¤è¯å¤±è´¥è¿”å› 401ã€‚<br />éµå¾ªâ€œæˆ–â€é€»è¾‘,ä¸”ä»»ä½•ä¸€ä¸ªæ’ä»¶æ ¸éªŒæˆåŠŸåéƒ½å°†ä¸å†è¿›è¡Œåç»­çš„æ’ä»¶éªŒè¯<br />å‰é¢çš„æ’ä»¶æ£€æŸ¥å¤±è´¥,åˆ™æ£€æŸ¥ä¸‹ä¸€ä¸ªæ’ä»¶,å¦‚é‡Œéƒ½ä¸æˆåŠŸ,æ‰å¤±è´¥,æˆ–ä»¥åŒ¿åèº«ä»½è®¿ é—® |
| æˆæƒ(Authz)          | ä¸åŒç”¨æˆ·è·å–ä¸åŒçš„èµ„æºæ“ä½œæƒé™ï¼Œæ¯”å¦‚æ™®é€šç”¨æˆ·ã€è¶…çº§ç”¨æˆ·ç­‰ã€‚æƒé™ä¸è¶³è¿” å›403<br />é‰´æƒè¿‡ç¨‹éµå¾ªâ€œæˆ–â€é€»è¾‘ï¼Œä¸”ä»»ä½•ä¸€ä¸ªæ’ä»¶å¯¹æ“ä½œçš„è®¸å¯æˆæƒåéƒ½å°†ä¸å†è¿›è¡Œå ç»­çš„æ’ä»¶éªŒè¯<br />å¦‚æœéƒ½æœªè®¸å¯,åˆ™æ‹’ç»è¯·æ±‚ |
| å‡†å…¥æ§åˆ¶ (Admission) | ç”¨æˆ·è®¤è¯ã€æˆæƒä¹‹åï¼Œå½“è¿›è¡Œä¸€äº›å†™æ“ä½œçš„æ—¶å€™ï¼Œéœ€è¦éµå¾ªçš„ä¸€äº›é™åˆ¶çš„è¦ æ±‚,æ¯”å¦‚èµ„æºé™åˆ¶<br />å†…å®¹åˆè§„æ€§æ£€æŸ¥ï¼Œéµå¾ªâ€œä¸â€é€»è¾‘ï¼Œä¸”æ— è®ºæˆè´¥ï¼Œæ¯æ¬¡æ“ä½œéƒ½è¦ç»ç”±æ‰€æœ‰æ’ä»¶æ£€ éªŒ,æœ€åç»Ÿä¸€è¿”å›ç»“æœ<br />åªå¯¹å†™æ“ä½œè¿›è¡Œåˆè§„æ€§æ£€æŸ¥ï¼Œåœ¨æˆæƒèŒƒå›´å†…ï¼Œå¯¹ç”¨æˆ·çš„æŸäº›å‘½ä»¤æˆ–è€…æ“ä½œè¿›è¡Œ è¿›ä¸€æ­¥çš„é™åˆ¶<br />åˆ†ä¸ºä¸¤ç±»: validaing æ ¡éªŒ(åˆè§„æ€§,èµ„æºé»˜è®¤å’Œæœ€å¤§å’Œæœ€å°é™åˆ¶)å’Œ mutating å˜ æ›´(è¡¥å…¨,é»˜è®¤å€¼å¡«å……) |



![image-20250106182813464](../markdown_img/image-20250106182813464.png)



### è®¤è¯æœºåˆ¶

ä¸»è¦æ¶‰åŠåˆ°**ç”¨æˆ·å¸å·UA**å’Œ**æœåŠ¡å¸å·SA**çš„è®¤è¯å†…å®¹



#### è®¤è¯æœºåˆ¶è¯´æ˜

æ‰€æœ‰ Kubernetes é›†ç¾¤éƒ½æœ‰**ä¸¤ç±»ç”¨æˆ·**ï¼šç”± Kubernetes ç®¡ç†çš„**æœåŠ¡è´¦å·**å’Œ**æ™®é€šç”¨æˆ·**ã€‚

åœ¨ Kubernetes ä¸­ï¼Œ**subject** æ˜¯æŒ‡ä¸€ä¸ªå¯¹è±¡æˆ–å®ä½“ï¼Œè¯¥å¯¹è±¡æˆ–å®ä½“å¯ä»¥**æ˜¯ç”¨æˆ·ã€æœåŠ¡å¸æˆ·ã€ç»„æˆ–å…¶ä»–å¯è¯†åˆ«çš„å®ä½“**ã€‚å®ƒåœ¨æˆæƒç­–ç•¥ä¸­ç”¨äºæ ‡è¯†å“ªäº›å®ä½“è¢«å…è®¸æˆ–è¢«æ‹’ç»è®¿é—®èµ„æºã€‚ç®€è€Œè¨€ä¹‹ï¼Œ**subject å°±æ˜¯éœ€è¦è¢«æˆæƒè®¿é—®èµ„æºçš„å®ä½“**ã€‚è®¤è¯ç”¨æˆ·å³å±äºSubject



åœ¨Kubernetesé›†ç¾¤ä¸­å®šä¹‰äº†**ä¸¤ç§ç±»å‹çš„subjectèµ„æºçš„è®¤è¯ç”¨æˆ·**ï¼š

| ç”¨æˆ·ç§ç±»        | è§£æ                                                         |
| --------------- | ------------------------------------------------------------ |
| User Account    | ç”¨æˆ·è´¦æˆ·ï¼ŒæŒ‡éPodç±»çš„å®¢æˆ·ç«¯è®¿é—®API Serveræ—¶ä½¿ç”¨çš„èº«ä»½æ ‡è¯†ï¼Œä¸€èˆ¬æ˜¯ç°å®ä¸­çš„ â€œäººâ€<br />API Serveræ²¡æœ‰ä¸ºè¿™ç±»è´¦æˆ·æä¾›ä¿å­˜å…¶ä¿¡æ¯çš„èµ„æºç±»å‹ï¼Œ**ç›¸å…³çš„ä¿¡æ¯é€šå¸¸ä¿å­˜äºå¤–éƒ¨çš„æ–‡ä»¶æˆ–è®¤è¯ç³»ç»Ÿä¸­**,ç”±å¤–éƒ¨ç‹¬ç«‹æœåŠ¡è¿›è¡Œç®¡ç†ï¼Œæ‰€ä»¥ç”¨æˆ·ä¸èƒ½é€šè¿‡é›†ç¾¤å†…éƒ¨çš„ API æ¥ è¿›è¡Œç®¡ç†ã€‚<br />èº«ä»½æ ¸éªŒæ“ä½œå¯ç”±API Serverè¿›è¡Œï¼Œä¹Ÿå¯èƒ½æ˜¯ç”±å¤–éƒ¨èº«ä»½è®¤è¯æœåŠ¡å®Œæˆ ä½œç”¨åŸŸä¸ºæ•´ä¸ªé›†ç¾¤çº§åˆ«,å¸¸è§çš„ç®¡ç†æ–¹å¼ï¼Œå¦‚ï¼š opensslç­‰ |
| Service Account | Service Accountsï¼ˆSAï¼‰åœ¨ Kubernetes ä¸­æ˜¯ä¸€ç§å†…å»ºçš„ã€ä¸ Pod å…³è”çš„è´¦å·ç±»å‹ã€‚ å®ƒä»¬ä¸»è¦æ˜¯ä¸ºäº†åœ¨Podä¸­è¿è¡Œçš„è¿›ç¨‹æä¾›ä¸€ä¸ªèº«ä»½æ ‡è¯†ï¼Œä»¥ä¾¿è®¿é—® Kubernetes API é€šè¿‡Kubernetes API æ¥ç®¡ç†çš„ç”¨æˆ·å¸å·ï¼Œé€‚ç”¨äºé›†ç¾¤ä¸­Podå†…çš„è¿›ç¨‹è®¿é—®API Server æ—¶ä½¿ç”¨çš„èº«ä»½ä¿¡æ¯ï¼Œéœ€è¦é€šè¿‡ API æ¥å®Œæˆæƒé™è®¤è¯<br />API Serverä½¿ç”¨ServiceAccountç±»å‹çš„èµ„æºå¯¹è±¡æ¥ä¿å­˜è¯¥ç±»è´¦å·<br />è®¤è¯åˆ°API Serverçš„è®¤è¯ä¿¡æ¯ç§°ä¸º**Service Account Token**ï¼Œå®ƒä»¬**ä¿å­˜äºåŒåçš„ä¸“ç”¨ç±»å‹çš„Secretå¯¹è±¡ä¸­**<br />åœ¨é›†ç¾¤å†…éƒ¨è¿›è¡Œæƒé™æ“ä½œï¼Œéƒ½éœ€è¦ä½¿ç”¨åˆ° ServiceAccount<br />**namespace åˆ«çº§çš„èµ„æºç±»å‹,å³å¸å·éš¶å±äºåç§°ç©ºé—´,ä½†å¯ä»¥æˆäºˆé›†ç¾¤çº§åˆ«çš„æƒé™** |
| åŒ¿åç”¨ æˆ·       | ä¸èƒ½è¢«è¯†åˆ«ä¸ºService Accountï¼Œä¹Ÿä¸èƒ½è¢«è¯†åˆ«ä¸ºUser Accountçš„ç”¨æˆ·ï¼Œå³â€œåŒ¿åç”¨æˆ·" |

å°½ç®¡æ— æ³•é€šè¿‡ API è°ƒç”¨æ¥æ·»åŠ æ™®é€šç”¨æˆ·ï¼Œ Kubernetes ä»ç„¶è®¤ä¸º**èƒ½å¤Ÿæä¾›**ç”±é›†ç¾¤çš„è¯ä¹¦æœºæ„ç­¾åçš„**åˆæ³•è¯ä¹¦**çš„**ç”¨æˆ·**æ˜¯**é€šè¿‡èº«ä»½è®¤è¯çš„ç”¨æˆ·**ã€‚ åŸºäºè¿™æ ·çš„é…ç½®**ï¼ŒKubernetes ä½¿ç”¨è¯ä¹¦ä¸­çš„ 'subject' çš„é€šç”¨åç§°** ï¼ˆCommon Nameï¼‰**å­—æ®µ** ï¼ˆä¾‹å¦‚ï¼Œ"/CN=bob"ï¼‰**æ¥ç¡®å®šç”¨æˆ·å**ã€‚ æ¥ä¸‹æ¥ï¼Œ**åŸºäºè§’è‰²è®¿é—®æ§åˆ¶**ï¼ˆRBACï¼‰ å­ç³»ç»Ÿä¼š**ç¡®å®šç”¨æˆ·æ˜¯å¦æœ‰æƒé’ˆå¯¹æŸèµ„æºæ‰§è¡Œç‰¹å®šçš„æ“ä½œ**ã€‚



##### ç”¨æˆ·ç»„

åœ¨kubernetesé›†ç¾¤ä¸­ï¼Œä¸ºäº†æ›´æ–¹ä¾¿çš„å¯¹æŸä¸€ç±»ç”¨æˆ·å¸å·UAè¿›è¡Œæ–¹ä¾¿ç®¡ç†ï¼Œä¸€èˆ¬ä¼šé€šè¿‡ç”¨æˆ·ç»„çš„æ–¹å¼æ¥è¿›è¡Œç®¡ç†

æ³¨æ„: Kubernetes ä¸æ”¯æŒå°†ä¸€ä¸ªSAæœåŠ¡å¸æˆ·åŠ å…¥ä¸€ä¸ªæŒ‡å®šçš„ç»„ä¸­,ä½†æ˜¯å¯ä»¥é€šè¿‡RBACæœºåˆ¶åˆ›å»ºä¸€ä¸ªæˆæƒ çš„è§’è‰²,å†å°†æœåŠ¡å¸æˆ·å’Œè§’è‰²ç»‘å®šå®ç°ã€‚

Kuberneteså¸¸è§çš„å†…ç½®ç”¨æˆ·ç»„æœ‰ä»¥ä¸‹å››ç±»ï¼š

| ç”¨æˆ·ç»„                              | è§£æ                                                         |
| ----------------------------------- | ------------------------------------------------------------ |
| system:unauthenticated              | æœªèƒ½é€šè¿‡ä»»ä½•ä¸€ä¸ªæˆæƒæ’ä»¶æ£€éªŒçš„è´¦å·çš„æ‰€æœ‰æœªé€šè¿‡è®¤è¯æµ‹è¯•çš„ç”¨æˆ· ç»Ÿä¸€éš¶å±çš„ç”¨æˆ·ç»„ |
| system:authenticated                | è®¤è¯æˆåŠŸåçš„ç”¨æˆ·è‡ªåŠ¨åŠ å…¥çš„ä¸€ä¸ªä¸“ç”¨ç»„ï¼Œç”¨äºå¿«æ·å¼•ç”¨æ‰€æœ‰æ­£å¸¸é€šè¿‡è®¤è¯çš„ç”¨æˆ·è´¦å· |
| system:serviceaccounts              | æ‰€æœ‰åç§°ç©ºé—´ä¸­çš„æ‰€æœ‰ServiceAccountå¯¹è±¡                       |
| system:serviceaccounts: <namespace> | ç‰¹å®šåç§°ç©ºé—´å†…æ‰€æœ‰çš„ServiceAccountå¯¹è±¡                       |

Kubernetesæœ¬èº«å¹¶æ²¡æœ‰å¯¹ç”¨æˆ·æˆ–ç”¨æˆ·ç»„çš„å†…å»ºæ¦‚å¿µæˆ–å®ä½“ã€‚

åœ¨**Kubernetesä¸­**ï¼Œ**ç”¨æˆ·å’Œç»„æ˜¯åœ¨èº«ä»½æä¾›è€…**ï¼ˆå¦‚OpenID Connectï¼ŒActive Directoryç­‰ï¼‰**ä¸­åˆ›å»ºå’Œç®¡ç† çš„**ï¼Œ**è€Œä¸æ˜¯åœ¨Kubernetesé›†ç¾¤è‡ªèº«ä¸­åˆ›å»º**ã€‚æ‰€ä»¥ï¼Œæ— æ³•ç›´æ¥åœ¨Kubernetesä¸­åˆ›å»ºç»„ã€‚

åœ¨Kubernetesä¸­ï¼Œç”¨æˆ·å’Œç”¨æˆ·ç»„ä¸»è¦åœ¨**è®¤è¯ (Authentication)** å’Œ**æˆæƒ (Authorization)** ç¯èŠ‚ä¸­å‘æŒ¥ä½œç”¨ã€‚

**è¿™å°±æ„å‘³ç€åœ¨Kubernetesä¸­æ²¡æœ‰ç›´æ¥çš„æ–¹å¼å»æŸ¥çœ‹ç”¨æˆ·æˆ–ç”¨æˆ·ç»„**

å¦‚æœæƒ³è¦æŸ¥çœ‹å½“å‰Kubernetesé›†ç¾¤ä¸­çš„ç”¨æˆ·å’Œç”¨æˆ·ç»„ï¼Œé€šå¸¸éœ€è¦æŸ¥çœ‹çš„æ˜¯**å¤–éƒ¨èº«ä»½æä¾›å•†çš„è®¾ç½®**æˆ–**Kubeconfigæ–‡ä»¶**ã€‚åŒæ—¶ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹åœ¨Kubernetesä¸­å®šä¹‰çš„RBACç­–ç•¥ï¼Œä»¥ç†è§£å“ªäº›ç”¨æˆ·å’Œç”¨æˆ·ç»„æœ‰ æƒè®¿é—®ç‰¹å®šèµ„æºã€‚

åœ¨Kubernetesä¸­ï¼Œ**æœåŠ¡å¸æˆ·(ServiceAccount)**é»˜è®¤ä¼šè¢«æ”¾å…¥ä¸¤ä¸ªç»„ä¹‹ä¸€ï¼š **system:serviceaccounts ï¼ˆ**è¡¨ç¤ºé›†ç¾¤ä¸­çš„æ‰€æœ‰æœåŠ¡å¸æˆ·ï¼‰å’Œ **system:serviceaccounts: `<namespace>`**ï¼ˆè¡¨ç¤ºç»™å®šå‘½åç©ºé—´ä¸­çš„æ‰€æœ‰æœåŠ¡å¸æˆ·ï¼‰ã€‚è¿™äº›æ˜¯å†…ç½®çš„ç»„ã€‚



**èŒƒä¾‹ï¼šæŸ¥çœ‹ç”¨æˆ·ç»„`system:master`çš„æƒé™**

```bash
#æ‰€æœ‰çš„k8sé›†ç¾¤èµ„æºæ“ä½œï¼Œå…¶å®éƒ½æ˜¯é€šè¿‡nodeèŠ‚ç‚¹ä¸Šçš„kubeletå’ŒmasterèŠ‚ç‚¹ä¸Šçš„apiserverä¹‹é—´çš„é€šä¿¡å®ç°ï¼Œè€Œåœ¨kubernetesçš„è®¤è¯ç›®å½•ä¸­æœ‰å…¶ä¸“ç”¨çš„é€šä¿¡è®¤è¯è¯ä¹¦ apiserver-kubelet-client.crtï¼Œå¯ä»¥é€šè¿‡è¯¥æ–‡ä»¶æ¥æ£€æŸ¥ä¸€ä¸‹è¿™ä¸¤è€…ä¹‹é—´æ˜¯ä¸€ä¸ªæ€æ ·çš„å…³ç³»ã€‚

# æ–°ç‰ˆ
[root@master1 pki]#openssl x509 -in /etc/kubernetes/pki/apiserver-kubelet-client.crt -text -noout
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 8841619138675744303 (0x7ab3bdc300101e2f)
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN = kubernetes
        Validity
            Not Before: Jan  4 01:39:06 2025 GMT
            Not After : Jan  4 01:44:06 2026 GMT
            # ä¸‹é¢Organizationçš„å€¼ä¸ºkubeadm: cluster-adminsï¼Œæ„æ€æ˜¯å°†è¯¥ç”¨æˆ·åŠ å…¥ç»„cluster-adminsä¸­
            # ä¸‹é¢æœ‰ä¸ºä»€ä¹ˆcluster-adminsæœ‰æ‰€æœ‰æƒé™
        Subject: O = kubeadm:cluster-admins, CN = kube-apiserver-kubelet-client
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
                Modulus:
                ......
                
# æŸ¥çœ‹é›†ç¾¤è§’è‰²æƒé™
[root@master1 pki]#kubectl get clusterrole cluster-admin -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  creationTimestamp: "2025-01-04T01:44:14Z"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: cluster-admin     # ç»™é›†ç¾¤è§’è‰²cluster-adminå…¨éƒ¨æƒé™ï¼Œä¸‹é¢éƒ½æ˜¯*ï¼Œå°±è¡¨ç¤ºæˆäºˆæ‰€æœ‰æƒé™
  resourceVersion: "74"
  uid: 7defd096-536a-4bd1-890c-e496d1c5f35e
rules:
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - '*'
- nonResourceURLs:
  - '*'
  verbs:
  - '*'

# æŸ¥çœ‹roleè§’è‰²cluster-adminåŒåçš„clusterrolebindingï¼Œåˆ†é…æƒé™ç»™kubeadm:cluster-adminsç»„
[root@master1 pki]# kubectl get clusterrolebinding kubeadm:cluster-admins -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: "2025-01-04T01:44:15Z"
  name: kubeadm:cluster-admins
  resourceVersion: "204"
  uid: c0010b58-45ce-4d63-a0b4-e1a1632f3977
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin   # å°†è¿™ä¸ªæ‹¥æœ‰å…¨éƒ¨æƒé™çš„è§’è‰²ï¼Œèµ‹äºˆä¸‹é¢çš„ç»„kubeadm:cluster-admins
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: kubeadm:cluster-admins   # å› æ­¤è¿™é‡Œè¿™ä¸ªç»„cluster-adminsæœ‰å…¨éƒ¨æƒé™

```



##### è®¤è¯æ’ä»¶

Kubernetes é€šè¿‡èº«ä»½è®¤è¯æ’ä»¶åˆ©ç”¨**å®¢æˆ·ç«¯è¯ä¹¦**ã€**æŒæœ‰è€…ä»¤ç‰Œï¼ˆBearer Tokenï¼‰**æˆ–**èº«ä»½è®¤è¯ä»£ç† ï¼ˆProxyï¼‰** æ¥è®¤è¯ API è¯·æ±‚çš„èº«ä»½ã€‚

kubernetesæä¾›äº†å¤šç§è®¤è¯æ–¹å¼ï¼Œå¯ä»¥åŒæ—¶ä½¿ç”¨ä¸€ç§æˆ–å¤šç§è®¤è¯æ–¹å¼ï¼Œåªè¦é€šè¿‡ä»»ä½•ä¸€ä¸ªæˆåŠŸå³è¢«è®¤ä½œ æ˜¯è®¤è¯é€šè¿‡ã€‚å³æˆ–å…³ç³»



**å¸¸è§çš„è®¤è¯æ–¹å¼å¦‚ä¸‹ï¼š**

| è®¤è¯æ–¹å¼            | è§£æ                                                         |
| ------------------- | ------------------------------------------------------------ |
| X509 å®¢æˆ·ç«¯è¯ä¹¦è®¤è¯ | TLSåŒå‘è®¤è¯ï¼Œå®¢æˆ·ç«¯æŒæœ‰æ•°å­—è¯ä¹¦,API Serverä¿¡ä»»å®¢æˆ·ç«¯è¯ä¹¦çš„é¢å‘è€….å³æœåŠ¡å™¨å®¢æˆ·ç«¯äº’ç›¸éªŒè¯<br />**ä¿¡ä»»çš„CA**éœ€è¦åœ¨kube-apiserverå¯åŠ¨æ—¶,é€šè¿‡**--client-ca-fileé€‰é¡¹æŒ‡å®š**.<br />è¯ä¹¦ä¸­çš„Subjectä¸­çš„ **CN(CommonName)å³è¢«è¯†åˆ«ä¸ºç”¨æˆ·å**ï¼Œè€Œ**Oï¼ˆOrganizationï¼‰ è¢«è¯†åˆ«ä¸ºç»„å**<br />å¯¹äºè¿™ç§å®¢æˆ·çš„è´¦å·ï¼Œk8sæ˜¯æ— æ³•ç®¡ç†çš„ã€‚ä¸ºäº†ä½¿ç”¨è¿™ä¸ªæ–¹æ¡ˆï¼Œapi-serveréœ€è¦ç”¨-- client-ca-fileã€--tls-private-key-fileã€--tls-cert-fileé€‰é¡¹æ¥å¼€å¯ã€‚<br />kubeadméƒ¨ç½²çš„Kubernetesé›†ç¾¤ï¼Œé»˜è®¤ä½¿ç”¨ **/etc/kubernetes/pki/ca.crt** è¿›è¡Œå®¢æˆ·ç«¯è®¤è¯,æ­¤æ–‡ä»¶æ˜¯kubeadmä¸ºKuberneteså„ç»„ä»¶é—´é¢å‘æ•°å­—è¯ä¹¦çš„**æ ¹CA** |
| ä»¤ç‰Œè®¤è¯ (Token)    | åœ¨èŠ‚ç‚¹æ•°é‡éå¸¸å¤šçš„æ—¶å€™ï¼Œå¤§é‡æ‰‹åŠ¨é…ç½®TLSè®¤è¯æ¯”è¾ƒéº»çƒ¦ï¼Œå¯ä»¥**é€šè¿‡åœ¨api-serverå¼€ å¯ experimental-bootstrap-token-auth ç‰¹æ€§**ï¼Œ**é€šè¿‡å¯¹å®¢æˆ·ç«¯çš„å’Œk8så¹³å°é¢„å…ˆå®šä¹‰çš„ tokenä¿¡æ¯è¿›è¡ŒåŒ¹é…**ï¼Œ**è®¤è¯é€šè¿‡åï¼Œè‡ªåŠ¨ä¸ºèŠ‚ç‚¹é¢å‘è¯ä¹¦**ï¼Œå¯ä»¥å¤§å¤§å‡è½»å·¥ä½œé‡ï¼Œè€Œä¸” åº”ç”¨åœºæ™¯éå¸¸å¹¿ã€‚<br />åŒ…æ‹¬: Service Account ä»¤ç‰Œ,é™æ€ä»¤ç‰Œæ–‡ä»¶,Bootstrapä»¤ç‰Œ,OIDC(OpenID Connect)ä»¤ ç‰Œ,Webhook ä»¤ç‰Œ ç­‰ |
| ä»£ç†è®¤è¯            | ä¸€èˆ¬å€ŸåŠ©äºä¸­é—´ä»£ç†çš„æ–¹å¼æ¥è¿›è¡Œç»Ÿç”¨çš„è®¤è¯æ–¹å¼ï¼Œæ ·å¼ä¸å›ºå®š     |
| åŒ¿å                | æ— æ³•è®¤è¯çš„å…¶å®ƒè¯·æ±‚                                           |



**API Serverå¯ç”¨çš„èº«ä»½è®¤è¯æœºåˆ¶**

- åŸºäºè®¤è¯æ’ä»¶æ”¯æŒå¤šç§è®¤è¯æ–¹å¼ï¼Œè€Œç›¸åº”è®¤è¯æ’ä»¶çš„å¯ç”¨éœ€è¦ç»ç”±kube-apiserverä¸Šçš„ä¸“ç”¨é€‰é¡¹å®Œæˆ
- kubeadm éƒ¨ç½²çš„é›†ç¾¤é»˜è®¤å¯ç”¨çš„è®¤è¯æœºåˆ¶åŒ…æ‹¬å¦‚ä¸‹å‡ ç§
  - X509å®¢æˆ·ç«¯è¯ä¹¦è®¤è¯
  - Bootstrapä»¤ç‰Œè®¤è¯
  - å‰ç«¯ä»£ç†èº«ä»½è®¤è¯ front-proxy
  - Service Account ä»¤ç‰Œ
- æ³¨æ„ï¼šAPI Serverå¹¶ä¸ä¿è¯å„è®¤è¯æ’ä»¶çš„ç”Ÿæ•ˆæ¬¡åºä¸å®šä¹‰çš„æ¬¡åºç›¸åŒ



**èŒƒä¾‹: æŸ¥çœ‹API Server çš„è®¤è¯æœºåˆ¶**

```bash
#åœ¨MasterèŠ‚æŸ¥çœ‹è®¤è¯æœºåˆ¶
[root@master1 pki] # cat /etc/kubernetes/manifests/kube-apiserver.yaml 
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 10.0.0.201:6443
  creationTimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=10.0.0.201
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt             # x509å®¢æˆ·ç«¯è®¤è¯ï¼Œæ­¤CAé¢å‘çš„è¯ä¹¦å¯¹åº”çš„ç”¨æˆ·æ˜¯åˆæ³•ç”¨æˆ·
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true                      # Bootstrap ä»¤ç‰Œè®¤è¯
    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
    - --etcd-servers=https://127.0.0.1:2379
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt     # èº«ä»½è®¤è¯ä»£ç†
    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key      # èº«ä»½è®¤è¯ä»£ç†
    - --requestheader-allowed-names=front-proxy-client                        # èº«ä»½è®¤è¯ä»£ç†
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt   # èº«ä»½è®¤è¯ä»£ç†
    - --requestheader-extra-headers-prefix=X-Remote-Extra-                    # èº«ä»½è®¤è¯ä»£ç†
    - --requestheader-group-headers=X-Remote-Group                            # èº«ä»½è®¤è¯ä»£ç†
    - --requestheader-username-headers=X-Remote-User                          # èº«ä»½è®¤è¯ä»£ç†
    - --secure-port=6443
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local   # SAè®¤è¯
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub                   # SAè®¤è¯
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key           # SAè®¤è¯
    - --service-cluster-ip-range=10.96.0.0/12
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    image: registry.aliyuncs.com/google_containers/kube-apiserver:v1.30.2
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 10.0.0.201
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-apiserver
    readinessProbe:
      failureThreshold: 3
      httpGet:
        host: 10.0.0.201
        path: /readyz
        port: 6443
        scheme: HTTPS
      periodSeconds: 1
      timeoutSeconds: 15
    resources:
      requests:
        cpu: 250m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 10.0.0.201
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: true
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: true
    - mountPath: /etc/pki
      name: etc-pki
      readOnly: true
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: true
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: true
  hostNetwork: true
  priority: 2000001000
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      type: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      type: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /etc/pki
      type: DirectoryOrCreate
    name: etc-pki
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /usr/local/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-share-ca-certificates
status: {}
```



**Kubeletå¯ç”¨çš„èº«ä»½è®¤è¯æœºåˆ¶**

- kubeletçš„REST APIç«¯ç‚¹é»˜è®¤é€šè¿‡TCPåè®®çš„10250ç«¯å£æä¾›ï¼Œæ”¯æŒç®¡ç†æ“ä½œ

| Kubelet API | åŠŸèƒ½ç®€ä»‹                   |
| ----------- | -------------------------- |
| /pods       | åˆ—å‡ºå½“å‰kubeletèŠ‚ç‚¹ä¸Šçš„Pod |
| /run        | åœ¨ä¸€ä¸ªå®¹å™¨å†…è¿è¡ŒæŒ‡å®šçš„å‘½ä»¤ |
| /exec       | åœ¨ä¸€ä¸ªå®¹å™¨å†…è¿è¡ŒæŒ‡å®šçš„å‘½ä»¤ |
| /configz    | è®¾ç½®Kubeletçš„é…ç½®æ–‡ä»¶å‚æ•°  |
| /debug      | è°ƒè¯•ä¿¡æ¯                   |

- éœ€è¦å¯¹å®¢æˆ·ç«¯èº«ä»½è¿›è¡Œè®¤è¯
- å¯ç”¨çš„èº«ä»½è®¤è¯:webhook,x509å®¢æˆ·ç«¯è¯ä¹¦è®¤è¯
  - æ³¨æ„ï¼šå»ºè®®æ˜¾å¼ç¦ç”¨åŒ¿åç”¨æˆ·
- API Serveræ˜¯è¯¥APIç«¯ç‚¹çš„å®¢æˆ·ç«¯ï¼Œå› æ­¤ï¼Œkubeletéœ€è¦åœ¨éªŒè¯å®¢æˆ·ç«¯èº«ä»½æ—¶ä¿¡ä»»ç»™API Serveré¢å‘æ•°å­—è¯ä¹¦çš„CA



**èŒƒä¾‹ï¼šæŸ¥çœ‹Kubeletçš„è®¤è¯æœºåˆ¶**

```yaml
#åœ¨æ¯ä¸ªworkerèŠ‚ç‚¹æŸ¥çœ‹
[root@node1 pki] # cat /var/lib/kubelet/config.yaml 
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false                             # åŒ¿åè®¤è¯ï¼Œtrueä¸ºå…è®¸åŒ¿åè®¿é—®ï¼Œä½†æ˜¯æƒé™ä¸è¶³
  webhook:
    cacheTTL: 0s                               # webhookè®¤è¯
    enabled: true
  x509:
    clientCAFile: /etc/kubernetes/pki/ca.crt   # è¯ä¹¦è®¤è¯
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 0s
    cacheUnauthorizedTTL: 0s
cgroupDriver: systemd
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
containerRuntimeEndpoint: ""
cpuManagerReconcilePeriod: 0s
evictionPressureTransitionPeriod: 0s
fileCheckFrequency: 0s
healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 0s
imageMaximumGCAge: 0s
imageMinimumGCAge: 0s
kind: KubeletConfiguration
logging:
  flushFrequency: 0
  options:
    json:
      infoBufferSize: "0"
    text:
      infoBufferSize: "0"
  verbosity: 0
memorySwap: {}
nodeStatusReportFrequency: 0s
nodeStatusUpdateFrequency: 0s
resolvConf: /run/systemd/resolve/resolv.conf
rotateCertificates: true
runtimeRequestTimeout: 0s
shutdownGracePeriod: 0s
shutdownGracePeriodCriticalPods: 0s
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 0s
syncFrequency: 0s
volumeStatsAggPeriod: 0s

#å¦‚æœä¿®æ”¹,ä¸å»ºè®®ä¿®æ”¹/var/lib/kubelet/config.yamlé…ç½®æ–‡ä»¶,è€Œé€šè¿‡ä¿®æ”¹å¯¹åº”çš„configmapå®ç°
[root@master1 pki]#kubectl get -n kube-system cm kubelet-config -o yaml
apiVersion: v1
data:
  kubelet: |
    apiVersion: kubelet.config.k8s.io/v1beta1
    authentication:
      anonymous:
        enabled: false
      webhook:
        cacheTTL: 0s
        enabled: true
      x509:
        clientCAFile: /etc/kubernetes/pki/ca.crt
    authorization:
      mode: Webhook
      webhook:
        cacheAuthorizedTTL: 0s
        cacheUnauthorizedTTL: 0s
    cgroupDriver: systemd
    clusterDNS:
    - 10.96.0.10
    clusterDomain: cluster.local
    containerRuntimeEndpoint: ""
    cpuManagerReconcilePeriod: 0s
    evictionPressureTransitionPeriod: 0s
    fileCheckFrequency: 0s
    healthzBindAddress: 127.0.0.1
    healthzPort: 10248
    httpCheckFrequency: 0s
    imageMaximumGCAge: 0s
    imageMinimumGCAge: 0s
    kind: KubeletConfiguration
    logging:
      flushFrequency: 0
      options:
        json:
          infoBufferSize: "0"
        text:
          infoBufferSize: "0"
      verbosity: 0
    memorySwap: {}
    nodeStatusReportFrequency: 0s
    nodeStatusUpdateFrequency: 0s
    resolvConf: /run/systemd/resolve/resolv.conf
    rotateCertificates: true
    runtimeRequestTimeout: 0s
    shutdownGracePeriod: 0s
    shutdownGracePeriodCriticalPods: 0s
    staticPodPath: /etc/kubernetes/manifests
    streamingConnectionIdleTimeout: 0s
    syncFrequency: 0s
    volumeStatsAggPeriod: 0s
kind: ConfigMap
metadata:
  annotations:
    kubeadm.kubernetes.io/component-config.hash: sha256:14a463ee2caafeaa2b6d58bb8c225fb8e9e4509ed1a77d8c55a943bc7d89f7ac
  creationTimestamp: "2025-01-04T01:44:15Z"
  name: kubelet-config
  namespace: kube-system
  resourceVersion: "208"
  uid: 4e74f407-d431-4379-9a22-4cd5b9f64916
```



#### X509å®¢æˆ·ç«¯è®¤è¯

Kubernetesé›†ç¾¤ä¸­çš„X509å®¢æˆ·ç«¯è®¤è¯ä¾èµ–äºPKIè¯ä¹¦ä½“ç³»,æœ‰å¦‚ä¸‹ä¸‰å¥—CAè¯ä¹¦ç³»ç»Ÿ

![image-20250107194258441](../markdown_img/image-20250107194258441.png)

kubeadméƒ¨ç½²Kubernetesé›†ç¾¤æ—¶ä¼šè‡ªåŠ¨ç”Ÿæˆæ‰€éœ€è¦çš„è¯ä¹¦ï¼Œå®ƒä»¬ä½äº**/etc/kubernetes/pki**è‡ªå½•ä¸‹

| æ–‡ä»¶                                     | Default CN               | è¯´æ˜                           |
| ---------------------------------------- | ------------------------ | ------------------------------ |
| ca.crt,ca.key                            | kubernetes-ca            | Kubernetes general CA          |
| etcd/ca.crt,etcd/ca.key                  | etcd-ca                  | For all etcd-related functions |
| front-proxy-ca.crt,front-proxyca.crt.key | kubernetes-frontproxy-ca | For the front-end proxy        |



**æ¡ˆä¾‹**

#####  **åˆ›å»ºåŸºäºX509å®¢æˆ·ç«¯æ™®é€šçš„ç”¨æˆ·è¯ä¹¦**

```ABAP
åŸç†ï¼šå®¢æˆ·ç«¯ï¼Œæ— è®ºæ˜¯ä½¿ç”¨kubectlè¿˜æ˜¯curlï¼Œå’ŒapiServeré€šä¿¡ï¼Œå®¢æˆ·ç«¯ä½¿ç”¨çš„è¯ä¹¦æ˜¯apiServeræœåŠ¡ç«¯ä¸Šæœ‰çš„caè¯ä¹¦ç”Ÿæˆçš„ï¼Œæ‰€ä»¥å®¢æˆ·ç«¯ä½¿ç”¨çš„è¯ä¹¦å¯ä»¥è¢«æœåŠ¡ç«¯ä¿¡ä»»ï¼Œå°±è¿™ä¹ˆç®€å•ï¼Œå“ˆå“ˆå“ˆ
```



```bash
# æŸ¥çœ‹åˆ°ä»¥ä¸‹å†…å®¹ï¼Œè¡¨ç¤ºé»˜è®¤kubernetesçš„CAç­¾å‘çš„è¯ä¹¦ï¼Œéƒ½æ˜¯k8så®¢æˆ·ç«¯çš„ç”¨æˆ·
[root@master1 kubelet]#grep '\-\-client-ca-file' /etc/kubernetes/manifests/kube-apiserver.yaml 
    - --client-ca-file=/etc/kubernetes/pki/ca.crt

# #åœ¨masterèŠ‚ç‚¹åˆ›å»ºtestç”¨æˆ·è¯ä¹¦
[root@master1 ~]#mkdir pki
[root@master1 pki]#(umask 077; openssl genrsa -out pki/mystical.key 4096)
[root@master1 pki]#ls pki/
mystical.key

# ç”Ÿæˆè¯ä¹¦ç”³è¯·,åŠ å…¥opsç»„åªå…·æœ‰æ™®é€šæƒé™
[root@master1 pki]# openssl req -new -key ./mystical.key -out ./mystical.csr -subj "/CN=mystical/O=ops"
[root@master1 pki]# ls
mystical.csr  mystical.key

#ä½¿ç”¨kubernetes-caé¢å‘è¯ä¹¦
[root@master1 pki]#openssl x509 -req -days 3650 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -in ./mystical.csr -out ./mystical.crt
Certificate request self-signature ok
subject=CN = mystical, O = ops

# å¤åˆ¶è¯ä¹¦æ–‡ä»¶åˆ°workerèŠ‚ç‚¹
[root@master1 ~]#scp -r pki/ 10.0.0.202:
mystical.key                                        100% 3272     1.7MB/s   00:00    
mystical.csr                                        100% 1602     2.4MB/s   00:00    
mystical.crt                                        100% 1359     2.0MB/s   00:00 

#åœ¨workerèŠ‚ç‚¹ä½¿ç”¨kubectlè®¿é—®ï¼Œæ­£å¸¸æ˜¯æ²¡æœ‰æƒé™çš„
[root@node1 pki]#kubectl get pod
E0107 20:00:19.853410  205917 memcache.go:265] couldn't get current server API group list: Get "http://localhost:8080/api?timeout=32s": dial tcp 127.0.0.1:8080: connect: connection refused

# ä½¿ç”¨åˆšåˆ›å»ºçš„è¯ä¹¦è¿›è¡Œè®¿é—®ï¼Œæ˜¾ç¤ºçš„æ˜¯æ— æƒé™ï¼Œè€Œä¸æ˜¯æ‹’ç»è®¿é—®ï¼Œæ˜¯Forbidden
[root@node1 ~]#kubectl get pod --server=https://10.0.0.201:6443 --client-certificate=pki/mystical.crt --client-key=pki/mystical.key --certificate-authority=/etc/kubernetes/pki/ca.crt
Error from server (Forbidden): pods is forbidden: User "mystical" cannot list resource "pods" in API group "" in the namespace "default"

# æˆ–è€…ä¸‹é¢é€‰é¡¹å¿½ç•¥è¯ä¹¦æ ¡éªŒä¹Ÿå¯ä»¥
[root@node1 ~]#kubectl get pod --server=https://10.0.0.201:6443 --client-certificate=pki/mystical.crt --client-key=pki/mystical.key --insecure-skip-tls-verify=true
Error from server (Forbidden): pods is forbidden: User "mystical" cannot list resource "pods" in API group "" in the namespace "default"

# é€šè¿‡curlä½¿ç”¨è¯ä¹¦è®¿é—®ï¼Œä»æ˜¯æƒé™ä¸è¶³
[root@node1 ~]#curl --cert pki/mystical.crt --key pki/mystical.key --key-type PEM --cacert /etc/kubernetes/pki/ca.crt https://10.0.0.201:6443
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "forbidden: User \"mystical\" cannot get path \"/\"",
  "reason": "Forbidden",
  "details": {},
  "code": 403
}
```



##### åˆ›å»ºåŸºäºX509å®¢æˆ·ç«¯ç®¡ç†å‘˜çš„ç”¨æˆ·è¯ä¹¦

```bash
# åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·adminè¯ä¹¦
[root@master1 pki]#(umask 077; openssl genrsa -out ./admin.key 4096)

[root@master1 pki]#ls
admin.key  mystical.crt  mystical.csr  mystical.key

# ç”Ÿæˆè¯ä¹¦ç”³è¯·æ–‡ä»¶ï¼Œæ³¨æ„ï¼šåŠ å…¥system:mastersç»„æˆSystemç»„æ‰å…·æœ‰ç®¡ç†æƒé™
# æ–°ç‰ˆ
[root@master1 pki]#openssl req -new -key ./admin.key -out ./admin.csr -subj "/CN=admin/O=kubeadm:cluster-admins"

[root@master1 pki]#ls
admin.csr  admin.key  mystical.crt  mystical.csr  mystical.key

#æŸ¥çœ‹åˆ°system:mastersç»„è¢«æˆæƒClusterRoleè§’è‰²,å…·æœ‰é›†ç¾¤çš„ç®¡ç†æƒé™
#æ–°ç‰ˆ
[root@master1 pki]#kubectl get clusterrolebindings.rbac.authorization.k8s.io kubeadm:cluster-admins -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: "2025-01-04T01:44:15Z"
  name: kubeadm:cluster-admins
  resourceVersion: "204"
  uid: c0010b58-45ce-4d63-a0b4-e1a1632f3977
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin            # è¯¥è§’è‰²è¢«èµ‹äºˆäº†æ‰€æœ‰æƒé™
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: kubeadm:cluster-admins   # ç»„
  
# ä½¿ç”¨kubernetes-caé¢å‘è¯ä¹¦
[root@master1 pki]#openssl x509 -req -days 3650 -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -in ./admin.csr -out ./admin.crt
Certificate request self-signature ok
subject=CN = admin, O = kubeadm:cluster-admins

[root@master1 pki]#ls
admin.crt  admin.csr  admin.key  mystical.crt  mystical.csr  mystical.key

# ä¼ ç»™workerèŠ‚ç‚¹
[root@master1 ~]#scp -r pki/ 10.0.0.202:

# workèŠ‚ç‚¹ä½¿ç”¨è¯ä¹¦è®¿é—®æµ‹è¯•
[root@node1 ~]#kubectl get ns -s https://10.0.0.201:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt --client-certificate=pki/admin.crt --client-key=pki/admin.key
NAME              STATUS   AGE
default           Active   3d11h
ingress-nginx     Active   3d9h
kube-flannel      Active   3d11h
kube-node-lease   Active   3d11h
kube-public       Active   3d11h
kube-system       Active   3d11h
metallb-system    Active   3d9h

# curlå‘½ä»¤ä½¿ç”¨è¯ä¹¦è®¿é—®
[root@node1 ~]#curl --cert pki/wang.crt --key pki/wang.key --key-type PEM --cacert /etc/kubernetes/pki/ca.crt https://10.0.0.201:6443/api
{
  "kind": "APIVersions",
  "versions": [
    "v1"
  ],
  "serverAddressByClientCIDRs": [
    {
      "clientCIDR": "0.0.0.0/0",
      "serverAddress": "10.0.0.201:6443"
    }
  ]

#æ³¨æ„ï¼šå¦‚æœåœ¨masterèŠ‚ç‚¹æ‰§è¡Œä¼šå‡ºç°ä¸‹é¢æç¤ºé”™
[root@master1 ~]#kubectl get ns -s https://10.0.0.201:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt --client-certificate=pki/wang.crt --client-key=pki/wang.key
Error in configuration: 
* client-cert-data and client-cert are both specified for kubernetes-admin. client-cert-data will override.
* client-key-data and client-key are both specified for kubernetes-admin; client-key-data will override

#æç¤ºé”™è¯¯çš„åŸå› :$HOME/.kube/configæ–‡ä»¶è¿˜æœ‰å…¶å®ƒç”¨æˆ·èº«ä»½ï¼Œè§£å†³æ–¹æ³•å¦‚ä¸‹
[root@master1 ~]# mv ~/.kube/config /tmp

#å†æ¬¡æ‰§è¡ŒæˆåŠŸ
[root@master1 ~]#]#kubectl get ns -s https://10.0.0.201:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt --client-certificate=pki/wang.crt --client-key=pki/wang.key
pod-test-6d8c97ff75-qt8zq   1/1     Running   1 (10h ago)   2d
pod-test-6d8c97ff75-rhwkv   1/1     Running   1 (10h ago)   2d
pod-test-6d8c97ff75-tmtl9   1/1     Running   1 (10h ago)   2d
```



##### æ–¹æ³•2ï¼šä½¿ç”¨kubernetesèµ„æºæ¥ç®¡CSRè¯ä¹¦ç”³è¯·æ–‡ä»¶

```bash
# åˆ›å»ºç§é’¥
[root@master1 ~]#openssl genrsa -out test2.key 2048

# åˆ›å»ºè¯ä¹¦ç”³è¯·
[root@master1 pki]#openssl req -new -key test2.key -out test2.csr -subj "/CN=test2/O=devops"

# æŸ¥çœ‹è¯ä¹¦ä¿¡æ¯
[root@master1 pki]#cat test2.csr|base64 |tr -d "\n"
LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ1pqQ0NBVTRDQVFBd0lURU9NQXdHQTFVRUF3d0ZkR1Z6ZERJeER6QU5CZ05WQkFvTUJtUmxkbTl3Y3pDQwpBU0l3RFFZSktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ0VCQUpoSUFOUzlra2x4ZFVxZjlqanRWZ2VnCm1ibkk1TUFYTjNJMU9WakZpQjd0UlhURzZuQngwOHFjM1lBc0NYcmQ5NFExYlVKbUNJR3Fyd0xVU1N4ZURJRlQKcEwreWR1QjlWdkN2MEhXbHFPbE9FcjNlUGtsV3pheUJpNUhqbUJYYlZrNUpsMlk2L1NZTkdzLzFhZWFFMk1FZApwSlAydTJFSDdqMFVvYVhSNlNVV1hwLzFGYjhkRXAvR2VaM29taFFKaC9uM0dvKzhCSlV5MStVRlF3b1VMMEtKCm05R2tKbnFPUkR4OTQ0RVptRmxKOFg1bXFFbHhkUUg3TGtRcXhpTkY4TitJUmZtdXplVVp6VncrbzFzRGo3STMKY2JrZCsrTGVVVmJkbC9VZThlUlphdHVZTzJZQy9TMk85S2loTWZONXR2K0ZnNjl1Ylc5RkhIK1g2L25XS3JjQwpBd0VBQWFBQU1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQXFyVlVLR3VWaHdxdjRuZnBsQVV3T0NaSkFNemcwCm5tMVpNYnFUeGM4ZE1BZFFBQTJOcTVOOEhMQzJ4NFhQeDdlUlFGL2hVSUh5SE0wZUNCcTVlV1htTlRlbERkdTUKWTVja1hkbjJOZmVVd0lJMmtNcGxyMXlxam9nTXc3QTIzemVYdHB6R29PbkxvZ1ZkV3Z0c1ludmNIS0hHSUVnWApSRUwwdDRtY0d2UkMrMFFRVjVEd1pBb2FTdnE0d3pzdllQSktFUmNSdzBNT2dzVGZ2ZXBlMW1mWVNYUCtMRUswCkVHYVVaY0tuY3FpTFFLdzY2SzVyU1ZMa25VMDBhcktIUGlvWWNyb0pRYktWN0w5ekMrblFtNHRYNFJDWFRPd2UKZ1QrdFVxTEZHK1hwNDlSUWNvblZhU0tZWjgzVnlHa2lPMjZqWUpOWHJUSUFPYmsrQ1ZJajJQMngKLS0tLS1FTkQgQ0VSVElGSUNBVEUgUkVRVUVTVC0tLS0tCg==


[root@master1 pki]#cat security-certificaterequests-test2.yaml 
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: test2
spec:
  # request: XXXX...
  requests: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ1pqQ0NBVTRDQVFBd0lURU9NQXdHQTFVRUF3d0ZkR1Z6ZERJeER6QU5CZ05WQkFvTUJtUmxkbTl3Y3pDQwpBU0l3RFFZSktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ0VCQUpoSUFOUzlra2x4ZFVxZjlqanRWZ2VnCm1ibkk1TUFYTjNJMU9WakZpQjd0UlhURzZuQngwOHFjM1lBc0NYcmQ5NFExYlVKbUNJR3Fyd0xVU1N4ZURJRlQKcEwreWR1QjlWdkN2MEhXbHFPbE9FcjNlUGtsV3pheUJpNUhqbUJYYlZrNUpsMlk2L1NZTkdzLzFhZWFFMk1FZApwSlAydTJFSDdqMFVvYVhSNlNVV1hwLzFGYjhkRXAvR2VaM29taFFKaC9uM0dvKzhCSlV5MStVRlF3b1VMMEtKCm05R2tKbnFPUkR4OTQ0RVptRmxKOFg1bXFFbHhkUUg3TGtRcXhpTkY4TitJUmZtdXplVVp6VncrbzFzRGo3STMKY2JrZCsrTGVVVmJkbC9VZThlUlphdHVZTzJZQy9TMk85S2loTWZONXR2K0ZnNjl1Ylc5RkhIK1g2L25XS3JjQwpBd0VBQWFBQU1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQXFyVlVLR3VWaHdxdjRuZnBsQVV3T0NaSkFNemcwCm5tMVpNYnFUeGM4ZE1BZFFBQTJOcTVOOEhMQzJ4NFhQeDdlUlFGL2hVSUh5SE0wZUNCcTVlV1htTlRlbERkdTUKWTVja1hkbjJOZmVVd0lJMmtNcGxyMXlxam9nTXc3QTIzemVYdHB6R29PbkxvZ1ZkV3Z0c1ludmNIS0hHSUVnWApSRUwwdDRtY0d2UkMrMFFRVjVEd1pBb2FTdnE0d3pzdllQSktFUmNSdzBNT2dzVGZ2ZXBlMW1mWVNYUCtMRUswCkVHYVVaY0tuY3FpTFFLdzY2SzVyU1ZMa25VMDBhcktIUGlvWWNyb0pRYktWN0w5ekMrblFtNHRYNFJDWFRPd2UKZ1QrdFVxTEZHK1hwNDlSUWNvblZhU0tZWjgzVnlHa2lPMjZqWUpOWHJUSUFPYmsrQ1ZJajJQMngKLS0tLS1FTkQgQ0VSVElGSUNBVEUgUkVRVUVTVC0tLS0tCg==
  signerName: kubernetes.io/kube-apiserver-client
  expirationSeconds: 8640000
  usages:
  - client auth

# ç”ŸæˆCSRèµ„æºå¯¹è±¡
[root@master1 pki]#kubectl apply -f security-certificaterequests-test2.yaml 
certificatesigningrequest.certificates.k8s.io/test2 created

# æŸ¥çœ‹
[root@master1 pki]#kubectl get csr
NAME    AGE    SIGNERNAME                            REQUESTOR          REQUESTEDDURATION   CONDITION
test2   119s   kubernetes.io/kube-apiserver-client   kubernetes-admin   100d                Pending

# ä»¥kubernetesç®¡ç†å‘˜èº«ä»½ï¼Œé¢å‘è¯ä¹¦
[root@master1 pki]# kubectl certificate approve test2
certificatesigningrequest.certificates.k8s.io/test2 approved

# æŸ¥çœ‹çŠ¶æ€å·²é¢å‘
[root@master1 pki]#kubectl get csr
NAME    AGE    SIGNERNAME                            REQUESTOR          REQUESTEDDURATION   CONDITION
test2   3m4s   kubernetes.io/kube-apiserver-client   kubernetes-admin   100d                Approved,Issued

# è·å–è¯ä¹¦
[root@master1 pki]#kubectl get csr test2 -o jsonpath={.status.certificate}|base64 -d > test2.crt

[root@master1 pki]#cat test2.crt 
-----BEGIN CERTIFICATE-----
MIIDBzCCAe+gAwIBAgIRAMjOBLtzoxNSnwuFWP0q0awwDQYJKoZIhvcNAQELBQAw
FTETMBEGA1UEAxMKa3ViZXJuZXRlczAeFw0yNTAxMDcxNDMxNDVaFw0yNTA0MTcx
NDMxNDVaMCExDzANBgNVBAoTBmRldm9wczEOMAwGA1UEAxMFdGVzdDIwggEiMA0G
CSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCYSADUvZJJcXVKn/Y47VYHoJm5yOTA
FzdyNTlYxYge7UV0xupwcdPKnN2ALAl63feENW1CZgiBqq8C1EksXgyBU6S/snbg
fVbwr9B1pajpThK93j5JVs2sgYuR45gV21ZOSZdmOv0mDRrP9WnmhNjBHaST9rth
B+49FKGl0eklFl6f9RW/HRKfxnmd6JoUCYf59xqPvASVMtflBUMKFC9CiZvRpCZ6
jkQ8feOBGZhZSfF+ZqhJcXUB+y5EKsYjRfDfiEX5rs3lGc1cPqNbA4+yN3G5Hfvi
3lFW3Zf1HvHkWWrbmDtmAv0tjvSooTHzebb/hYOvbm1vRRx/l+v51iq3AgMBAAGj
RjBEMBMGA1UdJQQMMAoGCCsGAQUFBwMCMAwGA1UdEwEB/wQCMAAwHwYDVR0jBBgw
FoAU1qvukPDcEq9gVsqNRan7GdWoTHswDQYJKoZIhvcNAQELBQADggEBAAenQ8eL
1+eOA7hpwuNcEZJs+OCn2CUFtYWQ+SHQQ0yhcfACcxXzXt7XagShKC4ZmP0oeAwq
YBgoFSGiJKetDhFLVdvN/ZeUsXoplg017QgfQZ0N3kOqhwkKeIPlY0dAB5S2v1Nb
CvMk/gyXqTGqGB57bVXYZUEHZ3G5xAB2mmskNa38tBykOFrhQfL7BB7rCD9HUZDE
QGbgyZxi7Oio8MDc7wEsG85GyE6FWyE+2ad6SLOLtB7pLvGltencMF2q0JWhqFzv
oWJ7T9b93TS5Xj2yQNg2zIDhZlNi8Wr9qdC0Qe2Kbr/Ose7I9M8gtmmUaNxj0UY/
ZMZO1382+baf02Q=
-----END CERTIFICATE-----

[root@master1 pki]#openssl x509 -in test2.crt -text -noout
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            c8:ce:04:bb:73:a3:13:52:9f:0b:85:58:fd:2a:d1:ac
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN = kubernetes
        Validity
            Not Before: Jan  7 14:31:45 2025 GMT
            Not After : Apr 17 14:31:45 2025 GMT
        Subject: O = devops, CN = test2

# åç»­ä½¿ç”¨è¿™ä¸ªè¯ä¹¦å¯ä»¥æ­£å¸¸è®¿é—®ï¼ŒæŒ‰ä¸Šè¿°æ–¹æ³•
```





#### ä»¤ç‰Œè®¤è¯

#####  å¸¸è§çš„ä»¤ç‰Œè®¤è¯

- **å¼•å¯¼ä»¤ç‰Œ**

  - kubeadmåˆ›å»ºé›†ç¾¤åˆå§‹åŒ–ç¯å¢ƒæ—¶ï¼Œè‡ªåŠ¨åˆ›å»ºå¥½çš„ä¸€æ¬¡æ€§ä»¤ç‰Œï¼Œç”¨äºå…¶ä»–èŠ‚ç‚¹åŠ å…¥åˆ°é›†ç¾¤ç¯å¢ƒä¸­

  ```bash
  kubeadm join kubeapi.wang.org:6443 --token jizd9o.tjfoyvdoisbklfi5 \
  	--discovery-token-ca-cert-hash sha256:c27e15a7a39394b6d64e419b60df835f9dedb7b015a92c1d9285effa1fbea600 \  # è¿™é‡Œå°±æ˜¯å¼•å¯¼ä»¤ç‰Œ
  	--control-plane --certificate-key 9fa84696a800c6b995a9249972c1dd76735701e5ea2ae05191c9f612a0d1252c --cri-socket=unix:///run/cri-dockerd.sock # åé¢è¿½åŠ  --cri-socket=unix:///run/cri-dockerd.sock
  ```

  

- **é™æ€ä»¤ç‰Œ**
  - å°†ç”¨æˆ·å’Œä»¤ç‰Œå­˜æ”¾äº**æ–‡æœ¬æ–‡ä»¶**ä¸­,å¹¶å¯åŠ¨API Serverè¿›ç¨‹æ—¶åŠ è½½æ­¤æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶å†…å®¹ä¼šç”±API Serverç¼“å­˜äºå†…å­˜ä¸­
  - ç”±kube-apiserveråœ¨å¯åŠ¨æ—¶é€šè¿‡--token-auth-fileé€‰é¡¹åŠ è½½,**é»˜è®¤æ²¡æœ‰åŠ è½½æ­¤é€‰é¡¹**
  - åŠ è½½å®Œæˆåçš„æ–‡ä»¶å˜åŠ¨ï¼Œä»…èƒ½é€šè¿‡é‡å¯ç¨‹åºè¿›è¡Œé‡è½½ï¼Œå› æ­¤ï¼Œç›¸å…³çš„ä»¤ç‰Œä¼šé•¿æœŸæœ‰æ•ˆ
  - å®¢æˆ·ç«¯åœ¨HTTPè¯·æ±‚ä¸­ï¼Œé€šè¿‡â€œ**Authorization Bearer TOKEN**â€æ ‡å¤´é™„å¸¦ä»¤ç‰Œä»¤ç‰Œä»¥å®Œæˆè®¤è¯
  - æ¯”å¦‚åœ¨ä½¿ç”¨kubeletçš„æ—¶å€™ï¼Œéœ€è¦ä¾èµ–çš„tokenæ–‡ä»¶



- **é™æ€å¯†ç **
  - å­˜å‚¨äºAPI Serverè¿›ç¨‹å¯ç›´æ¥åŠ è½½åˆ°çš„æ–‡ä»¶ä¸­ä¿å­˜çš„è´¦æˆ·å’Œå¯†ç ä»¤ç‰Œï¼Œè¯¥æ–‡ä»¶å†…å®¹ä¼šç”±API Server ç¼“å­˜äºå†…å­˜ä¸­
  - æ¯”å¦‚åœ¨ä½¿ç”¨kubeletçš„æ—¶å€™ï¼Œéœ€è¦ä¾èµ–çš„.kube/configæ–‡ä»¶



- **Service Account ä»¤ç‰Œ**
  - æ­¤ä»¤ç‰Œä¸“ç”¨äºServiceAccount
  - ç”¨äºå°†Podè®¤è¯åˆ°API Server ä¸Šï¼Œä»¥æ”¯æŒé›†ç¾¤å†…çš„è¿›ç¨‹ä¸API Serveré€šä¿¡
  - è¯¥è®¤è¯æ–¹å¼å°†ç”±kube-apiserverç¨‹åºå†…ç½®ç›´æ¥å¯ç”¨å®ƒå€ŸåŠ©äºç»è¿‡ç­¾åçš„Bearer Tokenæ¥éªŒè¯è¯·æ±‚
  - ç­¾åæ—¶ä½¿ç”¨çš„å¯†é’¥å¯ä»¥ç”±--service-account-key-fileé€‰é¡¹æŒ‡å®šï¼Œä¹Ÿå¯ä»¥é»˜è®¤ä½¿ç”¨API Serverçš„tlsç§é’¥
  - Kuberneteså¯ä½¿ç”¨ServiceAccountå‡†å…¥æ§åˆ¶å™¨è‡ªåŠ¨ä¸ºPodå…³è”ServiceAccount



- **OIDCä»¤ç‰Œ**
  - OIDC å°±æ˜¯ OpenID Connectï¼Œæ˜¯ä¸€ç§åŠ¨æ€ä»¤ç‰Œ,ä¸»è¦åº”ç”¨äºé›†æˆç¬¬ä¸‰æ–¹è®¤è¯çš„ä¸€ç§é›†ä¸­å¼è®¤è¯æ–¹å¼
  - æ¯”å¦‚: KeyCloak,é€šå¸¸éµå¾ªOAuth 2åè®®ã€‚å°¤å…¶æ˜¯ç¬¬ä¸‰æ–¹äº‘æœåŠ¡å•†çš„è®¤è¯



- **Webhookä»¤ç‰Œ**
  - å¸¸åº”ç”¨äºè§¦å‘ç¬¬ä¸‰æ–¹çš„åŠ¨ä½œæ—¶å€™çš„ä¸€äº›è®¤è¯æœºåˆ¶ï¼Œä¸»è¦ä¾§é‡äºhttpåè®®åœºæ™¯ã€‚





##### é™æ€ä»¤ç‰Œè®¤è¯å®ç°

- **é™æ€ä»¤ç‰Œè®¤è¯çš„é…ç½®è¯´æ˜**

  - ä»¤ç‰Œä¿¡æ¯ä¿å­˜äº**æ ¼å¼ä¸ºCSV**çš„æ–‡æœ¬æ–‡ä»¶ï¼Œæ¯è¡Œå®šä¹‰ä¸€ä¸ªç”¨æˆ·ï¼Œç”±â€œ**ä»¤ç‰Œã€ç”¨æˆ·åã€ç”¨æˆ·IDå’Œæ‰€å±çš„ç”¨æˆ·ç»„**â€å››ä¸ªå­—æ®µç»„æˆï¼Œç”¨æˆ·ç»„ä¸ºå¯é€‰å­—æ®µ

  ```ABAP
  æ ¼å¼: token, user, uid, "group1, group2, ......"
  ```

  - ç”±kube-apiserveråœ¨å¯åŠ¨æ—¶é€šè¿‡--token-auth-fileé€‰é¡¹åŠ è½½
  - åŠ è½½å®Œæˆåå¦‚æœå†æœ‰æ–‡ä»¶å˜åŠ¨ï¼Œéœ€è¦é€šè¿‡é‡å¯kube-apiserverè¿›è¡Œé‡è½½
  - å¯åœ¨å®¢æˆ·ç«¯åœ¨HTTPè¯·æ±‚ä¸­ï¼Œé€šè¿‡â€œAuthorization Bearer TOKENâ€æ ‡å¤´é™„å¸¦ä»¤ç‰Œä»¤ç‰Œä»¥å®Œæˆè®¤è¯



- **é™æ€ä»¤ç‰Œè®¤è¯é…ç½®è¿‡ç¨‹**

  - ç”Ÿæˆtokenï¼Œå‘½ä»¤ï¼šecho "$(openssl rand -hex 3).$(openssl rand -hex 8)"

  ```bash
  echo "$(openssl rand -hex 3).$(openssl rand -hex 8)"  # 3å’Œ8è¡¨ç¤ºçš„å­—èŠ‚æ•°ï¼Œæ•´ä½“æ„æ€æ˜¯3ä¸ªå­—èŠ‚çš„16è¿›åˆ¶æ˜¾ç¤ºçš„éšæœºæ•°
  ```

  - ç”Ÿæˆstatic tokenæ–‡ä»¶
  - é…ç½®kube-apiserveråŠ è½½è¯¥é™æ€ä»¤ç‰Œæ–‡ä»¶ä»¥å¯ç”¨ç›¸åº”çš„è®¤è¯åŠŸèƒ½
  - æµ‹è¯•å‘½ä»¤

  ```bash
  #æ–¹æ³•1
  curl -k -H "Authorization: Bearer $TOKEN"
  https://API_SERVER:6443/api/v1/namespaces/default/pods/
  
  #æ–¹æ³•2
  kubectl --insecure-skip-tls-verify  --token=$TOKEN -s
  https://kubeapi.wang.org:6443 get pod
  
  #è¯´æ˜ï¼š TOKENè¡¨ç¤ºä¸Šé¢ç”¨æˆ·ç”Ÿæˆçš„token 
  ```



**èŒƒä¾‹: åŸºäºé™æ€tokenä»¤ç‰Œå‘API Serveræ·»åŠ è®¤è¯ç”¨æˆ·**

```bash
#åœ¨æ‰€æœ‰MasterèŠ‚ç‚¹ä¸Šé…ç½®ä¸‹é¢è¿‡ç¨‹,å¦‚æœåªæœ‰ä¸€ä¸ªMasterèŠ‚ç‚¹é…ç½®,åªèƒ½è¿æ¥æ­¤MasterèŠ‚ç‚¹æµ‹è¯•
#å‡†å¤‡Tokenæ–‡ä»¶å­˜æ”¾çš„ç‹¬ç«‹ç›®å½•
[root@master1 ~]#mkdir /etc/kubernetes/auth

# åˆ›å»ºé™æ€ä»¤ç‰Œæ–‡ä»¶å¹¶æ·»åŠ ç”¨æˆ·ä¿¡æ¯
[root@master1 auth]#echo "$(openssl rand -hex 3).$(openssl rand -hex 8),wang,1001,ops" > /etc/kubernetes/auth/token.csv
[root@master1 auth]#echo "$(openssl rand -hex 3).$(openssl rand -hex 8),test,1002,dev" >> /etc/kubernetes/auth/token.csv

# æŸ¥çœ‹
[root@master1 auth]#cat /etc/kubernetes/auth/token.csv 
1ec32a.838c37d29a7c43b6,wang,1001,ops
fd3e78.2a0395a1c58fb561,test,1002,dev

#å…ˆå¤‡ä»½é…ç½®æ–‡ä»¶ï¼Œæ³¨æ„ï¼šä¸è¦å°†å¤‡ä»½æ–‡ä»¶æ”¾åœ¨åŸç›®å½•ä¸‹ï¼›
[root@master1 backup]#cp /etc/kubernetes/manifests/kube-apiserver.yaml .

#ç›´æ¥ä¿®æ”¹åŸæ–‡ä»¶
[root@master1 ~]#vim /etc/kubernetes/manifests/kube-apiserver.yaml 
......
  - command:
    - kube-apiserver
    - --advertise-address=10.0.0.200
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --token-auth-file=/etc/kubernetes/auth/token.csv  #æŒ‡å®šå‰é¢åˆ›å»ºæ–‡ä»¶çš„è·¯å¾„
.....
   volumeMounts:
   ......
    - mountPath: /etc/kubernetes/auth                   #æ·»åŠ ä¸‰è¡Œ,å®ç°æ•°æ®å·çš„æŒ‚è½½é…ç½®
     name: static-auth-token
     readOnly: true
 hostNetwork: true
......
 volumes:
 .......
  - hostPath:                                           #æ·»åŠ ä¸‰è¡Œæ•°æ®å·å®šä¹‰
     path: /etc/kubernetes/auth
     type: DirectoryOrCreate
   name: static-auth-token
   
# ä¸Šé¢æ–‡ä»¶ä¿®æ”¹å,Kubernetesä¼šè‡ªåŠ¨é‡å¯åä¸ºkube-apiserver-master1.wang.orgçš„Pod,å¯èƒ½éœ€è¦ç­‰ä¸€ä¼šå„¿æ‰èƒ½å¯åŠ¨æˆåŠŸ
# apiServeré‡å¯æœŸé—´å¯èƒ½æŠ¥é”™ï¼Œè®¿é—®å¯èƒ½æŠ¥é”™ï¼Œéœ€ç­‰å¾…
[root@master1 backup]# kubectl get pod -n kube-system kube-apiserver
The connection to the server master1.mystical.org:6443 was refused - did you specify the right host or port?


# ä¸€æ®µæ—¶é—´åï¼Œé‡å¯æˆåŠŸ
[root@master1 backup]#kubectl get pod -n kube-system kube-apiserver-master1 
NAME                     READY   STATUS    RESTARTS   AGE
kube-apiserver-master1   1/1     Running   0          2m54s


#æŸ¥çœ‹å®¹å™¨æ˜¯å¦åŠ è½½äº†token.csvæ–‡ä»¶
[root@master1 backup]# docker ps |grep api
a8e08a3f681f   56ce0fd9fb53                                        "kube-apiserver --adâ€¦"   33 seconds ago   Up 32 seconds             k8s_kube-apiserver_kube-apiserver-master1_kube-system_a940e438a9aff369d80b49179ee0f235_0
a90cdbbf53f0   registry.aliyuncs.com/google_containers/pause:3.9   "/pause"                  33 seconds ago   Up 32 seconds             k8s_POD_kube-apiserver-master1_kube-system_a940e438a9aff369d80b49179ee0f235_0

[root@master1 backup]# docker inspect a8e08a3f681f |grep -n token.csv
11:            "--token-auth-file=/etc/kubernetes/auth/token.csv",
302:                "--token-auth-file=/etc/kubernetes/auth/token.csv",


#éªŒè¯æ–¹æ³•1:ä½¿ç”¨ä¸Šé¢ä»»æ„ç”¨æˆ·çš„tokenè®¿é—®,æç¤ºç”¨æˆ·wangè¢«ç¦æ­¢è®¿é—®ï¼Œè¯´æ˜ç”¨æˆ·éªŒè¯æˆåŠŸï¼Œåªæ˜¯æƒé™ä¸è¶³
#æ³¨æ„:å¦‚æœåªæ˜¯ä¿®æ”¹ä¸€ä¸‹masterèŠ‚ç‚¹çš„é…ç½®,åªèƒ½è¿æ¥æ­¤èŠ‚ç‚¹æµ‹è¯•,ç¤ºä¾‹: "https://ä¿®æ”¹é…ç½®çš„masterèŠ‚ç‚¹:6443/api/....."

[root@master1 backup]#TOKEN="1ec32a.838c37d29a7c43b6";curl -k -H"Authorization: Bearer $TOKEN" https://10.0.0.201:6443/api/v1/namespaces/default/pods/
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "pods is forbidden: User \"wang\" cannot list resource \"pods\" in API group \"\" in the namespace \"default\"",
  "reason": "Forbidden",
  "details": {
    "kind": "pods"
  },
  "code": 403

# éªŒè¯æ–¹æ³•2:åœ¨workerèŠ‚ç‚¹æ‰§è¡Œ,æç¤ºç”¨æˆ·wangè¢«ç¦æ­¢è®¿é—®ï¼Œè¯´æ˜ç”¨æˆ·éªŒè¯æˆåŠŸï¼Œåªæ˜¯æƒé™ä¸è¶³
#æ³¨æ„:å¦‚æœåªæ˜¯ä¿®æ”¹ä¸€ä¸‹masterèŠ‚ç‚¹çš„é…ç½®,åªèƒ½è¿æ¥æ­¤èŠ‚ç‚¹æµ‹è¯•,ç¤ºä¾‹: -s "https://ä¿®æ”¹é…ç½®çš„masterèŠ‚ç‚¹:6443"

[root@node1 ~]#TOKEN="1ec32a.838c37d29a7c43b6";kubectl -s "https://10.0.0.201:6443" --token="$TOKEN" --insecure-skip-tls-verify=true get pod
Error from server (Forbidden): pods is forbidden: User "wang" cannot list resource "pods" in API group "" in the namespace "default"


# ä½¿ç”¨é”™è¯¯Tokenè®¿é—®ï¼Œè§‚å¯Ÿç»“æœ
[root@master1 backup]#TOKEN="1ec32a.838c37d29a7c43b5";curl -k -H"Authorization: Bearer $TOKEN" https://10.0.0.201:6443/api/v1/namespaces/default/pods/
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "Unauthorized",
  "reason": "Unauthorized",
  "code": 401


#ä¸ä½¿ç”¨Tokenè®¿é—®ï¼Œè§‚å¯Ÿç»“æœï¼Œå³åŒ¿åè®¿é—®
[root@master1 backup]##curl -k https://10.0.0.201:6443/api/v1/namespaces/default/pods/{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "pods is forbidden: User \"system:anonymous\" cannot list resource \"pods\" in API group \"\" in the namespace \"default\"",
  "reason": "Forbidden",
  "details": {
    "kind": "pods"
  },
  "code": 403
}
```



#### Kubeconfigç®¡ç†

kubeconfig æ˜¯YAMLæ ¼å¼çš„æ–‡ä»¶ï¼Œç”¨äºå­˜å‚¨èº«ä»½è®¤è¯ä¿¡æ¯ï¼Œä»¥ä¾¿äºå®¢æˆ·ç«¯åŠ è½½å¹¶è®¤è¯æ¥å…¥åˆ°API Server

kubeconfig ä¿å­˜æœ‰è®¤è¯åˆ°ä¸€æˆ–å¤šä¸ªKubernetesé›†ç¾¤çš„ç›¸å…³é…ç½®ä¿¡æ¯ï¼Œå¹¶å…è®¸ç®¡ç†å‘˜æŒ‰éœ€åœ¨å„é…ç½®é—´çµæ´»åˆ‡æ¢



##### Kubeconfig æ–‡ä»¶æ ¼å¼

KubeconfigåŒ…æ‹¬å¦‚ä¸‹ä¿¡æ¯

![image-20250108105650248](../markdown_img/image-20250108105650248.png)



- **clusters**ï¼šæ¯ä¸ªKubernetesé›†ç¾¤çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬é›†ç¾¤å¯¹åº”è®¿é—®ç«¯ç‚¹ï¼ˆAPI Serverï¼‰çš„åœ°å€
- **users**ï¼šè®¤è¯åˆ°API Serverçš„ç”¨æˆ·çš„èº«ä»½å‡­æ®åˆ—è¡¨
- **contexts**ï¼šå°†æ¯ä¸€ä¸ªuseråŒå¯è®¤è¯åˆ°çš„clusterå»ºç«‹å…³è”å…³ç³»çš„ä¸Šä¸‹æ–‡åˆ—è¡¨
- **current-context**ï¼šå½“å‰é»˜è®¤ä½¿ç”¨çš„context



**å®¢æˆ·ç«¯ç¨‹åºkubectl åŠ è½½çš„kubeconfigæ–‡ä»¶çš„é€”å¾„åŠä»é«˜åˆ°ä½ä¼˜å…ˆçº§æ¬¡åº**



- --kubeconfigé€‰é¡¹,åªæ”¯æŒä¸€ä¸ªæ–‡ä»¶
- KUBECONFIGç¯å¢ƒå˜é‡ï¼šå…¶å€¼æ˜¯åŒ…å«æœ‰kubeconfigæ–‡ä»¶çš„åˆ—è¡¨,æ”¯æŒå¤šä¸ªæ–‡ä»¶,ç”¨å†’å·éš”ç¦»
- é»˜è®¤è·¯å¾„ï¼š$HOME/.kube/config



**é»˜è®¤ /etc/kubernetes/*.conf çš„æ–‡ä»¶éƒ½å±äº Kubeconfig æ–‡ä»¶**

```bash
[root@master1 backup]# ls /etc/kubernetes/*.conf
/etc/kubernetes/admin.conf               /etc/kubernetes/scheduler.conf
/etc/kubernetes/controller-manager.conf  /etc/kubernetes/super-admin.conf
/etc/kubernetes/kubelet.conf

[root@master1 backup]#grep "^[a-z]" /etc/kubernetes/*.conf
/etc/kubernetes/admin.conf: apiVersion: v1
/etc/kubernetes/admin.conf: clusters:
/etc/kubernetes/admin.conf: contexts:
/etc/kubernetes/admin.conf: current-context: kubernetes-admin@kubernetes
/etc/kubernetes/admin.conf: kind: Config
/etc/kubernetes/admin.conf: preferences: {}
/etc/kubernetes/admin.conf: users:

/etc/kubernetes/controller-manager.conf: apiVersion: v1
/etc/kubernetes/controller-manager.conf: clusters:
/etc/kubernetes/controller-manager.conf: contexts:
/etc/kubernetes/controller-manager.conf: current-context: system:kube-controller-manager@kubernetes
/etc/kubernetes/controller-manager.conf: kind: Config
/etc/kubernetes/controller-manager.conf: preferences: {}
/etc/kubernetes/controller-manager.conf: users:

/etc/kubernetes/kubelet.conf: apiVersion: v1
/etc/kubernetes/kubelet.conf: clusters:
/etc/kubernetes/kubelet.conf: contexts:
/etc/kubernetes/kubelet.conf: current-context: system:node:master1@kubernetes
/etc/kubernetes/kubelet.conf: kind: Config
/etc/kubernetes/kubelet.conf: preferences: {}
/etc/kubernetes/kubelet.conf: users:

/etc/kubernetes/scheduler.conf: apiVersion: v1
/etc/kubernetes/scheduler.conf: clusters:
/etc/kubernetes/scheduler.conf: contexts:
/etc/kubernetes/scheduler.conf: current-context: system:kube-scheduler@kubernetes
/etc/kubernetes/scheduler.conf: kind: Config
/etc/kubernetes/scheduler.conf: preferences: {}
/etc/kubernetes/scheduler.conf: users:

/etc/kubernetes/super-admin.conf: apiVersion: v1
/etc/kubernetes/super-admin.conf: clusters:
/etc/kubernetes/super-admin.conf: contexts:
/etc/kubernetes/super-admin.conf: current-context: kubernetes-super-admin@kubernetes
/etc/kubernetes/super-admin.conf: kind: Config
/etc/kubernetes/super-admin.conf: preferences: {}
/etc/kubernetes/super-admin.conf: users:
```



**åˆ©ç”¨kubeconfigå®ç°é›†ç¾¤å¤–ä¸»æœºè®¿é—®é›†ç¾¤èµ„æº**

```bash
#åœ¨é›†ç¾¤å¤–èŠ‚ç‚¹å®‰è£…kubectlå·¥å…·
#æ–¹æ³•1
[root@ubuntu2204 ~]# curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -
Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).
OK

[root@ubuntu2204 ~]# cat << EOF > /etc/apt/sources.list.d/kubernetes.list
> deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
> EOF

# æŸ¥çœ‹
[root@ubuntu2204 ~]# cat /etc/apt/sources.list.d/kubernetes.list 
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main

# æ›´æ–°å…ƒæ•°æ®å¹¶å®‰è£…
[root@ubuntu2204 ~]# apt update &> /dev/null && apt install -y kubectl &> /dev/null


# æ–¹æ³•2ï¼šç›´æ¥å°†masterèŠ‚ç‚¹çš„kubectlç¨‹åºæ–‡ä»¶å¤åˆ¶åˆ°é›†ç¾¤å¤–èŠ‚ç‚¹
[root@ubuntu2204 ~]#scp master1.wang.org:/usr/bin/kubectl /usr/local/bin/
[root@ubuntu2204 ~]#ls -l /usr/local/bin/
total 46904
-rwxr-xr-x 1 root root 48029696 Jul  6 14:23 kubectl
[root@ubuntu2204 ~]#ldd /usr/local/bin/kubectl 
 not a dynamic executable


# å°†ä¸»èŠ‚ç‚¹çš„./kube/configä¼ é€’åˆ°é›†ç¾¤å¤–èŠ‚ç‚¹
[root@master1 ~]# scp .kube/config 10.0.0.131:

# åœ¨é›†ç¾¤å¤–èŠ‚ç‚¹é…ç½®hostsæ–‡ä»¶ä½¿å…¶èƒ½å¤Ÿè§£æconfigä¸­çš„apiServeråœ°å€çš„åŸŸå
echo "10.0.0.201 mater1.mystical.org" >> /etc/hosts

# æ‰§è¡Œkubectlæµ‹è¯•æ˜¯å¦èƒ½å¤Ÿè®¿é—®é›†ç¾¤
[root@ubuntu2204 ~]# kubectl get nodes --kubeconfig=./config
NAME      STATUS   ROLES           AGE    VERSION
master1   Ready    control-plane   4d1h   v1.30.8
node1     Ready    <none>          4d1h   v1.30.8
node2     Ready    <none>          4d1h   v1.30.8
node3     Ready    <none>          4d1h   v1.30.8
```





##### Kubeconfigåˆ›å»ºå’Œç®¡ç†



kubectl config å‘½ä»¤å¯ä»¥åˆ›å»ºå’Œç®¡ç†kubeconfigæ–‡ä»¶

æ‰©å±•å·¥å…·: **kubectx** å’Œ **kubens**

**kubectx** is a tool to switch between contexts (clusters) on kubectl faster.

**kubens** is a tool to switch between Kubernetes namespaces (and configure them for kubectl) easily.



**kubectl config å‘½ä»¤ç”¨æ³•**

```bash
#kubernetes é…ç½®æ–‡ä»¶ç®¡ç†
[root@master1 ~]#kubectl config -h
Modify kubeconfig files using subcommands like "kubectl config set
current-context my-context".

 The loading order follows these rules:
 
 # é…ç½®æ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯
    1 ä½¿ç”¨ --kubeconfig å‚æ•°ç®¡ç†æŸä¸ªæŒ‡å®šçš„é…ç½®æ–‡ä»¶è·¯å¾„
    2 è¯¥æ–‡ä»¶å¯ä»¥ä½¿ç”¨ $KUBECONFIG å˜é‡æ¥ç®¡ç†
    3 å…¶ä»–æƒ…å†µä¸‹ï¼Œé…ç½®æ–‡ä»¶æŒ‡çš„å°±æ˜¯ ${HOME}/.kube/config 
   ä¼˜å…ˆçº§ï¼š 1 > 2 > 3

  1.  If the --kubeconfig flag is set, then only that file is loaded. The flag
may only be set once and no merging takes place.

  2.  If $KUBECONFIG environment variable is set, then it is used as a list of
paths (normal path delimiting rules for your system). These paths are merged.
When a value is modified, it is modified in the file that defines the stanza.
When a value is created, it is created in the first file that exists. If no
files in the chain exist, then it creates the last file in the list.

  3.  Otherwise, ${HOME}/.kube/config is used and no merging takes place.


Available Commands:
  current-context   Display the current-context
  delete-cluster    ä» kubeconfig ä¸­åˆ é™¤æŒ‡å®šçš„é›†ç¾¤
  delete-context    ä» kubeconfig ä¸­åˆ é™¤æŒ‡å®šçš„ä¸Šä¸‹æ–‡
  delete-user       Delete the specified user from the kubeconfig
  get-clusters      æ˜¾ç¤ºåœ¨ kubeconfig ä¸­å®šä¹‰çš„é›†ç¾¤
  get-contexts      æè¿°ä¸€ä¸ªæˆ–å¤šä¸ªä¸Šä¸‹æ–‡
  get-users         Display users defined in the kubeconfig
  rename-context    Rename a context from the kubeconfig file
  set               Set an individual value in a kubeconfig file
  set-cluster       Set a cluster entry in kubeconfig
  set-context       Set a context entry in kubeconfig
  set-credentials   Set a user entry in kubeconfig
  unset             Unset an individual value in a kubeconfig file
  use-context       Set the current-context in a kubeconfig file
  view              æ˜¾ç¤ºåˆå¹¶çš„ kubeconfig é…ç½®æˆ–ä¸€ä¸ªæŒ‡å®šçš„ kubeconfig æ–‡ä»¶

Usage:
  kubectl config SUBCOMMAND [options]

# é›†ç¾¤ç›¸å…³
  delete-cluster
  set-cluster
  get-clusters
  
# ç”¨æˆ·ç›¸å…³
  set-credentials
  get-users
  delete-user
  
# ä¸Šä¸‹æ–‡ç›¸å…³
  delete-context
  get-contexts
  set-context
  rename-context
  
# current-contextç›¸å…³å­å‘½ä»¤
  user-context
  current-context

# æŸ¥çœ‹
  view
  
#ç»“æœæ˜¾ç¤ºï¼šå¯¹äºä¸€ä¸ªç”¨æˆ·è´¦å·ï¼Œè‡³å°‘åŒ…å«ä¸‰éƒ¨åˆ†ï¼š
1.ç”¨æˆ·æ¡ç›®-credentials è®¾å®šå…·ä½“çš„user accountåç§°
2.é›†ç¾¤-cluster è®¾å®šè¯¥user accountæ‰€å·¥ä½œçš„åŒºåŸŸ
3.ä¸Šä¸‹æ–‡ç¯å¢ƒ-context è®¾å®šç”¨æˆ·å’Œé›†ç¾¤çš„å…³ç³»
```



**åˆ›å»ºå’Œä½¿ç”¨kubeconfigæµç¨‹**

```bash
# 1) åœ¨kubeconfigä¸­æ·»åŠ é›†ç¾¤ä¿¡æ¯
# éœ€æŒ‡å®š3ä¸ªé‡è¦ä¿¡æ¯
# 1. Kubernetesé›†ç¾¤çš„CAè¯ä¹¦ä¿¡æ¯
# 2. apiServerçš„IPåœ°å€
# 3. æŒ‡å®šç”Ÿæˆçš„configæ–‡ä»¶æ‰€åœ¨è·¯å¾„
[root@node1 ~]# kubectl config set-cluster mykube --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server="https://10.0.0.201:6443" --kubeconfig=$HOME/.kube/mykube.conf
Cluster "mykube" set.

# æŸ¥çœ‹æ–‡ä»¶
[root@node1 ~]#ls .kube/
cache  mykube.conf

[root@node1 ~]#cat .kube/mykube.conf 
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJRmQ2UW5LYmkzK2t3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TlRBeE1EUXdNVE01TURaYUZ3MHpOVEF4TURJd01UUTBNRFphTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUURObjZibnVuWVZkV1kvQ1JPczVIaGE0TE8zYk81dEtZRlNOMnNYQ2pERXYyM0VWRTVDTE9qMmJlblkKRUt4YUcrdHR2UFJqWWpQUkZCWldjOFFJcmdQc2gzWHI4YzRHNFVMU1grdkJhdEdhVFhpSU9DQXNSRUxRcUExcgpXajkvZ0hrZlRvQlRCY2J5M0xEbms5RFJ3SXR4SXJYSTFxUUJLL2VLRmNFOVlBaG93YkpBK2I3TTJ3SHlPdFg2CmVnV09WVWRDQjRzN05qZHAvYytDamJXeStUYTBmbDQ4RVM4VHFFY3kxUXMvYXMybjAxOFdJei80TExDazFYSmwKTFdDRlJrOE5BOTVIcVZQbkRmVWVLK3RaSXpBS0dFbVpuM290RXNPdHgzanJBV2ZxbjV5UzVDVEZFZlRBU2FpWApFL3k4eFZrSzREQi8xNlFGSXM1cVBVSzVSMkhYQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJUV3ErNlE4TndTcjJCV3lvMUZxZnNaMWFoTWV6QVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQzRLOHRLaktMQQpUMWJaV1NHTmlGZStEVGRKZEx0NlEyRkdaTUdCT3Yyc04ybXhJZDJzMW1rSHFCbEJzQ1JEcDdpRXdwVE1EcWtjCjlJdWEzcG1hdDAxMWJZMVZmNUF6aktiVVYzYlplSXJUWWkrSEtZWThCWnZ2WTVUcDJOdTBOUjk5NkJjSE5zRWsKdlhCSS9JcmlOd0swUHZqRTNVeGFlMUx4T2MvcjdyZWI5bVZQSTlXYWorVDY3KzZZS3BhTHBYWXQ0dGFMWDFBOQpiU1lGekdFVzZqRFpJSG9hSDFxTDNXcGRud2VMcThldjRCV0dmdURHNUltY0tibHUrT3crNjRUZ05taC9oNk9CClVFa0FDQThqQVR4R2g4eEtQZFBtRHFNbEdET0kvOXVkc2U2b1E2QW40c1k2RldTb2NUYjEyWU1TUDVjbkhVa0sKTERhR0tWRUhmUFllCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://10.0.0.201:6443         # apiServeråœ°å€
  name: mykube
contexts: null
current-context: ""
kind: Config
preferences: {}
users: null

# 2) åœ¨kubeconfigä¸­æ·»åŠ ç”¨æˆ·å‡­è¯
# æ–¹å¼1ï¼šX509æ•°å­—è¯ä¹¦è®¤è¯
[root@node1 ~]# kubectl config set-credentials wang --embed-certs=true --client-certificate=pki/wang.crt --client-key=pki/wang.key --kubeconfig=$HOME/.kube/mykube.conf
User "wang" set.

# æŸ¥çœ‹
[root@node1 ~]#cat .kube/mykube.conf 
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJRmQ2UW5LYmkzK2t3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TlRBeE1EUXdNVE01TURaYUZ3MHpOVEF4TURJd01UUTBNRFphTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUURObjZibnVuWVZkV1kvQ1JPczVIaGE0TE8zYk81dEtZRlNOMnNYQ2pERXYyM0VWRTVDTE9qMmJlblkKRUt4YUcrdHR2UFJqWWpQUkZCWldjOFFJcmdQc2gzWHI4YzRHNFVMU1grdkJhdEdhVFhpSU9DQXNSRUxRcUExcgpXajkvZ0hrZlRvQlRCY2J5M0xEbms5RFJ3SXR4SXJYSTFxUUJLL2VLRmNFOVlBaG93YkpBK2I3TTJ3SHlPdFg2CmVnV09WVWRDQjRzN05qZHAvYytDamJXeStUYTBmbDQ4RVM4VHFFY3kxUXMvYXMybjAxOFdJei80TExDazFYSmwKTFdDRlJrOE5BOTVIcVZQbkRmVWVLK3RaSXpBS0dFbVpuM290RXNPdHgzanJBV2ZxbjV5UzVDVEZFZlRBU2FpWApFL3k4eFZrSzREQi8xNlFGSXM1cVBVSzVSMkhYQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJUV3ErNlE4TndTcjJCV3lvMUZxZnNaMWFoTWV6QVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQzRLOHRLaktMQQpUMWJaV1NHTmlGZStEVGRKZEx0NlEyRkdaTUdCT3Yyc04ybXhJZDJzMW1rSHFCbEJzQ1JEcDdpRXdwVE1EcWtjCjlJdWEzcG1hdDAxMWJZMVZmNUF6aktiVVYzYlplSXJUWWkrSEtZWThCWnZ2WTVUcDJOdTBOUjk5NkJjSE5zRWsKdlhCSS9JcmlOd0swUHZqRTNVeGFlMUx4T2MvcjdyZWI5bVZQSTlXYWorVDY3KzZZS3BhTHBYWXQ0dGFMWDFBOQpiU1lGekdFVzZqRFpJSG9hSDFxTDNXcGRud2VMcThldjRCV0dmdURHNUltY0tibHUrT3crNjRUZ05taC9oNk9CClVFa0FDQThqQVR4R2g4eEtQZFBtRHFNbEdET0kvOXVkc2U2b1E2QW40c1k2RldTb2NUYjEyWU1TUDVjbkhVa0sKTERhR0tWRUhmUFllCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://10.0.0.201:6443
  name: mykube
contexts: null
current-context: ""
kind: Config
preferences: {}
users:
- name: wang
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUR6RENDQXJRQ0ZGY3lqanV6VXpFUmVXcVV4MkNmVkpYcDJSTFhNQTBHQ1NxR1NJYjNEUUVCQ3dVQU1CVXgKRXpBUkJnTlZCQU1UQ210MVltVnlibVYwWlhNd0hoY05NalV3TVRBM01UTXdNakU1V2hjTk16VXdNVEExTVRNdwpNakU1V2pBd01RMHdDd1lEVlFRRERBUjNZVzVuTVI4d0hRWURWUVFLREJacmRXSmxZV1J0T21Oc2RYTjBaWEl0CllXUnRhVzV6TUlJQ0lqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQ0FnOEFNSUlDQ2dLQ0FnRUFyaDVoL1NOWDdSZHEKem04UzB1UUUwKzFRNkI3dklmQm5QK0xWbWkvS0crVHB5N0YwKzM1K2dsNy80NCsvc1RmcFR1SlNEYVh6VTVydwpOd3NyNlNqV2o3NVlYOCtBSVlja0VWVVNwS3hwUkJ0ZDJjbENUanF3bTVHZ21EUk1Ca1ptNzl1S1NmdmZKZnZqCjF5M3U1Q0lhTmNjZWJia29TdUZXeUtxWHQwcEM5WTFDTWhpV0FoNjFJRVU5UFZjSURqK0JoNjNSNS8yOXJSZHEKTk52ZlNuYUY0c2dVL09wRTZXd3lMdUQ4aVhLdFBMeUExa0tpbE5RaWlsS0NFbm13RmxLNVk5N3EwQU45RElRbgpmbStleGhDTnRwdHhvU3R6OXE1aHM2QWUvK041azBKZDQ1Q0dUZm5NbzMvYjE4SDdxSGlvaVlvUXNEaitlWkt3Ck9ua3A0YmVDZXAyZGZxNDlKcG1FOGprY0FUd2NtMFJoVFlUbG5IZ1crZWczSjV3SkRhT2RGRlVUQ29rOUhIS0kKMy9UMzVwdnZaNWRLcXJKYjJHajdFT210bUp5MGowQ2YvaVB1QkxBK0lwbm12NGg3TmFjaDAwb0p2LytBV3pUegpHOGRTcWhHMWR1ekFNOG9uZlBiU292Y0ZaYmZmSUhPSEpydlVxdkF1Y25aanNCQnFTbmt0d2U3L05hbWU0WDk5ClVZVU9TNVBHVGdBWG1WaUEyb1NpOWxaSnB4czVBZkhwUllKenpQRlFNZnFxS2o1VUhaV0ZzSW5JR25rTm5XcEkKNWtRcWZMUFNvSGVVQmp2TytqU3pLSnZyeTBJTGtyZmgzRHN0THlYV3kyK0pnaFQrUFprT0J5RnZma1VBVlpKRgpsUUtuN0czZlZXYmxDeUdOU0NjaHB0Z3FnNmxBVjBzQ0F3RUFBVEFOQmdrcWhraUc5dzBCQVFzRkFBT0NBUUVBCkpRdGRsblQvRm5PRklDeFY3NDFJNHRRT1dROEhWdVU4Y1F6eDV2b3FtZmU1OStZbUJxT2FPMjcxS0c2akVGMEsKTzM4RmNLVEltTGRhaHdXRkNWSkROV1B4cmFtM2FxUHoveXkxd0VXMkY1c0lSZ004VzAwc0tzTnNpMlR3MjJZawpiQ0NkUWYrZnhLTkh4TXJpS2FoYXYvNXFkWHA5elRkUFRLU1E2U0tTQm9Jd2NCYk1lTWZPWU1WZDdoSmJBdHFMCkh5ZmNOMkdHMW9LSjhMRDBrU1FHa1h2eEZQNFR6WThUenlEcnVFN0laMkJ3V0s1VFdlWXFXUTVXNjBNMnFMYncKLzlBMHJsMFhEM0hHZStpVkd3UWdYWXkxaWhhOUZaSUpTb3lVLzJhd2MvU3pENkFTWkFGNGpLOXZxa29iTHdjdgpQdTQzUmJicFl2WXJPNU9qakxWdm13PT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    client-key-data: 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
    
# æŸ¥çœ‹è¯ä¹¦
[root@node1 ~]#echo "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUR6RENDQXJRQ0ZGY3lqanV6VXpFUmVXcVV4MkNmVkpYcDJSTFhNQTBHQ1NxR1NJYjNEUUVCQ3dVQU1CVXgKRXpBUkJnTlZCQU1UQ210MVltVnlibVYwWlhNd0hoY05NalV3TVRBM01UTXdNakU1V2hjTk16VXdNVEExTVRNdwpNakU1V2pBd01RMHdDd1lEVlFRRERBUjNZVzVuTVI4d0hRWURWUVFLREJacmRXSmxZV1J0T21Oc2RYTjBaWEl0CllXUnRhVzV6TUlJQ0lqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQ0FnOEFNSUlDQ2dLQ0FnRUFyaDVoL1NOWDdSZHEKem04UzB1UUUwKzFRNkI3dklmQm5QK0xWbWkvS0crVHB5N0YwKzM1K2dsNy80NCsvc1RmcFR1SlNEYVh6VTVydwpOd3NyNlNqV2o3NVlYOCtBSVlja0VWVVNwS3hwUkJ0ZDJjbENUanF3bTVHZ21EUk1Ca1ptNzl1S1NmdmZKZnZqCjF5M3U1Q0lhTmNjZWJia29TdUZXeUtxWHQwcEM5WTFDTWhpV0FoNjFJRVU5UFZjSURqK0JoNjNSNS8yOXJSZHEKTk52ZlNuYUY0c2dVL09wRTZXd3lMdUQ4aVhLdFBMeUExa0tpbE5RaWlsS0NFbm13RmxLNVk5N3EwQU45RElRbgpmbStleGhDTnRwdHhvU3R6OXE1aHM2QWUvK041azBKZDQ1Q0dUZm5NbzMvYjE4SDdxSGlvaVlvUXNEaitlWkt3Ck9ua3A0YmVDZXAyZGZxNDlKcG1FOGprY0FUd2NtMFJoVFlUbG5IZ1crZWczSjV3SkRhT2RGRlVUQ29rOUhIS0kKMy9UMzVwdnZaNWRLcXJKYjJHajdFT210bUp5MGowQ2YvaVB1QkxBK0lwbm12NGg3TmFjaDAwb0p2LytBV3pUegpHOGRTcWhHMWR1ekFNOG9uZlBiU292Y0ZaYmZmSUhPSEpydlVxdkF1Y25aanNCQnFTbmt0d2U3L05hbWU0WDk5ClVZVU9TNVBHVGdBWG1WaUEyb1NpOWxaSnB4czVBZkhwUllKenpQRlFNZnFxS2o1VUhaV0ZzSW5JR25rTm5XcEkKNWtRcWZMUFNvSGVVQmp2TytqU3pLSnZyeTBJTGtyZmgzRHN0THlYV3kyK0pnaFQrUFprT0J5RnZma1VBVlpKRgpsUUtuN0czZlZXYmxDeUdOU0NjaHB0Z3FnNmxBVjBzQ0F3RUFBVEFOQmdrcWhraUc5dzBCQVFzRkFBT0NBUUVBCkpRdGRsblQvRm5PRklDeFY3NDFJNHRRT1dROEhWdVU4Y1F6eDV2b3FtZmU1OStZbUJxT2FPMjcxS0c2akVGMEsKTzM4RmNLVEltTGRhaHdXRkNWSkROV1B4cmFtM2FxUHoveXkxd0VXMkY1c0lSZ004VzAwc0tzTnNpMlR3MjJZawpiQ0NkUWYrZnhLTkh4TXJpS2FoYXYvNXFkWHA5elRkUFRLU1E2U0tTQm9Jd2NCYk1lTWZPWU1WZDdoSmJBdHFMCkh5ZmNOMkdHMW9LSjhMRDBrU1FHa1h2eEZQNFR6WThUenlEcnVFN0laMkJ3V0s1VFdlWXFXUTVXNjBNMnFMYncKLzlBMHJsMFhEM0hHZStpVkd3UWdYWXkxaWhhOUZaSUpTb3lVLzJhd2MvU3pENkFTWkFGNGpLOXZxa29iTHdjdgpQdTQzUmJicFl2WXJPNU9qakxWdm13PT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=" |base64 -d|openssl x509 -noout -text
Certificate:
    Data:
        Version: 1 (0x0)
        Serial Number:
            57:32:8e:3b:b3:53:31:11:79:6a:94:c7:60:9f:54:95:e9:d9:12:d7
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN = kubernetes
        Validity
            Not Before: Jan  7 13:02:19 2025 GMT
            Not After : Jan  5 13:02:19 2035 GMT
        Subject: CN = wang, O = kubeadm:cluster-admins    # ç®¡ç†å‘˜ç»„
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (4096 bit)
                Modulus:
                ......
                
# æ–¹æ³•2ï¼šé™æ€ä»¤ç‰Œè®¤è¯
kubectl config set-credentials wang --token="xxxxxxx" -- kubeconfig=$HOME/.kube/mykube.conf

# 3) åœ¨kubeconfigä¸­æ·»åŠ context,å®ç°é›†ç¾¤å’Œç”¨æˆ·å…³è”
[root@node1 ~]# kubectl config set-context wang@mykube --cluster=mykube --user=wang --kubeconfig=$HOME/.kube/mykube.conf
Context "wang@mykube" created.

# ä½¿ç”¨æŒ‡å®šçš„contextè®¿é—®é›†ç¾¤
[root@node1 ~]#kubectl get ns --context="wang@mykube"  --kubeconfig=.kube/mykube.conf
NAME              STATUS   AGE
default           Active   4d2h
ingress-nginx     Active   4d
kube-flannel      Active   4d2h
kube-node-lease   Active   4d2h
kube-public       Active   4d2h
kube-system       Active   4d2h
metallb-system    Active   4d

# è®¾ç½®é»˜è®¤context
[root@node1 ~]#kubectl config use-context wang@mykube --kubeconfig=.kube/mykube.conf
Switched to context "wang@mykube".

# æŸ¥çœ‹
[root@node1 ~]#kubectl get nodes --kubeconfig=.kube/mykube.conf
NAME      STATUS   ROLES           AGE    VERSION
master1   Ready    control-plane   4d2h   v1.30.8
node1     Ready    <none>          4d2h   v1.30.8
node2     Ready    <none>          4d2h   v1.30.8
node3     Ready    <none>          4d2h   v1.30.8

# æŸ¥çœ‹kubeconfigå†…å®¹
[root@node1 ~]#kubectl config view --kubeconfig=.kube/mykube.conf --raw


# ä½¿ç”¨kubeconfigæ€»ç»“
1)kubectl get pods --kubeconfig=$HOME/.kube/mykube.conf
2)export KUBECONFIG="$HOME/.kube/mykube.conf"; kubectl get pods 
3)kubectl get pods 
```



**æŸ¥çœ‹é»˜è®¤çš„kubeconfigé…ç½®å†…å®¹**

```bash
# æŸ¥çœ‹é»˜è®¤çš„é…ç½®æ–‡ä»¶å†…å®¹
[root@master1 ~]# kubectl config view
apiVersion: v1
clusters:                                                  # é›†ç¾¤åˆ—è¡¨
- cluster:
    certificate-authority-data: DATA+OMITTED               # è¯ä¹¦è®¤è¯æ–¹å¼
    server: https://master1.mystical.org:6443              # api_serverçš„åœ°å€
  name: kubernetes                                         # å½“å‰é›†ç¾¤åç§°
contexts:                                                  # ä¸Šä¸‹æ–‡åˆ—è¡¨ï¼Œä¸€èˆ¬æŒ‡çš„æ˜¯å¤šé›†ç¾¤é—´ç”¨æˆ·çš„åˆ‡æ¢æ‰€éœ€çš„ç¯å¢ƒå±æ€§
- context:
    cluster: kubernetes                                    # é›†ç¾¤åç§°ï¼škubernetes
    user: kubernetes-admin                                 # ä½¿ç”¨kubernetes-adminç”¨æˆ·æ¥è®¿é—®é›†ç¾¤kubernetes
  name: kubernetes-admin@kubernetes                        # è¯¥contextçš„åç§°æ ‡å‡†å†™æ³•
current-context: kubernetes-admin@kubernetes               # å½“å‰æ­£åœ¨ä½¿ç”¨çš„ä¸Šä¸‹æ–‡çš„åç§°
kind: Config
preferences: {}
users:                                                     # ç”¨æˆ·åˆ—è¡¨
- name: kubernetes-admin                                   # ç”¨æˆ·åç§°
  user:                                                    # ç”¨æˆ·è‡ªå·±è®¤è¯å±æ€§
    client-certificate-data: DATA+OMITTED                  # å®¢æˆ·ç«¯è¯ä¹¦
    client-key-data: DATA+OMITTED                          # å®¢æˆ·ç«¯ç§é’¥

# ç»“æœæ€»ç»“
# ä¸€ä¸ªconfigä¸»è¦åŒ…å«äº†ä¸‰éƒ¨åˆ†å†…å®¹ï¼šusersã€clustersã€contextsï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰ä¸¤éƒ¨åˆ†ç»„æˆï¼š
# nameå’Œuser|cluster|context
# å¯¹äºclusterï¼Œå¯¹å¤–çš„åœ°å€-server å’Œ åŸºæœ¬çš„è®¤è¯æ–¹å¼-certificate-authority-data
# å¯¹äºcontextï¼Œè¿æ¥åˆ°çš„é›†ç¾¤-cluster å’Œ è¿æ¥é›†ç¾¤çš„ç”¨æˆ·-user
# å¯¹äºuserï¼Œè¿æ¥é›†ç¾¤çš„è®¤è¯æ–¹å¼-client-certificate-data å’Œ ç§é’¥ä¿¡æ¯-client-key-data
# current-contextè¡¨æ˜æˆ‘ä»¬æ˜¯å¤„äºå“ªä¸€ä¸ªç¯å¢ƒä¸­ã€‚
```



##### åˆå¹¶å¤šä¸ªkubeconfigæ–‡ä»¶

å®¢æˆ·ç«¯èƒ½å¤Ÿé€šè¿‡å¤šç§é€”å¾„è·å–åˆ°kubeconfigæ–‡ä»¶æ—¶ï¼Œå°†éµå¾ªå¦‚ä¸‹ä¼˜å…ˆçº§é¡ºåºè¿›è¡Œæ–‡ä»¶åˆå¹¶

- è®¾ç½®äº†**--kubeconfigå‚æ•°**æ—¶ï¼Œåˆ™ä»…ä½¿ç”¨æŒ‡å®šçš„æ–‡ä»¶ï¼Œä¸”ä¸è¿›è¡Œåˆå¹¶ï¼›è¯¥å‚æ•°åªèƒ½ä½¿ç”¨ä¸€æ¬¡ï¼Œå³**ä¸æ”¯æŒå¤šä¸ªæ–‡ä»¶åˆå¹¶**
- è‹¥è®¾ç½®äº†**KUBECONFIGç¯å¢ƒå˜é‡**ï¼Œåˆ™**å¯ä»¥æŒ‡å®šç”¨å†’å·åˆ†éš”çš„å¤šä¸ªæ–‡ä»¶**ï¼Œ**è¿›è¡Œåˆå¹¶å¤„ç†è§„åˆ™**
  - å¿½ç•¥ä¸å­˜åœ¨çš„æ–‡ä»¶
  - é‡åˆ°å†…å®¹æ— æ³•ååºåˆ—åŒ–çš„æ–‡ä»¶æ—¶ï¼Œå°†ç”Ÿæˆé”™è¯¯ä¿¡æ¯
  - æ–‡ä»¶åˆ—è¡¨ä¸­ï¼Œç¬¬ä¸€ä¸ªè®¾å®šäº†ç‰¹å®šå€¼æˆ–æ˜ å°„é”®(map key)çš„æ–‡ä»¶æ˜¯ä¸ºç”Ÿæ•ˆæ–‡ä»¶ï¼Œå³**ç¬¬ä¸€ä¸ªæ–‡ä»¶ä¼˜å…ˆç”Ÿæ•ˆ**
    - ä¿®æ”¹æŸä¸ªæ˜ å°„é”®çš„å€¼æ—¶ï¼Œå°†ä¿®æ”¹åˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªå‡ºç°è¯¥é”®çš„æ–‡ä»¶ä¸­çš„å†…å®¹
    - åˆ›å»ºä¸€ä¸ªé”®æ—¶ï¼Œå…¶å°†ä¿å­˜äºåˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶ä¸­
    - è‹¥åˆ—è¡¨ä¸­æŒ‡å®šçš„æ–‡ä»¶å‡ä¸å­˜åœ¨æ—¶ï¼Œåˆ™è‡ªåŠ¨åˆ›å»ºåˆ—è¡¨ä¸­çš„æœ€åä¸€ä¸ªæ–‡ä»¶
- å°†ä½¿ç”¨é»˜è®¤çš„${HOME}/**.kube/config**ï¼Œä¸”**ä¸è¿›è¡Œåˆå¹¶**

```ABAP
ä»¥ä¸Šè¯´æ˜: åªæœ‰KUBECONFIGå˜é‡ä¸€ç§æ–¹å¼æ‰æ”¯æŒåˆå¹¶å¤šä¸ªkubeconfigæ–‡ä»¶
```



**åˆ©ç”¨KUBECONFIGå˜é‡åˆå¹¶å¤šä¸ªæ–‡ä»¶**

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
[root@node1 ~]#export KUBECONFIG="/root/.kube/config:/root/.kube/mykube.conf"

# æŸ¥çœ‹
[root@node1 ~]#kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://master1.mystical.org:6443
  name: kubernetes
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://10.0.0.201:6443
  name: mykube
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
  name: kubernetes-admin@kubernetes
- context:
    cluster: mykube
    user: wang
  name: wang@mykube
current-context: kubernetes-admin@kubernetes           # é»˜è®¤å·¦è¾¹çš„æ–‡ä»¶ç”Ÿæ•ˆ
kind: Config
preferences: {}
users:
- name: kubernetes-admin
  user:
    client-certificate-data: DATA+OMITTED
    client-key-data: DATA+OMITTED
- name: wang
  user:
    client-certificate-data: DATA+OMITTED
    client-key-data: DATA+OMITTED
    
    
#ä½¿ç”¨å½“å‰contextèº«ä»½kubernetes-admin@kubernetesè®¿é—®
[root@node1 ~]# kubectl get nodes
NAME      STATUS   ROLES           AGE    VERSION
master1   Ready    control-plane   4d4h   v1.30.8
node1     Ready    <none>          4d4h   v1.30.8
node2     Ready    <none>          4d4h   v1.30.8
node3     Ready    <none>          4d4h   v1.30.8
```



#### User Account ç»¼åˆæ¡ˆä¾‹



##### UAåˆ›å»ºæµç¨‹

ä»¥åŸºäºX509çš„å®¢æˆ·ç«¯ä¸ºä¾‹,ç”¨æˆ·è®¤è¯çš„åˆ›å»ºæµç¨‹

**åˆ›å»ºè¯ä¹¦**

- åˆ›å»ºç§é’¥æ–‡ä»¶
  - å¯¹äºç”¨æˆ·åå’Œç”¨æˆ·ç»„éœ€è¦æå‰è§„åˆ’å¥½ï¼Œå¦‚æœç”¨æˆ·å¤šæƒé™é›†ä¸­çš„æƒ…å†µä¸‹ï¼Œä¸€å®šè¦è§„åˆ’å¥½ç”¨æˆ·ç»„ä¿¡æ¯
- åŸºäºç§é’¥æ–‡ä»¶åˆ›å»ºè¯ä¹¦ç­¾åè¯·æ±‚
  - è¦åŸºäºæˆ‘ä»¬è‡ªå»ºçš„ç§é’¥æ¥åˆ›å»ºç­¾è¯è¯·æ±‚æ–‡ä»¶
- åŸºäºç§é’¥å’Œç­¾åè¯·æ±‚ç”Ÿæˆè¯ä¹¦æ–‡ä»¶
  - å› ä¸ºç”Ÿæˆçš„è¯ä¹¦è¦åº”ç”¨åœ¨kubernetesç¯å¢ƒä¸­ï¼Œæ‰€ä»¥å¿…é¡»ç”±kubernetesçš„å…¨å±€è¯ä¹¦æ¥è®¤è¯



**åˆ›å»ºuser**

- åŸºäºè¯ä¹¦æ–‡ä»¶åœ¨k8sä¸Šåˆ›å»ºç”¨æˆ· credentials

  ```bash
  kubectl config set-credentials wang --embed-certs=true --client-certificate=pki/wang.crt --client-key=pki/wang.key --kubeconfig=$HOME/.kube/mykube.conf
  ```



**åˆ›å»ºCluster**

- åˆ›å»ºå·¥ä½œåŒºåŸŸ-cluster

  - æ‰€è°“çš„å·¥ä½œåŒºåŸŸæ˜¯ç”¨æˆ·çš„å·¥ä½œåœºæ™¯ï¼Œå¿…é¡»å®šåˆ¶å¥½ï¼Œä¸€ä¸ªclusterå¯ä»¥è¢«å¤šä¸ªç”¨æˆ·ä½¿ç”¨

  ```bash
  kubectl config set-cluster mykube --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server="https://10.0.0.201:6443" --kubeconfig=$HOME/.kube/mykube.conf
  ```

  

**å…³è” user å’Œ cluster**

- å°†clusterå’Œuserå…³è”èµ·æ¥-context

- å…³è”çš„ä½œç”¨å°±æ˜¯ï¼Œå°†ç”¨æˆ·å’ŒåŒºåŸŸæ•´åˆåœ¨ä¸€èµ·ï¼Œä½¿ç”¨èµ„æºçš„æ—¶å€™ä¾¿äºè°ƒç”¨

  ```bash
  kubectl config set-context wang@mykube --cluster=mykube --user=wang --kubeconfig=$HOME/.kube/mykube.conf
  ```

  

**éªŒè¯ç”¨æˆ·**

- å› ä¸ºå‰é¢åªåšäº†è®¤è¯ï¼Œè€Œç”¨æˆ·çš„æ“ä½œæ¶‰åŠåˆ°èµ„æºæƒé™ï¼Œè¿™éƒ¨åˆ†æ˜¯éœ€è¦ç»“åˆæˆæƒæœºåˆ¶æ‰èƒ½è¿›è¡Œ
- é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœå¦å¤–çš„æ²¡æœ‰æˆæƒ, åŸºäºåˆ›å»ºå¥½çš„æ–‡ä»¶æ¥è·å–èµ„æºæ˜¯è¢«forbiddençš„





#####  åˆ›å»ºç§é’¥æ–‡ä»¶

```bash
# ç»™ç”¨æˆ·fengåˆ›å»ºä¸€ä¸ªç§é’¥ï¼Œå‘½åæˆï¼šfeng.keyï¼ˆæ— åŠ å¯†ï¼‰
[root@master1 ~]# (umask 077; openssl genrsa -out pki/feng.key 2048)

#å‘½ä»¤è§£æï¼š
#    genrsa è¯¥å­å‘½ä»¤ç”¨äºç”ŸæˆRSAç§é’¥ï¼Œä¸ä¼šç”Ÿæˆå…¬é’¥ï¼Œå› ä¸ºå…¬é’¥æå–è‡ªç§é’¥
#    -out filename ç”Ÿæˆçš„ç§é’¥ä¿å­˜è‡³filenameæ–‡ä»¶ï¼Œè‹¥æœªæŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œåˆ™ä¸ºæ ‡å‡†è¾“å‡º
#    -numbits æŒ‡å®šç§é’¥çš„é•¿åº¦ï¼Œé»˜è®¤1024ï¼Œè¯¥é¡¹å¿…é¡»ä¸ºå‘½ä»¤è¡Œçš„æœ€åä¸€é¡¹å‚æ•°

# æŸ¥çœ‹
[root@master1 ~]# ls pki/
admin.crt  feng.key      mystical.key                             test2.csr  wang.csr
admin.csr  mystical.crt  security-certificaterequests-test2.yaml  test2.key  wang.key
admin.key  mystical.csr  test2.crt 
```



#####  ç­¾åè¯·æ±‚

```bash
# ç”¨åˆšåˆ›å»ºçš„ç§é’¥åˆ›å»ºä¸€ä¸ªè¯ä¹¦ç­¾åè¯·æ±‚æ–‡ä»¶ï¼šfeng.csr
[root@master1 ~]#openssl req -new -key pki/feng.key -out feng.csr -subj "/CN=feng/O=kubeadm:cluster-admins"

#å‚æ•°è¯´æ˜ï¼š
    -new ç”Ÿæˆè¯ä¹¦è¯·æ±‚æ–‡ä»¶
    -key   æŒ‡å®šå·²æœ‰çš„ç§˜é’¥æ–‡ä»¶ç”Ÿæˆç­¾åè¯·æ±‚ï¼Œå¿…é¡»ä¸-newé…åˆä½¿ç”¨
    -out è¾“å‡ºè¯ä¹¦æ–‡ä»¶åç§°
    -subj è¾“å…¥è¯ä¹¦æ‹¥æœ‰è€…ä¿¡æ¯ï¼Œè¿™é‡ŒæŒ‡å®š CN ä»¥åŠ O çš„å€¼ï¼Œ/è¡¨ç¤ºå†…å®¹åˆ†éš”
           CNä»¥åŠOçš„å€¼å¯¹äºkuberneteså¾ˆé‡è¦ï¼Œå› ä¸ºkubernetesä¼šä»è¯ä¹¦è¿™ä¸¤ä¸ªå€¼å¯¹åº”è·å–ç›¸å…³ä¿¡æ¯ï¼š
       "CN"ï¼šCommon Nameï¼Œç”¨äºä»è¯ä¹¦ä¸­æå–è¯¥å­—æ®µä½œä¸ºè¯·æ±‚çš„ç”¨æˆ·å (User Name)ï¼›æµè§ˆå™¨ä½¿ç”¨è¯¥å­—æ®µéªŒè¯ç½‘ç«™æ˜¯å¦åˆæ³•ï¼›
       "O"ï¼š Organizationï¼Œç”¨äºåˆ†ç»„è®¤è¯
# æ³¨æ„ï¼š ç”¨æˆ·æ˜¯feng,ç»„æ˜¯kubeadm:cluster-admins

# æŸ¥çœ‹
[root@master1 ~]#ls pki/
admin.crt  feng.csr      mystical.csr                             test2.crt  wang.crt
admin.csr  feng.key      mystical.key                             test2.csr  wang.csr
admin.key  mystical.crt  security-certificaterequests-test2.yaml  test2.key  wang.key
#ç»“æœæ˜¾ç¤ºï¼š*.key æ˜¯ç§é’¥ï¼Œ*.csræ˜¯ç­¾åè¯·æ±‚æ–‡ä»¶
```



##### **ç”Ÿæˆè¯ä¹¦**

åˆšæ‰çš„ç§é’¥å’Œè®¤è¯å¹¶æ²¡æœ‰è¢«Kubernetesé›†ç¾¤çº³å…¥åˆ°ç®¡ç†ä½“ç³»ï¼Œéœ€è¦åŸºäºkubeadmé›†ç¾¤çš„CAç›¸å…³è¯ä¹¦æ¥ è¿›è¡Œè®¤è¯

CAç›¸å…³æ–‡ä»¶ä½äº/etc/kubernetes/pki/ç›®å½•ä¸‹é¢ï¼Œåˆ©ç”¨è¯¥ç›®å½•ä¸‹é¢çš„ca.crtå’Œca.keyä¸¤ä¸ªæ–‡ä»¶æ¥æ‰¹å‡†ä¸Šé¢ çš„è¯ä¹¦è¯·æ±‚

```bash
[root@master1 ~]# cd /etc/kubernetes/pki
[root@master1 pki]#openssl x509 -req -CA ./ca.crt -CAkey ./ca.key -CAcreateserial -in /root/pki/feng.csr -out /root/pki/feng.crt  -days 365 
Certificate request self-signature ok
subject=CN = feng, O = kubeadm:cluster-admins


#å‚æ•°è¯´æ˜ï¼š
    -req                 äº§ç”Ÿè¯ä¹¦ç­¾å‘ç”³è¯·å‘½ä»¤
    -in                  æŒ‡å®šéœ€è¦ç­¾åçš„è¯·æ±‚æ–‡ä»¶
    -CA                  æŒ‡å®šCAè¯ä¹¦æ–‡ä»¶
    -CAkey               æŒ‡å®šCAè¯ä¹¦çš„ç§˜é’¥æ–‡ä»¶
    -CAcreateserial      ç”Ÿæˆå”¯ä¸€çš„è¯ä¹¦åºåˆ—å·
    -x509                è¡¨ç¤ºè¾“å‡ºä¸€ä¸ªX509æ ¼å¼çš„è¯ä¹¦
    -days                æŒ‡å®šè¯ä¹¦è¿‡æœŸæ—¶é—´ä¸º365å¤©
    -out                 è¾“å‡ºè¯ä¹¦æ–‡ä»¶
    
# æ£€æŸ¥æ–‡ä»¶æ•ˆæœ[root@master1 pki]# ls /root/pki/
admin.crt  feng.csr      mystical.key                             test2.key
admin.csr  feng.key      security-certificaterequests-test2.yaml  wang.crt
admin.key  mystical.crt  test2.crt                                wang.csr
feng.crt   mystical.csr  test2.csr                                wang.key
#ç»“æœæ˜¾ç¤ºï¼š*.crtå°±æ˜¯æœ€ç»ˆç”Ÿæˆçš„ç­¾è¯è¯ä¹¦

# æŸ¥çœ‹è¯ä¹¦ä¿¡æ¯
[root@master1 pki]#openssl x509 -in /root/pki/feng.crt -noout -text
Certificate:
    Data:
        Version: 1 (0x0)
        Serial Number:
            08:b6:f7:4d:94:a6:7f:15:ed:18:36:29:c0:4b:1a:d0:85:1c:de:f9
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN = kubernetes
        Validity
            Not Before: Jan  8 06:38:55 2025 GMT
            Not After : Jan  8 06:38:55 2026 GMT
        Subject: CN = feng, O = kubeadm:cluster-admins
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
                ......
#ç»“æœæ˜¾ç¤ºï¼šIssuer: è¡¨ç¤ºæ˜¯å“ªä¸ªCAæœºæ„å¸®æˆ‘ä»¬è®¤è¯çš„,æˆ‘ä»¬å…³æ³¨çš„é‡ç‚¹åœ¨äºSubjectå†…å®¹ä¸­çš„è¯·æ±‚ç”¨æˆ·æ‰€å±çš„ç»„ä¿¡æ¯
```



##### åˆ›å»ºKubernetesç”¨æˆ·

```bash
#åˆ›å»ºç”¨æˆ·ä¿¡æ¯
[root@master1 pki]# kubectl config set-credentials feng --client-certificate=/root/pki/feng.crt --client-key=/root/pki/feng.key --embed-certs=true --kubeconfig=/tmp/feng.conf
User "feng" set.

#å‚æ•°è¯¦è§£ï¼š
set-credentials                          #å­å‘½ä»¤çš„ä½œç”¨å°±æ˜¯ç»™kubeconfigè®¤è¯æ–‡ä»¶åˆ›å»ºä¸€ä¸ªç”¨æˆ·æ¡ç›®
--client-certificate=path/to/certfile    #æŒ‡å®šç”¨æˆ·çš„ç­¾è¯è¯ä¹¦æ–‡ä»¶
--client-key=path/to/keyfile             #æŒ‡å®šç”¨æˆ·çš„ç§é’¥æ–‡ä»¶
--embed-certs=true                       #åœ¨kubeconfigä¸­ä¸ºç”¨æˆ·æ¡ç›®åµŒå…¥å®¢æˆ·ç«¯è¯ä¹¦/å¯†é’¥ï¼Œé»˜è®¤å€¼æ˜¯false
--kubeconfig=/path/other_config.file     #è¡¨ç¤ºå°†å±æ€§ä¿¡æ¯å•ç‹¬è¾“å‡ºåˆ°ä¸€ä¸ªæ–‡ä»¶ï¼Œå¦‚ä¸æŒ‡å®šï¼Œé»˜è®¤å­˜æ”¾åœ¨ ~/.kube/configæ–‡ä»¶ä¸­

# æŸ¥çœ‹ç”Ÿæˆæ–‡ä»¶
[root@master1 pki]#cat /tmp/feng.conf
apiVersion: v1
clusters: null
contexts: null
current-context: ""
kind: Config
preferences: {}
users:
- name: feng
  user:
......

# æŸ¥çœ‹æ•ˆæœ
kubect
[root@master1 pki]# kubectl config view --kubeconfig=/tmp/feng.conf 
apiVersion: v1
clusters: null
contexts: null
current-context: ""
kind: Config
preferences: {}
users:
- name: feng
  user:
    client-certificate-data: DATA+OMITTED
    client-key-data: DATA+OMITTED
```



##### åˆ›å»ºé›†ç¾¤

```bash
#åˆ›å»ºä¸€ä¸ªæ–°çš„é›†ç¾¤mycluster
[root@master1 pki]# kubectl config set-cluster fengcluster --server="https://10.0.0.201:6443" --certificate-authority=./ca.crt --embed-certs=true --kubeconfig=/tmp/feng.conf 
Cluster "fengcluster" set.

#å‚æ•°è¯¦è§£ï¼š
--server=cluster_api_server
--certificate-authority=path/to/certificate/authority
--embed-certs=true  #é»˜è®¤ä¸ºfalse,ä¼šå°†è¯ä¹¦æ–‡ä»¶è·¯å¾„å­˜å…¥kubeconfigæ–‡ä»¶ä¸­,trueæ—¶ä¼šå°†è¯ä¹¦å†…å®¹å­˜å…¥kubdconfigæ–‡ä»¶ä¸­
#æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨åˆ°çš„è¯ä¹¦å¿…é¡»æ˜¯kubernetesçš„caè¯ä¹¦

# æ£€æŸ¥æ•ˆæœ
[root@master1 pki]#kubectl config view --kubeconfig=/tmp/feng.conf
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://10.0.0.201:6443
  name: fengcluster
contexts: null
current-context: ""
kind: Config
preferences: {}
users:
- name: feng
  user:
    client-certificate-data: DATA+OMITTED
    client-key-data: DATA+OMITTED
```



##### å…³è”ç”¨æˆ·å’Œé›†ç¾¤

æ‰€è°“å…³è”å®é™…ä¸Šå°±æ˜¯è®¾ç½®ç”¨æˆ·èƒ½åœ¨å“ªä¸ªé›†ç¾¤çš„ä½¿ç”¨

```bash
#é…ç½®ä¸Šä¸‹æ–‡ä¿¡æ¯
[root@master1 pki]#kubectl config set-context feng@fengcluster --cluster=fengcluster --user=feng --kubeconfig=/tmp/feng.conf 
Context "feng@fengcluster" created.

#å±æ€§è¯¦è§£
--cluster=cluster_nickname     # å…³è”çš„é›†ç¾¤åç§°
--user=user_nickname           # å…³è”çš„ç”¨æˆ·åç§°
--namespace=namespace          # å¯ä»¥è®¾ç½®è¯¥ç”Ÿæ•ˆçš„å‘½åç©ºé—´

#æœ€ç»ˆæ•ˆæœ
[root@master1 pki]#kubectl config view --kubeconfig=/tmp/feng.conf
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://10.0.0.201:6443
  name: fengcluster
contexts:
- context:
    cluster: fengcluster
    user: feng
  name: feng@fengcluster
current-context: ""
kind: Config
preferences: {}
users:
- name: feng
  user:
    client-certificate-data: DATA+OMITTED
    client-key-data: DATA+OMITTED
```



##### éªŒè¯æ•ˆæœ

```bash
#æ ¹æ®åˆšæ‰çš„ä¿¡æ¯æ˜¾ç¤ºï¼Œcurrent-contextçš„ä¿¡æ¯æ˜¯ç©ºï¼Œé‚£ä¹ˆåˆ‡æ¢ä¸Šä¸‹æ–‡
#æ›´æ”¹ä¸Šä¸‹æ–‡
[root@master1 pki]# kubectl config use-context feng@fengcluster --kubeconfig=/tmp/feng.conf 
Switched to context "feng@fengcluster".

# éªŒè¯è®¿é—®
[root@master1 pki]#kubectl get nodes --kubeconfig=/tmp/feng.conf 
NAME      STATUS   ROLES           AGE    VERSION
master1   Ready    control-plane   4d5h   v1.30.8
node1     Ready    <none>          4d5h   v1.30.8
node2     Ready    <none>          4d5h   v1.30.8
node3     Ready    <none>          4d5h   v1.30.8
```





#### Service Account ç®¡ç†

#####  Service Account åŸºç¡€

**Service Account åŠŸèƒ½**

- KubernetesåŸç”Ÿï¼ˆkubernetes-nativeï¼‰åº”ç”¨æ‰˜ç®¡è¿è¡ŒäºKubernetesä¹‹ä¸Šï¼Œé€šå¸¸éœ€è¦ç›´æ¥ä¸API  Serverè¿›è¡Œäº¤äº’ä»¥è·å–å¿…è¦çš„ä¿¡æ¯
- API ServeråŒæ ·éœ€è¦å¯¹è¿™ç±»æ¥è‡ªäºPodèµ„æºä¸­å®¢æˆ·ç«¯ç¨‹åºè¿›è¡Œèº«ä»½éªŒè¯ï¼ŒService Accountä¹Ÿå°±æ˜¯è®¾è®¡ä¸“ç”¨äºè¿™ç±»åœºæ™¯çš„è´¦å·
- ServiceAccountæ˜¯API Serveræ”¯æŒçš„æ ‡å‡†èµ„æºç±»å‹ä¹‹ä¸€





**ServiceAccontï¼šæ ‡å‡†çš„APIèµ„æºç±»å‹**

- åŸºäºèµ„æºå¯¹è±¡ä¿å­˜ServiceAccountçš„æ•°æ®
- è®¤è¯ä¿¡æ¯ä¿å­˜äºServiceAccountå¯¹è±¡ä¸“ç”¨çš„Secretä¸­
- éš¶å±åç§°ç©ºé—´çº§åˆ«ï¼Œä¸“ä¾›é›†ç¾¤ä¸Šçš„Podä¸­çš„è¿›ç¨‹**è®¿é—®API Server**æ—¶ä½¿ç”¨
- éœ€è¦ç”¨åˆ°ç‰¹æ®Šæƒé™æ—¶ï¼Œå¯ä¸ºPodæŒ‡å®šè¦ä½¿ç”¨çš„è‡ªå®šä¹‰ServiceAccountèµ„æºå¯¹è±¡





**åœ¨Podä¸Šä½¿ç”¨Service Account**

- è‡ªåŠ¨è®¾å®šï¼šService Accounté€šå¸¸ç”±API Serverè‡ªåŠ¨åˆ›å»ºå¹¶é€šè¿‡ ServiceAccountå‡†å…¥æ§åˆ¶å™¨è‡ªåŠ¨å…³ è”åˆ°é›†ç¾¤ä¸­åˆ›å»ºçš„æ¯ä¸ªPodä¸Š

  - K8Sè‡ªåŠ¨ä¸ºæ¯ä¸ªPodæ³¨å…¥ä¸€ä¸ª ServiceAccount åŠé…å¥—çš„ä»¤ç‰Œ

  ```bash
  # é»˜è®¤å«defaultï¼Œæ¯ä¸ªåç§°ç©ºé—´éƒ½æœ‰ä¸€ä¸ªåä¸ºdefaultçš„saï¼Œè¯¥saæƒé™å¾ˆå°
  [root@master1 pki]#kubectl get sa -A |grep default
  default           default                                       0         4d5h
  ingress-nginx     default                                       0         4d3h
  kube-flannel      default                                       0         4d5h
  kube-node-lease   default                                       0         4d5h
  kube-public       default                                       0         4d5h
  kube-system       default                                       0         4d5h
  metallb-system    default                                       0         4d3h
  ```

- è‡ªå®šä¹‰ï¼šåœ¨Podè§„èŒƒä¸Šï¼Œä½¿ç”¨serviceAccountNameæŒ‡å®šè¦ä½¿ç”¨çš„ç‰¹å®šServiceAccount

- Podä¸­çš„å­—æ®µimagePullSecretsï¼Œå¯ä¸ºPodæä¾›ä»ç§æœ‰image registryè·å–æ—¶ä½¿ç”¨çš„è®¤è¯å‡­æ®

  ```bash
  imagePullSecrets:
        - name: harbor-docker-registry-secret  # æŒ‡å®šdocker-registryç±»å‹çš„secretï¼Œå¦‚æœæœ‰å¤šä¸ªä¼šé€ä¸ªéªŒè¯
  ```

  



**ä¸ºPodæä¾›å‘ç§æœ‰image registryæä¾›è®¤è¯å‡­æ®çš„æ–¹æ³•**

- pods.spec.imagePullSecrets: ç›´æ¥è°ƒç”¨çš„æ–¹å¼

- pods.spec.serviceAccountNameæŒ‡å®šä½¿ç”¨çš„ç‰¹æœ‰ServiceAccountï¼Œè€Œååœ¨ServiceAccountèµ„æºå¯¹è±¡ä¸Šï¼Œä½¿ç”¨serviceaccounts.imagePullSecrets æŒ‡å®š secret ,æ­¤ä¸ºé—´æ¥è°ƒç”¨çš„æ–¹å¼

  ```ABAP
  podä½¿ç”¨ServiceAccountï¼Œè¯¥SAä¸Šè®¾ç½®imagePullSecretsï¼Œä»è€Œå®ç°Podèƒ½å¤Ÿä»ç§æœ‰ä»“æ‹‰é•œåƒçš„æƒé™
  ```



**KubernetesåŸºäºä¸‰ä¸ªç»„ä»¶å®ŒæˆPodä¸Šservice accountçš„è‡ªåŠ¨åŒ–**

- ServiceAccount Admission Controller
- Token Controller
- ServiceAccount Controller



åœ¨æ¯ä¸ªåç§°ç©ºé—´ä¸­ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆ(ç”±ServiceAccountå‡†å…¥æ§åˆ¶å™¨è´Ÿè´£)ä¸€ä¸ªåç§°ä¸ºdefaultçš„ ServiceAccountï¼Œå¹¶é»˜è®¤å°†å…¶è‡ªåŠ¨åˆ†é…ç»™è¯¥ç©ºé—´ä¸‹çš„æ¯ä¸ªPodå…±äº«ä½¿ç”¨ã€‚

```bash
[root@master1 pki]#kubectl get sa -A |grep default
default           default                                       0         4d5h
ingress-nginx     default                                       0         4d3h
kube-flannel      default                                       0         4d5h
kube-node-lease   default                                       0         4d5h
kube-public       default                                       0         4d5h
kube-system       default                                       0         4d5h
metallb-system    default                                       0         4d3h
```

è®¤è¯ä»¤ç‰Œä¿å­˜äºè¯¥åç§°ç©ºé—´ä¸‹çš„ä¸€ä¸ªSecretå¯¹è±¡ä¸­ï¼Œè¯¥å¯¹è±¡ä¸­å…±æœ‰ä¸‰ä¸ªä¿¡æ¯ï¼šnamespaceã€ca.crtã€ token



**SA å°±æ˜¯é›†ç¾¤å†…éƒ¨èµ„æºæ“ä½œçš„è´¦å·**

- æ¯ä¸ªå‘½åç©ºé—´è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªåç§°ä¸ºdefaultçš„saç”¨æˆ·
- æ¯ä¸ªå‘½åç©ºé—´å¯ä»¥æœ‰å¾ˆå¤šsa
- saå†…éƒ¨æ˜¯secretsç±»å‹çš„token



**ServiceAccountä½¿ç”¨ä¸“ç”¨çš„Secretç±»å‹å­˜å‚¨ç›¸å…³çš„æ•æ„Ÿä¿¡æ¯**

- ç±»å‹æ ‡è¯†ä¸ºâ€œkubernetes.io/serviceaccountâ€
- data å­—æ®µæœ‰ä¸‰ä¸ªå›ºå®šçš„å±æ€§å­—æ®µï¼Œåç§°åˆ†åˆ«ä¸º
  - ca.crtï¼šKubernetes CAçš„æ•°å­—è¯ä¹¦
  - namespaceï¼šè¯¥ServiceAccountå¯é€‚ç”¨çš„åç§°ç©ºé—´
  - tokenï¼šè®¤è¯åˆ°API Serverçš„ä»¤ç‰Œ



**Podç”¨saä¸Šé™„åŠ çš„è®¤è¯å‡­æ®ï¼š**

- **Secretå·**ï¼šKubernetes-v1.23ç‰ˆæœ¬ä¹‹å‰,è¢«æŒ‚è½½è‡³ä¸€ä¸ªå›ºå®šè·¯å¾„`/var/run/secrets/kubernetes.io/serviceaccount`

  - åœ¨è¯¥è·¯å¾„ä¸‹å°†ä¼šå­˜åœ¨ä¸‰ä¸ªæ–‡ä»¶
    - ca.crtï¼škubernetes root caçš„è¯ä¹¦
    - namesapceï¼šç”Ÿæ•ˆçš„åç§°ç©ºé—´
    - tokenï¼šè®¤è¯ä»¤ç‰Œ

- **Projectedå·**ï¼šKubernetes-v1.24ç‰ˆæœ¬ä»¥å, åŒæ ·æ˜ å°„åˆ°å›ºå®šè·¯å¾„`/var/run/secrets/kubernetes.io/serviceaccount/`

  - serviceAccountTokenï¼šç”¨äºServiceAccountçš„Tokenä¿¡æ¯æä¾›ç»™Podï¼ŒåŒæ ·ä¸ºtokenæ–‡ä»¶
  - configMap/kube-root-ca.crtï¼šå°†kubernetes root caè‡ªèº«çš„è¯ä¹¦æä¾›ç»™Podï¼ŒåŒæ ·ä¸ºca.crt
  - downwardAPI: metadata.namespaceï¼Œç”¨äºé™åˆ¶è¯¥SAå¯ç”Ÿæ•ˆçš„åç§°ç©ºé—´ï¼ŒåŒæ ·ä¸º namespaceæ–‡ä»¶

  ```bash
  [root@master1 yaml]#kubectl exec -it myapp-7b94444f8d-hws2b -- /bin/sh
  / # cd /var/run/secrets/kubernetes.io/serviceaccount/
  /var/run/secrets/kubernetes.io/serviceaccount # ls
  ca.crt     namespace  token
  /var/run/secrets/kubernetes.io/serviceaccount # ls -l
  total 0
  lrwxrwxrwx    1 root     root            13 Jan  8 16:11 ca.crt -> ..data/ca.crt
  lrwxrwxrwx    1 root     root            16 Jan  8 16:11 namespace -> ..data/namespace
  lrwxrwxrwx    1 root     root            12 Jan  8 16:11 token -> ..data/token
  /var/run/secrets/kubernetes.io/serviceaccount # ls -la
  total 4
  drwxrwxrwt    3 root     root           140 Jan  8 16:11 .
  drwxr-xr-x    3 root     root          4096 Jan  8 16:11 ..
  drwxr-xr-x    2 root     root           100 Jan  8 16:11 ..2025_01_08_08_11_17.4084613224
  lrwxrwxrwx    1 root     root            32 Jan  8 16:11 ..data -> ..2025_01_08_08_11_17.4084613224
  lrwxrwxrwx    1 root     root            13 Jan  8 16:11 ca.crt -> ..data/ca.crt
  lrwxrwxrwx    1 root     root            16 Jan  8 16:11 namespace -> ..data/namespace
  lrwxrwxrwx    1 root     root            12 Jan  8 16:11 token -> ..data/token
  ```

  

**ServiceAccount Admission Controllerè´Ÿè´£å®ŒæˆPodä¸Šçš„ServiceAccountçš„è‡ªåŠ¨åŒ–**

- ä¸ºæ¯ä¸ªåç§°ç©ºé—´ç”Ÿæˆä¸€ä¸ªé»˜è®¤çš„default **ServiceAccountåŠå…¶**ä¾èµ–åˆ°çš„**Secretå¯¹è±¡**
- ä¸ºæœªå®šä¹‰serviceAccountNameçš„Podèµ„æºè‡ªåŠ¨é™„åŠ åç§°ç©ºé—´ä¸‹çš„serviceaccounts/default
- ä¸ºå®šä¹‰äº†serviceAccountNameçš„Podèµ„æºæ£€æŸ¥å…¶å¼•ç”¨çš„ç›®æ ‡å¯¹è±¡æ˜¯å¦å­˜åœ¨



æ¯ä¸ªserviceaccountï¼Œè¢«API Serverè®¤è¯ä¸º**`â€œsystem:serviceaccount:NAMESPACE:SAâ€`**

ServiceAccountç”¨åˆ°çš„tokenï¼Œä¹Ÿå¯ä»¥ä¸ºè¢«åˆ›å»ºä¸ºkubeconfigæ–‡ä»¶ï¼Œä»è€Œè¢«kubectlç­‰å…¶å®ƒå®¢æˆ·ç«¯å¼•ç”¨ï¼›

```BASH
kubectl config set-cluster myk8s --server=https://kubernetes.default -certificate-authority=ca.crt
kubectl config set-credentials user --token={serviceaccount_token}
kubectl config set-context user@myk8s --cluster=myk8s
kubectl config set-context user@myk8s --user=user
kubectl config use-context user@myk8s
```





**é»˜è®¤è®¤è¯ç¤ºä¾‹**

```bash
#åœ¨k8sç¯å¢ƒä¸­åˆ›å»ºä»»æ„ä¸€ä¸ªpodçš„æ—¶å€™ï¼Œå®ƒéƒ½ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªå±æ€§ä¿¡æ¯ï¼š
# æ–°ç‰ˆæƒ…å†µ
[root@master1 yaml]#kubectl get pod myapp-7b94444f8d-hws2b -o yaml
...
 volumes:
  - name: kube-api-access-6ffvs
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
...

# é»˜è®¤çš„sa:defaultæƒé™å¾ˆå°
# éªŒè¯defaultæƒé™
[root@master1 yaml]#kubectl cp myapp-7b94444f8d-hws2b:var/run/secrets/kubernetes.io/serviceaccount/..data/token token

# æŸ¥çœ‹tokenæ–‡ä»¶
[root@master1 yaml]#cat token 
eyJhbGciOiJSUzI1NiIsImtpZCI6IjVyZ2VtUUFRUk0zdnhNVUpRRHlqcUxCUGRVOGhqbFRTMDlCdEZTNmpSbE0ifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzY3ODU5ODc1LCJpYXQiOjE3MzYzMjM4NzUsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwianRpIjoiMTlhMzMzZjQtZWJjMi00MDYxLWFkNTYtZGZjZWFiZmY2ZmNmIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJkZWZhdWx0Iiwibm9kZSI6eyJuYW1lIjoibm9kZTEiLCJ1aWQiOiJmN2NkYjk5Yy1iYjQ5LTQ0N2MtOTQ4MS1jMzZjMTNhNWU3NTMifSwicG9kIjp7Im5hbWUiOiJteWFwcC03Yjk0NDQ0ZjhkLWh3czJiIiwidWlkIjoiZGEyYTk1MTctZTM1Mi00N2RlLWJiMDEtOGU1NDUwYmUzOTkxIn0sInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkZWZhdWx0IiwidWlkIjoiMDIyNjYxODItNzRlYS00NWRjLWIwZDctNmY3NDQ5ZjlhZTExIn0sIndhcm5hZnRlciI6MTczNjMyNzQ4Mn0sIm5iZiI6MTczNjMyMzg3NSwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50OmRlZmF1bHQ6ZGVmYXVsdCJ9.HERqhyZGaNj5juZWrfCJBJvoAGRfiHyzjqKyv8lNpwoBhH86ujnD4ql_f4thXY2lsM_1YCLrjtGssFLD7blaO4Ln91ekJLm-uMOvFZQKjCXwMxuLNNviC-OzqHrSmzoXyEqCaNGa5yJkjmpxbdXOk_zn0nu_HSkqk_qaegxYt9sDW_alQcWIsBtec2oN4CSnwUDTt_X7QvWceib5_2oKIgZlZXDpFViT9K2KtT3SxWUUFeFXGCLd7CaEGVckO1GhDI35oUobLZ2RjWrtoBsHYRzLa-zQhI43t9zpu7I1ss0bylFFOTdQkf7RtJzitpC1LKN70qYOf4GIlF4i2fqOIA

# å°†è¿™ä¸ªtokenè§£ç 
# SA çš„ Token æ˜¯ JWT æ ¼å¼ï¼Œå¹¶éç®€å•çš„ Base64 ç¼–ç æ•°æ®ï¼Œå› æ­¤ç›´æ¥ç”¨ Base64 è§£ç å¯èƒ½å¤±è´¥ã€‚
# JWT çš„æ ¼å¼ï¼š{Header}.{Payload}.{Signature}

# è§£å¯†æ–¹æ³•å¦‚ä¸‹
[root@master1 yaml]#cat token |cut -d '.' -f1 | base64 -d |jq
{
  "alg": "RS256",
  "kid": "5rgemQAQRM3vxMUJQDyjqLBPdU8hjlTS09BtFS6jRlM"
}

[root@master1 yaml]#cat token |cut -d '.' -f2 | base64 -d |jq
{
  "aud": [
    "https://kubernetes.default.svc.cluster.local"
  ],
  "exp": 1767859875,
  "iat": 1736323875,
  "iss": "https://kubernetes.default.svc.cluster.local",
  "jti": "19a333f4-ebc2-4061-ad56-dfceabff6fcf",
  "kubernetes.io": {
    "namespace": "default",
    "node": {
      "name": "node1",
      "uid": "f7cdb99c-bb49-447c-9481-c36c13a5e753"
    },
    "pod": {
      "name": "myapp-7b94444f8d-hws2b",
      "uid": "da2a9517-e352-47de-bb01-8e5450be3991"
    },
    "serviceaccount": {
      "name": "default",
      "uid": "02266182-74ea-45dc-b0d7-6f7449f9ae11"
    },
    "warnafter": 1736327482
  },
  "nbf": 1736323875,
  "sub": "system:serviceaccount:default:default"
}

# é»˜è®¤çš„defaultçš„Saæƒé™è¿‡å°
[root@ubuntu2204 ~]#kubectl get pod --insecure-skip-tls-verify -s https://10.0.0.201:6443 --token `cat token`
Error from server (Forbidden): pods is forbidden: User "system:serviceaccount:default:default" cannot list resource "pods" in API group "" in the namespace "default"
```



**saèµ„æºå±æ€§**

```bash
apiVersion: v1                           # ServiceAccountæ‰€å±çš„APIç¾¤ç»„åŠç‰ˆæœ¬
kind: ServiceAccount                     # èµ„æºç±»å‹æ ‡è¯†
metadata:
  name <string>                          # èµ„æºåç§°
  namespace <string>                     # ServiceAccountæ˜¯åç§°ç©ºé—´çº§åˆ«çš„èµ„æº
automountServiceAccountToken <boolean>   # æ˜¯å¦è®©Podè‡ªåŠ¨æŒ‚è½½APIä»¤ç‰Œ
secrets <[]Object>                       # ä»¥è¯¥SAè¿è¡Œçš„Podæ‰€è¦ä½¿ç”¨çš„Secretå¯¹è±¡ç»„æˆçš„åˆ—è¡¨
  apiVersion <string>                    # å¼•ç”¨çš„Secretå¯¹è±¡æ‰€å±çš„APIç¾¤ç»„åŠç‰ˆæœ¬ï¼Œå¯çœç•¥
  kind <string>                          # å¼•ç”¨çš„èµ„æºçš„ç±»å‹ï¼Œè¿™é‡Œæ˜¯æŒ‡Secretï¼Œå¯çœç•¥
  name <string>                          # å¼•ç”¨çš„Secretå¯¹è±¡çš„åç§°ï¼Œé€šå¸¸ä»…ç»™å‡ºè¯¥å­—æ®µå³å¯
  namespace <string>                     # å¼•ç”¨çš„Secretå¯¹è±¡æ‰€å±çš„åç§°ç©ºé—´
  uid <string>                           # å¼•ç”¨çš„Secretå¯¹è±¡çš„æ ‡è¯†ç¬¦ï¼›
imagePullSecrets <[]Object>              # å¼•ç”¨çš„ç”¨äºä¸‹è½½Podä¸­å®¹å™¨é•œåƒçš„Secretå¯¹è±¡åˆ—è¡¨
  name <string>                          # docker-registryç±»å‹çš„Secretèµ„æºçš„åç§°
```





#### åˆ›å»ºå’Œä½¿ç”¨SAè´¦å·

##### åˆ›å»ºæ–¹æ³•

```bash
# å‘½ä»¤æ ¼å¼
[root@master1 yaml]# kubectl create serviceaccount NAME [--dry-run] [options]
#ä½œç”¨ï¼šåˆ›å»ºä¸€ä¸ª"æœåŠ¡è´¦å·"

#å‚æ•°è¯¦è§£
--dry-run=false                  # æ¨¡æ‹Ÿåˆ›å»ºæ¨¡å¼
--generator='serviceaccount/v1'  # è®¾å®šapiç‰ˆæœ¬ä¿¡æ¯
-o, --output=''                  # è®¾å®šè¾“å‡ºä¿¡æ¯æ ¼å¼ï¼Œå¸¸è§çš„æœ‰ï¼šjson|yaml|name|template|...
--save-config=false              # ä¿å­˜é…ç½®ä¿¡æ¯
--template=''                    # è®¾å®šé…ç½®æ¨¡æ¿æ–‡ä»¶

#æ–‡ä»¶æ ¼å¼:
apiVersion: v1
kind: ServiceAccount
metadata:
  name: <SAåç§°>

#åˆ›å»ºSAèµ„æºæ–‡ä»¶çš„ç®€å•æ–¹æ³•
[root@master1 yaml]# kubectl create serviceaccount mysa --dry-run -o yaml
apiVersion: v1
kind: ServiceAccount
metadata:
 name: mysa
```



**èŒƒä¾‹: åˆ›å»ºSAåŠå…¶å¯¹åº”çš„Token**

```yaml
# æ¸…å•æ–‡ä»¶
[root@master1 sa] # cat security-sa-admin.yaml 
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin

---
# v1.24ç‰ˆä¹‹åæ·»åŠ ä¸‹é¢å†…å®¹æ‰‹åŠ¨åˆ›å»ºsecret
apiVersion: v1
kind: Secret
type: kubernetes.io/service-account-token
metadata:
  name: admin-secret
  annotations:
    kubernetes.io/service-account.name: "admin"

---
apiVersion: v1
kind: Pod
metadata:
  name: pod-sa-admin
spec:
  containers:
  - name: pod-sa-admin
    image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    imagePullPolicy: IfNotPresent
  serviceAccountName: admin
  
# åº”ç”¨
[root@master1 sa] # kubectl apply -f security-sa-admin.yaml 
serviceaccount/admin created
secret/admin-secret created
pod/pod-sa-admin created

# æŸ¥çœ‹
[root@master1 sa] # kubectl describe sa admin 
Name:                admin
Namespace:           default
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   <none>
Tokens:              admin-secret
Events:              <none>
```





### æˆæƒæœºåˆ¶

k8sé›†ç¾¤é»˜è®¤çš„è®¤è¯æ’ä»¶æœ‰ **Node** å’Œ **RBAC**ï¼Œå…¶ä»–çš„éƒ½æ˜¯ä½¿ç”¨å¤§é‡çš„è¯ä¹¦æ¥è¿›è¡Œçš„

å¦‚æœæ²¡æœ‰é‰´æƒæ–¹å¼å…è®¸,åˆ™é»˜è®¤ä¸ºæ‹’ç»



**é…ç½®æ–¹æ³•**

- åœ¨kube-apiserverä¸Šä½¿ç”¨ --authorization-mode é€‰é¡¹è¿›è¡Œå®šä¹‰
- å¤šä¸ªæ¨¡å—å½¼æ­¤é—´ä»¥é€—å·åˆ†éš”

```bash
[root@master1 sa]#cat /etc/kubernetes/manifests/kube-apiserver.yaml 
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 10.0.0.201:6443
  creationTimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=10.0.0.201
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC       # è¿™é‡Œè¿›è¡Œå®šä¹‰
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --token-auth-file=/etc/kubernetes/auth/token.csv
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true
    ......
```



![image-20250108193615349](../markdown_img/image-20250108193615349.png)





####  RBAC æœºåˆ¶



##### RBACåŸºç¡€æ¦‚å¿µ

- **å®ä½“ï¼ˆEntityï¼‰**ï¼šåœ¨RBACä¹Ÿç§°ä¸º**Subject**ï¼Œé€šå¸¸æŒ‡çš„æ˜¯**User**ã€**Group** æˆ–è€… **ServiceAccount**,å³å¯¹å“ªäº›äººè¿›è¡Œæˆæƒ
- **èµ„æºï¼ˆResourceï¼‰**ï¼šåœ¨RBACä¸­ä¹Ÿç§°ä¸º**Object**ï¼ŒæŒ‡ä»£SubjectæœŸæœ›æ“ä½œçš„ç›®æ ‡ï¼Œä¾‹å¦‚**Secretã€PodåŠ Serviceå¯¹è±¡**ç­‰
  - ä»…é™äº/api/v1/ æˆ– /apis/// å¼€å§‹çš„è·¯å¾„
  - å…¶å®ƒè·¯å¾„å¯¹åº”çš„ç«¯ç‚¹å‡è¢«è§†ä½œâ€œéèµ„æºç±»è¯·æ±‚ï¼ˆNon-Resource Requestsï¼‰â€ï¼Œä¾‹å¦‚: /healthz  ç«¯ç‚¹
- **åŠ¨ä½œï¼ˆActionsï¼‰**ï¼šSubjectå¯ä»¥äºObjectä¸Šæœ‰æƒé™æ‰§è¡Œçš„ç‰¹å®šæ“ä½œï¼Œå…·ä½“çš„å¯ç”¨åŠ¨ä½œå–å†³äºKubernetesçš„å®šä¹‰
  - **Object**
    - è¯»æ“ä½œï¼šgetã€listã€watchç­‰
    - å†™æ“ä½œï¼šcreateã€updateã€patchã€deleteã€deletecollectionç­‰
  - **éObject**: ä»…æ”¯æŒgetæ“ä½œ
- **è§„åˆ™Rules**: æ˜¯ä¸€ç»„å±äºä¸åŒ API Group èµ„æºä¸Šçš„æ“ä½œçš„æƒé™é›†åˆ,å³èµ„æºResourceå’ŒåŠ¨ä½œActions çš„ç»„åˆçš„æˆæƒè§„åˆ™
- **è§’è‰²ï¼ˆRoleï¼‰**ï¼šæ‰¿è½½èµ„æºæ“ä½œæƒé™çš„å®¹å™¨,åŒ…å«ä¸€ç»„æƒé™çš„è§„åˆ™,åªæœ‰å…è®¸æ²¡æœ‰æ‹’ç»æƒé™
- **Roleï¼š**åç§°ç©ºé—´çº§åˆ«ï¼Œç”Ÿæ•ˆèŒƒå›´ä¸ºå…¶æ‰€å±çš„åç§°ç©ºé—´
  - **ClusterRoleï¼š**é›†ç¾¤çº§åˆ«ï¼Œç”Ÿæ•ˆèŒƒå›´ä¸ºæ•´ä¸ªé›†ç¾¤
- **è§’è‰²ç»‘å®šï¼ˆRole Bindingï¼‰**ï¼šå°†è§’è‰²å…³è”è‡³å®ä½“ä¸Šï¼Œå®ƒèƒ½å¤Ÿå°†è§’è‰²å…·ä½“çš„æ“ä½œæƒé™èµ‹äºˆç»™å®ä½“,å³å°†è§’è‰²ä¸Šçš„æƒé™æˆäºˆç»™è´¦å·ï¼Œæ ‡å‡†çš„èµ„æºç±»å‹
- **RoleBinding:** ç»‘å®šåœ¨åç§°ç©ºé—´çº§åˆ«,å³åªæˆæƒæ‹¥æœ‰æŒ‡å®šåç§°ç©ºé—´èŒƒå›´çš„æƒé™ 
  - **ClusterRoleBinding:** ç»‘å®šåœ¨é›†ç¾¤çº§åˆ«,å³æˆæƒæ‹¥æœ‰é›†ç¾¤èŒƒå›´ä¸­æ‰€æœ‰åç§°ç©ºé—´çš„æƒé™





#####  RBAC æˆæƒæœºåˆ¶

 **è§’è‰²å’Œè§’è‰²ç»‘å®š**

æˆæƒæŒ‡çš„æ˜¯å°†æŸäº›subjectå¯¹è±¡èµ‹äºˆæ‰§è¡ŒæŸäº›èµ„æºåŠ¨ä½œçš„æƒé™ã€‚æœ‰æ—¶å€™ä¼šå°†å…¶ç§°ä¸ºGroup(æƒé™ç»„)ï¼Œæœ‰ä¸¤ éƒ¨åˆ†ç»„æˆï¼šè§’è‰²ï¼ˆç»„åï¼‰å’Œè§’è‰²ç»‘å®š(ç»„å…³è”)ã€‚

ç®€å•æ¥è¯´ï¼š**æˆæƒä¸ºç”¨æˆ·æˆäºˆæŸç§è§’è‰²**

| ç»„ æˆ    | è§£æ                                                         |
| -------- | ------------------------------------------------------------ |
| è§’è‰²     | å…¶å®æ˜¯é™„åŠ åœ¨æŸäº›èµ„æºä¸Šçš„ä¸€ç³»åˆ—æƒé™çš„é›†åˆï¼Œå¯¹äºk8sæ¥è¯´ï¼Œå®ƒä¸»è¦æœ‰ä¸¤ç±»ï¼š**Roleå’Œ clusterRole**<br />å…¶ä¸­Roleä¸»è¦æ˜¯ä½œç”¨äºnamespaceï¼Œè€ŒclusterRoleä¸»è¦ä½œç”¨äºå¤šä¸ªnamespaceï¼Œå®ƒä»¬ä¹‹é—´ æ˜¯ä¸€å¯¹å¤šçš„å…³ç³»ã€‚<br />ä¸ºäº†å°†æƒé™åº”ç”¨å’Œå…·ä½“æƒé™åˆ—è¡¨åˆ†å¼€æè¿°ï¼Œä¸€èˆ¬ç§°æƒé™åˆ—è¡¨ä¸ºè§„åˆ™-rules |
| è§’è‰²ç»‘å®š | å°†ä¹‹å‰å®šä¹‰çš„Subjectå’Œå¯¹åº”çš„æƒé™ç»„å…³è”åœ¨ä¸€èµ·ï¼Œè¡¨ç¤ºæŸä¸ªSubjectå…· æœ‰æ‰§è¡ŒæŸä¸ªèµ„æºçš„ä¸€ç³»åˆ—åŠ¨ä½œæƒé™ã€‚<br />å®ƒä¸»è¦æ¶‰åŠåˆ°ä¸¤ä¸ªRoleBindingå’Œ ClusterRoleBindingã€‚ |



![image-20250108195742108](../markdown_img/image-20250108195742108.png)



**è§’è‰²Roleåˆ†ç±»ï¼š**

- **ClusterRoleï¼š**é›†ç¾¤èŒƒå›´å†…çš„èµ„æºçš„æ“ä½œæƒé™çš„é›†åˆ,å­˜åœ¨äºæ‰€æœ‰åç§°ç©ºé—´
- **Roleï¼š**åç§°ç©ºé—´èŒƒå›´å†…èµ„æºæ“ä½œçš„æƒé™çš„é›†åˆ,åªå­˜åœ¨äºç‰¹å®šçš„åç§°ç©ºé—´



**è§’è‰²ç»‘å®š RoleBinding åˆ†ç±»**

- **ClusterRoleBinding**ï¼šé›†ç¾¤èŒƒå›´å†…çš„è§’è‰²ç»‘å®š,å³åˆ†é…ç»™é›†ç¾¤ä¸­æ‰€æœ‰åç§°ç©ºé—´ç›¸åº”çš„æƒé™
- **RoleBinding**ï¼šåç§°ç©ºé—´èŒƒå›´å†…çš„è§’è‰²ç»‘å®š,,å³åªåˆ†é…ç»™æŒ‡å®šåç§°ç©ºé—´ç›¸åº”çš„æƒé™



##### è§’è‰²å’Œè§’è‰²ç»‘å®šç»„åˆ

![image-20250108201908367](../markdown_img/image-20250108201908367.png)



- namespace çº§åˆ«
- cluster çº§åˆ«
- æ··åˆçº§åˆ«



**namespaceçº§åˆ«ç»„åˆ**

| æœ¯è¯­        | è§£æ                                                         |
| ----------- | ------------------------------------------------------------ |
| rules       |                                                              |
| role        | åç§°ç©ºé—´çº§åˆ«ï¼Œç”Ÿæ•ˆèŒƒå›´ä¸ºå…¶æ‰€å±çš„åç§°ç©ºé—´<br />è¡¨ç¤ºåœ¨ä¸€ä¸ªnamespaceä¸­åŸºäºrulesä½¿ç”¨èµ„æºçš„æƒé™ï¼Œå±äºé›†ç¾¤å†…éƒ¨çš„ API èµ„æºï¼Œ ä¸»è¦æ¶‰åŠåˆ°æ“ä½œå’Œå¯¹è±¡ |
| RoleBinding | å°†Subjectå…³è”è‡³Role,æˆæƒç»™Subjectå¯ä»¥åœ¨RoleBindingæ‰€åœ¨çš„åç§°ç©ºé—´ä½¿ç”¨æŒ‡å®š èµ„æºçš„roleè§’è‰²æƒé™<br />ä¹Ÿå¯ä»¥å°†Subjectä½¿ç”¨RoleBindingå…³è”è‡³ClusterRoleä¸Šï¼Œ**è¯¥è§’è‰²èµ‹äºˆåˆ°Subjectçš„ æƒé™ä¹Ÿä¼šé™çº§åˆ°RoleBindingæ‰€å±çš„NamespaceèŒƒå›´ä¹‹å†…** |

```ABAP
æ³¨æ„: åœ¨åç§°ç©ºé—´çº§æˆæƒæ—¶,å¿…é¡»è¦ä¿è¯ServiceAccounts (SA) and RoleBindings éƒ½åœ¨åŒä¸ªåç§°ç©ºé—´ä¸‹
```



**clusterçº§åˆ«ç»„åˆ**

| æœ¯è¯­               | è§£æ                                                         |
| ------------------ | ------------------------------------------------------------ |
| ClusterRole        | å®šä¹‰é›†ç¾¤èŒƒå›´å†…çš„èµ„æºæ“ä½œæƒé™é›†åˆï¼ŒåŒ…æ‹¬é›†ç¾¤çº§åˆ«åŠåç§°ç©ºé—´çº§åˆ«çš„èµ„æºå¯¹è±¡<br />è¡¨ç¤ºåœ¨ä¸€ä¸ªclusterä¸­åŸºäºrulesä½¿ç”¨èµ„æºçš„æƒé™ï¼Œå±äºé›†ç¾¤å†…éƒ¨çš„ API èµ„ æºï¼Œä¸€ä¸ªclusteræœ‰å¤šä¸ªnamespaceå³æœ‰å¤šä¸ªrole |
| ClusterRoleBinding | å°†Subjectå…³è”è‡³ClusterRoleï¼Œæˆæƒç»™Subjectå¯ä»¥åœ¨é›†ç¾¤ä¸­ä½¿ç”¨æŒ‡å®šèµ„æº çš„ClusterRoleè§’è‰²æƒé™<br />å³å°†å®ä½“ï¼ˆUserã€Groupæˆ–ServiceAccountï¼‰å…³è”è‡³ClusterRole |



**æ··åˆçº§åˆ«ç»„åˆ**

| æœ¯è¯­        | è§£æ                                                         |
| ----------- | ------------------------------------------------------------ |
| ClusterRole | å®šä¹‰é›†ç¾¤èŒƒå›´å†…çš„èµ„æºæ“ä½œæƒé™é›†åˆï¼ŒåŒ…æ‹¬é›†ç¾¤çº§åˆ«åŠåç§°ç©ºé—´çº§åˆ«çš„èµ„æºå¯¹è±¡ è¡¨ç¤ºåœ¨ä¸€ä¸ªclusterä¸­åŸºäºrulesä½¿ç”¨èµ„æºçš„æƒé™ï¼Œå±äºé›†ç¾¤å†…éƒ¨çš„ API èµ„æºï¼Œä¸€ä¸ª clusteræœ‰å¤šä¸ªnamespaceå³æœ‰å¤šä¸ªrole |
| RoleBinding | å°†SubjectåŸºäºRoleBindingä¸ClusterRoleç»‘å®šåœ¨ä¸€èµ·ï¼Œè¡¨ç¤ºSubjectå¯ä»¥ä½¿ç”¨æ‰€æœ‰ namespaceä¸­æŒ‡å®šèµ„æºçš„roleè§’è‰²ï¼Œä»è€Œé¿å…äº†å¤šæ¬¡roleå’Œuserçš„RoleBindingã€‚ åŒæ ·çš„æ“ä½œï¼Œç«™åœ¨ClusterRoleçš„è§’åº¦ï¼Œæˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºï¼Œç”¨æˆ·å¾—åˆ°çš„æƒé™ä»…æ˜¯ ClusterRoleçš„æƒé™åœ¨Rolebindingæ‰€å±çš„åç§°ç©ºé—´ä¸Šçš„ä¸€ä¸ªå­é›†ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“ çš„"æƒé™é™çº§" |



**RoleBinding ç»‘å®š ClusterRole çš„åœºæ™¯å’ŒåŸå› **

**åœºæ™¯1ï¼šé™å®šé›†ç¾¤çº§æƒé™åœ¨ç‰¹å®šå‘½åç©ºé—´ä¸­**

- `ClusterRole` é€šå¸¸å®šä¹‰é›†ç¾¤çº§åˆ«çš„æƒé™ï¼Œä½†æŸäº›æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½å¸Œæœ›å°†è¿™äº›é›†ç¾¤çº§æƒé™é™åˆ¶åˆ°ä¸€ä¸ªç‰¹å®šçš„å‘½åç©ºé—´ã€‚
- é€šè¿‡ `RoleBinding` ç»‘å®š `ClusterRole`ï¼Œä½ å¯ä»¥æœ‰æ•ˆåœ°**å°†é›†ç¾¤çº§çš„æ“ä½œæƒé™ä»…åº”ç”¨äºæŸä¸ªå‘½åç©ºé—´**ã€‚

**ç¤ºä¾‹ï¼š**

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: admin-binding
  namespace: my-namespace
subjects:
- kind: User
  name: alice
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: admin
  apiGroup: rbac.authorization.k8s.io
```

- é‡Œçš„ `admin` æ˜¯ä¸€ä¸ªé›†ç¾¤çº§åˆ«çš„è§’è‰²ï¼ˆ`ClusterRole`ï¼‰ï¼Œä½†é€šè¿‡ `RoleBinding` å°†å…¶æƒé™é™åˆ¶åœ¨ `my-namespace` å‘½åç©ºé—´ä¸­ã€‚



**ç”¨é€”**

- é™åˆ¶ç”¨æˆ·ï¼ˆå¦‚å¼€å‘äººå‘˜ï¼‰åœ¨ç‰¹å®šå‘½åç©ºé—´ä¸­çš„æ“ä½œæƒé™ï¼Œé˜²æ­¢å…¶å¯¹é›†ç¾¤å…¶ä»–éƒ¨åˆ†é€ æˆå½±å“ã€‚



**åœºæ™¯2ï¼šé‡ç”¨ ClusterRole**

- æœ‰æ—¶é›†ç¾¤ç®¡ç†å‘˜å¯èƒ½å·²ç»å®šä¹‰äº†ä¸€äº›é€šç”¨çš„ `ClusterRole`ï¼Œå¦‚ `view`ã€`edit`ã€`admin`ï¼Œè¿™äº›è§’è‰²å¯ä»¥è¦†ç›–å¾ˆå¤šåœºæ™¯ã€‚
- ä¸ºäº†é¿å…é‡æ–°åˆ›å»ºä¸€ä¸ªç›¸åŒè§„åˆ™çš„ `Role`ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡ `RoleBinding` ç»‘å®šå·²æœ‰çš„ `ClusterRole`ã€‚



**ç¤ºä¾‹ï¼š**

- ä¸ºäº†é¿å…é‡æ–°åˆ›å»ºä¸€ä¸ªç›¸åŒè§„åˆ™çš„ `Role`ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡ `RoleBinding` ç»‘å®šå·²æœ‰çš„ `ClusterRole`ã€‚
- è¿™æ ·å¯ä»¥å‡å°‘ç®¡ç†å¤æ‚åº¦ï¼Œå¹¶é‡ç”¨å·²æœ‰çš„æƒé™æ¨¡å‹ã€‚



##### é»˜è®¤çš„ClusterRoleåŠClusterRoleBinding

å¯ç”¨RBACé‰´æƒæ¨¡å—æ—¶ï¼ŒAPI Serverä¼šè‡ªåŠ¨åˆ›å»ºä¸€ç»„ClusterRoleå’ŒClusterRoleBindingå¯¹è±¡

- å¤šæ•°éƒ½ä»¥â€œsystem:â€ä¸ºå‰ç¼€ï¼Œä¹Ÿæœ‰å‡ ä¸ªé¢å‘ç”¨æˆ·çš„ClusterRoleæœªä½¿ç”¨è¯¥å‰ç¼€ï¼Œå¦‚cluster-adminã€ adminç­‰
- å®ƒä»¬éƒ½é»˜è®¤ä½¿ç”¨â€œkubernetes.io/bootstrapping: rbac-defaultsâ€è¿™ä¸€æ ‡ç­¾



**é»˜è®¤çš„ClusterRoleå¤§ä½“å¯ä»¥åˆ†ä¸ºå¦‚ä¸‹5ä¸ªç±»åˆ«**

- **APIå‘ç°ç›¸å…³çš„è§’è‰²**
  - åŒ…æ‹¬system:basic-userã€system:discoveryå’Œsystem:public-info-viewer
- **é¢å‘ç”¨æˆ·çš„è§’è‰²**
  - åŒ…æ‹¬cluster-adminã€adminã€editå’Œview
- **æ ¸å¿ƒç»„ä»¶ä¸“ç”¨çš„è§’è‰²**
  - åŒ…æ‹¬system:kube-schedulerã€system:volume-schedulerã€system:kube-controller-managerã€ system:nodeå’Œsystem:node-proxierç­‰
- **å…¶å®ƒç»„ä»¶ä¸“ç”¨çš„è§’è‰²**
  - åŒ…æ‹¬system:kube-dnsã€system:node-bootstrapperã€system:node-problem-detectorå’Œ system:monitoringç­‰
- **å†…ç½®æ§åˆ¶å™¨ä¸“ç”¨çš„è§’è‰²**





**ç”¨äºäº¤äº’å¼ç”¨æˆ·æˆæƒç›®çš„çš„å¸¸è§è§’è‰²**

```bash
# æŸ¥çœ‹cluster-admin
#å¯ä»¥é€šè¿‡clusterrole èµ„æºæ¥æŸ¥çœ‹cluster-adminçš„æ‰€æœ‰æƒé™ä¿¡æ¯
[root@master1 sa]# kubectl get clusterrole cluster-admin  -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  creationTimestamp: "2025-01-04T01:44:14Z"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: cluster-admin
  resourceVersion: "74"
  uid: 7defd096-536a-4bd1-890c-e496d1c5f35e
rules:
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - '*'
- nonResourceURLs:
  - '*'
  verbs:
  - '*'

#æŸ¥çœ‹roleè§’è‰²cluster-adminåŒåçš„clusterrolebinding
[root@master1 sa]# kubectl get clusterrolebinding cluster-admin -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  creationTimestamp: "2025-01-04T01:44:14Z"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: cluster-admin
  resourceVersion: "138"
  uid: 969955ea-19c0-4590-836c-68652f9deb73
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: system:masters    #å¯¹ç»„system:mastersè¿›è¡Œè§’è‰²ç»‘å®š

# æŸ¥çœ‹admin
[root@master1 sa]#kubectl get clusterrole admin  -o yaml
aggregationRule:
  clusterRoleSelectors:
  - matchLabels:
      rbac.authorization.k8s.io/aggregate-to-admin: "true"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  creationTimestamp: "2025-01-04T01:44:14Z"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: admin
  resourceVersion: "355"
  uid: 74c723db-9eac-4c11-89eb-172f8c98ec7b
rules:
- apiGroups:
  - ""          # ""ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰è¡¨ç¤ºé»˜è®¤çš„ Core API ç»„ï¼Œå³å±äº Kubernetes æ ¸å¿ƒ API çš„èµ„æº
  resources:
  - pods/attach
  - pods/exec
  - pods/portforward
  - pods/proxy
  - secrets
  - services/proxy
  verbs:
  - get
  - list
  - watch
......

# é‡å¯apiServerçš„æ–¹æ³•
# åˆ æ‰å½“å‰çš„API Server Podï¼Œkubelet ä¼šè‡ªåŠ¨é‡æ–°åˆ›å»º
kubectl delete pod kube-apiserver-<node-name> -n kube-system
```





#### Role å’Œ RoleBinding ç»„åˆå®ç°



##### åˆ›å»ºRole

**å±æ€§è§£æ**

```bash
#å› ä¸ºè§’è‰²ç”±äºçº§åˆ«ä¸ä¸€æ ·ï¼Œä½œç”¨çš„èŒƒå›´ä¹Ÿä¸åŒï¼ŒRoleçš„å±æ€§ï¼Œå¯ä»¥ä½¿ç”¨ kubectl explain role çš„æ–¹å¼æ¥æŸ¥çœ‹
[root@master1 ~]#kubectl explain role.rules
apiVersion <string>
kind <string>
metadata     <Object>
rules       <[]Object>
  apiGroups   <[]string>
  nonResourceURLs     <[]string>
  resourceNames       <[]string>
  resources   <[]string>
  verbs       <[]string> -required-
  
#ç»“æœæ˜¾ç¤ºï¼š
å¯¹äºroleæ¥è¯´ï¼Œå…¶æ ¸å¿ƒçš„å†…å®¹ä¸»è¦æ˜¯rulesçš„æƒé™è§„åˆ™
åœ¨è¿™ä¹ˆå¤šruleså±æ€§ä¸­ï¼Œæœ€é‡è¦çš„æ˜¯verbså°±æ˜¯æƒé™æ¡ç›®ï¼Œè€Œä¸”æ‰€æœ‰çš„å±æ€§éƒ½æ˜¯å¯ä»¥ä»¥åˆ—è¡¨çš„å½¢å¼ç´¯åŠ å­˜åœ¨

#å‘½ä»¤å¼å‘½ä»¤
kubectl create role NAME --verb=verb --resource=resource.group/subresource [--resource-name=resourcename]
verbï¼š#å…è®¸åœ¨èµ„æºä¸Šä½¿ç”¨çš„æ“ä½œï¼ˆverbï¼‰åˆ—è¡¨
resources.group/subresourceï¼š#æ“ä½œå¯æ–½åŠ çš„ç›®æ ‡èµ„æºç±»å‹æˆ–å­èµ„æºåˆ—è¡¨
resourcenameï¼š#ç‰¹å®šçš„èµ„æºå¯¹è±¡åˆ—è¡¨ï¼Œå¯é€‰

# ç¤ºä¾‹
# åˆ›å»ºä¸€ä¸ªå¯¹æ‰€æœ‰pod,service,deploymentå…·æœ‰get,listæƒé™çš„roleçš„èµ„æºå®šä¹‰æ–‡ä»¶æ ¼å¼
[root@master1 ~]# kubectl create role pods-viewer --verb=get,list --resource=pods,services,deployments --dry-run -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  creationTimestamp: null
  name: pods-viewer            
rules:                          
- apiGroups:                 
  - ""
  resources:
  - pods
  - services
  verbs:
  - get
  - list
- apiGroups:
  - apps
  resources:
  - deployments
  verbs:
  - get
  - list

#ç»“æœæ˜¾ç¤ºï¼š
#roleå¿…å¤‡çš„rulesä¸»è¦æœ‰ä¸‰éƒ¨åˆ†ç»„æˆï¼šapiGroupã€resourcesã€verbs
apiGroups #è®¾å®šåŒ…å«èµ„æºçš„apiç»„ï¼Œå¦‚æœæ˜¯å¤šä¸ªï¼Œè¡¨ç¤ºåªè¦å±äºapiç»„èŒƒå›´ä¸­çš„ä»»æ„èµ„æºéƒ½å¯ä»¥æ“ä½œ
resources #ä½äºapiGroupèŒƒå›´ä¸­çš„æŸäº›å…·ä½“çš„èµ„æºå¯¹è±¡
verbs #é’ˆå¯¹å…·ä½“èµ„æºå¯¹è±¡çš„ä¸€äº›å…·ä½“æ“ä½œ
```



##### è§’è‰²ç»‘å®šrolebinding

RoleBinding æˆ–è€… ClusterRoleBinding å¯ç»‘å®šè§’è‰²åˆ°æŸä¸»ä½“ï¼ˆSubjectï¼‰ ä¸Šã€‚ ä¸»ä½“å¯ä»¥æ˜¯ç»„ï¼Œç”¨æˆ·æˆ–è€… æœåŠ¡è´¦æˆ·ã€‚

Kubernetes ç”¨å­—ç¬¦ä¸²æ¥è¡¨ç¤ºç”¨æˆ·åã€‚ 

- ç”¨æˆ·åå¯ä»¥æ˜¯æ™®é€šçš„ç”¨æˆ·åï¼Œåƒ "alice"ï¼›
- é‚®ä»¶é£æ ¼çš„å ç§°ï¼Œå¦‚ "bob@example.com"ï¼Œ 
- ä»¥å­—ç¬¦ä¸²å½¢å¼è¡¨è¾¾çš„æ•°å­— IDã€‚



**æ³¨æ„ï¼š**

å‰ç¼€ system: æ˜¯ Kubernetes ç³»ç»Ÿä¿ç•™çš„ï¼Œæ‰€ä»¥ä½ **è¦ç¡®ä¿æ‰€é…ç½®çš„ç”¨æˆ·åæˆ–è€…ç»„åä¸èƒ½å‡ºç°ä¸Šè¿° system: å‰ç¼€**ã€‚é™¤äº†å¯¹å‰ç¼€çš„é™åˆ¶ä¹‹å¤–ï¼ŒRBAC é‰´æƒç³»ç»Ÿä¸å¯¹ç”¨æˆ·åæ ¼å¼ä½œä»»ä½•è¦æ±‚ã€‚

æœåŠ¡è´¦æˆ·ï¼ˆServiceAccountï¼‰ çš„ç”¨æˆ·åå‰ç¼€ä¸º system:serviceaccount:ï¼Œå±äºå‰ç¼€ä¸º system:serviceaccounts: çš„ç”¨æˆ·ç»„ã€‚

- **system:serviceaccount**: ï¼ˆå•æ•°ï¼‰æ˜¯ç”¨äºæœåŠ¡è´¦æˆ·ç”¨æˆ·åçš„å‰ç¼€
- **system:serviceaccounts**: ï¼ˆå¤æ•°ï¼‰æ˜¯ç”¨äºæœåŠ¡è´¦æˆ·ç»„åçš„å‰ç¼€



**RoleBinding ç¤ºä¾‹**

ä¸‹é¢ç¤ºä¾‹æ˜¯ RoleBinding ä¸­çš„ç‰‡æ®µï¼Œä»…å±•ç¤ºå…¶ subjects çš„éƒ¨åˆ†



**å¯¹äºåç§°ä¸º alice@example.com çš„ç”¨æˆ·ï¼š**

```yaml
subjects:
- kind: User
  name: "alice@example.com"
  apiGroup: rbac.authorization.k8s.io
```



**å¯¹äºåç§°ä¸º frontend-admins çš„ç”¨æˆ·ç»„ï¼š**

```yaml
subjects:
- kind: Group
  name: "frontend-admins"
  apiGroup: rbac.authorization.k8s.io

```



**å¯¹äº kube-system åå­—ç©ºé—´ä¸­çš„é»˜è®¤æœåŠ¡è´¦æˆ·ï¼š**

```yaml
subjects:
- kind: ServiceAccount
  name: default
  namespace: kube-system
```



**å¯¹äº "qa" åç§°ç©ºé—´ä¸­çš„æ‰€æœ‰æœåŠ¡è´¦æˆ·ï¼š**

```yaml
subjects:
- kind: Group
  name: system:serviceaccounts:qa
  apiGroup: rbac.authorization.k8s.io
```



**å¯¹äºåœ¨ä»»ä½•åå­—ç©ºé—´ä¸­çš„æœåŠ¡è´¦æˆ·ï¼š**

```yaml
subjects:
- kind: Group
  name: system:serviceaccounts
  apiGroup: rbac.authorization.k8s.io
```



**å¯¹äºæ‰€æœ‰å·²ç»è¿‡èº«ä»½è®¤è¯çš„ç”¨æˆ·ï¼š**

```yaml
subjects:
- kind: Group
  name: system:authenticated
  apiGroup: rbac.authorization.k8s.io
```



**å¯¹äºæ‰€æœ‰æœªé€šè¿‡èº«ä»½è®¤è¯çš„ç”¨æˆ·ï¼š**

```yaml
subjects:
- kind: Group
  name: system:unauthenticated
  apiGroup: rbac.authorization.k8s.io
```



**å¯¹äºæ‰€æœ‰ç”¨æˆ·ï¼š**

```yaml
subjects:
- kind: Group
  name: system:authenticated
  apiGroup: rbac.authorization.k8s.io
- kind: Group
  name: system:unauthenticated
  apiGroup: rbac.authorization.k8s.io
```

**æ³¨æ„**

```ABAP
RoleBinding çš„æƒé™ä½œç”¨èŒƒå›´ä»…é™äºå…¶æ‰€åœ¨çš„å‘½åç©ºé—´ã€‚å³ä½¿ç»‘å®šçš„è§’è‰²ï¼ˆRoleï¼‰å®šä¹‰äº†å¯ä»¥æ“ä½œæŸäº›èµ„æºçš„æƒé™ï¼Œè¿™äº›æƒé™ä¹Ÿåªèƒ½åœ¨ RoleBinding æ‰€åœ¨çš„å‘½åç©ºé—´å†…ç”Ÿæ•ˆã€‚
```





##### UAç»‘å®š

**ç”¨æˆ·ç»‘å®šå±æ€§ç®€ä»‹**

```bash
#æŸ¥çœ‹rolebindingçš„å±æ€§ä¿¡æ¯
[root@master1 ~]# kubectl explain rolebinding
apiVersion        <string>
kind              <string>
metadata          <Object>
roleRef           <Object> -required
subjects          <[]Object>

#ç»“æœæ˜¾ç¤ºï¼šå¯¹äºè§’è‰²ç»‘å®šæ¥è¯´ï¼Œä¸»è¦æ¶‰åŠåˆ°ä¸¤ç‚¹ï¼šsubjectå’Œå¯¹åº”çš„roleæƒé™åˆ—è¡¨ï¼Œå…¶ä¸­roleRefæ˜¯å¿…é€‰é¡¹ã€‚

#å‘½ä»¤å¼å‘½ä»¤ï¼š
kubectl create rolebinding NAME --clusterrole=NAME|--role=NAME [--user=username] [--group=groupname] [--namespace=namespace_name]

#å¯ä»¥ç»‘å®šåˆ°Roleï¼Œä¹Ÿå¯ä»¥ç»‘å®šåˆ°ClusterRoleï¼Œåè€…ä¼šå°†ClusterRoleçš„æƒé™ç¼©å‡è‡³å½“å‰åç§°ç©ºé—´ä¹‹å†…
#Subjectå¯ä»¥æ˜¯Userã€Groupæˆ–è€…ServiceAccount

#ç¤ºä¾‹ï¼šå°†ç”¨æˆ·tomç»‘å®šè‡³è§’è‰²pods-viewerä¹‹ä¸Š,æ³¨æ„ï¼špods-viewerå’Œtom-attachto-pods-vieweréƒ½è¦æ±‚åœ¨defaultåç§°ç©ºé—´ä¸­
kubectl create rolebinding tom-attachto-pods-viewer --role=pods-viewer --user=tom --namespace=default
#è€Œåå¯æµ‹è¯•tomç”¨æˆ·æ˜¯å¦å¯è¯»å–defaultåç§°ç©ºé—´å†…çš„podsèµ„æºï¼Œä»¥åŠå…¶å®ƒèµ„æº
```



**èŒƒä¾‹: é…ç½®æ–‡ä»¶**

```yaml
# å‡†å¤‡ä¸€ä¸ªroleèµ„æºæ–‡ä»¶ï¼Œå…è®¸ç”¨æˆ·æ“ä½œDeploymentï¼ŒPodï¼ŒRSçš„æ‰€æœ‰æƒé™
[root@master1 sa] # cat security-role-myrole.yaml 
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: myrole
rules:
- apiGroups: ["", "extensions", "apps"]
  resources: ["pods", "deployments", "replicasets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  
  
# ä»¥pod-sa-adminæˆ–è€…wangçš„subjectæ¥ä¸myroleè¿›è¡Œä¸€æ¬¡æ¨¡æ‹Ÿç»‘å®šæŸ¥çœ‹å±æ€§æ•ˆæœ
[root@master1 ~]#kubectl create rolebinding test-myrole --role=myrole --user=test -o yaml --dry-run
W0109 22:24:54.445293  235536 helpers.go:703] --dry-run is deprecated and can be replaced with --dry-run=client.
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  creationTimestamp: null
  name: test-myrole
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: myrole
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: User
  name: test


# åˆ›å»ºkubeconfigæ–‡ä»¶
[root@master1 sa] # kubectl config set-cluster mykube --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server="https://10.0.0.201:6443" --kubeconfig=$HOME/.kube/mykube.conf
Cluster "mykube" set.

[root@master1 sa] # kubectl config set-credentials test --token="fd3e78.2a0395a1c58fb561" --kubeconfig=$HOME/.kube/mykube.conf
User "test" set.

[root@master1 sa] # kubectl config set-context test@mykube --cluster=mykube --user=test --kubeconfig=$HOME/.kube/mykube.conf 
Context "test@mykube" created.
[root@master1 sa]#

# ä½¿ç”¨è¢«æˆæƒçš„testè´¦å·è¿›è¡Œæµ‹è¯•
# defaultä¸‹çš„podèµ„æºå¯ä»¥è®¿é—®
[root@master1 sa] # kubectl get pod --context=test@mykube --kubeconfig=$HOME/.kube/mykube.conf
NAME           READY   STATUS    RESTARTS        AGE
pod-sa-admin   1/1     Running   2 (3h33m ago)   2d21h

# defaultä¸‹çš„secretsèµ„æºæ²¡æœ‰æƒé™è®¿é—®
[root@master1 sa]#kubectl get secrets --context=test@mykube --kubeconfig=$HOME/.kube/mykube.conf
Error from server (Forbidden): secrets is forbidden: User "test" cannot list resource "secrets" in API group "" in the namespace "default"

# å…¶ä»–åç§°ç©ºé—´çš„podèµ„æºä¹Ÿæ²¡æœ‰æƒé™è®¿é—®
[root@master1 sa]#kubectl get pod -n kube-system --context=test@mykube --kubeconfig=$HOME/.kube/mykube.conf
Error from server (Forbidden): pods is forbidden: User "test" cannot list resource "pods" in API group "" in the namespace "kube-system"
```



##### SAç»‘å®š

SAå¯ä»¥è·¨åç§°ç©ºé—´è¿›è¡Œæˆæƒï¼Œæ¯”å¦‚:åç§°ç©ºé—´Açš„SAå¸å·å¯ä»¥æˆæƒç»™åç§°ç©ºé—´Bçš„æƒé™ï¼Œç”šè‡³å¯¹æ‰€æœ‰åç§°ç©ºé—´æˆæƒ



**å‘½ä»¤æ ¼å¼**

```bash
# æŸ¥çœ‹saçš„è§’è‰²ç»‘å®šæ ¼å¼
kubectl create rolebinding NAME --role=NAME [--serviceaccount=namespace:serviceaccoutname] [--namespace=namespace_name]

# æ³¨æ„ï¼šåœ¨åŸºäºæœåŠ¡è´¦å·è¿›è¡Œå…³è”çš„æ—¶å€™ï¼Œéœ€è¦å…³æ³¨ä¸€ä¸‹è¯¥SAæ‰€å±çš„namespaceä¿¡æ¯ã€‚
```



**èŒƒä¾‹**

```bash
# è‡ªå»ºçš„saæ˜¯adminè€Œä¸”æ˜¯å±äºdefaultç©ºé—´ï¼Œå…ˆå°†adminå’Œmyroleè¿›è¡Œç»‘å®šï¼ŒæŸ¥çœ‹ä¸€ä¸‹æ•ˆæœ
[root@master1 sa] # kubectl create rolebinding myrolebinding1 --role=myrole --serviceaccount=default:admin
rolebinding.rbac.authorization.k8s.io/myrolebinding1 created

# æŸ¥çœ‹æ•ˆæœ
[root@master1 sa]#kubectl describe rolebinding myrolebinding1 
Name:         myrolebinding1
Labels:       <none>
Annotations:  <none>
Role:
  Kind:  Role
  Name:  myrole
Subjects:
  Kind            Name   Namespace
  ----            ----   ---------
  ServiceAccount  admin  default
```



##### ç»¼åˆæ¡ˆä¾‹

**å®ç°Jenkinsçš„æƒé™**

è¿è¡ŒKubernetesä¸Šçš„Jenkinsï¼Œä¸ºèƒ½å¤ŸåŠ¨æ€åˆ›å»ºjenkins-slaveç›¸å…³çš„Podï¼Œéœ€è¦å¯¹è¿è¡Œè¯¥Podå¯¹åº”çš„ServiceAccountè¿›è¡Œè®¤è¯å’Œæˆæƒ

```yaml
# åˆ›å»ºRole
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: jenkins-master
  namespace: jenkins
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["create", "delete", "get", "list", "patch", "update", "watch"]
  - apiGroups: [""]
    resources: ["pods/exec"]
    verbs: ["create", "delete", "get", "list", "patch", "update", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["watch"]
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get"]

---
# åˆ›å»ºSA
apiVersion: v1
kind: ServiceAccount
metadata:
  name: jenkins-master
  namespace: jenkins

---
# è§’è‰²ç»‘å®š
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: jenkins-master
  namespace: jenkins
roleRef:
  kind: Role
  name: jenkins-master
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: jenkins-master
  namespace: jenkins     # è¿™é‡ŒæŒ‡å®šSAæ˜¯jenkinsåç§°ç©ºé—´ä¸‹çš„SAï¼Œå› ä¸ºSAæ˜¯åç§°ç©ºé—´çº§åˆ«çš„èµ„æº
```



#### ClusterRoleå’ŒClusterRoleBindingç»„åˆå®ç°

clusterçº§åˆ«çš„å®è·µä¸»è¦æ¶‰åŠåˆ°clusterRoleå’ŒClusterRoleBindingä¹‹é—´çš„æ“ä½œï¼Œå³å¯ä»¥æ“ä½œ**é›†ç¾¤å†…æ‰€æœ‰ namespaceç©ºé—´çš„èµ„æº**ã€‚



##### åˆ›å»ºClusterrole

```bash
# kubectl explain clusterrole
aggregationRule     <Object>   #å¯ä»¥å®ç°roleçš„åµŒå¥—å…³ç³»
apiVersion <string>
kind <string>
metadata     <Object>
rules        <[]Object>
  apiGroups           <[]string>
  nonResourceURLs     <[]string>
  resourceNames       <[]string>
  resources           <[]string>
  verbs               <[]string> -required-
  
#ç»“æœæ˜¾ç¤ºï¼šclusterroleç›¸å¯¹äºroleçš„å±æ€§å¤šäº†ä¸€ä¸ªé›†ä¸­æ§åˆ¶å™¨çš„å±æ€§aggregationRuleï¼Œè€Œè¿™æ˜¯ä¸€ä¸ªå¯é€‰çš„å±æ€§


# æŸ¥çœ‹ä¸€ä¸ªç®€å•çš„é…ç½®æ ¼å¼
[root@master1 sa]#kubectl create clusterrole myclusterrole --verb=get,list --resource=pods -o yaml --dry-run=client
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: myclusterrole
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
#ç»“æœæ˜¾ç¤ºï¼šå•ä»æ¨¡æ¿çš„èµ„æºé…ç½®æ ·å¼æ¥è¯´ï¼Œå…¶é…ç½®ä¿¡æ¯ä¸roleçš„é…ç½®ä¿¡æ¯å‡ ä¹ä¸€æ ·
```



**`aggregationRule` çš„å«ä¹‰å’Œç”¨æ³•**

åœ¨ Kubernetes ä¸­ï¼Œ`aggregationRule` æ˜¯ `ClusterRole` çš„ä¸€ä¸ªå±æ€§ï¼Œå®ƒå…è®¸å®ç°**è§’è‰²çš„åµŒå¥—å…³ç³»**ã€‚é€šè¿‡ `aggregationRule`ï¼Œä½ å¯ä»¥åŠ¨æ€ç»„åˆå¤šä¸ª `ClusterRole` çš„æƒé™ï¼Œä½¿å¾—ä¸€ä¸ª `ClusterRole` å¯ä»¥èšåˆå…¶ä»–è§’è‰²çš„æƒé™ã€‚



**`aggregationRule` çš„ç»“æ„**

- **`clusterRoleSelectors`**ï¼šè¿™æ˜¯ `aggregationRule` çš„æ ¸å¿ƒå­—æ®µï¼Œç”¨äºæŒ‡å®šä¸€ä¸ª LabelSelectorï¼Œé€šè¿‡åŒ¹é…å…¶ä»– `ClusterRole` çš„æ ‡ç­¾æ¥èšåˆå…¶æƒé™ã€‚

  - ç»“æ„ç¤ºä¾‹

  ```yaml
  aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        rbac.example.com/aggregate-to-admin: "true"
    - matchLabels:
        rbac.example.com/aggregate-to-edit: "true"
  ```

  

**`aggregationRule` çš„ç”¨æ³•**

- **åŠ¨æ€èšåˆè§’è‰²æƒé™**
  - `aggregationRule` å…è®¸å°†å…¶ä»– `ClusterRole` çš„è§„åˆ™åŠ¨æ€åœ°ç»„åˆåˆ°å½“å‰è§’è‰²ä¸­ã€‚
  - å¦‚æœæŸä¸ª `ClusterRole` çš„æ ‡ç­¾åŒ¹é…äº† `aggregationRule` ä¸­çš„ `clusterRoleSelectors`ï¼Œå®ƒçš„æƒé™ä¼šè‡ªåŠ¨æ·»åŠ åˆ°å®šä¹‰äº† `aggregationRule` çš„è§’è‰²ä¸­ã€‚



**è¯¦ç»†ç¤ºä¾‹**

- **åœºæ™¯:** å‡è®¾æˆ‘ä»¬å¸Œæœ›åˆ›å»ºä¸€ä¸ªåä¸º `super-admin` çš„è§’è‰²ï¼Œè¯¥è§’è‰²éœ€è¦èšåˆä¸¤ä¸ªå­è§’è‰²çš„æƒé™
  - ä¸€ä¸ªè§’è‰² `read-only`ï¼Œåªèƒ½å¯¹èµ„æºæ‰§è¡Œåªè¯»æ“ä½œã€‚
  - ä¸€ä¸ªè§’è‰² `edit`ï¼Œå¯ä»¥ç¼–è¾‘èµ„æºã€‚

- **å­è§’è‰²å®šä¹‰**ï¼š

  - **`read-only` ClusterRole**

  ```YAML
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: read-only
    labels:
      rbac.example.com/aggregate-to-super-admin: "true"
  rules:
  - apiGroups: [""]
    resources: ["pods", "services"]
    verbs: ["get", "list"]
  ```

  - **`edit` ClusterRole**

  ```yaml
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: edit
    labels:
      rbac.example.com/aggregate-to-super-admin: "true"
  rules:
  - apiGroups: [""]
    resources: ["pods", "services"]
    verbs: ["get", "list", "create", "update", "delete"]
  ```

- **èšåˆè§’è‰²å®šä¹‰**

  - ä½¿ç”¨ `aggregationRule` åŠ¨æ€èšåˆè¿™ä¸¤ä¸ªè§’è‰²ï¼š

  ```yaml
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: super-admin
  aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        rbac.example.com/aggregate-to-super-admin: "true"
  ```

  - **èšåˆç»“æœ**
    - `super-admin` è§’è‰²è‡ªåŠ¨ç»§æ‰¿äº† `read-only` å’Œ `edit` çš„è§„åˆ™ã€‚
    - ä¸éœ€è¦æ‰‹åŠ¨å†™è§„åˆ™ï¼Œåªè¦æŸä¸ªè§’è‰²è¢«æ‰“ä¸Š `rbac.example.com/aggregate-to-super-admin: "true"` æ ‡ç­¾ï¼Œå®ƒçš„æƒé™å°±ä¼šåŠ¨æ€æ·»åŠ åˆ° `super-admin` ä¸­ã€‚



**`aggregationRule` çš„ä¼˜åŠ¿**

- **åŠ¨æ€èšåˆæƒé™**ï¼š
  - æ— éœ€æ‰‹åŠ¨ç»´æŠ¤ç»„åˆè§’è‰²çš„æƒé™è§„åˆ™ï¼Œåªéœ€ç»™å­è§’è‰²æ‰“ä¸Šç‰¹å®šçš„æ ‡ç­¾å³å¯
- **æ¨¡å—åŒ–å’Œå¤ç”¨**ï¼š
  - å­è§’è‰²å¯ä»¥å•ç‹¬ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥é€šè¿‡èšåˆè§„åˆ™ç»„åˆæˆæ›´å¤§çš„æƒé™é›†ï¼Œä¾¿äºå¤ç”¨ã€‚
- **ç®€åŒ–ç®¡ç†**
  - å½“éœ€è¦æ‰©å±•æƒé™æ—¶ï¼Œåªéœ€åˆ›å»ºæ–°è§’è‰²å¹¶æ·»åŠ å¯¹åº”çš„æ ‡ç­¾ï¼Œä¸»èšåˆè§’è‰²ä¼šè‡ªåŠ¨æ›´æ–°æƒé™



**`aggregationRule` æ³¨æ„äº‹é¡¹**

- **åªé€‚ç”¨äº `ClusterRole`**ï¼š
  - ç›®å‰ `aggregationRule` ä»…èƒ½ç”¨äºèšåˆ `ClusterRole`ï¼Œä¸èƒ½ç”¨äº `Role`ã€‚
- **åŠ¨æ€æ›´æ–°**ï¼š
  - å¦‚æœä¿®æ”¹äº†æŸä¸ªå­è§’è‰²çš„è§„åˆ™æˆ–æ ‡ç­¾ï¼Œèšåˆè§’è‰²ä¼šåŠ¨æ€æ›´æ–°ï¼Œæ— éœ€é‡æ–°åˆ›å»ºã€‚
- **æ ‡ç­¾ç®¡ç†**ï¼š
  - å­è§’è‰²éœ€è¦æ­£ç¡®é…ç½®æ ‡ç­¾ï¼Œç¡®ä¿èƒ½è¢«èšåˆè§„åˆ™é€‰æ‹©åˆ°ã€‚





##### è§’è‰²ç»‘å®šClusterrolebinding

```bash
# å‘½ä»¤æ ¼å¼
kubectl create clusterrolebinding NAME --clusterrole=NAME [--user=username] [--group=groupname]
[--serviceaccount=namespace:serviceaccountname] [--dry-run=server|client|none] [options]

#å±æ€§è§£æ:å¯¹äºclusterrolebindingæ¥è¯´ï¼Œä»…ä»…å…è®¸é›†ç¾¤è§’è‰²è¿›è¡Œå’Œå…¶è¿›è¡Œç»‘å®šï¼Œå¯¹äºæ™®é€šçš„roleæ¥è¯´å°±æ— æ•ˆäº†

#å°†wangç”¨æˆ·å’Œmyclasterroleè¿›è¡Œè§’è‰²ç»‘å®šï¼ŒæŸ¥çœ‹èµ„æºé…ç½®æ•ˆæœ
[root@master1 sa]#kubectl create clusterrolebinding myclusterrolebinding --clusterrole=myclusterrole --user=test --dry-run=client -o yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: myclusterrolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: myclusterrole
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: User
  name: test

#å±æ€§è§£æï¼šè¿™é‡Œçš„å±æ€§é…ç½®ä¸æˆ‘ä»¬ä¹‹å‰çš„roleå’Œrolebindingçš„æ–¹æ³•å‡ ä¹ä¸€æ ·,åŒºåˆ«å°±æ˜¯kindå’Œ--clusterroleçš„ä¸åŒ
```



##### æ¡ˆä¾‹: å®ç° Prometheus çš„æƒé™

å°†Prometheuséƒ¨ç½²è¿è¡ŒäºKubernetesä¹‹ä¸Šå¹¶ç›‘æ§é›†ç¾¤æ—¶ï¼Œéœ€è¦ä½¿ç”¨ä¸“ç”¨çš„ServiceAccountè¿è¡Œè¯¥Pod å¹¶è®¤è¯å’Œæˆæƒåˆ°API Server

```yaml
[root@master1 sa] # vim clusterrolebinding-prometheus.yaml
# ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]

---
# åˆ›å»ºSA
apiVersion: v1 
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: prom

---
# ClusterRoleBinding
apiVersion: rbac.authoriaztion.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: prom
```



#### ClusterRoleå’ŒRoleBingdingæ··åˆç»„åˆå®ç°



##### å®ç°å¯¹æŒ‡å®šå¤šä¸ªåç§°ç©ºé—´çš„èµ„æºè®¾ç½®ç‰¹å®šæƒé™

å®ç°å¯¹æŒ‡å®šå¤šä¸ªåç§°ç©ºé—´çš„èµ„æºè®¾ç½®ç‰¹å®šæƒé™çš„æ–¹æ³•ï¼Œä½†éœ€è¦ç»„åˆä½¿ç”¨ **`RoleBinding`** å’Œ **`ClusterRole`**

**å®ç°æ€è·¯**

- åˆ›å»ºä¸€ä¸ª `ClusterRole`
  - `ClusterRole` æ˜¯é›†ç¾¤çº§åˆ«çš„è§’è‰²ï¼Œå¯ä»¥æŒ‡å®šèµ„æºçš„æ“ä½œæƒé™ï¼Œä½†ä¸ç»‘å®šåˆ°ä»»ä½•ç‰¹å®šåç§°ç©ºé—´ã€‚
- åœ¨ç›®æ ‡åç§°ç©ºé—´ä¸­åˆ›å»ºå¤šä¸ª `RoleBinding`
  - æ¯ä¸ª `RoleBinding` å°†è¯¥ `ClusterRole` ç»‘å®šåˆ°æŒ‡å®šçš„åç§°ç©ºé—´å’Œå¯¹åº”çš„ç”¨æˆ·æˆ–æœåŠ¡è´¦æˆ·



**ç¤ºä¾‹é…ç½®**ï¼šå‡è®¾éœ€è¦åœ¨ `namespace1` å’Œ `namespace2` ä¸­ï¼Œèµ‹äºˆ `UserA` å¯¹ `pods` å’Œ `services` èµ„æºçš„åªè¯»æƒé™ã€‚

- **åˆ›å»º `ClusterRole`**

  ```yaml
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: readonly-pods-services
  rules:
  - apiGroups: [""]
    resources:
    - pods
    - services
    verbs:
    - get
    - list
    - watch
  ```

- **ä¸º `namespace1` åˆ›å»º `RoleBinding`**

  ```yaml
  apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    name: readonly-access
    namespace: namespace1  # ç»‘å®šåˆ° namespace1
  subjects:
  - kind: User
    name: UserA  # æˆäºˆæƒé™çš„ç”¨æˆ·
    apiGroup: rbac.authorization.k8s.io
  roleRef:
    kind: ClusterRole
    name: readonly-pods-services  # å¼•ç”¨ä¸Šé¢å®šä¹‰çš„ ClusterRole
    apiGroup: rbac.authorization.k8s.io
  ```

- **ä¸º `namespace2` åˆ›å»º `RoleBinding`**

  ```yaml
  apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    name: readonly-access
    namespace: namespace2  # ç»‘å®šåˆ° namespace2
  subjects:
  - kind: User
    name: UserA  # æˆäºˆæƒé™çš„ç”¨æˆ·
    apiGroup: rbac.authorization.k8s.io
  roleRef:
    kind: ClusterRole
    name: readonly-pods-services  # å¼•ç”¨ä¸Šé¢å®šä¹‰çš„ ClusterRole
    apiGroup: rbac.authorization.k8s.io
  ```



**å·¥ä½œåŸç†**

- `ClusterRole` å®šä¹‰äº†å¯¹èµ„æºçš„å…·ä½“æƒé™ï¼Œä½†ä¸é™å®šä½œç”¨èŒƒå›´
- `RoleBinding` å°†è¯¥ `ClusterRole` çš„æƒé™é™å®šåœ¨æŒ‡å®šçš„åç§°ç©ºé—´ä¸­ï¼Œå¹¶æŒ‡å®šç”¨æˆ·æˆ–æœåŠ¡è´¦æˆ·ã€‚
- æ¯ä¸ª `RoleBinding` åªåœ¨å…¶æ‰€åœ¨çš„åç§°ç©ºé—´ä¸­ç”Ÿæ•ˆï¼Œå› æ­¤å¯ä»¥é€šè¿‡åœ¨å¤šä¸ªåç§°ç©ºé—´ä¸­åˆ›å»º `RoleBinding`ï¼Œå®ç°å¯¹ç‰¹å®šå¤šä¸ªåç§°ç©ºé—´çš„èµ„æºè¿›è¡Œæƒé™æ§åˆ¶ã€‚



### å›¾å½¢åŒ–é¢æ¿

#### kuboard

```ABAP
å®˜ç½‘ï¼šhttps://kuboard.cn/install/v3/install.html
```

![image-20250111162025438](../markdown_img/image-20250111162025438.png)



##### ä»¥Dockeræ–¹å¼åœ¨é›†ç¾¤å¤–éƒ¨ç½²

```bash
sudo docker run -d \
  --restart=unless-stopped \
  --name=kuboard \
  -p 80:80/tcp \
  -p 10081:10081/tcp \
  -e KUBOARD_ENDPOINT="http://å†…ç½‘IP:80" \
  -e KUBOARD_AGENT_SERVER_TCP_PORT="10081" \
  -v /root/kuboard-data:/data \
  eipwork/kuboard:v3
  # ä¹Ÿå¯ä»¥ä½¿ç”¨é•œåƒ swr.cn-east-2.myhuaweicloud.com/kuboard/kuboard:v3 ï¼Œå¯ä»¥æ›´å¿«åœ°å®Œæˆé•œåƒä¸‹è½½ã€‚
  # è¯·ä¸è¦ä½¿ç”¨ 127.0.0.1 æˆ–è€… localhost ä½œä¸ºå†…ç½‘ IP \
  # Kuboard ä¸éœ€è¦å’Œ K8S åœ¨åŒä¸€ä¸ªç½‘æ®µï¼ŒKuboard Agent ç”šè‡³å¯ä»¥é€šè¿‡ä»£ç†è®¿é—® Kuboard Server \

```





##### åŸºäºKubernetesé›†ç¾¤ä¸­éƒ¨ç½²

**ä½¿ç”¨StorageClassæŒä¹…åŒ–**

```yaml
[root@master1 nfc-sc] # cat rbac.yaml 
apiVersion: v1
kind: Namespace
metadata:
  name: nfs-provisioner-demo
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  # replace with namespace where provisioner is deployed æ ¹æ®ä¸šåŠ¡éœ€è¦ä¿®æ”¹æ­¤å¤„åç§°ç©ºé—´
  namespace: nfs-provisioner-demo
  
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
  - apiGroups: [""]
    resources: ["services", "endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "delete"]
    
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: nfs-provisioner-demo
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
  
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: nfs-provisioner-demo
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
    
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: nfs-provisioner-demo
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: nfs-provisioner-demo
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io


[root@master1 nfc-sc] # cat nfs-client-provisioner.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  labels:
    app: nfs-client-provisioner
  namespace: nfs-provisioner-demo
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
      - name: nfs-client-provisioner     
        image: k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2 #æ­¤é•œåƒå›½å†…å¯èƒ½æ— æ³•è®¿é—®
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: nfs-client-root
          mountPath: /persistentvolumes
        env:
        - name: PROVISIONER_NAME
          value: k8s-sigs.io/nfs-subdir-external-provisioner # åç§°ç¡®ä¿ä¸nfs-StorageClass.yamlæ–‡ä»¶ä¸­çš„provisioneråç§°ä¿æŒä¸€è‡´
        - name: NFS_SERVER
          value: nfs.mystical.org
        - name: NFS_PATH
          value: /nfs-data/sc-nfs
      volumes:
      - name: nfs-client-root
        nfs:
          server: nfs.mystical.org
          path: /nfs-data/sc-nfs


[root@master1 nfc-sc] # cat nfs-storageClass.yaml 
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-nfs
  annotations:
    storageclass.kubernetes.io/is-default-class: "false" # æ˜¯å¦è®¾ç½®ä¸ºé»˜è®¤çš„storageClass
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner # or choose another name, must match deployment's env PROVISIONER_NAME
parameters:
  archiveOnDelete: "true"   # å³ä½¿åˆ é™¤PVCï¼Œä¾ç„¶ä¼šä¿ç•™æ•°æ®
```



**è·å–éƒ¨ç½² Kuboard æ‰€éœ€çš„ YAML æ–‡ä»¶**

```bash
curl -o kuboard-v3.yaml https://addons.kuboard.cn/kuboard/kuboard-v3-storage-class.yaml
```



**ç¼–è¾‘ `kuboard-v3.yaml` æ–‡ä»¶ä¸­çš„é…ç½®ï¼Œè¯¥éƒ¨ç½²æ–‡ä»¶ä¸­ï¼Œæœ‰ä¸¤å¤„é…ç½®å¿…é¡»ä¿®æ”¹**

```bash
# KUBOARD_ENDPOINT
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kuboard-v3-config
  namespace: kuboard
data:
  # å…³äºå¦‚ä¸‹å‚æ•°çš„è§£é‡Šï¼Œè¯·å‚è€ƒæ–‡æ¡£ https://kuboard.cn/install/v3/install-built-in.html
  # [common]
  KUBOARD_ENDPOINT: 'http://your-node-ip-address:30080' # è¿™é‡Œæ”¹ä¸ºè‡ªå·±æŒ‡å®šçš„åŸŸåï¼Œåç»­ç”¨ingressæš´éœ²ï¼Œæ‰€ä»¥ä¸ç”¨å†™ç«¯å£
 #KUBOARD_ENDPOINT: 'http://kuboard.mystical.org'
  KUBOARD_AGENT_SERVER_UDP_PORT: '30081'
  KUBOARD_AGENT_SERVER_TCP_PORT: '30081'

# storageClassName
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      # è¯·å¡«å†™ä¸€ä¸ªæœ‰æ•ˆçš„ StorageClass name
      storageClassName: please-provide-a-valid-StorageClass-name-here
      #storageClassName: sc-nfs
      accessModes: [ "ReadWriteMany" ]
      resources:
        requests:
          storage: 5Gi

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kuboard-data-pvc
  namespace: kuboard   # è¿™é‡Œå®˜æ–¹æ²¡æœ‰åŠ åç§°ç©ºé—´ï¼Œä½†æ˜¯PVCæ˜¯åç§°ç©ºé—´èµ„æºï¼Œè¿™é‡Œéœ€è¦åŠ ä¸Š
spec:
  # è¯·å¡«å†™ä¸€ä¸ªæœ‰æ•ˆçš„ StorageClass name
  storageClassName:  please-provide-a-valid-StorageClass-name-here
  #storageClassName: sc-nfs
  accessModes:
    - ReadWriteOnce
    
    
# ä¸Šè¿°å®˜æ–¹æ–‡ä»¶ä¿®æ”¹åï¼Œåº”ç”¨
[root@master1 ~] # kubectl apply -f kuboard-v3.yaml 
namespace/kuboard created
configmap/kuboard-v3-config created
statefulset.apps/kuboard-etcd created
persistentvolumeclaim/kuboard-data-pvc created
service/kuboard-etcd created
deployment.apps/kuboard-v3 created
service/kuboard-v3 created


# æ·»åŠ ingressï¼Œè¦æå‰éƒ¨ç½²ingress-nginx
[root@ubuntu2204 ~]# kubectl create ingress kuboard-ingress --rule=kuboard.mystical.org/*=kuboard-v3:80 --class nginx -n kuboard -o yaml --dry-run=client > kuboard-ingress.yaml

[root@ubuntu2204 ~]#kubectl apply -f kuboard-ingress.yaml 
ingress.networking.k8s.io/kuboard-ingress created

[root@ubuntu2204 ~]#kubectl get ingress -n kuboard
NAME              CLASS   HOSTS                  ADDRESS     PORTS   AGE
kuboard-ingress   nginx   kuboard.mystical.org   10.0.0.10   80      21s

# åœ¨å®¿ä¸»æœºè§£æåŸŸåååœ¨æµè§ˆå™¨è®¿é—®kuboard.mystical.org
# é»˜è®¤ç”¨æˆ·åï¼šadmin
# é»˜è®¤å¯†ç ï¼šKuboard123
```

![image-20250111203856817](../markdown_img/image-20250111203856817.png)

![image-20250112195241195](../markdown_img/image-20250112195241195.png)



#### KubeSphere

```ABAP
å®˜ç½‘ï¼šhttps://www.kubesphere.io/zh/docs/v3.4/installing-on-linux/introduction/multioverview/
```



![image-20250111162716226](../markdown_img/image-20250111162716226.png)



##### éƒ¨ç½²KubeSphere

ç¡®ä¿æ‚¨çš„æœºå™¨æ»¡è¶³å®‰è£…çš„å‰ææ¡ä»¶ä¹‹åï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®‰è£… KubeSphereã€‚

```bash
wget https://github.com/kubesphere/ks-installer/releases/download/v3.4.1/kubesphere-installer.yaml

# åœ¨è¯¥æ–‡ä»¶æŒ‡å®šå­˜å‚¨ï¼Œæˆ–è€…é…ç½®å¥½é»˜è®¤å­˜å‚¨
wget https://github.com/kubesphere/ks-installer/releases/download/v3.4.1/cluster-configuration.yaml
```

å¯ä»¥é€šè¿‡ä¿®æ”¹`cluster-configuration.yaml`ï¼Œæ¥å¯ç”¨å¯æ’æ‹”æ’ä»¶ï¼Œæ¯”å¦‚æ—¥å¿—ï¼Œå•†åº—ï¼Œå‘Šè­¦ç­‰

![image-20250409093047769](../markdown_img/image-20250409093047769.png)

æ¯”å¦‚å¯ç”¨æ—¥å¿—ç³»ç»Ÿ

![image-20250409093135861](../markdown_img/image-20250409093135861.png)

æ¯”å¦‚å®‰è£…Devopsï¼Œå…¶å®å°±æ˜¯éƒ¨ç½²ä¸ªjenkins

![image-20250409093347609](../markdown_img/image-20250409093347609.png)

ä¹Ÿå¯ä»¥å¯ç”¨åéƒ¨ç½²

![image-20250409093423471](../markdown_img/image-20250409093423471.png)

![image-20250409104100121](../markdown_img/image-20250409104100121.png)

![image-20250409104403003](../markdown_img/image-20250409104403003.png)

![image-20250409104431982](../markdown_img/image-20250409104431982.png)



å¯ç”¨éƒ¨ç½²

```bash
[root@master-01 kubesphere]# kubectl apply -f kubesphere-installer.yaml 
customresourcedefinition.apiextensions.k8s.io/clusterconfigurations.installer.kubesphere.io created
namespace/kubesphere-system created
serviceaccount/ks-installer created
clusterrole.rbac.authorization.k8s.io/ks-installer created
clusterrolebinding.rbac.authorization.k8s.io/ks-installer created
deployment.apps/ks-installer created

[root@master-01 kubesphere]# kubectl apply  -f cluster-configuration.yaml 
clusterconfiguration.installer.kubesphere.io/ks-installer created

```

æ£€æŸ¥å®‰è£…æ—¥å¿—ï¼š

```bash
kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f
```

ä½¿ç”¨ `kubectl get pod --all-namespaces` æŸ¥çœ‹æ‰€æœ‰ Pod æ˜¯å¦åœ¨ KubeSphere çš„ç›¸å…³å‘½åç©ºé—´ä¸­æ­£å¸¸è¿è¡Œã€‚å¦‚æœæ˜¯ï¼Œè¯·é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ£€æŸ¥æ§åˆ¶å°çš„ç«¯å£ï¼ˆé»˜è®¤ä¸º `30880`ï¼‰ï¼š

```bash
kubectl get svc/ks-console -n kubesphere-system
```

ç¡®ä¿åœ¨å®‰å…¨ç»„ä¸­æ‰“å¼€äº†ç«¯å£ `30880`ï¼Œå¹¶é€šè¿‡ NodePort `(IP:30880)` ä½¿ç”¨é»˜è®¤å¸æˆ·å’Œå¯†ç  `(admin/P@88w0rd)` è®¿é—® Web æ§åˆ¶å°



æ‰§è¡Œä¸‹åˆ—å‘½ä»¤

```bash
[root@master1 kubesphere]#kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f

# æ˜¾ç¤ºä¸‹æ–¹
......
**************************************************
Collecting installation results ...
#####################################################
###              Welcome to KubeSphere!           ###
#####################################################

Console: http://172.22.201.124:30880
Account: admin
Password: P@88w0rd
NOTESï¼š
  1. After you log into the console, please check the
     monitoring status of service components in
     "Cluster Management". If any service is not
     ready, please wait patiently until all components 
     are up and running.
  2. Please change the default password after login.

#####################################################
https://kubesphere.io             2025-02-11 13:35:25
#####################################################

```

è®¿é—®http://172.22.201.124:30880

![image-20250211135114480](../markdown_img/image-20250211135114480.png)

![image-20250211135302152](../markdown_img/image-20250211135302152.png)



##### å¸è½½KubeSphere

```bash
# ä¸‹è½½å®˜æ–¹çš„å¸è½½è„šæœ¬
[root@master-01 ~]# wget https://github.com/kubesphere/ks-installer/blob/release-3.1/scripts/kubesphere-delete.sh

# å¸è½½k8sèµ„æº
[root@master-01 ~]# kubectl delete statefulsets.apps -n kubesphere-logging-system elasticsearch-logging-data
[root@master-01 ~]# kubectl delete statefulsets.apps -n kubesphere-logging-system elasticsearch-logging-discovery
[root@master-01 ~]# kubectl delete statefulsets.apps -n kubesphere-system openldap
[root@master-01 ~]# kubectl delete daemonsets.apps -n kubesphere-monitoring-system node-exporter

[root@master-01 ~]#  ./kubesphere-delete.sh

[root@master-01 ~]#  kubectl get pv | awk '{print $1}'
[root@master-01 ~]#  kubectl delete pv PV_NAME

# æœ€ååˆ æ‰kubesphereåˆ›å»ºçš„æ‰€æœ‰çš„namespace
```



## Kubernetesæœ‰çŠ¶æ€æœåŠ¡ç®¡ç†

**æœ¬ç« å†…å®¹**

- **StatefulSet**
- **CRD**
- **Operator**



### StatefulSet

#### StatefulSet æœºåˆ¶

```http
https://kubernetes.io/zh-cn/docs/tutorials/stateful-application/
https://kubernetes.io/zh-cn/docs/tasks/run-application/run-single-instance-stateful-application/
```



##### åº”ç”¨çŠ¶æ€è¯´æ˜

**æ— çŠ¶æ€ å’Œ æœ‰çŠ¶æ€**

- **æ— çŠ¶æ€ï¼ˆStatelessï¼‰**

  æ— çŠ¶æ€çš„ç³»ç»Ÿä¸ä¼šåœ¨å¤šä¸ªè¯·æ±‚ä¹‹é—´ä¿å­˜ä»»ä½•çŠ¶æ€ä¿¡æ¯ã€‚æ¯ä¸ªè¯·æ±‚éƒ½ç‹¬ç«‹å¤„ç†ï¼Œä¸è€ƒè™‘ä¹‹å‰çš„è¯·æ±‚æˆ–çŠ¶æ€ã€‚

  æ— çŠ¶æ€çš„æ¯æ¬¡çš„è¯·æ±‚éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œå®ƒçš„æ‰§è¡Œæƒ…å†µå’Œç»“æœä¸å‰é¢çš„è¯·æ±‚å’Œä¹‹åçš„è¯·æ±‚æ˜¯æ— ç›´æ¥å…³ç³» çš„ï¼Œå®ƒä¸ä¼šå—å‰é¢çš„è¯·æ±‚åº”ç­”æƒ…å†µç›´æ¥å½±å“ï¼Œä¹Ÿä¸ä¼šç›´æ¥å½±å“åé¢çš„è¯·æ±‚åº”ç­”æƒ…å†µ

  å…¸å‹çš„æ— çŠ¶æ€ç³»ç»ŸåŒ…æ‹¬HTTPåè®®ã€RESTful APIç­‰ã€‚æ¯ä¸ªè¯·æ±‚éƒ½åŒ…å«äº†è¶³å¤Ÿçš„ä¿¡æ¯æ¥å®Œæˆå…¶å¤„ç†ï¼Œ æœåŠ¡å™¨ä¸éœ€è¦ä¿å­˜ä»»ä½•å®¢æˆ·ç«¯çš„çŠ¶æ€ä¿¡æ¯ã€‚

- **æœ‰çŠ¶æ€ï¼ˆStatefulsetï¼‰**

  æœ‰çŠ¶æ€çš„ç³»ç»Ÿåœ¨å¤„ç†è¯·æ±‚æˆ–é€šä¿¡æ—¶ä¼šè®°ä½ä¹‹å‰çš„çŠ¶æ€ä¿¡æ¯ã€‚è¿™æ„å‘³ç€ç³»ç»Ÿä¼šå­˜å‚¨å®¢æˆ·ç«¯çš„å†å²ä¿¡æ¯ æˆ–çŠ¶æ€ï¼Œå¹¶åŸºäºè¿™äº›ä¿¡æ¯è¿›è¡Œå¤„ç†

  æœ‰çŠ¶æ€åº”ç”¨ä¼šåœ¨å…¶ä¼šè¯ä¸­ä¿å­˜å®¢æˆ·ç«¯çš„æ•°æ®ï¼Œå¹¶ä¸”æœ‰å¯èƒ½ä¼šåœ¨å®¢æˆ·ç«¯ä¸‹ä¸€æ¬¡çš„è¯·æ±‚ä¸­ä½¿ç”¨è¿™äº›æ•°æ®

  åº”ç”¨ä¸Šå¸¸è§çš„çŠ¶æ€ç±»å‹:ä¼šè¯çŠ¶æ€ã€è¿æ¥çŠ¶æ€ã€é…ç½®çŠ¶æ€ã€é›†ç¾¤çŠ¶æ€ã€æŒä¹…æ€§çŠ¶æ€ç­‰

  å…¸å‹çš„æœ‰çŠ¶æ€ç³»ç»ŸåŒ…æ‹¬æ•°æ®åº“ç³»ç»Ÿã€TCPè¿æ¥ç­‰ã€‚è¿™äº›ç³»ç»Ÿéœ€è¦åœ¨é€šä¿¡è¿‡ç¨‹ä¸­ç»´æŠ¤çŠ¶æ€ä¿¡æ¯ï¼Œä»¥ç¡® ä¿æ•°æ®çš„å¯é æ€§å’Œä¸€è‡´æ€§ã€‚

**æ— çŠ¶æ€å’Œæœ‰çŠ¶æ€åº”ç”¨åŒºåˆ«**

- **å¤æ‚åº¦**ï¼šæœ‰çŠ¶æ€ç³»ç»Ÿé€šå¸¸æ¯”æ— çŠ¶æ€ç³»ç»Ÿæ›´å¤æ‚ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦ç»´æŠ¤å’Œç®¡ç†çŠ¶æ€ä¿¡æ¯ã€‚æ— çŠ¶æ€ç³»ç»Ÿåˆ™ æ›´ç®€å•ï¼Œå› ä¸ºå®ƒä»¬ä¸éœ€è¦å¤„ç†çŠ¶æ€ä¿¡æ¯ã€‚
- **å¯ä¼¸ç¼©æ€§**ï¼šæ— çŠ¶æ€ç³»ç»Ÿé€šå¸¸æ›´æ˜“äºæ‰©å±•ï¼Œå› ä¸ºå®ƒä»¬ä¸éœ€è¦è€ƒè™‘ä¼šè¯çŠ¶æ€ï¼Œå¯ä»¥æ›´å®¹æ˜“åœ°å®ç°è´Ÿè½½å‡ è¡¡å’Œæ°´å¹³æ‰©å±•ã€‚æœ‰çŠ¶æ€ç³»ç»Ÿå¯èƒ½éœ€è¦æ›´å¤æ‚çš„çŠ¶æ€ç®¡ç†å’ŒåŒæ­¥æœºåˆ¶ï¼Œå› æ­¤åœ¨å¤§è§„æ¨¡åº”ç”¨ä¸­å¯èƒ½éœ€è¦ æ›´å¤šçš„èµ„æºå’Œè®¾è®¡è€ƒè™‘ã€‚

å¤§å‹åº”ç”¨é€šå¸¸å…·æœ‰ä¼—å¤šåŠŸèƒ½æ¨¡å—ï¼Œè¿™äº›æ¨¡å—é€šå¸¸ä¼šè¢«è®¾è®¡ä¸º**æœ‰çŠ¶æ€æ¨¡å—**å’Œ**æ— çŠ¶æ€æ¨¡å—**ä¸¤éƒ¨åˆ†

- ä¸šåŠ¡é€»è¾‘æ¨¡å—ä¸€èˆ¬ä¼šè¢«è®¾è®¡ä¸ºæ— çŠ¶æ€ï¼Œè¿™äº›æ¨¡å—éœ€è¦å°†å…¶çŠ¶æ€æ•°æ®ä¿å­˜åœ¨æœ‰çŠ¶æ€çš„ä¸­é—´ä»¶æœåŠ¡ä¸Šï¼Œ å¦‚æ¶ˆæ¯é˜Ÿåˆ—ã€æ•°æ®åº“æˆ–ç¼“å­˜ç³»ç»Ÿç­‰
- æ— çŠ¶æ€çš„ä¸šåŠ¡é€»è¾‘æ¨¡å—æ˜“äºæ¨ªå‘æ‰©å±•ï¼Œæœ‰çŠ¶æ€çš„åç«¯åˆ™å­˜åœ¨ä¸åŒçš„éš¾é¢˜

Http åè®®æ˜¯æ— çŠ¶æ€çš„ï¼Œå¯¹äºhttpåè®®æœ¬èº«çš„æ¯ä¸€æ¬¡è¯·æ±‚éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œå½¼æ­¤ä¹‹é—´æ²¡æœ‰å…³è”å…³ç³»ã€‚

è€Œ Http ç›¸å…³çš„åº”ç”¨å¾€å¾€æ˜¯æœ‰çŠ¶æ€çš„ã€‚

å¾ˆå¤šçš„ Web ç¨‹åºæ˜¯éœ€è¦æœ‰å¤§é‡çš„ä¸šåŠ¡é€»è¾‘ç›¸äº’å…³è”æ‰å¯ä»¥å®ç°æœ€ç»ˆçš„ç›®æ ‡ï¼Œä¹Ÿå°±æ˜¯è¯´åŸºäºhttpåè®®çš„ webåº”ç”¨ç¨‹åºæ˜¯æœ‰çŠ¶æ€çš„ã€‚

åªä¸è¿‡è¿™ä¸ªçŠ¶æ€æ˜¯éœ€è¦å€ŸåŠ©äºå…¶ä»–çš„æœºåˆ¶æ¥å®ç°ï¼Œæ¯”å¦‚ cookiesã€sessionã€tokenä»¥åŠå…¶ä»–è¾…åŠ©çš„æœº åˆ¶ã€‚

ä¸ºäº†å®ç°httpçš„ä¼šè¯æœ‰çŠ¶æ€ï¼ŒåŸºäº cookiesã€sessionã€tokenç­‰æœºåˆ¶éƒ½æ¶‰åŠåˆ°æ–‡ä»¶çš„ä¿å­˜ï¼Œè¦ä¹ˆä¿å­˜åˆ° å®¢æˆ·ç«¯ï¼Œè¦ä¹ˆä¿å­˜åˆ°æœåŠ¡ç«¯ã€‚

ä»¥sessionä¸ºä¾‹ï¼Œå°±åœ¨æœåŠ¡ç«¯ä¿å­˜ç›¸å…³çš„ä¿¡æ¯ï¼Œæé«˜æ­£å¸¸é€šä¿¡çš„æ•ˆç‡ã€‚

å®é™…çš„ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œwebç¨‹åºä¸ºäº†ä¿è¯é«˜å¯ç”¨ï¼Œæ‰€ä»¥é€šè¿‡é›†ç¾¤çš„æ–¹å¼å®ç°ï¼Œåº”ç”¨çš„è®¿é—®åˆ†å¸ƒå¼æ•ˆæœã€‚

åœ¨è¿™ç§åœºæ™¯ä¸­ï¼Œå¯ä»¥åŸºäºä¸‹é¢æ–¹æ³•å®ç°æœ‰çŠ¶æ€çš„ä¼šè¯ä¿æŒ

- **session sticky** - æ ¹æ®ç”¨æˆ·çš„è¡Œä¸ºæ•°æ®ï¼Œæ‰¾åˆ°ä¸Šæ¬¡å“åº”è¯·æ±‚çš„æœåŠ¡å™¨ï¼Œç›´æ¥å“åº”
- **session cluster** - é€šè¿‡æœåŠ¡é›†ç¾¤ä¹‹é—´çš„é€šä¿¡æœºåˆ¶å®ç°ä¼šè¯æ•°æ®çš„åŒæ­¥
- **session server** - å€ŸåŠ©äºä¸€ä¸ªä¸“ç”¨çš„æœåŠ¡å™¨æ¥ä¿å­˜ä¼šè¯ä¿¡æ¯ã€‚



ç”Ÿäº§ä¸­ä¸€äº›ä¸­é—´ä»¶ä¸šåŠ¡é›†ç¾¤ï¼Œæ¯”å¦‚MySQLé›†ç¾¤ã€Redisé›†ç¾¤ã€ElasticSearché›†ç¾¤ã€MongoDBé›†ç¾¤ã€ Nacosé›†ç¾¤ã€MinIOé›†ç¾¤ã€Zookeeperé›†ç¾¤ã€Kafkaé›†ç¾¤ã€RabbitMQé›†ç¾¤ç­‰

è¿™äº›åº”ç”¨é›†ç¾¤éƒ½æœ‰ä»¥ä¸‹ç›¸åŒç‰¹ç‚¹ï¼š

- æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰å›ºå®šçš„èº«ä»½IDï¼Œé›†ç¾¤æˆå‘˜é€šè¿‡èº«ä»½IDè¿›è¡Œé€šä¿¡
- é›†ç¾¤çš„è§„æ¨¡æ˜¯æ¯”è¾ƒå›ºå®šçš„ï¼Œä¸€èˆ¬ä¸èƒ½éšæ„å˜åŠ¨
- èŠ‚ç‚¹éƒ½æ˜¯ç”±çŠ¶æ€çš„ï¼Œè€Œä¸”çŠ¶æ€æ•°æ®é€šå¸¸ä¼šåšæŒä¹…åŒ–å­˜å‚¨
- é›†ç¾¤ä¸­æŸä¸ªèŠ‚ç‚¹å‡ºç°æ•…éšœï¼Œé›†ç¾¤åŠŸèƒ½è‚¯å®šå—åˆ°å½±å“ã€‚

åƒè¿™ç§çŠ¶æ€ç±»å‹çš„æœåŠ¡ï¼Œåªè¦è¿‡ç¨‹ä¸­å­˜åœ¨ä¸€ç‚¹é—®é¢˜ï¼Œé‚£ä¹ˆå½±å“åŠèŒƒå›´éƒ½æ˜¯ä¸å¯é¢„æµ‹ã€‚

**åº”ç”¨ç¼–æ’å·¥ä½œè´Ÿè½½å‹æ§åˆ¶å™¨**

- æ— çŠ¶æ€åº”ç”¨ç¼–æ’:Deployment<--ReplicaSet
- ç³»ç»Ÿçº§åº”ç”¨ç¼–æ’:DaemonSet
- æœ‰çŠ¶æ€åº”ç”¨ç¼–æ’: StatefulSet
- ä½œä¸šç±»åº”ç”¨ç¼–æ’:CronJob <--job



##### StatefulSet å·¥ä½œæœºåˆ¶

###### StatefulSet ä»‹ç»

Podçš„ç®¡ç†å¯¹è±¡æœ‰Deploymentï¼ŒRSã€DaemonSetã€RCè¿™äº›éƒ½æ˜¯é¢å‘æ— çŠ¶æ€çš„æœåŠ¡ï¼Œæ»¡è¶³ä¸äº†ä¸Šè¿°çš„æœ‰ çŠ¶æ€é›†ç¾¤çš„åœºæ™¯éœ€æ±‚

ä»Kubernetes-v1.4ç‰ˆæœ¬å¼•å…¥äº†é›†ç¾¤çŠ¶æ€ç®¡ç†çš„åŠŸèƒ½ï¼Œv1.5ç‰ˆæœ¬æ›´åä¸ºStatefulSet æœ‰çŠ¶æ€åº”ç”¨å‰¯æœ¬é›†

StatefulSet æœ€æ—©åœ¨ Kubernetes 1.5 ç‰ˆæœ¬ä¸­å¼•å…¥ï¼Œä½œä¸ºä¸€ä¸ª alpha ç‰¹æ€§ã€‚ç»è¿‡å‡ ä¸ªç‰ˆæœ¬çš„æ”¹è¿›å’Œç¨³å®šï¼Œ åœ¨ Kubernetes 1.9 ç‰ˆæœ¬ä¸­ï¼ŒStatefulSet å˜æˆäº†ä¸€ä¸ªç¨³å®šçš„ã€é€šç”¨å¯ç”¨ï¼ˆGAï¼ŒGeneral Availabilityï¼‰çš„ ç‰¹æ€§ã€‚

StatefulSet æ—¨åœ¨ä¸æœ‰çŠ¶æ€çš„åº”ç”¨åŠåˆ†å¸ƒå¼ç³»ç»Ÿä¸€èµ·ä½¿ç”¨ã€‚ç„¶è€Œåœ¨ Kubernetes ä¸Šç®¡ç†æœ‰çŠ¶æ€åº”ç”¨å’Œåˆ†å¸ƒ å¼ç³»ç»Ÿæ˜¯ä¸€ä¸ªå®½æ³›è€Œå¤æ‚çš„è¯é¢˜ã€‚

ç”±äºæ¯ä¸ªæœ‰çŠ¶æ€æœåŠ¡çš„ç‰¹ç‚¹ï¼Œå·¥ä½œæœºåˆ¶å’Œé…ç½®æ–¹å¼éƒ½å­˜åœ¨å¾ˆå¤§çš„ä¸åŒï¼Œå› æ­¤å½“å‰Kuberneteså¹¶æ²¡æœ‰æä¾› ç»Ÿä¸€çš„å…·ä½“çš„è§£å†³æ–¹æ¡ˆ

```ABAP
è€Œ Statefulset åªæ˜¯ä¸ºæœ‰çŠ¶æ€åº”ç”¨æä¾›äº†åŸºç¡€æ¡†æ¶ï¼Œè€Œéå®Œæ•´çš„è§£å†³æ–¹æ¡ˆ
å¦‚æœæƒ³å®ç°å…·ä½“çš„æœ‰çŠ¶æ€åº”ç”¨ï¼Œå»ºè®®å¯ä»¥ä½¿ç”¨ç›¸åº”çš„ä¸“ç”¨ Operator å®ç°
```



###### StatefulSet ç‰¹ç‚¹

- æ¯ä¸ªPod éƒ½æœ‰ç¨³å®šã€å”¯ä¸€çš„ç½‘ç»œè®¿é—®æ ‡è¯†
- æ¯ä¸ª**Pod å½¼æ­¤é—´çš„é€šä¿¡åŸºäºHeadless Serviceå®ç°**
- StatefulSet æ§åˆ¶çš„Podå‰¯æœ¬å¯åŠ¨ã€æ‰©å±•ã€åˆ é™¤ã€æ›´æ–°ç­‰æ“ä½œéƒ½æ˜¯æœ‰é¡ºåºçš„
- StatefulSeté‡Œçš„æ¯ä¸ªPodå­˜å‚¨çš„æ•°æ®ä¸åŒï¼Œæ‰€ä»¥é‡‡ç”¨ä¸“ç”¨çš„ç¨³å®šç‹¬ç«‹çš„æŒä¹…åŒ–å­˜å‚¨å·ï¼Œç”¨äºå­˜å‚¨ Podçš„çŠ¶æ€æ•°æ®



###### StatefulSet å¯¹åº”Pod çš„ç½‘ç»œæ ‡è¯†

- æ¯ä¸ªStatefulSetå¯¹è±¡å¯¹åº”äºä¸€ä¸ªä¸“ç”¨çš„Headless Service å¯¹è±¡

- ä½¿ç”¨ Headless service ç»™æ¯ä¸€ä¸ªStatufulSetæ§åˆ¶çš„Podæä¾›ä¸€ä¸ªå”¯ä¸€çš„DNSåŸŸåæ¥ä½œä¸ºæ¯ä¸ªæˆå‘˜çš„ ç½‘ç»œæ ‡è¯†
- æ¯ä¸ªPodéƒ½ä¸€ä¸ªä»0å¼€å§‹ï¼Œä»å°åˆ°çš„åºå·çš„åç§°ï¼Œåˆ›å»ºå’Œæ‰©å®¹æ—¶åºå·ä»å°åˆ°å¤§ï¼Œåˆ é™¤ï¼Œç¼©å®¹å’Œæ›´æ–° é•œåƒæ—¶ä»å¤§åˆ°å°
- é€šè¿‡ClusterDNSè§£æä¸ºPodçš„åœ°å€ï¼Œä»è€Œå®ç°é›†ç¾¤å†…éƒ¨æˆå‘˜ä¹‹é—´ä½¿ç”¨åŸŸåé€šä¿¡

æ¯ä¸ªPodå¯¹åº”çš„DNSåŸŸåæ ¼å¼ï¼š

```bash
$(statefulset_name)-$(orederID).$(headless_service_name).$(namespace_name).svc.cluster.local
 
#ç¤ºä¾‹
mysql-0.mysql.wordpress.svc.cluster.local
mysql-1.mysql.wordpress.svc.cluster.local
mysql-2.mysql.wordpress.svc.cluster.local
```



###### StatefulSetçš„ Pod ç®¡ç†ç­–ç•¥ Pod Management Policy

å®šä¹‰åˆ›å»ºã€åˆ é™¤åŠæ‰©ç¼©å®¹ç­‰ç®¡ç†æ“ä½œæœŸé—´ï¼Œåœ¨Podå‰¯æœ¬ä¸Šçš„åˆ›å»ºä¸¤ç§æ¨¡å¼

- **OrderedReady**

  åˆ›å»ºæˆ–æ‰©å®¹æ—¶ï¼Œ**é¡ºæ¬¡**å®Œæˆå„Podå‰¯æœ¬çš„åˆ›å»ºï¼Œä¸”è¦æ±‚åªæœ‰å‰ä¸€ä¸ªPodè½¬ä¸ºReadyçŠ¶æ€åï¼Œæ‰èƒ½è¿›è¡Œåä¸€ä¸ªPodå‰¯æœ¬çš„åˆ›å»º

  åˆ é™¤æˆ–ç¼©å®¹æ—¶ï¼Œé€†åºã€ä¾æ¬¡å®Œæˆç›¸å…³Podå‰¯æœ¬çš„ç»ˆæ­¢

- **Parallel**

  å„Podå‰¯æœ¬çš„åˆ›å»ºæˆ–åˆ é™¤æ“ä½œä¸å­˜åœ¨é¡ºåºæ–¹é¢çš„è¦æ±‚ï¼Œå¯åŒæ—¶è¿›è¡Œ



###### StatefulSet çš„å­˜å‚¨æ–¹å¼

- åŸºäºpodTempiateå®šä¹‰Podæ¨¡æ¿
- åœ¨`podTemplate`ä¸Šä½¿ç”¨`volumeTemplate`ä¸ºå„Podå‰¯æœ¬åŠ¨æ€ç½®å¤‡`PersistentVolume`
- å› ä¸ºæ¯ä¸ªPodå­˜å‚¨çš„çŠ¶æ€æ•°æ®ä¸å°½ç›¸åŒï¼Œæ‰€ä»¥åœ¨åˆ›å»ºæ¯ä¸€ä¸ªPodå‰¯æœ¬æ—¶ç»‘å®šè‡³ä¸“æœ‰çš„å›ºå®šçš„PVC
-  **PVCçš„åç§°éµå¾ªç‰¹å®šçš„æ ¼å¼ï¼Œä»è€Œèƒ½å¤Ÿä¸StatefulSetæ§åˆ¶å™¨å¯¹è±¡çš„Podå‰¯æœ¬å»ºç«‹ç´§å¯†çš„å…³è”å…³ç³»**
- æ”¯æŒä»é™æ€ç½®å¤‡æˆ–åŠ¨æ€ç½®å¤‡çš„PVä¸­å®Œæˆç»‘å®š
- åˆ é™¤Pod(ä¾‹å¦‚ç¼©å®¹)ï¼Œå¹¶ä¸ä¼šä¸€å¹¶åˆ é™¤ç›¸å…³çš„PVC



###### StatefulSet ç»„ä»¶

| ç»„ä»¶                | æè¿°                                                         |
| ------------------- | ------------------------------------------------------------ |
| headless service    | ä¸€èˆ¬çš„Podåç§°æ˜¯éšæœºçš„ï¼Œè€Œä¸ºäº†statefulsetçš„å”¯ä¸€æ€§ï¼Œæ‰€ä»¥å€Ÿç”¨ headless serviceé€šè¿‡å”¯ä¸€çš„"ç½‘ç»œæ ‡è¯†"æ¥ç›´æ¥æŒ‡å®šçš„podåº”ç”¨ï¼Œæ‰€ä»¥å®ƒè¦æ±‚æˆ‘ä»¬çš„**dnsç¯å¢ƒ**æ˜¯å®Œå¥½çš„ã€‚<br />å½“ä¸€ä¸ªStatefulSetæŒ‚æ‰ï¼Œæ–°åˆ›å»ºçš„StatefulSetä¼šè¢«èµ‹äºˆè·ŸåŸæ¥çš„Pod ä¸€æ ·çš„åå­—ï¼Œé€šè¿‡è¿™ä¸ªåå­—æ¥åŒ¹é…åˆ°åŸæ¥çš„å­˜å‚¨ï¼Œå®ç°äº†çŠ¶æ€ä¿å­˜ã€‚ |
| volumeClaimTemplate | æœ‰çŠ¶æ€é›†ç¾¤ä¸­çš„å‰¯æœ¬æ•°æ®æ˜¯ä¸ä¸€æ ·çš„(ä¾‹ï¼šredis)ï¼Œå¦‚æœç”¨å…±äº«å­˜å‚¨çš„ è¯ï¼Œä¼šå¯¼è‡´å¤šå‰¯æœ¬é—´çš„æ•°æ®è¢«è¦†ç›–ï¼Œä¸ºäº†statefulsedæ•°æ®æŒä¹…åŒ–ï¼Œéœ€è¦å°†podå’Œå…¶ç”³è¯·çš„æ•°æ®å·éš”ç¦»å¼€ï¼Œ**æ¯ä¸€ç§podéƒ½æœ‰å…¶ç‹¬ç«‹çš„å¯¹åº”çš„æ•°æ®å·é…ç½®æ¨¡æ¿**ï¼Œæ¥æ»¡è¶³è¯¥è¦æ±‚ã€‚ |



###### StatefulSet å±€é™æ€§

æ ¹æ®å¯¹ StatefulSetçš„åŸç†è§£æï¼Œå¦‚æœå®ç°ä¸€ä¸ªé€šç”¨çš„æœ‰çŠ¶æ€åº”ç”¨çš„é›†ç¾¤ï¼Œé‚£åŸºæœ¬æ²¡æœ‰å¯èƒ½å®Œæˆ

åŸå› æ˜¯ä¸åŒçš„åº”ç”¨é›†ç¾¤ï¼Œå…¶å†…éƒ¨çš„çŠ¶æ€æœºåˆ¶å‡ ä¹æ˜¯å®Œå…¨ä¸åŒçš„

| é›†ç¾¤           | è§£æ                                                         |
| -------------- | ------------------------------------------------------------ |
| MySQL ä¸»ä»é›†ç¾¤ | å½“å‘å½“å‰æ•°æ®åº“é›†ç¾¤æ·»åŠ ä»è§’è‰²èŠ‚ç‚¹çš„æ—¶å€™ï¼Œå¯ä¸ä»…ä»…ä¸ºæ·»åŠ ä¸€ä¸ªå”¯ä¸€çš„èŠ‚ç‚¹æ ‡è¯†åŠå¯¹ åº”çš„åç«¯å­˜å‚¨å°±å®Œäº†ã€‚æˆ‘ä»¬è¦æå‰çŸ¥é“ï¼Œä»è§’è‰²èŠ‚ç‚¹çš„æ—¶é—´ã€æ•°æ®å¤åˆ¶çš„èµ·å§‹ä½ç½®(æ—¥å¿—æ–‡ä»¶åã€æ—¥å¿—ä½ç½®ã€æ—¶é—´æˆ³ç­‰)ï¼Œç„¶åæ‰å¯ä»¥è¿›è¡Œæ•°æ®çš„åŒæ­¥ã€‚ |
| Redis ä¸»ä»é›†ç¾¤ | é›†ç¾¤ä¸­ï¼Œæ·»åŠ èŠ‚ç‚¹çš„æ—¶å€™ï¼Œä¼šè‡ªåŠ¨æ ¹æ®slaveofè®¾å®šçš„ä¸»è§’è‰²èŠ‚ç‚¹ä¸Šè·å–æœ€æ–°çš„æ•°æ®ï¼Œ ç„¶åç›´æ¥åœ¨æœ¬åœ°è¿˜åŸï¼Œç„¶åå€ŸåŠ©äºè½¯ä»¶ä¸“ç”¨çš„æœºåˆ¶è¿›è¡Œæ•°æ®çš„åŒæ­¥æœºåˆ¶ã€‚ |

- StatefulSetæœ¬èº«çš„ä»£ç æ— æ³•è€ƒè™‘å‘¨å…¨åˆ°æ‰€æœ‰çš„é›†ç¾¤çŠ¶æ€æœºåˆ¶
- StatefulSet åªæ˜¯æä¾›äº†ä¸€ä¸ªåŸºç¡€çš„ç¼–æ’æ¡†æ¶
- æœ‰çŠ¶æ€åº”ç”¨æ‰€éœ€è¦çš„ç®¡ç†æ“ä½œï¼Œéœ€è¦ç”±ç”¨æˆ·è‡ªè¡Œç¼–å†™ä»£ç å®Œæˆ

è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæ—©æœŸçš„Kubernetesåªèƒ½è¿è¡Œæ— çŠ¶æ€çš„åº”ç”¨ï¼Œä¸ºäº†å®ç°æ‰€è°“çš„çŠ¶æ€é›†ç¾¤æ•ˆæœï¼Œåªèƒ½å°†æ‰€æœ‰çš„ æœ‰çŠ¶æ€æœåŠ¡ç‹¬ç«‹ç®¡ç†ï¼Œç„¶åä»¥è‡ªå»ºEndPointæˆ–è€…ExternalNameçš„æ–¹å¼å¼•å…¥åˆ°Kubernetesé›†ç¾¤ä¸­ï¼Œå®ç° æ‰€è°“çš„ç±»ä¼¼çŠ¶æ€æ•ˆæœ.

å½“å‰è€Œè¿™ç§æ–¹æ³•ä»ç„¶åœ¨å¾ˆå¤šä¼ä¸šä¸­ä½¿ç”¨ã€‚



##### StatefulSet é…ç½®

æ³¨æ„ï¼šStatefulSeté™¤äº†éœ€è¦å®šä¹‰è‡ªèº«çš„æ ‡ç­¾é€‰æ‹©å™¨å’ŒPodæ¨¡æ¿ç­‰å±æ€§å­—æ®µï¼ŒStatefulSetå¿…é¡»è¦é…ç½®ä¸€ä¸ªä¸“ç”¨çš„Headless Serviceï¼Œè€Œä¸”è¿˜å¯èƒ½è¦æ ¹æ®éœ€è¦ï¼Œç¼–å†™ä»£ç å®Œæˆæ‰©å®¹ã€ç¼©å®¹ç­‰åŠŸèƒ½æ‰€ä¾èµ–çš„å¿…è¦æ“ä½œæ­¥éª¤

**å±æ€§è§£æ**

```yaml
apiVersion: apps/v1                    # APIç¾¤ç»„åŠç‰ˆæœ¬
kind: StatefulSet                      # èµ„æºç±»å‹çš„ç‰¹æœ‰æ ‡è¯†
metadata:             
  name: <string>                       # èµ„æºåç§°ï¼Œåœ¨ä½œç”¨åŸŸä¸­è¦å”¯ä¸€
  namespace: <string>                  # åç§°ç©ºé—´ï¼šStatefulsetéš¶å±åç§°ç©ºé—´çº§åˆ«
spec:
  replicas: <integer>                  # æœŸæœ›çš„podå‰¯æœ¬æ•°ï¼Œé»˜è®¤ä¸º1
  selector: <object>                   # æ ‡ç­¾é€‰æ‹©å™¨ï¼Œé¡»åŒ¹é…podæ¨¡ç‰ˆä¸­çš„æ ‡ç­¾ï¼Œå¿…é€‰å­—æ®µ
  template: <object>                   # podæ¨¡ç‰ˆå¯¹è±¡ï¼Œå¿…é€‰å­—æ®µ
  revisionHistoryLimit: <integer>      # æ»šåŠ¨æ›´æ–°å†å²è®°å½•æ•°é‡ï¼Œé»˜è®¤ä¸º10
  updateStragegy: <Object>             # æ»šåŠ¨æ›´æ–°ç­–ç•¥
    type: <string>                     # æŒ‡å®šæ›´æ–°ç­–ç•¥ç±»å‹ï¼Œå¯ç”¨å€¼ï¼šOnDeleteå’ŒRollingupdate
                                       # OnDelete è¡¨ç¤ºåªæœ‰åœ¨æ‰‹åŠ¨åˆ é™¤æ—§ Pod åæ‰ä¼šè§¦å‘æ›´æ–°
                                       # RollingUpdate è¡¨ç¤ºä¼šè‡ªåŠ¨è¿›è¡Œæ»šåŠ¨æ›´æ–°
    rollingUpdate: <Object>            # æ»šåŠ¨æ›´æ–°å‚æ•°ï¼Œä¸“ç”¨äºRollingUpdateç±»å‹
      maxUnavailable: <integer>        # æ›´æ–°æœŸé—´å¯æ¯”æœŸæœ›çš„Podæ•°é‡ç¼ºå°‘çš„æ•°é‡æˆ–æ¯”ä¾‹
      partition: <integer>             # åˆ†åŒºå€¼ï¼Œè¡¨ç¤ºåªæ›´æ–°å¤§äºç­‰äºæ­¤ç´¢å¼•å€¼çš„Podï¼Œé»˜è®¤ä¸º0,ä¸€èˆ¬ç”¨äºé‡‘ä¸é›€åœºæ™¯ï¼Œæ›´æ–°å’Œ                                              ç¼©å®¹æ—¶éƒ½æ˜¯ç´¢å¼•å·çš„Podä»å¤§åˆ°å°è¿›è¡Œï¼Œå³æŒ‰ä»å¤§åˆ°å°çš„é¡ºåºè¿›è¡Œï¼Œæ¯”å¦‚ï¼š                                                       MySQL2,MySQL-1,MySQL-0
  serviceName: <string>                # ç›¸å…³çš„Headless Serviceçš„åç§°ï¼Œå¿…é€‰å­—æ®µ
    apiVersion: <string>               # PVCèµ„æºæ‰€å±çš„APIç¾¤ç»„åŠç‰ˆæœ¬ï¼Œå¯çœç•¥
    kind: <string>                     # PVCèµ„æºç±»å‹æ ‡è¯†ï¼Œå¯çœç•¥
    metadata: <Object>                 # å·ç”³è¯·æ¨¡æ¿å…ƒæ•°æ®
    spec: <Object>                     # æœŸæœ›çš„çŠ¶æ€ï¼Œå¯ç”¨å­—æ®µåŒPVC
  podManagementPolicy: <string>        # Podç®¡ç†ç­–ç•¥ï¼Œé»˜è®¤â€œOrderedReadyâ€è¡¨ç¤ºé¡ºåºåˆ›å»ºå¹¶é€†åºåˆ é™¤ï¼Œâ€œParallelâ€è¡¨ç¤ºå¹¶                                              è¡Œæ¨¡å¼
  volumeClaimTemplates: <[]Object>     # æŒ‡å®šPVCçš„æ¨¡æ¿.å­˜å‚¨å·ç”³è¯·æ¨¡æ¿ï¼Œå®ç°æ•°æ®æŒä¹…åŒ–
  - metadata:
    name: <string>                     # ç”Ÿæˆçš„PVCçš„åç§°æ ¼å¼ä¸ºï¼š<volumeClaimTemplates>. <StatefulSet>-<orederID>
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: "sc-nfs"       #  å¦‚æœæœ‰åŠ¨æ€ç½®å¤‡çš„StorageClass,å¯ä»¥æŒ‡å®šåç§°
      resources:
        requests:
          storage: 1Gi
```

èŒƒä¾‹:  ç®€å• statefulset

```bash
[root@master1 yaml]# cat statefulset-demo.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: http
  clusterIP: None   # å¯ä½¿ç”¨æ— å¤´æœåŠ¡æˆ–æœ‰å¤´æœåŠ¡,å› ä¸ºæ¯ä¸ªæœ‰çŠ¶æ€æœåŠ¡çš„PodåŠŸèƒ½ä¸åŒ,æ‰€ä»¥ä¸€èˆ¬ä¼šä½¿ç”¨æ— å¤´æœåŠ¡,é˜²æ­¢åˆ©ç”¨åŒä¸€ä¸ªService                       åç§°éšæœºè§£æåˆ°ä¸åŒçš„Pod
  selector:
    app: nginx
    
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  serviceName: "nginx"
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
        ports:
        - containerPort: 80
          name: http
          
[root@master1 yaml]# kubectl apply -f statefulset-demo.yaml

# è§‚å¯Ÿåˆ°PodæŒ‰é¡ºåºåˆ›å»º
[root@master1 ~]#kubectl get pod -w
NAME                        READY   STATUS    RESTARTS       AGE
web-0                       1/1     Running   0              11s
web-1                       1/1     Running   0              7s

# æµ‹è¯•åç§°è§£æ
[root@master1 ~]#kubectl exec pod-test1-cd487559d-cjmxk -- host nginx
nginx.default.svc.cluster.local has address 192.168.123.19
nginx.default.svc.cluster.local has address 192.168.22.162

# æŸ¥çœ‹
[root@master1 ~]#kubectl get pod -o wide 
NAME                        READY   STATUS    RESTARTS       AGE    IP                NODE
web-0                       1/1     Running   0              20m    192.168.123.19    node3.mystical.org   <none>           <none>
web-1                       1/1     Running   0              20m    192.168.22.162    node1.mystical.org   <none>           <none>

# è®¿é—®å®Œæ•´çš„serviceåç§°,æ³¨æ„æœ€åçš„ç‚¹å·
[root@master1 ~]#kubectl exec pod-test1-cd487559d-cjmxk -- host nginx.default.svc.cluster.local.
nginx.default.svc.cluster.local has address 192.168.123.19
nginx.default.svc.cluster.local has address 192.168.22.162

# è®¿é—®æµ‹è¯•
[root@master1 ~]#kubectl exec -it pod-test1-cd487559d-cjmxk -- sh
[root@pod-test1-cd487559d-cjmxk /]# curl nginx
kubernetes pod-test v0.1!! ClientIP: 192.168.22.130, ServerName: web-1, ServerIP: 192.168.22.162!
[root@pod-test1-cd487559d-cjmxk /]# curl nginx
kubernetes pod-test v0.1!! ClientIP: 192.168.22.130, ServerName: web-0, ServerIP: 192.168.123.19!


# è§‚å¯Ÿæ‰©å®¹å’Œç¼©å®¹éƒ½æŒ‰é¡ºåº
[root@master1 ~]#kubectl scale sts web --replicas 5
statefulset.apps/web scaled
[root@master1 ~]#kubectl get statefulsets.apps 
NAME   READY   AGE
web    3/5     4h38m
[root@master1 ~]#kubectl get statefulsets.apps 
NAME   READY   AGE
web    4/5     4h38m
[root@master1 ~]#kubectl get statefulsets.apps 
NAME   READY   AGE
web    5/5     4h38m

# æŸ¥çœ‹æ‰©å®¹å’Œç¼©å®¹çš„è¿‡ç¨‹,æ‰©å®¹æ˜¯Podç¼–å·ä»å°åˆ°å¤§,ç¼©å®¹æ­£å¥½åä¹‹
# è§‚å¯Ÿåˆ°serviceä¸ºæ— å¤´æœåŠ¡
[root@master1 ~]#kubectl get svc nginx
NAME    TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
nginx   ClusterIP   None         <none>        80/TCP    4h48m

# æ”¯æŒç¼©å†™
[root@master1 ~]#kubectl get sts
NAME   READY   AGE
web    5/5     4h54m

# æŸ¥çœ‹ä¸»æœºåå’Œhostè§£æ
[root@master1 ~]#kubectl exec -it web-0 -- hostname
web-0
[root@master1 ~]#kubectl exec -it web-1 -- hostname
web-1
[root@master1 ~]#kubectl exec -it web-2 -- hostname
web-2

[root@master1 ~]#kubectl exec -it web-1 -- cat /etc/hosts
# Kubernetes-managed hosts file.
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
fe00::0	ip6-mcastprefix
fe00::1	ip6-allnodes
fe00::2	ip6-allrouters
192.168.22.162	web-1.nginx.default.svc.cluster.local	web-1
```

èŒƒä¾‹: çº§è”åˆ é™¤å’Œéçº§è”åˆ é™¤

```bash
# é»˜è®¤æ˜¯çº§è”åˆ é™¤,å³åˆ é™¤ sts åŒæ—¶åˆ é™¤ Pod
[root@master1 ~]#kubectl delete sts web 
statefulset.apps "web" deleted

#éçº§è”åˆ é™¤,å³åˆ é™¤stsä¸åŒæ—¶åˆ é™¤Pod,é€‰é¡¹--cascade=orphan(æ—§ç‰ˆfalseåºŸå¼ƒ)
[root@master1 ~]#kubectl delete sts web --cascade=orphan
statefulset.apps "web" deleted

# æŸ¥çœ‹stsåˆ é™¤,Podä»åœ¨,ä½†Podä¸ºå­¤å„¿çŠ¶æ€,å³åˆ é™¤Pod,å°†ä¸ä¼šè¢«é‡å»º
[root@master1 ~]#kubectl get sts
No resources found in default namespace.

[root@master1 ~]#kubectl get pod
web-0                       1/1     Running   0               2m50s
web-1                       1/1     Running   0               2m46s

# åˆ é™¤PodæŸ¥çœ‹æ˜¯å¦è¢«é‡å»º
[root@master1 ~]#kubectl delete pod web-0
pod "web-0" deleted
```



##### StatefulSet æ›´æ–°ç­–ç•¥

æ›´æ–°ç­–ç•¥å¯ä»¥å®ç°æ»šåŠ¨æ›´æ–°å‘å¸ƒ

```yaml
  updateStrategy: <Object>         # æ»šåŠ¨ç­–ç•¥
    type: <string>                 # æ»šåŠ¨æ›´æ–°ç±»å‹ï¼Œå¯ç”¨å€¼æœ‰OnDeleteå’ŒRollingUpdate
    rollingUpdate: <Object>        # æ»šåŠ¨æ›´æ–°å‚æ•°ï¼Œä¸“ç”¨äºRollingUpdateç±»å‹
      partition: <integer>         # åˆ†åŒºæŒ‡ç¤ºç´¢å¼•å€¼ï¼Œé»˜è®¤ä¸º0,ä¸€èˆ¬ç”¨äºç‰ˆæœ¬åˆ†åŒºåŸŸæ›´æ–°åœºæ™¯
```

**å¿«é€Ÿå¯¹æ¯”è¡¨**ï¼š

| ç±»å‹            | å«ä¹‰                                        | æ˜¯å¦è‡ªåŠ¨æ›´æ–° Pod     | ä½¿ç”¨åœºæ™¯                                 | æ˜¯å¦å¸¸ç”¨ |
| --------------- | ------------------------------------------- | -------------------- | ---------------------------------------- | -------- |
| `RollingUpdate` | è‡ªåŠ¨æŒ‰é¡ºåºæ»šåŠ¨æ›´æ–° StatefulSet ä¸­çš„ Pod     | âœ… æ˜¯                 | ç‰ˆæœ¬æ›´æ–°ã€æ— çŠ¶æ€æˆ–è½»å¾®æœ‰çŠ¶æ€çš„æœåŠ¡       | å¸¸ç”¨     |
| `OnDelete`      | ä»…å½“æ‰‹åŠ¨åˆ é™¤ Pod åï¼Œæ‰ä¼šç”¨æ–°çš„ç‰ˆæœ¬é‡æ–°åˆ›å»º | âŒ å¦ï¼ˆéœ€æ‰‹åŠ¨åˆ  Podï¼‰ | å¯¹å‡çº§æ§åˆ¶è¦æ±‚ä¸¥æ ¼çš„æ•°æ®åº“ã€ä¸­é—´ä»¶ç­‰åœºæ™¯ | æ¬¡å¸¸ç”¨   |

**ç»“åˆ `rollingUpdate.partition` ä½¿ç”¨ï¼ˆç°åº¦å‡çº§ï¼‰**

```yaml
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    partition: 1
```

è¡¨ç¤ºåªæœ‰ `ordinal >= 1` çš„ Pod ä¼šè¢«æ›´æ–°ï¼Œæ¯”å¦‚ï¼š

- `pod-1`, `pod-2` ä¼šæ›´æ–°
- `pod-0` ä¿æŒåŸæ ·

ğŸ¯ ç”¨äºç°åº¦æˆ–åˆ†æ‰¹å‡çº§ï¼Œæ¯”å¦‚å…ˆå‡çº§ä»èŠ‚ç‚¹ï¼Œæœ€åå‡çº§ä¸»èŠ‚ç‚¹ã€‚

**èŒƒä¾‹: æ›´æ–°ç­–ç•¥**

```bash
# æŸ¥çœ‹æ›´æ–°ç­–ç•¥
[root@master1 ~]#kubectl get sts web -o yaml|grep -A5 -i UpdateStrategy
  updateStrategy:
    rollingUpdate:
      partition: 0               #æ­¤ç¼–å·è¡¨ç¤ºæ›´æ–°æ—¶åªæ›´æ–°å¤§äºç­‰äºæ­¤ç¼–å·å¯¹åº”çš„Pod,å°äºæ­¤ç¼–å·çš„Podä¸ä¼šæ›´æ–°,0è¡¨ç¤ºæ¯æ¬¡å…¨éƒ¨æ›´                                     æ–°,æ¯”å¦‚:å…±5ä¸ªPod: web{0..4},æ­¤å¤„è®¾ä¸º2,åˆ™ä»Web-2å¼€å§‹æ›´æ–°,å¯ä»¥é€šè¿‡ä¸æ–­ä»å¤§åˆ°å°çš„ä¿®æ”¹æ­¤                                   å€¼,å¯ä»¥å®ç°æ»šåŠ¨æ›´æ–°ç­–ç•¥
    type: RollingUpdate
......

#å‡çº§imageç‰ˆæœ¬
[root@master1 yaml]#kubectl edit sts web
    - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2
    
#è§‚å¯Ÿæ›´æ–°é¡ºåº,å‘ç°Podç¼–å·ä»å¤§åˆ°å°æ›´æ–°
[root@master1 ~]#kubectl get pod
web-0                       1/1     Running       0               5m12s
web-1                       1/1     Terminating   0               5m8s

[root@master1 ~]#kubectl get pod
web-0                       1/1     Running             0               5m16s
web-1                       0/1     ContainerCreating   0               2s

[root@master1 ~]#kubectl get pod
web-0                       1/1     Terminating   0               5m37s
web-1                       1/1     Running       0               23s

[root@master1 ~]#kubectl get pod
web-0                       1/1     Running   0               15s
web-1                       1/1     Running   0               58s

#æ‰©å®¹ä¸º5ä¸ªPod
[root@master1 ~]#kubectl scale sts web --replicas 5

#ä¿®æ”¹æ›´æ–°ç­–ç•¥ä¸º4
[root@master1 ~]#kubectl edit sts web
.....
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.3  #ä¿®æ”¹é•œåƒç‰ˆæœ¬
.....
  updateStrategy:
    rollingUpdate:
      partition: 4  #å°†æ­¤å¤„çš„0ä¿®æ”¹ä¸º4
    type: RollingUpdate
.....

#ç¡®è®¤web-4ä»¥ä¸‹Podä¸æ›´æ–°
[root@master1 ~]#kubectl get pod web-4 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.3
[root@master1 ~]#kubectl get pod web-3 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2
[root@master1 ~]#kubectl get pod web-2 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2
[root@master1 ~]#kubectl get pod web-1 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2
[root@master1 ~]#kubectl get pod web-0 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2
  
# ä¿®æ”¹æ›´æ–°ç­–ç•¥ä¸º1
[root@master1 ~]#kubectl edit sts web
......
  updateStrategy:
    rollingUpdate:
      partition: 1  #ä¿®æ”¹æ­¤å¤„ä¸º1
    type: RollingUpdate
......

#è§‚å¯Ÿç»“æœ,å‘ç°web-1ä»¥ä¸Šéƒ½æ›´æ–°
[root@master1 ~]#kubectl get pod web-4 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.3
[root@master1 ~]#kubectl get pod web-3 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.3
[root@master1 ~]#kubectl get pod web-2 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.3
[root@master1 ~]#kubectl get pod web-1 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.3
[root@master1 ~]#kubectl get pod web-0 -o yaml|grep -m1  image
  - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.2
  
# ä¿®æ”¹æ›´æ–°ç­–ç•¥ä¸ºOnDelete,è¡¨ç¤ºåªæœ‰åˆ é™¤æ—¶æ‰æ›´æ–°
[root@master1 ~]#kubectl edit sts web
.......
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.3  #ä¿®æ”¹ç‰ˆæœ¬
      ....
 updateStrategy:
    type: OnDelete       # ä¿®æ”¹æ›´æ–°ç­–ç•¥
.......

# è§‚å¯Ÿåˆ°æ²¡æœ‰å˜åŒ–

# åˆ é™¤æŒ‡å®šPod
[root@master1 ~]#kubectl delete pod web-0
pod "web-0" deleted
[root@master1 ~]#kubectl get pod
NAME                        READY   STATUS               RESTARTS        AGE
web-0                       0/1     ContainerCreating    0               43s
web-1                       1/1     Running              0               79s
web-2                       1/1     Running              0               115s

#å‘ç°åªæœ‰åˆ é™¤çš„Podæ‰æ›´æ–°é•œåƒ

# å…¨éƒ¨åˆ é™¤ï¼Œåˆ é™¤åï¼Œåˆ™ä¼šæŒ‰é¡ºåºä»å°åˆ°å¤§åˆ›å»ºPod
```



#### æ¡ˆä¾‹ï¼šStatefulSet ç®€å•æ¡ˆä¾‹

##### å‡†å¤‡NFSæœåŠ¡å’ŒåŠ¨æ€ç½®å¤‡

```bash
# è¯¦æƒ…å‚è€ƒKubernetesæ•°æ®å­˜å‚¨ -> StorageClass -> NFS StorageClass
# æŸ¥çœ‹å®šä¹‰å¥½çš„StorageClass
[root@master1 ~]#kubectl get storageclasses.storage.k8s.io
NAME               PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
sc-nfs (default)   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  40d
```

##### å‡†å¤‡ Serviceèµ„æº

```bash
# å‡†å¤‡æ— å¤´æœåŠ¡
[root@master1 statefulset]#cat sts-headless.yaml 
apiVersion: v1
kind: Service
metadata:
  name: statefulset-headless
spec:
  ports:
  - port: 80
  clusterIP: None
  selector:
    app: myapp-pod

[root@master1 statefulset]#kubectl apply -f sts-headless.yaml 
service/statefulset-headless created

[root@master1 statefulset]#kubectl get svc statefulset-headless 
NAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
statefulset-headless   ClusterIP   None         <none>        80/TCP    58s
```

##### åˆ›å»º statefulset èµ„æº

```bash
#æ¸…å•æ–‡ä»¶
[root@master1 statefulset]#cat sts-test.yaml 
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: myapp
spec:
  serviceName: statefulset-headless
  replicas: 3
  selector:
    matchLabels:
      app: myapp-pod
  template:
    metadata:
      labels:
        app: myapp-pod
    spec:
      containers:
      - name: myapp
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/nginx:1.20.0
        volumeMounts:
        - name: myappdata
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
  - metadata:
      name: myappdata
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: "sc-nfs"
      resources:
        requests:
          storage: 1Gi

[root@master1 statefulset]#kubectl apply -f sts-test.yaml 
statefulset.apps/myapp created
```

**éªŒè¯ç»“æœ**

```bash
# ç»“æœæ˜¾ç¤ºï¼šæ‰€æœ‰çš„èµ„æºå¯¹è±¡(pod+pv)éƒ½æ˜¯æŒ‰ç…§é¡ºåºåˆ›å»ºçš„ï¼Œè€Œä¸”æ¯ä¸ªpvéƒ½æœ‰è‡ªå·±ç‹¬æœ‰çš„æ ‡è¯†ç¬¦
[root@master1 statefulset]#kubectl get pod
NAME                        READY   STATUS    RESTARTS      AGE
myapp-0                     1/1     Running   0             3m23s
myapp-1                     1/1     Running   0             2m45s
myapp-2                     1/1     Running   0             2m7s

[root@master1 statefulset]#kubectl get pvc
NAME                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
myappdata-myapp-0   Bound    pvc-4affd28a-5835-4018-bb49-ad07f19b89c4   1Gi        RWO            sc-nfs         <unset>                 4m16s
myappdata-myapp-1   Bound    pvc-d617b16a-112c-4355-b88f-d81bb699c2a7   1Gi        RWO            sc-nfs         <unset>                 3m38s
myappdata-myapp-2   Bound    pvc-357b644a-5de5-4889-a9cb-40250d89d6f3   1Gi        RWO            sc-nfs         <unset>                 3m

[root@ubuntu2204 default-myappdata-myapp-0-pvc-4affd28a-5835-4018-bb49-ad07f19b89c4]#echo myapp-0 > /data/sc-nfs/default-myappdata-myapp-0-pvc-4affd28a-5835-4018-bb49-ad07f19b89c4/index.html
[root@ubuntu2204 default-myappdata-myapp-1-pvc-d617b16a-112c-4355-b88f-d81bb699c2a7]#echo myapp-1 > /data/sc-nfs/default-myappdata-myapp-1-pvc-d617b16a-112c-4355-b88f-d81bb699c2a7/index.html
[root@ubuntu2204 default-myappdata-myapp-2-pvc-357b644a-5de5-4889-a9cb-40250d89d6f3]#echo myapp-2 > /data/sc-nfs/default-myappdata-myapp-2-pvc-357b644a-5de5-4889-a9cb-40250d89d6f3/index.html

[root@master1 /]#kubectl get pod -o wide
myapp-0                     1/1     Running   0             22m     192.168.123.49   node3.mystical.org   <none>           <none>
myapp-1                     1/1     Running   0             21m     192.168.22.223   node1.mystical.org   <none>           <none>
myapp-2                     1/1     Running   0             20m     192.168.253.40   node2.mystical.org   <none> 

[root@master1 /]#curl 192.168.123.49
myapp-0
[root@master1 /]#curl 192.168.22.223
myapp-1
[root@master1 /]#curl 192.168.253.40
myapp-2
```



##### ç¼©å®¹å’Œæ‰©å®¹

ç¼©å®¹å’Œæ‰©å®¹éƒ½æ˜¯æŒ‰ä¸€å®šçš„é¡ºåºè¿›è¡Œçš„

æ‰©å®¹æ˜¯ä»ç¼–å·ä¸º0åˆ°Nçš„é¡ºåºåˆ›å»ºPod

ç¼©å®¹æ­£å¥½ç›¸å, æ˜¯ä»ç¼–å·Nåˆ°0çš„é¡ºåºé”€æ¯Pod

```bash
# ç¼©å®¹ï¼Œä»å¤§åˆ°å°åˆ é™¤
[root@master1 /]#kubectl scale sts myapp --replicas=1; kubectl get pod -w
statefulset.apps/myapp scaled
NAME                        READY   STATUS        RESTARTS      AGE
myapp-0                     1/1     Running       0             30m
myapp-1                     1/1     Running       0             29m
myapp-2                     1/1     Terminating   0             29m
myapp-2                     0/1     Terminating   0             29m
myapp-1                     1/1     Terminating   0             30m
myapp-1                     0/1     Terminating   0             30m

[root@master1 /]#kubectl get pvc
NAME                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
myappdata-myapp-0   Bound    pvc-4affd28a-5835-4018-bb49-ad07f19b89c4   1Gi        RWO            sc-nfs         <unset>                 32m
myappdata-myapp-1   Bound    pvc-d617b16a-112c-4355-b88f-d81bb699c2a7   1Gi        RWO            sc-nfs         <unset>                 31m
myappdata-myapp-2   Bound    pvc-357b644a-5de5-4889-a9cb-40250d89d6f3   1Gi        RWO            sc-nfs         <unset>                 31m

# å¯ä»¥çœ‹åˆ°ï¼špodçš„åˆ é™¤ä¸å½±å“pvå’Œpvcï¼Œè¯´æ˜podçš„çŠ¶æ€æ•°æ®æ²¡æœ‰ä¸¢å¤±ï¼Œè€Œä¸”pvcæŒ‡å®šçš„åç§°ä¸å˜ï¼Œåªè¦æ˜¯åŒä¸€ä¸ªstatufulsetåˆ›å»ºçš„podï¼Œä¼šè‡ªåŠ¨æ‰¾åˆ°æ ¹æ®æŒ‡å®šçš„pvcæ‰¾åˆ°å…·ä½“çš„pv
# pvc çš„åç§°æ˜¯ <PVC_name>-<POD_name>çš„ç»„åˆï¼Œæ‰€ä»¥podå¯ä»¥ç›´æ¥æ‰¾åˆ°ç»‘å®šçš„pvc

# æ‰©å®¹ï¼Œä»å°åˆ°å¤§åˆ›å»ºpod
[root@master1 /]#kubectl scale sts myapp --replicas=4; kubectl get pod -w
statefulset.apps/myapp scaled
NAME                        READY   STATUS              RESTARTS      AGE 
myapp-0                     1/1     Running             0             33m
myapp-1                     0/1     ContainerCreating   0             1s
myapp-1                     0/1     ContainerCreating   0             3s
myapp-1                     1/1     Running             0             5s
myapp-2                     0/1     Pending             0             0s
myapp-2                     0/1     Pending             0             0s
myapp-2                     0/1     ContainerCreating   0             0s
myapp-2                     0/1     ContainerCreating   0             2s
myapp-2                     1/1     Running             0             4s
myapp-3                     0/1     Pending             0             0s
myapp-3                     0/1     Pending             0             0s
myapp-3                     0/1     Pending             0             2s
myapp-3                     0/1     ContainerCreating   0             2s
myapp-3                     0/1     ContainerCreating   0             4s
myapp-3                     1/1     Running             0             6s

# åªè¦æ˜¯åŒä¸€ä¸ªstatufulsetåˆ›å»ºçš„podï¼Œä¼šè‡ªåŠ¨æ‰¾åˆ°æ ¹æ®æŒ‡å®šçš„pvcæ‰¾åˆ°å…·ä½“çš„pv
[root@master1 /]#curl 192.168.253.72
myapp-2
```

##### åç§°è®¿é—®

è‡ªåŠ¨åˆ›å»ºpodçš„åç§°é»˜è®¤æ˜¯å¯ä»¥è§£æçš„

```bash
[root@master1 /]#kubectl exec -it pod-test1-cd487559d-cjmxk -- sh
[root@pod-test1-cd487559d-cjmxk /]# nslookup statefulset-headless
Server:		10.96.0.10
Address:	10.96.0.10#53

Name:	statefulset-headless.default.svc.cluster.local
Address: 192.168.123.47
Name:	statefulset-headless.default.svc.cluster.local
Address: 192.168.253.72
Name:	statefulset-headless.default.svc.cluster.local
Address: 192.168.123.49
Name:	statefulset-headless.default.svc.cluster.local
Address: 192.168.22.215

# æ³¨æ„ï¼šPodå¯ä»¥ç›´æ¥è§£æè‡ªå·±çš„podåç§°ï¼Œè§£æå…¶ä»–podçš„åç§°å¿…é¡»æºå¸¦å…¶æ— å¤´æœåŠ¡çš„å®Œæ•´åç§°
# å®Œæ•´åç§°æ ¼å¼ï¼š
# <statefulsetNmae>-<n>.<headless_name>.<ns_name>.svc.<k8s-clusterDoamin>
[root@pod-test1-cd487559d-cjmxk /]# nslookup myapp-0.statefulset-headless.default.svc.clust
er.local
Server:		10.96.0.10
Address:	10.96.0.10#53

Name:	myapp-0.statefulset-headless.default.svc.cluster.local
Address: 192.168.123.49

[root@pod-test1-cd487559d-cjmxk /]# nslookup myapp-1.statefulset-headless.default.svc.clust
er.local
Server:		10.96.0.10
Address:	10.96.0.10#53

Name:	myapp-1.statefulset-headless.default.svc.cluster.local
Address: 192.168.22.215

[root@pod-test1-cd487559d-cjmxk /]# nslookup myapp-2.statefulset-headless.default.svc.clust
er.local
Server:		10.96.0.10
Address:	10.96.0.10#53

Name:	myapp-2.statefulset-headless.default.svc.cluster.local
Address: 192.168.253.72

# ç›´æ¥è®¿é—®svc-headlessï¼Œåˆ™ä¼šè‡ªåŠ¨è½®è¯¢è®¿é—®
[root@pod-test1-cd487559d-cjmxk /]# curl statefulset-headless
myapp-1
[root@pod-test1-cd487559d-cjmxk /]# curl statefulset-headless
myapp-2
[root@pod-test1-cd487559d-cjmxk /]# curl statefulset-headless
myapp-0

# statefulsetä¸­ï¼Œpodçš„ä¸»æœºåå’Œpodåä¸€è‡´
[root@master1 /]#kubectl exec myapp-0 -- hostname
myapp-0
```



#### æ¡ˆä¾‹ï¼šMySQL ä¸»ä»å¤åˆ¶é›†ç¾¤

æ³¨æ„: MySQL5.7.39å¤±è´¥,å…¶å®ƒç‰ˆæœ¬MySQL5.7.36ï¼Œ44 éƒ½æˆåŠŸ

```http
https://kubernetes.io/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/
```

æ¶æ„è®¾è®¡

```bash
# åˆ›å»ºä¸¤ä¸ªSVCå®ç°è¯»å†™åˆ†ç¦»
# SVCï¼šæ‰€æœ‰èŠ‚ç‚¹ï¼Œè¯»æ“ä½œ
# SVC-headlessï¼šmysql-0 å†™æ“ä½œ
```



##### å‡†å¤‡ NFS æœåŠ¡å’Œ StorageClass åŠ¨æ€ç½®å¤‡

```bash
# è¯¦æƒ…å‚è€ƒKubernetesæ•°æ®å­˜å‚¨ -> StorageClass -> NFS StorageClass
# æŸ¥çœ‹å®šä¹‰å¥½çš„StorageClass
[root@master1 ~]#kubectl get storageclasses.storage.k8s.io
NAME               PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
sc-nfs (default)   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  40d
```



##### åˆ›å»º ConfigMap

```bash
# MySQLçš„é…ç½®
[root@master1 statefulset]#cat sts-mysql-configmap.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql
  labels:
    app: mysql
    app.kubernetes.io/name: mysql
data:
  primary.cnf: |
    [mysqld]
    log-bin
  replica.cnf: |
    [mysqld]
    super-read-only
```



##### åˆ›å»º Service

```bash
# ä¸º StatefulSet æˆå‘˜æä¾›ç¨³å®šçš„ DNS è¡¨é¡¹çš„æ— å¤´æœåŠ¡ï¼ˆHeadless Serviceï¼‰
#  ä¸»èŠ‚ç‚¹çš„å¯¹åº”çš„Service

[root@master1 statefulset]#cat sts-mysql-svc.yaml 
apiVersion: v1
kind: Service
metadata:
  name: mysql
  labels:
    app: mysql
    app.kubernetes.io/name: mysql
spec:
  ports:
  - name: mysql
    port: 3306
  clusterIP: None
  selector:
    app: mysql
---
# ç”¨äºè¿æ¥åˆ°ä»»ä¸€ MySQL å®ä¾‹æ‰§è¡Œè¯»æ“ä½œçš„å®¢æˆ·ç«¯æœåŠ¡
# å¯¹äºå†™æ“ä½œï¼Œå¿…é¡»è¿æ¥åˆ°ä¸»æœåŠ¡å™¨ï¼šmysql-0.mysql
# ä»èŠ‚ç‚¹çš„å¯¹åº”çš„Serviceï¼Œæ³¨æ„ï¼šæ­¤å¤„æ— éœ€æ— å¤´æœåŠ¡ï¼ˆHeadless Serviceï¼‰
# ä¸‹é¢çš„serviceå¯ä»¥ä¸åˆ›å»ºï¼Œç›´æ¥ä½¿ç”¨æ— å¤´æœåŠ¡mysqlä¹Ÿå¯ä»¥
apiVersion: v1
kind: Service
metadata:
  name: mysql-read
  labels:
    app: mysql
    app.kubernetes.io/name: mysql
    readonly: "true"
spec:
  ports:
  - name: mysql
    port: 3306
  selector:
    app: mysql
```



##### åˆ›å»º statefulset

```bash
[root@master1 statefulset]#cat sts-mysql-sts.yaml 
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  selector:
    matchLabels:
      app: mysql
      app.kubernetes.io/name: mysql
  serviceName: mysql
  replicas: 3
  template:
    metadata:
      labels:
        app: mysql
        app.kubernetes.io/name: mysql
    spec:
      initContainers:
      - name: init-mysql
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/mysql:5.7
        command:
        - bash
        - "-c"
        - |
          # -e: å¦‚æœä»»ä½•å‘½ä»¤å¤±è´¥ï¼ˆè¿”å›é0ï¼‰ï¼Œç«‹å³é€€å‡ºè„šæœ¬
          # -x: è¾“å‡ºæ‰§è¡Œçš„æ¯ä¸€æ¡å‘½ä»¤ï¼ˆè°ƒè¯•ç”¨ï¼‰ï¼Œå¯ä»¥å¸®åŠ©è¿½è¸ªé—®é¢˜
          # ç›®çš„æ˜¯ä¸ºäº†ç¡®ä¿è„šæœ¬æ‰§è¡Œæ—¶é€æ˜ã€å¯è°ƒè¯•ï¼Œå¹¶ä¸”å¤±è´¥å³åœã€‚
          set -ex
          # åŸºäº Pod åºå·ç”Ÿæˆ MySQL æœåŠ¡å™¨çš„ IDã€‚
          [[ $HOSTNAME =~ -([0-9]+)$ ]] || exit 1
          # BASH_REMATCH æ˜¯ Bash Shell çš„ä¸€ä¸ªå†…ç½®æ•°ç»„å˜é‡ï¼Œä¸“é—¨ç”¨äº æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç»“æœçš„
          # å½“ä½ ä½¿ç”¨ [[ string =~ regex ]] è¿™ç§è¯­æ³•åš æ­£åˆ™åŒ¹é… æ—¶
          # BASH_REMATCH[0] ä¼šåŒ…å«å®Œæ•´åŒ¹é…çš„å­—ç¬¦ä¸²
          # BASH_REMATCH[1] å¼€å§‹ä¾æ¬¡æ˜¯ æ¯ä¸ªæ‹¬å·æ•è·ç»„ï¼ˆcapture groupï¼‰åŒ¹é…åˆ°çš„å†…å®¹
          ordinal=${BASH_REMATCH[1]}
          echo [mysqld] > /mnt/conf.d/server-id.cnf
          # æ·»åŠ åç§»é‡ä»¥é¿å…ä½¿ç”¨ server-id=0 è¿™ä¸€ä¿ç•™å€¼ã€‚
          echo server-id=$((100 + $ordinal)) >> /mnt/conf.d/server-id.cnf
          # å°†åˆé€‚çš„ conf.d æ–‡ä»¶ä» config-map å¤åˆ¶åˆ° emptyDir
          if [[ $ordinal -eq 0 ]]; then
            cp /mnt/config-map/primary.cnf /mnt/conf.d/
          else
            cp /mnt/config-map/replica.cnf /mnt/conf.d/
          fi
        volumeMounts:
        - name: conf
          mountPath: /mnt/conf.d
        - name: config-map
          mountPath: /mnt/config-map
      - name: clone-mysql
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/xtrabackup:1.0
        command:
        # å‰¯æœ¬ Pod å¯åŠ¨æ—¶ï¼Œä»å‰ä¸€ä¸ªå‰¯æœ¬ï¼ˆordinal-1ï¼‰å…‹éš†æ•°æ®åº“æ•°æ®ï¼Œç”¨äºåˆå§‹åŒ–æ•°æ®ç›®å½•ã€‚
        # Pod æ˜¯æœ‰åºå¯åŠ¨çš„ï¼ˆå¦‚ï¼šmysql-0, mysql-1, mysql-2ï¼‰ï¼Œä¸” mysql-1 ä» mysql-0 å–æ•°æ®ï¼Œmysql-2 ä» mysql-1 å–æ•°æ®
        - bash
        - "-c"
        - |
          set -ex
          # å¦‚æœå·²æœ‰æ•°æ®ï¼Œåˆ™è·³è¿‡å…‹éš†
          [[ -d /var/lib/mysql/mysql ]] && exit 0
          # è·³è¿‡ä¸»å®ä¾‹ï¼ˆåºå·ç´¢å¼•0ï¼‰çš„å…‹éš†
          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
          ordinal=${BASH_REMATCH[1]}
          [[ $ordinal -eq 0 ]] && exit 0
          # ä»åŸæ¥çš„å¯¹ç­‰èŠ‚ç‚¹å…‹éš†æ•°æ®
          ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql
          # å‡†å¤‡å¤‡ä»½
          xtrabackup --prepare --target-dir=/var/lib/mysql
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
      containers:
      - name: mysql
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/mysql:5.7 
        env:
        - name: MYSQL_ALLOW_EMPTY_PASSWORD
          value: "1"
        ports:
        - name: mysql
          containerPort: 3306
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
        livenessProbe:
          exec:
            command: ["mysqladmin", "ping"]
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          exec:
            # æ£€æŸ¥æˆ‘ä»¬æ˜¯å¦å¯ä»¥é€šè¿‡ TCP æ‰§è¡ŒæŸ¥è¯¢ï¼ˆskip-networking æ˜¯å…³é—­çš„ï¼‰
            command: ["mysql", "-h", "127.0.0.1", "-e", "SELECT 1"]
          initialDelaySeconds: 5
          periodSeconds: 2
          timeoutSeconds: 1
      - name: xtrabackup
        image: registry.cn-beijing.aliyuncs.com/wangxiaochun/xtrabackup:1.0
        ports:
        - name: xtrabackup
          containerPort: 3307
        command:
        - bash
        - "-c"
        - |
          set -ex
          cd /var/lib/mysql

          # ç¡®å®šå…‹éš†æ•°æ®çš„ binlog ä½ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ã€‚
          if [[ -f xtrabackup_slave_info && "x$(<xtrabackup_slave_info)" != "x" ]]; then
            # XtraBackup å·²ç»ç”Ÿæˆäº†éƒ¨åˆ†çš„ â€œCHANGE MASTER TOâ€ æŸ¥è¯¢
            # å› ä¸ºä»ä¸€ä¸ªç°æœ‰å‰¯æœ¬è¿›è¡Œå…‹éš†ã€‚(éœ€è¦åˆ é™¤æœ«å°¾çš„åˆ†å·!)
            cat xtrabackup_slave_info | sed -E 's/;$//g' > change_master_to.sql.in
            #  åœ¨è¿™é‡Œè¦å¿½ç•¥ xtrabackup_binlog_info ï¼ˆå®ƒæ˜¯æ²¡ç”¨çš„ï¼‰
            rm -f xtrabackup_slave_info xtrabackup_binlog_info
          elif [[ -f xtrabackup_binlog_info ]]; then
            # ç›´æ¥ä»ä¸»å®ä¾‹è¿›è¡Œå…‹éš†ã€‚è§£æ binlog ä½ç½®
            [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1
            rm -f xtrabackup_binlog_info xtrabackup_slave_info
            echo "CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\
                  MASTER_LOG_POS=${BASH_REMATCH[2]}" > change_master_to.sql.in
          fi

          # æ£€æŸ¥æ˜¯å¦éœ€è¦é€šè¿‡å¯åŠ¨å¤åˆ¶æ¥å®Œæˆå…‹éš†
          if [[ -f change_master_to.sql.in ]]; then
            echo "Waiting for mysqld to be ready (accepting connections)"
            until mysql -h 127.0.0.1 -e "SELECT 1"; do sleep 1; done

            echo "Initializing replication from clone position"
            mysql -h 127.0.0.1 \
                  -e "$(<change_master_to.sql.in), \
                          MASTER_HOST='mysql-0.mysql', \
                          MASTER_USER='root', \
                          MASTER_PASSWORD='', \
                          MASTER_CONNECT_RETRY=10; \
                        START SLAVE;" || exit 1
            # å¦‚æœå®¹å™¨é‡æ–°å¯åŠ¨ï¼Œæœ€å¤šå°è¯•ä¸€æ¬¡
            mv change_master_to.sql.in change_master_to.sql.orig
          fi

          # å½“å¯¹ç­‰ç‚¹è¯·æ±‚æ—¶ï¼Œå¯åŠ¨æœåŠ¡å™¨å‘é€å¤‡ä»½ã€‚
          exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \
            "xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root"
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
      volumes:
      - name: conf
        emptyDir: {} 
      - name: config-map
        configMap:
          name: mysql
  volumeClaimTemplates:
  - metadata: 
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: "sc-nfs"
      resources:
        requests:
          storage: 10Gi
```

**éªŒè¯**

```bash
[root@master1 statefulset]# kubectl apply -f sts-mysql-configmap.yaml
[root@master1 statefulset]#kubectl apply -f sts-mysql-svc.yaml
[root@master1 statefulset]#kubectl apply -f sts-mysql-sts.yaml

# è·Ÿè¸ªæŸ¥çœ‹
[root@master1 statefulset]#kubectl get pod
NAME                        READY   STATUS    RESTARTS        AGE
mysql-0                     2/2     Running   0               15m
mysql-1                     2/2     Running   1 (10m ago)     13m
mysql-2                     2/2     Running   1 (7m23s ago)   10m


[root@master1 statefulset]#kubectl get pvc
NAME                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
data-mysql-0        Bound    pvc-d5652db9-83f6-4cba-9948-41701ad1bf28   10Gi       RWO            sc-nfs         <unset>                 34m
data-mysql-1        Bound    pvc-a01ad5de-f70b-44af-a076-676285143eb1   10Gi       RWO            sc-nfs         <unset>                 13m
data-mysql-2        Bound    pvc-33d51af1-3ea0-4b90-afe9-e2ae0733517c   10Gi       RWO            sc-nfs         <unset>                 10m

# æµ‹è¯•ä¸»ä»
[root@master1 statefulset]#kubectl exec -it mysql-0 -- mysql
Defaulted container "mysql" out of: mysql, xtrabackup, init-mysql (init), clone-mysql (init)
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 258
Server version: 5.7.13-log MySQL Community Server (GPL)

Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show processlist;
+-----+------+----------------------+------+-------------+------+---------------------------------------------------------------+------------------+
| Id  | User | Host                 | db   | Command     | Time | State                                                         | Info             |
+-----+------+----------------------+------+-------------+------+---------------------------------------------------------------+------------------+
| 112 | root | 192.168.22.226:44306 | NULL | Binlog Dump |  250 | Master has sent all binlog to slave; waiting for more updates | NULL             |
| 222 | root | 192.168.253.22:58180 | NULL | Binlog Dump |   67 | Master has sent all binlog to slave; waiting for more updates | NULL             |
| 258 | root | localhost            | NULL | Query       |    0 | starting                                                      | show processlist |
+-----+------+----------------------+------+-------------+------+---------------------------------------------------------------+------------------+
3 rows in set (0.00 sec)
```



### CRD å®šåˆ¶èµ„æº

#### CRD è¯´æ˜

ä¸ºäº†åœ¨k8sä¸Šèƒ½å¤Ÿæ­£å¸¸çš„è¿è¡Œæ‰€éœ€çš„æœåŠ¡ï¼Œéœ€è¦éµå¾ªä»¥ä¸‹æ–¹å¼æ¥åˆ›å»ºç›¸å…³èµ„æºï¼š

- åˆç†çš„åˆ†æä¸šåŠ¡éœ€æ±‚
- æ¢³ç†ä¸šåŠ¡éœ€æ±‚çš„ç›¸å…³åŠŸèƒ½
- å®šåˆ¶ä¸åŒåŠŸèƒ½çš„èµ„æºé…ç½®æ–‡ä»¶
- åº”ç”¨èµ„æºé…ç½®æ–‡ä»¶ï¼Œå®Œå–„ä¸šåŠ¡ç¯å¢ƒã€‚

å½“å‰æ‰€æœ‰çš„æ“ä½œåŸºæœ¬ä¸Šéƒ½æ˜¯åœ¨k8så†…ç½®çš„æœ‰é™çš„èµ„æºå¯¹è±¡ä¸­è¿›è¡Œç›¸å…³çš„æ“ä½œï¼Œè¿™äº›èµ„æºå¯¹è±¡é€‚ç”¨äºé€šç”¨çš„ ä¸šåŠ¡åœºæ™¯ï¼Œè€Œåœ¨æˆ‘ä»¬çš„ä¸šåŠ¡åœºæ™¯ä¸­ï¼Œå¤šå¤šå°‘å°‘çš„ä¼šæ¶‰åŠåˆ°ç‰¹æ®ŠåŠŸèƒ½çš„èµ„æºå¯¹è±¡ã€‚

æ¯”å¦‚ï¼šç›‘æ§åœºæ™¯éœ€è¦ç›‘æ§çš„æ•°æ®ã€æ—¥å¿—åœºæ™¯éœ€è¦æ”¶é›†çš„æ—¥å¿—ã€æµé‡åœºæ™¯éœ€è¦ä¼ é€’çš„æ•°æ®ç­‰ç­‰

ä¸ºäº†é«˜æ•ˆçš„å®šåˆ¶æˆ‘ä»¬éœ€è¦çš„ç¯å¢ƒï¼Œé‚£ä¹ˆéœ€è¦æ‹¥æœ‰ä¸€äº›ä¸“ç”¨çš„èµ„æºæ–¹ä¾¿æˆ‘ä»¬æ¥ä½¿ç”¨ï¼Œè€Œåœ¨k8sä¹‹ä¸Šæä¾›äº†ä¸€ä¸ªä¸“ç”¨çš„æ¥å£ï¼Œå¯ä»¥æ–¹ä¾¿æˆ‘ä»¬è‡ªå·±æ¥å®šåˆ¶éœ€è¦çš„èµ„æºã€‚



**æ‰©å±•Kubernetes APIå¸¸ç”¨æ–¹å¼ï¼š**

- äºŒæ¬¡å¼€å‘ API Server æºç ,é€‚åˆåœ¨æ·»åŠ æ–°çš„**æ ¸å¿ƒç±»å‹**æ—¶é‡‡ç”¨
- å¼€å‘è‡ªå®šä¹‰API Serverå¹¶èšåˆè‡³ä¸»API Server ,å¯Œäºå¼¹æ€§ä½†ä»£ç å·¥ä½œé‡å¤§
- ä½¿ç”¨CRD( Custom Resource Definition )è‡ªå®šä¹‰èµ„æºç±»å‹ , æ˜“ç”¨ä½†é™åˆ¶è¾ƒå¤šï¼Œå¯¹åº”çš„æ§åˆ¶å™¨è¿˜éœ€å†è‡ªè¡Œå¼€å‘

![image-20250324173232195](../markdown_img/image-20250324173232195.png)

ç¤ºä¾‹: æŸ¥çœ‹calico è‡ªå®šä¹‰çš„èµ„æºCRD

```bash
# calicoç¯å¢ƒåˆ›å»ºçš„æ—¶å€™ï¼Œå°±ç”¨åˆ°äº†å¾ˆå¤šCRDå¯¹è±¡ï¼Œè€Œä¸”æˆ‘ä»¬ä¸ºäº†è®©CRDèƒ½å¤Ÿç”Ÿæ•ˆï¼Œè¯¥è½¯ä»¶è¿˜æä¾›äº†ä¸€ä¸ªcontrollerçš„CRDæ§åˆ¶å™¨ã€‚è¿™ä¸ªæ§åˆ¶å™¨å°±æ˜¯å°†CRDå¯¹è±¡è½¬æ¢ä¸ºçœŸæ­£æœ‰æ„ä¹‰çš„ç°å®çš„ä»£ç ã€‚
[root@master1 statefulset]#kubectl get pod -n kube-system |grep -i calico
calico-kube-controllers-77d59654f4-rwl4p       1/1     Running   22 (8h ago)   41d
calico-node-7xpvt                              1/1     Running   25 (8h ago)   41d
calico-node-8tn8p                              1/1     Running   22 (8h ago)   41d
calico-node-qqmsz                              1/1     Running   24 (8h ago)   41d
calico-node-wzdrm                              1/1     Running   24 (8h ago)   41d
```



##### CRDç®€ä»‹

èµ„æºï¼ˆResourceï¼‰ æ˜¯ Kubernetes API ä¸­çš„ä¸€ä¸ªç«¯ç‚¹ï¼Œ å…¶ä¸­å­˜å‚¨çš„æ˜¯æŸä¸ªç±»åˆ«çš„ API å¯¹è±¡ çš„ä¸€ä¸ªé›†åˆã€‚ ä¾‹å¦‚å†…ç½®çš„ pods èµ„æºåŒ…å«ä¸€ç»„ Pod å¯¹è±¡

å®šåˆ¶èµ„æºï¼ˆCustom Resourceï¼‰ æ˜¯å¯¹ Kubernetes API çš„æ‰©å±•ï¼Œä¸ä¸€å®šåœ¨é»˜è®¤çš„ Kubernetes å®‰è£…ä¸­å°±å¯ç”¨ã€‚å®šåˆ¶èµ„æºæ‰€ä»£è¡¨çš„æ˜¯å¯¹ç‰¹å®š Kubernetes å®‰è£…çš„ä¸€ç§å®šåˆ¶ã€‚ ä¸è¿‡ï¼Œå¾ˆå¤š Kubernetes æ ¸å¿ƒåŠŸèƒ½ç°åœ¨éƒ½ç”¨å®šåˆ¶èµ„æºæ¥å®ç°ï¼Œè¿™ä½¿å¾— Kubernetes æ›´åŠ æ¨¡å—åŒ–ã€‚

CRD( Custom Resource Definition ) å®šåˆ¶èµ„æºå¯ä»¥é€šè¿‡åŠ¨æ€æ³¨å†Œçš„æ–¹å¼åœ¨è¿è¡Œä¸­çš„é›†ç¾¤å†…æˆ–å‡ºç°æˆ–æ¶ˆå¤±ï¼Œé›†ç¾¤ç®¡ç†å‘˜å¯ä»¥ç‹¬ç«‹äºé›†ç¾¤æ›´æ–°å®šåˆ¶èµ„æºã€‚ä¸€æ—¦æŸå®šåˆ¶èµ„æºè¢«å®‰è£…ï¼Œç”¨æˆ·å¯ä»¥ä½¿ç”¨ kubectl æ¥åˆ›å»º å’Œè®¿é—®å…¶ä¸­çš„å¯¹è±¡ï¼Œå°±åƒä»–ä»¬ä¸º pods è¿™ç§å†…ç½®èµ„æºæ‰€åšçš„ä¸€æ ·ã€‚

CRD åŠŸèƒ½æ˜¯åœ¨ Kubernetes 1.7 ç‰ˆæœ¬è¢«å¼•å…¥çš„ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚æ·»åŠ è‡ªå®šä¹‰çš„ Kubernetes å¯¹è±¡èµ„æºã€‚

![image-20250324173658794](../markdown_img/image-20250324173658794.png)

##### å®šåˆ¶CRDçš„æ§åˆ¶å™¨

å°±å®šåˆ¶èµ„æºæœ¬èº«è€Œè¨€ï¼Œå®ƒåªèƒ½ç”¨æ¥å­˜å–ç»“æ„åŒ–çš„æ•°æ®ã€‚ å½“ä½ å°†**å®šåˆ¶èµ„æº**ä¸**å®šåˆ¶æ§åˆ¶å™¨**ï¼ˆCustom  Controllerï¼‰ ç›¸ç»“åˆæ—¶ï¼Œå®šåˆ¶èµ„æºå°±èƒ½å¤Ÿ æä¾›çœŸæ­£çš„å£°æ˜å¼ APIï¼ˆDeclarative APIï¼‰ã€‚

ä½¿ç”¨å£°æ˜å¼ APIï¼Œ ä½ å¯ä»¥å£°æ˜æˆ–è€…è®¾å®šä½ çš„èµ„æºçš„æœŸæœ›çŠ¶æ€ï¼Œå¹¶å°è¯•è®© Kubernetes å¯¹è±¡çš„å½“å‰çŠ¶æ€åŒ æ­¥åˆ°å…¶æœŸæœ›çŠ¶æ€ã€‚æ§åˆ¶å™¨è´Ÿè´£å°†ç»“æ„åŒ–çš„æ•°æ®è§£é‡Šä¸ºç”¨æˆ·æ‰€æœŸæœ›çŠ¶æ€çš„è®°å½•ï¼Œå¹¶æŒç»­åœ°ç»´æŠ¤è¯¥çŠ¶æ€ã€‚

**èµ„æºå¯¹è±¡çš„å®šåˆ¶æ–¹å¼:**

- åœ¨ç°æœ‰çš„æ§åˆ¶å™¨åŸºç¡€ä¸Šï¼Œæ‰©å±•èµ„æºå¯¹è±¡
- ä»0å¼€å§‹å®šåˆ¶èµ„æºå¯¹è±¡å’Œèµ„æºå¯¹è±¡æ§åˆ¶å™¨ï¼Œæ­¤æ–¹å¼éœ€è¦å…·æœ‰ç¼–ç¨‹è¯­è¨€çš„å¼€å‘èƒ½åŠ›

é€šå¸¸æƒ…å†µä¸‹ï¼Œä¸€ä¸ªCRDä¼šç»“åˆå¯¹åº”çš„Controllerï¼Œå¹¶æ·»åŠ ä¸€äº›å…¶å®ƒèµ„æºï¼Œç»„æˆä¸€ä¸ªä¸“å±åº”ç”¨çš„ **Operator**ï¼Œæ¥è§£å†³ç‰¹å®šåº”ç”¨çš„åŠŸèƒ½



#### CRD é…ç½®è§£æ

```yaml
apiVersion: apiextensions.k8s.io/v1          # APIç¾¤ç»„å’Œç‰ˆæœ¬
kind: CustomResourceDefinition               # èµ„æºç±»åˆ«
metadata:
  name: <string>                             # èµ„æºåç§°
spec:
  conversion: <Object>                       # å®šä¹‰ä¸åŒç‰ˆæœ¬é—´çš„æ ¼å¼è½¬æ¢æ–¹å¼
    trategy: <string>                        # ä¸åŒç‰ˆæœ¬é—´çš„è‡ªå®šä¹‰èµ„æºè½¬æ¢ç­–ç•¥ï¼Œæœ‰Noneå’ŒWebhookä¸¤ç§å–å€¼
    webhook: <Object>                        # å¦‚ä½•è°ƒç”¨ç”¨äºè¿›è¡Œæ ¼å¼è½¬æ¢çš„webhook
  group: <string>                            # èµ„æºæ‰€å±çš„APIç¾¤ç»„
  names: <Object>                            # è‡ªå®šä¹‰èµ„æºçš„ç±»å‹ï¼Œå³è¯¥CRDåˆ›å»ºèµ„æºè§„èŒƒæ—¶ä½¿ç”¨çš„kind
    categories: <[]string>                   # èµ„æºæ‰€å±çš„ç±»åˆ«ç¼–ç›®ï¼Œä¾‹å¦‚â€kubectl get allâ€ä¸­çš„all
    kind: <string>                           # kindåç§°ï¼Œå¿…é€‰å­—æ®µ
    listkind: <string>                       # èµ„æºåˆ—è¡¨åç§°ï¼Œé»˜è®¤ä¸º"`kind`List"
    plural: <string>                         # ç”¨äºAPIè·¯å¾„ï¼Œ/apis/<group>/<version>/.../<plural>
    shortNames: <[]string>                   # è¯¥èµ„æºçš„kindçš„ç¼©å†™æ ¼å¼
    singular: <string>                       # èµ„æºkindçš„å•æ•°å½¢å¼ï¼Œå¿…é¡»ä½¿ç”¨å…¨å°å†™å­—æ¯
  preserveUnknownFields: <boolean>           # é¢„ç•™çš„éçŸ¥åå­—æ®µï¼Œkindç­‰éƒ½æ˜¯çŸ¥åçš„é¢„ç•™å­—æ®µ
  scope: <string>                            # ä½œç”¨åŸŸï¼Œå¯ç”¨å€¼ä¸ºClusterå’ŒNamespaced
  versions: <[]Object>                       # ç‰ˆæœ¬å·å®šä¹‰
    additionalPrinterColumns: <[]Object>     # éœ€è¦è¿”å›çš„é¢å¤–ä¿¡æ¯
    name: <string>                           # å½¢å¦‚vM[alphaN|betaN]æ ¼å¼çš„ç‰ˆæœ¬åç§°ï¼Œä¾‹å¦‚v1æˆ–v1alpha2
    schema: <Object>                         # è¯¥èµ„æºçš„æ•°æ®æ ¼å¼ï¼ˆschemaï¼‰å®šä¹‰ï¼Œå¿…é€‰å­—æ®µ
    openAPIV3Schame: <Object>                # ç”¨äºæ ¡éªŒå­—æ®µçš„schemaå¯¹è±¡ï¼Œæ ¼å¼è¯·å‚è€ƒç›¸å…³æ‰‹å†Œ
  served: <boolean>                          # æ˜¯å¦å…è®¸é€šè¿‡RESTful APIè°ƒåº¦è¯¥ç‰ˆæœ¬ï¼Œå¿…é€‰å­—æ®µ
  storage: <boolean>                         # å°†è‡ªå®šä¹‰èµ„æºå­˜å‚¨äºetcdä¸­æ—¶æ˜¯ä¸æ˜¯ä½¿ç”¨è¯¥ç‰ˆæœ¬
  subresources: <Object>                     # å­èµ„æºå®šä¹‰
    scale: <Object>                          # å¯ç”¨scaleå­èµ„æºï¼Œé€šè¿‡autoscaling/v1.Scaleå‘é€è´Ÿè·
    status <map[string]>                     # å¯ç”¨statuså­èµ„æºï¼Œä¸ºèµ„æºç”Ÿæˆ/statusç«¯ç‚¹
```



#### CRD æ¡ˆä¾‹

èŒƒä¾‹: å®šä¹‰CRDèµ„æº

```bash
[root@master1 statefulset]#cat crd-user.yaml 
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: users.auth.democrd.io
spec:
  group: auth.democrd.io
  names:
    kind: User
    plural: users          # å¤æ•°
    singular: user         # å•æ•°
    shortNames:
    - u
  scope: Namespaced
  versions:
  - served: true
    storage: true
    name: v1alpha1
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              userID:
                type: integer
                minimum: 1
                maximum: 65535
              groups:
                type: array
                items:
                  type: string
              email:
                type: string
              password:
                type: string
                format: password
            required: ["userID","groups"]
            
# å¯ç”¨
[root@master1 statefulset]#kubectl apply -f crd-user.yaml

# æŸ¥çœ‹æ•ˆæœ
[root@master1 statefulset]#kubectl get crd|grep 'users'
users.auth.democrd.io                                 2025-03-24T10:04:14Z
```





### Operator

#### Operator è¯´æ˜

ç”±äºä¸åŒé›†ç¾¤çš„ç‰¹æ®Šæ€§ï¼Œæ‰€ä»¥StatefulSetåªèƒ½åº”ç”¨äºé€šç”¨çš„çŠ¶æ€ç®¡ç†æœºåˆ¶,ç”¨æˆ·è‡ªå·²å®ç°åº”ç”¨çš„é›†ç¾¤åˆæ¯”è¾ƒéº»çƒ¦

ä¸€äº›çƒ­å¿ƒçš„è½¯ä»¶å¼€å‘è€…åˆ©ç”¨Statefulsetç­‰æŠ€æœ¯å°†åº”ç”¨å°è£…æˆå„ç§åº”ç”¨ç¨‹åºä¸“ç”¨çš„ Operatorï¼Œä»¥ä¾¿äºå¸®åŠ© ç›¸å…³ä¼ä¸šè¿›è¡Œä½¿ç”¨Kubernetesï¼Œå¹¶å°†è¿™äº›åšå¥½çš„çŠ¶æ€ç®¡ç†å·¥å…·æ”¾åˆ°äº† GitHubç½‘ç«™çš„awsomes operatorsé¡¹ç›®ä¸­ï¼Œå½“å‰è¿ç§»åˆ°äº†  https://operatorhub.io/

å› æ­¤å¦‚æœæ¶‰åŠåˆ°ä¸€äº›çŠ¶æ€é›†ç¾¤åœºæ™¯ï¼Œå»ºè®®å¯ä»¥ç›´æ¥ä½¿ç”¨operatorhubæä¾›å¥½çš„å·¥å…·ï¼Œè€Œæ— éœ€è‡ªå·±ç¼–å†™å®ç°



##### Operator å·¥ä½œæœºåˆ¶

Kubernetesä¸­ä¸¤ä¸ªæ ¸å¿ƒçš„ç†å¿µï¼šâ€œå£°æ˜å¼APIâ€å’Œâ€œæ§åˆ¶å™¨æ¨¡å¼â€ã€‚

â€œå£°æ˜å¼APIâ€çš„æ ¸å¿ƒåŸç†ï¼Œå°±æ˜¯å½“ç”¨æˆ·å‘Kubernetesæäº¤äº†ä¸€ä¸ªAPIå¯¹è±¡æè¿°ä¹‹åï¼ŒKubernetesä¼šè´Ÿè´£ä¸º ä½ ä¿è¯æ•´ä¸ªé›†ç¾¤é‡Œå„é¡¹èµ„æºçš„çŠ¶æ€ï¼Œéƒ½ä¸ä½ çš„APIå¯¹è±¡æè¿°çš„éœ€æ±‚ä¿æŒä¸€è‡´

Kubernetesé€šè¿‡å¯åŠ¨ä¸€ç§å«åšâ€œæ§åˆ¶å™¨æ¨¡å¼â€çš„æ— é™å¾ªç¯ï¼Œwatchè¿™äº›APIå¯¹è±¡çš„å˜åŒ–ï¼Œä¸æ–­æ£€æŸ¥ï¼Œç„¶åè°ƒè°ï¼Œæœ€åç¡®ä¿æ•´ä¸ªé›†ç¾¤çš„çŠ¶æ€ä¸è¿™ä¸ªAPIå¯¹è±¡çš„æè¿°ä¸€è‡´ã€‚

Operatorå°±æ˜¯åŸºäºä»¥ä¸ŠåŸç†å·¥ä½œï¼Œä»¥Redis Operatorä¸ºä¾‹ï¼Œä¸ºäº†å®ç°Operatorï¼Œé¦–å…ˆéœ€è¦å°†è‡ªå®šä¹‰å¯¹ è±¡CRD(Custom Resource Definition)çš„è¯´æ˜ï¼Œæ³¨å†Œåˆ°Kubernetesä¸­ï¼Œç”¨äºæè¿°Operatoræ§åˆ¶çš„åº”ç”¨ï¼š Redisé›†ç¾¤å®ä¾‹ï¼Œè¿™æ ·å½“ç”¨æˆ·å‘Šè¯‰Kubernetesæƒ³è¦ä¸€ä¸ªredisé›†ç¾¤å®ä¾‹åï¼ŒRedis Operatorå°±èƒ½é€šè¿‡æ§åˆ¶ å¾ªç¯æ‰§è¡Œè°ƒè°é€»è¾‘è¾¾åˆ°ç”¨æˆ·å®šä¹‰çŠ¶æ€ã€‚

æ‰€ä»¥**Operatoræœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªç‰¹æ®Šåº”ç”¨çš„æ§åˆ¶å™¨**ï¼Œå…¶æä¾›äº†ä¸€ç§åœ¨Kubernetes APIä¹‹ä¸Šæ„å»ºåº”ç”¨ç¨‹åºï¼Œ å¹¶åœ¨Kubernetesä¸Šéƒ¨ç½²ç¨‹åºçš„æ–¹æ³•ï¼Œå®ƒå…è®¸å¼€å‘è€…æ‰©å±•Kubernetes APIï¼Œå¢åŠ æ–°åŠŸèƒ½ï¼Œåƒç®¡ç† KubernetesåŸç”Ÿç»„ä»¶ä¸€æ ·ç®¡ç†è‡ªå®šä¹‰çš„èµ„æºã€‚

å¦‚æœä½ æƒ³è¿è¡Œä¸€ä¸ªRediså“¨å…µæ¨¡å¼çš„ä¸»ä»é›†ç¾¤ï¼Œæˆ–è€…TiDBé›†ç¾¤ï¼Œé‚£ä¹ˆä½ åªéœ€è¦æäº¤ä¸€ä¸ªå£°æ˜å°±å¯ä»¥äº†ï¼Œ è€Œä¸éœ€è¦å…³å¿ƒéƒ¨ç½²è¿™äº›åˆ†å¸ƒå¼çš„åº”ç”¨éœ€è¦çš„ç›¸å…³é¢†åŸŸçš„çŸ¥è¯†

Operatoræœ¬èº«å°±å¯ä»¥åšåˆ°åˆ›å»ºåº”ç”¨ã€ç›‘æ§åº”ç”¨çŠ¶æ€ã€æ‰©ç¼©å®¹ã€å‡çº§ã€æ•…éšœæ¢å¤ã€åŠèµ„æºæ¸…ç†ç­‰ï¼Œä»è€Œå°† åˆ†å¸ƒå¼åº”ç”¨çš„é—¨æ§›é™åˆ°æœ€ä½ã€‚

**åŸºäºä¸“ç”¨çš„Operatorç¼–æ’è¿è¡ŒæŸæœ‰çŠ¶æ€åº”ç”¨çš„æµç¨‹ï¼š**

- éƒ¨ç½²OperatoråŠå…¶ä¸“ç”¨çš„èµ„æºç±»å‹
- ä½¿ç”¨ä¸Šé¢åˆ›å»ºçš„ä¸“ç”¨çš„èµ„æºç±»å‹ï¼Œæ¥å£°æ˜ä¸€ä¸ªæœ‰çŠ¶æ€åº”ç”¨çš„ç¼–æ’éœ€æ±‚



**Operator é“¾æ¥ï¼š**

```http
https://operatorhub.io/
https://github.com/operator-framework/awesome-operators
```

![image-20250324181448621](../markdown_img/image-20250324181448621.png)





## KubernetesåŒ…ç®¡ç†Helm



**å†…å®¹**

- **Helm ä»‹ç»**
- **Helm éƒ¨ç½²**
- **Helm å‘½ä»¤ç”¨æ³•**
- **åŸºäº Helm éƒ¨ç½²**
- **è‡ªå®šä¹‰ Chart ç»“æ„**
- **è‡ªå®šä¹‰ Chart è¯­æ³•è¯´æ˜**
- **è‡ªå®šä¹‰ Chart æ¡ˆä¾‹**



### Helm è¯´æ˜å’Œéƒ¨ç½²

#### Helm è¯´æ˜

**Helm ä»‹ç»**

![image-20250324193356822](../markdown_img/image-20250324193356822.png)

**ä¼ ç»Ÿçš„è½¯ä»¶ç®¡ç†æœºåˆ¶**

ä¼ ç»Ÿçš„è½¯ä»¶å®‰è£…åŸºäºç¼–è¯‘å®‰è£…æ–¹å¼éå¸¸ç¹çï¼Œæ‰€ä»¥ä¼šä½¿ç”¨åŒ…ç®¡ç†æ–¹å¼ç®€åŒ–è½¯ä»¶å®‰è£…çš„è¿‡ç¨‹

åŒ…ç®¡ç†å™¨ï¼š

- deb
- rpm

ç¨‹åºåŒ…ä»“åº“ï¼šç»´æŠ¤æœ‰ä»“åº“å†…éƒ¨å„ç¨‹åºæ–‡ä»¶å…ƒæ•°æ®ï¼Œå…¶ä¸­åŒ…å«äº†åŒ…ä¾èµ–å…³ç³» 



**å°†åº”ç”¨æœåŠ¡éƒ¨ç½²åˆ° Kubernetes é›†ç¾¤çš„ä¼ ç»Ÿæµç¨‹**

- æ‹‰å–ä»£ç 
- æ‰“åŒ…ç¼–è¯‘
- æ„å»ºé•œåƒ
- å‡†å¤‡ä¸€å †ç›¸å…³éƒ¨ç½²èµ„æºæ¸…å•çš„ yaml æ–‡ä»¶(å¦‚:deploymentã€statefulsetã€serviceã€ingressç­‰)
- kubectl apply éƒ¨ç½²



**ä¼ ç»Ÿæ–¹å¼éƒ¨ç½²å¼•å‘çš„é—®é¢˜**

- éšç€èµ„æºå¼•ç”¨çš„å¢å¤šï¼Œéœ€è¦**ç»´æŠ¤å¤§é‡çš„yamlæ–‡ä»¶**
- å¾®æœåŠ¡åœºæ™¯ä¸‹ï¼Œæ¯ä¸ªå¾®æœåŠ¡æ‰€éœ€é…ç½®å·®åˆ«ä¸å¤§ï¼Œä½†æ˜¯ä¼—å¤šçš„å¾®æœåŠ¡çš„yamlæ–‡ä»¶**æ— æ³•é«˜æ•ˆå¤ç”¨**
- **æ— æ³•**å°†ç›¸å…³yamlæ–‡ä»¶åšä¸ºä¸€ä¸ª**æ•´ä½“ç®¡ç†**ï¼Œå¹¶å®ç°åº”ç”¨çº§åˆ«çš„å‡çº§å’Œå›æ»šç­‰åŠŸèƒ½
- æ— æ³•æ ¹æ®ä¸€å¥—yamlæ–‡ä»¶æ¥åˆ›å»ºå¤šä¸ªç¯å¢ƒï¼Œéœ€è¦æ‰‹åŠ¨è¿›è¡Œä¿®æ”¹ï¼Œå°¤å…¶æ˜¯å¾®æœåŠ¡ä¼—å¤šçš„æƒ…å†µï¼Œæ•ˆç‡ä½ä¸‹ 
  ä¾‹å¦‚: éƒ¨ç½²çš„ç¯å¢ƒéƒ½åˆ†ä¸ºå¼€å‘ã€é¢„ç”Ÿäº§ã€ç”Ÿäº§ç¯å¢ƒï¼Œåœ¨å¼€å‘è¿™å¥—ç¯å¢ƒéƒ¨ç½²å®Œäº†ï¼Œåé¢å†éƒ¨ç½²åˆ°é¢„ç”Ÿäº§å’Œç”Ÿäº§ç¯å¢ƒï¼Œè¿˜éœ€è¦é‡æ–°å¤åˆ¶å‡ºä¸¤å¥—é…ç½®æ–‡ä»¶ï¼Œå¹¶æ‰‹åŠ¨ä¿®æ”¹æ‰èƒ½å®Œæˆ



**Kubernetes çš„è½¯ä»¶ç®¡ç†å™¨ Helm ä»‹ç»**

```ABAP
Helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.
```

Kubernetesä¹Ÿæä¾›äº†ç±»ä¼¼äºåŒ…ç®¡ç†æœºåˆ¶Helm 

Helm æ˜¯ä¸€ä¸ªç”¨äºç®€åŒ–å’Œç®¡ç† Kubernetes åº”ç”¨éƒ¨ç½²çš„åŒ…ç®¡ç†å™¨ã€‚

Helm å¯ä»¥å°†éƒ¨ç½²åº”ç”¨æ‰€éœ€è¦çš„æ‰€æœ‰é…ç½®æ¸…å•æ–‡ä»¶YAMLæ‰“åŒ…è‡³ä¸€ä¸ª**Chart**çš„åŒ…æ–‡ä»¶ä¸­ï¼Œå¹¶æ”¯æŒé’ˆå¯¹å¤šå¥—ç¯å¢ƒçš„å®šåˆ¶éƒ¨ç½²

Helm å…è®¸ç”¨æˆ·è¿›è¡Œå®šä¹‰ã€å®‰è£…å’Œå‡çº§ Kubernetes åº”ç”¨ç¨‹åºçš„èµ„æºï¼Œç§°ä¸º Helm Chartsã€‚

Helm ä¸æ˜¯ Kubernetes å®˜æ–¹æä¾›çš„å·¥å…·ï¼Œä½†å®ƒæ˜¯ç”± Kubernetes ç¤¾åŒºç»´æŠ¤å’Œæ”¯æŒçš„ã€‚

Helm åœ¨ç¤¾åŒºä¸­å¾—åˆ°äº†å¹¿æ³›çš„æ”¯æŒå’Œé‡‡ç”¨ï¼Œå¹¶æˆä¸º Kubernetes ç”Ÿæ€ç³»ç»Ÿä¸­æµè¡Œçš„éƒ¨ç½²å·¥å…·ä¹‹ä¸€

**Helm å®˜ç½‘**

```http
https://helm.sh/
https://github.com/helm/helm
```

 **Helm æ–‡æ¡£**

```http
https://helm.sh/zh/docs/
https://helm.sh/zh/docs/intro/quickstart/
```



**Helm é‡è¦ç‰¹æ€§**

- å°†å„ç§èµ„æºæ–‡ä»¶è¿›è¡Œæ‰“åŒ…ï¼ŒåŸºäºåŒ…çš„æ–¹å¼å®‰è£…ï¼Œæ›´åŠ æ–¹ä¾¿
- æä¾›templateåŠŸèƒ½ï¼Œå¯ä»¥åŸºäºåŒä¸€å¥—templateæ–‡ä»¶ï¼Œä½†å¯¹äºä¸åŒç¯å¢ƒå¯ä»¥èµ‹äºˆä¸åŒçš„å€¼ä»è€Œå®ç°çš„çµæ´»éƒ¨ç½²
- æä¾›ç‰ˆæœ¬ç®¡ç†åŠŸèƒ½ï¼Œæ¯”å¦‚ï¼Œå‡çº§ï¼Œå›æ»šç­‰



#### Helm ç›¸å…³æ¦‚å¿µ

- **Helm**ï¼šHelmçš„å®¢æˆ·ç«¯å·¥å…·ï¼Œè´Ÿè´£å’ŒAPI Server é€šä¿¡

  Helm å’Œkubectlç±»ä¼¼ï¼Œä¹Ÿæ˜¯Kubernetes API Serverçš„å‘½ä»¤è¡Œå®¢æˆ·ç«¯å·¥å…·

  æ”¯æŒkubeconfigè®¤è¯æ–‡ä»¶

  éœ€è¦äº‹å…ˆä»ä»“åº“æˆ–æœ¬åœ°åŠ è½½åˆ°è¦ä½¿ç”¨ç›®æ ‡Chartï¼Œå¹¶åŸºäºChartå®Œæˆåº”ç”¨ç®¡ç†ï¼ŒChartå¯ç¼“å­˜äºHelmæœ¬åœ°ä¸»æœºä¸Š
  æ”¯æŒä»“åº“ç®¡ç†å’ŒåŒ…ç®¡ç†çš„å„ç±»å¸¸ç”¨æ“ä½œï¼Œä¾‹å¦‚Chartä»“åº“çš„å¢ã€åˆ ã€æ”¹ã€æŸ¥ï¼Œä»¥åŠChartåŒ…çš„åˆ¶ä½œã€ å‘å¸ƒã€æœç´¢ã€ä¸‹è½½ç­‰

- **Chart**ï¼šæ‰“åŒ…æ–‡ä»¶ï¼Œå°†æ‰€æœ‰ç›¸å…³çš„èµ„æºæ¸…å•æ–‡ä»¶YAMLçš„æ‰“åŒ…æ–‡ä»¶

  Chart  æ˜¯ä¸€ç§æ‰“åŒ…æ ¼å¼ï¼Œæ–‡ä»¶åç¼€ä¸ºtar.gzæˆ–è€… tgzï¼Œä»£è¡¨ç€å¯ç”±Helmç®¡ç†çš„æœ‰ç€ç‰¹å®šæ ¼å¼çš„ç¨‹åºåŒ…ï¼Œç±»ä¼¼äºRPMï¼ŒDEBåŒ…æ ¼å¼

  Chart åŒ…å«äº†åº”ç”¨æ‰€éœ€çš„èµ„æºç›¸å…³çš„å„ç§yaml/jsoné…ç½®æ¸…å•æ–‡ä»¶ï¼Œæ¯”å¦‚ï¼šdeployment,service ç­‰ï¼Œä½†ä¸åŒ…å«å®¹å™¨çš„é•œåƒ

  Chart å¯ä»¥ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œæˆ–è€…å®šåˆ¶ç”¨æˆ·è‡ªå·²çš„é…ç½®è¿›è¡Œå®‰è£…åº”ç”¨

  Chart ä¸­çš„èµ„æºé…ç½®æ–‡ä»¶é€šå¸¸ä»¥æ¨¡æ¿(go template)å½¢å¼å®šä¹‰ï¼Œåœ¨éƒ¨ç½²æ—¶ï¼Œç”¨æˆ·å¯é€šè¿‡å‘æ¨¡æ¿å‚æ•°èµ‹å€¼å®ç°å®šåˆ¶åŒ–å®‰è£…çš„ç›®çš„

  Chart ä¸­å„æ¨¡æ¿å‚æ•°é€šå¸¸ä¹Ÿæœ‰**é»˜è®¤å€¼**ï¼Œè¿™äº›é»˜è®¤å€¼å®šä¹‰åœ¨ChartåŒ…é‡Œä¸€ä¸ªåä¸º**`values.yml`**çš„æ–‡ä»¶ä¸­

- **Release**ï¼šè¡¨ç¤ºåŸºäºchartéƒ¨ç½²çš„ä¸€ä¸ªå®ä¾‹ã€‚é€šè¿‡chartéƒ¨ç½²çš„åº”ç”¨éƒ½ä¼šç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„Release,å³ä½¿åŒä¸€ä¸ªchartéƒ¨ç½²å¤šæ¬¡ä¹Ÿä¼šäº§ç”Ÿå¤šä¸ªRelease.å°†è¿™äº›releaseåº”ç”¨éƒ¨ç½²å®Œæˆåï¼Œä¹Ÿä¼šè®°å½•éƒ¨ç½²çš„ä¸€ä¸ªç‰ˆæœ¬ï¼Œç»´æŠ¤äº†ä¸€ä¸ªreleaseç‰ˆæœ¬çŠ¶æ€,åŸºäºæ­¤å¯ä»¥å®ç°ç‰ˆæœ¬å›æ»šç­‰æ“ä½œ

- **Repository**ï¼šchartåŒ…å­˜æ”¾çš„ä»“åº“ï¼Œç›¸å½“äºAPTå’ŒYUMä»“åº“



#### Helm ç‰ˆæœ¬

##### Helm-v2

**C/S æ¶æ„:**

- **Client** : helm clientï¼Œé€šè¿‡gRPCåè®®å’ŒTilleré€šä¿¡
- **Server**: ç§°ä¸ºTiller, ä»¥Operatorå½¢å¼éƒ¨ç½²Kubernetes é›†ç¾¤å†…ï¼Œè¡¨ç°ä¸ºç›¸åº”çš„ä¸€ä¸ªPodï¼Œè¿˜éœ€è¦åš RBACçš„æˆæƒ

**Tiller Server**

Tiller Serveræ˜¯ä¸€ä¸ªéƒ¨ç½²åœ¨Kubernetesé›†ç¾¤å†…éƒ¨çš„ serverï¼Œå…¶ä¸ Helm clientã€Kubernetes API server  è¿›è¡Œäº¤äº’ã€‚

Tiller server ä¸»è¦è´Ÿè´£å¦‚ä¸‹ï¼š

- ç›‘å¬æ¥è‡ª Helm client çš„è¯·æ±‚
- é€šè¿‡ chart åŠå…¶é…ç½®æ„å»ºä¸€æ¬¡å‘å¸ƒ
- å®‰è£… chart åˆ°Kubernetesé›†ç¾¤ï¼Œå¹¶è·Ÿè¸ªéšåçš„å‘å¸ƒ
- é€šè¿‡ä¸Kubernetesäº¤äº’å‡çº§æˆ–å¸è½½ chart

**æƒé™ç®¡ç†**

- **Helm å®¢æˆ·ç«¯**é…ç½® kubeconfig æ–‡ä»¶ï¼Œä»¥ä¾¿èƒ½å¤Ÿä¸ Kubernetes API æœåŠ¡å™¨é€šä¿¡ã€‚è¿™ä¸ªé…ç½®é€šå¸¸åœ¨  ~/.kube/config æ–‡ä»¶ä¸­ã€‚åŠ è½½è®¤è¯é…ç½®æ–‡ä»¶çš„æœºåˆ¶åŒkubectl
- **Tiller æœåŠ¡ç«¯**éœ€è¦åœ¨å…¶è¿è¡Œçš„å‘½åç©ºé—´ä¸­å…·æœ‰è¶³å¤Ÿçš„æƒé™æ¥ç®¡ç† Kubernetes èµ„æºã€‚è¿™é€šå¸¸é€šè¿‡åˆ› å»ºä¸€ä¸ªæœåŠ¡è´¦æˆ·ï¼ˆServiceAccountï¼‰å¹¶ç»‘å®šé€‚å½“çš„è§’è‰²ï¼ˆä¾‹å¦‚ ClusterRole å’Œ  ClusterRoleBindingï¼‰æ¥å®ç°ã€‚



#####  Helm-v3

2019å¹´11æœˆå‘å¸ƒHelm-v3ç‰ˆæœ¬

![image-20250324204943199](../markdown_img/image-20250324204943199.png)

**Helm 3 çš„å˜åŒ–**

- Tiller æœåŠ¡å™¨ç«¯è¢«åºŸå¼ƒ

  ä»…ä¿ç•™helmå®¢æˆ·ç«¯ï¼Œhelm é€šè¿‡ kubeconfig è®¤è¯åˆ° API Server ï¼Œ åŠ è½½è®¤è¯é…ç½®æ–‡ä»¶çš„æœºåˆ¶åŒ kubectl

-  Release å¯ä»¥åœ¨ä¸åŒåç§°ç©ºé—´é‡ç”¨ï¼Œæ¯ä¸ªåç§°ç©ºé—´åç§°å”¯ä¸€å³å¯

- æ”¯æŒå°† Chart æ¨é€è‡³ Docker é•œåƒä»“åº“

- æ”¯æŒæ›´å¼ºå¤§çš„ Chart templating è¯­æ³•ï¼ŒåŒ…æ‹¬ Go æ¨¡æ¿å’Œæ–°çš„ templating å‡½æ•°ã€‚

  è¿™ä½¿å¾— Helm 3 æ›´çµæ´»ï¼Œå¯ä»¥ç”¨äºæ›´å¤æ‚çš„éƒ¨ç½²åœºæ™¯

- Helm 3 é»˜è®¤ä½¿ç”¨secretsæ¥å­˜å‚¨å‘è¡Œä¿¡æ¯ï¼Œæä¾›äº†æ›´é«˜çš„å®‰å…¨æ€§ã€‚

  Helm 2 é»˜è®¤ä½¿ç”¨configmapså­˜å‚¨å‘è¡Œä¿¡æ¯ã€‚

- è‡ªåŠ¨åˆ›å»ºåç§°ç©ºé—´

  åœ¨ä¸å­˜åœ¨çš„å‘½åç©ºé—´ä¸­åˆ›å»ºå‘è¡Œç‰ˆæ—¶ï¼ŒHelm 2 åˆ›å»ºäº†å‘½åç©ºé—´ã€‚

  Helm 3 éµå¾ªå…¶ä»–Kubermeteså¯¹è±¡çš„è¡Œä¸ºï¼Œå¦‚æœå‘½åç©ºé—´ä¸å­˜åœ¨åˆ™è¿”å›é”™è¯¯ã€‚

  Helm 3 å¯ä»¥é€šè¿‡ `--create-namespace` é€‰é¡¹å½“åç§°ç©ºé—´ä¸å­˜åœ¨æ—¶è‡ªåŠ¨åˆ›å»º

- ä¸å†éœ€è¦requirements.yaml,ä¾èµ–å…³ç³»æ˜¯ç›´æ¥åœ¨ Chart.yamlä¸­å®šä¹‰

- å‘½ä»¤å˜åŒ–

  - åˆ é™¤ release å‘½ä»¤å˜åŒ–

    helm delete RELEASE_NAME --purge => helm uninstall RELEASE_NAME

  - æŸ¥çœ‹ chart ä¿¡æ¯å‘½ä»¤å˜åŒ–

    helm inspect RELEASE_NAME   => helm  show RELEASE_NAME

  - æ‹‰å– chartåŒ…å‘½ä»¤å˜åŒ–

    helm fetch CHART_NAME => helm pull CHART_NAME

  - ç”Ÿæˆreleaseçš„éšæœºå

    helm-v3 å¿…é¡»æŒ‡å®šreleaseåï¼Œå¦‚æœæƒ³ä½¿ç”¨éšæœºåï¼Œå¿…é¡»é€šè¿‡--genrate-name é€‰é¡¹å®ç°ï¼Œ

    helm-v2 å¯ä»¥è‡ªåŠ¨ç”Ÿæˆéšæœºå

    helo install ./mychart  --generate-name





#### Chart ä»“åº“

**Chart ä»“åº“**ï¼šç”¨äºå®ç°ChartåŒ…çš„é›†ä¸­å­˜å‚¨å’Œåˆ†å‘,ç±»ä¼¼äºDockerä»“åº“Harbor

**Chart ä»“åº“**

- **å®˜æ–¹ä»“åº“**:  https://artifacthub.io/
- **å¾®è½¯ä»“åº“**: æ¨èä½¿ç”¨ï¼Œhttp://mirror.azure.cn/kubernetes/charts/
- **é˜¿é‡Œäº‘ä»“åº“**ï¼šhttp://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
- **é¡¹ç›®å®˜æ–¹ä»“åº“**ï¼šé¡¹ç›®è‡ªèº«ç»´æŠ¤çš„Chartä»“åº“
- **Harbor ä»“åº“**ï¼šæ–°ç‰ˆæ”¯æŒåŸºäº **OCI:// åè®®**ï¼Œå°†Chart å­˜æ”¾åœ¨å…¬å…±çš„docker é•œåƒä»“åº“

**Chart å®˜æ–¹ä»“åº“Hub:**

```http
https://artifacthub.io/
```

![image-20250324210429688](../markdown_img/image-20250324210429688.png)

å¯ä»¥æœç´¢éœ€è¦çš„åº”ç”¨ï¼Œå¦‚ä¸‹ç¤ºä¾‹ï¼šredis

![image-20250324223149745](../markdown_img/image-20250324223149745.png)



#### ä½¿ç”¨Helméƒ¨ç½²åº”ç”¨æµç¨‹

- å®‰è£… helm å·¥å…·

- æŸ¥æ‰¾åˆé€‚çš„ chart ä»“åº“

- é…ç½® chart ä»“åº“

- å®šä½ chart

- é€šè¿‡å‘Chartä¸­æ¨¡æ¿æ–‡ä»¶ä¸­å­—ä¸²èµ‹å€¼å®Œæˆå…¶å®ä¾‹åŒ–ï¼Œå³æ¨¡æ¿æ¸²æŸ“ï¼Œ å®ä¾‹åŒ–çš„ç»“æœå°±å¯ä»¥éƒ¨ç½²åˆ°ç›®æ ‡ Kubernetesä¸Š

  æ¨¡æ¿å­—ä¸²çš„å®šåˆ¶æ–¹å¼ä¸‰ç§ï¼š

  - é»˜è®¤ä½¿ç”¨ chart ä¸­çš„ values.yaml ä¸­å®šä¹‰çš„é»˜è®¤å€¼
  - ç›´æ¥åœ¨helm installçš„å‘½ä»¤è¡Œï¼Œé€šè¿‡--seté€‰é¡¹è¿›è¡Œ
  - è‡ªå®šä¹‰values.yamlï¼Œç”±helm install -f values.yaml å‘½ä»¤åŠ è½½è¯¥æ–‡ä»¶

- åŒä¸€ä¸ªchart å¯ä»¥éƒ¨ç½²å‡ºæ¥çš„å¤šä¸ªä¸åŒçš„å®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹ç§°ä¸ºä¸€ä¸ªrelease

   Chart å’Œ Release çš„å…³ç³»ï¼Œç›¸å½“äºOOPå¼€å‘ä¸­çš„Classå’Œå¯¹è±¡çš„å…³ç³»,ç›¸å½“äºimageå’Œcontainer

  åº”ç”¨release å®‰è£…å‘½ä»¤ï¼šhelm install 



### Helm å®¢æˆ·ç«¯å®‰è£…

#### å®˜æ–¹è¯´æ˜

```http
https://helm.sh/docs/intro/install/
```

**Helm ä¸‹è½½é“¾æ¥**

```http
https://github.com/helm/helm/releases
```

![image-20250324224641501](../markdown_img/image-20250324224641501.png)



#### èŒƒä¾‹ï¼šäºŒè¿›åˆ¶å®‰è£… Helm

```bash
# åœ¨kubernetesçš„ç®¡ç†èŠ‚ç‚¹éƒ¨ç½²
[root@master1 ~]# wget -P /usr/local/src https://get.helm.sh/helm-v3.17.2-linux-amd64.tar.gz
[root@master1 ~]# tar xf /usr/local/src/helm-v3.17.2-linux-amd64.tar.gz -C /usr/local/
[root@master1 ~]# ls /usr/local/linux-amd64/
helm  LICENSE  README.md
[root@master1 ~]# ln -s /usr/local/linux-amd64/helm /usr/local/bin/

# helm-v3ç‰ˆæœ¬æ˜¾ç¤ºæ•ˆæœå¦‚ä¸‹
[root@master1 ~]#helm version
version.BuildInfo{Version:"v3.17.2", GitCommit:"cc0bbbd6d6276b83880042c1ecb34087e84d41eb", GitTreeState:"clean", GoVersion:"go1.23.7"}

# Helmå‘½ä»¤è¡¥ä¼š,é‡æ–°ç™»å½•ç”Ÿæ•ˆ
# æ–¹æ³•1
[root@master1 ~]# echo 'source <(helm completion bash)' >> .bashrc && exit

# æ–¹æ³•2
[root@master1 ~]# helm completion bash > /etc/bash_completion.d/helm  && exit
```



### Helm å‘½ä»¤ç”¨æ³•

```http
https://v3.helm.sh/zh/docs/helm/
https://docs.helm.sh/docs/helm/helm/
```



#### Helm å‘½ä»¤ç”¨æ³•è¯´æ˜

**å¸¸ç”¨çš„ helmå‘½ä»¤åˆ†ç±»**

- **Repostory ç®¡ç†**

  repo å‘½ä»¤ï¼Œæ”¯æŒ repository çš„`add`ã€`list`ã€`remove`ã€`update` å’Œ `index` ç­‰å­å‘½ä»¤

- **Chart ç®¡ç†**

  `create`ã€`package`ã€`pull`ã€`push`ã€`dependency`ã€`search`ã€`show` å’Œ `verify` ç­‰æ“ä½œ

- **Release ç®¡ç†**

  `install`ã€`upgrade`ã€`get`ã€`list`ã€`history`ã€`status`ã€`rollback `å’Œ `uninstall` ç­‰æ“ä½œ



**Helmå¸¸è§å­å‘½ä»¤**

```bash
version          # æŸ¥çœ‹helmå®¢æˆ·ç«¯ç‰ˆæœ¬
repo             # æ·»åŠ ã€åˆ—å‡ºã€ç§»é™¤ã€æ›´æ–°å’Œç´¢å¼•chartä»“åº“ï¼Œç›¸å½“äºapt/yumä»“åº“,å¯ç”¨å­å‘½ä»¤:addã€indexã€listã€removeã€update
search           # æ ¹æ®å…³é”®å­—æœç´¢chartåŒ…
show             # æŸ¥çœ‹chartåŒ…çš„åŸºæœ¬ä¿¡æ¯å’Œè¯¦ç»†ä¿¡æ¯ï¼Œå¯ç”¨å­å‘½ä»¤:allã€chartã€readmeã€values
pull             # ä»è¿œç¨‹ä»“åº“ä¸­æ‹‰å–chartåŒ…å¹¶è§£å‹åˆ°æœ¬åœ°ï¼Œé€šè¿‡é€‰é¡¹ --untar è§£å‹,é»˜è®¤ä¸è§£å‹
create           # åˆ›å»ºä¸€ä¸ªchartåŒ…å¹¶æŒ‡å®šchartåŒ…åå­—
install          # é€šè¿‡chartåŒ…å®‰è£…ä¸€ä¸ªreleaseå®ä¾‹
list             # åˆ—å‡ºreleaseå®ä¾‹å
upgrade          # æ›´æ–°ä¸€ä¸ªreleaseå®ä¾‹
rollback         # ä»ä¹‹å‰ç‰ˆæœ¬å›æ»šreleaseå®ä¾‹ï¼Œä¹Ÿå¯æŒ‡å®šè¦å›æ»šçš„ç‰ˆæœ¬å·
uninstall        # å¸è½½ä¸€ä¸ªreleaseå®ä¾‹
history          # è·å–releaseå†å²ï¼Œç”¨æ³•:helm history releaseå®ä¾‹å
package          # å°†chartç›®å½•æ‰“åŒ…æˆchartå­˜æ¡£æ–‡ä»¶.tgzä¸­
get              # ä¸‹è½½ä¸€ä¸ªrelease,å¯ç”¨å­å‘½ä»¤:allã€hooksã€manifestã€notesã€values
status           # æ˜¾ç¤ºreleaseå®ä¾‹çš„çŠ¶æ€ï¼Œæ˜¾ç¤ºå·²å‘½åç‰ˆæœ¬çš„çŠ¶æ€
```



**Helm å¸¸è§å‘½ä»¤ç”¨æ³•**

```bash
# ä»“åº“ç®¡ç†
helm repo list    # åˆ—å‡ºå·²æ·»åŠ çš„ä»“åº“
helm repo add [REPO_NAME] [URL]  # æ·»åŠ è¿œç¨‹ä»“åº“å¹¶å‘½å,å¦‚ä¸‹ç¤ºä¾‹
helm repo add myharbor https://harbor.wangxiaochun.com/chartrepo/myweb --username admin --password 123456
helm repo remove [REPO1 [REPO2 ...]]   # åˆ é™¤ä»“åº“
helm repo update                       # æ›´æ–°ä»“åº“,ç›¸å½“äºapt update
helm search hub  [KEYWORD]             # ä»artifacthubç½‘ç«™æœç´¢,æ— éœ€é…ç½®æœ¬åœ°ä»“åº“,ç›¸å½“äºdocker search
helm search repo [KEYWORD]             # æœ¬åœ°ä»“åº“æœç´¢,éœ€è¦é…ç½®æœ¬åœ°ä»“åº“æ‰èƒ½æœç´¢,ç›¸å½“äºapt search
helm search repo [KEYWORD] --versions  # æ˜¾ç¤ºæ‰€æœ‰ç‰ˆæœ¬
helm show chart [CHART]                # æŸ¥çœ‹chartåŒ…çš„ä¿¡æ¯,ç±»ä¼¼äºapt info
helm show values [CHART]               # æŸ¥çœ‹chartåŒ…çš„values.yamlæ–‡ä»¶å†…å®¹

# æ‹‰å–chartåˆ°æœ¬åœ°
helm pull repo/chartname               # ä¸‹è½½chartsåˆ°å½“å‰ç›®å½•ä¸‹ï¼Œè¡¨ç°ä¸ºtgzæ–‡ä»¶,é»˜è®¤æœ€æ–°ç‰ˆæœ¬ï¼Œç›¸å½“äºwget  
helm pull chart_URL                    # ç›´æ¥ä¸‹è½½ï¼Œé»˜è®¤ä¸º.tgzæ–‡ä»¶
helm pull myrepo/myapp --version 1.2.3 --untar      # ç›´æ¥ä¸‹è½½æŒ‡å®šç‰ˆæœ¬çš„chartåŒ…å¹¶è§£å‹ç¼©

# åˆ›å»ºchartç›®å½•ç»“æ„
helm create NAME

# æ£€æŸ¥è¯­æ³•
helm lint [PATH]  #é»˜è®¤æ£€æŸ¥å½“å‰ç›®å½•

# å®‰è£…
helm install [NAME] [CHART] [--version <string> ]    # å®‰è£…æŒ‡å®šç‰ˆæœ¬çš„chart
helm install [CHART] --generate-name                 # è‡ªåŠ¨ç”Ÿæˆ  RELEASE_NAME
helm install --set KEY1=VALUE1 --set KEY2=VALUE2  RELEASE_NAME CHART ...    #æŒ‡å®šå±æ€§å®ç°å®šåˆ¶é…ç½®
helm install -f values.yaml  RELEASE_NAME CHART..... # å¼•ç”¨æ–‡ä»¶å®ç°å®šåˆ¶é…ç½®
helm install --debug --dry-run RELEASE_NAME CHART    # è°ƒè¯•å¹¶ä¸æ‰§è¡Œï¼Œå¯ä»¥æŸ¥çœ‹åˆ°æ‰§è¡Œçš„æ¸²æŸ“ç»“æœ

# åˆ é™¤
helm uninstall RELEASE_NAME                          # å¸è½½RELEASE


# æŸ¥çœ‹
helm list                                            # åˆ—å‡ºå®‰è£…çš„release
helm status RELEASE_NAME                             # æŸ¥çœ‹RELEASEçš„çŠ¶æ€
helm get notes RELEASE_NAME -n NAMESPACE             # æŸ¥çœ‹RELEASEçš„è¯´æ˜
helm get values RELEASE_NAME -n NAMESPACE > values.yaml   # æŸ¥çœ‹RELEASEçš„ç”Ÿæˆå€¼ï¼Œå¯ä»¥å¯¼å‡ºæ–¹ä¾¿ä»¥åä½¿ç”¨
helm get manifest RELEASE_NAME -n NAMESPACE          # æŸ¥çœ‹RELEASEçš„ç”Ÿæˆçš„èµ„æºæ¸…å•æ–‡ä»¶

# å‡ä»·å’Œå›æ»š
helm upgrade RELEASE_NAME CHART --set key=newvalue       # release æ›´æ–°
helm upgrade RELEASE_NAME CHART -f mychart/values.yaml   # release æ›´æ–°
helm rollback RELEASE_NAME [REVISION]                    # release å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬ï¼Œå¦‚æœä¸æŒ‡å®šç‰ˆæœ¬ï¼Œé»˜è®¤å›æ»šè‡³ä¸Šä¸€ç‰ˆæœ¬
helm history RELEASE_NAME                                # æŸ¥çœ‹å†å²

# æ‰“åŒ…
helm package mychart/ #å°†æŒ‡å®šç›®å½•çš„chartæ‰“åŒ…ä¸º.tgzåˆ°å½“å‰ç›®å½•ä¸‹
```



#### Helm å‘½ä»¤èŒƒä¾‹

èŒƒä¾‹ï¼šæ·»åŠ ä»“åº“å¹¶ä¸‹è½½MySQL chart

```bash
# é»˜è®¤æ²¡æœ‰ä»“åº“
[root@master1 ~]#helm repo list
Error: no repositories to show

# é»˜è®¤æ²¡æœ‰é€šè¿‡Helmå®‰è£…çš„release
[root@master1 ~]#helm list
NAME	NAMESPACE	REVISION	UPDATED	STATUS	CHART	APP VERSION

# ä»å®˜æ–¹ä»“åº“æœç´¢MySQL
[root@master1 ~]#helm search hub mysql|head -n 5
URL                                               	CHART VERSION	APP VERSION            	DESCRIPTION                                       
https://artifacthub.io/packages/helm/bitnami/mysql	12.3.2       	8.4.4                  	MySQL is a fast, reliable, scalable, and easy t...
https://artifacthub.io/packages/helm/dify-tidb/...	11.1.17      	8.4.2                  	MySQL is a fast, reliable, scalable, and easy t...
https://artifacthub.io/packages/helm/kubesphere...	1.0.2        	5.7.33                 	High Availability MySQL Cluster, Open Source.     
https://artifacthub.io/packages/helm/cloudnativ...	5.0.1        	8.0.16                 	Chart to create a Highly available MySQL cluster 

# æ·»åŠ ä»“åº“
[root@master1 ~]#helm repo add bitnami https://charts.bitnami.com/bitnami
"bitnami" has been added to your repositories

# æ·»åŠ ç¬¬äºŒä¸ªä»“åº“
[root@master1 ~]#helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
"ingress-nginx" has been added to your repositories

# æŸ¥çœ‹æœ¬åœ°é…ç½®çš„ä»“åº“
[root@master1 ~]#helm repo list
NAME         	URL                                       
bitnami      	https://charts.bitnami.com/bitnami        
ingress-nginx	https://kubernetes.github.io/ingress-nginx

# æŸ¥çœ‹é…ç½®çš„ä»“åº“ï¼Œä½†æ²¡æœ‰å®‰è£…çš„release
[root@master1 ~]#helm list 
NAME	NAMESPACE	REVISION	UPDATED	STATUS	CHART	APP VERSION

# æ–°ç‰ˆè·¯å¾„æ”¯æŒOCIï¼Œæ— éœ€å…ˆåˆ›å»ºä»“åº“ï¼Œå¯ä»¥æ‹‰å–äº’è”ç½‘ä¸Šçš„chart
[root@master1 ~]#helm pull oci://registry-1.docker.io/bitnamicharts/mysql
Pulled: registry-1.docker.io/bitnamicharts/mysql:12.3.2
Digest: sha256:ba0fd39f3d592c08e90f7c6fe86ea499df5810be3f296546f9eb27f6c51ba24b

# æŸ¥çœ‹
[root@master1 ~]#ll mysql-12.3.2.tgz 
-rw-r--r-- 1 root root 64599  3æœˆ 25 10:14 mysql-12.3.2.tgz


# è§£å‹chartæ–‡ä»¶ï¼Œå¹¶æŸ¥çœ‹ç›®å½•ç»“æ„
[root@master1 ~]#tree mysql
mysql
â”œâ”€â”€ Chart.lock
â”œâ”€â”€ charts
â”‚Â Â  â””â”€â”€ common
â”‚Â Â      â”œâ”€â”€ Chart.yaml
â”‚Â Â      â”œâ”€â”€ README.md
â”‚Â Â      â”œâ”€â”€ templates
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _affinities.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _capabilities.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _compatibility.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _errors.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _images.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _ingress.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _labels.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _names.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _resources.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _secrets.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _storage.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _tplvalues.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ _utils.tpl
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ validations
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _cassandra.tpl
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _mariadb.tpl
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _mongodb.tpl
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _mysql.tpl
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _postgresql.tpl
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _redis.tpl
â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ _validations.tpl
â”‚Â Â      â”‚Â Â  â””â”€â”€ _warnings.tpl
â”‚Â Â      â””â”€â”€ values.yaml
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ README.md
â”œâ”€â”€ templates
â”‚Â Â  â”œâ”€â”€ ca-cert.yaml
â”‚Â Â  â”œâ”€â”€ cert.yaml
â”‚Â Â  â”œâ”€â”€ extra-list.yaml
â”‚Â Â  â”œâ”€â”€ _helpers.tpl
â”‚Â Â  â”œâ”€â”€ metrics-svc.yaml
â”‚Â Â  â”œâ”€â”€ networkpolicy.yaml
â”‚Â Â  â”œâ”€â”€ NOTES.txt
â”‚Â Â  â”œâ”€â”€ primary
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ configmap.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ initialization-configmap.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ pdb.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ startdb-configmap.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ statefulset.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ svc-headless.yaml
â”‚Â Â  â”‚Â Â  â””â”€â”€ svc.yaml
â”‚Â Â  â”œâ”€â”€ prometheusrule.yaml
â”‚Â Â  â”œâ”€â”€ rolebinding.yaml
â”‚Â Â  â”œâ”€â”€ role.yaml
â”‚Â Â  â”œâ”€â”€ secondary
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ configmap.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ pdb.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ statefulset.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ svc-headless.yaml
â”‚Â Â  â”‚Â Â  â””â”€â”€ svc.yaml
â”‚Â Â  â”œâ”€â”€ secrets.yaml
â”‚Â Â  â”œâ”€â”€ serviceaccount.yaml
â”‚Â Â  â”œâ”€â”€ servicemonitor.yaml
â”‚Â Â  â”œâ”€â”€ tls-secret.yaml
â”‚Â Â  â””â”€â”€ update-password
â”‚Â Â      â”œâ”€â”€ job.yaml
â”‚Â Â      â”œâ”€â”€ new-secret.yaml
â”‚Â Â      â””â”€â”€ previous-secret.yaml
â”œâ”€â”€ values.schema.json
â””â”€â”€ values.yaml

8 directories, 58 files
```



### Helm æ¡ˆä¾‹

#### æ¡ˆä¾‹ï¼šéƒ¨ç½² MySQL

```http
https://artifacthub.io/packages/helm/bitnami/mysql
```

![image-20250325102118866](../markdown_img/image-20250325102118866.png)



##### æ¡ˆä¾‹ï¼šæ·»åŠ ä»“åº“å¹¶ä½¿ç”¨é»˜è®¤é…ç½®å®‰è£… MySQL8.0

```bash
# æ·»åŠ ä»“åº“
[root@master1 ~]#helm repo add bitnami https://charts.bitnami.com/bitnami
"bitnami" has been added to your repositories

[root@master1 ~]#helm search repo mysql
NAME                  	CHART VERSION	APP VERSION	DESCRIPTION                                       
bitnami/mysql         	12.3.2       	8.4.4      	MySQL is a fast, reliable, scalable, and easy t...
bitnami/phpmyadmin    	18.1.5       	5.2.2      	phpMyAdmin is a free software tool written in P...
bitnami/mariadb       	20.4.2       	11.4.5     	MariaDB is an open source, community-developed ...
bitnami/mariadb-galera	14.2.1       	11.4.5     	MariaDB Galera is a multi-primary database clus...

# æŸ¥çœ‹ç‰ˆæœ¬
[root@master1 ~]#helm search repo mysql --versions
NAME                  	CHART VERSION	APP VERSION	DESCRIPTION                                       
bitnami/mysql         	12.3.2       	8.4.4      	MySQL is a fast, reliable, scalable, and easy t...
bitnami/mysql         	12.3.1       	8.4.4      	MySQL is a fast, reliable, scalable, and easy t...
bitnami/mysql         	12.3.0       	8.4.4      	MySQL is a fast, reliable, scalable, and easy t...
bitnami/mysql         	12.2.4       	8.4.4      	MySQL is a fast, reliable, scalable, and easy t...
bitnami/mysql         	12.2.2       	8.4.4      	MySQL is a fast, reliable, scalable, and easy t...
......

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
[root@master1 ~]#helm show values bitnami/mysql --version 12.3.2
# Copyright Broadcom, Inc. All Rights Reserved.
# SPDX-License-Identifier: APACHE-2.0

## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
##

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.defaultStorageClass Global default StorageClass for Persistent Volume(s)
## @param global.storageClass DEPRECATED: use global.defaultStorageClass instead
......

#å®‰è£…æ—¶å¿…é¡»æŒ‡å®šå­˜å‚¨å·ï¼Œå¦åˆ™ä¼šå¤„äºPendingçŠ¶æ€
[root@master1 statefulset]#helm install mysql bitnami/mysql --version 12.3.2 --set primary.persistence.storageClass=sc-nfs
NAME: mysql
LAST DEPLOYED: Tue Mar 25 10:44:22 2025
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
CHART NAME: mysql
CHART VERSION: 12.3.2
APP VERSION: 8.4.4

Did you know there are enterprise versions of the Bitnami catalog? For enhanced secure software supply chain features, unlimited pulls from Docker, LTS support, or application customization, see Bitnami Premium or Tanzu Application Catalog. See https://www.arrow.com/globalecs/na/vendors/bitnami for more information.

** Please be patient while the chart is being deployed **

Tip:

  Watch the deployment status using the command: kubectl get pods -w --namespace default

Services:

  echo Primary: mysql.default.svc.cluster.local:3306

Execute the following to get the administrator credentials:

  echo Username: root
  MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default mysql -o jsonpath="{.data.mysql-root-password}" | base64 -d)

To connect to your database:

  1. Run a pod that you can use as a client:

      kubectl run mysql-client --rm --tty -i --restart='Never' --image  docker.io/bitnami/mysql:8.4.4-debian-12-r7 --namespace default --env MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD --command -- bash

  2. To connect to primary service (read/write):

      mysql -h mysql.default.svc.cluster.local -uroot -p"$MYSQL_ROOT_PASSWORD"



WARNING: There are "resources" sections in the chart not set. Using "resourcesPreset" is not recommended for production. For production installations, please set the following values according to your workload needs:
  - primary.resources
  - secondary.resources
+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

# æŸ¥çœ‹
[root@master1 statefulset]#helm list 
NAME 	NAMESPACE	REVISION	UPDATED                                	STATUS    CHART       	APP VERSION
mysql	default  	1       	2025-03-25 10:44:22.868931866 +0800 CST	deployed  mysql-12.3.2	8.4.4 

# æŒ‰ç…§ä¸Šè¿°çš„æç¤ºæ“ä½œ
[root@master1 ~]# MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default mysql -o jsonpath="{.data.mysql-root-password}" | base64 -d)

# åˆ›å»ºä¸€ä¸ªç”¨äºè®¿é—®çš„å®¢æˆ·ç«¯pod
[root@master1 ~]# kubectl run mysql-client --rm --tty -i --restart='Never' --image  docker.io/bitnami/mysql:8.4.4-debian-12-r7 --namespace default --env MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD --command -- bash

# è®¿é—®mysql
I have no name!@mysql-client:/$ mysql -h mysql.default.svc.cluster.local -uroot -p"$MYSQL_ROOT_PASSWORD"
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 122
Server version: 8.4.4 Source distribution

Copyright (c) 2000, 2025, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> 

# å¸è½½mysql
[root@master1 ~]#helm uninstall mysql 
release "mysql" uninstalled

# æ‹‰å–chartåŒ…
[root@master1 ~]# helm pull oci://registry-1.docker.io/bitnamicharts/mysql
Pulled: registry-1.docker.io/bitnamicharts/mysql:12.3.2
Digest: sha256:ba0fd39f3d592c08e90f7c6fe86ea499df5810be3f296546f9eb27f6c51ba24b

# ä½¿ç”¨æœ¬åœ°pullä¸‹æ¥çš„chartè¿›è¡Œç¦»çº¿å®‰è£…
[root@master1 ~]#helm install mysql ./mysql-12.3.2.tgz --set primary.persistence.storageClass=sc-nfs
```



##### helm install è¯´æ˜

```bash
# å®‰è£…çš„CHARTæœ‰å…­ç§å½¢å¼

1. By chart reference: helm install mymaria example/mariadb  #åœ¨çº¿å®‰è£…,å…ˆé€šè¿‡helm repo addæ·»åŠ ä»“åº“ï¼Œæ‰èƒ½åœ¨çº¿å®‰è£…
2. By path to a packaged chart: helm install myweb ./nginx-1.2.3.tgz  #ç¦»çº¿å®‰è£…
3. By path to an unpacked chart directory: helm install myweb ./nginx #ç¦»çº¿å®‰è£…
4. By absolute URL: helm install myweb https://example.com/charts/nginx-1.2.3.tgz #åœ¨çº¿å®‰è£…
5. By chart reference and repo url: helm install --repo https://example.com/charts/ myweb nginx #åœ¨çº¿å®‰è£…
6. By OCI registries: helm install myweb --version 1.2.3 oci://example.com/charts/nginx #åœ¨çº¿å®‰è£…ã€‚
```



##### æ¡ˆä¾‹ï¼šæŒ‡å®šå€¼æ–‡ä»¶values.yamlå†…å®¹å®ç°å®šåˆ¶Release

```bash
[root@master1 ~]# helm show values bitnami/mysql --version 10.3.0 > value.yaml

# å®šåˆ¶å†…å®¹
[root@master1 ~]# vim values.yaml
image:
  registry: docker.io
  repository: bitnami/mysql
  tag: 8.0.37-debian-12-r2
  
auth:
  rootPassword: "123456"
  database: mysticaldb
  username: mystical
  password: "654321"
  
primary:
  persistence:
    storageClass: "sc-nfs"
    
persistence:
  enabled: true
  storageClass: "sc-nfs"
  accessMode: ReadWrite0nce
  size: 8Gi
  
[root@master1 ~]#helm install mysql bitnami/mysql -f values.yaml

# æµ‹è¯•è®¿é—®
[root@master1 ~]# MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default mysql -o jsonpath="{.data.mysql-root-password}" | base64 -d)
[root@master1 ~]# kubectl run mysql-client --rm --tty -i --restart='Never' --image  docker.io/bitnami/mysql:8.0.37-debian-12-r2 --namespace default --env MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD --command -- bash
I have no name!@mysql-client:/$ mysql -h mysql.default.svc.cluster.local -uroot -p"$MYSQL_ROOT_PASSWORD"
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 22
Server version: 8.0.37 Source distribution

Copyright (c) 2000, 2024, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| mysticaldb         |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.03 sec)

# æ›´æ”¹mysticalç”¨æˆ·ç™»å½•
I have no name!@mysql-client:/$ mysql -h mysql.default.svc.cluster.local -u mystical -p"654321"
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 83
Server version: 8.0.37 Source distribution

Copyright (c) 2000, 2024, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysticaldb         |
| performance_schema |
+--------------------+
3 rows in set (0.01 sec)
```



##### æ¡ˆä¾‹ï¼šMySQL ä¸»ä»å¤åˆ¶

```bash
# æ–¹æ³•1ï¼šé€šè¿‡ä»“åº“
[root@master1 ~]#helm repo add bitnami https://charts.bitnami.com/bitnami
"bitnami" has been added to your repositories

# æ³¨æ„ï¼š\ åé¢ä¸èƒ½æœ‰ä»»ä½•å­—ç¬¦ï¼ˆåŒ…æ‹¬ç©ºæ ¼ã€Tabï¼‰
[root@master1 ~]# helm install mysql bitnami/mysql  \
    --set 'auth.rootPassword=Zyf646130' \
    --set 'auth.replicationPassword=Zyf646130' \
    --set global.storageClass=sc-nfs \
    --set auth.database=wordpress \
    --set auth.username=wordpress \
    --set 'auth.password=Zyf646130' \
    --set architecture=replication \
    --set secondary.replicaCount=1 \
    -n wordpress --create-namespace
    
# æ–¹æ³•2ï¼šé€šè¿‡OCIåè®®
[root@master1 ~]# helm install mysql  \
    --set auth.rootPassword='P@ssw0rd' \
    --set global.storageClass=sc-nfs \
    --set auth.database=wordpress \
    --set auth.username=wordpress \
    --set auth.password='P@ssw0rd' \
    --set architecture=replication \
    --set secondary.replicaCount=1 \
    --set auth.replicationPassword='P@ssw0rd' \
    oci://registry-1.docker.io/bitnamicharts/mysql \
    -n wordpress --create-namespace
```

ä¸»ä»å¤åˆ¶æ›´æ–°å‰¯æœ¬æ•°ä¸º2

```bash
[root@master1 ~]# helm upgrade mysql \
    --set auth.rootPassword='Zyf646130' \
    --set global.storageClass=sc-nfs \
    --set auth.database=wordpress \
    --set auth.username=wordpress \
    --set auth.password='Zyf646130' \
    --set architecture=replication \
    --set secondary.replicaCount=2 \
    --set auth.replicationPassword='Zyf646130' \
    bitnami/mysql \
    -n wordpress
    
# æŸ¥çœ‹
[root@master1 ~]# kubectl get pod -n wordpress 
NAME                READY   STATUS     RESTARTS   AGE
mysql-primary-0     1/1     Running    0          7m7s
mysql-secondary-0   1/1     Running    0          7m7s
mysql-secondary-1   0/1     Init:0/1   0          6s

# ä¸‰åˆ†é’Ÿï¼Œæœ‰ç‚¹æ…¢
[root@master1 ~]# kubectl get pod -n wordpress 
NAME                READY   STATUS    RESTARTS   AGE
mysql-primary-0     1/1     Running   0          10m
mysql-secondary-0   1/1     Running   0          10m
mysql-secondary-1   1/1     Running   0          3m30s
```



#### æ¡ˆä¾‹ï¼šéƒ¨ç½² WordPress

```http
https://artifacthub.io/packages/helm/bitnami/wordpress
```

##### ä½¿ç”¨å¤–éƒ¨MySQLä¸»ä»å¤åˆ¶å’Œå¹¶å®ç°Ingressæš´éœ²æœåŠ¡

```bash
[root@master1 ~]# helm install wordpress \
    --version 22.4.20 \
    --set mariadb.enabled=false \
    --set externalDatabase.host=mysql-primary.wordpress.svc.cluster.local \
    --set externalDatabase.user=wordpress \
    --set externalDatabase.password='Zyf646130' \
    --set externalDatabase.port=3306 \
    --set wordpressUsername=admin \
    --set wordpressPassword='Zyf646130' \
    --set persistence.storageClass=sc-nfs \
    --set ingress.enabled=true \
    --set ingress.ingressClassName=nginx \
    --set ingress.hostname=wordpress.mystical.org \
    --set ingress.pathType=Prefix \
    --set externalDatabase.database=wordpress \
    --set volumePermissions.enabled=true \
    --set livenessProbe.enabled=false \
    --set readinessProbe.enabled=false \
    --set startupProbe.enabled=false \
    bitnami/wordpress \
    -n wordpress --create-namespace
    
# å…¨è¿‡ç¨‹ï¼š15åˆ†é’Ÿå·¦å³ï¼Œå…¶ä¸­æ•°æ®ä¸‹è½½ï¼š10åˆ†é’Ÿå·¦å³
# NFSä¸Šçš„wordpressæ•°æ®å¤§å°
[root@ubuntu2204 wordpress-wordpress-pvc-7704d2ef-3f52-4fd7-9c1f-add88dd30c1f]#du -sh wordpress/
256M	wordpress/
```

![image-20250325161641974](../markdown_img/image-20250325161641974.png)

![image-20250325190744228](../markdown_img/image-20250325190744228.png)



#### æ¡ˆä¾‹ï¼šéƒ¨ç½² Harbor

```http
https://artifacthub.io/packages/helm/harbor/harbor
```

![image-20250325193832806](../markdown_img/image-20250325193832806.png)

â€‹        

**å®ç°æµç¨‹**

- ä½¿ç”¨ `helm` å°† `harbor` éƒ¨ç½²åˆ° `kubernetes` é›†ç¾¤
- ä½¿ç”¨ingresså‘å¸ƒåˆ°é›†ç¾¤å¤–éƒ¨
- ä½¿ç”¨ PVC æŒä¹…å­˜å‚¨

èŒƒä¾‹

```bash
# å®‰è£…å‰å‡†å¤‡
# ingress controller åŸºäºnginxå®ç°
# SCåç§°ä¸ºsc-nfs

# æ·»åŠ ä»“åº“é…ç½®
[root@master1 ~]#helm repo add harbor https://helm.goharbor.io
"harbor" has been added to your repositories

# æŸ¥çœ‹
[root@master1 ~]#helm search repo harbor
NAME          	CHART VERSION	APP VERSION	DESCRIPTION                                       
bitnami/harbor	24.4.1       	2.12.2     	Harbor is an open source trusted cloud-native r...
harbor/harbor 	1.16.2       	2.12.2     	An open source trusted cloud native registry th...


# å®šåˆ¶é…ç½®
[root@master1 ~]#helm show values bitnami/harbor > harbor.values.yaml

[root@master1 ~]#cat harbor.values.yaml |grep -Pv "^\s*#"
expose:
  type: ingress
  tls:
    enabled: true                                       # å¼€å¯tls
    certSource: auto                                    # è‡ªåŠ¨é…ç½®ca
    auto:
      commonName: ""
    secret:
      secretName: ""
  ingress:
    hosts:
      core: harbor.mystical.org                          # æŒ‡å®šharborè®¿é—®çš„åŸŸå
    controller: default
    kubeVersionOverride: ""
    className: "nginx"                                   # æŒ‡å®šingress
    annotations:
      ingress.kubernetes.io/ssl-redirect: "true"
      ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      kubernetes.io/ingress.class: "nginx"               # æŒ‡å®šingressï¼Œæ—§ç‰ˆç”¨æ³•
......
externalURL: https://harbor.mystical.org                 # æŒ‡å®šharborè®¿é—®çš„åŸŸå

persistence:
  enabled: true
  resourcePolicy: "keep"
  persistentVolumeClaim:
    registry:
      existingClaim: ""
      storageClass: "sc-nfs"
      subPath: ""
      accessMode: ReadWriteOnce
      size: 5Gi
      annotations: {}
    jobservice:
      jobLog:
        existingClaim: ""
        storageClass: "sc-nfs"
        subPath: ""
        accessMode: ReadWriteOnce
        size: 1Gi
        annotations: {}
    database:                                       # PostgreSQlæ•°æ®åº“ç»„ä»¶
      existingClaim: ""
      storageClass: "sc-nfs"
      subPath: ""
      accessMode: ReadWriteOnce
      size: 1Gi
      annotations: {}
    redis:
      existingClaim: ""
      storageClass: "sc-nfs"
      subPath: ""
      accessMode: ReadWriteOnce
      size: 1Gi
      annotations: {}
    trivy:
      existingClaim: ""
      storageClass: "sc-nfs"
      subPath: ""
      accessMode: ReadWriteOnce
      size: 5Gi
      annotations: {}
......

existingSecretAdminPasswordKey: HARBOR_ADMIN_PASSWORD
harborAdminPassword: "123456"                           # æ›´æ”¹å¯†ç 
    
#åˆ›å»ºåç§°ç©ºé—´(å¯é€‰)
[root@master1 ~]# kubectl create namespace harbor    

[root@master1 ~]#helm install myharbor -f harbor.values.yaml harbor/harbor -n harbor --create-namespace

# æŸ¥çœ‹ç”Ÿæˆçš„å€¼
[root@master1 ~]#helm get values -n harbor myharbor

# æŸ¥çœ‹ç”Ÿæˆçš„èµ„æºæ¸…å•æ–‡ä»¶
[root@master1 ~]#helm get manifest -n harbor myharbor

# æŸ¥çœ‹ingress
[root@master1 ~]#kubectl get ingress -n harbor 
NAME               CLASS   HOSTS                 ADDRESS         PORTS     AGE
myharbor-ingress   nginx   harbor.mystical.org   172.22.200.10   80, 443   15m

# æŸ¥çœ‹pod
[root@master1 ~]#kubectl get pod -n harbor 
NAME                                   READY   STATUS    RESTARTS      AGE
myharbor-core-65876d6984-c8j6w         1/1     Running   2 (13m ago)   15m
myharbor-database-0                    1/1     Running   0             15m
myharbor-jobservice-5cfbf75f96-8zv2g   1/1     Running   6 (12m ago)   15m
myharbor-portal-9884f7648-4dwhc        1/1     Running   0             15m
myharbor-redis-0                       1/1     Running   0             15m
myharbor-registry-784898f8cb-xq8bw     2/2     Running   0             15m
myharbor-trivy-0                       1/1     Running   0             15m

# åœ¨å®¿ä¸»æœºé…ç½®åŸŸåè§£æ
# è®¿é—®æµè§ˆå™¨ï¼šhttps://harbor.mystical.org
# è´¦å·/å¯†ç ï¼šadmin/123456
```

![image-20250325222106027](../markdown_img/image-20250325222106027.png)





### è‡ªå®šä¹‰ Chart

#### Chart ç›®å½•ç»“æ„

```http
https://docs.helm.sh/docs/chart_template_guide/getting_started/
```

```bash
# åˆ›å»ºchartæ–‡ä»¶ç»“æ„
[root@master1 ~]#helm create mychart
Creating mychart

[root@master1 ~]#tree mychart/
mychart/
â”œâ”€â”€ charts
â”œâ”€â”€ Chart.yaml                        # å¿…é¡»é¡¹ï¼ŒåŒ…å«äº†è¯¥chartçš„æè¿°ï¼Œhelm show chart [CHART] æŸ¥çœ‹åˆ°å³æ­¤æ–‡ä»¶å†…å®¹
â”œâ”€â”€ templates                         # åŒ…æ‹¬äº†å„ç§èµ„æºæ¸…å•çš„æ¨¡æ¿æ–‡ä»¶
â”‚Â Â  â”œâ”€â”€ deployment.yaml
â”‚Â Â  â”œâ”€â”€ _helpers.tpl
â”‚Â Â  â”œâ”€â”€ hpa.yaml
â”‚Â Â  â”œâ”€â”€ ingress.yaml
â”‚Â Â  â”œâ”€â”€ NOTES.txt
â”‚Â Â  â”œâ”€â”€ serviceaccount.yaml
â”‚Â Â  â”œâ”€â”€ service.yaml
â”‚Â Â  â””â”€â”€ tests
â”‚Â Â      â””â”€â”€ test-connection.yaml
â””â”€â”€ values.yaml                       # å¦‚æœtemplates/ç›®å½•ä¸­åŒ…å«å˜é‡æ—¶,å¯ä»¥é€šè¿‡æ­¤æ–‡ä»¶æä¾›å˜é‡çš„é»˜è®¤å€¼
                                      # è¿™äº›å€¼å¯ä»¥åœ¨ç”¨æˆ·æ‰§è¡Œ helm install æˆ– helm upgrade æ—¶è¢«è¦†ç›–
                                      # helm show values  [CHART]  æŸ¥çœ‹åˆ°å³æ­¤æ–‡ä»¶å†…å®¹
3 directories, 10 files
```

**Chart.yaml æ–‡ä»¶**

```bash
# harborçš„chart.yamlç¤ºä¾‹
[root@master1 harbor]#cat Chart.yaml 
apiVersion: v1
appVersion: 2.12.2
description: An open source trusted cloud native registry that stores, signs, and
  scans content
home: https://goharbor.io
icon: https://raw.githubusercontent.com/goharbor/website/main/static/img/logos/harbor-icon-color.png
keywords:
- docker
- registry
- harbor
maintainers:
- email: yan-yw.wang@broadcom.com
  name: Yan Wang
- email: stone.zhang@broadcom.com
  name: Stone Zhang
- email: miner.yang@broadcom.com
  name: Miner Yang
name: harbor
sources:
- https://github.com/goharbor/harbor
- https://github.com/goharbor/harbor-helm
version: 1.16.2

[root@master1 harbor]#helm list -n harbor
NAME    	NAMESPACE	REVISION	UPDATED                     STATUS  	CHART        	APP VERSION
myharbor	harbor   	1       	2025-03-25 22... +0800 CST	deployed	harbor-1.16.2	2.12.2
```

**templates/ ç›®å½•**

åŒ…æ‹¬äº†å„ç§èµ„æºæ¸…å•çš„æ¨¡æ¿æ–‡ä»¶ã€‚æ¯”å¦‚: `deployment` ,`service` ,`ingress` , `configmap` , `secret` ç­‰

å¯ä»¥æ˜¯å›ºå®šå†…å®¹çš„æ–‡æœ¬,ä¹Ÿå¯ä»¥åŒ…å«ä¸€äº›å˜é‡,å‡½æ•°ç­‰æ¨¡æ¿è¯­æ³•

å½“Helmè¯„ä¼°chartæ—¶ï¼Œä¼šé€šè¿‡æ¨¡æ¿æ¸²æŸ“å¼•æ“å°†æ‰€æœ‰æ–‡ä»¶å‘é€åˆ° `templates/` ç›®å½•ä¸­ã€‚ ç„¶åæ”¶é›†æ¨¡æ¿çš„ç»“æœå¹¶å‘é€ç»™Kubernetesã€‚

```bash
# ä»¥harborçš„chartä¸­ï¼Œtemplate/nginx/secretä¸ºä¾‹
[root@master1 templates]#cat nginx/secret.yaml 
{{- if eq (include "harbor.autoGenCertForNginx" .) "true" }}
{{- $ca := genCA "harbor-ca" 365 }}
{{- $cn := (required "The \"expose.tls.auto.commonName\" is required!" .Values.expose.tls.auto.commonName) }}
apiVersion: v1
kind: Secret
metadata:
  name: {{ template "harbor.nginx" . }}
  namespace: {{ .Release.Namespace | quote }}
  labels:
{{ include "harbor.labels" . | indent 4 }}
type: Opaque
data:
  {{- if regexMatch `^((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$` $cn }}
  {{- $cert := genSignedCert $cn (list $cn) nil 365 $ca }}
  tls.crt: {{ $cert.Cert | b64enc | quote }}
  tls.key: {{ $cert.Key | b64enc | quote }}
  ca.crt: {{ $ca.Cert | b64enc | quote }}
  {{- else }}
  {{- $cert := genSignedCert $cn nil (list $cn) 365 $ca }}
  tls.crt: {{ $cert.Cert | b64enc | quote }}
  tls.key: {{ $cert.Key | b64enc | quote }}
  ca.crt: {{ $ca.Cert | b64enc | quote }}
  {{- end }}
{{- end }}
```

**values.yaml æ–‡ä»¶ï¼ˆå¯é€‰é¡¹ï¼‰**

å¦‚æœ `templetes/` ç›®å½•ä¸‹æ–‡ä»¶éƒ½æ˜¯å›ºå®šå†…å®¹,æ­¤æ–‡ä»¶æ— éœ€åˆ›å»º

å¦‚æœ `templates/` ç›®å½•ä¸­åŒ…å«å˜é‡æ—¶,å¯ä»¥é€šè¿‡æ­¤æ–‡ä»¶æä¾›å˜é‡çš„é»˜è®¤å€¼

è¿™äº›å€¼å¯ä»¥åœ¨ç”¨æˆ·æ‰§è¡Œ `helm install` æˆ– `helm upgrade` æ—¶è¢«è¦†ç›–

`helm show values  [CHART]`  æŸ¥çœ‹åˆ°å³æ­¤æ–‡ä»¶å†…å®¹

**charts/ ç›®å½•ï¼ˆå¯é€‰é¡¹ï¼‰**

å¯ä»¥åŒ…å«ä¾èµ–çš„å…¶ä»–çš„chart, ç§°ä¹‹ä¸º å­chart



#### å¸¸ç”¨çš„å†…ç½®å¯¹è±¡

Chart ä¸­æ”¯æŒå¤šç§å†…ç½®å¯¹è±¡,å³ç›¸å…³å†…ç½®çš„ç›¸å…³å˜é‡,å¯ä»¥é€šè¿‡å¯¹è¿™äº›å˜é‡è¿›è¡Œå®šä¹‰å’Œå¼•ç”¨,å®ç°å®šåˆ¶ Chart çš„ç›®çš„

- **Release å¯¹è±¡**
- **Values å¯¹è±¡**
- **Chart å¯¹è±¡**
- **Capabilities å¯¹è±¡**
- **Template å¯¹è±¡**



##### helm3 çš„å†…ç½®å¯¹è±¡è¯¦è§£

**Releaseå¯¹è±¡**

æè¿°åº”ç”¨å‘å¸ƒè‡ªèº«çš„ä¸€äº›ä¿¡æ¯,ä¸»è¦åŒ…æ‹¬å¦‚ä¸‹å¯¹è±¡

```bash
.Release.Name              # release çš„åç§°
.Release.Namespace         # release çš„å‘½åç©ºé—´
.Release.Revision          # è·å–æ­¤æ¬¡ä¿®è®¢çš„ç‰ˆæœ¬å·ã€‚åˆæ¬¡å®‰è£…æ—¶ä¸º1ï¼Œæ¯æ¬¡å‡çº§æˆ–å›æ»šéƒ½ä¼šé€’å¢
.Release.Service           # è·å–æ¸²æŸ“å½“å‰æ¨¡æ¿çš„æœåŠ¡åç§°ã€‚ä¸€èˆ¬éƒ½æ˜¯ Helm
.Release.IsInstall         # å¦‚æœå½“å‰æ“ä½œæ˜¯å®‰è£…ï¼Œè¯¥å€¼ä¸º true
.Release.IsUpgrade         # å¦‚æœå½“å‰æ“ä½œæ˜¯å‡çº§æˆ–å›æ»šï¼Œè¯¥å€¼ä¸ºtrue
.Release.Time              # Chartå‘å¸ƒæ—¶é—´

#å¼•ç”¨
{{ .Release.Name }}
```



**Values å¯¹è±¡**

æè¿° values.yaml æ–‡ä»¶(ç”¨äºå®šä¹‰é»˜è®¤å˜é‡çš„å€¼æ–‡ä»¶)ä¸­çš„å†…å®¹ï¼Œé»˜è®¤ä¸ºç©ºã€‚

ä½¿ç”¨ Values å¯¹è±¡å¯ä»¥è·å–åˆ° values.yaml æ–‡ä»¶ä¸­å·²å®šä¹‰çš„ä»»ä½•å˜é‡æ•°å€¼

å½¢å¼ä¸º `key/value` å¯¹

ç¤ºä¾‹

```bash
# å˜é‡èµ‹å€¼
key1: value1

info:
  key2: value2

# å˜é‡å¼•ç”¨
# æ³¨æ„: å¤§å†™å­—æ¯V
{{ .Value.key1 }}
{{ .Value.info.key2 }}
```

**å®šåˆ¶å€¼çš„ä¸¤ç§æ–¹æ³•**

| values.yaml æ–‡ä»¶                                  | --set é€‰é¡¹                                     |
| ------------------------------------------------- | ---------------------------------------------- |
| name: mystical                                    | --set name=mystical                            |
| name: "mystical,recluse"                          | --set name=mystical\,recluse                   |
| name: mystical<br />age: 18                       | --set name=mystical, age=18                    |
| info:<br />  name: mystical                       | --set info.name=mystical                       |
| name:<br />- mystical<br />- recluse<br />- curry | --set name={mystical,recluse,curry}            |
| info:<br />- name: mystical                       | --set info[0].name=mystical                    |
| info:<br />- name: mystical<br />  age: 18        | --set info[0].name=mystical, info[0].age=18    |
| nodeSelector:<br />  kubernetes.io/role: worker   | --set nodeSelector."kubernetes.io/role"=worker |



 **Chart å¯¹è±¡**

ç”¨äºè·å–Chart.yaml æ–‡ä»¶ä¸­çš„å†…å®¹

```bash
.Chart.Name                # å¼•ç”¨Chart.yamlæ–‡ä»¶å®šä¹‰çš„chartçš„åç§°
.Chart.Version             # å¼•ç”¨Chart.yamlæ–‡ä»¶å®šä¹‰çš„Chartçš„ç‰ˆæœ¬

#å¼•ç”¨
{{ .Chart.Name }}
```



**Capabilities å¯¹è±¡**

æä¾›äº†å…³äºkubernetes é›†ç¾¤ç›¸å…³çš„ä¿¡æ¯ã€‚è¯¥å¯¹è±¡æœ‰å¦‚ä¸‹å¯¹è±¡

```bash
.Capabilities.APIVersions               # è¿”å›kubernetesé›†ç¾¤ APIç‰ˆæœ¬ä¿¡æ¯é›†åˆ
.Capabilities.APIVersions.Has $version  # æ£€æµ‹æŒ‡å®šç‰ˆæœ¬æˆ–èµ„æºåœ¨k8sä¸­æ˜¯å¦å¯ç”¨ï¼Œä¾‹å¦‚:apps/v1/Deployment,å¯ç”¨ä¸ºtrue
.Capabilities.KubeVersionå’Œ.Capabilities.KubeVersion.Version  # éƒ½ç”¨äºè·å–kubernetes çš„ç‰ˆæœ¬,åŒ…æ‹¬Majorå’ŒMinor
.Capabilities.KubeVersion.Major         # å¼•ç”¨kubernetes çš„ä¸»ç‰ˆæœ¬å·,ç¬¬ä¸€ä½çš„ç‰ˆæœ¬å·,æ¯”å¦‚:v1.18.2ä¸­ä¸º1
.Capabilities.KubeVersion.Minor         # å¼•ç”¨kubernetes çš„å°ç‰ˆæœ¬å·,ç¬¬äºŒä½ç‰ˆæœ¬å·,æ¯”å¦‚:v1.18.2ä¸­ä¸º18

# å¼•ç”¨
{{ .Capabilities.APIVersions }}
```



**Template å¯¹è±¡**

ç”¨äºè·å–å½“å‰æ¨¡æ¿çš„ä¿¡æ¯ï¼Œå®ƒåŒ…å«å¦‚ä¸‹ä¸¤ä¸ªå¯¹è±¡

```bash
.Template.BasePath  # å¼•ç”¨å½“å‰æ¨¡æ¿çš„åç§°å’Œè·¯å¾„(ç¤ºä¾‹:mychart/templates/configmap.yaml)
.Template.Name      # å¼•ç”¨å½“å‰æ¨¡æ¿çš„ç›®å½•è·¯å¾„(ç¤ºä¾‹:mychart/templates)

# å¼•ç”¨
{{ .Template.Name }}c
```



##### å‡½æ•°

```http
https://helm.sh/zh/docs/chart_template_guide/function_list/
```

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“äº†å¦‚ä½•å°†ä¿¡æ¯ä¼ åˆ°æ¨¡æ¿ä¸­ã€‚ ä½†æ˜¯ä¼ å…¥çš„ä¿¡æ¯å¹¶ä¸èƒ½è¢«ä¿®æ”¹ã€‚

æœ‰æ—¶æˆ‘ä»¬å¸Œæœ›ä»¥ä¸€ç§æ›´æœ‰ç”¨çš„æ–¹å¼æ¥è½¬æ¢æ‰€æä¾›çš„æ•°æ®ã€‚

æ¯”å¦‚: å¯ä»¥é€šè¿‡è°ƒç”¨æ¨¡æ¿æŒ‡ä»¤ä¸­çš„ quote å‡½æ•°æŠŠ `.Values` å¯¹è±¡ä¸­çš„å­—ç¬¦ä¸²å±æ€§ç”¨åŒå¼•å·å¼•èµ·æ¥ï¼Œç„¶åæ”¾åˆ°æ¨¡æ¿ä¸­ã€‚

```bash
apiVersion: v1
kind: ConfigMap
metadata: 
  name: {{ .Release.Name }}-configmap
data:
  myvalue: "Hello World"
  # æ ¼å¼1
  drink: {{ quote .Values.favorite.drink }}
  food: {{ squote .Values.favorite.food }}
  # æ ¼å¼2
  #drink: {{ .Value.favorite.drink | quote }}   # åŒå¼•å·å‡½æ•°quote
  #food: {{ .Value.favorite.food | squote }}    # å•å¼•å·å‡½æ•°squote
```

æ¨¡æ¿å‡½æ•°çš„è¯­æ³•æ˜¯

```bash
# æ ¼å¼1
function arg1 arg2...
# æ ¼å¼2ï¼š å¤šæ¬¡å‡½æ•°å¤„ç†
arg1 | functionName1 | functionName2 ...
```

åœ¨ä¸Šé¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œ `quote .Values.favorite.drink` è°ƒç”¨äº† `quote` å‡½æ•°å¹¶ä¼ é€’äº†ä¸€ä¸ªå‚æ•° `(.Values.favorite.drink)`ã€‚

Helm æœ‰è¶…è¿‡60ä¸ªå¯ç”¨å‡½æ•°ã€‚å…¶ä¸­æœ‰äº›é€šè¿‡  Goæ¨¡æ¿è¯­è¨€ æœ¬èº«å®šä¹‰ã€‚å…¶ä»–å¤§éƒ¨åˆ†éƒ½æ˜¯`Sprig æ¨¡ç‰ˆåº“`  å¯ä»¥åœ¨ç¤ºä¾‹çœ‹åˆ°å…¶ä¸­å¾ˆå¤šå‡½æ•°ã€‚

Helm åŒ…å«äº†å¾ˆå¤šå¯ä»¥åœ¨æ¨¡æ¿ä¸­åˆ©ç”¨çš„æ¨¡æ¿å‡½æ•°ã€‚ä»¥ä¸‹åˆ—å‡ºäº†å…·ä½“åˆ†ç±»ï¼š

```ABAP
Cryptographic and Security
Date
Dictionaries
Encoding
File Path
Kubernetes and Chart
Logic and Flow Control
Lists
Math
Float Math
Network
Reflection
Regular Expressions
Semantic Versions
String
Type Conversion
URL
UUID
```



##### å¸¸ç”¨è¯­æ³•

###### `with` è¯­æ³•

**ä½œç”¨**ï¼šè¿›å…¥æŸä¸ªå€¼çš„ä¸Šä¸‹æ–‡ï¼Œç®€åŒ–è®¿é—®è·¯å¾„

```yaml
# values.yaml
image:
  repository: nginx
  tag: 1.21.6
  pullPolicy: IfNotPresent
```

```yaml
# templates/deployment.yaml
spec:
  containers:
    - name: nginx
      {{- with .Values.image }}
      image: {{ .repository }}:{{ .tag }}
      imagePullPolicy: {{ .pullPolicy }}
      {{- end }}
```

**ç­‰ä»·äº**

```yaml
image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
```

ä½† `with` ä¼šæŠŠ `image` å½“ä½œå½“å‰ä¸Šä¸‹æ–‡ï¼Œå†™æ³•æ›´æ¸…æ™°ã€‚

**é€‚åˆåœºæ™¯**ï¼š

- å¤šæ¬¡ä½¿ç”¨ `.Values.xxx` ç»“æ„ä½“çš„å­å­—æ®µ
- æ¡ä»¶å­˜åœ¨æ—¶æ‰è¿›å…¥ä½¿ç”¨ï¼ˆé¿å…ç©ºæŒ‡é’ˆï¼‰

**æ³¨æ„**ï¼š

- `with` åªåœ¨å€¼éç©ºæ—¶æ‰§è¡Œå…¶å†…éƒ¨ä»£ç å—



###### `range` è¯­å¥

**ä½œç”¨**ï¼š**è¿­ä»£æ•°ç»„ã€åˆ—è¡¨ã€å­—å…¸**

ç¤ºä¾‹ 1ï¼šè¿­ä»£åˆ—è¡¨

```yaml
# values.yaml
tolerations:
  - key: "node-type"
    operator: "Equal"
    value: "gpu"
    effect: "NoSchedule"
```

```yaml
# templates/deployment.yaml
spec:
  tolerations:
    {{- range .Values.tolerations }}
    - key: {{ .key }}
      operator: {{ .operator }}
      value: {{ .value }}
      effect: {{ .effect }}
    {{- end }}
```

ç¤ºä¾‹ 2ï¼šè¿­ä»£å­—å…¸ï¼ˆmapï¼‰

```yaml
# values.yaml
config:
  A: "value-a"
  B: "value-b"
```

```yaml
env:
{{- range $key, $val := .Values.config }}
  - name: {{ $key }}
    value: {{ $val | quote }}
{{- end }}
```

- `$key` å’Œ `$val` æ˜¯è‡ªå®šä¹‰å˜é‡å

- `quote` ç”¨äºç»™å­—ç¬¦ä¸²åŠ å¼•å·



###### `with` å’Œ `range` ç»„åˆç”¨æ³•

```yaml
# values.yaml
service:
  ports:
    - name: http
      port: 80
    - name: https
      port: 443
```

```yaml
{{- with .Values.service }}
  ports:
    {{- range .ports }}
    - name: {{ .name }}
      port: {{ .port }}
    {{- end }}
{{- end }}
```

å…ˆè¿›å…¥ `service` å†éå† `ports`ï¼Œæ›´ç»“æ„åŒ–ã€‚



###### ç©ºç™½æ§åˆ¶ï¼ˆwhitespace controlï¼‰è¯­æ³•

**å†™æ³•è¯´æ˜**

| å†™æ³•          | ä½œç”¨                             |
| ------------- | -------------------------------- |
| `{{ ... }}`   | é»˜è®¤æ¸²æŸ“ï¼Œå‰åä¿ç•™ç©ºæ ¼å’Œæ¢è¡Œ     |
| `{{- ... }}`  | å»é™¤å·¦ä¾§çš„æ‰€æœ‰ç©ºç™½ç¬¦ï¼ˆåŒ…æ‹¬æ¢è¡Œï¼‰ |
| `{{ ... -}}`  | å»é™¤å³ä¾§çš„æ‰€æœ‰ç©ºç™½ç¬¦ï¼ˆåŒ…æ‹¬æ¢è¡Œï¼‰ |
| `{{- ... -}}` | åŒæ—¶å»é™¤å·¦å³ä¸¤ä¾§ç©ºç™½ç¬¦           |

**ç¤ºä¾‹å¯¹æ¯”**

**æ™®é€šå†™æ³•ï¼ˆä¿ç•™ç©ºè¡Œï¼‰**

```yaml
containers:
  - name: nginx
    image: {{ .Values.image.repository }}:{{ .Values.image.tag }}

    imagePullPolicy: {{ .Values.image.pullPolicy }}
```

å¯èƒ½å¤šå‡ºä¸€ä¸ªç©ºè¡Œæˆ–å¤šä½™ç¼©è¿›ã€‚

**åŠ  `-` æ§åˆ¶ç©ºç™½**

```yaml
{{- with .Values.image }}
image: {{ .repository }}:{{ .tag }}
imagePullPolicy: {{ .pullPolicy }}
{{- end }}
```

ä¼šå»æ‰å‰åå¤šä½™çš„ç©ºæ ¼å’Œç©ºè¡Œï¼Œè¾“å‡ºæ›´ç´§å‡‘ã€‚



**ä½¿ç”¨å»ºè®®**

| æƒ…å†µ                                      | æ˜¯å¦åŠ  `-`                              |
| ----------------------------------------- | --------------------------------------- |
| åœ¨é€»è¾‘è¯­å¥å—å‰åï¼ˆ`with`, `if`, `range`ï¼‰ | âœ…å»ºè®®åŠ                                  |
| åœ¨å†…å®¹è¡Œä¸­é—´                              | âŒé¿å…ç”¨ï¼Œå¦åˆ™ä¼šç ´å YAML æ ¼å¼           |
| ä»£ç ç¼©è¿›å¾ˆé‡è¦çš„åœ°æ–¹                      | ğŸ‘€éœ€å°å¿ƒä½¿ç”¨ï¼Œç¡®è®¤ä¸ä¼šç ´å YAML ç¼©è¿›ç»“æ„ |



**å®æˆ˜æ€»ç»“**

```yaml
# æ¨è
{{- if .Values.enabled }}
spec:
  containers:
    - name: my-app
      {{- with .Values.image }}
      image: {{ .repository }}:{{ .tag }}
      imagePullPolicy: {{ .pullPolicy }}
      {{- end }}
{{- end }}
```

è¿™æ ·å¯ä»¥ä¿æŒç”Ÿæˆçš„ YAML **å¹²å‡€ã€æ— å¤šä½™ç©ºè¡Œã€ç¼©è¿›æ•´é½**ã€‚







##### å˜é‡

åœ¨ helm3 ä¸­ï¼Œå˜é‡é€šå¸¸æ˜¯æ­é… `with` è¯­å¥ å’Œ `range` è¯­å¥ä½¿ç”¨ï¼Œè¿™æ ·èƒ½æœ‰æ•ˆçš„ç®€åŒ–ä»£ç ã€‚

å˜é‡çš„å®šä¹‰æ ¼å¼å¦‚ä¸‹: 

```bash
$name :=  value
# :=  ä¸ºèµ‹å€¼è¿ç®—ç¬¦ï¼Œå°†åé¢å€¼èµ‹å€¼ç»™å‰é¢çš„å˜é‡ name
```

ä½¿ç”¨å˜é‡è§£å†³å¯¹è±¡ä½œç”¨åŸŸé—®é¢˜

å› ä¸ºwithè¯­å¥é‡Œä¸èƒ½è°ƒç”¨çˆ¶çº§åˆ«çš„å˜é‡ï¼Œæ‰€ä»¥å¦‚æœéœ€è¦è°ƒç”¨çˆ¶çº§åˆ«çš„å˜é‡ï¼Œéœ€è¦å£°æ˜ä¸€ä¸ªå˜é‡åï¼Œå°†çˆ¶çº§åˆ«çš„å˜é‡å€¼èµ‹å€¼ç»™å£°æ˜çš„å˜é‡

helmæµæ§åˆ¶ç»“æ„ä¸­ä½¿ç”¨with æ›´æ”¹å½“å‰ä½œç”¨åŸŸçš„ç”¨æ³•ï¼Œå½“æ—¶å­˜åœ¨ä¸€ä¸ªé—®é¢˜æ˜¯åœ¨with è¯­å¥ä¸­ï¼Œæ— æ³•ä½¿ç”¨çˆ¶ä½œç”¨åŸŸä¸­çš„å¯¹è±¡ï¼Œéœ€è¦ä½¿ç”¨$ç¬¦å·æˆ–è€…å°†è¯­å¥ç§»åˆ° `{{-end }}` çš„å¤–é¢æ‰å¯ä»¥ã€‚ç°åœ¨ä½¿ç”¨å˜é‡ä¹Ÿå¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

```yaml
# values.yaml
people:
  info:
    name: mystical
    age: 18
    sex: boy
    
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-configmap
  data:
    {{ - $releaseName := .Release.Name }}
    {{ - with .Values.people.info }}       # æŒ‡å®šä½œç”¨åŸŸ
    name: {{ .name }}
    age: {{ .age }}
    # release1: {{ .Release.Name }} # åœ¨withè¯­å¥å†…(å› ä¸ºæ”¹å˜äº†å˜é‡ä½œç”¨åŸŸ)ï¼Œä¸èƒ½è°ƒç”¨çˆ¶çº§åˆ«çš„å˜é‡,ä¸”ä¼šæŠ¥é”™
    release2: {{ $releaseName }}    # é€šè¿‡å˜é‡åè§£å†³è°ƒç”¨çˆ¶çº§åˆ«çš„å˜é‡
    release3: {{ - Release.Name }}  # åœ¨withè¯­å¥å¤–ï¼Œå¯ä»¥è°ƒç”¨çˆ¶çº§åˆ«çš„å˜é‡
```



**å˜é‡åœ¨åˆ—è¡¨æˆ–å…ƒç»„ä¸­çš„ä½¿ç”¨**

å˜é‡ä¹Ÿå¸¸ç”¨åœ¨éå†åˆ—è¡¨æˆ–å…ƒç»„ä¸­ï¼Œå¯ä»¥è·å–åˆ°ç´¢å¼•å’Œå€¼

```yaml
# values.yaml
address:
- beijing
- shanghai
- guangzhou

# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-configmap
  namespace: {{ .Release.Namespace }}
data:
  address: |-
    {{ - range $index,$add := .Values.address }}  # å°†éå†çš„åˆ—è¡¨å…ƒç´ èµ‹å€¼ç»™ä¸¤ä¸ªå˜é‡,ä¸€ä¸ªæ˜¯ç´¢å¼•å·ï¼Œä¸€ä¸ªæ˜¯å…ƒç´ å€¼,å¹¶ä¸”é€šè¿‡                                                     rangeè¯­å¥å¾ªç¯éå†å‡ºæ¥
    {{ $index }}:{{ $add }}
    {{ - end }}

# ç»“æœï¼š
address: |-
  0: beijing
  1: shanghai
  2: guangzhou
```

**å˜é‡åœ¨å­—å…¸ä¸­çš„ä½¿ç”¨**

å˜é‡ä¹Ÿèƒ½ç”¨äºå˜é‡å­—å…¸ï¼Œè·å–æ¯ä¸ªé”®å€¼å¯¹ `key/value`

å¯¹äºå­—å…¸ç±»å‹çš„ç»“æ„ï¼Œå¯ä»¥ä½¿ç”¨ range è·å–åˆ°æ¯ä¸ªé”®å€¼å¯¹çš„ `key` å’Œ `value`

æ³¨æ„ï¼Œå­—å…¸æ˜¯æ— åºçš„ï¼Œæ‰€ä»¥éå†å‡ºæ¥çš„ç»“æœä¹Ÿæ˜¯æ— åºçš„ã€‚

ç¤ºä¾‹ï¼š

```yaml
# values.yaml å®šä¹‰å˜é‡å’Œèµ‹å€¼
person:
  info:
    name: mystical
    sex: boy
    address: beijing
    age: 18
    
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-configmap
data:
  info: |-
    {{ - range $key, $value := .Values.person.info }}
    {{ $key }}:{{ $value }}
    {{ - end }}

# ç»“æœ
info: |-
  address: beijing
  age: 18
  name: mystical
  sex: boy
```



##### è°ƒç”¨å­æ¨¡ç‰ˆ

###### å®šä¹‰å¹¶è°ƒç”¨å­æ¨¡æ¿è¯´æ˜

å®šä¹‰å­æ¨¡æ¿çš„ä¸¤ä¸ªä½ç½®

- ä¸»æ¨¡æ¿ä¸­
- `helpers.tp`l æ–‡ä»¶å†…, `helpers.tpl` æ˜¯ä¸“é—¨æä¾›çš„å®šä¹‰å­æ¨¡æ¿çš„æ–‡ä»¶ï¼Œå®é™…ä½¿ç”¨ä¸­ï¼Œé€šå¸¸å»ºè®®æ”¾åœ¨  `helpers.tpl` æ–‡ä»¶å†…

å­æ¨¡æ¿çš„å®šä¹‰å’Œè°ƒç”¨

- å®šä¹‰å­æ¨¡æ¿: é€šè¿‡defineå®šä¹‰
- è°ƒç”¨å­æ¨¡æ¿: é€šè¿‡templateæˆ–è€…includeè°ƒç”¨(æ¨è),templateå’Œinclude ç”¨æ³•ä¸€æ ·ï¼Œç¨å¾®æœ‰ç‚¹åŒºåˆ« 



###### æ¼”ç¤ºæ¡ˆä¾‹

ä½¿ç”¨defineåœ¨ä¸»æ¨¡æ¿ä¸­å®šä¹‰å­æ¨¡æ¿çš„è¯­å¥å—ï¼Œä½¿ç”¨templateè¿›è¡Œè°ƒç”¨å­æ¨¡æ¿

æ³¨æ„: defineå®šä¹‰çš„å­æ¨¡æ¿ï¼Œéœ€è¦é€šè¿‡è°ƒç”¨æ‰èƒ½è¾“å‡ºï¼Œå¦‚æœä¸è°ƒç”¨æ˜¯ä¸ä¼šæœ‰è¾“å‡ºçš„ã€‚

```yaml
# æ ¼å¼ï¼š
{{ - define "mychart.labels" }}
  labels:
    author: mystical
    date: {{ now | htmlDate }}
{{ - end }}
```

ç¤ºä¾‹

```yaml
# ç¼–å†™ä¸€ä¸ªè‡ªå·±éœ€è¦çš„æ¨¡æ¿æ–‡ä»¶
# ./mychart/templates/configmap.yaml
{{ - define "mychart.labels" }}
  labels:
    author: mystical
    date: {{ now | htmlDate }}
{{ - end }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-configmap
  {{ - template "mychart.labels" }}
data:
  message: "hello"
  
# è¯´æ˜
# define å®šä¹‰ä¸€ä¸ªå­æ¨¡æ¿,å­æ¨¡æ¿çš„åç§°æ˜¯: mychart.labels
# template è°ƒç”¨å­æ¨¡æ¿,é€šè¿‡å­æ¨¡æ¿çš„åç§°è°ƒç”¨,è¾“å‡ºå­æ¨¡æ¿çš„å†…å®¹
```



##### æµæ§åˆ¶

```http
https://helm.sh/zh/docs/chart_template_guide/control_structures/
```

æ§åˆ¶ç»“æ„(åœ¨æ¨¡æ¿è¯­è¨€ä¸­ç§°ä¸º"actions")æä¾›ç»™ä½ å’Œæ¨¡æ¿ä½œè€…æ§åˆ¶æ¨¡æ¿è¿­ä»£æµçš„èƒ½åŠ›ã€‚ Helmçš„æ¨¡æ¿è¯­è¨€æä¾›äº†ä»¥ä¸‹æ§åˆ¶ç»“æ„ï¼š

- `if / else` ï¼Œ ç”¨æ¥åˆ›å»ºæ¡ä»¶è¯­å¥
- `with` ï¼Œ ä¸»è¦æ˜¯ç”¨æ¥æ§åˆ¶å˜é‡çš„èŒƒå›´ï¼Œä¹Ÿå°±æ˜¯ä¿®æ”¹æŸ¥æ‰¾å˜é‡çš„ä½œç”¨åŸŸ
- `range` ï¼Œ æä¾›"for each"ç±»å‹çš„å¾ªç¯



######  If/Else

ç¬¬ä¸€ä¸ªæ§åˆ¶ç»“æ„æ˜¯åœ¨æŒ‰ç…§æ¡ä»¶åœ¨ä¸€ä¸ªæ¨¡æ¿ä¸­åŒ…å«ä¸€ä¸ªå—æ–‡æœ¬ã€‚å³ `if/else`å—

åŸºæœ¬çš„æ¡ä»¶ç»“æ„çœ‹èµ·æ¥åƒè¿™æ ·ï¼š

```bash
{{ if PIPELINE }}
  # Do something
{{ else if OTHER PIPELINE }}
  # DO somehting
{{ else }}
  # Default case
{{ end }}
```

æ³¨æ„æˆ‘ä»¬è®¨è®ºçš„æ˜¯ PIPELINE è€Œä¸æ˜¯å€¼ã€‚è¿™æ ·åšçš„åŸå› æ˜¯è¦æ¸…æ¥šåœ°è¯´æ˜æ§åˆ¶ç»“æ„å¯ä»¥æ‰§è¡Œæ•´ä¸ªç®¡é“ï¼Œè€Œä¸ä»…ä»…æ˜¯è®¡ç®—ä¸€ä¸ªå€¼ã€‚

å¦‚æœæ˜¯ä»¥ä¸‹å€¼æ—¶ï¼ŒPIPELINEä¼šè¢«è®¾ç½®ä¸º false

- å¸ƒå°” false
- æ•°å­— 0
- ç©ºå­—ç¬¦ä¸²
- nil ( ç©º æˆ– null )
- ç©ºé›†åˆ( map ,  slice ,  tuple ,  dict ,  array )

åœ¨æ‰€æœ‰å…¶ä»–æ¡ä»¶ä¸‹ï¼Œæ¡ä»¶éƒ½ä¸ºtrueã€‚

è®©æˆ‘ä»¬å…ˆåœ¨é…ç½®æ˜ å°„ä¸­æ·»åŠ ä¸€ä¸ªç®€å•çš„æ¡ä»¶ã€‚å¦‚æœé¥®å“æ˜¯coffeeä¼šæ·»åŠ å¦ä¸€ä¸ªé…ç½®ï¼š

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-configmap
data:
  myvalue: "Hello World"
  drink: {{ .Values.favorite.drink | default "tea" | quote }}
  food: {{ .Values.favorite.food | upper | quote }}
  {{ if eq .Values.favorite.drink "coffee" }}mug: "true" {{ end }}
```

ç”±äºæˆ‘ä»¬åœ¨æœ€åä¸€ä¸ªä¾‹å­ä¸­æ³¨é‡Šäº† `drink: coffee` ï¼Œè¾“å‡ºä¸­å°±ä¸ä¼šåŒ…å« `mug: "true"` æ ‡è¯†ã€‚ä½†å¦‚æœå°† è¿™è¡Œæ·»åŠ åˆ° values.yaml æ–‡ä»¶ä¸­ï¼Œè¾“å…¥å°±ä¼šæ˜¯è¿™æ ·ï¼š

```yaml
# Source: mychart/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: eyewitness-elk-configmap
data:
  myvalue: "Hello World"
  drink: "coffee"
  food: "PIZZA"
  mug: "true"
```

èŒƒä¾‹

```yaml
# mychart/values.yaml #å®šä¹‰å˜é‡å’Œèµ‹å€¼
person:
  name: mystical
  age: 18
  sex: boy
  address: beijing
ingress:
  enabled: true
  
# ç¼–å†™ä¸€ä¸ªéœ€è¦çš„æ¨¡æ¿æ–‡ä»¶
#./mychart/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-configmap
  namespace: {{ .Release.Namespace }}
data:
  name: {{ .Values.person.name | default "mystical" | quote }}
  sex: {{ .Values.person.sex | upper quote }}
  {{- if .Value.ingress.enabled }}
  ingress: "é…ç½®ingress..."    # è‹¥ingresså¼€å…³å¼€å¯,åšingressç›¸å…³é…ç½®
  {{- else }}
  ingress: "ä¸é…ç½®ingress..."  #å¦åˆ™ingresså¼€å…³æ²¡å¼€å¯,ä¸é…ç½®ingress
  {{- end }}
  {{- if eq .Values.person.address "beijing" }}
  address: {{ .Values.person.address | quote }}
  {{- else }}
  address: "other city"
  {{- end }}
  
# æ³¨æ„:æ‰§è¡ŒæŠ¥é”™æ—¶å€™ï¼Œå»æ‰ä¸‹é¢æ³¨é‡Š
# {{- }} è¡¨ç¤ºå‘å·¦åˆ é™¤ç©ºç™½åŒ…æ‹¬åˆ é™¤ç©ºæ ¼å’Œæ¢è¡Œ,ä¸åŠ å¯èƒ½ä¼šå¢åŠ ä¸€ä¸ªæ¢è¡Œ,å‰é¢åŠ æ¨ªçº¿æ˜¯ä¸ºäº†å»æ‰è¯¥è¡Œçš„ç©ºæ ¼,å¦‚æœä¸åŠ ,è¯¥è¡Œæ¸²æŸ“æ—¶ä¼šå½¢æˆç©ºæ ¼
# {{ -}} è¡¨ç¤ºå‘å³åˆ é™¤ç©ºç™½,å¹¶ä¸”ä¼šåˆ é™¤æ¢è¡Œ,ä¸€èˆ¬æ…ç”¨,å› ä¸ºåˆ é™¤æ¢è¡Œæ—¶å€™ï¼Œæ‰“å°å†…å®¹å°±ä¹±äº†,è¿˜å¯èƒ½è¯­æ³•æŠ¥é”™
```





#### æ¡ˆä¾‹ï¼šè‡ªå®šä¹‰ Chart å®ç°éƒ¨ç½²å‡çº§å›æ»šç‰ˆæœ¬ç®¡ç†

##### å›ºå®šé…ç½®çš„ Chart

```bash
[root@master1 helm]# helm create myapp-chart
Creating myapp-chart

[root@master1 helm]# tree myapp-chart/
myapp-chart/
â”œâ”€â”€ charts
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ templates
â”‚Â Â  â”œâ”€â”€ deployment.yaml
â”‚Â Â  â”œâ”€â”€ _helpers.tpl
â”‚Â Â  â”œâ”€â”€ hpa.yaml
â”‚Â Â  â”œâ”€â”€ ingress.yaml
â”‚Â Â  â”œâ”€â”€ NOTES.txt
â”‚Â Â  â”œâ”€â”€ serviceaccount.yaml
â”‚Â Â  â”œâ”€â”€ service.yaml
â”‚Â Â  â””â”€â”€ tests
â”‚Â Â      â””â”€â”€ test-connection.yaml
â””â”€â”€ values.yaml

3 directories, 10 files

# åˆ é™¤ä¸éœ€è¦çš„æ–‡ä»¶
[root@master1 helm]# rm -rf myapp-chart/templates/* myapp-chart/values.yaml myapp-chart/charts/
[root@master1 helm]# tree .
.
â””â”€â”€ myapp-chart
    â”œâ”€â”€ Chart.yaml
    â””â”€â”€ templates

2 directories, 1 file

# ç”Ÿæˆç›¸å…³çš„èµ„æºæ¸…å•æ–‡ä»¶
[root@master1 helm]# kubectl create deployment myapp --image registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1 --replicas 3 --dry-run=client -o yaml > myapp-chart/templates/myapp-deployment.yaml
[root@master1 helm]# kubectl create service nodeport myapp --tcp 80:80 --dry-run=client -o yaml > myapp-chart/templates/myapp-service.yaml
[root@master1 helm]# tree myapp-chart/
myapp-chart/
â”œâ”€â”€ Chart.yaml
â””â”€â”€ templates
    â”œâ”€â”€ myapp-deployment.yaml
    â””â”€â”€ myapp-service.yaml

1 directory, 3 files

# ä¿®æ”¹æ¸…å•æ–‡ä»¶
[root@master1 helm]#vim myapp-chart/templates/myapp-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myapp
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
        name: pod-test

[root@master1 helm]# vim myapp-chart/templates/myapp-service.yaml 
apiVersion: v1
kind: Service
metadata:
  labels:
    app: myapp
  name: myapp
spec:
  ports:
  - name: 80-80
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: myapp
  type: NodePort

# ä¿®æ”¹é…ç½®
[root@master1 helm]# vim myapp-chart/Chart.yaml
apiVersion: v2
name: myapp-chart
description: A Helm chart for Kubernetes
type: application
version: 0.0.1
appVersion: "0.1.0"

# æ£€æŸ¥è¯­æ³•
[root@master1 helm]#helm lint myapp-chart/
==> Linting myapp-chart/
[INFO] Chart.yaml: icon is recommended
[INFO] values.yaml: file does not exist

1 chart(s) linted, 0 chart(s) failed

# éƒ¨ç½²åº”ç”¨
[root@master1 helm]#helm install myapp ./myapp-chart/ --create-namespace --namespace helmdemo
NAME: myapp
LAST DEPLOYED: Wed Mar 26 13:44:00 2025
NAMESPACE: helmdemo
STATUS: deployed
REVISION: 1
TEST SUITE: None

[root@master1 helm]#kubectl get pod -n helmdemo 
NAME                     READY   STATUS    RESTARTS   AGE
myapp-547df679bb-cj4hh   1/1     Running   0          10s
myapp-547df679bb-nz52d   1/1     Running   0          10s
myapp-547df679bb-z6978   1/1     Running   0          10s

[root@master1 helm]#kubectl get svc -n helmdemo 
NAME    TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
myapp   NodePort   10.105.237.73   <none>        80:30503/TCP   20s

# æŸ¥çœ‹
[root@master1 helm]#helm list -n helmdemo 
NAME 	NAMESPACE	REVISION	UPDATED                                	STATUS    CHART            	APP VERSION
myapp	helmdemo 	1       	2025-03-26 13:44:00.261990749 +0800 CST	deployed  myapp-chart-0.0.1	0.1.0

# å¸è½½
[root@master1 helm]#helm uninstall -n helmdemo myapp 
release "myapp" uninstalled

[root@master1 helm]#kubectl get pod -n helmdemo 
NAME                     READY   STATUS        RESTARTS   AGE
myapp-547df679bb-cj4hh   1/1     Terminating   0          5m17s
myapp-547df679bb-nz52d   1/1     Terminating   0          5m17s
myapp-547df679bb-z6978   1/1     Terminating   0          5m17s

# å°†ç›®å½•æ‰“åŒ…è‡³æ–‡ä»¶
[root@master1 ~]# helm package ./myapp-chart/
Successfully packaged chart and saved it to: /root/myapp-chart-0.1.0.tgz
[root@master1 helm]#ll myapp-chart-0.0.1.tgz 
-rw-r--r-- 1 root root 774  3æœˆ 26 14:10 myapp-chart-0.0.1.tgz
```



##### å¯å˜é…ç½®çš„ Chart

```bash
[root@master1 helm]#helm create myweb-chart
Creating myweb-chart
[root@master1 helm]#tree myweb-chart/
myweb-chart/
â”œâ”€â”€ charts
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ templates
â”‚Â Â  â”œâ”€â”€ deployment.yaml
â”‚Â Â  â”œâ”€â”€ _helpers.tpl
â”‚Â Â  â”œâ”€â”€ hpa.yaml
â”‚Â Â  â”œâ”€â”€ ingress.yaml
â”‚Â Â  â”œâ”€â”€ NOTES.txt
â”‚Â Â  â”œâ”€â”€ serviceaccount.yaml
â”‚Â Â  â”œâ”€â”€ service.yaml
â”‚Â Â  â””â”€â”€ tests
â”‚Â Â      â””â”€â”€ test-connection.yaml
â””â”€â”€ values.yaml

3 directories, 10 files

# åˆ é™¤å¤šä½™çš„æ–‡ä»¶
[root@master1 helm]#rm -rf myweb-chart/templates/*
[root@master1 helm]#tree myweb-chart/
myweb-chart/
â”œâ”€â”€ charts
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ templates
â””â”€â”€ values.yaml

2 directories, 2 files

# åˆ›å»ºèµ„æºæ¸…å•æ–‡ä»¶
[root@master1 helm]##kubectl create deployment myweb --image nginx:1.22.0 --replicas=3 --dry-run=client -o yaml > myweb-chart/templates/myweb-deployment.yaml

[root@master1 helm]#kubectl create service nodeport myweb --tcp 80:80  --dry-run=client -o yaml > myweb-chart/templates/myweb-service.yaml

# ä¿®æ”¹æ¸…å•æ–‡ä»¶ä¸ºåŠ¨æ€æ¨¡ç‰ˆæ–‡ä»¶
[root@master1 helm]#vim myweb-chart/templates/myweb-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.deployment_name }}
  #namespace: {{ .Values.namespace }} 
  namespace: {{ .Release.Namespace }}
spec:
  replicas: {{ .Values.replicas }}
  selector:
    matchLabels:
      app: {{ .Values.pod_label }}
  template:
    metadata:
      labels:
        app: {{ .Values.pod_label }}
    spec:
      containers:
      - image: {{ .Values.image }}:{{ .Values.imageTag }}
        name: {{ .Values.container_name }}
        ports:
        - containerPort: {{ .Values.containerport }}
        
[root@master1 helm]#vim myweb-chart/templates/myweb-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ .Values.service_name }}
  namespace: {{ .Release.Namespace }}
spec:
  ports:
  - port: {{ .Values.port }}
    protocol: TCP
    targetPort: {{ .Values.targetport }}
  selector:
    app: {{ .Values.pod_label }}
  type: NodePort
  
# ç¼–è¾‘values.yamlæ–‡ä»¶
[root@master1 helm]#vim myweb-chart/values.yaml
#namespace: default
deployment_name: myweb-deployment
replicas: 3
pod_label: myweb-pod-label
image: registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test
imageTag: v0.1
container_name: myweb-container
service_name: myweb-service
port: 80targetport: 80
containerport: 80

# æŸ¥çœ‹Chart.yaml
[root@master1 helm]#grep -v "#" myweb-chart/Chart.yaml
apiVersion: v2
name: myweb-chart
description: A Helm chart for Kubernetes

type: application

version: 0.1.0

appVersion: "1.16.0"

[root@master1 helm]#tree myweb-chart/
myweb-chart/
â”œâ”€â”€ charts
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ templates
â”‚Â Â  â”œâ”€â”€ myweb-deployment.yaml
â”‚Â Â  â””â”€â”€ myweb-service.yaml
â””â”€â”€ values.yaml

2 directories, 4 files

[root@master1 helm]#helm install myweb ./myweb-chart/ --create-namespace --namespace helmdemo
NAME: myweb
LAST DEPLOYED: Wed Mar 26 16:27:23 2025
NAMESPACE: helmdemo
STATUS: deployed
REVISION: 1
TEST SUITE: None

# æŸ¥çœ‹
[root@master1 helm]# kubectl get pod -n helmdemo 
NAME                                READY   STATUS    RESTARTS   AGE
myweb-deployment-745dc5b6c5-2zgn5   1/1     Running   0          16s
myweb-deployment-745dc5b6c5-rmgx5   1/1     Running   0          16s
myweb-deployment-745dc5b6c5-z5js4   1/1     Running   0          16s

[root@master1 helm]# kubectl get svc -n helmdemo 
NAME            TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
myweb-service   NodePort   10.105.117.141   <none>        80:30814/TCP   32s

#æ‰“åŒ…
[root@master1 helm]#helm package ./myweb-chart/
Successfully packaged chart and saved it to: /root/helm/myweb-chart-0.1.0.tgz
```





##### ä¸Šä¼ è‡³harbor

ä» **Harbor v2.2 èµ·ï¼ˆå°¤å…¶æ˜¯ v2.5+ï¼‰**ï¼Œå®˜æ–¹æ¨è **å…¨é¢ä½¿ç”¨ OCIï¼ˆOpen Container Initiativeï¼‰æ ‡å‡†** æ¥ç®¡ç† Helm Chartsï¼Œè€Œä¸å†æ¨èä½¿ç”¨è€æ—§çš„ **ChartMuseum æ’ä»¶**ã€‚

**ChartMuseum åœ¨æ–°ç‰ˆ Harbor çš„ç°çŠ¶**

| é¡¹ç›®        | è¯´æ˜                                                         |
| ----------- | ------------------------------------------------------------ |
| ChartMuseum | å·²ä» Harbor é»˜è®¤ç»„ä»¶ä¸­ç§»é™¤ï¼ˆä½†ä»æ”¯æŒé€šè¿‡ Helm è‡ªå®šä¹‰å¯ç”¨ï¼‰   |
| æ”¯æŒæƒ…å†µ    | ä»æ”¯æŒå…¼å®¹ï¼Œä½†ä¸æ¨èæ–°é¡¹ç›®å†ä½¿ç”¨ ChartMuseum                 |
| åŸå›         | ChartMuseum æ˜¯è€å¼é OCI åè®®çš„ä»“åº“ï¼ŒåŠŸèƒ½æœ‰é™ã€å®‰å…¨æ€§å¼±      |
| å®˜æ–¹å»ºè®®    | ä½¿ç”¨ Harbor æœ¬èº«ä½œä¸º **OCI Helm Chart ä»“åº“**ï¼Œæ›´ç®€æ´ã€æ›´æ ‡å‡†ã€æ›´å®‰å…¨ |

```bash
# ä½¿ç”¨ OCIåè®®ä¸Šä¼ helmåŒ…
# Helm çš„ OCI æ¨¡å¼ å¼ºåˆ¶è¦æ±‚ä½¿ç”¨ HTTPS åè®®ï¼Œä¸æ”¯æŒ HTTPï¼
# å‰ç½®è¦æ±‚ï¼Œå¯¼å‡ºharborçš„è‡ªç­¾CAè¯ä¹¦ï¼Œå¹¶å°†å…¶åŠ å…¥ä¿¡ä»»é“¾ï¼ŒåŒæ—¶æ”¾å…¥helmçš„ä¿¡ä»»è·¯å¾„

# å¯¼å‡ºè‡ªç­¾è¯ä¹¦
[root@master1 helm]# kubectl get secret myharbor-ingress -n harbor -o jsonpath="{.data['tls\.crt']}"|base64 -d > harbor-ca.crt

# ç„¶åå°†å…¶æ”¾å…¥ Helm ä½¿ç”¨çš„ç›®å½•ï¼š
[root@master1 helm]# mkdir -p ~/.config/helm/registry/certs
[root@master1 helm]# cp harbor-ca.crt ~/.config/helm/registry/certs/harbor.mystical.org.crt

# ã€é‡ç‚¹ã€‘è¿˜è¦æŠŠ CA è¯ä¹¦åŠ å…¥åˆ° ç³»ç»Ÿä¿¡ä»»é“¾ä¸­
# è™½ç„¶ Helm æ”¯æŒæœ¬åœ° certs/ï¼Œä½†æŸäº›ç‰ˆæœ¬ï¼ˆå°¤å…¶è€ç‰ˆæœ¬æˆ– go æ¨¡å—ç¼–è¯‘æ—¶æœªå¯ç”¨è‡ªå®šä¹‰ CA è·¯å¾„ï¼‰è¿˜æ˜¯ä¼šä¾èµ–ç³»ç»Ÿ CAã€‚

# æ‹·è´è¯ä¹¦åˆ°ç³»ç»Ÿä¿¡ä»»ç›®å½•
[root@master1 helm]# cp harbor.mystical.org.crt /etc/pki/ca-trust/source/anchors/

# æˆ–è€…å¯¹äº Debian/Ubuntu ç³»ç»Ÿ
[root@master1 helm]#  cp harbor.mystical.org.crt /usr/local/share/ca-certificates/harbor.crt

# æ›´æ–°ä¿¡ä»»é“¾
[root@master1 helm]# update-ca-trust extract
# Ubuntu ç”¨è¿™ä¸ªï¼š
[root@master1 helm]# update-ca-certificates

# é‡å¯shellï¼Œå†é‡æ–°ç™»é™†
[root@master1 ~]#helm registry login harbor.mystical.org
Username: admin
Password: 
Login Succeeded

# å°†æ‰“å¥½çš„åŒ…ä¸Šä¼ è‡³harbor
[root@master1 helm]#helm push myapp-chart-0.0.1.tgz oci://harbor.mystical.org/myhelm
Pushed: harbor.mystical.org/myhelm/myapp-chart:0.0.1
Digest: sha256:02d3f2b5ecdb89369284d8fdb34813a9a6e7bab910e98c36febc78c478bd86e4

# å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ Helm çš„æ³¨å†Œè¡¨ç™»å½•ä¿¡æ¯
[root@master1 helm]#cat ~/.config/helm/registry/config.json 
{
	"auths": {
		"harbor.mystical.org": {
			"auth": "YWRtaW46MTIzNDU2"
		}
	}
}

# auth å­—æ®µæ˜¯ Base64 ç¼–ç çš„ username:passwordã€‚
[root@master1 helm]#echo "YWRtaW46MTIzNDU2" |base64 -d
admin:123456
```

![image-20250326154011722](../markdown_img/image-20250326154011722.png)





## Kubernetesç½‘ç»œå‰–æ

åœ¨Dockeræ¨¡å—çš„**`æµ…è°ˆå®¹å™¨ç½‘ç»œ`**ä¸­ï¼Œä»‹ç»äº†å®¿ä¸»æœºä¸­çš„å®¹å™¨é—´é€šä¿¡æ˜¯é€šè¿‡docker0ä½œä¸ºç½‘æ¡¥ï¼Œå°†å®¿ä¸»æœºå†…çš„å®¹å™¨éƒ½è¿åœ¨è¿™ä¸ªç½‘æ¡¥ä¸Šã€‚

é‚£ä¹ˆKubernetesä¸­ï¼Œä¸åŒèŠ‚ç‚¹é—´çš„å®¹å™¨è¿›è¡Œé€šä¿¡ï¼Œæ˜¯ä¸æ˜¯å¯ä»¥**é€šè¿‡è½¯ä»¶çš„æ–¹å¼ï¼Œåˆ›å»ºä¸€ä¸ªæ•´ä¸ªé›†ç¾¤â€œå…¬ç”¨â€çš„ç½‘æ¡¥ï¼Œç„¶åæŠŠé›†ç¾¤é‡Œçš„æ‰€æœ‰å®¹å™¨éƒ½è¿æ¥åˆ°è¿™ä¸ªç½‘æ¡¥ä¸Šï¼Œä¸å°±å¯ä»¥ç›¸äº’é€šä¿¡äº†å—?**

è¿™æ ·ä¸€æ¥ï¼Œæˆ‘ä»¬æ•´ä¸ªé›†ç¾¤é‡Œçš„å®¹å™¨ç½‘ç»œå°±ä¼šç±»ä¼¼äºä¸‹å›¾æ‰€ç¤ºçš„æ ·å­ï¼š

![image-20250116155827857](../markdown_img/image-20250116155827857.png)

å¯ä»¥çœ‹åˆ°ï¼Œæ„å»ºè¿™ç§å®¹å™¨ç½‘ç»œçš„æ ¸å¿ƒåœ¨äºï¼šæˆ‘ä»¬éœ€è¦åœ¨å·²æœ‰çš„å®¿ä¸»æœºç½‘ç»œä¸Šï¼Œå†**é€šè¿‡è½¯ä»¶æ„å»ºä¸€ä¸ªè¦†ç›–åœ¨å·²æœ‰å®¿ä¸»æœºç½‘ç»œä¹‹ä¸Šçš„ã€å¯ä»¥æŠŠæ‰€æœ‰å®¹å™¨è¿é€šåœ¨ä¸€èµ·çš„è™šæ‹Ÿç½‘ç»œ**ã€‚æ‰€ä»¥ï¼Œè¿™ç§æŠ€æœ¯å°±è¢«ç§°ä¸ºï¼š**Overlay Networkï¼ˆè¦†ç›–ç½‘ç»œï¼‰**ã€‚





### æ·±å…¥äº†è§£å®¹å™¨è·¨ä¸»æœºç½‘ç»œ



#### Flannelæ¦‚è¿°

Flannel é¡¹ç›®æ˜¯ CoreOS å…¬å¸ä¸»æ¨çš„å®¹å™¨ç½‘ç»œæ–¹æ¡ˆã€‚äº‹å®ä¸Šï¼ŒFlannel é¡¹ç›®æœ¬èº«åªæ˜¯ä¸€ä¸ªæ¡†æ¶ï¼ŒçœŸæ­£ä¸ºæˆ‘ä»¬æä¾›å®¹å™¨ç½‘ç»œåŠŸèƒ½çš„ï¼Œæ˜¯ Flannel çš„åç«¯å®ç°ã€‚ç›®å‰ï¼ŒFlannel æ”¯æŒä¸‰ç§åç«¯å®ç°ï¼Œåˆ†åˆ«æ˜¯ï¼š

- **VXLAN**
- **host-gw**
- **UDP**



è¿™ä¸‰ç§ä¸åŒçš„åç«¯å®ç°ï¼Œæ­£ä»£è¡¨äº†ä¸‰ç§å®¹å™¨è·¨ä¸»ç½‘ç»œçš„ä¸»æµå®ç°æ–¹æ³•



##### UDPæ¨¡å¼çš„è·¨ä¸»ç½‘ç»œå®ç°åŸç†ï¼ˆå·²åºŸå¼ƒï¼‰

å‡è®¾æœ‰ä¸¤å°å®¿ä¸»æœº

- å®¿ä¸»æœº Node 1 ä¸Šæœ‰ä¸€ä¸ªå®¹å™¨ container-1ï¼Œå®ƒçš„ IP åœ°å€æ˜¯ 10.244.2.20ï¼Œå¯¹åº”çš„ docker0 ç½‘æ¡¥çš„åœ°å€æ˜¯ï¼š172.17.0.1/16
- å®¿ä¸»æœº Node 2 ä¸Šæœ‰ä¸€ä¸ªå®¹å™¨ container-2ï¼Œå®ƒçš„ IP åœ°å€æ˜¯ 10.244.3.27ï¼Œå¯¹åº”çš„ docker0 ç½‘æ¡¥çš„åœ°å€æ˜¯ï¼š172.17.0.1/16



**è®© container-1 è®¿é—® container-2**



container-1 å®¹å™¨é‡Œçš„è¿›ç¨‹å‘èµ·çš„ IP åŒ…ï¼Œå…¶æºåœ°å€å°±æ˜¯ 10.244.2.20ï¼Œç›®çš„åœ°å€å°±æ˜¯ 10.244.3.27ã€‚ç”±äºç›®çš„åœ°å€ 10.244.3.27 å¹¶ä¸åœ¨ Node 1 çš„ docker0 ç½‘æ¡¥çš„ç½‘æ®µé‡Œï¼Œæ‰€ä»¥è¿™ä¸ª IP åŒ…ä¼šè¢«äº¤ç»™é»˜è®¤è·¯ç”±è§„åˆ™ï¼Œé€šè¿‡å®¹å™¨çš„ç½‘å…³è¿›å…¥ docker0 ç½‘æ¡¥ï¼ˆå¦‚æœæ˜¯åŒä¸€å°å®¿ä¸»æœºä¸Šçš„å®¹å™¨é—´é€šä¿¡ï¼Œèµ°çš„æ˜¯ç›´è¿è§„åˆ™ï¼‰ï¼Œä»è€Œå‡ºç°åœ¨å®¿ä¸»æœºä¸Šã€‚



è¿™æ—¶å€™ï¼Œè¿™ä¸ª IP åŒ…çš„ä¸‹ä¸€ä¸ªç›®çš„åœ°ï¼Œå°±å–å†³äºå®¿ä¸»æœºä¸Šçš„è·¯ç”±è§„åˆ™äº†ã€‚æ­¤æ—¶ï¼ŒFlannel å·²ç»åœ¨å®¿ä¸»æœºä¸Šåˆ›å»ºå‡ºäº†ä¸€ç³»åˆ—çš„è·¯ç”±è§„åˆ™ï¼Œä»¥ Node 1 ä¸ºä¾‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
[root@node1 ~]# route -n
å†…æ ¸ IP è·¯ç”±è¡¨
ç›®æ ‡            ç½‘å…³            å­ç½‘æ©ç         æ ‡å¿—  è·ƒç‚¹   å¼•ç”¨  ä½¿ç”¨ æ¥å£
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
10.244.0.0      10.244.0.0      255.255.255.0   UG    0      0        0 flannel.1 # å‘½ä¸­ï¼Œå¹¶è¿›å…¥flannel1.1è®¾å¤‡
10.244.1.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0
10.244.2.0      10.244.2.0      255.255.255.0   UG    0      0        0 flannel.1
10.244.3.0      10.244.3.0      255.255.255.0   UG    0      0        0 flannel.1   
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
```

ç”±äºæˆ‘ä»¬çš„ IP åŒ…çš„ç›®çš„åœ°å€æ˜¯10.244.3.27ï¼Œå®ƒåŒ¹é…ä¸åˆ°æœ¬æœº docker0 ç½‘æ¡¥å¯¹åº”çš„ 172.17.0.1/16 ç½‘æ®µï¼Œåªèƒ½åŒ¹é…åˆ°ç¬¬ä¸‰æ¡ã€ä¹Ÿå°±æ˜¯ 10.244.0.0/16 å¯¹åº”çš„è¿™æ¡è·¯ç”±è§„åˆ™ï¼Œä»è€Œè¿›å…¥åˆ°ä¸€ä¸ªå«ä½œ flannel1.1 çš„è®¾å¤‡ä¸­ã€‚



 **flannel1.1 è®¾å¤‡æ˜¯ä¸€ä¸ªTUNè®¾å¤‡ï¼ˆTunnel è®¾å¤‡ï¼‰ã€‚**

```ABAP
åœ¨ Linux ä¸­ï¼ŒTUN è®¾å¤‡æ˜¯ä¸€ç§å·¥ä½œåœ¨ä¸‰å±‚ï¼ˆNetwork Layerï¼‰çš„è™šæ‹Ÿç½‘ç»œè®¾å¤‡ã€‚TUN è®¾å¤‡çš„åŠŸèƒ½éå¸¸ç®€å•ï¼Œå³ï¼šåœ¨æ“ä½œç³»ç»Ÿå†…æ ¸å’Œç”¨æˆ·åº”ç”¨ç¨‹åºä¹‹é—´ä¼ é€’ IP åŒ…ã€‚
```



å½“æ“ä½œç³»ç»Ÿå°†ä¸€ä¸ª IP åŒ…å‘é€ç»™ flannel0 è®¾å¤‡ä¹‹åï¼Œflannel0 å°±ä¼šæŠŠè¿™ä¸ª IP åŒ…ï¼Œäº¤ç»™åˆ›å»ºè¿™ä¸ªè®¾å¤‡çš„åº”ç”¨ç¨‹åºï¼Œä¹Ÿå°±æ˜¯ Flannel è¿›ç¨‹ã€‚è¿™æ˜¯ä¸€ä¸ªä»å†…æ ¸æ€ï¼ˆLinux æ“ä½œç³»ç»Ÿï¼‰å‘ç”¨æˆ·æ€ï¼ˆFlannel è¿›ç¨‹ï¼‰çš„æµåŠ¨æ–¹å‘ã€‚

```ABAP
Container1-eth0 ---> æ ¹æ®è·¯ç”± ---> flannel1.1 ---> flanneldè¿›ç¨‹å¤„ç†
```



åä¹‹ï¼Œå¦‚æœ Flannel è¿›ç¨‹å‘ flannel0 è®¾å¤‡å‘é€äº†ä¸€ä¸ª IP åŒ…ï¼Œé‚£ä¹ˆè¿™ä¸ª IP åŒ…å°±ä¼šå‡ºç°åœ¨å®¿ä¸»æœºç½‘ç»œæ ˆä¸­ï¼Œç„¶åæ ¹æ®å®¿ä¸»æœºçš„è·¯ç”±è¡¨è¿›è¡Œä¸‹ä¸€æ­¥å¤„ç†ã€‚è¿™æ˜¯ä¸€ä¸ªä»ç”¨æˆ·æ€å‘å†…æ ¸æ€çš„æµåŠ¨æ–¹å‘ã€‚

å½“ IP åŒ…ä»å®¹å™¨ç»è¿‡ docker0 å‡ºç°åœ¨å®¿ä¸»æœºï¼Œç„¶ååˆæ ¹æ®è·¯ç”±è¡¨è¿›å…¥ flannel0 è®¾å¤‡åï¼Œå®¿ä¸»æœºä¸Šçš„ flanneld è¿›ç¨‹ï¼ˆFlannel é¡¹ç›®åœ¨æ¯ä¸ªå®¿ä¸»æœºä¸Šçš„ä¸»è¿›ç¨‹ï¼‰ï¼Œå°±ä¼šæ”¶åˆ°è¿™ä¸ª IP åŒ…ã€‚ç„¶åï¼Œflanneld çœ‹åˆ°äº†è¿™ä¸ª IP åŒ…çš„ç›®çš„åœ°å€ï¼Œæ˜¯ 10.244.3.27ï¼Œå°±æŠŠå®ƒå‘é€ç»™äº† Node 2 å®¿ä¸»æœºã€‚



**flanneld åˆæ˜¯å¦‚ä½•çŸ¥é“è¿™ä¸ª IP åœ°å€å¯¹åº”çš„å®¹å™¨ï¼Œæ˜¯è¿è¡Œåœ¨ Node 2 ä¸Šçš„å‘¢ï¼Ÿ**



 Flannel é¡¹ç›®é‡Œä¸€ä¸ªéå¸¸é‡è¦çš„æ¦‚å¿µï¼šå­ç½‘ï¼ˆSubnetï¼‰ã€‚

äº‹å®ä¸Šï¼Œåœ¨ç”± Flannel ç®¡ç†çš„å®¹å™¨ç½‘ç»œé‡Œï¼Œä¸€å°å®¿ä¸»æœºä¸Šçš„æ‰€æœ‰å®¹å™¨ï¼Œéƒ½å±äºè¯¥å®¿ä¸»æœºè¢«åˆ†é…çš„ä¸€ä¸ªâ€œå­ç½‘â€ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼ŒNode 1 çš„å­ç½‘æ˜¯ 100.96.1.0/24ï¼Œcontainer-1 çš„ IP åœ°å€æ˜¯ 100.96.1.2ã€‚Node 2 çš„å­ç½‘æ˜¯ 100.96.2.0/24ï¼Œcontainer-2 çš„ IP åœ°å€æ˜¯ 100.96.2.3ã€‚

è€Œè¿™äº›å­ç½‘ä¸å®¿ä¸»æœºçš„å¯¹åº”å…³ç³»ï¼Œæ­£æ˜¯ä¿å­˜åœ¨ Etcd å½“ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
$ etcdctl ls /coreos.com/network/subnets
/coreos.com/network/subnets/100.96.1.0-24
/coreos.com/network/subnets/100.96.2.0-24
/coreos.com/network/subnets/100.96.3.0-24
```



**æ³¨æ„ï¼š****å¦‚æœ `--kube-subnet-mgr` å‚æ•°å­˜åœ¨**ï¼Œè¯´æ˜ Flannel ä½¿ç”¨ Kubernetes API è€Œé etcd å­˜å‚¨æ•°æ®ã€‚

```bash
[root@master1 net.d]#kubectl -n kube-flannel describe daemonsets.apps kube-flannel-ds |grep -P "\-\-kube-subnet-mgr"
      --kube-subnet-mgr  # è¯´æ˜Flannelä½¿ç”¨çš„Kubernetes API

```



åœ¨Kubernetes APIæ¨¡å¼ä¸‹ï¼ŒFlannelçš„å­ç½‘åˆ†é…ä¿¡æ¯å­˜å‚¨åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„Annotationä¸­ï¼Œå¯ä»¥é€šè¿‡ä¸€ä¸‹å‘½ä»¤æŸ¥çœ‹

```bash
[root@master1 ~]#kubectl get nodes -o json | jq '.items[] | {name: .metadata.name, podCIDR: .spec.podCIDR, flannelSubnet: .metadata.annotations["flannel.alpha.coreos.com/subnet"]}'
{
  "name": "master1",
  "podCIDR": "10.244.0.0/24",
  "flannelSubnet": null
}
{
  "name": "node1",
  "podCIDR": "10.244.1.0/24",
  "flannelSubnet": null
}
{
  "name": "node2",
  "podCIDR": "10.244.2.0/24",
  "flannelSubnet": null
}
{
  "name": "node3",
  "podCIDR": "10.244.3.0/24",
  "flannelSubnet": null
}
```



æ‰€ä»¥ï¼Œflanneld è¿›ç¨‹åœ¨å¤„ç†ç”± flannel0 ä¼ å…¥çš„ IP åŒ…æ—¶ï¼Œå°±å¯ä»¥æ ¹æ®ç›®çš„ IP çš„åœ°å€ï¼ˆæ¯”å¦‚ 100.96.2.3ï¼‰ï¼ŒåŒ¹é…åˆ°å¯¹åº”çš„å­ç½‘ï¼ˆæ¯”å¦‚ 100.96.2.0/24ï¼‰ï¼Œä» Etcd ä¸­æ‰¾åˆ°è¿™ä¸ªå­ç½‘å¯¹åº”çš„å®¿ä¸»æœºçš„ IP åœ°å€



**å½“container-1å‘èµ·å¯¹container-2çš„è®¿é—®è¯·æ±‚æ—¶ï¼Œæ•°æ®åŒ…çš„é€šä¿¡è¿‡ç¨‹å¦‚ä¸‹**

- container-1å‘å‡ºä¸€ä¸ªIPåŒ…ï¼Œæºåœ°å€ä¸º`10.244.2.20`ï¼Œç›®çš„åœ°å€ä¸º`10.244.3.27`
- è¿™ä¸ªIPåŒ…é¦–å…ˆåˆ°è¾¾Node 1çš„docker0ç½‘æ¡¥**ï¼ˆè¿™é‡Œè¿›è¡Œä¸€æ¬¡åˆ¤æ–­ï¼‰**ã€‚ç”±äºç›®çš„åœ°å€`10.244.3.37`ä¸åœ¨docker0ç½‘æ¡¥çš„ç½‘æ®µå†…ï¼Œæ‰€ä»¥è¿™ä¸ªIPåŒ…ä¼šè¢«è½¬å‘ç»™é»˜è®¤è·¯ç”±**ã€‚(åº”ç”¨è¿›ç¨‹å‘å‡ºæ•°æ®åŒ…ç»™åˆ°ç½‘æ¡¥è®¾å¤‡ï¼Œæ­¤æ—¶è¿›è¡Œç¬¬ä¸€æ¬¡ç”¨æˆ·æ€å’Œå†…æ ¸æ€çš„åˆ‡æ¢)**
- æ ¹æ®Node 1ä¸Šçš„è·¯ç”±è§„åˆ™ï¼Œè¿™ä¸ªIPåŒ…ä¼šè¢«é€å¾€ä¸€ä¸ªåä¸ºflannel0çš„è®¾å¤‡ã€‚flannel0æ˜¯ä¸€ä¸ªTUNè®¾å¤‡ï¼Œå®ƒåœ¨ä¸‰å±‚ç½‘ç»œä¸Šå·¥ä½œã€‚
- flannel0è®¾å¤‡ä¼šå°†è¿™ä¸ªIPåŒ…äº¤ç»™ç”¨æˆ·æ€çš„flanneldè¿›ç¨‹å¤„ç†ã€‚**(æ­¤æ—¶è¿›è¡Œç¬¬äºŒæ¬¡ç”¨æˆ·æ€å’Œå†…æ ¸æ€çš„åˆ‡æ¢)**
- flanneldè¿›ç¨‹é€šè¿‡æŸ¥è¯¢Etcdï¼ˆæˆ–è€…**Kubernetes API**ï¼‰ï¼Œå¾—çŸ¥ç›®çš„IPåœ°å€10.244.3.27æ‰€åœ¨çš„å­ç½‘å¯¹åº”çš„å®¿ä¸»æœºæ˜¯Node 2ï¼Œå…¶IPåœ°å€ä¸º`10.0.0.202`ã€‚
- flanneldå°†åŸå§‹çš„IPåŒ…å°è£…åœ¨ä¸€ä¸ªUDPåŒ…é‡Œï¼Œç„¶åå‘é€ç»™Node 2çš„8285ç«¯å£ï¼ˆflanneldé»˜è®¤ç›‘å¬çš„ç«¯å£ï¼‰ã€‚**(æ­¤æ—¶è¿›è¡Œä¸‰æ¬¡ç”¨æˆ·æ€å’Œå†…æ ¸æ€çš„åˆ‡æ¢)**
- å½“è¿™ä¸ªUDPåŒ…åˆ°è¾¾Node 2åï¼Œä¼šè¢«Node 2ä¸Šçš„flanneldè¿›ç¨‹æ¥æ”¶å’Œè§£åŒ…ï¼Œè¿˜åŸå‡ºåŸå§‹çš„IPåŒ…ã€‚**(æ­¤æ—¶å¦ä¸€å°ä¸»æœºè¿›è¡Œä¸€æ¬¡ç”¨æˆ·æ€å’Œå†…æ ¸æ€çš„åˆ‡æ¢)**
- Node 2çš„flanneldå°†è¿˜åŸå‡ºçš„IPåŒ…äº¤ç»™æœ¬æœºçš„flannel0è®¾å¤‡ã€‚**(æ­¤æ—¶å¦ä¸€å°ä¸»æœºè¿›è¡ŒäºŒæ¬¡ç”¨æˆ·æ€å’Œå†…æ ¸æ€çš„åˆ‡æ¢)**
- flannel0è®¾å¤‡å°†IPåŒ…è½¬å‘ç»™docker0ç½‘æ¡¥ã€‚
- docker0ç½‘æ¡¥æ ¹æ®ç›®çš„IPåœ°å€ï¼Œå°†åŒ…è½¬å‘ç»™container-2ã€‚**(æ­¤æ—¶å¦ä¸€å°ä¸»æœºè¿›è¡Œä¸‰æ¬¡ç”¨æˆ·æ€å’Œå†…æ ¸æ€çš„åˆ‡æ¢)**



![image-20250326164947210](../markdown_img/image-20250326164947210.png)



**UDPå°è£…ä¸è§£å°è£…è¿‡ç¨‹**

- **å°è£…è¿‡ç¨‹åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤**

  - flanneldé¦–å…ˆæ£€æŸ¥æ•°æ®åŒ…çš„ç›®çš„IPåœ°å€ï¼Œç¡®å®šç›®æ ‡å®¹å™¨æ‰€åœ¨çš„å®¿ä¸»æœº
  - flanneldç„¶ååˆ›å»ºä¸€ä¸ªæ–°çš„UDPæ•°æ®åŒ…ã€‚è¿™ä¸ªUDPæ•°æ®åŒ…çš„æºIPåœ°å€æ˜¯å½“å‰å®¿ä¸»æœºçš„IPåœ°å€ï¼Œç›®çš„IPåœ°å€æ˜¯ç›®æ ‡å®¹å™¨æ‰€åœ¨å®¿ä¸»æœºçš„IPåœ°å€ã€‚UDPç«¯å£é€šå¸¸æ˜¯8285ã€‚
  - åŸå§‹çš„IPæ•°æ®åŒ…è¢«æ”¾å…¥è¿™ä¸ªUDPæ•°æ®åŒ…çš„è´Ÿè½½éƒ¨åˆ†ã€‚
  - flanneldå°†å°è£…å¥½çš„UDPæ•°æ®åŒ…äº¤ç»™å®¿ä¸»æœºçš„ç½‘ç»œæ ˆï¼Œç”±å®¿ä¸»æœºçš„ç½‘ç»œæ ˆè´Ÿè´£å°†è¿™ä¸ªUDPåŒ…å‘é€å‡ºå»ã€‚

  

- **æ‹†è§£UDPè§£å°è£…è¿‡ç¨‹**

  - ç›®æ ‡å®¿ä¸»æœºçš„ç½‘ç»œæ ˆæ¥æ”¶åˆ°UDPåŒ…ï¼Œå‘ç°ç›®çš„ç«¯å£æ˜¯8285ï¼Œäºæ˜¯å°†è¿™ä¸ªåŒ…äº¤ç»™ç›‘å¬åœ¨8285ç«¯å£çš„flanneldè¿›ç¨‹ã€‚
  - flanneldè¿›ç¨‹æ¥æ”¶åˆ°UDPåŒ…åï¼Œä»UDPåŒ…çš„è´Ÿè½½ä¸­æå–å‡ºåŸå§‹çš„IPæ•°æ®åŒ…
  - flanneldå°†æå–å‡ºçš„åŸå§‹IPåŒ…å†™å…¥æœ¬æœºçš„flannel0è®¾å¤‡ã€‚
  - Linuxå†…æ ¸æ¥æ”¶åˆ°è¿™ä¸ªIPåŒ…ï¼Œæ ¹æ®è·¯ç”±è§„åˆ™å°†å…¶è½¬å‘ç»™docker0ç½‘æ¡¥ã€‚
  - docker0ç½‘æ¡¥æ ¹æ®IPåŒ…çš„ç›®çš„åœ°å€ï¼Œå°†åŒ…è½¬å‘ç»™ç›®æ ‡å®¹å™¨ã€‚

![image-20250326165552416](../markdown_img/image-20250326165552416.png)



**UDPç½‘ç»œæ¨¡å¼æ€§èƒ½é—®é¢˜åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å¯èƒ½å¦‚ä¸‹:**

- **è¾ƒé«˜çš„ç½‘ç»œå»¶è¿Ÿ**: ç”±äºæ¯ä¸ªæ•°æ®åŒ…éƒ½éœ€è¦ç»è¿‡å¤šæ¬¡å¤„ç†å’ŒçŠ¶æ€åˆ‡æ¢ï¼Œç½‘ç»œå»¶è¿Ÿä¼šæ˜¾è‘—å¢åŠ ã€‚
- **CPUä½¿ç”¨ç‡å‡é«˜**: é¢‘ç¹çš„çŠ¶æ€åˆ‡æ¢å’Œæ•°æ®æ‹·è´ä¼šæ¶ˆè€—å¤§é‡çš„CPUèµ„æºã€‚
- **ååé‡å—é™**: ç”±äºå•ä¸ªflanneldè¿›ç¨‹éœ€è¦å¤„ç†æ‰€æœ‰æµé‡ï¼Œåœ¨é«˜å¹¶å‘æƒ…å†µä¸‹å¯èƒ½ä¼šæˆä¸ºç“¶é¢ˆã€‚
- **å†…å­˜å¸¦å®½å‹åŠ›**: å¤šæ¬¡æ•°æ®æ‹·è´ä¼šå¢åŠ å†…å­˜å¸¦å®½çš„ä½¿ç”¨ã€‚
- **ç½‘ç»œæ•ˆç‡é™ä½**: UDPå°è£…å¢åŠ äº†æ•°æ®åŒ…å¤§å°ï¼Œé™ä½äº†ç½‘ç»œçš„æœ‰æ•ˆè½½è·æ¯”ä¾‹ã€‚



æˆ‘ä»¬åœ¨è¿›è¡Œç³»ç»Ÿçº§ç¼–ç¨‹çš„æ—¶å€™ï¼Œæœ‰ä¸€ä¸ªéå¸¸é‡è¦çš„ä¼˜åŒ–åŸåˆ™ï¼Œå°±æ˜¯è¦å‡å°‘ç”¨æˆ·æ€åˆ°å†…æ ¸æ€çš„åˆ‡æ¢æ¬¡æ•°ï¼Œå¹¶ä¸”æŠŠæ ¸å¿ƒçš„å¤„ç†é€»è¾‘éƒ½æ”¾åœ¨å†…æ ¸æ€è¿›è¡Œã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆï¼ŒFlannel åæ¥æ”¯æŒçš„VXLAN æ¨¡å¼ï¼Œé€æ¸æˆä¸ºäº†ä¸»æµçš„å®¹å™¨ç½‘ç»œæ–¹æ¡ˆçš„åŸå› ã€‚



##### VXLANç½‘ç»œæ¨¡å¼å‰–æ

VXLANï¼Œå³ Virtual Extensible LANï¼ˆè™šæ‹Ÿå¯æ‰©å±•å±€åŸŸç½‘ï¼‰ï¼Œæ˜¯ Linux å†…æ ¸æœ¬èº«å°±æ”¯æŒçš„ä¸€ç§ç½‘ç»œè™šä¼¼åŒ–æŠ€æœ¯ã€‚æ‰€ä»¥è¯´ï¼ŒVXLAN å¯ä»¥å®Œå…¨åœ¨å†…æ ¸æ€å®ç°ä¸Šè¿°å°è£…å’Œè§£å°è£…çš„å·¥ä½œï¼Œä»è€Œé€šè¿‡ä¸å‰é¢ç›¸ä¼¼çš„â€œéš§é“â€æœºåˆ¶ï¼Œæ„å»ºå‡ºè¦†ç›–ç½‘ç»œï¼ˆOverlay Networkï¼‰ã€‚

VXLAN çš„è¦†ç›–ç½‘ç»œçš„è®¾è®¡æ€æƒ³æ˜¯ï¼šåœ¨ç°æœ‰çš„ä¸‰å±‚ç½‘ç»œä¹‹ä¸Šï¼Œâ€œè¦†ç›–â€ä¸€å±‚è™šæ‹Ÿçš„ã€ç”±å†…æ ¸ VXLAN æ¨¡å—è´Ÿè´£ç»´æŠ¤çš„**äºŒå±‚ç½‘ç»œ**ï¼Œä½¿å¾—è¿æ¥åœ¨è¿™ä¸ª VXLAN äºŒå±‚ç½‘ç»œä¸Šçš„â€œä¸»æœºâ€ï¼ˆè™šæ‹Ÿæœºæˆ–è€…å®¹å™¨éƒ½å¯ä»¥ï¼‰ä¹‹é—´ï¼Œå¯ä»¥åƒåœ¨åŒä¸€ä¸ªå±€åŸŸç½‘ï¼ˆLANï¼‰é‡Œé‚£æ ·è‡ªç”±é€šä¿¡ã€‚å½“ç„¶ï¼Œå®é™…ä¸Šï¼Œè¿™äº›â€œä¸»æœºâ€å¯èƒ½åˆ†å¸ƒåœ¨ä¸åŒçš„å®¿ä¸»æœºä¸Šï¼Œç”šè‡³æ˜¯åˆ†å¸ƒåœ¨ä¸åŒçš„ç‰©ç†æœºæˆ¿é‡Œã€‚

è€Œä¸ºäº†èƒ½å¤Ÿåœ¨äºŒå±‚ç½‘ç»œä¸Šæ‰“é€šâ€œéš§é“â€ï¼ŒVXLAN ä¼šåœ¨å®¿ä¸»æœºä¸Šè®¾ç½®ä¸€ä¸ªç‰¹æ®Šçš„ç½‘ç»œè®¾å¤‡ä½œä¸ºâ€œéš§é“â€çš„ä¸¤ç«¯ã€‚è¿™ä¸ªè®¾å¤‡å°±å«ä½œ **VTEP**ï¼Œå³ï¼š**VXLAN Tunnel End Pointï¼ˆè™šæ‹Ÿéš§é“ç«¯ç‚¹ï¼‰**ã€‚

è€Œ VTEP è®¾å¤‡çš„ä½œç”¨ï¼Œå…¶å®è·Ÿå‰é¢çš„ flanneld è¿›ç¨‹éå¸¸ç›¸ä¼¼ã€‚åªä¸è¿‡ï¼Œ**å®ƒè¿›è¡Œå°è£…å’Œè§£å°è£…çš„å¯¹è±¡ï¼Œæ˜¯äºŒå±‚æ•°æ®å¸§ï¼ˆEthernet frameï¼‰ï¼›è€Œä¸”è¿™ä¸ªå·¥ä½œçš„æ‰§è¡Œæµç¨‹ï¼Œå…¨éƒ¨æ˜¯åœ¨å†…æ ¸é‡Œå®Œæˆçš„ï¼ˆå› ä¸º VXLAN æœ¬èº«å°±æ˜¯ Linux å†…æ ¸ä¸­çš„ä¸€ä¸ªæ¨¡å—ï¼‰**



![image-20250326165451015](../markdown_img/image-20250326165451015.png)



å›¾ä¸­æ¯å°å®¿ä¸»æœºä¸Šåå« flannel.1 çš„è®¾å¤‡ï¼Œå°±æ˜¯ VXLAN æ‰€éœ€çš„ VTEP è®¾å¤‡ï¼Œå®ƒæ—¢æœ‰ IP åœ°å€ï¼Œä¹Ÿæœ‰ MAC åœ°å€

container-1 çš„ IP åœ°å€æ˜¯ 10.1.15.2ï¼Œè¦è®¿é—®çš„ container-2 çš„ IP åœ°å€æ˜¯ 10.1.16.3ã€‚

é‚£ä¹ˆï¼Œä¸å‰é¢ UDP æ¨¡å¼çš„æµç¨‹ç±»ä¼¼ï¼Œå½“ container-1 å‘å‡ºè¯·æ±‚ä¹‹åï¼Œè¿™ä¸ªç›®çš„åœ°å€æ˜¯ 10.1.16.3 çš„ IP åŒ…ï¼Œä¼šå…ˆå‡ºç°åœ¨ cni0 ç½‘æ¡¥ï¼Œç„¶åè¢«è·¯ç”±åˆ°æœ¬æœº flannel.1 è®¾å¤‡è¿›è¡Œå¤„ç†ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¥åˆ°äº†â€œéš§é“â€çš„å…¥å£ã€‚ä¸ºäº†æ–¹ä¾¿å™è¿°ï¼Œæˆ‘æ¥ä¸‹æ¥ä¼šæŠŠè¿™ä¸ª IP åŒ…ç§°ä¸ºâ€œåŸå§‹ IP åŒ…â€ã€‚

**è¡¥å……ï¼šä»cni0åˆ°flannel.1æ˜¯å¦‚ä½•è·¯ç”±çš„**

```bash
[root@master1 ~]# kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS   AGE     IP           NODE             NOMINATED NODE   READINESS GATES
myweb-565cb68445-49fqg   1/1     Running   0          2m14s   10.244.1.3   node1.feng.org   <none>           <none>
myweb-565cb68445-7fv5x   1/1     Running   0          2m14s   10.244.2.2   node2.feng.org   <none>           <none>
myweb-565cb68445-tgnvw   1/1     Running   0          2m14s   10.244.1.2   node1.feng.org   <none>           <none>

[root@mystical ~]# kubectl exec -it myweb-565cb68445-49fqg -- sh
[root@myweb-565cb68445-49fqg /]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.244.1.1      0.0.0.0         UG    0      0        0 eth0
10.244.0.0      10.244.1.1      255.255.0.0     UG    0      0        0 eth0
10.244.1.0      0.0.0.0         255.255.255.0   U     0      0        0 eth0

[root@master1 ~]# kubectl exec myweb-565cb68445-7fv5x -- route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.244.2.1      0.0.0.0         UG    0      0        0 eth0
10.244.0.0      10.244.2.1      255.255.0.0     UG    0      0        0 eth0
10.244.2.0      0.0.0.0         255.255.255.0   U     0      0        0 eth0

# æ¯ä¸ªpodé‡Œé¢ä¼šç”ŸæˆæŒ‡å‘æ‰€åœ¨å®¿ä¸»æœºè™šæ‹Ÿç½‘ç»œè®¾å¤‡cni0è™šæ‹Ÿç½‘æ¡¥çš„é»˜è®¤è·¯ç”±

[root@node1 ~]# ip a show flannel.1
[root@node1 ~]# ip a show cni0
5: cni0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000
    link/ether ca:d6:5b:9c:59:c7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.1.1/24 brd 10.244.1.255 scope global cni0
       valid_lft forever preferred_lft forever
    inet6 fe80::c8d6:5bff:fe9c:59c7/64 scope link 
       valid_lft forever preferred_lft forever
       
# æ•°æ®è¿›å…¥cni0åï¼Œä¼šæ ¹æ®å®¿ä¸»æœºçš„è·¯ç”±è¡¨ï¼Œä»è€Œè¿›å…¥flannel1.1
[root@node1 ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         11.0.1.2        0.0.0.0         UG    0      0        0 eth0
10.244.0.0      10.244.0.0      255.255.255.0   UG    0      0        0 flannel.1
10.244.1.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0
10.244.2.0      10.244.2.0      255.255.255.0   UG    0      0        0 flannel.1
11.0.1.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
```

ä¸ºäº†èƒ½å¤Ÿå°†â€œåŸå§‹ IP åŒ…â€å°è£…å¹¶ä¸”å‘é€åˆ°æ­£ç¡®çš„å®¿ä¸»æœºï¼ŒVXLAN å°±éœ€è¦æ‰¾åˆ°è¿™æ¡â€œéš§é“â€çš„å‡ºå£ï¼Œå³ï¼šç›®çš„å®¿ä¸»æœºçš„ VTEP è®¾å¤‡ã€‚

è€Œè¿™ä¸ªè®¾å¤‡çš„ä¿¡æ¯ï¼Œæ­£æ˜¯æ¯å°å®¿ä¸»æœºä¸Šçš„ flanneld è¿›ç¨‹è´Ÿè´£ç»´æŠ¤çš„ã€‚

æ¯”å¦‚ï¼Œå½“ Node 2 å¯åŠ¨å¹¶åŠ å…¥ Flannel ç½‘ç»œä¹‹åï¼Œåœ¨ Node 1ï¼ˆä»¥åŠæ‰€æœ‰å…¶ä»–èŠ‚ç‚¹ï¼‰ä¸Šï¼Œflanneld å°±ä¼šæ·»åŠ ä¸€æ¡å¦‚ä¸‹æ‰€ç¤ºçš„è·¯ç”±è§„åˆ™ï¼š

```bash
$ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
...
10.1.16.0       10.1.16.0       255.255.255.0   UG    0      0        0 flannel.1
```

è¿™æ¡è§„åˆ™çš„æ„æ€æ˜¯ï¼šå‡¡æ˜¯å‘å¾€ 10.1.16.0/24 ç½‘æ®µçš„ IP åŒ…ï¼Œéƒ½éœ€è¦ç»è¿‡ flannel.1 è®¾å¤‡å‘å‡ºï¼Œå¹¶ä¸”ï¼Œå®ƒæœ€åè¢«å‘å¾€çš„ç½‘å…³åœ°å€æ˜¯ï¼š10.1.16.0ã€‚

ä»ä¸Šå›¾ çš„ Flannel VXLAN æ¨¡å¼çš„æµç¨‹å›¾ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œ10.1.16.0 æ­£æ˜¯ Node 2 ä¸Šçš„ VTEP è®¾å¤‡ï¼ˆä¹Ÿå°±æ˜¯ flannel.1 è®¾å¤‡ï¼‰çš„ IP åœ°å€ã€‚

ä¸ºäº†æ–¹ä¾¿å™è¿°ï¼Œæ¥ä¸‹æ¥æˆ‘ä¼šæŠŠ Node 1 å’Œ Node 2 ä¸Šçš„ flannel.1 è®¾å¤‡åˆ†åˆ«ç§°ä¸ºâ€œ**æº VTEP è®¾å¤‡**â€å’Œâ€œ**ç›®çš„ VTEP è®¾å¤‡**â€ã€‚

è€Œè¿™äº› VTEP è®¾å¤‡ä¹‹é—´ï¼Œå°±éœ€è¦æƒ³åŠæ³•ç»„æˆä¸€ä¸ªè™šæ‹Ÿçš„äºŒå±‚ç½‘ç»œï¼Œå³ï¼š**é€šè¿‡äºŒå±‚æ•°æ®å¸§è¿›è¡Œé€šä¿¡**ã€‚

æ‰€ä»¥åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œâ€œæº VTEP è®¾å¤‡â€æ”¶åˆ°â€œåŸå§‹ IP åŒ…â€åï¼Œå°±è¦æƒ³åŠæ³•æŠŠâ€œåŸå§‹ IP åŒ…â€åŠ ä¸Šä¸€ä¸ªç›®çš„ MAC åœ°å€ï¼Œå°è£…æˆä¸€ä¸ªäºŒå±‚æ•°æ®å¸§ï¼Œç„¶åå‘é€ç»™â€œç›®çš„ VTEP è®¾å¤‡â€ï¼ˆå½“ç„¶ï¼Œè¿™ä¹ˆåšè¿˜æ˜¯å› ä¸ºè¿™ä¸ª IP åŒ…çš„ç›®çš„åœ°å€ä¸æ˜¯æœ¬æœºï¼‰ã€‚

è¿™é‡Œéœ€è¦è§£å†³çš„é—®é¢˜å°±æ˜¯ï¼š**ç›®çš„ VTEP è®¾å¤‡â€çš„ MAC åœ°å€æ˜¯ä»€ä¹ˆ**

æ­¤æ—¶ï¼Œæ ¹æ®å‰é¢çš„è·¯ç”±è®°å½•ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“äº†â€œç›®çš„ VTEP è®¾å¤‡â€çš„ IP åœ°å€ã€‚è€Œè¦æ ¹æ®ä¸‰å±‚ IP åœ°å€æŸ¥è¯¢å¯¹åº”çš„äºŒå±‚ MAC åœ°å€ï¼Œè¿™æ­£æ˜¯ ARPï¼ˆAddress Resolution Protocol ï¼‰è¡¨çš„åŠŸèƒ½ã€‚

è€Œè¿™é‡Œè¦ç”¨åˆ°çš„ ARP è®°å½•ï¼Œä¹Ÿæ˜¯ flanneld è¿›ç¨‹åœ¨ Node 2 èŠ‚ç‚¹å¯åŠ¨æ—¶ï¼Œè‡ªåŠ¨æ·»åŠ åœ¨ Node 1 ä¸Šçš„ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ ip å‘½ä»¤çœ‹åˆ°å®ƒï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
# åœ¨Node 1ä¸Š
$ ip neigh show dev flannel.1
10.1.16.0 lladdr 5e:f8:4f:00:e3:37 PERMANENT
# PERMANENT: è¡¨ç¤ºè¿™ä¸ªé‚»å±…é¡¹æ˜¯æ‰‹åŠ¨æˆ–é€šè¿‡æŸç§æœºåˆ¶å†™å…¥çš„ï¼Œä¸ä¼šè¢«ç³»ç»Ÿè‡ªåŠ¨æ¸…é™¤
# å¦‚æœæ˜¯åŠ¨æ€å­¦ä¹ åˆ°çš„ï¼Œä¼šæ˜¯ REACHABLE / STALE / DELAY / FAILED ç­‰çŠ¶æ€
```

è¿™æ¡è®°å½•çš„æ„æ€éå¸¸æ˜ç¡®ï¼Œå³ï¼šIP åœ°å€ 10.1.16.0ï¼Œå¯¹åº”çš„ MAC åœ°å€æ˜¯ 5e:f8:4f:00:e3:37ã€‚

```ABAP
å¯ä»¥çœ‹åˆ°ï¼Œæœ€æ–°ç‰ˆæœ¬çš„ Flannel å¹¶ä¸ä¾èµ– L3 MISS äº‹ä»¶å’Œ ARP å­¦ä¹ ï¼Œè€Œä¼šåœ¨æ¯å°èŠ‚ç‚¹å¯åŠ¨æ—¶æŠŠå®ƒçš„ VTEP è®¾å¤‡å¯¹åº”çš„ ARP è®°å½•ï¼Œç›´æ¥ä¸‹æ”¾åˆ°å…¶ä»–æ¯å°å®¿ä¸»æœºä¸Šã€‚
```

**å»¶ä¼¸çŸ¥è¯†**

å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ‰‹åŠ¨æ·»åŠ ä¸€ä¸ª PERMANENT æ¡ç›®ï¼š

```bash
ip neigh add 192.168.1.100 lladdr aa:bb:cc:dd:ee:ff dev eth0 nud permanent
# nud permanent: è¡¨ç¤ºè¿™ä¸ªé‚»å±…é¡¹æ°¸è¿œæœ‰æ•ˆï¼ˆå³ä½¿ä¸åœ¨çº¿ä¹Ÿä¸ä¼šæ¶ˆå¤±ï¼‰
# lladdr: æ˜ å°„çš„ MAC åœ°å€
```

æœ‰äº†è¿™ä¸ªâ€œç›®çš„ VTEP è®¾å¤‡â€çš„ MAC åœ°å€ï¼ŒLinux å†…æ ¸å°±å¯ä»¥å¼€å§‹äºŒå±‚å°åŒ…å·¥ä½œäº†ã€‚è¿™ä¸ªäºŒå±‚å¸§çš„æ ¼å¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![image-20250326171508850](../markdown_img/image-20250326171508850.png)



å¯ä»¥çœ‹åˆ°ï¼ŒLinux å†…æ ¸ä¼šæŠŠâ€œç›®çš„ VTEP è®¾å¤‡â€çš„ MAC åœ°å€ï¼Œå¡«å†™åœ¨å›¾ä¸­çš„ Inner Ethernet Header å­—æ®µï¼Œå¾—åˆ°ä¸€ä¸ªäºŒå±‚æ•°æ®å¸§

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸Šè¿°å°åŒ…è¿‡ç¨‹åªæ˜¯åŠ ä¸€ä¸ªäºŒå±‚å¤´ï¼Œä¸ä¼šæ”¹å˜â€œåŸå§‹ IP åŒ…â€çš„å†…å®¹ã€‚æ‰€ä»¥å›¾ä¸­çš„ Inner IP Header å­—æ®µï¼Œä¾ç„¶æ˜¯ container-2 çš„ IP åœ°å€ï¼Œå³ 10.1.16.3ã€‚

ä½†æ˜¯ï¼Œä¸Šé¢æåˆ°çš„è¿™äº› VTEP è®¾å¤‡çš„ MAC åœ°å€ï¼Œå¯¹äºå®¿ä¸»æœºç½‘ç»œæ¥è¯´å¹¶æ²¡æœ‰ä»€ä¹ˆå®é™…æ„ä¹‰ã€‚æ‰€ä»¥ä¸Šé¢å°è£…å‡ºæ¥çš„è¿™ä¸ªæ•°æ®å¸§ï¼Œå¹¶ä¸èƒ½åœ¨æˆ‘ä»¬çš„å®¿ä¸»æœºäºŒå±‚ç½‘ç»œé‡Œä¼ è¾“ã€‚ä¸ºäº†æ–¹ä¾¿å™è¿°ï¼Œæˆ‘ä»¬æŠŠå®ƒç§°ä¸ºâ€œå†…éƒ¨æ•°æ®å¸§â€ï¼ˆInner Ethernet Frameï¼‰ã€‚

æ‰€ä»¥æ¥ä¸‹æ¥ï¼ŒLinux å†…æ ¸è¿˜éœ€è¦å†æŠŠâ€œå†…éƒ¨æ•°æ®å¸§â€è¿›ä¸€æ­¥å°è£…æˆä¸ºå®¿ä¸»æœºç½‘ç»œé‡Œçš„ä¸€ä¸ªæ™®é€šçš„æ•°æ®å¸§ï¼Œå¥½è®©å®ƒâ€œè½½ç€â€â€œå†…éƒ¨æ•°æ®å¸§â€ï¼Œé€šè¿‡å®¿ä¸»æœºçš„ eth0 ç½‘å¡è¿›è¡Œä¼ è¾“ã€‚

æˆ‘ä»¬æŠŠè¿™æ¬¡è¦å°è£…å‡ºæ¥çš„ã€å®¿ä¸»æœºå¯¹åº”çš„æ•°æ®å¸§ç§°ä¸ºâ€œå¤–éƒ¨æ•°æ®å¸§â€ï¼ˆOuter Ethernet Frameï¼‰ã€‚

ä¸ºäº†å®ç°è¿™ä¸ªâ€œæ­ä¾¿è½¦â€çš„æœºåˆ¶ï¼ŒLinux å†…æ ¸ä¼šåœ¨â€œå†…éƒ¨æ•°æ®å¸§â€å‰é¢ï¼ŒåŠ ä¸Šä¸€ä¸ªç‰¹æ®Šçš„ VXLAN å¤´ï¼Œç”¨æ¥è¡¨ç¤ºè¿™ä¸ªâ€œä¹˜å®¢â€å®é™…ä¸Šæ˜¯ä¸€ä¸ª VXLAN è¦ä½¿ç”¨çš„æ•°æ®å¸§ã€‚

è€Œè¿™ä¸ª VXLAN å¤´é‡Œæœ‰ä¸€ä¸ªé‡è¦çš„æ ‡å¿—å«ä½œ **VNI**ï¼Œå®ƒæ˜¯ VTEP è®¾å¤‡è¯†åˆ«æŸä¸ªæ•°æ®å¸§æ˜¯ä¸æ˜¯åº”è¯¥å½’è‡ªå·±å¤„ç†çš„é‡è¦æ ‡è¯†ã€‚è€Œåœ¨ Flannel ä¸­ï¼Œ**VNI çš„é»˜è®¤å€¼æ˜¯ 1**ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä½•ï¼Œå®¿ä¸»æœºä¸Šçš„ VTEP è®¾å¤‡éƒ½å«ä½œ flannel.1 çš„åŸå› ï¼Œè¿™é‡Œçš„â€œ1â€ï¼Œå…¶å®å°±æ˜¯ VNI çš„å€¼ã€‚

æ‰€ä»¥ï¼Œè·Ÿ UDP æ¨¡å¼ç±»ä¼¼ï¼Œåœ¨å®¿ä¸»æœºçœ‹æ¥ï¼Œå®ƒä¼šä»¥ä¸ºè‡ªå·±çš„ flannel.1 è®¾å¤‡åªæ˜¯åœ¨å‘å¦å¤–ä¸€å°å®¿ä¸»æœºçš„ flannel.1 è®¾å¤‡ï¼Œå‘èµ·äº†ä¸€æ¬¡æ™®é€šçš„ UDP é“¾æ¥ã€‚å®ƒå“ªé‡Œä¼šçŸ¥é“ï¼Œè¿™ä¸ª UDP åŒ…é‡Œé¢ï¼Œå…¶å®æ˜¯ä¸€ä¸ªå®Œæ•´çš„äºŒå±‚æ•°æ®å¸§

ä¸è¿‡ï¼Œä¸è¦å¿˜äº†ï¼Œä¸€ä¸ª flannel.1 è®¾å¤‡åªçŸ¥é“å¦ä¸€ç«¯çš„ flannel.1 è®¾å¤‡çš„ MAC åœ°å€ï¼Œå´ä¸çŸ¥é“å¯¹åº”çš„å®¿ä¸»æœºåœ°å€æ˜¯ä»€ä¹ˆ

ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ª UDP åŒ…è¯¥å‘ç»™å“ªå°å®¿ä¸»æœºå‘¢ï¼Ÿ

åœ¨è¿™ç§åœºæ™¯ä¸‹ï¼Œflannel.1 è®¾å¤‡å®é™…ä¸Šè¦æ‰®æ¼”ä¸€ä¸ªâ€œç½‘æ¡¥â€çš„è§’è‰²ï¼Œåœ¨äºŒå±‚ç½‘ç»œè¿›è¡Œ UDP åŒ…çš„è½¬å‘ã€‚è€Œåœ¨ Linux å†…æ ¸é‡Œé¢ï¼Œâ€œç½‘æ¡¥â€è®¾å¤‡è¿›è¡Œè½¬å‘çš„ä¾æ®ï¼Œæ¥è‡ªäºä¸€ä¸ªå«ä½œ **FDBï¼ˆForwarding Databaseï¼‰çš„è½¬å‘æ•°æ®åº“**ã€‚

ä¸éš¾æƒ³åˆ°ï¼Œè¿™ä¸ª flannel.1â€œç½‘æ¡¥â€å¯¹åº”çš„ FDB ä¿¡æ¯ï¼Œä¹Ÿæ˜¯ flanneld è¿›ç¨‹è´Ÿè´£ç»´æŠ¤çš„ã€‚å®ƒçš„å†…å®¹å¯ä»¥é€šè¿‡ bridge fdb å‘½ä»¤æŸ¥çœ‹åˆ°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
# åœ¨Node 1ä¸Šï¼Œä½¿ç”¨â€œç›®çš„VTEPè®¾å¤‡â€çš„MACåœ°å€è¿›è¡ŒæŸ¥è¯¢
$ bridge fdb show flannel.1 | grep 5e:f8:4f:00:e3:37
5e:f8:4f:00:e3:37 dev flannel.1 dst 10.168.0.3 self permanent
```

å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ä¸Šé¢è¿™æ¡ FDB è®°å½•é‡Œï¼ŒæŒ‡å®šäº†è¿™æ ·ä¸€æ¡è§„åˆ™ï¼Œå³ï¼š

å‘å¾€æˆ‘ä»¬å‰é¢æåˆ°çš„â€œç›®çš„ VTEP è®¾å¤‡â€ï¼ˆMAC åœ°å€æ˜¯ 5e:f8:4f:00:e3:37ï¼‰çš„äºŒå±‚æ•°æ®å¸§ï¼Œåº”è¯¥é€šè¿‡ flannel.1 è®¾å¤‡ï¼Œå‘å¾€ IP åœ°å€ä¸º 10.168.0.3 çš„ä¸»æœºã€‚æ˜¾ç„¶ï¼Œè¿™å°ä¸»æœºæ­£æ˜¯ Node 2ï¼ŒUDP åŒ…è¦å‘å¾€çš„ç›®çš„åœ°å°±æ‰¾åˆ°äº†ã€‚

æ‰€ä»¥æ¥ä¸‹æ¥çš„æµç¨‹ï¼Œå°±æ˜¯ä¸€ä¸ªæ­£å¸¸çš„ã€å®¿ä¸»æœºç½‘ç»œä¸Šçš„å°åŒ…å·¥ä½œ

æˆ‘ä»¬çŸ¥é“ï¼ŒUDP åŒ…æ˜¯ä¸€ä¸ªå››å±‚æ•°æ®åŒ…ï¼Œæ‰€ä»¥ Linux å†…æ ¸ä¼šåœ¨å®ƒå‰é¢åŠ ä¸Šä¸€ä¸ª IP å¤´ï¼Œå³åŸç†å›¾ä¸­çš„ Outer IP Headerï¼Œç»„æˆä¸€ä¸ª IP åŒ…ã€‚å¹¶ä¸”ï¼Œåœ¨è¿™ä¸ª IP å¤´é‡Œï¼Œä¼šå¡«ä¸Šå‰é¢é€šè¿‡ FDB æŸ¥è¯¢å‡ºæ¥çš„ç›®çš„ä¸»æœºçš„ IP åœ°å€ï¼Œå³ Node 2 çš„ IP åœ°å€ 10.168.0.3

ç„¶åï¼ŒLinux å†…æ ¸å†åœ¨è¿™ä¸ª IP åŒ…å‰é¢åŠ ä¸ŠäºŒå±‚æ•°æ®å¸§å¤´ï¼Œå³åŸç†å›¾ä¸­çš„ Outer Ethernet Headerï¼Œå¹¶æŠŠ Node 2 çš„ MAC åœ°å€å¡«è¿›å»ã€‚è¿™ä¸ª MAC åœ°å€æœ¬èº«ï¼Œæ˜¯ Node 1 çš„ ARP è¡¨è¦å­¦ä¹ çš„å†…å®¹ï¼Œæ— éœ€ Flannel ç»´æŠ¤ã€‚è¿™æ—¶å€™ï¼Œæˆ‘ä»¬å°è£…å‡ºæ¥çš„â€œå¤–éƒ¨æ•°æ®å¸§â€çš„æ ¼å¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š



![image-20250326172315923](../markdown_img/image-20250326172315923.png)



è¿™æ ·ï¼Œå°åŒ…å·¥ä½œå°±å®£å‘Šå®Œæˆäº†ã€‚

```bash
UDP 8472
# IANA å®˜æ–¹æ³¨å†Œ çš„ VXLAN ç«¯å£
# Flannel ä½¿ç”¨çš„é»˜è®¤ç«¯å£
```

æ¥ä¸‹æ¥ï¼ŒNode 1 ä¸Šçš„ flannel.1 è®¾å¤‡å°±å¯ä»¥æŠŠè¿™ä¸ªæ•°æ®å¸§ä» Node 1 çš„ eth0 ç½‘å¡å‘å‡ºå»ã€‚æ˜¾ç„¶ï¼Œè¿™ä¸ªå¸§ä¼šç»è¿‡å®¿ä¸»æœºç½‘ç»œæ¥åˆ° Node 2 çš„ eth0 ç½‘å¡ã€‚

è¿™æ—¶å€™ï¼ŒNode 2 çš„å†…æ ¸ç½‘ç»œæ ˆä¼šå‘ç°è¿™ä¸ªæ•°æ®å¸§é‡Œæœ‰ VXLAN Headerï¼Œå¹¶ä¸” VNI=1ã€‚æ‰€ä»¥ Linux å†…æ ¸ä¼šå¯¹å®ƒè¿›è¡Œæ‹†åŒ…ï¼Œæ‹¿åˆ°é‡Œé¢çš„å†…éƒ¨æ•°æ®å¸§ï¼Œç„¶åæ ¹æ® VNI çš„å€¼ï¼ŒæŠŠå®ƒäº¤ç»™ Node 2 ä¸Šçš„ flannel.1 è®¾å¤‡ã€‚

è€Œ flannel.1 è®¾å¤‡åˆ™ä¼šè¿›ä¸€æ­¥æ‹†åŒ…ï¼Œå–å‡ºâ€œåŸå§‹ IP åŒ…â€ã€‚æœ€ç»ˆï¼ŒIP åŒ…å°±è¿›å…¥åˆ°äº† container-2 å®¹å™¨çš„ Network Namespace é‡Œ

ä»¥ä¸Šï¼Œå°±æ˜¯ Flannel VXLAN æ¨¡å¼çš„å…·ä½“å·¥ä½œåŸç†äº†ã€‚

**å»¶ä¼¸çŸ¥è¯†**

å¤§éƒ¨åˆ†æ”¯æŒVXLANçš„äº¤æ¢æœºéƒ½æ˜¯ä¸‰å±‚äº¤æ¢æœº

```ABAP
ä¸‰å±‚äº¤æ¢æœº = â€œèƒ½è·¯ç”±çš„äº¤æ¢æœºâ€
è·¯ç”±å™¨ = â€œæ›´æ™ºèƒ½ã€åŠŸèƒ½æ›´ä¸°å¯Œçš„ç½‘ç»œå†³ç­–ä¸­å¿ƒâ€
```

**åŠŸèƒ½å¯¹æ¯”è¡¨æ ¼**

| å¯¹æ¯”ç»´åº¦            | ä¸‰å±‚äº¤æ¢æœº (L3 Switch)                         | è·¯ç”±å™¨ (Router)                                              |
| ------------------- | ---------------------------------------------- | ------------------------------------------------------------ |
| **æ ¸å¿ƒåŠŸèƒ½**        | åŸºäº IP è¿›è¡Œé«˜é€Ÿè½¬å‘ï¼Œæ³¨é‡äº¤æ¢+è·¯ç”±            | ç½‘ç»œå±‚åè®®å¤„ç†ã€è·¯å¾„é€‰æ‹©ã€NATã€é˜²ç«å¢™ã€QoS ç­‰å…¨å¥—åŠŸèƒ½        |
| **ç›®æ ‡åœºæ™¯**        | é«˜æ€§èƒ½åŒæ„ç½‘ç»œå†…éƒ¨é€šä¿¡ï¼ˆå¦‚ï¼šæ•°æ®ä¸­å¿ƒã€å›­åŒºç½‘ï¼‰ | ä¸åŒç½‘ç»œ/ä¸åŒåè®®ä¹‹é—´çš„è¿æ¥ï¼ˆå¦‚ï¼šå…¬ç½‘/ç§ç½‘ã€å¹¿åŸŸç½‘ï¼‰         |
| **æ€§èƒ½**            | é«˜ï¼ˆç¡¬ä»¶ASICèŠ¯ç‰‡å¤„ç†ï¼Œè½¬å‘çº¿é€Ÿï¼‰**ç¡¬ä»¶å¤„ç†**   | ç›¸å¯¹ä½ï¼ˆä¸»è¦åŸºäºCPUå¤„ç†å³ **è½¯ä»¶å¤„ç†**ï¼Œè½¬å‘æ€§èƒ½å–å†³äºå‹å·ï¼‰ |
| **åŠŸèƒ½ä¸°å¯Œæ€§**      | ä¸€èˆ¬åŠŸèƒ½å°‘ï¼ˆé‡ç‚¹æ˜¯è½¬å‘å¿«ï¼‰                     | åŠŸèƒ½éå¸¸å…¨ï¼Œå¦‚åŠ¨æ€è·¯ç”±åè®®ã€VPNã€ACLã€QoSã€æµé‡ç­–ç•¥ç­‰        |
| **åè®®æ”¯æŒ**        | æ”¯æŒéƒ¨åˆ†è·¯ç”±åè®®ï¼ˆå¦‚ OSPFã€é™æ€è·¯ç”±ï¼‰          | æ”¯æŒå¤šç§è·¯ç”±åè®®ï¼ˆOSPFã€BGPã€RIPã€IS-ISã€EIGRP ç­‰ï¼‰          |
| **NAT/é˜²ç«å¢™**      | é€šå¸¸ä¸æ”¯æŒ                                     | åŸç”Ÿæ”¯æŒ                                                     |
| **ä»·æ ¼æˆæœ¬**        | è¾ƒä½ï¼ˆç”¨äºå±€åŸŸç½‘ï¼‰                             | é«˜ï¼ˆé€‚ç”¨äºå¹¿åŸŸç½‘ã€è¾¹ç•Œç½‘ç»œï¼‰                                 |
| **æ‰©å±•æ€§/çµæ´»æ€§**   | ä¸€èˆ¬                                           | å¾ˆå¼ºï¼ˆæ›´é€‚åˆä½œä¸ºç½‘ç»œâ€œè¾¹ç•Œè®¾å¤‡â€ï¼‰                             |
| **å¯è§†åŒ–/ç›‘æ§èƒ½åŠ›** | æœ‰é™                                           | æ›´å¼ºï¼Œé€‚åˆåšç­–ç•¥ã€æ—¥å¿—ã€ç›‘æ§ä¸­å¿ƒ                             |

```ABAP
/etc/cni/net.d/ æ˜¯ Kubernetes æˆ–å…¶ä»–ä½¿ç”¨ CNIï¼ˆContainer Network Interfaceï¼‰çš„å®¹å™¨å¹³å°ä¸­ç”¨äºå­˜æ”¾ CNI ç½‘ç»œé…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚åˆ é™¤è¯¥ç›®å½•ä¸‹çš„å†…å®¹ä¼šå¯¼è‡´æ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œä»è€Œå¯¼è‡´ç½‘ç»œå¤±æ•ˆ
åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œ/etc/cni/net.d/ è¿™ä¸ªç›®å½•åŸºæœ¬ä¸Šæ˜¯â€œé«˜å±åŒºâ€ï¼Œé€šå¸¸ä¸ä¼šè½»æ˜“åŠ¨å®ƒã€‚
ä¸€èˆ¬åªæœ‰åˆæ¬¡å®‰è£…ç½‘ç»œæ’ä»¶ï¼ˆå¦‚ flannelã€calicoï¼‰æˆ–è€… æ›´æ¢ CNI æ’ä»¶æ‰å¯èƒ½åŠ¨å®ƒ
```

![image-20250328133758938](../markdown_img/image-20250328133758938.png)

#### Flannel VXLAN é€šä¿¡è¿‡ç¨‹æ€»ç»“

- Container-1ï¼ˆ10.244.1.2ï¼‰å‘é€æ•°æ®ç»™ Container-2ï¼ˆ10.244.2.2ï¼‰

- åŸºäºContainer-1å†…çš„è·¯ç”±è¡¨ï¼Œæ•°æ®å‘ç»™ `Container-1` æ‰€åœ¨èŠ‚ç‚¹çš„ `cni0`

  ```bash
  # Container-1é‡Œçš„è·¯ç”±è¡¨
  [root@myweb-565cb68445-49fqg /]# route -n
  Kernel IP routing table
  Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
  0.0.0.0         10.244.1.1      0.0.0.0         UG    0      0        0 eth0
  10.244.0.0      10.244.1.1      255.255.0.0     UG    0      0        0 eth0
  10.244.1.0      0.0.0.0         255.255.255.0   U     0      0        0 eth0
  
  #æ‰€åœ¨èŠ‚ç‚¹çš„ip
  [root@node1 ~]# ip a show cni0
  5: cni0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000
      link/ether ca:d6:5b:9c:59:c7 brd ff:ff:ff:ff:ff:ff
      inet 10.244.1.1/24 brd 10.244.1.255 scope global cni0
         valid_lft forever preferred_lft forever
      inet6 fe80::c8d6:5bff:fe9c:59c7/64 scope link 
         valid_lft forever preferred_lft forever
  ```

- æ•°æ®åŒ…åˆ°è¾¾CNI0åï¼Œæ­¤æ—¶è¿›å…¥**å®¿ä¸»æœºç½‘ç»œåç§°ç©ºé—´**ï¼Œæ ¹æ®å®¿ä¸»æœºä¸Šçš„è·¯ç”±ï¼Œå°†æ•°æ®å‘ç»™flannel.1å¤„ç†

  ```bash
  [root@node1 ~]# route -n
  Kernel IP routing table
  Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
  0.0.0.0         11.0.1.2        0.0.0.0         UG    0      0        0 eth0
  10.244.0.0      10.244.0.0      255.255.255.0   UG    0      0        0 flannel.1
  10.244.1.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0
  10.244.2.0      10.244.2.0      255.255.255.0   UG    0      0        0 flannel.1   # å‘½ä¸­
  11.0.1.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
  172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
  
  # æ³¨æ„ï¼šè¿™é‡Œçš„ 10.244.2.0 ä½œä¸º ä¸‹ä¸€è·³ çš„å†™æ³•æ˜¯ flannel ç‰¹æœ‰ï¼Œå®ƒä¸æ˜¯æ ‡å‡†ç½‘å…³åœ°å€ï¼Œè€Œæ˜¯ Flannel è‡ªå·±è¯†åˆ«ä½¿ç”¨çš„â€œå‡ç½‘å…³â€ã€‚
  ```

- æ•°æ®åˆ°è¾¾flannel.1åï¼Œæ ¹æ®ARPè¡¨ï¼Œæ‰¾åˆ°ç›®çš„VETPè®¾å¤‡å¯¹åº”çš„MACåœ°å€(è¿™ä¸ªé‚»å±…è¡¨é¡¹æ˜¯è¢«flanneldè¿›ç¨‹å†™å…¥çš„)ï¼Œç„¶åå°è£…åœ¨ç›®çš„å®¹å™¨IPåœ°å€å‰é¢ï¼Œå¹¶åœ¨å‰é¢å°è£…VXLANçš„Headerï¼ˆå¸¦å›ºå®šçš„ VNI=1ï¼‰ï¼Œç„¶åå†æœ€å‰é¢å°è£…UDPHeaderï¼ˆUDPç«¯å£ä¸º8472ï¼‰

  ```bash
  [root@master2 ~]# ip neigh show dev flannel.1
  10.244.2.0 lladdr 72:10:86:1f:57:18 PERMANENT
  10.244.0.0 lladdr 8e:1b:9f:a8:26:96 PERMANENT    # è¡¨ç¤ºè¿™ä¸ªé‚»å±…é¡¹æ˜¯æ‰‹åŠ¨æˆ–é€šè¿‡æŸç§æœºåˆ¶å†™å…¥çš„ï¼Œä¸ä¼šè¢«ç³»ç»Ÿè‡ªåŠ¨æ¸…é™¤
  
  [root@master2 ~]# ss -unlp|grep 8472
  UNCONN 0      0            0.0.0.0:8472      0.0.0.0:* 
  ```

  ```ABAP
  åœ¨ Flannel è¿™ç±»åªæ”¯æŒå•ç§Ÿæˆ·ã€æ— éš”ç¦»éœ€æ±‚çš„åœºæ™¯ä¸­ï¼Œè¿™é‡ŒVXLANHeaderä¸­çš„ VNI æ²¡æœ‰å®é™…ç”¨é€”ï¼Œä½†ä¸ºäº†æ»¡è¶³ VXLAN åè®®æ ¼å¼ï¼Œå¿…é¡»å¡«å†™ï¼ˆå³ä½¿å®ƒä¸€ç›´æ˜¯å›ºå®šçš„ï¼Œæ¯”å¦‚ VNI=1ï¼‰
  ```

- å°è£…å®ŒUDPHeaderåï¼Œæ ¹æ®FDBï¼Œæ‰¾åˆ°ç›®çš„ VETP flannel.1 çš„ MAC åœ°å€  å¯¹åº”çš„ æ‰€åœ¨èŠ‚ç‚¹çš„ IP

  ```bash
  [root@node1 ~]$ bridge fdb show flannel.1|grep 72:10:86:1f:57:18
  72:10:86:1f:57:18 dev flannel.1 dst 11.0.1.103 self permanent      # æ ¹æ®è¿™æ¡è®°å½•æ‰¾åˆ°æ­£ç¡®çš„èŠ‚ç‚¹åœ°å€11.0.1.103
  ```

- æ‰¾åˆ°ç›®çš„IPæ‰€åœ¨èŠ‚ç‚¹çš„IPåï¼Œå°†å…¶å°è£…åœ¨æœ€å¤–å±‚ï¼Œåç»­æ ¹æ®æ­£å¸¸çš„è·¯ç”±å‘é€åˆ°ç›®çš„èŠ‚ç‚¹ï¼Œä¹Ÿå°±æ˜¯åœ¨æœ€å¤–å±‚å°è£…ä¸‹ä¸€æ¡ç½‘å…³çš„MACåœ°å€

![image-20250326172315923](../markdown_img/image-20250326172315923.png)

- åœ¨å°è£…ç›®èŠ‚ç‚¹IPçš„æ—¶å€™ï¼Œ**æº IP ä¼šè¢«æ›¿æ¢æˆå®¿ä¸»æœºèŠ‚ç‚¹çš„ IP**ï¼Œå› ä¸º**æºåœ°å€ IP ä¼šå½±å“æ•°æ®åŒ…çš„â€œè¿”å›è·¯å¾„â€å’Œâ€œä¸­é—´ç½‘ç»œè®¾å¤‡çš„è¡Œä¸ºâ€ï¼Œè¿™æ˜¯å¿…é¡»æ›¿æ¢æˆå®¿ä¸»æœº IP çš„æ ¹æœ¬åŸå› ä¹‹ä¸€ã€‚**

  ```css
  ''' æ•°æ®åŒ…å°è£…ç»“æ„å›¾ï¼ˆä»å†…åˆ°å¤–ï¼‰'''
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚          åŸå§‹Podæ•°æ®åŒ…               â”‚
  â”‚  Src IP: 10.244.1.2 (Pod1)           â”‚
  â”‚  Dst IP: 10.244.2.2 (Pod2)           â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“  å°è£…åœ¨ VXLAN payload ä¸­
  
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚             VXLAN Header             â”‚
  â”‚         VNI = 1ï¼ˆå›ºå®šå€¼ï¼‰            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“  å°è£…åœ¨ UDP ä¸­
  
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚             UDP Header               â”‚
  â”‚  Src Port: éšæœº                      â”‚
  â”‚  Dst Port: 8472ï¼ˆVXLANæ ‡å‡†ç«¯å£ï¼‰    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“  å°è£…åœ¨ IP åŒ…ä¸­
  
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚             Outer IP Header          â”‚
  â”‚  Src IP: 11.0.1.101ï¼ˆå®¿ä¸»æœº1ï¼‰       â”‚
  â”‚  Dst IP: 11.0.1.103ï¼ˆå®¿ä¸»æœº2ï¼‰       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ```

  



### Kubernetes ç½‘ç»œæ¨¡å‹ ä¸ CNI ç½‘ç»œæ’ä»¶

åœ¨ä¸Šè¿°çš„è®²è§£ä¸­ï¼Œè¿™äº›ä¾‹å­æœ‰ä¸€ä¸ªå…±æ€§ï¼Œé‚£å°±æ˜¯ç”¨æˆ·çš„å®¹å™¨éƒ½è¿æ¥åœ¨ docker0 ç½‘æ¡¥ä¸Šã€‚è€Œç½‘ç»œæ’ä»¶åˆ™åœ¨å®¿ä¸»æœºä¸Šåˆ›å»ºäº†ä¸€ä¸ªç‰¹æ®Šçš„è®¾å¤‡ï¼ˆUDP æ¨¡å¼åˆ›å»ºçš„æ˜¯ TUN è®¾å¤‡ï¼ŒVXLAN æ¨¡å¼åˆ›å»ºçš„åˆ™æ˜¯ VTEP è®¾å¤‡ï¼‰ï¼Œdocker0 ä¸è¿™ä¸ªè®¾å¤‡ä¹‹é—´ï¼Œé€šè¿‡ IP è½¬å‘ï¼ˆè·¯ç”±è¡¨ï¼‰è¿›è¡Œåä½œ

ç„¶åï¼Œç½‘ç»œæ’ä»¶çœŸæ­£è¦åšçš„äº‹æƒ…ï¼Œåˆ™æ˜¯é€šè¿‡æŸç§æ–¹æ³•ï¼ŒæŠŠä¸åŒå®¿ä¸»æœºä¸Šçš„ç‰¹æ®Šè®¾å¤‡è¿é€šï¼Œä»è€Œè¾¾åˆ°å®¹å™¨è·¨ä¸»æœºé€šä¿¡çš„ç›®çš„

ä¸Šé¢è¿™ä¸ªæµç¨‹ï¼Œä¹Ÿæ­£æ˜¯ Kubernetes å¯¹å®¹å™¨ç½‘ç»œçš„ä¸»è¦å¤„ç†æ–¹æ³•ã€‚åªä¸è¿‡ï¼ŒKubernetes æ˜¯é€šè¿‡ä¸€ä¸ªå«ä½œ CNI çš„æ¥å£ï¼Œç»´æŠ¤äº†ä¸€ä¸ªå•ç‹¬çš„ç½‘æ¡¥æ¥ä»£æ›¿ docker0ã€‚è¿™ä¸ªç½‘æ¡¥çš„åå­—å°±å«ä½œï¼šCNI ç½‘æ¡¥ï¼Œå®ƒåœ¨å®¿ä¸»æœºä¸Šçš„è®¾å¤‡åç§°é»˜è®¤æ˜¯ï¼š**cni0ã€‚**

ä»¥ Flannel çš„ VXLAN æ¨¡å¼ä¸ºä¾‹ï¼Œåœ¨ Kubernetes ç¯å¢ƒé‡Œï¼Œå®ƒçš„å·¥ä½œæ–¹å¼åªä¸è¿‡ï¼Œdocker0 ç½‘æ¡¥è¢«æ›¿æ¢æˆäº† CNI ç½‘æ¡¥è€Œå·²ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š



![image-20250327091544986](../markdown_img/image-20250327091544986.png)



åœ¨è¿™é‡Œï¼ŒKubernetes ä¸º Flannel åˆ†é…çš„å­ç½‘èŒƒå›´æ˜¯ 10.244.0.0/16ã€‚è¿™ä¸ªå‚æ•°å¯ä»¥åœ¨éƒ¨ç½²çš„æ—¶å€™æŒ‡å®šï¼Œæ¯”å¦‚ï¼š

```bash
$ kubeadm init --pod-network-cidr=10.244.0.0/16
```

ä¹Ÿå¯ä»¥åœ¨éƒ¨ç½²å®Œæˆåï¼Œé€šè¿‡ä¿®æ”¹ kube-controller-manager çš„é…ç½®æ–‡ä»¶æ¥æŒ‡å®šã€‚

è¿™æ—¶å€™ï¼Œå‡è®¾ Infra-container-1 è¦è®¿é—® Infra-container-2ï¼ˆä¹Ÿå°±æ˜¯ Pod-1 è¦è®¿é—® Pod-2ï¼‰ï¼Œè¿™ä¸ª IP åŒ…çš„æºåœ°å€å°±æ˜¯ 10.244.0.2ï¼Œç›®çš„ IP åœ°å€æ˜¯ 10.244.1.3ã€‚è€Œæ­¤æ—¶ï¼ŒInfra-container-1 é‡Œçš„ eth0 è®¾å¤‡ï¼ŒåŒæ ·æ˜¯ä»¥ Veth Pair çš„æ–¹å¼è¿æ¥åœ¨ Node 1 çš„ cni0 ç½‘æ¡¥ä¸Šã€‚æ‰€ä»¥è¿™ä¸ª IP åŒ…å°±ä¼šç»è¿‡ cni0 ç½‘æ¡¥å‡ºç°åœ¨å®¿ä¸»æœºä¸Šã€‚

æ­¤æ—¶ï¼ŒNode 1 ä¸Šçš„è·¯ç”±è¡¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
# åœ¨Node 1ä¸Š
$ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
...
10.244.0.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0
10.244.1.0      10.244.1.0      255.255.255.0   UG    0      0        0 flannel.1
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
```

ä¸ºæˆ‘ä»¬çš„ IP åŒ…çš„ç›®çš„ IP åœ°å€æ˜¯ 10.244.1.3ï¼Œæ‰€ä»¥å®ƒåªèƒ½åŒ¹é…åˆ°ç¬¬äºŒæ¡è§„åˆ™ï¼Œä¹Ÿå°±æ˜¯ 10.244.1.0 å¯¹åº”çš„è¿™æ¡è·¯ç”±è§„åˆ™ã€‚

å¯ä»¥çœ‹åˆ°ï¼Œè¿™æ¡è§„åˆ™æŒ‡å®šäº†æœ¬æœºçš„ flannel.1 è®¾å¤‡è¿›è¡Œå¤„ç†ã€‚å¹¶ä¸”ï¼Œflannel.1 åœ¨å¤„ç†å®Œåï¼Œè¦å°† IP åŒ…è½¬å‘åˆ°çš„ç½‘å…³ï¼ˆGatewayï¼‰ï¼Œæ­£æ˜¯â€œéš§é“â€å¦ä¸€ç«¯çš„ VTEP è®¾å¤‡ï¼Œä¹Ÿå°±æ˜¯ Node 2 çš„ flannel.1 è®¾å¤‡ã€‚æ‰€ä»¥ï¼Œæ¥ä¸‹æ¥çš„æµç¨‹å°±è·ŸFlannel VXLAN æ¨¡å¼å®Œå…¨ä¸€æ ·äº†ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒCNI ç½‘æ¡¥åªæ˜¯æ¥ç®¡æ‰€æœ‰ CNI æ’ä»¶è´Ÿè´£çš„ã€å³ Kubernetes åˆ›å»ºçš„å®¹å™¨ï¼ˆPodï¼‰ã€‚è€Œæ­¤æ—¶ï¼Œå¦‚æœä½ ç”¨ docker run å•ç‹¬å¯åŠ¨ä¸€ä¸ªå®¹å™¨ï¼Œé‚£ä¹ˆ Docker é¡¹ç›®è¿˜æ˜¯ä¼šæŠŠè¿™ä¸ªå®¹å™¨è¿æ¥åˆ° docker0 ç½‘æ¡¥ä¸Šã€‚æ‰€ä»¥è¿™ä¸ªå®¹å™¨çš„ IP åœ°å€ï¼Œä¸€å®šæ˜¯å±äº docker0 ç½‘æ¡¥çš„ 172.17.0.0/16 ç½‘æ®µã€‚

Kubernetes ä¹‹æ‰€ä»¥è¦è®¾ç½®è¿™æ ·ä¸€ä¸ªä¸ docker0 ç½‘æ¡¥åŠŸèƒ½å‡ ä¹ä¸€æ ·çš„ CNI ç½‘æ¡¥ï¼Œä¸»è¦åŸå› åŒ…æ‹¬ä¸¤ä¸ªæ–¹é¢ï¼š

- ä¸€æ–¹é¢ï¼ŒKubernetes é¡¹ç›®å¹¶æ²¡æœ‰ä½¿ç”¨ Docker çš„ç½‘ç»œæ¨¡å‹ï¼ˆCNMï¼‰ï¼Œæ‰€ä»¥å®ƒå¹¶ä¸å¸Œæœ›ã€ä¹Ÿä¸å…·å¤‡é…ç½® docker0 ç½‘æ¡¥çš„èƒ½åŠ›ï¼›
- å¦ä¸€æ–¹é¢ï¼Œè¿™è¿˜ä¸ Kubernetes å¦‚ä½•é…ç½® Podï¼Œä¹Ÿå°±æ˜¯ Infra å®¹å™¨çš„ Network Namespace å¯†åˆ‡ç›¸å…³ã€‚

æˆ‘ä»¬çŸ¥é“ï¼ŒKubernetes åˆ›å»ºä¸€ä¸ª Pod çš„ç¬¬ä¸€æ­¥ï¼Œå°±æ˜¯åˆ›å»ºå¹¶å¯åŠ¨ä¸€ä¸ª Infra å®¹å™¨ï¼Œç”¨æ¥â€œholdâ€ä½è¿™ä¸ª Pod çš„ Network Namespace

æ‰€ä»¥ï¼ŒCNI çš„è®¾è®¡æ€æƒ³ï¼Œå°±æ˜¯ï¼š**Kubernetes åœ¨å¯åŠ¨ Infra å®¹å™¨ä¹‹åï¼Œå°±å¯ä»¥ç›´æ¥è°ƒç”¨ CNI ç½‘ç»œæ’ä»¶ï¼Œä¸ºè¿™ä¸ª Infra å®¹å™¨çš„ Network Namespaceï¼Œé…ç½®ç¬¦åˆé¢„æœŸçš„ç½‘ç»œæ ˆ**

```ABAP
ä¸€ä¸ª Network Namespace çš„ç½‘ç»œæ ˆåŒ…æ‹¬ï¼š
ç½‘å¡ï¼ˆNetwork Interfaceï¼‰ã€å›ç¯è®¾å¤‡ï¼ˆLoopback Deviceï¼‰ã€è·¯ç”±è¡¨ï¼ˆRouting Tableï¼‰å’Œ iptables è§„åˆ™ã€‚
```



##### CNI æ’ä»¶çš„éƒ¨ç½²æ–¹å¼

é‚£ä¹ˆï¼Œè¿™ä¸ªç½‘ç»œæ ˆçš„é…ç½®å·¥ä½œåˆæ˜¯å¦‚ä½•å®Œæˆçš„å‘¢ï¼Ÿ

ä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°±éœ€è¦ä» CNI æ’ä»¶çš„éƒ¨ç½²å’Œå®ç°æ–¹å¼è°ˆèµ·äº†ã€‚

æˆ‘ä»¬åœ¨éƒ¨ç½² Kubernetes çš„æ—¶å€™ï¼Œæœ‰ä¸€ä¸ªæ­¥éª¤æ˜¯å®‰è£… kubernetes-cni åŒ…ï¼Œå®ƒçš„ç›®çš„å°±æ˜¯åœ¨å®¿ä¸»æœºä¸Šå®‰è£… CNI æ’ä»¶æ‰€éœ€çš„åŸºç¡€å¯æ‰§è¡Œæ–‡ä»¶

```ABAP
åœ¨ä½¿ç”¨ kubeadm å®‰è£… Kubernetes é›†ç¾¤çš„è¿‡ç¨‹ä¸­ï¼Œkubernetes-cni åŒ…ä½œä¸ºå®ƒä»¬çš„ä¾èµ–é¡¹è‡ªåŠ¨å®‰è£…çš„ã€‚
```

éªŒè¯

```bash
[root@node1 ~]#apt-cache depends kubelet | grep kubernetes-cni
  ä¾èµ–: kubernetes-cni
```

åœ¨å®‰è£…å®Œæˆåï¼Œä½ å¯ä»¥åœ¨å®¿ä¸»æœºçš„ /opt/cni/bin ç›®å½•ä¸‹çœ‹åˆ°å®ƒä»¬ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
[root@node1 ~]#ls -al /opt/cni/bin/
æ€»è®¡ 209428
-rwxr-xr-x 1 root root  4141145  3æœˆ 26 21:44 bandwidth
-rwxr-xr-x 1 root root  4652757  1æœˆ 11  2024 bridge
-rwxr-xr-x 1 root root 65288440  3æœˆ 26 21:44 calico
-rwxr-xr-x 1 root root 65288440  3æœˆ 26 21:44 calico-ipam
-rwxr-xr-x 1 root root 11050013  1æœˆ 11  2024 dhcp
-rwxr-xr-x 1 root root  4297556  1æœˆ 11  2024 dummy
-rwxr-xr-x 1 root root  4736299  1æœˆ 11  2024 firewall
-rwxr-xr-x 1 root root  2586700  3æœˆ 26 21:44 flannel
-rwxr-xr-x 1 root root  4191837  1æœˆ 11  2024 host-device
-rwxr-xr-x 1 root root  3637994  3æœˆ 26 21:44 host-local
-rwxr-xr-x 1 root root  4315686  1æœˆ 11  2024 ipvlan
-rwxr-xr-x 1 root root  3705893  3æœˆ 26 21:44 loopback
-rwxr-xr-x 1 root root  4349395  1æœˆ 11  2024 macvlan
-rwxr-xr-x 1 root root  4178588  3æœˆ 26 21:44 portmap
-rwxr-xr-x 1 root root  4470977  1æœˆ 11  2024 ptp
-rwxr-xr-x 1 root root  3851218  1æœˆ 11  2024 sbr
-rwxr-xr-x 1 root root  3110828  1æœˆ 11  2024 static
-rwxr-xr-x 1 root root  4371897  1æœˆ 11  2024 tap
-rwxr-xr-x 1 root root  3861557  3æœˆ 26 21:44 tuning
-rwxr-xr-x 1 root root  4310173  1æœˆ 11  2024 vlan
-rwxr-xr-x 1 root root  4001842  1æœˆ 11  2024 vrf
```

è¿™äº› CNI çš„åŸºç¡€å¯æ‰§è¡Œæ–‡ä»¶ï¼ŒæŒ‰ç…§åŠŸèƒ½å¯ä»¥åˆ†ä¸ºä¸‰ç±»ï¼š

**ç¬¬ä¸€ç±»ï¼Œå«ä½œ Main æ’ä»¶ï¼Œå®ƒæ˜¯ç”¨æ¥åˆ›å»ºå…·ä½“ç½‘ç»œè®¾å¤‡çš„äºŒè¿›åˆ¶æ–‡ä»¶**ã€‚æ¯”å¦‚ï¼Œbridgeï¼ˆç½‘æ¡¥è®¾å¤‡ï¼‰ã€ipvlanã€loopbackï¼ˆlo è®¾å¤‡ï¼‰ã€macvlanã€ptpï¼ˆVeth Pair è®¾å¤‡ï¼‰ï¼Œä»¥åŠ vlanã€‚

Flannelã€Weave ç­‰é¡¹ç›®ï¼Œéƒ½å±äºâ€œç½‘æ¡¥â€ç±»å‹çš„ CNI æ’ä»¶ã€‚æ‰€ä»¥åœ¨å…·ä½“çš„å®ç°ä¸­ï¼Œå®ƒä»¬å¾€å¾€ä¼šè°ƒç”¨ bridge è¿™ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶ã€‚

**ç¬¬äºŒç±»ï¼Œå«ä½œ IPAMï¼ˆIP Address Managementï¼‰æ’ä»¶ï¼Œå®ƒæ˜¯è´Ÿè´£åˆ†é… IP åœ°å€çš„äºŒè¿›åˆ¶æ–‡ä»¶ã€‚**æ¯”å¦‚ï¼Œdhcpï¼Œè¿™ä¸ªæ–‡ä»¶ä¼šå‘ DHCP æœåŠ¡å™¨å‘èµ·è¯·æ±‚ï¼›host-localï¼Œåˆ™ä¼šä½¿ç”¨é¢„å…ˆé…ç½®çš„ IP åœ°å€æ®µæ¥è¿›è¡Œåˆ†é…ã€‚

**ç¬¬ä¸‰ç±»ï¼Œæ˜¯ç”± CNI ç¤¾åŒºç»´æŠ¤çš„å†…ç½® CNI æ’ä»¶ã€‚**æ¯”å¦‚ï¼šflannelï¼Œå°±æ˜¯ä¸“é—¨ä¸º Flannel é¡¹ç›®æä¾›çš„ CNI æ’ä»¶ï¼›tuningï¼Œæ˜¯ä¸€ä¸ªé€šè¿‡ sysctl è°ƒæ•´ç½‘ç»œè®¾å¤‡å‚æ•°çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼›portmapï¼Œæ˜¯ä¸€ä¸ªé€šè¿‡ iptables é…ç½®ç«¯å£æ˜ å°„çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼›bandwidthï¼Œæ˜¯ä¸€ä¸ªä½¿ç”¨ Token Bucket Filter (TBF) æ¥è¿›è¡Œé™æµçš„äºŒè¿›åˆ¶æ–‡ä»¶ã€‚

ä»è¿™äº›äºŒè¿›åˆ¶æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœè¦å®ç°ä¸€ä¸ªç»™ Kubernetes ç”¨çš„å®¹å™¨ç½‘ç»œæ–¹æ¡ˆï¼Œå…¶å®éœ€è¦åšä¸¤éƒ¨åˆ†å·¥ä½œï¼Œä»¥ Flannel é¡¹ç›®ä¸ºä¾‹ï¼š

**é¦–å…ˆï¼Œå®ç°è¿™ä¸ªç½‘ç»œæ–¹æ¡ˆæœ¬èº«ã€‚**è¿™ä¸€éƒ¨åˆ†éœ€è¦ç¼–å†™çš„ï¼Œå…¶å®å°±æ˜¯ flanneld è¿›ç¨‹é‡Œçš„ä¸»è¦é€»è¾‘ã€‚æ¯”å¦‚ï¼Œåˆ›å»ºå’Œé…ç½® flannel.1 è®¾å¤‡ã€é…ç½®å®¿ä¸»æœºè·¯ç”±ã€é…ç½® ARP å’Œ FDB è¡¨é‡Œçš„ä¿¡æ¯ç­‰ç­‰ã€‚

**ç„¶åï¼Œå®ç°è¯¥ç½‘ç»œæ–¹æ¡ˆå¯¹åº”çš„ CNI æ’ä»¶**ã€‚è¿™ä¸€éƒ¨åˆ†ä¸»è¦éœ€è¦åšçš„ï¼Œå°±æ˜¯é…ç½® Infra å®¹å™¨é‡Œé¢çš„ç½‘ç»œæ ˆï¼Œå¹¶æŠŠå®ƒè¿æ¥åœ¨ CNI ç½‘æ¡¥ä¸Šã€‚

ç”±äº Flannel é¡¹ç›®å¯¹åº”çš„ CNI æ’ä»¶å·²ç»è¢«å†…ç½®äº†ï¼Œæ‰€ä»¥å®ƒæ— éœ€å†å•ç‹¬å®‰è£…ã€‚

æ¥ä¸‹æ¥ï¼Œä½ å°±éœ€è¦åœ¨å®¿ä¸»æœºä¸Šå®‰è£… flanneldï¼ˆç½‘ç»œæ–¹æ¡ˆæœ¬èº«ï¼‰ã€‚è€Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œflanneld å¯åŠ¨åä¼šåœ¨æ¯å°å®¿ä¸»æœºä¸Šç”Ÿæˆå®ƒå¯¹åº”çš„ **CNI é…ç½®æ–‡ä»¶ï¼ˆå®ƒå…¶å®æ˜¯ä¸€ä¸ª ConfigMapï¼‰**ï¼Œä»è€Œå‘Šè¯‰ Kubernetesï¼Œè¿™ä¸ªé›†ç¾¤è¦ä½¿ç”¨ Flannel ä½œä¸ºå®¹å™¨ç½‘ç»œæ–¹æ¡ˆã€‚

è¿™ä¸ª CNI é…ç½®æ–‡ä»¶çš„å†…å®¹å¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
$ cat /etc/cni/net.d/10-flannel.conflist 
{
  "name": "cbr0",
  "plugins": [
    {
      "type": "flannel",
      "delegate": {
        "hairpinMode": true,
        "isDefaultGateway": true
      }
    },
    {
      "type": "portmap",
      "capabilities": {
        "portMappings": true
      }
    }
  ]
}
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ Kubernetes ä¸­ï¼Œå¤„ç†å®¹å™¨ç½‘ç»œç›¸å…³çš„é€»è¾‘å¹¶ä¸ä¼šåœ¨ kubelet ä¸»å¹²ä»£ç é‡Œæ‰§è¡Œï¼Œè€Œæ˜¯ä¼šåœ¨å…·ä½“çš„ CRIï¼ˆContainer Runtime Interfaceï¼Œå®¹å™¨è¿è¡Œæ—¶æ¥å£ï¼‰å®ç°é‡Œå®Œæˆã€‚å¯¹äº Docker é¡¹ç›®æ¥è¯´ï¼Œè¦ç»§ç»­ä½¿ç”¨ Docker ä½œä¸ºè¿è¡Œæ—¶ï¼Œå¿…é¡»ç”¨ç¤¾åŒºç»´æŠ¤çš„ [**cri-dockerd**](https://github.com/Mirantis/cri-dockerd) é€‚é…å™¨

æ‰€ä»¥ï¼Œæ¥ä¸‹æ¥cri-dockerdä¼šåŠ è½½ä¸Šè¿°çš„CNIé…ç½®æ–‡ä»¶

éœ€è¦æ³¨æ„ï¼ŒKubernetes ç›®å‰ä¸æ”¯æŒå¤šä¸ª CNI æ’ä»¶æ··ç”¨ã€‚å¦‚æœä½ åœ¨ CNI é…ç½®ç›®å½•ï¼ˆ/etc/cni/net.dï¼‰é‡Œæ”¾ç½®äº†å¤šä¸ª CNI é…ç½®æ–‡ä»¶çš„è¯ï¼Œcri-dockerd åªä¼šåŠ è½½æŒ‰å­—æ¯é¡ºåºæ’åºçš„ç¬¬ä¸€ä¸ªæ’ä»¶ã€‚

ä½†å¦ä¸€æ–¹é¢ï¼ŒCNI å…è®¸ä½ åœ¨ä¸€ä¸ª CNI é…ç½®æ–‡ä»¶é‡Œï¼Œé€šè¿‡ plugins å­—æ®µï¼Œå®šä¹‰å¤šä¸ªæ’ä»¶è¿›è¡Œåä½œã€‚

æ¯”å¦‚ï¼Œåœ¨æˆ‘ä»¬ä¸Šé¢è¿™ä¸ªä¾‹å­é‡Œï¼ŒFlannel é¡¹ç›®å°±æŒ‡å®šäº† flannel å’Œ portmap è¿™ä¸¤ä¸ªæ’ä»¶ã€‚

**è¿™æ—¶å€™ï¼Œcri-dockerd ä¼šæŠŠè¿™ä¸ª CNI é…ç½®æ–‡ä»¶åŠ è½½èµ·æ¥ï¼Œå¹¶ä¸”æŠŠåˆ—è¡¨é‡Œçš„ç¬¬ä¸€ä¸ªæ’ä»¶ã€ä¹Ÿå°±æ˜¯ flannel æ’ä»¶ï¼Œè®¾ç½®ä¸ºé»˜è®¤æ’ä»¶ã€‚**è€Œåœ¨åé¢çš„æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œflannel å’Œ portmap æ’ä»¶ä¼šæŒ‰ç…§å®šä¹‰é¡ºåºè¢«è°ƒç”¨ï¼Œä»è€Œä¾æ¬¡å®Œæˆâ€œé…ç½®å®¹å™¨ç½‘ç»œâ€å’Œâ€œé…ç½®ç«¯å£æ˜ å°„â€è¿™ä¸¤æ­¥æ“ä½œ



##### CNI æ’ä»¶çš„å·¥ä½œåŸç†

å½“ kubelet ç»„ä»¶éœ€è¦åˆ›å»º Pod çš„æ—¶å€™ï¼Œå®ƒç¬¬ä¸€ä¸ªåˆ›å»ºçš„ä¸€å®šæ˜¯ Infra å®¹å™¨ã€‚æ‰€ä»¥åœ¨è¿™ä¸€æ­¥ï¼Œcri-dockerd å°±ä¼šå…ˆè°ƒç”¨ Docker API åˆ›å»ºå¹¶å¯åŠ¨ Infra å®¹å™¨ï¼Œç´§æ¥ç€æ‰§è¡Œä¸€ä¸ªå«ä½œ SetUpPod çš„æ–¹æ³•ã€‚è¿™ä¸ªæ–¹æ³•çš„ä½œç”¨å°±æ˜¯ï¼šä¸º CNI æ’ä»¶å‡†å¤‡å‚æ•°ï¼Œç„¶åè°ƒç”¨ CNI æ’ä»¶ä¸º Infra å®¹å™¨é…ç½®ç½‘ç»œã€‚

è¿™é‡Œè¦è°ƒç”¨çš„ CNI æ’ä»¶ï¼Œå°±æ˜¯ `/opt/cni/bin/flannel`ï¼›è€Œè°ƒç”¨å®ƒæ‰€éœ€è¦çš„å‚æ•°ï¼Œåˆ†ä¸ºä¸¤éƒ¨åˆ†ã€‚

**ç¬¬ä¸€éƒ¨åˆ†ï¼Œæ˜¯ç”± cri-dockerd è®¾ç½®çš„ä¸€ç»„ CNI ç¯å¢ƒå˜é‡**

å…¶ä¸­ï¼Œæœ€é‡è¦çš„ç¯å¢ƒå˜é‡å‚æ•°å«ä½œï¼šCNI_COMMANDã€‚å®ƒçš„å–å€¼åªæœ‰ä¸¤ç§ï¼šADD å’Œ DELã€‚

**è¿™ä¸ª ADD å’Œ DEL æ“ä½œï¼Œå°±æ˜¯ CNI æ’ä»¶å”¯ä¸€éœ€è¦å®ç°çš„ä¸¤ä¸ªæ–¹æ³•ã€‚**

å…¶ä¸­ ADD æ“ä½œçš„å«ä¹‰æ˜¯ï¼šæŠŠå®¹å™¨æ·»åŠ åˆ° CNI ç½‘ç»œé‡Œï¼›DEL æ“ä½œçš„å«ä¹‰åˆ™æ˜¯ï¼šæŠŠå®¹å™¨ä» CNI ç½‘ç»œé‡Œç§»é™¤æ‰ã€‚

è€Œå¯¹äºç½‘æ¡¥ç±»å‹çš„ CNI æ’ä»¶æ¥è¯´ï¼Œè¿™ä¸¤ä¸ªæ“ä½œæ„å‘³ç€æŠŠå®¹å™¨ä»¥ Veth Pair çš„æ–¹å¼â€œæ’â€åˆ° CNI ç½‘æ¡¥ä¸Šï¼Œæˆ–è€…ä»ç½‘æ¡¥ä¸Šâ€œæ‹”â€æ‰ã€‚



æ¥ä¸‹æ¥ï¼Œ**ä»¥ ADD æ“ä½œä¸ºé‡ç‚¹è¿›è¡Œè®²è§£**ã€‚

CNI çš„ ADD æ“ä½œéœ€è¦çš„å‚æ•°åŒ…æ‹¬ï¼š

- å®¹å™¨é‡Œç½‘å¡çš„åå­— eth0ï¼ˆCNI_IFNAMEï¼‰
- Pod çš„ Network Namespace æ–‡ä»¶çš„è·¯å¾„ï¼ˆCNI_NETNSï¼‰
- å®¹å™¨çš„ IDï¼ˆCNI_CONTAINERIDï¼‰ç­‰

è¿™äº›å‚æ•°éƒ½å±äºä¸Šè¿°ç¯å¢ƒå˜é‡é‡Œçš„å†…å®¹ã€‚å…¶ä¸­ï¼ŒPodï¼ˆInfra å®¹å™¨ï¼‰çš„ Network Namespace æ–‡ä»¶çš„è·¯å¾„ï¼Œæˆ‘åœ¨å‰é¢è®²è§£å®¹å™¨åŸºç¡€çš„æ—¶å€™æåˆ°è¿‡ï¼Œå³ï¼š`/proc/< å®¹å™¨è¿›ç¨‹çš„ PID>/ns/net`

é™¤æ­¤ä¹‹å¤–ï¼Œåœ¨ CNI ç¯å¢ƒå˜é‡é‡Œï¼Œè¿˜æœ‰ä¸€ä¸ªå«ä½œ CNI_ARGS çš„å‚æ•°ã€‚é€šè¿‡è¿™ä¸ªå‚æ•°ï¼ŒCRI å®ç°ï¼ˆæ¯”å¦‚ cri-dockerdï¼‰å°±å¯ä»¥ä»¥ Key-Value çš„æ ¼å¼ï¼Œä¼ é€’è‡ªå®šä¹‰ä¿¡æ¯ç»™ç½‘ç»œæ’ä»¶ã€‚è¿™æ˜¯ç”¨æˆ·å°†æ¥è‡ªå®šä¹‰ CNI åè®®çš„ä¸€ä¸ªé‡è¦æ–¹æ³•ã€‚

```bash
# å¦‚æœä½ æ˜¯è°ƒè¯• CNI æ’ä»¶æˆ–è‡ªå·±å†™æ’ä»¶ï¼Œå¯ä»¥é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡æ¥æµ‹è¯•æ‰§è¡Œï¼š
CNI_COMMAND=ADD \
CNI_CONTAINERID=dummy \
CNI_NETNS=/var/run/netns/test \
CNI_IFNAME=eth0 \
CNI_PATH=/opt/cni/bin \
/opt/cni/bin/bridge < /etc/cni/net.d/10-bridge.conf
```

```ABAP
åœ¨ Kubernetes ä¸­ï¼Œcri-dockerd è°ƒç”¨ CNI æ’ä»¶æ—¶æ‰€éœ€çš„ç¯å¢ƒå˜é‡ç¡®å®æ˜¯ç”± kubelet ä¼ é€’ç»™å®ƒçš„ã€‚
```

**è¯¦ç»†è§£é‡Šå¦‚ä¸‹ï¼š**

ğŸŒ 1. **Kubelet å†³å®šç½‘ç»œæ’ä»¶å’Œå‚æ•°**

å½“ kubelet å¯åŠ¨æ—¶ï¼Œå®ƒçš„å‚æ•°ä¸­ä¼šåŒ…å«å¦‚ä¸‹ä¸ CNI ç›¸å…³çš„é…ç½®

```bash
# ä¸‹é¢å‚æ•°ä¸ºé»˜è®¤å€¼
--network-plugin=cni
--cni-bin-dir=/opt/cni/bin
--cni-conf-dir=/etc/cni/net.d
```

è¿™äº›å‚æ•°å‘Šè¯‰ kubelet

- è¦ä½¿ç”¨ CNI ä½œä¸ºç½‘ç»œæ’ä»¶ï¼›
- å»å“ªé‡Œæ‰¾æ’ä»¶äºŒè¿›åˆ¶ï¼›
- å»å“ªé‡Œæ‰¾ CNI ç½‘ç»œé…ç½®æ–‡ä»¶ï¼ˆJSON æ ¼å¼ï¼‰

ğŸ”— 2. **kubelet é€šè¿‡ CRI ä¸ cri-dockerd é€šä¿¡**

- kubelet ä¸ç›´æ¥è°ƒç”¨ Dockerï¼Œè€Œæ˜¯é€šè¿‡ CRI ä¸ **cri-dockerd** é€šä¿¡ï¼›
- å½“ kubelet éœ€è¦åˆ›å»ºä¸€ä¸ª Podï¼Œå®ƒå…ˆè®© cri-dockerd åˆ›å»º **infra å®¹å™¨ï¼ˆPause å®¹å™¨ï¼‰**ï¼›
- ç„¶åè°ƒç”¨ `SetUpPod()`ï¼Œcri-dockerd å†…éƒ¨å°±ä¼šæ ¹æ®é…ç½®ï¼Œæ‰§è¡Œå¯¹åº”çš„ CNI æ’ä»¶ï¼›

ğŸ§  3. **cri-dockerd è°ƒç”¨ CNI æ’ä»¶æ—¶ä½¿ç”¨çš„ç¯å¢ƒå˜é‡**

å½“ cri-dockerd è°ƒç”¨æŸä¸ª CNI æ’ä»¶ï¼ˆå¦‚ `bridge`ã€`flannel`ï¼‰æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ â€”â€” **è¿™äº›å˜é‡çš„å€¼å°±æ˜¯ç”± kubelet ä¼ é€’ç»™ cri-dockerd çš„ï¼š**

| ç¯å¢ƒå˜é‡          | å«ä¹‰                              |
| ----------------- | --------------------------------- |
| `CNI_COMMAND`     | æ“ä½œç±»å‹ï¼ˆå¦‚ ADDã€DELï¼‰           |
| `CNI_CONTAINERID` | å®¹å™¨ IDï¼ˆå³ infra å®¹å™¨ï¼‰          |
| `CNI_NETNS`       | å®¹å™¨ç½‘ç»œå‘½åç©ºé—´è·¯å¾„              |
| `CNI_IFNAME`      | ç½‘ç»œæ¥å£åç§°ï¼Œé€šå¸¸æ˜¯ eth0         |
| `CNI_PATH`        | æ’ä»¶è·¯å¾„ï¼Œæ¥è‡ª `--cni-bin-dir`    |
| `CNI_ARGS`        | é™„åŠ ä¿¡æ¯ï¼Œå¦‚ pod åã€namespace ç­‰ |

è¿™äº›å˜é‡ä¼šä¼ é€’ç»™æ’ä»¶ï¼Œæ’ä»¶å†ä¾æ® `/etc/cni/net.d/` ä¸‹çš„ JSON æ–‡ä»¶æ‰§è¡Œå…·ä½“çš„ç½‘ç»œæ“ä½œ



**ç¬¬äºŒéƒ¨åˆ†ï¼Œåˆ™æ˜¯ cri-dockerd ä» CNI é…ç½®æ–‡ä»¶é‡ŒåŠ è½½åˆ°çš„ã€é»˜è®¤æ’ä»¶çš„é…ç½®ä¿¡æ¯ã€‚**



**ä¸Šè¿°çš„æ•´ä½“æµç¨‹æ¢³ç†å¦‚ä¸‹**

1. **Pod è¦åˆ›å»ºäº†ï¼Œkubelet å‘èµ·ç½‘ç»œåˆå§‹åŒ–**

- kubelet è´Ÿè´£è°ƒç”¨å®¹å™¨è¿è¡Œæ—¶ï¼ˆæ¯”å¦‚ `cri-dockerd`ï¼‰æ¥åˆ›å»º Podã€‚
- kubelet ä¼šä½¿ç”¨å¦‚ä¸‹å‚æ•°å‘Šè¯‰è¿è¡Œæ—¶åº”è¯¥ä½¿ç”¨å“ªç§ç½‘ç»œæ’ä»¶ï¼š

```bash
--network-plugin=cni
--cni-conf-dir=/etc/cni/net.d
--cni-bin-dir=/opt/cni/bin
```

2. **kubelet é€šè¿‡ cri-dockerd è°ƒç”¨ CNI æ’ä»¶**

- kubelet é€šè¿‡ `--container-runtime-endpoint=unix:///run/cri-dockerd.sock` è¿æ¥åˆ° `cri-dockerd`
- ç„¶åï¼Œcri-dockerd ä¼šè°ƒç”¨ `/opt/cni/bin` ç›®å½•ä¸‹çš„ CNI æ’ä»¶ï¼ˆå¦‚ flannelã€bridgeã€calicoï¼‰
- å¹¶ **ä¼ é€’å¿…è¦çš„ç¯å¢ƒå˜é‡å’Œå‚æ•°**ï¼ˆå¦‚ä¸‹ ğŸ‘‡ï¼‰

3. **ä¼ å…¥ç»™ CNI æ’ä»¶çš„å…¸å‹ç¯å¢ƒå˜é‡**

```bash
CNI_COMMAND=ADD
CNI_CONTAINERID=<å®¹å™¨ID>
CNI_IFNAME=eth0
CNI_NETNS=/proc/<pid>/ns/net
CNI_PATH=/opt/cni/bin
```

è¿™äº›ç¯å¢ƒå˜é‡ + é…ç½®æ–‡ä»¶ï¼ˆå¦‚ `/etc/cni/net.d/10-flannel.conflist`ï¼‰ä¼šä¸€èµ·äº¤ç»™æ’ä»¶æ‰§è¡Œ

4. **å¦‚æœ `.conflist` ä½¿ç”¨ `delegate`**

- å¦‚ä½ çœ‹åˆ°çš„ Flannel ç¤ºä¾‹ï¼Œå®ƒä¸ä¼šç›´æ¥è®¾ç½®ç½‘ç»œ
- å®ƒæ ¹æ® Pod çš„ä¿¡æ¯å’Œ flannel è‡ªå·±çš„çŠ¶æ€ï¼ˆå¦‚ `subnet.env`ï¼‰ç”Ÿæˆæ–°çš„é…ç½®ï¼š
  - æŠŠ bridge ç±»å‹ã€IPAM åˆ†é…ç­‰å­—æ®µå†™å…¥
- ç„¶åè°ƒç”¨å†…ç½®çš„ bridge æ’ä»¶ã€host-local æ’ä»¶æ‰§è¡Œç½‘ç»œåˆ›å»º

```ABAP
æ€»ç»“ä¸€å¥è¯ï¼š
kubelet â†’ cri-dockerd â†’ åŠ è½½ /etc/cni/net.d/*.conflist â†’ è°ƒç”¨æ’ä»¶ï¼ˆæ¯”å¦‚ flannelï¼‰â†’ flannel å†…éƒ¨é€šè¿‡ delegate å†è°ƒç”¨ bridge æ’ä»¶ç­‰ â†’ ç½‘ç»œå®Œæˆé…ç½®
```



**flannel æ”¶åˆ°ä¸Šè¿°ä¸¤éƒ¨åˆ†å‚æ•°åï¼Œç½‘ç»œé…ç½®çš„å®é™…æ‰§è¡Œè¿‡ç¨‹** 

é¦–å…ˆï¼ŒCNI bridge æ’ä»¶ä¼šåœ¨å®¿ä¸»æœºä¸Šæ£€æŸ¥ CNI ç½‘æ¡¥æ˜¯å¦å­˜åœ¨ã€‚å¦‚æœæ²¡æœ‰çš„è¯ï¼Œé‚£å°±åˆ›å»ºå®ƒã€‚è¿™ç›¸å½“äºåœ¨å®¿ä¸»æœºä¸Šæ‰§è¡Œï¼š

```bash
# åœ¨å®¿ä¸»æœºä¸Š
$ ip link add cni0 type bridge
$ ip link set cni0 up
```

æ¥ä¸‹æ¥ï¼ŒCNI bridge æ’ä»¶ä¼šé€šè¿‡ Infra å®¹å™¨çš„ Network Namespace æ–‡ä»¶ï¼Œè¿›å…¥åˆ°è¿™ä¸ª Network Namespace é‡Œé¢ï¼Œç„¶ååˆ›å»ºä¸€å¯¹ Veth Pair è®¾å¤‡ã€‚

ç´§æ¥ç€ï¼Œå®ƒä¼šæŠŠè¿™ä¸ª Veth Pair çš„å…¶ä¸­ä¸€ç«¯ï¼Œâ€œç§»åŠ¨â€åˆ°å®¿ä¸»æœºä¸Šã€‚è¿™ç›¸å½“äºåœ¨å®¹å™¨é‡Œæ‰§è¡Œå¦‚ä¸‹æ‰€ç¤ºçš„å‘½ä»¤ï¼š

```bash
#åœ¨å®¹å™¨é‡Œ

# åˆ›å»ºä¸€å¯¹Veth Pairè®¾å¤‡ã€‚å…¶ä¸­ä¸€ä¸ªå«ä½œeth0ï¼Œå¦ä¸€ä¸ªå«ä½œvethb4963f3
$ ip link add eth0 type veth peer name vethb4963f3

# å¯åŠ¨eth0è®¾å¤‡
$ ip link set eth0 up 

# å°†Veth Pairè®¾å¤‡çš„å¦ä¸€ç«¯ï¼ˆä¹Ÿå°±æ˜¯vethb4963f3è®¾å¤‡ï¼‰æ”¾åˆ°å®¿ä¸»æœºï¼ˆä¹Ÿå°±æ˜¯Host Namespaceï¼‰é‡Œ
$ ip link set vethb4963f3 netns $HOST_NS

# é€šè¿‡Host Namespaceï¼Œå¯åŠ¨å®¿ä¸»æœºä¸Šçš„vethb4963f3è®¾å¤‡
$ ip netns exec $HOST_NS ip link set vethb4963f3 up 
```

è¿™æ ·ï¼Œvethb4963f3 å°±å‡ºç°åœ¨äº†å®¿ä¸»æœºä¸Šï¼Œè€Œä¸”è¿™ä¸ª Veth Pair è®¾å¤‡çš„å¦ä¸€ç«¯ï¼Œå°±æ˜¯å®¹å™¨é‡Œé¢çš„ eth0ã€‚

å½“ç„¶ï¼Œä½ å¯èƒ½å·²ç»æƒ³åˆ°ï¼Œä¸Šè¿°åˆ›å»º Veth Pair è®¾å¤‡çš„æ“ä½œï¼Œå…¶å®ä¹Ÿå¯ä»¥å…ˆåœ¨å®¿ä¸»æœºä¸Šæ‰§è¡Œï¼Œç„¶åå†æŠŠè¯¥è®¾å¤‡çš„ä¸€ç«¯æ”¾åˆ°å®¹å™¨çš„ Network Namespace é‡Œï¼Œè¿™ä¸ªåŸç†æ˜¯ä¸€æ ·çš„ã€‚

ä¸è¿‡ï¼ŒCNI æ’ä»¶ä¹‹æ‰€ä»¥è¦â€œåç€â€æ¥ï¼Œæ˜¯å› ä¸º CNI é‡Œå¯¹ Namespace æ“ä½œå‡½æ•°çš„è®¾è®¡å°±æ˜¯å¦‚æ­¤ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
err := containerNS.Do(func(hostNS ns.NetNS) error {
  ...
  return nil
})
```

è¿™ä¸ªè®¾è®¡å…¶å®å¾ˆå®¹æ˜“ç†è§£ã€‚åœ¨ç¼–ç¨‹æ—¶ï¼Œå®¹å™¨çš„ Namespace æ˜¯å¯ä»¥ç›´æ¥é€šè¿‡ Namespace æ–‡ä»¶æ‹¿åˆ°çš„ï¼›è€Œ Host Namespaceï¼Œåˆ™æ˜¯ä¸€ä¸ªéšå«åœ¨ä¸Šä¸‹æ–‡çš„å‚æ•°ã€‚æ‰€ä»¥ï¼Œåƒä¸Šé¢è¿™æ ·ï¼Œå…ˆé€šè¿‡å®¹å™¨ Namespace è¿›å…¥å®¹å™¨é‡Œé¢ï¼Œç„¶åå†åå‘æ“ä½œ Host Namespaceï¼Œå¯¹äºç¼–ç¨‹æ¥è¯´è¦æ›´åŠ æ–¹ä¾¿ã€‚

æ¥ä¸‹æ¥ï¼ŒCNI bridge æ’ä»¶å°±å¯ä»¥æŠŠ vethb4963f3 è®¾å¤‡è¿æ¥åœ¨ CNI ç½‘æ¡¥ä¸Šã€‚è¿™ç›¸å½“äºåœ¨å®¿ä¸»æœºä¸Šæ‰§è¡Œï¼š

```bash
# åœ¨å®¿ä¸»æœºä¸Š
$ ip link set vethb4963f3 master cni0
```

åœ¨å°† vethb4963f3 è®¾å¤‡è¿æ¥åœ¨ CNI ç½‘æ¡¥ä¹‹åï¼ŒCNI bridge æ’ä»¶è¿˜ä¼šä¸ºå®ƒè®¾ç½® Hairpin Modeï¼ˆå‘å¤¹æ¨¡å¼ï¼‰ã€‚è¿™æ˜¯å› ä¸ºï¼Œåœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œç½‘æ¡¥è®¾å¤‡æ˜¯ä¸å…è®¸ä¸€ä¸ªæ•°æ®åŒ…ä»ä¸€ä¸ªç«¯å£è¿›æ¥åï¼Œå†ä»è¿™ä¸ªç«¯å£å‘å‡ºå»çš„ã€‚ä½†æ˜¯ï¼Œå®ƒå…è®¸ä½ ä¸ºè¿™ä¸ªç«¯å£å¼€å¯ Hairpin Modeï¼Œä»è€Œå–æ¶ˆè¿™ä¸ªé™åˆ¶ã€‚

è¿™ä¸ªç‰¹æ€§ï¼Œä¸»è¦ç”¨åœ¨å®¹å™¨éœ€è¦é€šè¿‡NATï¼ˆå³ï¼šç«¯å£æ˜ å°„ï¼‰çš„æ–¹å¼ï¼Œâ€œè‡ªå·±è®¿é—®è‡ªå·±â€çš„åœºæ™¯ä¸‹ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œæ¯”å¦‚æˆ‘ä»¬æ‰§è¡Œ docker run -p 8080:80ï¼Œå°±æ˜¯åœ¨å®¿ä¸»æœºä¸Šé€šè¿‡ iptables è®¾ç½®äº†ä¸€æ¡DNATï¼ˆç›®çš„åœ°å€è½¬æ¢ï¼‰è½¬å‘è§„åˆ™ã€‚è¿™æ¡è§„åˆ™çš„ä½œç”¨æ˜¯ï¼Œå½“å®¿ä¸»æœºä¸Šçš„è¿›ç¨‹è®¿é—®â€œ< å®¿ä¸»æœºçš„ IP åœ°å€ >:8080â€æ—¶ï¼Œiptables ä¼šæŠŠè¯¥è¯·æ±‚ç›´æ¥è½¬å‘åˆ°â€œ< å®¹å™¨çš„ IP åœ°å€ >:80â€ä¸Šã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ªè¯·æ±‚æœ€ç»ˆä¼šç»è¿‡ docker0 ç½‘æ¡¥è¿›å…¥å®¹å™¨é‡Œé¢ã€‚

ä½†å¦‚æœä½ æ˜¯åœ¨å®¹å™¨é‡Œé¢è®¿é—®å®¿ä¸»æœºçš„ 8080 ç«¯å£ï¼Œé‚£ä¹ˆè¿™ä¸ªå®¹å™¨é‡Œå‘å‡ºçš„ IP åŒ…ä¼šç»è¿‡ vethb4963f3 è®¾å¤‡ï¼ˆç«¯å£ï¼‰å’Œ docker0 ç½‘æ¡¥ï¼Œæ¥åˆ°å®¿ä¸»æœºä¸Šã€‚æ­¤æ—¶ï¼Œæ ¹æ®ä¸Šè¿° DNAT è§„åˆ™ï¼Œè¿™ä¸ª IP åŒ…åˆéœ€è¦å›åˆ° docker0 ç½‘æ¡¥ï¼Œå¹¶ä¸”è¿˜æ˜¯é€šè¿‡ vethb4963f3 ç«¯å£è¿›å…¥åˆ°å®¹å™¨é‡Œã€‚æ‰€ä»¥ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°±éœ€è¦å¼€å¯ vethb4963f3 ç«¯å£çš„ Hairpin Mode äº†ã€‚

æ‰€ä»¥è¯´ï¼ŒFlannel æ’ä»¶è¦åœ¨ CNI é…ç½®æ–‡ä»¶é‡Œå£°æ˜ hairpinMode=trueã€‚è¿™æ ·ï¼Œå°†æ¥è¿™ä¸ªé›†ç¾¤é‡Œçš„ Pod æ‰å¯ä»¥é€šè¿‡å®ƒè‡ªå·±çš„ Service è®¿é—®åˆ°è‡ªå·±

æ¥ä¸‹æ¥ï¼ŒCNI bridge æ’ä»¶ä¼šè°ƒç”¨ CNI ipam æ’ä»¶ï¼Œä» ipam.subnet å­—æ®µè§„å®šçš„ç½‘æ®µé‡Œä¸ºå®¹å™¨åˆ†é…ä¸€ä¸ªå¯ç”¨çš„ IP åœ°å€ã€‚ç„¶åï¼ŒCNI bridge æ’ä»¶å°±ä¼šæŠŠè¿™ä¸ª IP åœ°å€æ·»åŠ åœ¨å®¹å™¨çš„ eth0 ç½‘å¡ä¸Šï¼ŒåŒæ—¶ä¸ºå®¹å™¨è®¾ç½®é»˜è®¤è·¯ç”±ã€‚è¿™ç›¸å½“äºåœ¨å®¹å™¨é‡Œæ‰§è¡Œï¼š

```bash
# åœ¨å®¹å™¨é‡Œ
$ ip addr add 10.244.0.2/24 dev eth0
$ ip route add default via 10.244.0.1 dev eth0
```

æœ€åï¼ŒCNI bridge æ’ä»¶ä¼šä¸º CNI ç½‘æ¡¥æ·»åŠ  IP åœ°å€ã€‚è¿™ç›¸å½“äºåœ¨å®¿ä¸»æœºä¸Šæ‰§è¡Œï¼š

```bash
# åœ¨å®¿ä¸»æœºä¸Š
$ ip addr add 10.244.0.1/24 dev cni0
```

åœ¨æ‰§è¡Œå®Œä¸Šè¿°æ“ä½œä¹‹åï¼ŒCNI æ’ä»¶ä¼šæŠŠå®¹å™¨çš„ IP åœ°å€ç­‰ä¿¡æ¯è¿”å›ç»™ dockershimï¼Œç„¶åè¢« kubelet æ·»åŠ åˆ° Pod çš„ Status å­—æ®µ

è‡³æ­¤ï¼ŒCNI æ’ä»¶çš„ ADD æ–¹æ³•å°±å®£å‘Šç»“æŸäº†ã€‚æ¥ä¸‹æ¥çš„æµç¨‹ï¼Œå°±è·Ÿæˆ‘ä»¬ä¸Šä¸€ç¯‡æ–‡ç« ä¸­å®¹å™¨è·¨ä¸»æœºé€šä¿¡çš„è¿‡ç¨‹å®Œå…¨ä¸€è‡´äº†ã€‚

```ABAP
éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¯¹äºéç½‘æ¡¥ç±»å‹çš„ CNI æ’ä»¶ï¼Œä¸Šè¿°â€œå°†å®¹å™¨æ·»åŠ åˆ° CNI ç½‘ç»œâ€çš„æ“ä½œæµç¨‹ï¼Œä»¥åŠç½‘ç»œæ–¹æ¡ˆæœ¬èº«çš„å·¥ä½œåŸç†ï¼Œå°±éƒ½ä¸å¤ªä¸€æ ·äº†
```





### è§£è¯» Kubernetes ä¸‰å±‚ç½‘ç»œæ–¹æ¡ˆ

#### Flannel çš„ host-gw æ¨¡å¼

![image-20250327140420571](../markdown_img/image-20250327140420571.png)

â€‹                        

å‡è®¾ç°åœ¨ï¼ŒNode 1 ä¸Šçš„ Infra-container-1ï¼Œè¦è®¿é—® Node 2 ä¸Šçš„ Infra-container-2

å½“ä½ è®¾ç½® Flannel ä½¿ç”¨ host-gw æ¨¡å¼ä¹‹åï¼Œflanneld ä¼šåœ¨å®¿ä¸»æœºä¸Šåˆ›å»ºè¿™æ ·ä¸€æ¡è§„åˆ™ï¼Œä»¥ Node 1 ä¸ºä¾‹ï¼š

```bash
$ ip route
...
10.244.1.0/24 via 10.168.0.3 dev eth0
```

è¿™æ¡è·¯ç”±è§„åˆ™çš„å«ä¹‰æ˜¯ï¼šç›®çš„ IP åœ°å€å±äº 10.244.1.0/24 ç½‘æ®µçš„ IP åŒ…ï¼Œåº”è¯¥ç»è¿‡æœ¬æœºçš„ eth0 è®¾å¤‡å‘å‡ºå»ï¼ˆå³ï¼šdev eth0ï¼‰ï¼›å¹¶ä¸”ï¼Œå®ƒä¸‹ä¸€è·³åœ°å€ï¼ˆnext-hopï¼‰æ˜¯ 10.168.0.3ï¼ˆå³ï¼švia 10.168.0.3ï¼‰ã€‚

æ‰€è°“ä¸‹ä¸€è·³åœ°å€å°±æ˜¯ï¼šå¦‚æœ IP åŒ…ä»ä¸»æœº A å‘åˆ°ä¸»æœº Bï¼Œéœ€è¦ç»è¿‡è·¯ç”±è®¾å¤‡ X çš„ä¸­è½¬ã€‚é‚£ä¹ˆ X çš„ IP åœ°å€å°±åº”è¯¥é…ç½®ä¸ºä¸»æœº A çš„ä¸‹ä¸€è·³åœ°å€ã€‚

è€Œä» host-gw ç¤ºæ„å›¾ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ªä¸‹ä¸€è·³åœ°å€å¯¹åº”çš„ï¼Œæ­£æ˜¯æˆ‘ä»¬çš„ç›®çš„å®¿ä¸»æœº Node 2ã€‚

ä¸€æ—¦é…ç½®äº†ä¸‹ä¸€è·³åœ°å€ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥ï¼Œå½“ IP åŒ…ä»ç½‘ç»œå±‚è¿›å…¥é“¾è·¯å±‚å°è£…æˆå¸§çš„æ—¶å€™ï¼Œeth0 è®¾å¤‡å°±ä¼šä½¿ç”¨ä¸‹ä¸€è·³åœ°å€å¯¹åº”çš„ MAC åœ°å€ï¼Œä½œä¸ºè¯¥æ•°æ®å¸§çš„ç›®çš„ MAC åœ°å€ã€‚æ˜¾ç„¶ï¼Œè¿™ä¸ª MAC åœ°å€ï¼Œæ­£æ˜¯ Node 2 çš„ MAC åœ°å€ã€‚

è¿™æ ·ï¼Œè¿™ä¸ªæ•°æ®å¸§å°±ä¼šä» Node 1 é€šè¿‡å®¿ä¸»æœºçš„äºŒå±‚ç½‘ç»œé¡ºåˆ©åˆ°è¾¾ Node 2 ä¸Šã€‚

å¯ä»¥çœ‹åˆ°ï¼Œ**host-gw æ¨¡å¼çš„å·¥ä½œåŸç†ï¼Œå…¶å®å°±æ˜¯å°†æ¯ä¸ª Flannel å­ç½‘ï¼ˆFlannel Subnetï¼Œæ¯”å¦‚ï¼š10.244.1.0/24ï¼‰çš„â€œä¸‹ä¸€è·³â€ï¼Œè®¾ç½®æˆäº†è¯¥å­ç½‘å¯¹åº”çš„å®¿ä¸»æœºçš„ IP åœ°å€ã€‚**

 ```ABAP
 ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™å°â€œä¸»æœºâ€ï¼ˆHostï¼‰ä¼šå……å½“è¿™æ¡å®¹å™¨é€šä¿¡è·¯å¾„é‡Œçš„â€œç½‘å…³â€ï¼ˆGatewayï¼‰ã€‚è¿™ä¹Ÿæ­£æ˜¯â€œhost-gwâ€çš„å«ä¹‰ã€‚
 ```

å½“ç„¶ï¼ŒFlannel å­ç½‘å’Œä¸»æœºçš„ä¿¡æ¯ï¼Œéƒ½æ˜¯ä¿å­˜åœ¨ Etcd å½“ä¸­çš„ã€‚flanneld åªéœ€è¦ WACTH è¿™äº›æ•°æ®çš„å˜åŒ–ï¼Œç„¶åå®æ—¶æ›´æ–°è·¯ç”±è¡¨å³å¯ã€‚

```ABAP
æ³¨æ„ï¼šåœ¨ Kubernetes v1.7 ä¹‹åï¼Œç±»ä¼¼ Flannelã€Calico çš„ CNI ç½‘ç»œæ’ä»¶éƒ½æ˜¯å¯ä»¥ç›´æ¥è¿æ¥ Kubernetes çš„ APIServer æ¥è®¿é—® Etcd çš„ï¼Œæ— éœ€é¢å¤–éƒ¨ç½² Etcd ç»™å®ƒä»¬ä½¿ç”¨ã€‚
```

è€Œåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œå®¹å™¨é€šä¿¡çš„è¿‡ç¨‹å°±å…é™¤äº†é¢å¤–çš„å°åŒ…å’Œè§£åŒ…å¸¦æ¥çš„æ€§èƒ½æŸè€—ã€‚æ ¹æ®å®é™…çš„æµ‹è¯•ï¼Œ**host-gw çš„æ€§èƒ½æŸå¤±å¤§çº¦åœ¨ 10% å·¦å³**ï¼Œè€Œ**å…¶ä»–æ‰€æœ‰åŸºäº VXLANâ€œéš§é“â€æœºåˆ¶çš„ç½‘ç»œæ–¹æ¡ˆï¼Œæ€§èƒ½æŸå¤±éƒ½åœ¨ 20%~30% å·¦å³ã€‚**

å½“ç„¶ï¼Œé€šè¿‡ä¸Šé¢çš„å™è¿°ï¼Œä½ ä¹Ÿåº”è¯¥çœ‹åˆ°ï¼Œhost-gw æ¨¡å¼èƒ½å¤Ÿæ­£å¸¸å·¥ä½œçš„æ ¸å¿ƒï¼Œå°±åœ¨äº IP åŒ…åœ¨å°è£…æˆå¸§å‘é€å‡ºå»çš„æ—¶å€™ï¼Œä¼šä½¿ç”¨è·¯ç”±è¡¨é‡Œçš„â€œä¸‹ä¸€è·³â€æ¥è®¾ç½®ç›®çš„ MAC åœ°å€ã€‚è¿™æ ·ï¼Œå®ƒå°±ä¼šç»è¿‡äºŒå±‚ç½‘ç»œåˆ°è¾¾ç›®çš„å®¿ä¸»æœºã€‚

```ABAP
æ‰€ä»¥è¯´ï¼ŒFlannel host-gw æ¨¡å¼å¿…é¡»è¦æ±‚é›†ç¾¤å®¿ä¸»æœºä¹‹é—´æ˜¯äºŒå±‚è¿é€šçš„ã€‚
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå®¿ä¸»æœºä¹‹é—´äºŒå±‚ä¸è¿é€šçš„æƒ…å†µä¹Ÿæ˜¯å¹¿æ³›å­˜åœ¨çš„ã€‚æ¯”å¦‚ï¼Œå®¿ä¸»æœºåˆ†å¸ƒåœ¨äº†ä¸åŒçš„å­ç½‘ï¼ˆVLANï¼‰é‡Œã€‚ä½†æ˜¯ï¼Œåœ¨ä¸€ä¸ª Kubernetes é›†ç¾¤é‡Œï¼Œå®¿ä¸»æœºä¹‹é—´å¿…é¡»å¯ä»¥é€šè¿‡ IP åœ°å€è¿›è¡Œé€šä¿¡ï¼Œä¹Ÿå°±æ˜¯è¯´è‡³å°‘æ˜¯ä¸‰å±‚å¯è¾¾çš„ã€‚å¦åˆ™çš„è¯ï¼Œä½ çš„é›†ç¾¤å°†ä¸æ»¡è¶³ä¸Šä¸€ç¯‡æ–‡ç« ä¸­æåˆ°çš„å®¿ä¸»æœºä¹‹é—´ IP äº’é€šçš„å‡è®¾ï¼ˆKubernetes ç½‘ç»œæ¨¡å‹ï¼‰ã€‚å½“ç„¶ï¼Œâ€œä¸‰å±‚å¯è¾¾â€ä¹Ÿå¯ä»¥é€šè¿‡ä¸ºå‡ ä¸ªå­ç½‘è®¾ç½®ä¸‰å±‚è½¬å‘æ¥å®ç°ã€‚            

```ABAP
è€Œåœ¨å®¹å™¨ç”Ÿæ€ä¸­ï¼Œè¦è¯´åˆ°åƒ Flannel host-gw è¿™æ ·çš„ä¸‰å±‚ç½‘ç»œæ–¹æ¡ˆï¼Œæˆ‘ä»¬å°±ä¸å¾—ä¸æåˆ°è¿™ä¸ªé¢†åŸŸé‡Œçš„â€œé¾™å¤´è€å¤§â€Calico é¡¹ç›®äº†ã€‚
```

å®é™…ä¸Šï¼ŒCalico é¡¹ç›®æä¾›çš„ç½‘ç»œè§£å†³æ–¹æ¡ˆï¼Œä¸ Flannel çš„ host-gw æ¨¡å¼ï¼Œå‡ ä¹æ˜¯å®Œå…¨ä¸€æ ·çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒCalico ä¹Ÿä¼šåœ¨æ¯å°å®¿ä¸»æœºä¸Šï¼Œæ·»åŠ ä¸€ä¸ªæ ¼å¼å¦‚ä¸‹æ‰€ç¤ºçš„è·¯ç”±è§„åˆ™ï¼š

```bash
<ç›®çš„å®¹å™¨IPåœ°å€æ®µ> via <ç½‘å…³çš„IPåœ°å€> dev eth0
```

æ­£å¦‚å‰æ‰€è¿°ï¼Œ**è¿™ä¸ªä¸‰å±‚ç½‘ç»œæ–¹æ¡ˆå¾—ä»¥æ­£å¸¸å·¥ä½œçš„æ ¸å¿ƒï¼Œæ˜¯ä¸ºæ¯ä¸ªå®¹å™¨çš„ IP åœ°å€ï¼Œæ‰¾åˆ°å®ƒæ‰€å¯¹åº”çš„ã€â€œä¸‹ä¸€è·³â€çš„ç½‘å…³ã€‚**

```ABAP
ä¸åŒäº Flannel é€šè¿‡ Etcd å’Œå®¿ä¸»æœºä¸Šçš„ flanneld æ¥ç»´æŠ¤è·¯ç”±ä¿¡æ¯çš„åšæ³•ï¼ŒCalico é¡¹ç›®ä½¿ç”¨äº†ä¸€ä¸ªâ€œé‡å‹æ­¦å™¨â€æ¥è‡ªåŠ¨åœ°åœ¨æ•´ä¸ªé›†ç¾¤ä¸­åˆ†å‘è·¯ç”±ä¿¡æ¯ã€‚
è¿™ä¸ªâ€œé‡å‹æ­¦å™¨â€ï¼Œå°±æ˜¯ BGPã€‚
```

**BGP çš„å…¨ç§°æ˜¯ Border Gateway Protocolï¼Œå³ï¼šè¾¹ç•Œç½‘å…³åè®®**ã€‚å®ƒæ˜¯ä¸€ä¸ª Linux å†…æ ¸åŸç”Ÿå°±æ”¯æŒçš„ã€ä¸“é—¨ç”¨åœ¨å¤§è§„æ¨¡æ•°æ®ä¸­å¿ƒé‡Œç»´æŠ¤ä¸åŒçš„â€œè‡ªæ²»ç³»ç»Ÿâ€ä¹‹é—´è·¯ç”±ä¿¡æ¯çš„ã€æ— ä¸­å¿ƒçš„è·¯ç”±åè®®ã€‚



#### BGPç®€è¿°

![image-20250327141505381](../markdown_img/image-20250327141505381.png)

â€‹                       

åœ¨è¿™ä¸ªå›¾ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªè‡ªæ²»ç³»ç»Ÿï¼ˆAutonomous Systemï¼Œç®€ç§°ä¸º ASï¼‰ï¼šAS 1 å’Œ AS 2ã€‚è€Œæ‰€è°“çš„ä¸€ä¸ªè‡ªæ²»ç³»ç»Ÿï¼ŒæŒ‡çš„æ˜¯ä¸€ä¸ªç»„ç»‡ç®¡è¾–ä¸‹çš„æ‰€æœ‰ IP ç½‘ç»œå’Œè·¯ç”±å™¨çš„å…¨ä½“ã€‚ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªå°å…¬å¸é‡Œçš„æ‰€æœ‰ä¸»æœºå’Œè·¯ç”±å™¨ã€‚åœ¨æ­£å¸¸æƒ…å†µä¸‹ï¼Œè‡ªæ²»ç³»ç»Ÿä¹‹é—´ä¸ä¼šæœ‰ä»»ä½•â€œæ¥å¾€â€ã€‚

ä½†æ˜¯ï¼Œå¦‚æœè¿™æ ·ä¸¤ä¸ªè‡ªæ²»ç³»ç»Ÿé‡Œçš„ä¸»æœºï¼Œè¦é€šè¿‡ IP åœ°å€ç›´æ¥è¿›è¡Œé€šä¿¡ï¼Œæˆ‘ä»¬å°±å¿…é¡»ä½¿ç”¨è·¯ç”±å™¨æŠŠè¿™ä¸¤ä¸ªè‡ªæ²»ç³»ç»Ÿè¿æ¥èµ·æ¥

å¦‚ï¼ŒAS 1 é‡Œé¢çš„ä¸»æœº 10.10.0.2ï¼Œè¦è®¿é—® AS 2 é‡Œé¢çš„ä¸»æœº 172.17.0.3 çš„è¯ã€‚å®ƒå‘å‡ºçš„ IP åŒ…ï¼Œå°±ä¼šå…ˆåˆ°è¾¾è‡ªæ²»ç³»ç»Ÿ AS 1 ä¸Šçš„è·¯ç”±å™¨ Router 1ã€‚

è€Œåœ¨æ­¤æ—¶ï¼ŒRouter 1 çš„è·¯ç”±è¡¨é‡Œï¼Œæœ‰è¿™æ ·ä¸€æ¡è§„åˆ™ï¼Œå³ï¼šç›®çš„åœ°å€æ˜¯ 172.17.0.2 åŒ…ï¼Œåº”è¯¥ç»è¿‡ Router 1 çš„ C æ¥å£ï¼Œå‘å¾€ç½‘å…³ Router 2ï¼ˆå³ï¼šè‡ªæ²»ç³»ç»Ÿ AS 2 ä¸Šçš„è·¯ç”±å™¨ï¼‰ã€‚

æ‰€ä»¥ IP åŒ…å°±ä¼šåˆ°è¾¾ Router 2 ä¸Šï¼Œç„¶åç»è¿‡ Router 2 çš„è·¯ç”±è¡¨ï¼Œä» B æ¥å£å‡ºæ¥åˆ°è¾¾ç›®çš„ä¸»æœº 172.17.0.3ã€‚

ä½†æ˜¯åè¿‡æ¥ï¼Œå¦‚æœä¸»æœº 172.17.0.3 è¦è®¿é—® 10.10.0.2ï¼Œé‚£ä¹ˆè¿™ä¸ª IP åŒ…ï¼Œåœ¨åˆ°è¾¾ Router 2 ä¹‹åï¼Œå°±ä¸çŸ¥é“è¯¥å»å“ªå„¿äº†ã€‚å› ä¸ºåœ¨ Router 2 çš„è·¯ç”±è¡¨é‡Œï¼Œå¹¶æ²¡æœ‰å…³äº AS 1 è‡ªæ²»ç³»ç»Ÿçš„ä»»ä½•è·¯ç”±è§„åˆ™ã€‚

æ‰€ä»¥è¿™æ—¶å€™ï¼Œç½‘ç»œç®¡ç†å‘˜å°±åº”è¯¥ç»™ Router 2 ä¹Ÿæ·»åŠ ä¸€æ¡è·¯ç”±è§„åˆ™ï¼Œæ¯”å¦‚ï¼šç›®æ ‡åœ°å€æ˜¯ 10.10.0.2 çš„ IP åŒ…ï¼Œåº”è¯¥ç»è¿‡ Router 2 çš„ C æ¥å£ï¼Œå‘å¾€ç½‘å…³ Router 1ã€‚

ä¸Šé¢è¿™æ ·è´Ÿè´£æŠŠè‡ªæ²»ç³»ç»Ÿè¿æ¥åœ¨ä¸€èµ·çš„è·¯ç”±å™¨ï¼Œæˆ‘ä»¬å°±æŠŠå®ƒå½¢è±¡åœ°ç§°ä¸ºï¼š**è¾¹ç•Œç½‘å…³**ã€‚å®ƒè·Ÿæ™®é€šè·¯ç”±å™¨çš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œå®ƒçš„è·¯ç”±è¡¨é‡Œæ‹¥æœ‰å…¶ä»–è‡ªæ²»ç³»ç»Ÿé‡Œçš„ä¸»æœºè·¯ç”±ä¿¡æ¯ã€‚

ä¸Šé¢çš„è¿™éƒ¨åˆ†åŸç†ï¼Œç›¸ä¿¡ä½ ç†è§£èµ·æ¥åº”è¯¥å¾ˆå®¹æ˜“ã€‚æ¯•ç«Ÿï¼Œè·¯ç”±å™¨è¿™ä¸ªè®¾å¤‡æœ¬èº«çš„ä¸»è¦ä½œç”¨ï¼Œå°±æ˜¯è¿é€šä¸åŒçš„ç½‘ç»œã€‚

ä½†æ˜¯ï¼Œä½ å¯ä»¥æƒ³è±¡ä¸€ä¸‹ï¼Œå‡è®¾æˆ‘ä»¬ç°åœ¨çš„ç½‘ç»œæ‹“æ‰‘ç»“æ„éå¸¸å¤æ‚ï¼Œæ¯ä¸ªè‡ªæ²»ç³»ç»Ÿéƒ½æœ‰æˆåƒä¸Šä¸‡ä¸ªä¸»æœºã€æ— æ•°ä¸ªè·¯ç”±å™¨ï¼Œç”šè‡³æ˜¯ç”±å¤šä¸ªå…¬å¸ã€å¤šä¸ªç½‘ç»œæä¾›å•†ã€å¤šä¸ªè‡ªæ²»ç³»ç»Ÿç»„æˆçš„å¤åˆè‡ªæ²»ç³»ç»Ÿå‘¢ï¼Ÿ

è¿™æ—¶å€™ï¼Œå¦‚æœè¿˜è¦ä¾é äººå·¥æ¥å¯¹è¾¹ç•Œç½‘å…³çš„è·¯ç”±è¡¨è¿›è¡Œé…ç½®å’Œç»´æŠ¤ï¼Œé‚£æ˜¯ç»å¯¹ä¸ç°å®çš„

è€Œè¿™ç§æƒ…å†µä¸‹ï¼ŒBGP å¤§æ˜¾èº«æ‰‹çš„æ—¶åˆ»å°±åˆ°äº†ã€‚

åœ¨ä½¿ç”¨äº† BGP ä¹‹åï¼Œä½ å¯ä»¥è®¤ä¸ºï¼Œåœ¨æ¯ä¸ªè¾¹ç•Œç½‘å…³ä¸Šéƒ½ä¼šè¿è¡Œç€ä¸€ä¸ªå°ç¨‹åºï¼Œå®ƒä»¬ä¼šå°†å„è‡ªçš„è·¯ç”±è¡¨ä¿¡æ¯ï¼Œé€šè¿‡ TCP ä¼ è¾“ç»™å…¶ä»–çš„è¾¹ç•Œç½‘å…³ã€‚è€Œå…¶ä»–è¾¹ç•Œç½‘å…³ä¸Šçš„è¿™ä¸ªå°ç¨‹åºï¼Œåˆ™ä¼šå¯¹æ”¶åˆ°çš„è¿™äº›æ•°æ®è¿›è¡Œåˆ†æï¼Œç„¶åå°†éœ€è¦çš„ä¿¡æ¯æ·»åŠ åˆ°è‡ªå·±çš„è·¯ç”±è¡¨é‡Œã€‚

è¿™æ ·ï¼Œå›¾ 2 ä¸­ Router 2 çš„è·¯ç”±è¡¨é‡Œï¼Œå°±ä¼šè‡ªåŠ¨å‡ºç° 10.10.0.2 å’Œ 10.10.0.3 å¯¹åº”çš„è·¯ç”±è§„åˆ™äº†ã€‚

æ‰€ä»¥è¯´ï¼Œ**æ‰€è°“ BGPï¼Œå°±æ˜¯åœ¨å¤§è§„æ¨¡ç½‘ç»œä¸­å®ç°èŠ‚ç‚¹è·¯ç”±ä¿¡æ¯å…±äº«çš„ä¸€ç§åè®®ã€‚**

**å…³äºBGPçš„è¯¦ç»†çŸ¥è¯†ï¼Œè¯¦æƒ…è§çŸ¥è¯†æ‰©å±•**

åœ¨äº†è§£äº† BGP ä¹‹åï¼ŒCalico é¡¹ç›®çš„æ¶æ„å°±éå¸¸å®¹æ˜“ç†è§£äº†ã€‚å®ƒç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼š

- **Calico çš„ CNI æ’ä»¶**ã€‚è¿™æ˜¯ Calico ä¸ Kubernetes å¯¹æ¥çš„éƒ¨åˆ†ã€‚æˆ‘å·²ç»åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­ï¼Œå’Œä½ è¯¦ç»†åˆ†äº«äº† CNI æ’ä»¶çš„å·¥ä½œåŸç†ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°äº†ã€‚
- **Felix**ã€‚å®ƒæ˜¯ä¸€ä¸ª DaemonSetï¼Œè´Ÿè´£åœ¨å®¿ä¸»æœºä¸Šæ’å…¥è·¯ç”±è§„åˆ™ï¼ˆå³ï¼šå†™å…¥ Linux å†…æ ¸çš„ FIB è½¬å‘ä¿¡æ¯åº“ï¼‰ï¼Œä»¥åŠç»´æŠ¤ Calico æ‰€éœ€çš„ç½‘ç»œè®¾å¤‡ç­‰å·¥ä½œã€‚
- **BIRD**ã€‚å®ƒå°±æ˜¯ BGP çš„å®¢æˆ·ç«¯ï¼Œä¸“é—¨è´Ÿè´£åœ¨é›†ç¾¤é‡Œåˆ†å‘è·¯ç”±è§„åˆ™ä¿¡æ¯ã€‚

**é™¤äº†å¯¹è·¯ç”±ä¿¡æ¯çš„ç»´æŠ¤æ–¹å¼ä¹‹å¤–ï¼ŒCalico é¡¹ç›®ä¸ Flannel çš„ host-gw æ¨¡å¼çš„å¦ä¸€ä¸ªä¸åŒä¹‹å¤„ï¼Œå°±æ˜¯å®ƒä¸ä¼šåœ¨å®¿ä¸»æœºä¸Šåˆ›å»ºä»»ä½•ç½‘æ¡¥è®¾å¤‡ã€‚**è¿™æ—¶å€™ï¼ŒCalico çš„å·¥ä½œæ–¹å¼ï¼Œå¯ä»¥ç”¨ä¸€å¹…ç¤ºæ„å›¾æ¥æè¿°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆåœ¨æ¥ä¸‹æ¥çš„è®²è¿°ä¸­ï¼Œæˆ‘ä¼šç»Ÿä¸€ç”¨â€œBGP ç¤ºæ„å›¾â€æ¥æŒ‡ä»£å®ƒï¼‰ï¼š

![image-20250327142246955](../markdown_img/image-20250327142246955.png)

å…¶ä¸­çš„ç»¿è‰²å®çº¿æ ‡å‡ºçš„è·¯å¾„ï¼Œå°±æ˜¯ä¸€ä¸ª IP åŒ…ä» Node 1 ä¸Šçš„ Container 1ï¼Œåˆ°è¾¾ Node 2 ä¸Šçš„ Container 4 çš„å®Œæ•´è·¯å¾„

å¯ä»¥çœ‹åˆ°ï¼ŒCalico çš„ CNI æ’ä»¶ä¼šä¸ºæ¯ä¸ªå®¹å™¨è®¾ç½®ä¸€ä¸ª Veth Pair è®¾å¤‡ï¼Œç„¶åæŠŠå…¶ä¸­çš„ä¸€ç«¯æ”¾ç½®åœ¨å®¿ä¸»æœºä¸Šï¼ˆå®ƒçš„åå­—ä»¥ cali å‰ç¼€å¼€å¤´ï¼‰ã€‚

æ­¤å¤–ï¼Œç”±äº Calico æ²¡æœ‰ä½¿ç”¨ CNI çš„ç½‘æ¡¥æ¨¡å¼ï¼ŒCalico çš„ CNI æ’ä»¶è¿˜éœ€è¦åœ¨å®¿ä¸»æœºä¸Šä¸ºæ¯ä¸ªå®¹å™¨çš„ Veth Pair è®¾å¤‡é…ç½®ä¸€æ¡è·¯ç”±è§„åˆ™ï¼Œç”¨äºæ¥æ”¶ä¼ å…¥çš„ IP åŒ…ã€‚æ¯”å¦‚ï¼Œå®¿ä¸»æœº Node 2 ä¸Šçš„ Container 4 å¯¹åº”çš„è·¯ç”±è§„åˆ™ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
10.233.2.3 dev cali5863f3 scope link
# å³ï¼šå‘å¾€ 10.233.2.3 çš„ IP åŒ…ï¼Œåº”è¯¥è¿›å…¥ cali5863f3 è®¾å¤‡ã€‚
```

æœ‰äº†è¿™æ ·çš„ Veth Pair è®¾å¤‡ä¹‹åï¼Œå®¹å™¨å‘å‡ºçš„ IP åŒ…å°±ä¼šç»è¿‡ Veth Pair è®¾å¤‡å‡ºç°åœ¨å®¿ä¸»æœºä¸Šã€‚ç„¶åï¼Œå®¿ä¸»æœºç½‘ç»œæ ˆå°±ä¼šæ ¹æ®è·¯ç”±è§„åˆ™çš„ä¸‹ä¸€è·³ IP åœ°å€ï¼ŒæŠŠå®ƒä»¬è½¬å‘ç»™æ­£ç¡®çš„ç½‘å…³ã€‚æ¥ä¸‹æ¥çš„æµç¨‹å°±è·Ÿ Flannel host-gw æ¨¡å¼å®Œå…¨ä¸€è‡´äº†ã€‚

å…¶ä¸­ï¼Œ**è¿™é‡Œæœ€æ ¸å¿ƒçš„â€œä¸‹ä¸€è·³â€è·¯ç”±è§„åˆ™ï¼Œå°±æ˜¯ç”± Calico çš„ Felix è¿›ç¨‹è´Ÿè´£ç»´æŠ¤çš„ã€‚**è¿™äº›è·¯ç”±è§„åˆ™ä¿¡æ¯ï¼Œåˆ™æ˜¯é€šè¿‡ BGP Client ä¹Ÿå°±æ˜¯ BIRD ç»„ä»¶ï¼Œä½¿ç”¨ BGP åè®®ä¼ è¾“è€Œæ¥çš„ã€‚

è€Œè¿™äº›é€šè¿‡ BGP åè®®ä¼ è¾“çš„æ¶ˆæ¯ï¼Œä½ å¯ä»¥ç®€å•åœ°ç†è§£ä¸ºå¦‚ä¸‹æ ¼å¼ï¼š

```bash
[BGPæ¶ˆæ¯]
æˆ‘æ˜¯å®¿ä¸»æœº192.168.1.3
10.233.2.0/24ç½‘æ®µçš„å®¹å™¨éƒ½åœ¨æˆ‘è¿™é‡Œ
è¿™äº›å®¹å™¨çš„ä¸‹ä¸€è·³åœ°å€æ˜¯æˆ‘
```

ä¸éš¾å‘ç°ï¼ŒCalico é¡¹ç›®å®é™…ä¸Šå°†é›†ç¾¤é‡Œçš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œéƒ½å½“ä½œæ˜¯è¾¹ç•Œè·¯ç”±å™¨æ¥å¤„ç†ï¼Œå®ƒä»¬ä¸€èµ·ç»„æˆäº†ä¸€ä¸ªå…¨è¿é€šçš„ç½‘ç»œï¼Œäº’ç›¸ä¹‹é—´é€šè¿‡ BGP åè®®äº¤æ¢è·¯ç”±è§„åˆ™ã€‚è¿™äº›èŠ‚ç‚¹ï¼Œæˆ‘ä»¬ç§°ä¸º **BGP Peer**ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒCalico ç»´æŠ¤çš„ç½‘ç»œåœ¨é»˜è®¤é…ç½®ä¸‹ï¼Œæ˜¯ä¸€ä¸ªè¢«ç§°ä¸ºâ€œNode-to-Node Meshâ€çš„æ¨¡å¼ã€‚è¿™æ—¶å€™ï¼Œæ¯å°å®¿ä¸»æœºä¸Šçš„ BGP Client éƒ½éœ€è¦è·Ÿå…¶ä»–æ‰€æœ‰èŠ‚ç‚¹çš„ BGP Client è¿›è¡Œé€šä¿¡ä»¥ä¾¿äº¤æ¢è·¯ç”±ä¿¡æ¯ã€‚ä½†æ˜¯ï¼Œéšç€èŠ‚ç‚¹æ•°é‡ N çš„å¢åŠ ï¼Œè¿™äº›è¿æ¥çš„æ•°é‡å°±ä¼šä»¥ NÂ²çš„è§„æ¨¡å¿«é€Ÿå¢é•¿ï¼Œä»è€Œç»™é›†ç¾¤æœ¬èº«çš„ç½‘ç»œå¸¦æ¥å·¨å¤§çš„å‹åŠ›ã€‚

æ‰€ä»¥ï¼ŒNode-to-Node Mesh æ¨¡å¼ä¸€èˆ¬æ¨èç”¨åœ¨å°‘äº 100 ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤é‡Œã€‚è€Œåœ¨æ›´å¤§è§„æ¨¡çš„é›†ç¾¤ä¸­ï¼Œä½ éœ€è¦ç”¨åˆ°çš„æ˜¯ä¸€ä¸ªå«ä½œ **Route Reflector** çš„æ¨¡å¼ã€‚

åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼ŒCalico ä¼šæŒ‡å®šä¸€ä¸ªæˆ–è€…å‡ ä¸ªä¸“é—¨çš„èŠ‚ç‚¹ï¼Œæ¥è´Ÿè´£è·Ÿæ‰€æœ‰èŠ‚ç‚¹å»ºç«‹ BGP è¿æ¥ä»è€Œå­¦ä¹ åˆ°å…¨å±€çš„è·¯ç”±è§„åˆ™ã€‚è€Œå…¶ä»–èŠ‚ç‚¹ï¼Œåªéœ€è¦è·Ÿè¿™å‡ ä¸ªä¸“é—¨çš„èŠ‚ç‚¹äº¤æ¢è·¯ç”±ä¿¡æ¯ï¼Œå°±å¯ä»¥è·å¾—æ•´ä¸ªé›†ç¾¤çš„è·¯ç”±è§„åˆ™ä¿¡æ¯äº†ã€‚

è¿™äº›ä¸“é—¨çš„èŠ‚ç‚¹ï¼Œå°±æ˜¯æ‰€è°“çš„ Route Reflector èŠ‚ç‚¹ï¼Œå®ƒä»¬å®é™…ä¸Šæ‰®æ¼”äº†â€œä¸­é—´ä»£ç†â€çš„è§’è‰²ï¼Œä»è€ŒæŠŠ BGP è¿æ¥çš„è§„æ¨¡æ§åˆ¶åœ¨ N çš„æ•°é‡çº§ä¸Šã€‚

```ABAP
Flannel host-gw æ¨¡å¼æœ€ä¸»è¦çš„é™åˆ¶ï¼Œå°±æ˜¯è¦æ±‚é›†ç¾¤å®¿ä¸»æœºä¹‹é—´æ˜¯äºŒå±‚è¿é€šçš„ã€‚è€Œè¿™ä¸ªé™åˆ¶å¯¹äº Calico æ¥è¯´ï¼Œä¹ŸåŒæ ·å­˜åœ¨ã€‚
```

ä¸¾ä¸ªä¾‹å­ï¼Œå‡å¦‚æˆ‘ä»¬æœ‰ä¸¤å°å¤„äºä¸åŒå­ç½‘çš„å®¿ä¸»æœº Node 1 å’Œ Node 2ï¼Œå¯¹åº”çš„ IP åœ°å€åˆ†åˆ«æ˜¯ 192.168.1.2 å’Œ 192.168.2.2ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸¤å°æœºå™¨é€šè¿‡è·¯ç”±å™¨å®ç°äº†ä¸‰å±‚è½¬å‘ï¼Œæ‰€ä»¥è¿™ä¸¤ä¸ª IP åœ°å€ä¹‹é—´æ˜¯å¯ä»¥ç›¸äº’é€šä¿¡çš„ã€‚

è€Œæˆ‘ä»¬ç°åœ¨çš„éœ€æ±‚ï¼Œè¿˜æ˜¯ Container 1 è¦è®¿é—® Container 4ã€‚

æŒ‰ç…§æˆ‘ä»¬å‰é¢çš„è®²è¿°ï¼ŒCalico ä¼šå°è¯•åœ¨ Node 1 ä¸Šæ·»åŠ å¦‚ä¸‹æ‰€ç¤ºçš„ä¸€æ¡è·¯ç”±è§„åˆ™ï¼š

```bash
10.233.2.0/16 via 192.168.2.2 eth0
```

ä½†æ˜¯ï¼Œè¿™æ—¶å€™é—®é¢˜å°±æ¥äº†ã€‚

ä¸Šé¢è¿™æ¡è§„åˆ™é‡Œçš„ä¸‹ä¸€è·³åœ°å€æ˜¯ 192.168.2.2ï¼Œå¯æ˜¯å®ƒå¯¹åº”çš„ Node 2 è·Ÿ Node 1 å´æ ¹æœ¬ä¸åœ¨ä¸€ä¸ªå­ç½‘é‡Œï¼Œæ²¡åŠæ³•é€šè¿‡äºŒå±‚ç½‘ç»œæŠŠ IP åŒ…å‘é€åˆ°ä¸‹ä¸€è·³åœ°å€ã€‚

**åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å°±éœ€è¦ä¸º Calico æ‰“å¼€ IPIP æ¨¡å¼ã€‚**

æˆ‘æŠŠè¿™ä¸ªæ¨¡å¼ä¸‹å®¹å™¨é€šä¿¡çš„åŸç†ï¼Œæ€»ç»“æˆäº†ä¸€å¼ å›¾ç‰‡ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆæ¥ä¸‹æ¥æˆ‘ä¼šç§°ä¹‹ä¸ºï¼šIPIP ç¤ºæ„å›¾ï¼‰ï¼š

![image-20250327143350887](../markdown_img/image-20250327143350887.png)

åœ¨ Calico çš„ IPIP æ¨¡å¼ä¸‹ï¼ŒFelix è¿›ç¨‹åœ¨ Node 1 ä¸Šæ·»åŠ çš„è·¯ç”±è§„åˆ™ï¼Œä¼šç¨å¾®ä¸åŒï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
10.233.2.0/24 via 192.168.2.2 tunl0
```

å¯ä»¥çœ‹åˆ°ï¼Œå°½ç®¡è¿™æ¡è§„åˆ™çš„ä¸‹ä¸€è·³åœ°å€ä»ç„¶æ˜¯ Node 2 çš„ IP åœ°å€ï¼Œä½†è¿™ä¸€æ¬¡ï¼Œè¦è´Ÿè´£å°† IP åŒ…å‘å‡ºå»çš„è®¾å¤‡ï¼Œå˜æˆäº† tunl0ã€‚æ³¨æ„ï¼Œæ˜¯ T-U-N-L-0ï¼Œè€Œä¸æ˜¯ Flannel UDP æ¨¡å¼ä½¿ç”¨çš„ T-U-N-0ï¼ˆtun0ï¼‰ï¼Œè¿™ä¸¤ç§è®¾å¤‡çš„åŠŸèƒ½æ˜¯å®Œå…¨ä¸ä¸€æ ·çš„ã€‚

**Calico ä½¿ç”¨çš„è¿™ä¸ª tunl0 è®¾å¤‡ï¼Œæ˜¯ä¸€ä¸ª IP éš§é“ï¼ˆIP tunnelï¼‰è®¾å¤‡ã€‚**    

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼ŒIP åŒ…è¿›å…¥ IP éš§é“è®¾å¤‡ä¹‹åï¼Œå°±ä¼šè¢« Linux å†…æ ¸çš„ IPIP é©±åŠ¨æ¥ç®¡ã€‚IPIP é©±åŠ¨ä¼šå°†è¿™ä¸ª IP åŒ…ç›´æ¥å°è£…åœ¨ä¸€ä¸ªå®¿ä¸»æœºç½‘ç»œçš„ IP åŒ…ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![image-20250327143630044](../markdown_img/image-20250327143630044.png)

 å…¶ä¸­ï¼Œç»è¿‡å°è£…åçš„æ–°çš„ IP åŒ…çš„ç›®çš„åœ°å€ï¼ˆå›¾ 5 ä¸­çš„ Outer IP Header éƒ¨åˆ†ï¼‰ï¼Œæ­£æ˜¯åŸ IP åŒ…çš„ä¸‹ä¸€è·³åœ°å€ï¼Œå³ Node 2 çš„ IP åœ°å€ï¼š192.168.2.2ã€‚

è€ŒåŸ IP åŒ…æœ¬èº«ï¼Œåˆ™ä¼šè¢«ç›´æ¥å°è£…æˆæ–° IP åŒ…çš„ Payloadã€‚

è¿™æ ·ï¼ŒåŸå…ˆä»å®¹å™¨åˆ° Node 2 çš„ IP åŒ…ï¼Œå°±è¢«ä¼ªè£…æˆäº†ä¸€ä¸ªä» Node 1 åˆ° Node 2 çš„ IP åŒ…ã€‚

ç”±äºå®¿ä¸»æœºä¹‹é—´å·²ç»ä½¿ç”¨è·¯ç”±å™¨é…ç½®äº†ä¸‰å±‚è½¬å‘ï¼Œä¹Ÿå°±æ˜¯è®¾ç½®äº†å®¿ä¸»æœºä¹‹é—´çš„â€œä¸‹ä¸€è·³â€ã€‚æ‰€ä»¥è¿™ä¸ª IP åŒ…åœ¨ç¦»å¼€ Node 1 ä¹‹åï¼Œå°±å¯ä»¥ç»è¿‡è·¯ç”±å™¨ï¼Œæœ€ç»ˆâ€œè·³â€åˆ° Node 2 ä¸Šã€‚

è¿™æ—¶ï¼ŒNode 2 çš„ç½‘ç»œå†…æ ¸æ ˆä¼šä½¿ç”¨ IPIP é©±åŠ¨è¿›è¡Œè§£åŒ…ï¼Œä»è€Œæ‹¿åˆ°åŸå§‹çš„ IP åŒ…ã€‚ç„¶åï¼ŒåŸå§‹ IP åŒ…å°±ä¼šç»è¿‡è·¯ç”±è§„åˆ™å’Œ Veth Pair è®¾å¤‡åˆ°è¾¾ç›®çš„å®¹å™¨å†…éƒ¨ã€‚

ä¸éš¾çœ‹åˆ°ï¼Œå½“ Calico ä½¿ç”¨ IPIP æ¨¡å¼çš„æ—¶å€™ï¼Œé›†ç¾¤çš„ç½‘ç»œæ€§èƒ½ä¼šå› ä¸ºé¢å¤–çš„å°åŒ…å’Œè§£åŒ…å·¥ä½œè€Œä¸‹é™ã€‚åœ¨å®é™…æµ‹è¯•ä¸­ï¼ŒCalico IPIP æ¨¡å¼ä¸ Flannel VXLAN æ¨¡å¼çš„æ€§èƒ½å¤§è‡´ç›¸å½“ã€‚æ‰€ä»¥ï¼Œåœ¨å®é™…ä½¿ç”¨æ—¶ï¼Œå¦‚éç¡¬æ€§éœ€æ±‚ï¼Œ**å»ºè®®å°†æ‰€æœ‰å®¿ä¸»æœºèŠ‚ç‚¹æ”¾åœ¨ä¸€ä¸ªå­ç½‘é‡Œï¼Œé¿å…ä½¿ç”¨ IPIPã€‚**

â€‹                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           

## Kubernetesç½‘ç»œæ’ä»¶è¯¦è§£



**Kubernetesç½‘ç»œ** 

- **Nodeç½‘ç»œ**
  - å„Nodeæ˜¯å¦åœ¨åŒä¸€ç½‘æ®µï¼ˆå­ç½‘ï¼‰ä¼šå½±å“å¯ä»¥ä½¿ç”¨çš„Podçš„ç½‘ç»œæ¨¡å‹
- **Serviceç½‘ç»œ**
  - ç”±é›†ç¾¤è‡ªè¡Œç®¡ç†ï¼ˆKube proxyï¼‰
- **Podç½‘ç»œ**
  - åªæä¾›äº†CNIï¼Œå…·ä½“å®ç°äº¤ç»™ç¬¬ä¸‰æ–¹
  - Flanny
    - é»˜è®¤ç½‘æ®µï¼š10.244.0.0/16
  - Calico
    - é»˜è®¤ç½‘æ®µï¼š192.168.0.0/16
  - Cilium
    - é»˜è®¤ç½‘æ®µï¼š192.168.0.0/16

```ABAP
Tip:æ­£å¸¸æƒ…å†µä¸‹ï¼ŒèŠ‚ç‚¹çš„ç½‘ç»œé…ç½®åœ¨èŠ‚ç‚¹çš„ç½‘ç»œæ¥å£ä¸Šï¼ŒServiceç½‘ç»œé…ç½®åœ¨èŠ‚ç‚¹çš„å†…æ ¸ä¸Šï¼ŒPodç½‘ç»œèŠ‚ç‚¹ä¸Šçš„è™šæ‹Ÿçš„ç½‘ç»œåç§°ç©ºé—´ä¸­ã€‚
å¯¹äºä»»ä½•ä¸€ä¸ªèŠ‚ç‚¹æ¥è®²ï¼Œå®ƒçš„å†…æ ¸ï¼Œå°±æ˜¯è¿™ä¸‰ä¸ªç½‘ç»œäº¤æ±‡çš„ä½ç½®ï¼Œå› æ­¤å¯¹äºä»»ä½•ä¸€ä¸ªèŠ‚ç‚¹ä¸Šï¼Œä»ä»»ä½•ä¸€ä¸ªç½‘ç»œå‘å‡ºçš„è¯·æ±‚ï¼Œåˆ°è¾¾å¦å¤–ä¸€ä¸ªç½‘ç»œï¼Œåªè¦ä½äºé›†ç¾¤çš„ä»»æ„èŠ‚ç‚¹ï¼Œéƒ½æ˜¯å¯è¾¾çš„ã€‚
è¿™é‡Œå¯ä»¥æŠ½è±¡çš„å°†æ¯ä¸ªèŠ‚ç‚¹å†…æ ¸çœ‹åšæ˜¯ä¸€ä¸ªè·¯ç”±ï¼Œåªè¦å¼€å¯ip_forwardè½¬å‘ï¼Œé›†ç¾¤å†…å’Œç½‘ç»œä¹‹é—´å°±æ˜¯å¯è¾¾çš„
```



**å°†å®¹å™¨æ¥å…¥åˆ°ç½‘ç»œä¸­**

- é¦–å…ˆè¦æœ‰è™šæ‹Ÿç½‘ç»œæ¥å£æä¾›ç»™å®¹å™¨ï¼Œå³å‘å®¹å™¨**æ³¨å…¥è™šæ‹Ÿç½‘ç»œæ¥å£**ï¼ˆåˆ›å»ºPodæ—¶ï¼‰
- ä¸ºPod**å‡†å¤‡å¥½ä¸“æœ‰ç½‘ç»œ**ï¼ˆç”±ç½‘ç»œæ’ä»¶è´Ÿè´£ï¼‰
- å°†Podå®¹å™¨çš„ç½‘ç»œæ¥å£è¿å…¥åˆ°Podç½‘ç»œï¼ˆåˆ›å»ºPodæ—¶ï¼‰
- ä¸ºè¯¥Podçš„ç½‘ç»œæ¥å£æä¾›IPåœ°å€ï¼ˆå¯åŠ¨Podæ—¶ï¼Œå…³é—­Podé‡Šæ”¾IPåœ°å€ï¼‰

```ABAP
é™¤äº†å‡†å¤‡Podç½‘ç»œæ˜¯åœ¨éƒ¨ç½²ç½‘ç»œæ’ä»¶æ—¶ä¸€æ¬¡æ€§æä¾›å¥½çš„ä¹‹å¤–ï¼Œåç»­çš„æ³¨å…¥æ¥å£ï¼Œé…ç½®åœ°å€ç­‰ï¼Œéƒ½å’ŒPodè‡ªèº«çš„ç”Ÿå‘½å‘¨æœŸç›¸å…³ï¼Œè€Œå’Œç½‘ç»œæ’ä»¶æ— å…³
```



**çœŸæ­£ç»™Podåˆ†é…åœ°å€çš„ç¨‹åºï¼Œæ˜¯ä½äºæ¯ä¸ªèŠ‚ç‚¹ä¸Šéƒ½æœ‰ä¸€ä¸ªèŠ‚ç‚¹èŒƒå›´çš„åœ°å€çš„ç»´æŠ¤ç¨‹åºï¼Œè€Œä¸æ˜¯æ•´ä¸ªé›†ç¾¤èŒƒå›´çš„**

- è¿™ä¸ªç¨‹åºé€šå¸¸åœ¨èŠ‚ç‚¹èŒƒå›´å†…ç»´æŠ¤ä¸€ä¸ªåœ°å€æ± ï¼Œå¹¶ä»è¯¥åœ°å€æ± ä¸­åˆ†é… IP åœ°å€ç»™æ–°åˆ›å»ºçš„ Podã€‚è¿™ç§è®¾è®¡ä½“ç°äº† Kubernetes ç½‘ç»œçš„å»ä¸­å¿ƒåŒ–ç‰¹ç‚¹ã€‚



**è¯¦ç»†è§£é‡Š**

- **èŠ‚ç‚¹èŒƒå›´çš„åœ°å€æ± **
  - æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ CNI æ’ä»¶è´Ÿè´£**ä»èŠ‚ç‚¹èŒƒå›´å†…çš„åœ°å€æ± **ä¸­ä¸º Pod åˆ†é… IP åœ°å€ã€‚
  - æ¯ä¸ªèŠ‚ç‚¹é€šå¸¸ä¼šåˆ†é…ä¸€ä¸ª**å­ç½‘èŒƒå›´çš„åœ°å€æ± **ï¼Œè¿™ä¸ªåœ°å€æ± æ˜¯ç”±ç½‘ç»œæ’ä»¶åœ¨åˆå§‹åŒ–æ—¶åˆ†é…çš„ã€‚ä¾‹å¦‚ï¼ŒèŠ‚ç‚¹ A çš„åœ°å€æ± å¯èƒ½æ˜¯ `10.244.1.0/24`ï¼ŒèŠ‚ç‚¹ B çš„åœ°å€æ± å¯èƒ½æ˜¯ `10.244.2.0/24`ã€‚
  - Pod çš„ IP åœ°å€æ˜¯ä»è¯¥å­ç½‘ä¸­åˆ†é…çš„ï¼Œæ¯”å¦‚èŠ‚ç‚¹ A ä¸Šçš„ Pod IP å¯èƒ½æ˜¯ `10.244.1.2`ï¼Œè€ŒèŠ‚ç‚¹ B ä¸Šçš„ Pod IP å¯èƒ½æ˜¯ `10.244.2.3`ã€‚
- **æœ¬åœ°åˆ†é…ä¸å…¨å±€é€šä¿¡**
  - åˆ†é… IP çš„è¿‡ç¨‹æ˜¯æœ¬åœ°åŒ–çš„ï¼Œç½‘ç»œæ’ä»¶åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šç‹¬ç«‹è¿è¡Œï¼Œä¸éœ€è¦ä¸æ•´ä¸ªé›†ç¾¤çš„æ§åˆ¶å¹³é¢ç›´æ¥é€šä¿¡ã€‚
  - åˆ†é…å®Œæˆåï¼ŒKubernetes çš„æ§åˆ¶å¹³é¢ï¼ˆAPI Server ç­‰ï¼‰ä¼šçŸ¥é“æ¯ä¸ª Pod çš„ IP åœ°å€ï¼Œä»¥ä¾¿è¿›è¡Œç½‘ç»œé€šä¿¡çš„è·¯ç”±è®¾ç½®ã€‚
- **å»ä¸­å¿ƒåŒ–çš„ä¼˜åŠ¿**
  - å»ä¸­å¿ƒåŒ–åˆ†é…é™ä½äº†ä¸­å¿ƒèŠ‚ç‚¹çš„è´Ÿè½½ï¼Œå› ä¸º IP åœ°å€çš„åˆ†é…å’Œç®¡ç†æ˜¯åˆ†å¸ƒå¼çš„ã€‚
  - å³ä½¿é›†ç¾¤è§„æ¨¡æ‰©å¤§ï¼Œç”±äºåœ°å€åˆ†é…æ˜¯æ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹å®Œæˆçš„ï¼Œåˆ†é…é€Ÿåº¦ä¸ä¼šæ˜¾è‘—å—åˆ°å½±å“





**å¦‚ä½•é¿å…æ¯ä¸ªèŠ‚ç‚¹ä¸Šç‹¬ç«‹çš„ç½‘ç»œåœ°å€åˆ†é…ç¨‹åºæ‰€åˆ†é…çš„IPåœ¨ä¸åŒèŠ‚ç‚¹ä¸Šä¸ç›¸äº’å†²çª**

æ•´ä¸ªKubernetesæœ‰å¾ˆå¤šä¸ªèŠ‚ç‚¹ï¼Œé€šå¸¸åœ¨èŠ‚ç‚¹ä¸Šç»´æŠ¤èŠ‚ç‚¹ä¸ŠPodåœ°å€çš„æ˜¯èŠ‚ç‚¹çº§çš„æ’ä»¶ï¼Œå«**IPAMæ’ä»¶**ï¼ˆIP Addresses Managerï¼‰

**Flannyè§£å†³æ–¹æ¡ˆ**

- ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ†é…ä¸€ä¸ªå­ç½‘
- æ€»çš„å­ç½‘æ˜¯10.244.0.0/16ï¼Œå°†å…¶å†åšå­ç½‘åˆ’åˆ†ï¼Œé»˜è®¤ä½¿ç”¨**24bits**æ©ç 
- å› æ­¤ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„å­ç½‘æ˜¯0-255ï¼Œè€Œæ•´ä¸ªKubernetesé›†ç¾¤**æœ€å¤šèƒ½ç®¡ç†256ä¸ªèŠ‚ç‚¹**
- æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„**å¯ç”¨åœ°å€ä¸º254ä¸ª**ï¼ˆ256-2ï¼‰

```ABAP
é»˜è®¤æƒ…å†µä¸‹ï¼ŒKubernetesä¸ºæ¯ä¸ªèŠ‚ç‚¹æœ€å¤šè°ƒåº¦è¿è¡Œçš„Podæ•°é‡ä¸º110ä¸ª
```



**Calicoè§£å†³æ–¹æ¡ˆ**

- æ€»çš„å­ç½‘æ˜¯192.168.0.0/16
- é»˜è®¤ä½¿ç”¨**26bits**æ©ç ï¼Œè¿›è¡Œå­ç½‘åˆ’åˆ†ï¼Œå› æ­¤å­ç½‘æ•°é‡ï¼š2 ^ 10 = 24ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„å¯ç”¨åœ°å€ï¼š2 ^ 6 - 2 = 62



### Flannelç½‘ç»œæ’ä»¶

ç”±CoreOSç ”å‘ï¼Œå…¼å®¹CNIæ’ä»¶APIï¼Œæ”¯æŒKubernetesï¼ŒOpenShiftï¼ŒCloud Foundryï¼ŒMesosï¼ŒAmazon ECSï¼ŒSingularityå’ŒOPenSVCç­‰å¹³å°ã€‚

ä½¿ç”¨ â€œ è™šæ‹Ÿç½‘æ¡¥ å’Œ vethè®¾å¤‡ â€ çš„æ–¹å¼ä¸ºPodåˆ›å»ºè™šæ‹Ÿç½‘ç»œæ¥å£ï¼Œé€šè¿‡å¯é…ç½®çš„ â€œåç«¯â€ å®šä¹‰Podé—´çš„é€šä¿¡ç½‘ç»œï¼Œæ”¯æŒåŸºäºVXLAN å’Œ UDP çš„ Overlay ç½‘ç»œï¼Œä»¥åŠåŸºäºä¸‰å±‚è·¯ç”±çš„Underlayç½‘ç»œ

- è™šæ‹Ÿç½‘æ¡¥ cni
- éš§é“æ¥å£é€šå¸¸ä¸º flannel.1

åœ¨IPåœ°å€åˆ†é…æ–¹é¢ï¼Œå®ƒå°†é¢„ç•™çš„ä¸€ä¸ªä¸“ç”¨ç½‘ç»œï¼ˆé»˜è®¤ä¸º10.244.0.0/16ï¼‰åˆ‡åˆ†æˆå¤šä¸ªå­ç½‘åä½œä¸ºæ¯ä¸ªèŠ‚ç‚¹çš„ podCIDRï¼Œè€Œåç”±èŠ‚ç‚¹å·²IPAMæ’ä»¶host-localè¿›è¡Œåœ°å€åˆ†é…ï¼Œå¹¶å°†å­ç½‘åˆ†é…ä¿¡æ¯ä¿å­˜äºetcdä¹‹ä¸­ã€‚



#### Flannel æ”¯æŒçš„â€œåç«¯â€

**Flanneld**

- Flannelåœ¨æ¯ä¸ªä¸»æœºä¸Šè¿è¡Œä¸€ä¸ªåä¸ºflanneldçš„äºŒè¿›åˆ¶ä»£ç†ç¨‹åº

  ```bash
  [root@mystical ~]# ps -ef|grep flannel
  root       30446   30426  0 10:04 ?        00:00:00 /opt/bin/flanneld --ip-masq --kube-subnet-mg
  ```

- è¯¥ç¨‹åºè´Ÿè½½ä»é¢„ç•™çš„ç½‘ç»œä¸­æŒ‰ç…§æŒ‡å®šæˆ–é»˜è®¤çš„æ©ç é•¿åº¦ä¸ºå½“å‰èŠ‚ç‚¹ç”³è¯·åˆ†é…ä¸€ä¸ªå­ç½‘ï¼Œå¹¶å°†ç½‘ç»œé…ç½®ï¼Œå·²åˆ†é…çš„å­ç½‘å’Œè¾…åŠ©æ•°æ®ï¼ˆä¾‹å¦‚ä¸»æœºçš„å…¬ç½‘IPç­‰ï¼‰å­˜å‚¨äºKubernetes API æˆ– etcd ä¸­



Flannelä½¿ç”¨ç§°ä¸ºåç«¯ï¼ˆbackendï¼‰çš„å®¹å™¨ç½‘ç»œæœºåˆ¶è½¬å‘è·¨èŠ‚ç‚¹çš„PodæŠ¥æ–‡ï¼Œå®ƒç›®å‰æ”¯æŒçš„ä¸»æµ backend å¦‚ä¸‹

- **vxlan**
  - ä½¿ç”¨Linuxå†…æ ¸ä¸­Vxlanæ¨¡å—å°è£…éš§é“æŠ¥æ–‡ï¼Œä»¥å åŠ ç½‘ç»œæ¨¡å‹æ”¯æŒè·¨èŠ‚ç‚¹çš„Podé—´äº’è”é€šä¿¡
  - **é¢å¤–æ”¯æŒç›´æ¥è·¯ç”±ï¼ˆDirect Routingï¼‰æ¨¡å¼ï¼Œå³æ··åˆæ¨¡å¼**ï¼Œè¯¥æ¨¡å¼ä¸‹ä½äºåŒäºŒå±‚ç½‘ç»œå†…çš„èŠ‚ç‚¹ä¸Šçš„Podé—´é€šä¿¡å¯é€šè¿‡è·¯ç”±æ¨¡å¼ç›´æ¥å‘é€ï¼Œè€Œè·¨ç½‘ç»œçš„èŠ‚ç‚¹ä¹‹ä¸Šçš„Podé—´é€šä¿¡ä»è¦ä½¿ç”¨VXLANéš§é“åè®®è½¬å‘
  - vxlanåç«¯æ¨¡å¼ä¸­ï¼ŒFlannelç›‘å¬äº**8472/UDP**å‘é€å°è£…çš„æ•°æ®åŒ…
- **host-gw**
  - ç±»ä¼¼äºVXLANä¸­çš„ç›´æ¥è·¯ç”±æ¨¡å¼ï¼Œä½†ä¸æ”¯æŒè·¨ç½‘ç»œçš„èŠ‚ç‚¹ï¼Œå› æ­¤è¿™ç§æ–¹å¼å¼ºåˆ¶è¦æ±‚å„èŠ‚ç‚¹æœ¬èº«å¿…é¡»åœ¨åŒä¸€ä¸ªäºŒå±‚ç½‘ç»œä¸­ï¼Œä¸å¤ªé€‚ç”¨äºè¾ƒå¤§çš„ç½‘ç»œè§„æ¨¡
  - æœ‰ç€è¾ƒå¥½çš„è½¬å‘æ€§èƒ½ï¼Œä¸”æ˜“äºè®¾å®šï¼Œæ¨èå¯¹æŠ¥æ–‡è½¬å‘æ€§èƒ½è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ä½¿ç”¨
- **udp**
  - ä½¿ç”¨å¸¸è§„UDPæŠ¥æ–‡å°è£…å®Œæˆéš§é“è½¬å‘ï¼Œæ€§èƒ½è¾ƒå‰ä¸¤ç§æ–¹å¼ä½å¾ˆå¤šï¼Œå®ƒä»…åº”è¯¥ç”¨åœ¨ä¸æ”¯æŒå‰ä¸¤ç§åç«¯çš„ç¯å¢ƒä¸­ä½¿ç”¨
  - UDPåç«¯æ¨¡å¼ä¸­ï¼ŒFlannelç›‘å¬äº**8285/UDP**å‘é€å°è£…çš„æŠ¥æ–‡



#### Flannelæ›´æ”¹åç«¯ç½‘ç»œæ¨¡å¼

```bash
[root@mystical ~]# kubectl get cm -n kube-flannel 
NAME               DATA   AGE
kube-flannel-cfg   2      19m
kube-root-ca.crt   1      19m

[root@mystical ~]# kubectl edit cm -n kube-flannel kube-flannel-cfg
......
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "EnableNFTables": false,
      "Backend": {
        # "Type": "vxlan"   # æ›´æ”¹è¿™é‡Œ
        "Type": "host-gw"
      }
    }
    
# é‡å¯DeamonSet
[root@mystical ~]# kubectl rollout restart daemonset kube-flannel-ds -n kube-flannel

# æŸ¥çœ‹ 
[root@master2 ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         11.0.1.2        0.0.0.0         UG    0      0        0 eth0 
10.244.0.0      11.0.1.101      255.255.255.0   UG    0      0        0 eth0      # æ–°ç”Ÿæˆçš„è·¯ç”±
10.244.1.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0
10.244.2.0      11.0.1.103      255.255.255.0   UG    0      0        0 eth0      # æ–°ç”Ÿæˆçš„è·¯ç”±
11.0.1.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0


# æ›´æ”¹ä¸ºæ··åˆæ¨¡å¼ï¼Œå³è·¨ç½‘æ®µä½¿ç”¨vxlanï¼Œä¸è·¨ç½‘æ®µï¼Œä½¿ç”¨host-gw
[root@mystical ~]# kubectl edit cm -n kube-flannel kube-flannel-cfg
......
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "EnableNFTables": false,
      "Backend": {
        "Type": "vxlan"
        "Directrouting": "true"   # æ·»åŠ è¿™è¡Œ
      }
    }
......

# é‡å¯DeamonSet
[root@mystical ~]# kubectl rollout restart daemonset kube-flannel-ds -n kube-flannel
```





### Calico ç½‘ç»œæ’ä»¶

#### calicoç®€ä»‹

- calicoè¢«ç§°ä½œæ˜¯çº¯ä¸‰å±‚ç½‘ç»œæ’ä»¶ï¼Œä¸ºä»€ä¹ˆ
  - å¯¹æ¯”flannelï¼Œflannelä½¿ç”¨çš„æ˜¯è™šæ‹Ÿç½‘è·¯æ¥å£æ˜¯veth-pairï¼Œä¸€æ®µè¿æ¥å®¹å™¨podï¼Œå¦ä¸€ç«¯è¿æ¥è™šæ‹Ÿç½‘æ¡¥cni0ä¸Šï¼ŒåŒä¸€èŠ‚ç‚¹ä¸Šçš„ä¸¤ä¸ªpodé€šä¿¡ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡ç½‘æ¡¥cni0è¿›è¡Œé€šä¿¡ï¼Œè€Œç½‘æ¡¥æ˜¯äºŒå±‚è®¾å¤‡ï¼Œå› æ­¤è¿™é‡Œæ˜¯åŸºäºäºŒå±‚ç½‘ç»œçš„é€šä¿¡
  - è€Œcalicoä¸€æ ·ä½¿ç”¨veth-pairï¼ˆè™šæ‹Ÿä»¥å¤ªç½‘æ¥å£å¯¹ï¼‰ï¼Œä¸€ç«¯æ³¨å…¥åˆ°podå†…éƒ¨ï¼Œå¦ä¸€ç«¯é©»ç•™åœ¨èŠ‚ç‚¹ä¸Šï¼Œä¸ä¼šæ·»åŠ åˆ°æŸè™šæ‹Ÿç½‘æ¡¥ä¸Šï¼Œè€Œæ˜¯ç›´æ¥ä¿ç•™åœ¨å®¿ä¸»æœºä¸Šï¼Œå› æ­¤åŒä¸€èŠ‚ç‚¹ä¸Šçš„ä¸¤ä¸ªpodé€šä¿¡ï¼Œç›¸å½“äºä¸¤ä¸ªpodè¢«å†…æ ¸é“¾æ¥èµ·æ¥ï¼Œè€Œå†…æ ¸ç›¸å½“äºè·¯ç”±è®¾å¤‡ï¼Œå› æ­¤åŒèŠ‚ç‚¹é—´çš„podé€šä¿¡éœ€è¦è·¯ç”±ï¼Œå› ä¸ºæ²¡æœ‰ç½‘æ¡¥äº†ï¼Œæ‰€ä»¥è¦æŒ‡ç½‘å…³ï¼Œæœ€èµ·ç è¦æŒ‡ä¸‹ä¸€è·³çš„åœ°å€ï¼Œå› æ­¤å¿…é¡»åœ¨é€šä¿¡å‰ç”Ÿæˆè·¯ç”±è¡¨æ¡ç›®
  - å°±å› ä¸ºå“ªæ€•æ˜¯åŒä¸€èŠ‚ç‚¹çš„podè¦é€šä¿¡ï¼Œä¹Ÿå¿…é¡»éœ€è¦è·¯ç”±è¡¨è¿›è¡Œè·¯ç”±ï¼Œæ‰€ä»¥æ˜¯çº¯ä¸‰å±‚ç½‘ç»œ

- calicoæŠŠæ¯ä¸ªèŠ‚ç‚¹éƒ½å½“åšè™šæ‹Ÿè·¯ç”±å™¨(vrouter)ï¼ŒæŠŠæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„podéƒ½å½“åšæ˜¯â€œèŠ‚ç‚¹è·¯ç”±å™¨â€åçš„ä¸€ä¸ªç»ˆç«¯è®¾å¤‡å¹¶ä¸ºå…¶åˆ†é…ä¸€ä¸ªipåœ°å€

- å„èŠ‚ç‚¹è·¯ç”±å™¨é€šè¿‡bgp(border gateway protocol)åè®®å­¦ä¹ ç”Ÿæˆè·¯ç”±è§„åˆ™ï¼Œä»è€Œå®ç°ä¸åŒèŠ‚ç‚¹ä¸Špodé—´çš„äº’è”äº’é€š

- calicoåœ¨æ¯ä¸€ä¸ªè®¡ç®—èŠ‚ç‚¹åˆ©ç”¨linuxå†…æ ¸å®ç°äº†ä¸€ä¸ªé«˜æ•ˆçš„vrouterï¼ˆè™šæ‹Ÿè·¯ç”±å™¨ï¼‰è¿›è¡ŒæŠ¥æ–‡è½¬å‘ï¼Œè€Œæ¯ä¸ª vrouter é€šè¿‡ bgpåè®® è´Ÿè´£æŠŠè‡ªèº«æ‰€å±çš„èŠ‚ç‚¹ä¸Šçš„è¿è¡Œçš„podèµ„æºçš„ipåœ°å€ä¿¡æ¯**åŸºäºèŠ‚ç‚¹çš„agentç¨‹åº (felix) ç›´æ¥ç”±vrouterç”Ÿæˆè·¯ç”±è§„åˆ™**å‘æ•´ä¸ªcalicoç½‘ç»œå†…ä¼ æ’­



#### Calico ç³»ç»Ÿç»„ä»¶

![image-20250328155236970](../markdown_img/image-20250328155236970.png)

æ¦‚æ‹¬æ¥è¯´ï¼Œcalicoä¸»è¦ç”±felixã€orchestratorã€etcdã€birdå’Œbgprouterreflectorç­‰ç»„ä»¶ç»„æˆ

- **Felix**ï¼šæ ¸å¿ƒ agentï¼Œè´Ÿè´£é…ç½®æœ¬åœ°èŠ‚ç‚¹ï¼Œç»´æŠ¤æœ¬èŠ‚ç‚¹çš„è·¯ç”±ã€iptablesã€å®‰å…¨ç­–ç•¥

  - è¯»å– etcd æˆ– K8s API ä¸­çš„æ•°æ®ï¼ˆä¾‹å¦‚ï¼šPod ä¿¡æ¯ã€NetworkPolicyã€IPPool ç­‰ï¼‰
  - æ ¹æ®è¿™äº›ä¿¡æ¯
    - è®¾ç½® iptablesï¼ˆç”¨äºç½‘ç»œç­–ç•¥ï¼‰ï¼Œ**é€šå¸¸éƒ½æ˜¯ä¿®æ”¹Filterè¡¨**
    - æ·»åŠ æœ¬èŠ‚ç‚¹çš„ `cali*` æ¥å£ï¼ˆveth å¯¹ç«¯ï¼‰
    - å†™å…¥æœ¬èŠ‚ç‚¹çš„è·¯ç”±è¡¨ï¼ˆè®©æœ¬åœ°å†…æ ¸çŸ¥é“æ€ä¹ˆè½¬å‘æµé‡ï¼‰

  ```ABAP
  é‡ç‚¹ï¼šFelix åªé…ç½®æœ¬åœ°å†…æ ¸ï¼Œä¸è´Ÿè´£è·¨èŠ‚ç‚¹é€šå‘Šã€‚
  ```

- **Orchestrator Plugin**ï¼šç¼–æ’ç³»ç»Ÿï¼ˆæ¯”å¦‚k8sï¼Œopenstackç­‰ï¼‰ç”¨äºå°†calicoæ•´åˆè¿›è¡Œç³»ç»Ÿä¸­çš„æ’ä»¶ï¼Œä¾‹å¦‚k8sçš„cni

- **etcd**ï¼šæŒä¹…å­˜å‚¨calicoæ•°æ®çš„å­˜å‚¨ç®¡ç†ç³»ç»Ÿ

- **BIRD**ï¼šè¿›è¡Œ BGP è·¯ç”±é€šå‘Šï¼Œå‘ŠçŸ¥å…¶ä»–èŠ‚ç‚¹æˆ‘æœ‰å“ªäº› Pod ç½‘ç»œ

  - ä»æœ¬åœ°å†…æ ¸è¯»å–å·²ç»æ·»åŠ çš„è·¯ç”±ï¼ˆä¾‹å¦‚ï¼šæŸä¸ª Pod CIDR åœ¨æˆ‘è¿™é‡Œï¼‰
  - é€šè¿‡ BGP åè®®ï¼Œå°†è¿™äº›è·¯ç”±å¹¿æ’­ç»™ BGP peerï¼ˆä¹Ÿå°±æ˜¯å…¶ä»–èŠ‚ç‚¹æˆ–è·¯ç”±å™¨ï¼‰
  - åŒæ—¶æ¥æ”¶å…¶ä»–èŠ‚ç‚¹é€šå‘Šæ¥çš„è·¯ç”±ï¼Œæ›´æ–°æœ¬åœ°è·¯ç”±è¡¨ï¼ˆä½¿å¾—è·¨èŠ‚ç‚¹é€šä¿¡å¯è¾¾ï¼‰

  ```ABAP
  é‡ç‚¹ï¼šBIRD ä¸è´Ÿè´£è·¯ç”±æ·»åŠ ï¼Œåªè´Ÿè´£â€œé€šå‘Šâ€å’Œâ€œæ¥æ”¶â€è·¯ç”±ã€‚
  ```

- **BGPRoute Reflector**ï¼šBGPè·¯ç”±åå°„å™¨ï¼Œå¯é€‰ç»„ä»¶ï¼Œç”¨äºè¾ƒå¤§è§„æ¨¡çš„ç½‘ç»œåœºæ™¯



##### Felix å’Œ BIRD çš„å…³ç³»

**Felix è´Ÿè´£ IGPï¼ŒBIRD è´Ÿè´£ BGP**

| ç»„ä»¶      | ç±»æ¯”                | èŒè´£                                                         |
| --------- | ------------------- | ------------------------------------------------------------ |
| **Felix** | IGPï¼ˆå†…éƒ¨ç½‘å…³åè®®ï¼‰ | é…ç½®æœ¬åœ°è·¯ç”±è¡¨ï¼ˆInterface + è·¯ç”±ï¼‰ï¼Œå°±åƒä¼ ç»Ÿ IGP ç»´æŠ¤æœ¬åœ°èŠ‚ç‚¹çš„é‚»æ¥å…³ç³»ã€æ¥å£ä¿¡æ¯ |
| **BIRD**  | BGPï¼ˆè¾¹ç•Œç½‘å…³åè®®ï¼‰ | è·¨èŠ‚ç‚¹è¿›è¡Œè·¯ç”±é€šå‘Šå’Œå­¦ä¹ ï¼Œè®©æ‰€æœ‰èŠ‚ç‚¹çŸ¥é“å½¼æ­¤æœ‰å“ªäº› Pod ç½‘ç»œæ®µ |



![image-20250328164803605](../markdown_img/image-20250328164803605.png)



##### Calico-kube-controller

`calico-kube-controllers` æ˜¯ä¸€ä¸ª **æ§åˆ¶å™¨ç»„ä»¶**ï¼Œéƒ¨ç½²åœ¨ Kubernetes é›†ç¾¤ä¸­ï¼Œè´Ÿè´£ **ç›‘å¬ Kubernetes çš„èµ„æºå˜åŒ–ï¼ˆå¦‚ NetworkPolicyã€Namespaceã€ServiceAccount ç­‰ï¼‰**ï¼Œç„¶å **å°†å®ƒä»¬åŒæ­¥ä¸º Calico æ‰€ä½¿ç”¨çš„è‡ªå®šä¹‰èµ„æºï¼ˆCRDï¼‰**ï¼Œå¹¶è§¦å‘ç½‘ç»œç­–ç•¥ç”Ÿæ•ˆã€‚



**ğŸ”¹Calico-kube-controller çš„ä½œç”¨**

Kubernetes æ”¯æŒåŸç”Ÿçš„ `NetworkPolicy` èµ„æºï¼Œä½†å®ƒåªå®šä¹‰äº† APIï¼Œå¯¹å®é™…å¦‚ä½•å®ç°å¹¶ä¸è´Ÿè´£ã€‚

**Calico çš„ç½‘ç»œç­–ç•¥åŠŸèƒ½**éå¸¸å¼ºå¤§ï¼Œä½†å®ƒä½¿ç”¨çš„æ˜¯è‡ªå·±å®šä¹‰çš„ä¸€å¥— CRDï¼Œæ¯”å¦‚ï¼š

- `GlobalNetworkPolicy`
- `NetworkPolicy`
- `HostEndpoint`
- `NetworkSet`

æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªç»„ä»¶æ¥ï¼š

1. **ç›‘å¬ Kubernetes åŸç”Ÿçš„èµ„æºå˜åŒ–**
2. **å°†å®ƒä»¬è½¬æ¢ä¸º Calico çš„ CRD èµ„æº**
3. **é©±åŠ¨ç­–ç•¥åœ¨èŠ‚ç‚¹ä¸Šè½åœ°ï¼ˆä¾‹å¦‚é€šè¿‡ Felixï¼‰**

è¿™å°±æ˜¯ `calico-kube-controllers` çš„èŒè´£ã€‚



ğŸ”¹**å®ƒéƒ½åŒ…å«äº†å“ªäº› Controller**

è¿™æ˜¯ä¸€ä¸ªæ§åˆ¶å™¨é›†åˆï¼ˆcontroller setï¼‰ï¼ŒåŒ…å«å¤šä¸ªå­æ§åˆ¶å™¨ï¼Œæ¯”å¦‚ï¼š

| æ§åˆ¶å™¨åç§°                   | åŠŸèƒ½è¯´æ˜                                                     |
| ---------------------------- | ------------------------------------------------------------ |
| `PolicyController`           | ç›‘å¬ K8s çš„ `NetworkPolicy`ï¼Œå¹¶è½¬æ¢ä¸º Calico çš„ç­–ç•¥          |
| `NamespaceController`        | å°† namespace ä¸­çš„ labels åŒæ­¥åˆ° Calico çš„ç­–ç•¥åŸŸï¼ˆä¾¿äºç­–ç•¥ä½¿ç”¨ namespace selectorï¼‰ |
| `ServiceAccountController`   | åŒæ­¥ K8s ServiceAccount ä½œä¸º Calico ç­–ç•¥çš„ selector æ¡ä»¶     |
| `NodeController`             | å°† K8s Node çš„çŠ¶æ€åŒæ­¥åˆ° Calico ä¸­ï¼ˆç”¨äºè·¯ç”±ä¿¡æ¯ï¼‰           |
| `WorkloadEndpointController` | ç»´æŠ¤æ¯ä¸ª Pod çš„ç½‘ç»œç«¯ç‚¹èµ„æº                                  |
| `ServiceController`          | ç®¡ç† `Service` èµ„æºç›¸å…³çš„ç­–ç•¥ï¼ˆä¾‹å¦‚ egressï¼‰                 |

å¯ä»¥é€šè¿‡ deployment çš„ `--controllers` å‚æ•°å¯ç”¨/å…³é—­å…¶ä¸­æŸäº› controllerã€‚



ğŸ”¹**Calico-kube-controller å’Œ Felix çš„å…³ç³»**

- `calico-kube-controllers` è´Ÿè´£â€œç¿»è¯‘â€K8såŸç”Ÿå‘½ä»¤ï¼Œå¹¶å­˜å…¥ï¼ˆAPI Server æˆ– etcdï¼‰

- è€Œ `Felix` è´Ÿè´£â€œæ‰§è¡Œâ€è¿™äº›ç­–ç•¥ï¼Œä¸”æ˜¯ç›´æ¥ä»å­˜å‚¨å±‚ï¼ˆAPI Server æˆ– etcdï¼‰ä¸­è¯»å–ç¿»è¯‘åçš„ CRD æ•°æ®ã€‚

```gfm
[Kubernetes åŸç”Ÿèµ„æº]
     â”‚
     â–¼
[calico-kube-controllers]
     â”‚      ï¼ˆè½¬æ¢ä¸º CRDï¼‰
     â–¼
[CRD å­˜å‚¨ï¼šK8s API Server æˆ– etcd]
     â”‚
     â–¼
[Felix] â€”â€” è¯»å–è¿™äº› CRDï¼Œç”Ÿæˆç½‘ç»œç­–ç•¥å’Œè·¯ç”±
```



##### Typha

**ğŸ”¹ Typha æ˜¯ä»€ä¹ˆï¼Ÿ**

**Typha** æ˜¯ Calico çš„ä¸€ä¸ªç»„ä»¶ï¼Œ**ç”¨äºä¼˜åŒ–å¤§è§„æ¨¡ Kubernetes é›†ç¾¤ä¸­ Felix ä¸ Kubernetes API Serverï¼ˆæˆ– etcdï¼‰ä¹‹é—´çš„æ•°æ®åŒæ­¥æ•ˆç‡**ã€‚

```ABAP
åœ¨ä¸€ä¸ªå¤§å‹é›†ç¾¤ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ Felix è¿›ç¨‹éƒ½éœ€è¦ watch æ¥è‡ª API Server æˆ– etcd çš„èµ„æºæ›´æ–°ï¼ˆæ¯”å¦‚ Podã€NetworkPolicyã€Node ç­‰ï¼‰ï¼Œå½“èŠ‚ç‚¹æ•°é‡ä¸€å¤šï¼ˆæ¯”å¦‚ 100+ èŠ‚ç‚¹ï¼‰ï¼ŒKubernetes API Server ä¼šè¢«å¤§é‡è¿æ¥å‹å®
```



**ğŸ”¹Typha çš„ä½œç”¨**

Typha ä½œä¸ºä¸€ä¸ª **â€œä¸­é—´ä»£ç†â€**ï¼Œåœ¨ API Server å’Œå¤§é‡ Felix ä¹‹é—´èµ·åˆ°äº†ä¸­è½¬ä½œç”¨ï¼š

```css
[API Server]
     â†‘
     â”‚  ï¼ˆå°‘é‡è¿æ¥ï¼‰
 [Typha Server]
   â†‘     â†‘     â†‘
 [Felix] [Felix] [Felix]   â† æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ agent
```

ğŸŒŸ **ä¼˜ç‚¹**

- å‡å°‘å¯¹ API Server çš„å‹åŠ›ï¼ˆåªéœ€è¦ Typha è¿æ¥ï¼‰
- æ›´é«˜æ•ˆçš„äº‹ä»¶åˆ†å‘ï¼ˆTypha å°†åŒæ ·çš„äº‹ä»¶â€œå¹¿æ’­â€ç»™ Felixï¼‰
- æ›´é€‚åˆ **å¤§è§„æ¨¡é›†ç¾¤ï¼ˆ>50èŠ‚ç‚¹ï¼‰**



ğŸ”¹**Typha çš„éƒ¨ç½²æ–¹å¼**

- **ä½¿ç”¨ Tigera Operator æˆ– Helm å®‰è£… Calico æ—¶** ğŸ‘‰ **ä¼šè‡ªåŠ¨é…ç½® `calico-node` æŒ‡å‘ Typha**
- **ä½¿ç”¨ `calico.yaml` æ‰‹åŠ¨å®‰è£…æ—¶** ğŸ‘‰ **ä½ éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ DaemonSet ä¸­ `calico-node` çš„ç¯å¢ƒå˜é‡æ¥æŒ‡å®š Typha çš„åœ°å€**ã€‚



###### è‡ªåŠ¨é…ç½®çš„æƒ…å†µï¼ˆä½¿ç”¨ Operator æˆ– Helmï¼‰

```bash
helm install calico projectcalico/tigera-operator \
  --set installation.typha.replicaCount=3
```

æˆ–è€…ä½ ä½¿ç”¨çš„æ˜¯åŒ…å« `operator.tigera.io` çš„ manifest æ–‡ä»¶å®‰è£…ï¼ˆå³ Tigera Operatorï¼‰ï¼Œ**Typha ä¼šè‡ªåŠ¨éƒ¨ç½²å¥½å¹¶è‡ªåŠ¨é…ç½®å¥½ `calico-node` è¿æ¥ Typha**ï¼Œä½ æ— éœ€æ‰‹åŠ¨æ›´æ”¹ã€‚

åœ¨ `calico-node` çš„å®¹å™¨ä¸­ï¼Œä¼šè‡ªåŠ¨æœ‰å¦‚ä¸‹ç¯å¢ƒå˜é‡ï¼š

```yaml
- name: FELIX_TYPHAADDR
  valueFrom:
    fieldRef:
      fieldPath: status.podIP
```

æˆ–è€…ç›´æ¥æ˜¯

```yaml
- name: FELIX_TYPHAADDR
  value: "typha.calico.svc.cluster.local:5473"
```



###### æ‰‹åŠ¨éƒ¨ç½²æ—¶éœ€è¦æ‰‹åŠ¨é…ç½®

å¦‚æœä½ ä½¿ç”¨äº†å®˜æ–¹çš„ `calico.yaml` 

```bash
curl https://docs.projectcalico.org/manifests/calico.yaml -O
```

ç„¶ååˆæ‰‹åŠ¨æ·»åŠ äº† Typha çš„éƒ¨ç½²ï¼Œé‚£ä¹ˆä½ è¿˜éœ€è¦å»æ‰‹åŠ¨ç¼–è¾‘ `calico-node` çš„ DaemonSetï¼Œåœ¨å®¹å™¨ç¯å¢ƒå˜é‡ä¸­æ·»åŠ ï¼š

```yaml
- name: FELIX_TYPHAADDR
  value: "typha.calico.svc.cluster.local:5473"
```

è¿™ä¸€æ­¥æ˜¯æ‰‹åŠ¨é…ç½®ï¼å¦åˆ™ Felix è¿˜æ˜¯ä¼šé»˜è®¤å»è¿ Kubernetes API Serverã€‚

**ä¿®æ”¹æ–¹å¼ä¸¾ä¾‹**

```bash
kubectl edit daemonset calico-node -n kube-system
```

æ·»åŠ åˆ° `env:` ä¸‹ï¼š

```yaml
        env:
        - name: FELIX_TYPHAADDR
          value: "typha.calico.svc.cluster.local:5473"
```

ä¿å­˜åï¼Œ`DaemonSet` ä¼šæ»šåŠ¨æ›´æ–°ï¼ŒFelix ä¼šè¿ä¸Š Typhaã€‚



##### è¡¥å……é—®é¢˜ï¼šFelix æ˜¯ä»å“ªé‡Œ watch ç½‘ç»œç­–ç•¥ï¼ˆå¦‚ NetworkPolicyï¼‰ç­‰æ•°æ®çš„ï¼Ÿæˆ‘å¦‚ä½•æŒ‡å®šå®ƒä» apiserver è¿˜æ˜¯ etcd è·å–ï¼Ÿ

Calico çš„ Felix æ˜¯é€šè¿‡ **`DatastoreType`** å‚æ•°æ¥å†³å®šæ˜¯ä»å“ªé‡Œè·å–æ•°æ®çš„ï¼š

| æ•°æ®æº       | ä½œç”¨æ–¹å¼                                                     |
| ------------ | ------------------------------------------------------------ |
| `kubernetes` | Felix ä» **K8s API Server** è·å– Calico CRD æ•°æ®ï¼ˆæ¨èæ–¹å¼ï¼‰ |
| `etcd`       | Felix ä» **etcd** ç›´æ¥è·å– Calico è‡ªå®šä¹‰èµ„æºï¼ˆè€æ–¹å¼ï¼‰       |



**å¦‚ä½•é…ç½® `DatastoreType`**

åœ¨ `calico-node` Pod ä¸­ï¼ˆDaemonSet çš„å®¹å™¨ï¼‰ï¼Œé€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```yaml
- name: DATASTORE_TYPE
  value: "kubernetes"
```

æˆ–è€…

```yaml
- name: DATASTORE_TYPE
  value: "etcd"
```

å°±å¯ä»¥æ§åˆ¶ Felix çš„æ•°æ®æ¥æºã€‚é€šå¸¸è¿™ä¸ªé…ç½®åœ¨ `calico-node` DaemonSet çš„ `calico` å®¹å™¨ä¸­ã€‚

**ç¤ºä¾‹ï¼šé…ç½®ä¸ºä½¿ç”¨ Kubernetes API Server**

```yaml
        env:
        - name: DATASTORE_TYPE
          value: "kubernetes"
        - name: KUBECONFIG
          value: "/etc/cni/net.d/calico-kubeconfig"
```

è¿™è¡¨ç¤º Felix ä¼šå»è®¿é—® Kubernetes API Server ä¸­æ³¨å†Œçš„ Calico CRDsï¼Œæ¯”å¦‚ï¼š

- `networkpolicies.crd.projectcalico.org`
- `bgppeers.crd.projectcalico.org`ç­‰ç­‰

**ç¤ºä¾‹ï¼šé…ç½®ä¸ºä½¿ç”¨ etcd**

å¦‚æœä½ ä½¿ç”¨ `etcd` æ¨¡å¼éƒ¨ç½² Calicoï¼ˆå¸¸è§äºæ—©æœŸçš„çº¯ Calico ç½‘ç»œï¼Œæ—  Kubernetesï¼‰ï¼Œåˆ™é…ç½®ï¼š

```yaml
        env:
        - name: DATASTORE_TYPE
          value: "etcd"
        - name: ETCD_ENDPOINTS
          value: "https://<your-etcd-endpoint>:2379"
        - name: ETCD_CA_CERT_FILE
          value: "/calico-secrets/etcd-ca"
        - name: ETCD_CERT_FILE
          value: "/calico-secrets/etcd-cert"
        - name: ETCD_KEY_FILE
          value: "/calico-secrets/etcd-key"
```

**æ³¨æ„äº‹é¡¹ï¼š**

- **Kubernetes æ¨¡å¼**ï¼ˆé€šè¿‡ CRD å­˜å‚¨ï¼‰æ˜¯ç›®å‰ Calico çš„ **é»˜è®¤å’Œæ¨èæ¨¡å¼**ã€‚
- å¦‚æœä½ éƒ¨ç½²çš„æ˜¯ Calico æ’ä»¶ç”¨äº K8s ç½‘ç»œï¼Œé»˜è®¤å°±æ˜¯ `kubernetes` æ¨¡å¼ã€‚
- åªæœ‰å½“ä½ æ˜ç¡®éƒ¨ç½²äº†å¤–éƒ¨ etcdï¼Œå¹¶ç”¨äº† old-school Calico ç½‘ç»œæ¶æ„ï¼Œæ‰ä¼šè®¾ç½®ä¸º `etcd` æ¨¡å¼ã€‚

```ABAP
é€šå¸¸50ä¸ªèŠ‚ç‚¹ä»¥ä¸Šä½¿ç”¨Typhaï¼Œè€Œ100ä¸ªèŠ‚ç‚¹ä»¥ä¸Šä½¿ç”¨BGPRoute Reflector
```







#### éš§é“æ¨¡å‹ (Overlay)

- **IPIPï¼ˆIP - IN - IPï¼‰**
- **VXLAN**

![image-20250327143350887](../markdown_img/image-20250327143350887.png)



##### ipipéš§é“

- é€‚ç”¨æ€§å¥½ï¼Œå°¤å…¶æ˜¯è·¨å¤šå­ç½‘çš„ç½‘ç»œç¯å¢ƒ
- å­˜åœ¨é¢å¤–å¼€é”€ï¼Œmtuä¸€èˆ¬è¦è®¾ç½®ä¸º1480
- ipipæ¨¡å¼åŒæ ·éœ€è¦ä½¿ç”¨bgpåè®®ï¼Œä»¥å®Œæˆè·¯ç”±åˆ†å‘

- éš¾ä»¥ä½¿ç”¨è¯¥æ¨¡å¼çš„å¸¸è§åœºæ™¯
  - ç¦æ­¢ä½¿ç”¨ipipåè®®çš„ç¯å¢ƒï¼Œä¾‹å¦‚ï¼šazure
  - é˜»æ­¢æ‰€æœ‰bgpæŠ¥æ–‡çš„ç½‘ç»œç¯å¢ƒ

- æŠ¥æ–‡çš„æµå‘ï¼špod --> eth0 --> calixx --> tunl0 --> enp1s0

##### vxlanéš§é“æ¨¡å¼

- å®Œå…¨ä¸ä¾èµ–äºbgpï¼Œå¼€é”€è¾ƒä¹‹ipipç•¥å¤§(mtuä¸º1450)ï¼Œä½†åŠŸèƒ½æ›´ä¸ºå¼ºå¤§
- é»˜è®¤ä½¿ç”¨udpçš„4789ç«¯å£
- vxlanéš§é“å‡ºå…¥å£ï¼švxlan.calico
- æŠ¥æ–‡æµå‘ï¼špod --> eth0 --> calixxx --> vxlan.calico --> enp1so



#### è·¯ç”±æ¨¡å‹ (Underlay)

**åŸºäºBGPå­¦ä¹ ç”Ÿæˆè·¯ç”±è¡¨**

```ABAP
å¦‚æœèŠ‚ç‚¹é—´è·¯ç”±æ”¯æŒBGPåè®®ï¼Œåˆ™å¯ä»¥è·¨å­ç½‘ï¼Œå¦åˆ™ä¸èƒ½è·¨å­ç½‘
```

![image-20250327142246955](../markdown_img/image-20250327142246955.png)

- æ¯ä¸ª Pod éƒ½ä¼šè¢« Calico åˆ›å»ºä¸€ä¸ª `veth` å¯¹ï¼ˆå®¹å™¨é‡Œæ˜¯ `eth0`ï¼Œå®¿ä¸»æœºä¸Šæ˜¯ä»¥ `caliXXXX` å¼€å¤´çš„æ¥å£ï¼‰ã€‚
- è¿™ä¸ª `caliXXX` è™šæ‹Ÿæ¥å£ç›´æ¥æŒ‚è½½åœ¨å®¿ä¸»æœºçš„ç½‘ç»œå‘½åç©ºé—´ä¸­ã€‚



**èŠ‚ç‚¹é—´é€šä¿¡ï¼šé  ä¸»æœºè·¯ç”±è¡¨**

- æ¯ä¸ªå®¿ä¸»æœºä¼šå°†å…¶æœ¬åœ° Pod çš„ IP æ®µé€šè¿‡ `ip route` æ³¨å†Œåˆ°å†…æ ¸è·¯ç”±è¡¨ã€‚

- alico ä¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šæ·»åŠ é™æ€è·¯ç”±ï¼ŒæŒ‡å‘å…¶ä»–èŠ‚ç‚¹çš„ Pod ç½‘æ®µï¼š

  ```bash
  [root@node1 ~]#route -n
  å†…æ ¸ IP è·¯ç”±è¡¨
  ç›®æ ‡            ç½‘å…³            å­ç½‘æ©ç         æ ‡å¿—  è·ƒç‚¹   å¼•ç”¨  ä½¿ç”¨ æ¥å£
  0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
  10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
  172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
  192.168.22.0    0.0.0.0         255.255.255.0   U     0      0        0 *
  192.168.22.14   0.0.0.0         255.255.255.255 UH    0      0        0 calid1eb843872f
  192.168.22.15   0.0.0.0         255.255.255.255 UH    0      0        0 cali214a0d1d46d
  192.168.22.16   0.0.0.0         255.255.255.255 UH    0      0        0 cali2266a186640
  192.168.22.17   0.0.0.0         255.255.255.255 UH    0      0        0 cali2c6d5459769
  192.168.22.18   0.0.0.0         255.255.255.255 UH    0      0        0 caliecbcd92008b
  192.168.22.19   0.0.0.0         255.255.255.255 UH    0      0        0 calie58a73424e2
  192.168.123.0   10.0.0.102      255.255.255.0   UG    0      0        0 eth0
  192.168.252.0   10.0.0.104      255.255.255.0   UG    0      0        0 eth0
  192.168.253.0   10.0.0.105      255.255.255.0   UG    0      0        0 eth0
  ```

**æ•°æ®åŒ…é€šè¿‡ ARPè¡¨ å®šä½å…·ä½“ Pod**

- å½“æ•°æ®åŒ…åˆ°è¾¾ç›®æ ‡èŠ‚ç‚¹åï¼Œç›®çš„ IP æ˜¯ Pod çš„åœ°å€
- Linux å†…æ ¸ä¼šä»è·¯ç”±è¡¨ä¸Šçœ‹åˆ°è¿™ä¸ª IP æ˜¯ `10.244.2.x`ï¼ˆå³æœ¬åœ°å­ç½‘ï¼‰
- å®ƒæŸ¥æ‰¾è¿™ä¸ªåœ°å€åœ¨å“ªä¸ª `caliXXXX` æ¥å£ä¸Šï¼ˆARP æŸ¥è¯¢ï¼‰ï¼Œç„¶åé€šè¿‡é‚£ä¸ªæ¥å£æŠŠåŒ…é€å…¥ Pod å®¹å™¨çš„ç½‘ç»œå‘½åç©ºé—´ã€‚

```bash
[root@node1 ~]#arp -n
åœ°å€                     ç±»å‹    ç¡¬ä»¶åœ°å€            æ ‡å¿—  Mask            æ¥å£
192.168.22.17            ether   5a:6c:92:d8:48:dd   C                     cali2c6d5459769
192.168.22.16            ether   3a:54:a9:7f:07:42   C                     cali2266a186640
192.168.22.19            ether   42:2f:fe:bf:f9:44   C                     calie58a73424e2
10.0.0.105               ether   00:50:56:25:92:3d   C                     eth0
10.0.0.103               ether   00:50:56:31:8d:87   C                     eth0
10.0.0.104               ether   00:50:56:3d:93:a0   C                     eth0
10.0.0.102               ether   00:50:56:3b:b3:19   C                     eth0
10.0.0.2                 ether   00:50:56:eb:68:01   C                     eth0
192.168.22.18            ether   26:cb:ed:9f:30:94   C                     caliecbcd92008b
192.168.22.14            ether   22:86:9f:08:b2:90   C                     calid1eb843872f
10.0.0.106               ether   00:50:56:27:b7:ba   C                     eth0
```

**è¡¥å……ï¼šPodå†…è·¯ç”±è¡¨è§£è¯»**

```bash
[root@master1 ~]#kubectl exec myapp-547df679bb-67kkp -- route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         169.254.1.1     0.0.0.0         UG    0      0        0 eth0
169.254.1.1     0.0.0.0         255.255.255.255 UH    0      0        0 eth0
```

è¿™å¼ è·¯ç”±è¡¨çš„å«ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ

ğŸ”¹ **ç½‘å…³ `169.254.1.1`**

- è¿™ä¸ª IP æ˜¯ **å®¿ä¸»æœºä¸Š veth å¯¹ç«¯ï¼ˆcaliXXXXï¼‰æ¥å£çš„åœ°å€**ã€‚
- Pod ä¸­çš„é»˜è®¤ç½‘å…³æŒ‡å‘è¿™ä¸ªåœ°å€ï¼Œæ˜¯ CNI æ’ä»¶ï¼ˆå¦‚ Calicoï¼‰**è‡ªåŠ¨åˆ†é…å¹¶æ³¨å…¥çš„â€œä¼ªç½‘å…³â€åœ°å€**ã€‚

å®ƒå…¶å® **å¹¶ä¸æ˜¯çœŸæ­£çš„ç‰©ç†è®¾å¤‡ IP**ï¼Œè€Œæ˜¯ CNI ç½‘ç»œæ’ä»¶ç”¨äºå‡ºç½‘è·¯ç”±çš„ä¸€ç§**æŠ½è±¡è·³æ¿**ï¼Œç”¨æ¥è®© Pod çš„ç½‘ç»œæµé‡ä»å®¹å™¨ç½‘ç»œç©ºé—´å‡ºæ¥ã€‚

**ğŸ”¹ é»˜è®¤è·¯ç”±ï¼ˆ0.0.0.0/0ï¼‰**

è¿™è¡Œä»£è¡¨ï¼š

```ABAP
ä»»ä½•ä¸åœ¨æœ¬åœ°å­ç½‘çš„ IPï¼Œå‘ç»™ 169.254.1.1ï¼ˆç”± eth0 æ¥å£é€å‡ºï¼‰
```

æ„æ€æ˜¯ï¼š

- å½“ Pod æƒ³è®¿é—®ä»»ä½•éæœ¬åœ°åœ°å€ï¼ˆæ¯”å¦‚å…¶ä»– Podã€Serviceã€å¤–éƒ¨ç½‘ç»œï¼‰æ—¶ï¼Œ
- å®ƒå°±ä¼šå°†æ•°æ®åŒ…å‘ç»™è¿™ä¸ªâ€œé»˜è®¤ç½‘å…³â€ã€‚

Pod ä¸­å‡ºç° `169.254.1.1` è¿™æ ·çš„ç½‘å…³åœ°å€ï¼Œ**é€šå¸¸å°±æ˜¯è·Ÿ ARP Proxyï¼ˆä»£ç† ARPï¼‰æœºåˆ¶æœ‰å…³**ï¼Œè€Œè¿™ä¸ªæœºåˆ¶é€šå¸¸ç”±åƒ Calico è¿™æ ·çš„ CNI æ’ä»¶å¯ç”¨çš„ **â€œä»£ç†ç½‘å…³â€** å®ç°ã€‚

**ğŸ”¹Proxy ARPï¼ˆä»£ç† ARPï¼‰**

**Proxy ARP** æŒ‡çš„æ˜¯ï¼š

ä¸€å°ä¸»æœºï¼ˆé€šå¸¸æ˜¯ç½‘å…³æˆ–è·¯ç”±å™¨ï¼‰**ä»£æ›¿å…¶ä»–ä¸»æœºå“åº” ARP è¯·æ±‚**ï¼Œä½¿å¾—å±€åŸŸç½‘ä¸­çš„ä¸»æœºå¯ä»¥æŠŠæµé‡å‘é€ç»™å®ƒï¼Œç„¶åç”±å®ƒæ¥è½¬å‘ã€‚

è¿™ä¸ªè¡Œä¸ºåœ¨ **Calico çš„ç›´æ¥è·¯ç”±ï¼ˆDirect Routingï¼‰æ¨¡å¼æˆ– BGP æ¨¡å¼ä¸­å¾ˆå¸¸è§**ï¼š

- æ¯ä¸ª Pod çš„ç½‘å…³è®¾ä¸º `169.254.1.1`
- å®¿ä¸»æœºï¼ˆå³ calico-nodeï¼‰é€šè¿‡å¼€å¯ `Proxy ARP`ï¼Œåœ¨å†…æ ¸ä¸­å“åº”å¯¹è¿™ä¸ªåœ°å€çš„ ARP è¯·æ±‚
- Pod å‘åŒ…æ—¶ï¼Œç›®æ ‡ MAC åœ°å€å°±ä¼šè¢«å®¿ä¸»æœºï¼ˆProxy ARPï¼‰æ¥æ”¶ï¼Œä»è€Œå°†æ•°æ®åŒ…é€å‡º

```bash
[root@node1 ~]#cat /proc/sys/net/ipv4/conf/cali2c6d5459769/proxy_arp
1
```

**ç¤ºä¾‹**

Pod è·¯ç”±ï¼š

```bash
Destination     Gateway         Genmask         Flags Iface
0.0.0.0         169.254.1.1     0.0.0.0         UG    eth0
```

å®¿ä¸»æœºä¸Šé€šè¿‡ Proxy ARP å“åº” ARP è¯·æ±‚

```bash
# Pod æƒ³æ‰¾ 169.254.1.1 çš„ MAC
# å®¿ä¸»æœºå“åº”ï¼šæˆ‘å°±æ˜¯ï¼ˆProxy ARPï¼‰
```

å®¿ä¸»æœºæ”¶åˆ°åï¼Œå¦‚æœå‘é€ç»™åŒèŠ‚ç‚¹çš„å…¶ä»–Podï¼Œåœ¨ä½¿ç”¨å®¿ä¸»æœºä¸Šçš„arpè¡¨ï¼Œå°†æ•°æ®å‘é€åˆ°å¯¹åº”çš„æ¥å£

```bash
[root@node1 ~]#arp -n
åœ°å€                     ç±»å‹    ç¡¬ä»¶åœ°å€            æ ‡å¿—  Mask            æ¥å£
192.168.22.17            ether   5a:6c:92:d8:48:dd   C                     cali2c6d5459769
192.168.22.16            ether   3a:54:a9:7f:07:42   C                     cali2266a186640
192.168.22.19            ether   42:2f:fe:bf:f9:44   C                     calie58a73424e2
10.0.0.105               ether   00:50:56:25:92:3d   C                     eth0
10.0.0.103               ether   00:50:56:31:8d:87   C                     eth0
10.0.0.104               ether   00:50:56:3d:93:a0   C                     eth0
10.0.0.102               ether   00:50:56:3b:b3:19   C                     eth0
10.0.0.2                 ether   00:50:56:eb:68:01   C                     eth0
192.168.22.18            ether   26:cb:ed:9f:30:94   C                     caliecbcd92008b
192.168.22.14            ether   22:86:9f:08:b2:90   C                     calid1eb843872f
10.0.0.106               ether   00:50:56:27:b7:ba   C                     eth0
```

å¦‚æœä¸æ˜¯åŒèŠ‚ç‚¹ï¼Œåˆ™æ ¹æ®è·¯ç”±è¡¨å‘ç»™å¯¹åº”èŠ‚ç‚¹

```ABAP
Calicoæ¨¡å¼å¯ç”¨IPIPæ¨¡å¼ï¼Œå°† Calico çš„ ipipMode è®¾ç½®æˆipipMode: Neverï¼Œæ­¤æ—¶ç¦ç”¨äº† IPIP éš§é“å°è£…ï¼Œæ–°çš„èŠ‚ç‚¹é—´é€šä¿¡ä¼šä½¿ç”¨ç›´æ¥è·¯ç”±ï¼ˆhost-gw æ¨¡å¼ï¼‰ï¼Œä¸å†ä½¿ç”¨ IPIP äº†ã€‚

ä½†æ˜¯tunl0 è¿˜åœ¨
tunl0 æ˜¯ Linux ç³»ç»Ÿä¸‹ç”± calico-node çš„ felix æˆ– bird è‡ªåŠ¨åˆ›å»ºçš„è™šæ‹Ÿç½‘ç»œæ¥å£ï¼Œç”¨æ¥å°è£…/è§£å°è£… IPIP æ•°æ®åŒ…ã€‚
ä½ å³ä½¿å°† IPIP æ¨¡å¼å…³é—­äº†ï¼š

Felix ä¸ä¼šä¸»åŠ¨åˆ é™¤ tunl0 æ¥å£
å› ä¸º Calico æ²¡æ³•åˆ¤æ–­è¿™ä¸ªæ¥å£æ˜¯å¦åœ¨è¢«å…¶ä»–ç³»ç»Ÿä½¿ç”¨
æ‰€ä»¥ä¸ºäº†å®‰å…¨èµ·è§ï¼Œå®ƒä¿ç•™äº†è¿™ä¸ªæ¥å£

å¯ä»¥æ‰‹åŠ¨åˆ é™¤tunl
ip link delete tunl0
åˆ é™¤åå¦‚æœ Calico å†æ¬¡å¯åŠ¨æ—¶ä»ç„¶å¯ç”¨äº† IPIPï¼Œå®ƒä¼šé‡æ–°åˆ›å»º tunl0
```



#### æ··åˆæ¨¡å‹

- **BGP With IPIP**
- **BGP With VXLAN**



#### éƒ¨ç½²calicoæ’ä»¶

- éƒ¨ç½²æ–¹å¼ï¼š

  - operatorï¼šç”±ä¸“ç”¨çš„operatorå’Œcrdç®¡ç†
  - manifestï¼šåŸºäºé…ç½®æ¸…å•è¿›è¡Œéƒ¨ç½²
    - å°†kubernetes apiä½œä¸ºå­˜å‚¨ï¼ŒèŠ‚ç‚¹æ•°å°äºç­‰äº50
    - å°†kubernetes apiä½œä¸ºå­˜å‚¨ï¼ŒèŠ‚ç‚¹æ•°å¤§äº50ï¼›é‡ç‚¹åœ¨äºå¯ç”¨typha
    - ä½¿ç”¨ä¸“ç”¨çš„etcdæ•°æ®å­˜å‚¨ï¼Œä¸æ¨è 

- éƒ¨ç½²å‰è¦å…³æ³¨çš„å‡ é¡¹é…ç½®

  - é€‰ç”¨çš„pod cidråŠå­ç½‘æ©ç é•¿åº¦
    - é»˜è®¤ä¸º192.168.0.0/16
    - å¯ä¿®æ”¹

  ```shell
  env:
  - name: calico_ipv4pool_cidr
    value: "192.168.0.0/16"
  - name: calico_ipv4pool_block_size
    value: "24"  # é»˜è®¤26ä½
  ```

- é€‰ç”¨çš„è·¯ç”±æ¨¡å¼

  - always, never, cross-subnet

  ```shell
  env:
  # é»˜è®¤ipip:alwaysï¼Œä¸”ipipå’Œvxlanåªèƒ½äºŒé€‰ä¸€
  - name: calico_ipv4pool_ipip
    value: "Always"
  - name: calico_ipv4pool_vxlan
    value: "Never"
  - name: calico_ipv6pool_vxlan
    value: "Never"
  ```

- ipipå’Œvxlançš„mtu

  - é»˜è®¤ç”±configmap/calico-configæä¾›é…ç½®

- bgpè¦æ˜¯ç”¨çš„ipåœ°å€

```shell
env:
- name: ip
  value: "autodetect"
  # value: "interface=ens33" 
  # é€‰æ‹©bgpé€šè¿‡å“ªä¸ªæ¥å£å°†å­ç½‘ä¿¡æ¯åŒæ­¥ç»™å…¶ä»–èŠ‚ç‚¹
  # autodetectæ˜¯è‡ªåŠ¨æ¢æµ‹
  # å¦‚æœæ¢æµ‹é”™äº†ï¼Œéœ€è¦æ‰‹åŠ¨è¿›è¡Œæ›´æ”¹ï¼Œæ‰‹åŠ¨æ›´æ”¹çš„å‰ææ˜¯æ ‡å‡†åŒ–æ¥å£åç§°ç­‰
```



#### ippool crd

ippoolçš„ä½œç”¨

- calicoå¯ç”¨äºä¸ºpodé…ç½®ipåœ°å€çš„åœ°å€æ± 
- é…ç½®è·¯ç”±æ¨¡å¼
- æ”¯æŒåœ¨åŒä¸€é›†ç¾¤ä¸Šé…ç½®ä½¿ç”¨å¤šä¸ªåœ°å€æ± 
  - å¯é€šè¿‡annotationé…ç½®é»˜è®¤çš„ippool
  - å¯é€šè¿‡nodeselectoré™å®šå…¶ä½¿ç”¨åˆ°çš„ç›®æ ‡èŠ‚ç‚¹
- éœ€è¦é¢„ç•™ä¸€å°æ®µåœ°å€æ—¶ï¼Œå¯é€šè¿‡ipreservation crdè¿›è¡Œå®šä¹‰

```yaml
apiversion: crd.projectcalico.org/v1
kind: ippool
metadata:
  name: ...
spec:
  alloweduses: <[]string> #æ”¯æŒçš„ä½¿ç”¨åœºæ™¯ï¼Œå¯é€‰é¡¹æœ‰tunnelå’Œworkload
  blocksize: <integer> # ä½¿ç”¨çš„å­ç½‘æ©ç é•¿åº¦ï¼Œipv4é»˜è®¤ä¸º26ï¼Œipv6é»˜è®¤ä¸º122
  cidr: <string>  # ä½¿ç”¨çš„cidr
  ipipmode: <string>   # ipipçš„å¯ç”¨æ¨¡å¼ï¼Œé»˜è®¤ä¸ºnever
  natoutgoing: <boolean>   # ç›®æ ‡åœ°å€ä¸åœ¨æœ¬åœ°cidrèŒƒå›´å†…æ—¶ï¼Œæ˜¯å¦å¯ç”¨snat
  vxlanmode: <string>   # vxlançš„å¯ç”¨æ¨¡å¼ï¼Œé»˜è®¤ä¸ºnever
  nodeselector: <string>  # åœ°å€æ± é€‚ç”¨åˆ°çš„ç›®æ ‡èŠ‚ç‚¹ï¼Œæ­¤ä¸ºèŠ‚ç‚¹çš„æ ‡ç­¾é€‰æ‹©å™¨
  disablebgpexport: <boolean>  # æ˜¯å¦ç¦æ­¢bgpä¼ æ’­æœ¬åœ°å€æ± å†…çš„ç›¸å…³è·¯ç”±
  disabled: <boolean> # æ˜¯å¦ç¦ç”¨æœ¬åœ°å€æ± 
```



#### calicoéƒ¨ç½²

- é‡ç½®kubeadm

```shell
kubeadm reset -f 

# æ¸…é™¤ç½‘è·¯æ’ä»¶å’Œæ®‹ç•™æ•°æ®
rm -rf /etc/cni/net.d
rm -rf $home/.kube

rm -rf /var/lib/cni
```

- ä¸»èŠ‚ç‚¹æ‰§è¡Œkubeadmåˆå§‹åŒ–

```shell
k8s_release_version=1.30.2 && kubeadm init --control-plane-endpoint kubeapi.feng.org --kubernetes-version=v${k8s_release_version} --pod-network-cidr ls
0/16 --service-cidr 10.96.0.0/12 --image-repository registry.aliyuncs.com/google_containers --token-ttl=0 --upload-certs --cri-socket=unix:///run/cri-dockerd.sock

# workerèŠ‚ç‚¹åŠ å…¥ä¸»èŠ‚ç‚¹
kubeadm join kubeapi.feng.org:6443 --token se55ec.bu2rwnwjz13os7ss \
--discovery-token-ca-cert-hash sha256:0b6211893138164398ebcb2b17661178e03010dc662ffeccc52843751a68ef91 --cri-socket=unix:///run/cri-dockerd.sock
```

- ä¸‹è½½calicoçš„yamlæ–‡ä»¶

```shell
curl https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/calico.yaml -o

# ç¼–è¾‘ä¿®æ”¹calico.yaml
# é€‰ç”¨çš„pod cidråŠå­ç½‘æ©ç é•¿åº¦  
- name: calico_ipv4pool_cidr
  vlaue: "192.168.0.0/16"
  name: calico_ipv4pool_block_size
  values: "24"

# é€‰ç”¨çš„è·¯ç”±æ¨¡å¼ï¼šalways, never, cross-subnet
env:
- name: calico_ipv4pool_ipip
  value: "always"
- name: calico_ipv4pool_vxlan
  value: "never"
- name: calico_ipv6pool_vxlan
  value: "never"
```

- æ‰§è¡Œcalicoçš„yaml

```shell
kubectl apply -f calico.yaml

# ä¸‹è½½calicoctl
curl -l https://github.com/projectcalico/calico/releases/download/v3.28.1/calicoctl-linux-amd64 -o calicoctl

# æˆæƒå¹¶åŠ å…¥pathå˜é‡
chmod +x ./calicoctl
mv calicoctl /usr/local/bin

# ä½¿ç”¨calicoctlæŸ¥çœ‹nodeçŠ¶æ€
[root@master1 ~]#calicoctl get node -o wide
name               asn       ipv4            ipv6   
master1.feng.org   (64512)   10.0.0.121/24          
worker1.feng.org   (64512)   10.0.0.122/24          
worker2.feng.org   (64512)   10.0.0.123/24          
worker3.feng.org   (64512)   10.0.0.124/24 
```

#### è·¯ç”±æ¨¡å¼åˆ†æ

- ipipæ¨¡å¼
  - ipipçš„éš§é“åœ¨éš§é“å‡ºå…¥å£å¤„ï¼ŒæŠ“ä¸åˆ°å°è£…çš„åŒ…ï¼Œå¿…é¡»åœ¨ç‰©ç†ç½‘å¡å¤„æ‰èƒ½çœ‹åˆ°å°è£…æˆèŠ‚ç‚¹æŠ¥æ–‡çš„åŒ…

#### calicoåˆ‡æ¢æ¨¡å¼

```shell
kubectl get ippool default-ipv4-ippool -o yaml > ippool.yaml

vim ippool.yaml

apiversion: crd.projectcalico.org/v1
kind: ippool
metadata:
  annotations:
    projectcalico.org/metadata: '{"creationtimestamp":"2024-08-25t11:47:34z"}'
  creationtimestamp: "2024-08-25t11:47:34z"
  generation: 1
  name: default-ipv4-ippool
  resourceversion: "1521"
  uid: 2a607e35-fdcd-4bf9-affc-86ef119e86ad
spec:
  alloweduses:
  - workload
  - tunnel
  blocksize: 24
  cidr: 192.168.0.0/16
  ipipmode: never    # å°†å…¶æ”¹ä¸ºneverï¼Œå½“ipipå’Œvxlanéƒ½æ˜¯neveræ—¶ï¼Œåˆ™æˆåŠŸåˆ‡æ¢æˆè·¯ç”±æ¨¡å¼
  natoutgoing: true
  nodeselector: all()
  vxlanmode: never

# åœ¨ä»èŠ‚ç‚¹æŸ¥çœ‹è·¯ç”±è¡¨
# éš§é“èŠ‚ç‚¹å·²ç»æ²¡äº†
å†…æ ¸ IP è·¯ç”±è¡¨
ç›®æ ‡            ç½‘å…³            å­ç½‘æ©ç         æ ‡å¿—  è·ƒç‚¹   å¼•ç”¨  ä½¿ç”¨ æ¥å£
0.0.0.0         10.0.0.2        0.0.0.0         UG    0      0        0 eth0
10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
10.244.0.0      10.0.0.121      255.255.255.0   UG    0      0        0 eth0
10.244.1.0      10.0.0.122      255.255.255.0   UG    0      0        0 eth0
10.244.2.0      10.0.0.123      255.255.255.0   UG    0      0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
192.168.163.0   10.0.0.123      255.255.255.0   UG    0      0        0 eth0
192.168.210.0   0.0.0.0         255.255.255.0   U     0      0        0 *
192.168.210.2   0.0.0.0         255.255.255.255 UH    0      0        0 cali1b10d3456be
192.168.222.0   10.0.0.122      255.255.255.0   UG    0      0        0 eth0
192.168.247.0   10.0.0.121      255.255.255.0   UG    0      0        0 eth0

# åˆ‡æ¢æ··åˆæ¨¡å¼
vim ippool.yaml

apiversion: crd.projectcalico.org/v1
kind: ippool
metadata:
  annotations:
    projectcalico.org/metadata: '{"creationtimestamp":"2024-08-25t11:47:34z"}'
  creationtimestamp: "2024-08-25t11:47:34z"
  generation: 1
  name: default-ipv4-ippool
  resourceversion: "1521"
  uid: 2a607e35-fdcd-4bf9-affc-86ef119e86ad
spec:
  alloweduses:
  - workload
  - tunnel
  blocksize: 24
  cidr: 192.168.0.0/16
  ipipmode: CrossSubnet    # æ³¨æ„Crosså’ŒSubnetä¹‹é—´æ²¡æœ‰æ¨ªæ 
  natoutgoing: true
  nodeselector: all()
  vxlanmode: never

```





#### BGP Peering

- Calicoåœ¨å„èŠ‚ç‚¹é—´åŸºäºBGPä¼ æ’­è·¯ç”±ä¿¡æ¯
  - BGPæ˜¯è·¯ç”±å™¨äº¤æ¢è·¯ç”±ä¿¡æ¯çš„æ ‡å‡†è·¯ç”±åè®®
    - iBGPï¼šInterior Border Gateway Protocola, è´Ÿè´£åœ¨åŒä¸€AS(è‡ªæ²»ç³»ç»Ÿ,æ¯ä¸ªè‡ªæ²»ç³»ç»Ÿæœ‰è‡ªå·±çš„è‡ªæ²»ç³»ç»Ÿå·)å†…çš„BGPè·¯ç”±å™¨é—´ä¼ æ’­è·¯ç”±ï¼Œå®ƒé€šè¿‡é€’å½’æ–¹å¼è¿›è¡Œè·¯å¾„é€‰æ‹©
    - eBGPï¼šExterior Border Gateway Protocolï¼Œç”¨äºåœ¨ä¸åŒASé—´ä¼ æ’­BGPè·¯ç”±ï¼Œå®ƒåŸºäºhop-by-hopæœºåˆ¶è¿›è¡Œè·¯å¾„é€‰æ‹©
  - æ¯ä¸ªè·¯ç”±å™¨éƒ½å­˜åœ¨ä¸€åˆ°å¤šä¸ªBGP Peerï¼ˆå¯¹ç­‰ç«¯ï¼‰
  - Calico Nodeèƒ½å¤ŸåŸºäºBGPåè®®å°†ç‰©ç†è·¯ç”±å™¨ä½œä¸ºBGP Peer

- BGPçš„å¸¸ç”¨æ‹“æ‰‘
  - Full-mesh
    - å¯ç”¨BGPæ—¶ï¼ŒCalicoé»˜è®¤åœ¨æ‰€æœ‰èŠ‚ç‚¹é—´å»ºç«‹ä¸€ä¸ªAS(64512)ï¼Œå¹¶åŸºäºiBGPä¸ºå®ƒä»¬åˆ›å»ºfull-meshè¿æ¥
    - è¯¥æ¨¡å¼è¾ƒé€‚ç”¨äºé›†ç¾¤è§„æ¨¡è¾ƒå°(100ä¸ªèŠ‚ç‚¹ä»¥å†…)çš„åœºæ™¯
  - Route Reflectors
    - åœ¨å¤§è§„æ¨¡çš„iBGPåœºæ™¯ä¸­ï¼ŒBGP route reflectorsèƒ½æ˜¾è‘—é™ä½æ¯ä¸ªèŠ‚ç‚¹éœ€è¦ç»´æŠ¤çš„BGP Peerçš„æ•°é‡
    - å¯é€‰æ‹©å‡ ä¸ªèŠ‚ç‚¹ä½œä¸ºBGP RR,å¹¶åœ¨è¿™äº›RRä¹‹é—´å»ºç«‹full-meshæ‹“æ‰‘
    - å…¶ä»–èŠ‚ç‚¹åªéœ€è¦åŒè¿™äº›RRä¹‹é—´å»ºç«‹Peerè¿æ¥å³å¯
  - ToR(Top of Rack)
    - èŠ‚ç‚¹ç›´æ¥åŒæœºæŸœæ ˆé¡¶çš„L3äº¤æ¢æœºå»ºç«‹Peerè¿æ¥ï¼Œå¹¶ç¦ç”¨é»˜è®¤çš„full-meshæ¨¡å¼
    - Calicoä¹Ÿèƒ½å¤Ÿå®Œå…¨æ”¯æŒeBGPæœºåˆ¶ï¼Œä»è€Œå…è®¸ç”¨æˆ·çµæ´»æ„å»ºå‡ºéœ€è¦çš„ç½‘ç»œæ‹“æ‰‘

![image-20250328211351849](../markdown_img/image-20250328211351849.png)

#### é…ç½®Route Reflectoræ¨¡å¼

- åœ¨100ä¸ªèŠ‚ç‚¹è§„æ¨¡ä»¥ä¸Šçš„Calicoé›†ç¾¤ç¯å¢ƒä¸­ï¼Œä¸ºæå‡iBGPçš„æ•ˆç‡ï¼Œé€šå¸¸åº”è¯¥å»ºç«‹Router Reflector
- åœ¨å¤§è§„æ¨¡ Kubernetes é›†ç¾¤ä¸­ï¼Œ**å»ºè®®ä½¿ç”¨å¤šä¸ª Worker èŠ‚ç‚¹ä½œä¸º Route Reflectorï¼ˆRRï¼‰**ï¼Œä»¥æé«˜ **BGP è·¯ç”±çš„æ‰©å±•æ€§ã€ç¨³å®šæ€§å’Œæ€§èƒ½**ã€‚
- é…ç½®æ­¥éª¤
  - ç¦ç”¨é»˜è®¤çš„Full-meshæ‹“æ‰‘
  - åœ¨é€‰å®šçš„RRèŠ‚ç‚¹ä¸Šæ·»åŠ ä¸“ç”¨çš„èŠ‚ç‚¹æ ‡ç­¾
  - é…ç½®é›†ç¾¤èŠ‚ç‚¹åŒRRèŠ‚ç‚¹å»ºç«‹BGPä¼šè¯

- åˆ›å»ºBGPConfigurationå¯¹è±¡ï¼Œç¦ç”¨é»˜è®¤çš„full-meshæ‹“æ‰‘

```yaml
# æŸ¥çœ‹calicoçš„crdèµ„æº
[root@master1 ~]#kubectl get crd -n -A|grep -i bgp
bgpadvertisements.metallb.io                          2025-03-26T13:48:53Z
bgpconfigurations.crd.projectcalico.org               2025-03-26T13:42:55Z
bgpfilters.crd.projectcalico.org                      2025-03-26T13:42:55Z
bgppeers.crd.projectcalico.org                        2025-03-26T13:42:55Z
bgppeers.metallb.io                                   2025-03-26T13:48:53Z

# åˆ›å»ºbgpconfigurations.crd.projectcalico.orgèµ„æº
apiVersion: crd.projectcalico.org/v1
kind: BGPConfiguration
metadata:
  name: default
spec:
  logSeverityScreen: Info
  # æ˜¯å¦å¯ç”¨full-meshæ¨¡å¼ï¼Œé»˜è®¤ä¸ºtrue
  nodeToNodeMeshEnabled: false
  nodeMeshMaxRestartTime: 120s
  # ä½¿ç”¨çš„è‡ªæ²»ç³»ç»Ÿå·ï¼Œé»˜è®¤ä¸º64512
  asNumber: 65009
  # BGPè¦å¯¹å¤–é€šå‘Šçš„Service CIDR
  ServiceClusterIPs:
  - cidr: 10.96.0.0/12
 
```

- åˆ›å»ºBGPPeerå¯¹è±¡ï¼Œé…ç½®æ‰€æœ‰èŠ‚ç‚¹åŒé€‰å®šçš„RRèŠ‚ç‚¹å»ºç«‹BGP Peer

```yaml
# åˆ›å»ºbgppeers.crd.projectcalico.org
apiVersion: crd.projectcalico.org/v1
kind: BGPPeer
metadata:
  name: bgppeer-rr
spec:
  # èŠ‚ç‚¹æ ‡ç­¾é€‰æ‹©å™¨ï¼Œå®šä¹‰å½“å‰é…ç½®è¦ç”Ÿæ•ˆåˆ°çš„ç›®æ ‡èŠ‚ç‚¹
  nodeSelector: all()
  # è¯¥èŠ‚ç‚¹è¦è¯·æ±‚ä¸ä¹‹å»ºç«‹BGP Peerçš„èŠ‚ç‚¹æ ‡ç­¾é€‰æ‹©å™¨ï¼Œç”¨äºè¿‡æ»¤å’Œé€‰å®šè¿œç«¯èŠ‚ç‚¹
  peerSelector: route-reflector == 'true'
 
```



**è¯¦ç»†é…ç½®ç¤ºä¾‹**

```http
https://github.com/iKubernetes/learning-k8s/tree/master/ProjectCalico
```









### Cilium ç½‘ç»œæ’ä»¶

Flannel å’Œ Calico æ˜¯åˆ©ç”¨å†…æ ¸ä¸­çš„ Netfilter ä»è€Œå®ç°ç½‘ç»œè·¯ç”±å®ç°ï¼Œè€Œ Cilium æ˜¯ä½¿ç”¨ebpfå®ç°çš„

| é¡¹ç›®        | æŠ€æœ¯æœºåˆ¶                                                     | å®ç°è¯´æ˜                             |
| ----------- | ------------------------------------------------------------ | ------------------------------------ |
| **Flannel** | ä½¿ç”¨ Linux è·¯ç”±è¡¨ + VXLAN/IPIP + iptablesï¼ˆNetfilterï¼‰       | æ¯”è¾ƒç®€å•ï¼Œä¸è´Ÿè´£å®‰å…¨ç­–ç•¥ã€æœåŠ¡å‘ç°ç­‰ |
| **Calico**  | ä½¿ç”¨ Linux è·¯ç”±è¡¨ã€IPIP/VXLAN/ç›´æ¥è·¯ç”± + iptablesï¼ˆNetfilterï¼‰ | è´Ÿè´£ç½‘ç»œç­–ç•¥ï¼Œæ”¯æŒ BGPï¼ŒåŠŸèƒ½æ›´å¼º     |
| **Cilium**  | ä½¿ç”¨ **eBPF**ï¼ˆæ‰©å±•çš„ BPFï¼‰æ¥æ›¿ä»£ä¼ ç»Ÿ iptablesã€å®ç°è´Ÿè½½å‡è¡¡ã€ç½‘ç»œç­–ç•¥ã€å®‰å…¨ç›‘æ§ç­‰ | é«˜æ€§èƒ½ã€ä½å»¶è¿Ÿã€äº‘åŸç”Ÿå‹å¥½           |



#### eBPF ç®€ä»‹

eBPF å…¨ç§°æ˜¯ï¼š**extended Berkeley Packet Filter**

å®ƒæ˜¯ä¸€ç§è¿è¡Œåœ¨ Linux å†…æ ¸ä¸­çš„â€œæ²™ç›’åŒ–ç¨‹åºâ€ï¼Œå¯ä»¥åœ¨å†…æ ¸ä¸­è¿è¡Œç”¨æˆ·å®šä¹‰çš„é€»è¾‘ï¼Œè€Œ **ä¸éœ€è¦å†…æ ¸æ¨¡å—é‡ç¼–è¯‘æˆ–é‡å¯ç³»ç»Ÿ**ã€‚

**eBPF å¯ä»¥åšä»€ä¹ˆï¼Ÿ**

- æ•°æ®åŒ…è¿‡æ»¤ï¼ˆæ¯” iptables æ›´é«˜æ•ˆï¼‰
- è·¯ç”±è½¬å‘ï¼ˆå¦‚ Cilium ç›´æ¥ç”¨ eBPF å®ç° pod ç½‘ç»œè½¬å‘ï¼‰
- æ€§èƒ½ç›‘æ§ï¼ˆå¦‚ `bcc`ã€`bpftrace` å·¥å…·ï¼‰
- ç³»ç»Ÿè°ƒç”¨æ‹¦æˆªï¼ˆç”¨äºå®‰å…¨ç­–ç•¥ã€å®¡è®¡ï¼‰
- è´Ÿè½½å‡è¡¡ï¼ˆCilium çš„ kube-proxy æ›¿ä»£æ–¹æ¡ˆï¼‰



#### éš§é“æ¨¡å¼ï¼ˆOverlayï¼‰

- **VXLAN**
- **GENEVE**
- **BGPï¼ˆCiliumè¦ä½¿ç”¨BGPï¼Œå¿…é¡»éƒ¨ç½²kube-routerï¼‰**





#### è·¯ç”±æ¨¡å‹ï¼ˆUnderlayï¼‰





### NetWork Policy

#### NetWork Policy **ç®€ä»‹**

- æ ‡å‡†çš„ API èµ„æºç±»å‹
- ç”±ç½‘ç»œæ’ä»¶è´Ÿè´£è½¬æ¢ä¸ºèŠ‚ç‚¹ä¸Šçš„iptables Filterè§„åˆ™ï¼Œå·²å®šä¹‰ Pod é—´çš„é€šä¿¡è®¸å¯
- ä¸»è¦é’ˆå¯¹ TCPã€UDPçš„ SCTP åè®®ï¼Œå®ç°åœ¨ IPåœ°å€ æˆ–è€… Portå±‚é¢ è¿›è¡Œæµé‡æ§åˆ¶
- **NetworkPolicy å°±æ˜¯é’ˆå¯¹ä¸€ç»„ Pod è¿›è¡Œç®¡æ§ï¼Œè¦ä¹ˆæ˜¯ç®¡æ§è‡ªå·±èƒ½å¤Ÿè®¿é—®è°ï¼ˆEgressï¼‰ï¼Œè¦ä¹ˆæ˜¯ç®¡æ§è°èƒ½è®¿é—®æˆ‘ï¼ˆIngressï¼‰**
  - NetworkPolicy ä¸æ˜¯è®¾ç½®åœ¨é›†ç¾¤å…¨å±€çš„ï¼Œå®ƒæ˜¯ **ä½œç”¨äºè¢«é€‰ä¸­çš„ä¸€ç»„ Pod**ï¼ˆé€šè¿‡ `podSelector`ï¼‰ã€‚
  - å°±åƒä½ ç»™æŸäº› Pod è£…äº†é˜²ç«å¢™ï¼Œå®ƒä»¬èƒ½ä¸èƒ½è®¿é—®åˆ«äººã€èƒ½ä¸èƒ½è¢«åˆ«äººè®¿é—®ï¼Œå…¨çœ‹ä½ åœ¨ Policy é‡Œæ€ä¹ˆå†™ã€‚



#### Network Policy çš„åŠŸèƒ½

- é’ˆå¯¹ä¸€ç»„Podï¼Œå®šä¹‰å…¶åŒå¯¹ç«¯å®ä½“é€šä¿¡æ—¶ï¼Œåœ¨å…¥å‘ï¼ˆIngressï¼‰æˆ–/å’Œ å‡ºå‘ï¼ˆEgressï¼‰æµé‡ä¸Šçš„æ§åˆ¶è§„åˆ™
- æè¿°å¯¹ç«¯å®ä½“çš„æ–¹æ³•æœ‰å¦‚ä¸‹å‡ ç§
  - ä¸€ç»„ Pod å¯¹è±¡ï¼Œé€šå¸¸åŸºäºæ ‡ç­¾é€‰æ‹©å™¨å®šä¹‰ç­›é€‰æ¡ä»¶
  - å•ä¸ªæˆ–ä¸€ç»„åç§°ç©ºé—´
  - IPåœ°å€å—ï¼ˆä½† Pod åŒå…¶æ‰€åœ¨çš„èŠ‚ç‚¹é—´çš„é€šä¿¡ä¸å—é™åˆ¶ï¼‰
- Network Policy çš„å…·ä½“å®ç°ä¾èµ–äº Network Plugin



#### Network Policy çš„ç”Ÿæ•ˆæœºåˆ¶

- é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸€ç»„Podä¸Šçš„å‡ºå‘å’Œå…¥å‘æµé‡å‡è¢«å…è®¸
- åŒä¸€æ–¹å‘ä¸Šï¼Œé€‚ç”¨äºä¸€ç»„Podçš„å¤šä¸ªè§„åˆ™çš„ç”Ÿæ•ˆéµå¾ªåŠ æ³•æœºåˆ¶
  - ä¸€ç»„Podä¸Šï¼Œå¤šä¸ªIngressç­–ç•¥ç›¸åŠ æ‰€ç”Ÿæˆçš„é›†åˆï¼ˆå¹¶é›†ï¼‰æ˜¯ä¸ºæœ€ç»ˆç”Ÿæ•ˆçš„æ•ˆæœ
  - ä¸€ç»„Podä¸Šï¼Œå¤šä¸ªEgressç­–ç•¥ç›¸åŒæ‰€ç”Ÿæˆçš„é›†åˆæ˜¯ä¸ºæœ€ç»ˆç”Ÿæ•ˆçš„ç­–ç•¥	

- è‹¥åŒæ—¶å®šä¹‰äº†Ingresså’ŒEgressè§„åˆ™ï¼Œé’ˆå¯¹ä¸€ä¸ªå¯¹ç«¯ï¼ŒåŒå‘ç­–ç•¥éƒ½ä¸ºâ€œè®¸å¯â€ï¼Œé€šä¿¡æ‰èƒ½çœŸå®å®ç°



#### Network Policy èµ„æºè§„èŒƒ

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ...
  namespace: ...          # NetworkPolicyæ˜¯åç§°ç©ºé—´çº§åˆ«çš„èµ„æº
spec:
  egress:                 # å‡ºå‘æµé‡æ§åˆ¶è§„åˆ™ï¼Œé»˜è®¤å¼€æ”¾
    to:                   # å‡ºå‘æµé‡æ§åˆ¶è§„åˆ™ï¼Œé»˜è®¤ä¸ºå¼€æ”¾ï¼›æµé‡ç›®æ ‡çš„è¡¨ç¤ºæ–¹å¼ä¸Ingress.fromç›¸åŒ 
    ports:                # å‡ºå‘æµé‡çš„ç›®æ ‡ç«¯å£ï¼›æµé‡ç›®æ ‡ç«¯å£çš„è¡¨ç¤ºæ–¹å¼ä¸Ingress.portsç›¸åŒ
  ingress:                # å…¥å‘æµé‡æ§åˆ¶è§„åˆ™ï¼Œé»˜è®¤å¼€æ”¾
    from:                 # å…¥å‘æµé‡æºï¼Œå¤šä¸ªåˆ—è¡¨é¡¹ä¹‹é—´ä¸º"æˆ–"é€»è¾‘ï¼›æœªç»™å®šä»»ä½•å€¼æˆ–æœªå®šä¹‰è¯¥å­—æ®µï¼Œå°†åŒ¹é…æ‰€æœ‰æµé‡æºï¼›
                          # å®šä¹‰äº†è¯¥å­—æ®µä¸”è‡³å°‘å­˜åœ¨ä¸€ä¸ªitemï¼Œåˆ™è¡¨ç¤ºä»…å…è®¸æŒ‡å®šçš„æµé‡æº
      ipBlock:            # æºIPåœ°å€æ®µï¼Œé€šå¸¸æ˜¯ç½‘ç»œåœ°å€ï¼›ä¸æ”¯æŒåŒNamespaceSelectoræˆ–podSeletoråŒæ—¶ä½¿ç”¨ï¼›
        cidr:             # CIDRæ ¼å¼çš„ç½‘ç»œåœ°å€
        except:           # è¦æ’é™¤çš„åœ°å€åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯CIDRæ ¼å¼çš„å­ç½‘åœ°å€
      namespaceSelector:  # namespaceæ ‡ç­¾é€‰æ‹©å™¨ï¼Œç”¨äºè¡¨ç¤ºæºè‡ªåŒ¹é…åˆ°çš„Namespaceå†…çš„æ‰€æœ‰æµé‡
      podSelector:        # podæ ‡ç­¾é€‰æ‹©å™¨ï¼Œç”¨äºè¡¨ç¤ºæºè‡ªåŒ¹é…åˆ°çš„Podä¸Šçš„æ‰€æœ‰æµé‡ï¼›å¯ä»¥åŒnamespaceSelectoråŒæ—¶ä½¿ç”¨
                          # ç”¨äºåŒ¹é…é€‰å®šçš„namespaceä¸­çš„pod
    ports:                # å…¥å‘æµé‡çš„ç›®æ ‡ç«¯å£ï¼Œå³æµé‡æºè¦è®¿é—®çš„ç›®æ ‡ç«¯å£ï¼Œç”Ÿæ•ˆæœºåˆ¶åŒfrom
      port:               # ç«¯å£ï¼ŒåŒendPortå­—æ®µåŒæ—¶ä½¿ç”¨æ—¶ï¼Œè¡¨ç¤ºç«¯å£èŒƒå›´çš„èµ·å§‹ç«¯å£å·
      endpoint:           # ç«¯å£å·ï¼šåŒportå­—æ®µåŒæ—¶ä½¿ç”¨æ—¶ï¼Œè¡¨ç¤ºç«¯å£èŒƒå›´çš„ç»“æŸç«¯å£å·
      protocol:           # åè®®ï¼Œä»…æ”¯æŒTCPã€UDPå’ŒSCTPï¼Œé»˜è®¤ä¸ºTCP
  podSelector:            # Podæ ‡ç­¾é€‰æ‹©å™¨ï¼Œç”¨äºé€‰å®šæµé‡è§„åˆ™é€‚ç”¨çš„å¯¹è±¡ï¼Œå¿…é€‰å­—æ®µ
  policyTypes:            # è§„åˆ™ç±»å‹ï¼Œæ”¯æŒIngressï¼ŒEgressï¼Œé»˜è®¤åœ¨ä¸¤ä¸ªæ–¹å‘ä¸ŠåŒæ—¶ç”Ÿæ•ˆ
```



#### Network Policy èµ„æºç¤ºä¾‹

```yaml
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-all-ingress
spec:
  podSelector: {}
  ingress:            
  - {}     # æ­¤å¤„ï¼Œé…ç½®äº†Ingresså­—æ®µï¼Œä¸”æ·»åŠ äº†ä¸€ä¸ªåˆ—è¡¨å…ƒç´ ï¼Œè¡¨ç¤ºä»…å…è®¸åŒ¹é…åˆ°çš„æµé‡æºï¼Œè€Œä¸€ä¸ªä¸ºç©ºçš„å…ƒç´ åˆ™è¡¨ç¤ºåŒ¹é…æ‰€æœ‰æµé‡æº
  policyTypes:
  - Ingress
```

```yaml
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
spec:
  podSelector: {}
  # ingress:
  ingress: []  # æ­¤å¤„ï¼Œä¸åŒ¹é…ingresså­—æ®µï¼Œæˆ–ä½¿ç”¨å¦‚ä¸‹ä¸¤ç§æ–¹å¼ä¹‹ä¸€ï¼Œæ„ä¹‰ç›¸åŒï¼›å®ƒä»¬è¡¨ç¤ºä¸åŒ¹é…ä»»ä½•æµé‡æºï¼šingress:|ingress:[]
  policyTypes:
  - ingress
```

```yaml
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-selector-ingresses
  namespace: default
spec:
  podSelector: {}
  ingress:
  - from:  # ç¬¬ä¸€ä¸ªfromä¸­ä¸¤ä¸ªåˆ—è¡¨å…ƒç´ namespaceSelectorå’ŒipBlockï¼Œå®ƒä»¬æ˜¯å¹¶åˆ—å…³ç³»ï¼Œå³åŒ¹é…ä¸¤ä¸ªè§„åˆ™ï¼Œå› æ­¤å–æˆ–
    - namespaceSelector:
      matchExpressions:
      - key: kubernetes.io/metadata.name
        operator: in
        values: ["default", "kuber-system", "monitor"]  # å¦‚æœåŒä¸€åç§°ç©ºé—´ä¸­ï¼Œæ²¡æœ‰åŒ¹é…è‡ªå·±çš„åç§°ç©ºé—´ï¼Œåˆ™åç§°ç©ºé—´å†…éƒ¨æ—                                                            æ³•é€šä¿¡
    - ipBlock:
      cidr: 192.168.10.0/24
    ports: []  # portsä¸ºç©ºï¼Œè¡¨ç¤ºå…¨åŒ¹é…
  - from:  # ç¬¬äºŒä¸ªfromä¸­æ˜¯ç¬¬ä¸€ä¸ªåˆ—è¡¨å…ƒç´ ä¸­çš„å­—æ®µå…ƒç´ namespaceSelectorå’ŒpodSelector,å³ä¸€ä¸ªåŒ¹é…è§„åˆ™ä¸¤ä¸ªæ¡ä»¶ï¼Œå› æ­¤å–ä¸
    - namespaceSelector:   # ä¸¤ä¸ªfromå½¼æ­¤é—´æ˜¯æˆ–é€»è¾‘
        matchLabels:
          kubernetes.io/metadata.name: demo
      podSelector:
        matchExpressions:
        - key: app
          operator: in
          values: ["demoapp","nginx"]
    ports:
    - port: 80
      protocol: TCP
  policyTypes:
  - ingress
```





## Kubernetes æŒ‡æ ‡æµæ°´çº¿

### èµ„æºæŒ‡æ ‡

Kubernetesæœ‰ä¸€äº›ä¾èµ–äºæŒ‡æ ‡æ•°æ®çš„ç»„ä»¶ï¼Œä¾‹å¦‚**HPA**å’Œ**VPA**ç­‰ã€

- Kubernetes ä½¿ç”¨ Metrics API æš´éœ²ç³»ç»ŸæŒ‡æ ‡ç»™è¿™äº›ç»„ä»¶
- è¯¥ API ä»…æä¾› CPU å’Œå†…å­˜ç›¸å…³çš„æŒ‡æ ‡æ•°æ®
- è´Ÿè´£æ”¯æ’‘Metrics APIã€ç”Ÿæˆå¹¶æä¾›æŒ‡æ ‡æ•°æ®çš„ç»„ä»¶ï¼Œç§°ä¸ºæ ¸å¿ƒæŒ‡æ ‡æµæ°´çº¿ï¼ˆCore Metrics Pipelineï¼‰

![image-20250330151801963](../markdown_img/image-20250330151801963.png)

- **cAdvisor**: ç”¨äºæ”¶é›†ã€èšåˆå’Œå…¬å¼€ Kubelet ä¸­åŒ…å«çš„å®¹å™¨æŒ‡æ ‡çš„å®ˆæŠ¤ç¨‹åºã€‚
- **kubelet**: ç”¨äºç®¡ç†å®¹å™¨èµ„æºçš„èŠ‚ç‚¹ä»£ç†ã€‚ å¯ä»¥ä½¿ç”¨ /metrics/resource å’Œ /stats kubelet API ç«¯ç‚¹è®¿é—®èµ„æºæŒ‡æ ‡ã€‚
- **Summary API**: kubelet æä¾›çš„ APIï¼Œç”¨äºå‘ç°å’Œæ£€ç´¢å¯é€šè¿‡ /stats ç«¯ç‚¹è·å¾—çš„æ¯ä¸ªèŠ‚ç‚¹çš„æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯ã€‚
- **metrics-server**: é›†ç¾¤æ’ä»¶ç»„ä»¶ï¼Œç”¨äºæ”¶é›†å’Œèšåˆä»æ¯ä¸ª kubelet ä¸­æå–çš„èµ„æºæŒ‡æ ‡ã€‚ API æœåŠ¡å™¨æä¾› Metrics API ä»¥ä¾› HPAã€VPA å’Œ kubectl top å‘½ä»¤ä½¿ç”¨ã€‚Metrics Server æ˜¯ Metrics API çš„å‚è€ƒå®ç°ã€‚
- **Metrics API**: Kubernetes API æ”¯æŒè®¿é—®ç”¨äºå·¥ä½œè´Ÿè½½è‡ªåŠ¨ç¼©æ”¾çš„ CPU å’Œå†…å­˜ã€‚ è¦åœ¨ä½ çš„é›†ç¾¤ä¸­è¿›è¡Œè¿™é¡¹å·¥ä½œï¼Œä½ éœ€è¦ä¸€ä¸ªæä¾› Metrics API çš„ API æ‰©å±•æœåŠ¡å™¨ã€‚

```ABAP
cAdvisor æ˜¯ kubelet å†…ç½®çš„å®¹å™¨ç›‘æ§æ¨¡å—ï¼Œè´Ÿè´£å°†èŠ‚ç‚¹ä¸Šæ¯ä¸ªå®¹å™¨çš„èµ„æºä½¿ç”¨æ•°æ®é‡‡é›†å¹¶æä¾›ç»™ç›‘æ§ç³»ç»Ÿä½¿ç”¨ã€‚
```



Kubernetesè®¾è®¡ç”¨äºæš´éœ²å…¶å®ƒæŒ‡æ ‡çš„APIï¼Œæ˜¯**Custom  Metrics API** å’Œ **External Metrics API**

- æ­¤äºŒè€…é€šå¸¸ä¹Ÿè¦ç”±ä¸“ç”¨çš„è¾…åŠ©API Serveræä¾›ï¼Œä¾‹å¦‚è‘—åçš„ **Prometheus Adapter** é¡¹ç›®
- è´Ÿè´£æ”¯æ’‘Custom Metrics APIï¼Œç”Ÿæˆå¹¶æä¾›æŒ‡æ ‡æ•°æ®çš„ç»„ä»¶ï¼Œç§°ä¸º**è‡ªå®šä¹‰æµæ°´çº¿**



### æ ¸å¿ƒæŒ‡æ ‡æµæ°´çº¿å’Œè‡ªå®šä¹‰æŒ‡æ ‡æµæ°´çº¿



![image-20250330152904957](../markdown_img/image-20250330152904957.png)



#### Metrics Server

**Metrics Serverä»‹ç»**

ç”±Kubernetes SIGç¤¾åŒºç»´æŠ¤

ä»Kubeletæ”¶é›†CPUå’Œå†…å­˜çš„èµ„æºæŒ‡æ ‡ï¼Œé»˜è®¤æ¯15ç§’æ”¶é›†ä¸€æ¬¡ï¼Œå¹¶ç»ç”±Metrics APIæš´éœ²

è®¾è®¡ç”¨äºæ”¯æ’‘HPAå’ŒVPAç­‰ç»„ä»¶çš„åŠŸèƒ½ï¼Œä¸é€‚ç”¨äºä½œä¸ºç›‘æ§ç³»ç»Ÿç»„ä»¶



**éƒ¨ç½²è¦æ±‚**

kube-apiserver å¿…é¡»å¯ç”¨èšåˆå±‚

å„èŠ‚ç‚¹å¿…é¡»å¯ç”¨Webhookè®¤è¯å’Œé‰´æƒæœºåˆ¶

kubeletè¯ä¹¦éœ€è¦ç”±Kubernetes CAç­¾åï¼Œæˆ–è€…è¦ä½¿ç”¨"**--kubelet-insecure-tls**" é€‰é¡¹ç¦ç”¨è¯ä¹¦éªŒè¯

Container Runtimeéœ€è¦æ”¯æŒcontainer metrics RPCï¼Œæˆ–è€…å†…ç½®**cAdvisor**

æ§åˆ¶å¹³é¢èŠ‚ç‚¹éœ€è¦ç»ç”±**10250/TCP** ç«¯å£è®¿é—® Metrics Server

Metrics Serveréœ€è¦è®¿é—®æ‰€æœ‰çš„èŠ‚ç‚¹ä»¥é‡‡é›†æŒ‡æ ‡ï¼Œé»˜è®¤ä¸º kubelet ç›‘å¬çš„ 10250 ç«¯å£

```bash
[root@master1 ~]# curl -LO https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

#é»˜è®¤æ–‡ä»¶éœ€è¦ä¿®æ”¹æ‰èƒ½å·¥ä½œ,å› ä¸ºé»˜è®¤éœ€è¦å†…éƒ¨è¯ä¹¦éªŒè¯å’Œé•œåƒåœ°å€k8s.gcr.ioæ‰€ä»¥ä¿®æ”¹
# vim components.yaml
spec:
      containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=10250
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        - --kubelet-insecure-tls
        #image: registry.cn-hangzhou.aliyuncs.com/google_containers/metricsserver:v0.7.1 # å¯ä»¥æ·»åŠ å›½å†…æº
        image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /livez
            port: https
            scheme: HTTPS
          periodSeconds: 10
        name: metrics-server
        ports:
        - containerPort: 10250
          name: https
          protocol: TCP
          
[root@master1 yaml]# kubectl apply -f components.yaml 
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created


root@master1 yaml]#kubectl get pod -n kube-system metrics-server-b79d5c976-hqrct 
NAME                             READY   STATUS    RESTARTS   AGE
metrics-server-b79d5c976-hqrct   1/1     Running   0          60s
[root@master1 yaml]#kubectl top node
NAME      CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
master1   62m          3%     910Mi           49%       
node1     30m          1%     669Mi           36%       
node2     20m          1%     927Mi           50%       
node3     27m          1%     715Mi           39% 
```



#### æ ¸å¿ƒæŒ‡æ ‡æµæ°´çº¿ï¼ˆCore Metrics Pipelineï¼‰å®šä¹‰

**æ ¸å¿ƒæŒ‡æ ‡æµæ°´çº¿ï¼ˆCore Metrics Pipelineï¼‰** æ˜¯ Kubernetes ä¸­ä¸€æ¡ç”± kubelet æä¾›æŒ‡æ ‡ï¼ŒMetrics Server èšåˆå¤„ç†çš„åŸºç¡€ç›‘æ§æ•°æ®é“¾è·¯ï¼Œä¸“é—¨ç”¨äºæ”¯æŒ HPAï¼ˆHorizontal Pod Autoscalerï¼‰ã€VPAï¼ˆéƒ¨åˆ†åœºæ™¯ï¼‰ã€`kubectl top` å‘½ä»¤ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚



**æ„æˆç»„ä»¶**

| ç»„ä»¶                  | è§’è‰²       | è¯´æ˜                                                         |
| --------------------- | ---------- | ------------------------------------------------------------ |
| **cAdvisor**          | æŒ‡æ ‡é‡‡é›†å™¨ | kubelet å†…åµŒï¼Œé‡‡é›†å®¹å™¨çš„ CPUã€å†…å­˜ç­‰å®æ—¶æŒ‡æ ‡                 |
| **kubelet**           | æŒ‡æ ‡æä¾›è€… | æä¾› `/metrics/resource` å’Œ `/stats/summary` æ¥å£ï¼Œè¢« Metrics Server æ‹‰å– |
| **Metrics Server**    | æŒ‡æ ‡èšåˆå™¨ | è´Ÿè´£ä»æ¯ä¸ª Node çš„ kubelet æ‹‰å–æŒ‡æ ‡ï¼Œå­˜å…¥å†…å­˜ä¸­ï¼Œæš´éœ² `/apis/metrics.k8s.io/` æ¥å£ |
| **HPA / kubectl top** | æ¶ˆè´¹è€…     | HPA æŸ¥è¯¢ Metrics Server çš„ APIï¼Œæ ¹æ®ç­–ç•¥è¿›è¡Œè‡ªåŠ¨æ‰©ç¼©å®¹ï¼›kubectl top å‘½ä»¤å±•ç¤ºèŠ‚ç‚¹/Pod å®æ—¶èµ„æºä½¿ç”¨ |



åœ¨ **æ ¸å¿ƒæŒ‡æ ‡æµæ°´çº¿** ä¸­ï¼Œ**Metrics Server** å°±æ˜¯ä¸€ä¸ªä¸­é—´æ¡¥æ¢ï¼Œå®ƒçš„æ ¸å¿ƒä½œç”¨å°±æ˜¯ï¼š

âœ… **ä»å„ä¸ª Node çš„ kubeletï¼ˆåº•å±‚ç”± cAdvisor æä¾›æŒ‡æ ‡ï¼‰æ‹‰å–æŒ‡æ ‡**ï¼Œ
âœ… **è½¬åŒ–ä¸º Kubernetes æ‰€ç†è§£çš„ Metrics API æ ¼å¼**ï¼Œ
âœ… å¹¶é€šè¿‡ `/apis/metrics.k8s.io/v1beta1` æš´éœ²å‡ºæ¥ï¼Œä¾› **HPAã€kubectl topã€VPAï¼ˆéƒ¨åˆ†ï¼‰** ä½¿ç”¨ã€‚



**æ•´ä½“æµç¨‹**

- `cAdvisor` æ˜¯ kubelet å†…ç½®ç»„ä»¶ï¼Œé‡‡é›†å®¹å™¨çº§åˆ«çš„ CPUã€å†…å­˜ã€ç½‘ç»œç­‰åŸå§‹æŒ‡æ ‡ï¼›
- `kubelet` ä¼šæä¾› `/stats/summary` æ¥å£ï¼ŒæŠŠè¿™äº›åŸå§‹æŒ‡æ ‡ç»“æ„åŒ–ï¼›
- `Metrics Server` ä»¥ **å®šæ—¶è½®è¯¢ï¼ˆé»˜è®¤ 60sï¼‰** çš„æ–¹å¼ï¼Œä»æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„ kubelet æ‹‰è¿™äº›æ•°æ®ï¼›
- ç„¶åèšåˆå¹¶ç¼“å­˜ï¼ˆä¿ç•™çŸ­æ—¶é—´ï¼‰è¿™äº›æ•°æ®ï¼›
- æœ€åé€šè¿‡ Kubernetes çš„ API Server ç»Ÿä¸€æš´éœ²ä¸º `metrics.k8s.io` API ç»„ã€‚

```ABAP
æ ¸å¿ƒæŒ‡æ ‡æµæ°´çº¿ = kubelet + cAdvisor + Metrics Server + HPAï¼Œå®ƒæ˜¯ Kubernetes å†…å»ºçš„æœ€è½»é‡çº§çš„å®æ—¶èµ„æºç›‘æ§å’Œè‡ªåŠ¨æ‰©ç¼©å®¹é€šé“ã€‚
```



æ ¸å¿ƒæŒ‡æ ‡æµæ°´çº¿ä»…æš´éœ²CPUå’Œå†…å­˜æŒ‡æ ‡ï¼Œè€Œæ›´å¤šçš„å…¶ä»–æŒ‡æ ‡å¹¶ä¸æ”¯æŒï¼Œå¦‚æœéœ€è¦ä½¿ç”¨æ›´å¤šçš„æŒ‡æ ‡ï¼Œæ­¤éœ€è¦è‡ªå®šä¹‰æŒ‡æ ‡æµæ°´çº¿



#### è‡ªå®šä¹‰æŒ‡æ ‡æµæ°´çº¿ï¼ˆCustom Metrics Pipelineï¼‰

**è‡ªå®šä¹‰æŒ‡æ ‡æµæ°´çº¿å®šä¹‰**

**è‡ªå®šä¹‰æŒ‡æ ‡æµæ°´çº¿**æ˜¯æŒ‡ Kubernetes é›†ç¾¤ä¸­ï¼Œç”¨äºæ”¶é›†ã€å¤„ç†ã€æš´éœ²å’Œæ¶ˆè´¹ç”¨æˆ·è‡ªå·±å®šä¹‰çš„ä¸šåŠ¡æŒ‡æ ‡æˆ–åº”ç”¨æ€§èƒ½æŒ‡æ ‡çš„æ•´å¥—ä½“ç³»ã€‚å®ƒé€šå¸¸æœåŠ¡äºï¼š

- â« **HPAï¼ˆHorizontalPodAutoscalerï¼‰åŸºäºè‡ªå®šä¹‰æŒ‡æ ‡çš„è‡ªåŠ¨æ‰©ç¼©å®¹**
- ğŸ“ˆ **VPA æˆ–å…¶ä»–ç­–ç•¥å‹æ§åˆ¶å™¨çš„æŒ‡æ ‡è¾“å…¥**
- âœ… æ›´å¤æ‚çš„ä¸šåŠ¡åœºæ™¯ï¼ˆæ¯”å¦‚ QPSã€æ•°æ®åº“è¿æ¥æ•°ã€Redis hit rateï¼‰



##### è‡ªå®šä¹‰æŒ‡æ ‡æµæ°´çº¿çš„ç»„æˆç»“æ„

å¯ä»¥åˆ†ä¸º **ä¸‰ä¸ªå±‚æ¬¡**ï¼š

**1ï¸âƒ£ åº”ç”¨å±‚ï¼ˆä¸šåŠ¡ä¾§ï¼‰ï¼šäº§ç”ŸæŒ‡æ ‡**

- åº”ç”¨è‡ªèº«æš´éœ² Prometheus æ ¼å¼çš„ `/metrics` æ¥å£ï¼Œä¾‹å¦‚ï¼š

  ```properties
  http_requests_total{job="myapp", status="200"} 1234
  redis_connection_pool_size{instance="redis"} 42
  ```

**2ï¸âƒ£ æŒ‡æ ‡æ”¶é›†å±‚ï¼šPrometheus + Adapter**

- **Prometheus**ï¼šè´Ÿè´£æŠ“å–ä¸šåŠ¡ Pod æš´éœ²çš„æŒ‡æ ‡
- **Custom Metrics Adapter**ï¼ˆå¦‚ Prometheus Adapterï¼‰ï¼š
  - è´Ÿè´£å°† Prometheus ä¸­çš„æŒ‡æ ‡è½¬æ¢ä¸º Kubernetes æ‰€è¯†åˆ«çš„ API æ ¼å¼
  - å¹¶å°†å…¶æ³¨å†Œåœ¨ API Server ä¸­çš„ `/apis/custom.metrics.k8s.io/v1beta1/`

**3ï¸âƒ£ æ¶ˆè´¹å±‚ï¼šHPA æ§åˆ¶å™¨**

- HPA æ§åˆ¶å™¨é€šè¿‡ Kubernetes API è¯·æ±‚ `/apis/custom.metrics.k8s.io/...`
- æ‹¿åˆ°ä½ è®¾ç½®çš„æŒ‡æ ‡å€¼
- å†ç»“åˆä½ çš„ HPA é…ç½®ï¼ˆç›®æ ‡å€¼ã€å®¹å™¨å‰¯æœ¬æ•°ï¼‰è¿›è¡Œå†³ç­–

```ABAP
App (æŒ‡æ ‡æº) --> Prometheus --> Prometheus Adapter --> custom.metrics.k8s.io --> HPA æ§åˆ¶å™¨
```



#### kube-state-metrics

Prometheus æœ¬èº«åªæ”¯æŒæŠ“å– **Kubernetes çš„è¿è¡Œæ—¶èµ„æºï¼ˆRuntime objectsï¼‰**ï¼Œé€šè¿‡ `kubernetes_sd_config` æŠ“å–çš„ `role` ä¸»è¦åŒ…æ‹¬ï¼š

| Role ç±»å‹   | æè¿°                                        |
| ----------- | ------------------------------------------- |
| `pod`       | é‡‡é›† Pod çš„ metricsï¼ˆéœ€ Pod æä¾› /metricsï¼‰ |
| `endpoints` | é‡‡é›†æŸä¸ª Service çš„ endpoints               |
| `service`   | é‡‡é›† Service IPï¼ˆé€šå¸¸ç”¨äºé™æ€æ¢æµ‹ï¼‰         |
| `ingress`   | è·å– Ingress ä¿¡æ¯                           |
| `node`      | èŠ‚ç‚¹çº§æŒ‡æ ‡ï¼ˆå¦‚ node_exporterï¼‰              |
| `apiserver` | é‡‡é›† K8s API Server çš„çŠ¶æ€                  |

è¿™äº›éƒ½æ˜¯ **è¿è¡Œä¸­çš„å¯¹è±¡**ï¼Œå¹¶ä¸èƒ½æä¾›èµ„æºå®šä¹‰å±‚é¢çš„çŠ¶æ€ï¼Œä¾‹å¦‚ï¼š

- Deployment æœŸæœ›å‰¯æœ¬ vs å®é™…å‰¯æœ¬æ•°é‡
- PVC æ˜¯å¦ç»‘å®šäº† PVï¼Ÿ
- StatefulSet çš„æ»šåŠ¨å‡çº§çŠ¶æ€
- CronJob ä¸Šæ¬¡è¿è¡Œæ˜¯å¦æˆåŠŸï¼Ÿ

è¿™äº›ä¿¡æ¯ **Prometheus é»˜è®¤æ˜¯æ‹¿ä¸åˆ°çš„**ï¼Œå› ä¸ºå®ƒä¸æ˜¯é€šè¿‡ Metrics API æš´éœ²çš„ã€‚



##### kube-state-metrics çš„ä½œç”¨

âœ… ä¸“é—¨ä¸ºäº† Prometheus æä¾› **Kubernetes çŠ¶æ€å¯¹è±¡çš„æŒ‡æ ‡**ã€‚

å®ƒä»¥ Kubernetes Controller çš„å½¢å¼è¿è¡Œï¼Œç›‘å¬å¦‚ä¸‹ **æ§åˆ¶å±‚ï¼ˆControl Planeï¼‰å¯¹è±¡**ï¼š

| ç±»å‹        | ç¤ºä¾‹æŒ‡æ ‡                               |
| ----------- | -------------------------------------- |
| Deployment  | `.spec.replicas` vs `.status.replicas` |
| StatefulSet | `.status.readyReplicas`                |
| DaemonSet   | `.status.numberUnavailable`            |
| PVC / PV    | pvc phaseï¼ˆBoundã€Pendingï¼‰            |
| CronJob     | ä¸Šæ¬¡æ˜¯å¦æˆåŠŸ / ä¸‹æ¬¡è°ƒåº¦æ—¶é—´            |
| HPA         | å½“å‰å‰¯æœ¬æ•° / ç›®æ ‡æŒ‡æ ‡å€¼                |
| Namespace   | çŠ¶æ€ï¼ˆActive/Terminatingï¼‰             |

ä¸¾ä¸ªä¾‹å­ï¼š

```properties
kube_deployment_status_replicas_ready{deployment="myapp"} = 3
kube_persistentvolumeclaim_status_phase{namespace="default",persistentvolumeclaim="mypvc",phase="Bound"} 1
```

è¿™äº›æŒ‡æ ‡æ˜¯ **Prometheus æœ¬èº«æ— æ³•ç›´æ¥è·å–çš„**ï¼Œåªæœ‰é€šè¿‡ `kube-state-metrics` æš´éœ²ç»™ Prometheusï¼Œæ‰èƒ½å®ç°è¿™ç±»ä¸šåŠ¡é€»è¾‘æˆ–æŠ¥è­¦

```ABAP
ç±»ä¼¼äºç”¨äºè¡¥å……æŠ“å–Kubernetesé»˜è®¤å¯è·å–èµ„æºç±»å‹æŒ‡æ ‡ä¹‹å¤–çš„èµ„æºç±»å‹æŒ‡æ ‡çš„exporter
```



### Kubernetes **API Aggregation Layer** å·¥ä½œæœºåˆ¶

API Aggregation Layerï¼ˆç®€ç§° **AA Layer**ï¼‰æ˜¯ Kubernetes **æ‰©å±• API çš„æœºåˆ¶ä¹‹ä¸€**ï¼Œå…è®¸ä½ å°†å¤–éƒ¨çš„ã€éæ ¸å¿ƒçš„ API Server é›†æˆåˆ°ä¸» Kubernetes API Server ä¸­ï¼Œè¡¨ç°å¾—å°±åƒæ˜¯åŸç”Ÿçš„ä¸€éƒ¨åˆ†ã€‚

![image-20250330182658650](D:\git_repository\cyber_security_learning\markdown_img\image-20250330182658650.png)



#### å·¥ä½œæµç¨‹è¯´æ˜

å½“å®¢æˆ·ç«¯å‘èµ·è¯·æ±‚æ—¶ï¼š

```ABAP
Client â†’ kube-apiserver â†’ Aggregation Layer â†’ å¤–éƒ¨æ‰©å±• API Serverï¼ˆå¦‚ Metrics Serverï¼‰ â†’ è¿”å›æ•°æ®
```



#### åœºæ™¯ä¸¾ä¾‹ï¼ˆä»¥ Metrics Server ä¸ºä¾‹ï¼‰

å½“ä½ è¿è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š

```bash
kubectl top pod
```

å®é™…è¿‡ç¨‹ï¼š

1. `kubectl` å‘ `kube-apiserver` å‘èµ·è¯·æ±‚ `/apis/metrics.k8s.io/v1beta1/...`
2. kube-apiserver çš„ **Aggregation Layer** åˆ¤æ–­è¯¥ API ç”± `metrics-server` æä¾›ï¼›
3. è¯·æ±‚è¢«**ä»£ç†è½¬å‘**ç»™æ³¨å†Œåœ¨ Aggregation Layer çš„æ‰©å±• API Serverï¼ˆå³ `metrics-server`ï¼‰ï¼›
4. `metrics-server` è¿”å›æŒ‡æ ‡æ•°æ®ï¼›
5. kube-apiserver å°†ç»“æœè¿”å›ç»™ `kubectl`ã€‚



**æ”¯æŒ API Aggregation çš„ç»„ä»¶ä¸¾ä¾‹**

| ç»„ä»¶                         | è¯´æ˜                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| `metrics-server`             | é‡‡é›†èµ„æºæŒ‡æ ‡çš„æ‰©å±• APIï¼Œè·¯å¾„æ˜¯ `/apis/metrics.k8s.io`        |
| `custom-metrics-apiserver`   | æä¾› HPA ä½¿ç”¨çš„è‡ªå®šä¹‰æŒ‡æ ‡                                    |
| `external-metrics-apiserver` | æä¾›å¤–éƒ¨æœåŠ¡æŒ‡æ ‡ï¼ˆå¦‚é˜Ÿåˆ—é•¿åº¦ï¼‰                               |
| ä½ è‡ªå®šä¹‰çš„ API Server        | å¦‚åŸºäº [KubeBuilder](https://github.com/kubernetes-sigs/kubebuilder) æ„å»º |



#### Prometheus Adapter

åœ¨ Kubernetes ä¸­ï¼Œ**Prometheus Adapter**â€¯å°±æ˜¯ä¸€ä¸ª**æ‰©å±• API Server**ï¼Œå®ƒé€šè¿‡ **[API Aggregation Layerï¼ˆèšåˆå±‚ï¼‰]** ä¸ä¸» API Server è¿›è¡Œé›†æˆï¼Œä»è€Œæ”¯æŒ **è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆCustom Metricsï¼‰** å’Œ **å¤–éƒ¨æŒ‡æ ‡ï¼ˆExternal Metricsï¼‰** çš„æŸ¥è¯¢ã€‚



**ä½¿ç”¨ Prometheus Adapter çš„å…³é”®æµç¨‹å¦‚ä¸‹ï¼š**

âœ… 1. **Adapter æœ¬èº«æ˜¯ä¸€ä¸ªæ‰©å±• API Server**

- å®ƒå®ç°äº† Kubernetes è‡ªå®šä¹‰æŒ‡æ ‡ API (`custom.metrics.k8s.io`) å’Œ/æˆ–å¤–éƒ¨æŒ‡æ ‡ API (`external.metrics.k8s.io`)ã€‚
- å®ƒä¼šæš´éœ²å‡ºè¿™äº› API çš„è·¯å¾„ï¼Œå¦‚ `/apis/custom.metrics.k8s.io/v1beta1/...`ã€‚

âœ… 2. **é€šè¿‡æ³¨å†Œ `APIService` å¯¹è±¡ä½¿å…¶å¯ç”¨**

- è¦ä½¿ Kubernetes èšåˆå±‚è¯†åˆ«å¹¶è½¬å‘è¯·æ±‚ç»™è¿™ä¸ªæ‰©å±• API Serverï¼Œéœ€è¦æ³¨å†Œä¸€ä¸ª `APIService` èµ„æºã€‚

- è¿™ä¸ªèµ„æºæŒ‡å®šï¼š

  - API çš„ç»„åï¼ˆå¦‚ `custom.metrics.k8s.io`ï¼‰
  - å¯¹åº”çš„æœåŠ¡åœ°å€ï¼ˆå³ Prometheus Adapter çš„ `Service`ï¼‰

  ç¤ºä¾‹ï¼š

  ```yaml
  apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    name: v1beta1.custom.metrics.k8s.io
  spec:
    group: custom.metrics.k8s.io
    version: v1beta1
    service:
      name: prometheus-adapter
      namespace: monitoring
    groupPriorityMinimum: 100
    versionPriority: 100
  ```

âœ… 3. **ä½¿ç”¨åœºæ™¯**

- **Horizontal Pod Autoscalerï¼ˆHPAï¼‰v2** å°±å¯ä»¥é€šè¿‡è¿™ä¸ª API ä½¿ç”¨ Prometheus æä¾›çš„è‡ªå®šä¹‰æŒ‡æ ‡ã€‚
- ä¾‹å¦‚ï¼Œä½ å¯ä»¥æ ¹æ®æŸä¸ªåº”ç”¨æš´éœ²çš„è‡ªå®šä¹‰ `requests_per_second` æŒ‡æ ‡æ¥è‡ªåŠ¨æ‰©ç¼©å®¹ã€‚



#### APIServiceèµ„æºç±»å‹

è¦ä½¿ç”¨æ‰©å±•apiServerå¿…é¡»ï¼Œå¿…é¡»æ³¨å†Œå¯¹åº”çš„APIServiceå¯¹è±¡

Kubernetes çš„èšåˆå±‚æœºåˆ¶å…è®¸ä½ é€šè¿‡æ‰©å±• API Server æä¾›é¢å¤–çš„ API ç»„ï¼Œä½†å‰ææ˜¯ï¼š

> â˜‘ï¸ ä½ è¦å‘Šè¯‰ä¸» API Serverï¼š
>  â€œè¿™ä¸ª API ç»„ï¼ˆä¾‹å¦‚ `custom.metrics.k8s.io`ï¼‰ä¸æ˜¯ä½ æœ¬èº«æä¾›çš„ï¼Œè¯·è½¬å‘åˆ°æˆ‘è¿™é‡Œï¼ˆæ‰©å±• API Serverï¼‰ã€‚â€

è¿™ä¸ªâ€œå‘Šè¯‰â€çš„åŠ¨ä½œï¼Œå°±æ˜¯é€šè¿‡åˆ›å»ºä¸€ä¸ª `APIService` èµ„æºæ¥å®ç°çš„ã€‚



**å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š**

1. **Prometheus Adapter**ï¼ˆæˆ–å…¶ä»–æ‰©å±• API Serverï¼‰å¯åŠ¨å¹¶åœ¨é›†ç¾¤ä¸­è¿è¡Œï¼Œé€šå¸¸ä½œä¸ºä¸€ä¸ª `Deployment` å’Œ `Service`ã€‚

2. **ä½ åˆ›å»º `APIService` å¯¹è±¡**ï¼š

   ```yaml
   apiVersion: apiregistration.k8s.io/v1
   kind: APIService
   metadata:
     name: v1beta1.custom.metrics.k8s.io
   spec:
     group: custom.metrics.k8s.io
     version: v1beta1
     service:
       name: prometheus-adapter     # æŒ‡å‘ adapter çš„ Service å
       namespace: monitoring
     groupPriorityMinimum: 100
     versionPriority: 100
   ```

3. Kubernetes èšåˆå±‚ä¼šè‡ªåŠ¨å°†å¯¹ `/apis/custom.metrics.k8s.io/v1beta1/...` çš„è¯·æ±‚ï¼Œè½¬å‘ç»™è¿™ä¸ª Adapterã€‚

4. HPA ç­‰ç»„ä»¶å°±å¯ä»¥é€šè¿‡è¿™ä¸ªè·¯å¾„æ‹¿åˆ° Prometheus ä¸­çš„æŒ‡æ ‡äº†ã€‚



### Prometheus éƒ¨ç½²è‡³ Kubernetes

#### Prometheus ä¸ºä»€ä¹ˆèƒ½æœåŠ¡å‘ç° Kubernetes çš„ apiServer

Prometheus é€šè¿‡ `kubernetes_sd_configs` å®ç°å¯¹ Kubernetes é›†ç¾¤çš„è‡ªåŠ¨æœåŠ¡å‘ç°ï¼Œå®ƒæ˜¯é  **Kubernetes å®˜æ–¹ Go Clientï¼ˆclient-goï¼‰** è¿æ¥ API Server çš„ã€‚

```bash
# è§£é‡ŠGO Client
âœ… Prometheus å†…ç½®äº†å¯¹ Kubernetes çš„æœåŠ¡å‘ç°åŠŸèƒ½ï¼Œè€Œå®ƒå†…éƒ¨ç”¨çš„æ­£æ˜¯ Kubernetes å®˜æ–¹çš„ Go å®¢æˆ·ç«¯åº“ client-goï¼
âœ… client-go æ˜¯ Kubernetes å®˜æ–¹æä¾›çš„ ç”¨äºæ“ä½œ Kubernetes API çš„ Go è¯­è¨€å®¢æˆ·ç«¯åº“ã€‚
âœ… å‡¡æ˜¯è¦ä¸ Kubernetes API Server é€šä¿¡çš„ Go åº”ç”¨ï¼ˆæ¯”å¦‚ Prometheusã€Ingress Controllerã€Operator ç­‰ï¼‰ï¼ŒåŸºæœ¬éƒ½ä¼šç”¨å®ƒã€‚

# Prometheus æ˜¯å¦‚ä½•ä½¿ç”¨ client-go çš„ï¼Ÿ
ğŸ“¦Prometheus çš„æ¨¡å—ç»“æ„é‡Œæœ‰ä¸€ä¸ªå«ï¼šdiscovery/kubernetes
è¿™ä¸ªæ¨¡å—å°±æ˜¯ä¸“é—¨ç”¨äºä¸ Kubernetes é›†æˆçš„ï¼Œé‡Œé¢å°è£…äº†å¯¹ Kubernetes API çš„è®¿é—®é€»è¾‘ã€‚
å®ƒçš„å®ç°ç›´æ¥ä¾èµ– client-goï¼Œå¯ä»¥è‡ªåŠ¨å®ç°ï¼š
âœ… pod/service/endpoint/ingress/node çš„æœåŠ¡å‘ç°ï¼ˆé€šè¿‡ kubernetes_sd_configsï¼‰
âœ… è‡ªåŠ¨è¯»å–é›†ç¾¤å†…éƒ¨çš„ service accountï¼ˆå« tokenã€CAã€namespaceï¼‰
âœ… è‡ªåŠ¨æ„é€ å®¢æˆ·ç«¯ä¸ API Server é€šä¿¡
```



**è€Œ `client-go` ä¼šè‡ªåŠ¨ä»ä»¥ä¸‹å‡ ä¸ªåœ°æ–¹è¯»å– API Server çš„åœ°å€å’Œå‡­æ®ï¼š**

| ä¼˜å…ˆçº§ | æ¥æºè¯´æ˜                                                     |
| ------ | ------------------------------------------------------------ |
| 1ï¸âƒ£      | ç¯å¢ƒå˜é‡ `KUBERNETES_SERVICE_HOST` å’Œ `KUBERNETES_SERVICE_PORT`ï¼ˆ**Pod è¿è¡Œåœ¨é›†ç¾¤ä¸­è‡ªåŠ¨æ³¨å…¥**ï¼‰ |
| 2ï¸âƒ£      | é»˜è®¤çš„ service DNS å `https://kubernetes.default.svc`       |
| 3ï¸âƒ£      | `~/.kube/config`ï¼ˆå¦‚æœä½ åœ¨å¤–éƒ¨éƒ¨ç½² Prometheusï¼‰              |



**åœºæ™¯è¯´æ˜**

**âœ… åœºæ™¯1ï¼šPrometheus è¿è¡Œåœ¨ K8s é›†ç¾¤å†…éƒ¨ï¼ˆé€šå¸¸æ˜¯è¿™ç§ï¼‰**

1. Kubernetes ä¼šå°†ä»¥ä¸‹ç¯å¢ƒå˜é‡æ³¨å…¥åˆ° Pod ä¸­ï¼š

   ```bash
   KUBERNETES_SERVICE_HOST=10.96.0.1
   KUBERNETES_SERVICE_PORT=443
   ```

2. å¹¶æŒ‚è½½ `/var/run/secrets/kubernetes.io/serviceaccount` ç›®å½•ä¸­çš„ï¼š

   - `ca.crt`
   - `token`
   - `namespace`

3. Prometheus é€šè¿‡è¿™äº›ä¿¡æ¯è‡ªåŠ¨è¿æ¥åˆ° API Serverï¼Œç„¶åå¼€å§‹åŸºäº `kubernetes_sd_configs` çš„æœåŠ¡å‘ç°ã€‚

**âœ… åœºæ™¯2ï¼šPrometheus åœ¨é›†ç¾¤å¤–éƒ¨è¿è¡Œ**

- ä½ éœ€è¦æ‰‹åŠ¨é…ç½® `kubeconfig` æ–‡ä»¶ï¼š

  ```yaml
  kubernetes_sd_configs:
    - role: pod
      api_server: https://<apiserver-ip>:6443
      kubeconfig_file: /path/to/kubeconfig
  ```



**ğŸ§ª éªŒè¯æ–¹æ³•**

ä½ å¯ä»¥ exec è¿› Prometheus Pod ä¸­ï¼Œçœ‹ä¸‹ç¯å¢ƒå˜é‡ï¼š

```bash
kubectl exec -it <prometheus-pod> -n <namespace> -- env | grep KUBERNETES
```

ä½ ä¹Ÿå¯ä»¥çœ‹ä¸‹æŒ‚è½½çš„ tokenï¼š

```bash
kubectl exec -it <prometheus-pod> -n <namespace> -- cat /var/run/secrets/kubernetes.io/serviceaccount/token
```

```ABAP
Prometheus æ˜¯é€šè¿‡ kubernetes_sd_configs + Kubernetes çš„ service account token è‡ªåŠ¨è¿æ¥åˆ°å½“å‰é›†ç¾¤çš„ API Server çš„ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å®šåœ°å€ã€‚
```





#### Prometheus åœ¨ Kubernetes ä¸­æŠ“å–ç›®æ ‡çš„å®Œæ•´æµç¨‹

**1ï¸âƒ£ ä½¿ç”¨ `client-go` è‡ªåŠ¨å‘ç° Kubernetes API Server**

Prometheus å¯åŠ¨åï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨å†…ç½®çš„ `client-go`ï¼š

- é€šè¿‡é›†ç¾¤ä¸­çš„ **ServiceAccount Token** å’Œ **Kube API çš„ CA** æ¥è®¿é—® API Serverã€‚
- è¿™äº›ä¿¡æ¯é»˜è®¤åœ¨å®¹å™¨å†… `/var/run/secrets/kubernetes.io/serviceaccount/` ä¸‹æŒ‚è½½ã€‚

**2ï¸âƒ£ `kubernetes_sd_configs` å®ç°èµ„æºå‘ç°ï¼ˆService Discoveryï¼‰**

åœ¨ `prometheus.yml` ä¸­é…ç½®ï¼š

```yaml
kubernetes_sd_configs:
  - role: pod        # è¿™é‡Œå¯ä»¥æ¢æˆ endpointsã€serviceã€nodeã€ingress ç­‰
```

æ¯ä¸ª `role` å¯¹åº”ä¸€ç§èµ„æºå‘ç°å¯¹è±¡ï¼Œä¾‹å¦‚ï¼š

| role        | å«ä¹‰                               |
| ----------- | ---------------------------------- |
| `pod`       | è·å–æ‰€æœ‰ Pod åˆ—è¡¨                  |
| `service`   | è·å–æ‰€æœ‰ Service                   |
| `endpoints` | è·å–æ‰€æœ‰ Endpointï¼ˆPod IP + ç«¯å£ï¼‰ |
| `node`      | è·å–æ‰€æœ‰ Node                      |
| `ingress`   | è·å–æ‰€æœ‰ Ingress                   |

3ï¸âƒ£ `relabel_configs` + æ³¨è§£ç²¾å‡†æ§åˆ¶æŠ“å–ç›®æ ‡

æ¯”å¦‚ä½ ç”¨ `endpoints` ä½œä¸º roleï¼Œä¼šæŠ“åˆ°æ‰€æœ‰å¸¦æœ‰ endpoint çš„æœåŠ¡ï¼Œç„¶åä½ å¯ä»¥é€šè¿‡æ³¨è§£åœ¨ç‰¹å®š Pod æˆ– Service ä¸Šæ§åˆ¶ Prometheus æ˜¯å¦æŠ“å–ï¼š

```yaml
# ä»…æŠ“å–å¸¦æœ‰ prometheus.io/scrape=true çš„ç›®æ ‡
relabel_configs:
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
    action: keep
    regex: true

# è‡ªå®šä¹‰æŠ“å–è·¯å¾„
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
    action: replace
    target_label: __metrics_path__
    regex: (.+)

# è‡ªå®šä¹‰æŠ“å–ç«¯å£
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
    action: replace
    target_label: __address__
    regex: (.+)
    replacement: $1
```

**å¸¸ç”¨æ³¨è§£ç¤ºä¾‹ï¼ˆåŠ åœ¨ Pod æˆ– Service ä¸Šï¼‰ï¼š**

```yaml
annotations:
  prometheus.io/scrape: "true"       # æ˜¯å¦æŠ“å–è¯¥ç›®æ ‡çš„æŒ‡æ ‡ã€‚è®¾ä¸º true æ—¶æ‰æŠ“å–ã€‚
  prometheus.io/port: "8080"         # æŒ‡å®šæŠ“å–æŒ‡æ ‡çš„ç«¯å£å·ã€‚é»˜è®¤ä¸ºå®¹å™¨æš´éœ²çš„ç«¯å£ã€‚   
  prometheus.io/path: "/metrics"     # æŒ‡å®šæŠ“å–æŒ‡æ ‡çš„ HTTP è·¯å¾„ï¼Œé»˜è®¤ä¸º /metricsã€‚
```



#### Prometheus éƒ¨ç½²å®ç°

##### manifestsæ–¹å¼éƒ¨ç½²

```bash
# åˆ›å»ºåç§°ç©ºé—´
[root@master1 k8s-prom]#kubectl create namespace prom
namespace/prom created

# gitæ‹‰å–Prometheusçš„é…ç½®æ–‡ä»¶
[root@master1 ~]# git clone https://github.com/iKubernetes/k8s-prom.git

# å¯ç”¨éƒ¨ç½²Prometheus
[root@master1 ~]#cd k8s-prom/prometheus
[root@master1 prometheus]#ls
ingress              prometheus-deploy.yaml  prometheus-rules.yaml
prometheus-cfg.yaml  prometheus-rbac.yaml    prometheus-svc.yaml
[root@master1 prometheus]#kubectl apply -f . -n prom 
configmap/prometheus-config created
deployment.apps/prometheus-server created
clusterrole.rbac.authorization.k8s.io/prometheus created
serviceaccount/prometheus created
clusterrolebinding.rbac.authorization.k8s.io/prometheus created
configmap/prometheus-rules created
service/prometheus created

# ä½¿ç”¨ingressæš´éœ²Prometheus
[root@master1 prometheus]#cat ingress/ingress-prometheus.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: prometheus
  namespace: prom
  labels:
    app: prometheus
spec:
  ingressClassName: 'nginx'
  rules:
  - host: prom.mystical.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus
            port:
              number: 9090
  - host: prometheus.mystical.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus
            port: 
              number: 9090

# å¯ç”¨kube-state-metrics,å°†deployï¼ŒStatefulsetç­‰é»˜è®¤ä¸æš´éœ²çš„èµ„æºä¹Ÿçº³å…¥ç›‘æ§
[root@master1 k8s-prom]#cd kube-state-metrics/
[root@master1 kube-state-metrics]#ls
kube-state-metrics-deploy.yaml  kube-state-metrics-rbac.yaml  kube-state-metrics-svc.yaml

[root@master1 kube-state-metrics]#kubectl apply -f . -n prom 
deployment.apps/kube-state-metrics created
serviceaccount/kube-state-metrics created
clusterrole.rbac.authorization.k8s.io/kube-state-metrics created
clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics created
service/kube-state-metrics created
```



##### Helmæ–¹å¼éƒ¨ç½²ï¼ˆç”Ÿäº§ä½¿ç”¨ï¼‰

```bash
# ä»githubæ‹‰å–ä»“åº“
[root@master1 ~]# git clone https://github.com/iKubernetes/k8s-prom.git

[root@master1 ~]#cd k8s-prom/helm
[root@master1 helm]#ls 
blackbox-exporter-values.yaml  prom-adapter-values.yaml  prom-values.yaml  README.md

# æ·»åŠ Prometheus Communityçš„Chartä»“åº“ã€‚
[root@master1 k8s-prom]#helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
"prometheus-community" has been added to your repositories

# æ›´æ–°ä»“åº“
[root@master1 k8s-prom]#helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "harbor" chart repository
...Successfully got an update from the "prometheus-community" chart repository
Update Complete. âˆHappy Helming!âˆ

# è¿è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œå³å¯åŠ è½½æœ¬åœ°çš„valuesæ–‡ä»¶ï¼Œéƒ¨ç½²Prometheusç”Ÿæ€ç»„ä»¶ã€‚
[root@master1 helm]#helm install prometheus prometheus-community/prometheus --namespace monitoring --values prom-values.yaml --create-namespace
NAME: prometheus
LAST DEPLOYED: Mon Mar 31 11:01:31 2025
NAMESPACE: monitoring
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
The Prometheus server can be accessed via port 9090 on the following DNS name from within your cluster:
prometheus-server.monitoring.svc.cluster.local

From outside the cluster, the server URL(s) are:
http://prometheus.magedu.com
......

# æŸ¥çœ‹ingress
[root@master1 helm]#kubectl get ingress -n monitoring 
NAME                CLASS   HOSTS                   ADDRESS     PORTS   AGE
prometheus-server   nginx   prometheus.magedu.com   10.0.0.11   80      2m45s

# æŸ¥çœ‹pod
[root@master1 helm]#kubectl get pod -n monitoring 
NAME                                                 READY   STATUS    RESTARTS   AGE
prometheus-alertmanager-0                            1/1     Running   0          3m19s
prometheus-kube-state-metrics-55f8b5d87b-b24hh       1/1     Running   0          3m19s
prometheus-prometheus-node-exporter-b9bck            1/1     Running   0          3m19s
prometheus-prometheus-node-exporter-dzvv8            1/1     Running   0          3m19s
prometheus-prometheus-node-exporter-klghj            1/1     Running   0          3m19s
prometheus-prometheus-node-exporter-xl4qb            1/1     Running   0          3m19s
prometheus-prometheus-pushgateway-79964b5788-zq6ds   1/1     Running   0          3m19s
prometheus-server-65996d7b65-tqqhf                   2/2     Running   0          3m19s

# æµè§ˆå™¨è®¿é—®
http://prometheus.magedu.com/query
```

![image-20250331110706503](../markdown_img/image-20250331110706503.png)

```bash
# éƒ¨ç½²æµ‹è¯•pod
[root@master1 example-metrics]#cat metrics-example-app.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
    name: metrics-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: metrics-app
      controller: metrics-app
  template:
    metadata:
      labels:
        app: metrics-app
        controller: metrics-app
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "80"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - image: ikubernetes/metrics-app
        name: metrics-app
        ports:
        - name: web
          containerPort: 80
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "256Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: metrics-app
spec:
  type: NodePort
  ports:
  - name: web
    port: 80
    targetPort: 80
  selector:
    app: metrics-app
    controller: metrics-app
    
# å¯ç”¨
[root@master1 example-metrics]# kubectl apply -f metrics-example-app.yaml

# æŸ¥çœ‹
[root@master1 example-metrics]#kubectl get pod
NAME                           READY   STATUS    RESTARTS        AGE
metrics-app-56c77b4999-d4nkl   1/1     Running   0               61m
metrics-app-56c77b4999-rw9nv   1/1     Running   0               61m


# æ­¤æ—¶æŸ¥çœ‹æµè§ˆå™¨ä¸ŠPrometheusä¸Šçš„æœåŠ¡å‘ç°ï¼Œä¼šçœ‹åˆ°æŠ¥é”™
Error scraping target: non-compliant scrape target sending blank Content-Type and no fallback_scrape_protocol specified for target

# è¿™ä¸ªæŠ¥é”™çš„åŸå› æ˜¯ï¼šè¿™è¡¨ç¤ºæŸäº› target çš„ /metrics æ¥å£æ²¡æœ‰è¿”å› Content-Type å¤´ï¼ˆæˆ–è¿”å›ä¸ºç©ºï¼‰ï¼ŒPrometheus æ— æ³•åˆ¤æ–­å¦‚ä½•è§£æå“åº”ä½“ï¼ˆé»˜è®¤æ˜¯ text/plain; version=0.0.4ï¼‰ã€‚

# è§£å†³æ–¹æ³•ï¼š
[root@master1 helm]#kubectl edit cm -n monitoring prometheus-server 
......
- honor_labels: true
      job_name: kubernetes-pods
      fallback_scrape_protocol: PrometheusText0.0.4  # æ·»åŠ è¿™è¡Œ
      kubernetes_sd_configs:
      - role: pod
      scheme: http
......
```



### Prometheus Adapter

#### manifestæ–¹å¼éƒ¨ç½²Prometheus Adapter

```http
https://github.com/iKubernetes/k8s-prom/tree/master/prometheus-adpater
```

```bash
# è¿›å…¥Prometheus-adpaterç›®å½•
[root@master1 k8s-prom]#cd prometheus-adpater/

# åˆ›å»ºåç§°ç©ºé—´
[root@master1 prometheus-adpater]#kubectl create namespace custom-metrics

# å®‰è£… golang-cfssl
[root@master1 prometheus-adpater]#apt install -y golang-cfssl

# è¿è¡Œè„šæœ¬
[root@master1 prometheus-adpater]#bash gencerts.sh

# æ‰§è¡Œè„šæœ¬åï¼Œåœ¨Manifestç›®å½•ä¸‹ï¼Œä¼šåˆ›å»ºä¸€ä¸ªæ–‡ä»¶cm-adapter-serving-certs.yaml
[root@master1 prometheus-adpater]#ls manifests/cm-adapter-serving-certs.yaml 
manifests/cm-adapter-serving-certs.yaml

# å¯ç”¨æ¸…å•æ–‡ä»¶
[root@master1 prometheus-adpater]#kubectl apply -f manifests/
secret/cm-adapter-serving-certs created
clusterrolebinding.rbac.authorization.k8s.io/custom-metrics:system:auth-delegator created
rolebinding.rbac.authorization.k8s.io/custom-metrics-auth-reader created
deployment.apps/custom-metrics-apiserver created
clusterrolebinding.rbac.authorization.k8s.io/custom-metrics-resource-reader created
serviceaccount/custom-metrics-apiserver created
service/custom-metrics-apiserver created
apiservice.apiregistration.k8s.io/v1beta1.custom.metrics.k8s.io created
apiservice.apiregistration.k8s.io/v1beta2.custom.metrics.k8s.io created
apiservice.apiregistration.k8s.io/v1beta1.external.metrics.k8s.io created
clusterrole.rbac.authorization.k8s.io/custom-metrics-server-resources created
configmap/adapter-config created
clusterrole.rbac.authorization.k8s.io/custom-metrics-resource-reader created
clusterrolebinding.rbac.authorization.k8s.io/hpa-controller-custom-metrics created

# æŸ¥çœ‹æ‰©å±•apièµ„æº
[root@master1 prometheus-adpater]#kubectl api-versions |grep external.metrics
external.metrics.k8s.io/v1beta1
[root@master1 prometheus-adpater]#kubectl api-versions |grep custom
custom.metrics.k8s.io/v1beta1
custom.metrics.k8s.io/v1beta2

# è¿è¡Œä¸‹é¢å‘½ä»¤ï¼Œéƒ¨ç½²ç¤ºä¾‹åº”ç”¨ã€‚è¯¥ç¤ºä¾‹åº”ç”¨æä¾›äº†ä¸€ä¸ªCounterç±»å‹çš„æŒ‡æ ‡http_requests_totalã€‚
[root@master1 prometheus-adpater]#kubectl apply -f example-metrics/metrics-example-app.yaml
deployment.apps/metrics-app created
service/metrics-app created

# æŸ¥çœ‹
[root@master1 prometheus-adpater]#kubectl get pod
NAME                           READY   STATUS    RESTARTS      AGE
metrics-app-56c77b4999-6gmwk   1/1     Running   0             60s
metrics-app-56c77b4999-p4kmt   1/1     Running   0             60s

# æŸ¥çœ‹ç¤ºä¾‹podæš´éœ²çš„æŒ‡æ ‡
[root@master1 prometheus-adpater]#curl 192.168.253.38/metrics
# HELP http_requests_total The amount of requests in total
# TYPE http_requests_total counter
http_requests_total 8
# HELP http_requests_per_second The amount of requests per second the latest ten seconds
# TYPE http_requests_per_second gauge
http_requests_per_second 0.2
```

```ABAP
ä¸Šè¿°Manifestæ–¹å¼åˆ›å»ºçš„Prometheus Adapterå’ŒManifestæ–¹å¼åˆ›å»ºPrometheusç‰ˆæœ¬ä¸æ˜¯å¾ˆå…¼å®¹ï¼Œå¯¼è‡´æ‰‹åŠ¨å°†PromQLè½¬åˆ°ä¸ºK8S APIå‡ºç°é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨helméƒ¨ç½²Prometheuså’ŒPrometheus Adapter
```



#### Helmæ–¹å¼éƒ¨ç½²Prometheus Adapter

```bash
# helm éƒ¨ç½²Prometheus-adapter
[root@master1 helm]#helm install prometheus-adapter prometheus-community/prometheus-adapter --values prom-adapter-values.yaml --namespace monitoring
NAME: prometheus-adapter
LAST DEPLOYED: Mon Mar 31 11:38:59 2025
NAMESPACE: monitoring
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
prometheus-adapter has been deployed.
In a few minutes you should be able to list metrics using the following command(s):

  kubectl get --raw /apis/metrics.k8s.io/v1beta1
  kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1

  kubectl get --raw /apis/external.metrics.k8s.io/v1beta1
  
# æŸ¥çœ‹Prometheus -> è½¬æ¢ä¸ºKubernetes-APIï¼Œè½¬æ¢æˆåŠŸ
[root@master1 example-metrics]#kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/http_requests_per_second|jq
{
  "kind": "MetricValueList",
  "apiVersion": "custom.metrics.k8s.io/v1beta1",
  "metadata": {},
  "items": [
    {
      "describedObject": {
        "kind": "Pod",
        "namespace": "default",
        "name": "metrics-app-56c77b4999-d4nkl",
        "apiVersion": "/v1"
      },
      "metricName": "http_requests_per_second",
      "timestamp": "2025-03-31T04:20:03Z",
      "value": "100m",
      "selector": null
    },
    {
      "describedObject": {
        "kind": "Pod",
        "namespace": "default",
        "name": "metrics-app-56c77b4999-rw9nv",
        "apiVersion": "/v1"
      },
      "metricName": "http_requests_per_second",
      "timestamp": "2025-03-31T04:20:03Z",
      "value": "100m",
      "selector": null
    }
  ]
}

# æŸ¥çœ‹æµè§ˆå™¨
```

![image-20250331122308933](../markdown_img/image-20250331122308933.png)



#### Prometheus Adapter ä¸è‡ªå®šä¹‰æŒ‡æ ‡çš„ä½¿ç”¨é€»è¾‘

âœ… **Prometheus Adapter çš„åŸºæœ¬ä½œç”¨ï¼š**

Prometheus Adapter æ˜¯ä¸€ä¸ª **æ‰©å±• API Server**ï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼š

å°† Prometheus ä¸­çš„ **PromQL æŸ¥è¯¢ç»“æœ** æš´éœ²ä¸º Kubernetes å¯è¯†åˆ«çš„ **Custom Metrics API æˆ– External Metrics API**ï¼Œä¾› HPA / VPA ä½¿ç”¨ã€‚



**âœ… é»˜è®¤æ”¯æŒçš„æŒ‡æ ‡**

Prometheus Adapter é»˜è®¤å¯ä»¥æš´éœ²ä¸€äº›ã€Œæ ‡å‡†æ ¼å¼ã€çš„ Prometheus æŒ‡æ ‡ï¼Œä¾‹å¦‚ï¼š

- Podã€Deployment çš„ CPUã€å†…å­˜ï¼ˆè¿™äº›å…¶å®å°±æ˜¯ `metrics.k8s.io` æä¾›çš„æ ¸å¿ƒæŒ‡æ ‡ï¼‰
- å·²çŸ¥æ ‡ç­¾ç»“æ„ï¼ˆæ¯”å¦‚æœ‰ `namespace`, `pod`, `container` ç­‰æ ‡ç­¾ï¼‰

è¿™äº›é€šå¸¸ä¸éœ€è¦å¤æ‚é…ç½®å°±èƒ½è½¬å‘å‡ºæ¥ã€‚



âœ… **å®šä¹‰/è®¡ç®—å‹æŒ‡æ ‡ âœ éœ€è¦é…ç½® rules**

å¯¹äº **éæ ‡å‡†æ ¼å¼** æˆ– **éœ€è¦è®¡ç®—å¾—å‡º** çš„æŒ‡æ ‡ï¼Œæ¯”å¦‚ï¼š

- `http_requests_total`ï¼ˆéœ€è¦èšåˆæˆ QPSï¼‰
- `queue_length`
- `latency_bucket`ï¼ˆç›´æ–¹å›¾ç±»å‹ï¼‰
- éæ ‡å‡† labelï¼Œæ¯”å¦‚ `app`, `instance`, `custom_tag`

å°±éœ€è¦åœ¨ Prometheus Adapter çš„é…ç½®ä¸­å®šä¹‰ `rules`ï¼Œæ‰‹åŠ¨å°† PromQL æŸ¥è¯¢è½¬æ¢æˆ API æŒ‡æ ‡ã€‚

**ç¤ºä¾‹é…ç½®ï¼ˆé€‚ç”¨äº `custom-metrics`ï¼‰**

```yaml
rules:
  custom:
    - seriesQuery: 'http_requests_total{job="my-app"}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "http_requests_total"
        as: "http_requests_per_second"
      metricsQuery: 'sum(rate(http_requests_total{job="my-app"}[2m])) by (pod, namespace)'
```



#### Prometheus Adapter çš„ `rules` é…ç½®è¯¦è§£

é…ç½®è·¯å¾„é€šå¸¸åœ¨ Prometheus Adapter çš„ Helm chart ä¸­ï¼š

```yaml
prometheus-adapter
â””â”€â”€ values.yaml
    â””â”€â”€ rules:
        â””â”€â”€ custom:  # æˆ– external:
```



**ä¸€ä¸ªå®Œæ•´çš„ `rules.custom` é…ç½®ç¤ºä¾‹ï¼š**

```yaml
rules:
  custom:
    - seriesQuery: 'http_requests_total{job="my-app"}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "http_requests_total"
        as: "http_requests_per_second"
      metricsQuery: 'sum(rate(http_requests_total{job="my-app"}[2m])) by (pod, namespace)'
```



**é…ç½®å­—æ®µè§£é‡Š**

1ï¸âƒ£ **`seriesQuery` â€” åŒ¹é…åŸå§‹æŒ‡æ ‡å**

- åŒ¹é… Prometheus ä¸­çš„åŸå§‹æŒ‡æ ‡ï¼ˆä¾‹å¦‚ `http_requests_total`ï¼‰

- ä¹Ÿå¯ä»¥åŠ å…¥æ ‡ç­¾ç­›é€‰ï¼Œæ¯”å¦‚ `job="my-app"`ï¼Œå‡å°‘èŒƒå›´ã€‚

  ```yaml
  seriesQuery: 'http_requests_total{job="my-app"}'
  ```

**2ï¸âƒ£ `resources.overrides` â€” æ ‡ç­¾è½¬ä¸ºèµ„æº**

å°† Prometheus æŒ‡æ ‡ä¸­çš„æ ‡ç­¾æ˜ å°„ä¸º Kubernetes çš„èµ„æºå¯¹è±¡ï¼š
```yaml
resources:
  overrides:
    pod:        # æŒ‡å®šæ ‡ç­¾ä¸º pod
      resource: "pod"
    namespace:  # æŒ‡å®šæ ‡ç­¾ä¸º namespace
      resource: "namespace"
```

ğŸ‘‰ è¡¨ç¤ºè¿™æ¡æŒ‡æ ‡å¯¹åº”çš„æ˜¯å“ªä¸ª namespace å’Œå“ªä¸ª podã€‚

**è¡¥å……è¯¦è§£**

Prometheus æ˜¯é **æ ‡ç­¾ï¼ˆlabelï¼‰ç³»ç»Ÿ**ç»„ç»‡æŒ‡æ ‡çš„ï¼Œæ¯”å¦‚ï¼š

```properties
http_requests_total{pod="myapp-67kkp", namespace="default", job="my-app"}
```

è€Œ Kubernetes æ˜¯é èµ„æºå¯¹è±¡ï¼ˆPodã€Namespaceã€Deploymentï¼‰æ¥ç»„ç»‡ç®¡ç†çš„ã€‚

æ‰€ä»¥ Prometheus Adapter éœ€è¦çŸ¥é“ï¼š
 â¡ï¸ **è¿™ä¸ªæŒ‡æ ‡çš„å“ªä¸ª label è¡¨ç¤º Kubernetes ä¸­å“ªä¸ªèµ„æºã€‚**



**ä¸¾ä¸ªå®é™…ä¾‹å­**

å‡è®¾ä½  Prometheus ä¸­æœ‰ä¸€æ¡æŒ‡æ ‡ï¼š

```cpp
http_requests_total{pod="myapp-67kkp", namespace="default"}
```

ä½ æƒ³é€šè¿‡ HPA å¯¹è¿™ä¸ª Pod åšä¼¸ç¼©ï¼Œé‚£ä¹ˆ Prometheus Adapter å°±è¦çŸ¥é“ï¼š

- `pod="myapp-67kkp"` è¿™è¡¨ç¤º **Kubernetes çš„ Pod åå­—**
- `namespace="default"` è¡¨ç¤º **è¿™ä¸ª Pod å±äºå“ªä¸ª Namespace**

å¦‚æœä½ ä¸å‘Šè¯‰å®ƒï¼Œå®ƒå°±ä¸çŸ¥é“è¿™äº›æ ‡ç­¾è¯¥æ€ä¹ˆâ€œç¿»è¯‘â€ä¸º K8s å¯¹è±¡ã€‚

æ‰€ä»¥ä½ åœ¨é…ç½®é‡ŒåŠ ï¼š

```yaml
resources:
  overrides:
    pod:
      resource: "pod"
    namespace:
      resource: "namespace"
```

å°±è¡¨ç¤ºï¼š

- Prometheus ä¸­å« `pod` çš„ labelï¼Œå¯¹åº” Kubernetes ä¸­çš„ `Pod` èµ„æºã€‚
- Prometheus ä¸­å« `namespace` çš„ labelï¼Œå¯¹åº” Kubernetes ä¸­çš„ `Namespace`ã€‚



**æœ€ç»ˆ Adapter å°±çŸ¥é“ï¼š**

- â€œè¿™æ¡æŒ‡æ ‡æ˜¯æ¥è‡ªå“ªä¸ª pod çš„â€
- â€œå®ƒå±äºå“ªä¸ª namespaceâ€
- â€œæˆ‘å¯ä»¥æš´éœ²æˆä¸€ä¸ª pod çº§åˆ«çš„æŒ‡æ ‡ï¼Œç»™ Kubernetes ä½¿ç”¨â€



 **HPA æ‰èƒ½è¿™æ ·é…ç½®**

```yaml
metrics:
- type: Pods
  pods:
    metric:
      name: http_requests_per_second
    target:
      type: AverageValue
      averageValue: "10"
```

âš ï¸ å¦åˆ™ï¼ŒHPA ä¼šæŠ¥é”™ï¼š**æ— æ³•æ‰¾åˆ°è¿™ä¸ªæŒ‡æ ‡å¯¹åº”çš„èµ„æºå¯¹è±¡**ã€‚



**3ï¸âƒ£ `name.matches` / `as` â€” é‡å‘½åæŒ‡æ ‡åï¼ˆæš´éœ²ç»™ K8sï¼‰**

- `matches`: åŒ¹é…åŸæŒ‡æ ‡å
- `as`: è‡ªå®šä¹‰æš´éœ²ç»™ K8s çš„æ–°åç§°ï¼ˆç”¨äº HPAï¼‰

```yaml
name:
  matches: "http_requests_total"
  as: "http_requests_per_second"
```

æœ€ç»ˆä½ å¯ä»¥åœ¨ HPA ä¸­è¿™ä¹ˆä½¿ç”¨ï¼š

```yaml
metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "10"
```



**4ï¸âƒ£ `metricsQuery` â€” å®é™… PromQL æŸ¥è¯¢è¯­å¥**

è¿™æ˜¯å…³é”®çš„è½¬æ¢éƒ¨åˆ†ï¼Œç”¨äºç”Ÿæˆæœ€ç»ˆæŒ‡æ ‡å€¼ï¼š

```yaml
metricsQuery: 'sum(rate(http_requests_total{job="my-app"}[2m])) by (pod, namespace)'
```



**å®æˆ˜ç¤ºä¾‹**

![image-20250331095555708](../markdown_img/image-20250331095555708.png)

```bash
# æ·»åŠ è½¬æ¢è§„åˆ™
[root@master1 ~]#kubectl edit cm -n custom-metrics adapter-config
    - seriesQuery: 'http_requests_total{kubernetes_namespace!="",kubernetes_pod_name!=""}'
      resources:
        overrides:
          kubernetes_namespace: {resource: "namespace"}
          kubernetes_pod_name: {resource: "pod"}
      name:
        matches: "^(.*)_total"
        as: "${1}_per_second"
      metricsQuery: rate(<<.Series>>{<<.LabelMatchers>>}[1m])
      
# æµ‹è¯•
[root@master1 ~]# kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/http_requests_per_second | jq .
```



#### Prometheus Adapter çš„é…ç½®æ–‡ä»¶ä¸­ rules è§„åˆ™æ®µä¸­Go æ¨¡æ¿è¯­æ³• çš„å ä½ç¬¦è¯¦è§£

Prometheus Adapter çš„é…ç½®æ–‡ä»¶ä¸­ `rules` æ®µä½¿ç”¨äº†ä¸€äº› **Go æ¨¡æ¿è¯­æ³•çš„å ä½ç¬¦**ï¼Œè¿™äº›å ä½ç¬¦ç”¨äºå°† Prometheus ä¸­çš„æŒ‡æ ‡ä¿¡æ¯è‡ªåŠ¨ **å¡«å……å¹¶è½¬åŒ–** ä¸º Kubernetes API æ‰€éœ€çš„æ ¼å¼ã€‚è¿™äº›å ä½ç¬¦æ˜¯åœ¨ `metricsQuery` ç”Ÿæˆ PromQL æŸ¥è¯¢è¯­å¥æ—¶åŠ¨æ€æ›¿æ¢çš„ã€‚

âœ… **Prometheus Adapter ä¸­ `rules` çš„ç»“æ„å›é¡¾**

```yaml
rules:
  - seriesQuery: <PromQLåŒ¹é…æŒ‡æ ‡çš„è§„åˆ™>
    resources:
      overrides:     # æˆ– template
    name:
      matches: <æ­£åˆ™è¡¨è¾¾å¼>
      as: <è½¬æ¢åçš„æŒ‡æ ‡åç§°>
    metricsQuery: <çœŸæ­£ç”¨äº PromQL æŸ¥è¯¢çš„è¡¨è¾¾å¼>
```

**âœ… å ä½ç¬¦æ¨¡æ¿å˜é‡è¯¦è§£ï¼ˆGo Templateï¼‰**

è¿™äº›å˜é‡å†™æ³•å¦‚ `<<.Series>>`ã€`<<.LabelMatchers>>`ã€`<<.GroupBy>>` ç­‰ï¼Œéƒ½æ˜¯ [Go template](https://golang.org/pkg/text/template/) é£æ ¼ã€‚

| æ¨¡æ¿å˜é‡å           | å«ä¹‰è¯´æ˜                                                     |
| -------------------- | ------------------------------------------------------------ |
| `<<.Series>>`        | åŒ¹é…çš„æŒ‡æ ‡åï¼ˆå¦‚ `container_cpu_usage_seconds_total`ï¼‰       |
| `<<.LabelMatchers>>` | è½¬æ¢è‡ª `seriesQuery` ä¸­çš„æ ‡ç­¾æ¡ä»¶ï¼ˆå¦‚ `{pod!="",namespace!="",container!="POD"}`ï¼‰ |
| `<<.GroupBy>>`       | èµ„æºç›¸å…³æ ‡ç­¾ç»„æˆçš„ `by (namespace, pod)` å­—æ®µ                |
| `<<.Resource>>`      | åªç”¨äº external metricsï¼Œè¡¨ç¤ºå½“å‰èµ„æºå¯¹è±¡ç±»å‹ï¼ˆå¦‚ `deployment`ï¼‰ |

**âœ… å„å­—æ®µä½¿ç”¨ç¤ºä¾‹**

**1ï¸âƒ£ `<<.Series>>`**

è¡¨ç¤ºä½ åœ¨ `seriesQuery` ä¸­åŒ¹é…åˆ°çš„æŒ‡æ ‡åã€‚

```yaml
seriesQuery: '{__name__=~"^container_.*"}'
metricsQuery: sum(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)
```

å¦‚æœ `__name__=~"^container_cpu_usage_seconds_total"`ï¼Œåˆ™æœ€ç»ˆç”Ÿæˆï¼š

```properties
sum(container_cpu_usage_seconds_total{...}) by (...)
```

**2ï¸âƒ£ `<<.LabelMatchers>>`**

è¿™ä¸ªå˜é‡æ ¹æ® `seriesQuery` ä¸­çš„æ ‡ç­¾åŒ¹é…è¡¨è¾¾å¼ï¼Œè‡ªåŠ¨æŠ½å–å‡ºéœ€è¦å¸¦å…¥çš„ label è¿‡æ»¤å™¨ã€‚

```yaml
seriesQuery: '{__name__=~"^container_.*", container!="POD", pod!="", namespace!=""}'
```

æœ€ç»ˆå˜æˆï¼š

```properties
sum(container_cpu_usage_seconds_total{container!="POD", pod!="", namespace!=""})
```

**3ï¸âƒ£ `<<.GroupBy>>`**

è‡ªåŠ¨ä½¿ç”¨å’Œèµ„æºæ˜ å°„ç›¸å…³çš„æ ‡ç­¾ä½œä¸º `group by` çš„å­—æ®µã€‚

```yaml
resources:
  overrides:
    namespace:
      resource: "namespace"
    pod:
      resource: "pod"
```

ä¼šç”Ÿæˆï¼š

```properties
by (namespace, pod)
```

**4ï¸âƒ£ `<<.Resource>>`ï¼ˆåªç”¨äº external.metricsï¼‰**

è¿™ä¸ªç”¨äº external metrics è§„åˆ™ä¸­ï¼Œç”¨äºå°†èµ„æºåï¼ˆå¦‚ deploymentã€statefulsetï¼‰å†™å…¥ metric åä¸­ã€‚

```yaml
resources:
  template: <<.Resource>>
```

æ¯”å¦‚ `<<.Resource>>` æ˜¯ `deployment`ï¼Œé‚£ä¹ˆç”Ÿæˆçš„è·¯å¾„å°†æ˜¯ï¼š

```properties
apis/external.metrics.k8s.io/v1beta1/namespaces/default/deployments/<name>/http_requests_pe
```

**âœ… è¿›é˜¶ç¤ºä¾‹ï¼ˆå®Œæ•´ï¼‰**

```yaml
rules:
  - seriesQuery: '{__name__=~"^container_memory_usage_bytes$", container!="POD", pod!="", namespace!=""}'
    resources:
      overrides:
        namespace:
          resource: namespace
        pod:
          resource: pod
    name:
      matches: "^container_memory_usage_bytes$"
      as: "memory_usage"
    metricsQuery: sum(<<.Series>>{<<.LabelMatchers>>, container!="POD"}) by (<<.GroupBy>>)
```

ä¼šè½¬åŒ–ä¸º PromQLï¼š

```properties
sum(container_memory_usage_bytes{namespace!="", pod!="", container!="POD"}) by (namespace, pod)
```

ç„¶åæš´éœ²ä¸ºï¼š

```http
/apis/custom.metrics.k8s.io/v1beta1/namespaces/<namespace>/pods/<pod>/memory_usage
```

**ğŸš€ å°ç»“**

| å ä½ç¬¦               | ä½œç”¨                                                |
| -------------------- | --------------------------------------------------- |
| `<<.Series>>`        | æŒ‡ä»£ Prometheus æŒ‡æ ‡å                              |
| `<<.LabelMatchers>>` | ä» `seriesQuery` ä¸­è§£æå‡ºçš„ label æ¡ä»¶              |
| `<<.GroupBy>>`       | æ ¹æ® `resources.overrides` æ¨æ–­å‡ºçš„ `group by` å­—æ®µ |
| `<<.Resource>>`      | external metrics ä¸­ç”¨äºç”Ÿæˆèµ„æºç±»å‹è·¯å¾„             |







#### å¯¹äº Prometheus adapter è½¬æ¢åçš„ Kubernetes API ç±»å‹çš„æŒ‡æ ‡çš„è¯·æ±‚æ–¹å¼

```bash
kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1/namespaces/<namespace>/<resource>/<resource-name>/<metric-name>"
```

**å‚æ•°è¯´æ˜ï¼š**

| å­—æ®µ                     | å«ä¹‰                                                         |
| ------------------------ | ------------------------------------------------------------ |
| `/apis`                  | è¯´æ˜è¿™æ˜¯ä¸€ä¸ªæ‰©å±• API Server çš„è·¯å¾„ï¼ˆèšåˆå±‚ä¸‹çš„ APIï¼‰         |
| `custom.metrics.k8s.io`  | Prometheus Adapter æ³¨å†Œçš„ API Groupï¼ˆä¹Ÿæœ‰å¯èƒ½æ˜¯ `external.metrics.k8s.io`ï¼‰ |
| `v1beta1`                | å½“å‰ç‰ˆæœ¬ï¼ˆæ³¨æ„ï¼šå¯èƒ½å› ç‰ˆæœ¬ä¸åŒè€Œå˜åŒ–ï¼‰                       |
| `namespaces/<namespace>` | æŒ‡å®šå‘½åç©ºé—´                                                 |
| `<resource>`             | èµ„æºç±»å‹ï¼Œå¦‚ `pods`ã€`deployments`                           |
| `<resource-name>`        | èµ„æºå¯¹è±¡åç§°ï¼Œä¾‹å¦‚ pod åæˆ– deployment å                    |
| `<metric-name>`          | æŒ‡æ ‡åç§°ï¼Œæ¯”å¦‚ `http_requests_per_second`                    |

**ç¤ºä¾‹**

```bash
kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/myapp-547df679bb-67kkp/http_requests_per_second"
```

è¿™æ¡å‘½ä»¤çš„å«ä¹‰æ˜¯ï¼š

- æŸ¥è¯¢ default å‘½åç©ºé—´ä¸‹çš„ pod `myapp-547df679bb-67kkp`
- å¯¹åº”æŒ‡æ ‡åæ˜¯ `http_requests_per_second`
- ç”± Prometheus Adapter ä»£ç†ï¼Œä» Prometheus æ‹‰å–å¹¶è¿”å›æŒ‡æ ‡æ•°æ®



**ğŸ†š å¦å¤–ä¸€ç§ï¼šExternal Metrics çš„æ ¼å¼**

å¦‚æœä½ é…ç½®çš„æ˜¯ `external.metrics.k8s.io`ï¼Œæ ¼å¼ä¼šç•¥æœ‰ä¸åŒï¼Œ**æ²¡æœ‰ resource-name**ï¼š

```bash
kubectl get --raw "/apis/external.metrics.k8s.io/v1beta1/namespaces/<namespace>/<metric-name>"
```

æ¯”å¦‚ï¼š

```bash
kubectl get --raw "/apis/external.metrics.k8s.io/v1beta1/namespaces/default/qps"
```

**ğŸš¨ å°ç»“**

| ç±»å‹                           | API Group                 | ä½¿ç”¨æ–¹å¼          | ç¤ºä¾‹                                                         |
| ------------------------------ | ------------------------- | ----------------- | ------------------------------------------------------------ |
| è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆPod/Deploymentç­‰ï¼‰ | `custom.metrics.k8s.io`   | æ¯ä¸ªèµ„æºä¸€ä¸ª      | `/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/mypod/cpu_usage` |
| å¤–éƒ¨æŒ‡æ ‡ï¼ˆä¸ç»‘å®šèµ„æºï¼‰         | `external.metrics.k8s.io` | æŒ‰å‘½åç©ºé—´+æŒ‡æ ‡å | `/apis/external.metrics.k8s.io/v1beta1/namespaces/defaul`    |



#### å¯¹è‡ªå®šä¹‰æŒ‡æ ‡è¿›è¡Œæµ‹è¯•

ä¸Šé¢åˆ›å»ºçš„æµ‹è¯•Podï¼ˆmetrics-appï¼‰æš´éœ²äº†è‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆhttp_requests_per_secondï¼‰ï¼Œå¯¹å…¶è¿›è¡Œæµ‹è¯•

```bash
# æŸ¥çœ‹æµ‹è¯•Pod
[root@master1 example-metrics]#kubectl get pod
NAME                           READY   STATUS    RESTARTS        AGE
metrics-app-56c77b4999-d4nkl   1/1     Running   0               139m
metrics-app-56c77b4999-rw9nv   1/1     Running   0               139m

# æŸ¥çœ‹service
[root@master1 example-metrics]#kubectl get svc metrics-app
NAME                         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
metrics-app                  NodePort       10.109.188.210   <none>        80:30574/TCP   14h

# æµ‹è¯•
[root@master1 ~]# while true; do curl 10.109.188.210; sleep 0.$RANDOM;done
```

![image-20250331133822701](../markdown_img/image-20250331133822701.png)



### HPA

**HPA** æ˜¯ Kubernetes çš„ä¸€ä¸ªæ§åˆ¶å™¨ï¼Œç”¨äºæ ¹æ®å®æ—¶ç›‘æ§çš„æŒ‡æ ‡ï¼ˆå¦‚ CPU ä½¿ç”¨ç‡ã€å†…å­˜ã€è‡ªå®šä¹‰æŒ‡æ ‡ç­‰ï¼‰**è‡ªåŠ¨å¢åŠ æˆ–å‡å°‘ Pod å‰¯æœ¬æ•°é‡**ï¼Œä»è€Œå®ç°å¼¹æ€§æ‰©ç¼©å®¹ã€‚



#### åŠ¨æ€ä¼¸ç¼©æ§åˆ¶å™¨ç±»å‹

**æ°´å¹³Podè‡ªåŠ¨ç¼©æ”¾å™¨ï¼ˆHPAï¼‰**

- åŸºäºpodèµ„æºåˆ©ç”¨ç‡æ¨ªå‘è°ƒæ•´podå‰¯æœ¬æ•°é‡

**å‚ç›´podè‡ªåŠ¨ç¼©æ”¾å™¨ï¼ˆVPAï¼‰**

- åŸºäºPodèµ„æºåˆ©ç”¨ç‡ï¼Œè°ƒæ•´å¯¹å•ä¸ªpodçš„æœ€å¤§èµ„æºé™åˆ¶ï¼Œä¸èƒ½ä¸HPAåŒæ—¶ä½¿ç”¨

**é›†ç¾¤ä¼¸ç¼©ï¼ˆCluster Autoscaler, CAï¼‰**

- åŸºäºé›†ç¾¤nodeèµ„æºä½¿ç”¨æƒ…å†µï¼ŒåŠ¨æ€ä¼¸ç¼©nodeèŠ‚ç‚¹ï¼Œä»è€Œä¿è¯æœ‰CPUå’Œå†…å­˜èµ„æºç”¨äºåˆ›å»ºPod



#### HPAæ§åˆ¶å™¨ç®€ä»‹

Horizontal Pod Authscalingï¼ˆHPAï¼‰æ§åˆ¶å™¨ï¼Œæ ¹æ®é¢„å®šä¹‰çš„é˜ˆå€¼åŠPodå½“å‰çš„èµ„æºåˆ©ç”¨ç‡ï¼Œè‡ªåŠ¨æ§åˆ¶åœ¨K8Sé›†ç¾¤ä¸­è¿è¡Œçš„Podæ•°é‡ï¼ˆè‡ªåŠ¨å¼¹æ€§æ°´å¹³è‡ªåŠ¨ä¼¸ç¼©ï¼‰

```bash
--horizontal-pod-autoscaler-sync-period                # é»˜è®¤æ¯éš”15sï¼ˆå¯ä»¥é€šè¿‡ --horizontal-pod-autoscaler-sync-periodä¿®æ”¹ï¼‰æŸ¥è¯¢metricsçš„èµ„æºä½¿ç”¨æƒ…å†µ
--horizontal-pod-autoscaler-downscale-stabilization    # ç¼©å®¹é—´éš”å‘¨æœŸï¼Œé»˜è®¤5åˆ†é’Ÿï¼ˆé˜²æ­¢æµé‡æŠ–åŠ¨ï¼‰
--horizontal-pod-autoscaler-sync-period                # HPAæ§åˆ¶å™¨åŒæ­¥podå‰¯æœ¬æ•°çš„é—´éš”å‘¨æœŸ
--horizontal-pod-autoscaler-cpu-initalization-period   # åˆå§‹åŒ–å»¶è¿Ÿæ—¶é—´ï¼Œåœ¨æ­¤æ—¶é—´å†…podçš„CPUèµ„æºæŒ‡æ ‡å°†ä¸ä¼šç”Ÿæ•ˆï¼Œé»˜è®¤ä¸º5åˆ†é’Ÿ
--horizontal-pod-autoscaler-initial-readiness-delay    # ç”¨äºè®¾ç½®podå‡†å¤‡æ—¶é—´ï¼Œåœ¨æ­¤æ—¶é—´å†…çš„podç»Ÿç»Ÿè¢«è®¤ä¸ºæœªå°±ç»ªåŠä¸é‡‡é›†æ•°æ®ï¼Œé»˜è®¤ä¸º30ç§’,ä¸¾ä¾‹è§£é‡Šï¼šè¯¥å‚æ•°æ˜¯ä¸ºäº†é˜²æ­¢åˆšåˆ›å»ºçš„ Pod åœ¨è¿˜æœªå°±ç»ªæ—¶å°±è¢«çº³å…¥ HPA çš„æŒ‡æ ‡é‡‡é›†ä¸­ï¼ˆå› ä¸ºå¯åŠ¨æœŸèµ„æºå ç”¨å¯èƒ½éå¸¸ä½ï¼‰ï¼Œä»è€Œè¯¯å¯¼ç¼©å®¹å†³ç­–ã€‚
#æ¯”å¦‚ï¼šå¦‚æœä½ æ–°æ‰©å®¹äº† 3 ä¸ª Podï¼Œå®ƒä»¬åˆšå¯åŠ¨æ—¶çš„èµ„æºä½¿ç”¨ç‡å‡ ä¹ä¸º 0ï¼Œå¦‚æœä¸è®¾ç½®è¿™ä¸ªå»¶è¿Ÿï¼ŒHPA ä¼šé©¬ä¸Šè®¤ä¸ºæ•´ä½“ä½¿ç”¨ç‡ä¸‹é™ï¼Œä»è€Œé”™è¯¯è§¦å‘ç¼©å®¹ã€‚
--horizontal-pod-autoscaler-tolerance   # HPAæ§åˆ¶å™¨èƒ½å®¹å¿çš„æ•°æ®å·®å¼‚ï¼ˆæµ®ç‚¹æ•°ï¼Œé»˜è®¤ä¸º0.1ï¼‰å³æ–°çš„æŒ‡æ ‡è¦ä¸å½“å‰çš„é˜ˆå€¼å·®å¼‚åœ¨0.1æˆ–ä»¥ä¸Šï¼Œå³è¦å¤§äº1+0.1=1.1,æˆ–å°äº1-0.1=0.9ï¼Œæ¯”å¦‚é˜ˆå€¼ä¸ºCPUåˆ©ç”¨ç‡50%ï¼Œå½“å‰ä¸º80%ï¼Œé‚£ä¹ˆ80/50=1.6 > 1.1åˆ™ä¼šè§¦å‘æ‰©å®¹ï¼Œåä¹‹ä¼šç¼©å®¹ï¼Œå³è§¦å‘æ¡ä»¶ï¼šavg(CurrentPodsConsumption / Target > 1.1 æˆ– <0.9=æŠŠNä¸ªpodçš„æ•°æ®ç›¸åŠ åæ ¹æ®podçš„æ•°é‡è®¡ç®—å‡ºå¹³å‡æ•°é™¤ä»¥é˜ˆå€¼ï¼Œå¤§äº1.1å°±æ‰©å®¹ï¼Œå°äº0.9å°±ç¼©å®¹)

# è®¡ç®—å…¬å¼ï¼šTargetNumOfPods = ceil(sum(CurrentPodsCPUUtilization) / Target) #ceilæ˜¯å‘ä¸Šå–æ•´çš„ç›®çš„podæ•´æ•°

# æŒ‡æ ‡æ•°æ®éœ€è¦éƒ¨ç½²metrics-serverï¼Œå³HPAä½¿ç”¨metrics-serverä½œä¸ºæ•°æ®æº

[root@master-01 ~]#kube-controller-manager --help|grep horizontal 
......
      --concurrent-horizontal-pod-autoscaler-syncs int32               The number of horizontal pod autoscaler objects that are allowed to sync concurrently. Larger number = more responsive horizontal pod autoscaler objects processing, but more CPU (and network) load. (default 5)
      --horizontal-pod-autoscaler-cpu-initialization-period duration   The period after pod start when CPU samples might be skipped. (default 5m0s)
      --horizontal-pod-autoscaler-downscale-stabilization duration     The period for which autoscaler will look backwards and not scale down below any recommendation it made during that period. (default 5m0s)
      --horizontal-pod-autoscaler-initial-readiness-delay duration     The period after pod start during which readiness changes will be treated as initial readiness. (default 30s)
      --horizontal-pod-autoscaler-sync-period duration                 The period for syncing the number of pods in horizontal pod autoscaler. (default 15s)
      --horizontal-pod-autoscaler-tolerance float                      The minimum change (from 1.0) in the desired-to-actual metrics ratio for the horizontal pod autoscaler to consider scaling. (default 0.1)

```

ä½¿ç”¨ HPA çš„å‰ææ¡ä»¶ï¼šå¿…é¡»éƒ¨ç½² `metrics-server`

```ABAP
HPA é»˜è®¤ä¾èµ– metrics.k8s.io API æ¥è·å– Pod çš„èµ„æºä½¿ç”¨æƒ…å†µï¼ˆå¦‚ CPUã€å†…å­˜ï¼‰ï¼Œè€Œè¿™ä¸ª API æ˜¯ç”± metrics-server æä¾›çš„ã€‚
```

**æ³¨æ„ï¼š**

```ABAP
ä½¿ç”¨HPAï¼Œè¯¥å¯¹è±¡å¿…é¡»è®¾ç½®èµ„æºé™åˆ¶ï¼Œå³Requestçš„å€¼ï¼Œå¦åˆ™HPAå–ä¸åˆ°å€¼ï¼ŒHPAæ˜¯æ ¹æ®:å½“å‰ä½¿ç”¨çš„å€¼ / Request = ä½¿ç”¨ç‡ï¼Œä»è€Œå’Œé˜ˆå€¼è¿›è¡Œæ¯”è¾ƒæ¥å†³å®šå¦‚ä½•æ‰©ç¼©å®¹çš„ï¼ˆè¿™é‡Œæ³¨æ„ï¼Œä¸æ˜¯Limitå€¼ï¼Œè€Œæ˜¯Requestçš„å€¼ï¼‰
```

```ABAP
ä¸€æ—¦éƒ¨ç½²äº† HPAï¼ŒPod çš„å‰¯æœ¬æ•°æ§åˆ¶æƒå°±ä» Deployment / StatefulSet è½¬ç§»åˆ°äº† HPAã€‚
å¦‚æœä½ åŒæ—¶è®¾ç½®äº† Deployment çš„ replicas: 3 å’Œ HPA çš„ minReplicas=5ï¼Œæœ€ç»ˆå‰¯æœ¬æ•°ä¼šæ˜¯ â‰¥5ã€‚
å¦‚æœä½ åˆ é™¤äº† HPA å¯¹è±¡ï¼ŒDeployment æˆ– StatefulSet ä¼šå›é€€åˆ°è‡ªå·± .spec.replicas çš„å€¼
```



#### kube-controller-manager çš„å¯åŠ¨å‚æ•°è°ƒä¼˜ç¤ºä¾‹





#### HPAå‘½ä»¤åŸºç¡€

**âœ… åˆ›å»º HPA**

```bash
kubectl autoscale deployment <deployment-name> \
  --cpu-percent=75 \
  --min=2 \
  --max=10
```

**ç¤ºä¾‹**ï¼š

```bash
kubectl autoscale deployment myapp --cpu-percent=70 --min=2 --max=6
```

è¿™ä¸ªå‘½ä»¤ï¼š

- ä¸º `myapp` éƒ¨ç½²åˆ›å»ºä¸€ä¸ª HPAã€‚
- æŒ‡å®šå½“ CPU ä½¿ç”¨ç‡è¶…è¿‡ 70% æ—¶è¿›è¡Œæ‰©å®¹ã€‚
- é™å®šå‰¯æœ¬æ•°é‡ä¸º 2ï½6 ä¹‹é—´ã€‚



#### æŸ¥çœ‹ HPA

âœ… æŸ¥çœ‹æ‰€æœ‰å‘½åç©ºé—´ä¸‹çš„ HPA

```bash
kubectl get hpa --all-namespaces
```

âœ… æŸ¥çœ‹æŸä¸ª HPA çš„è¯¦æƒ…

```bash
kubectl describe hpa <hpa-name>
```

ç¤ºä¾‹

```bash
kubectl describe hpa myapp
```

è¿™ä¼šå±•ç¤ºï¼š

- å½“å‰/ç›®æ ‡ CPU ä½¿ç”¨ç‡
- æ‰©å®¹å†å²
- å½“å‰ Pod æ•°
- æ˜¯å¦è§¦å‘äº†æ‰©ç¼©å®¹
- ä½¿ç”¨çš„æŒ‡æ ‡ç­‰





#### HPA çš„æ¸…å•ç»“æ„å’Œå­—æ®µè¯´æ˜

ä»¥ä¸‹æ˜¯ä¸€ä¸ª**ç”Ÿäº§çº§åˆ«** HPA å®Œæ•´ç¤ºä¾‹ï¼ˆåŸºäº CPU åˆ©ç”¨ç‡ï¼‰ï¼š

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
  namespace: default
spec:
  scaleTargetRef:                       # ç›®æ ‡å¯¹è±¡ï¼šå³è¢«æ‰©ç¼©å®¹çš„Deploymentæˆ–Statefulset
    apiVersion: apps/v1                 # è¢«æ‰©ç¼©å®¹çš„ç›®æ ‡èµ„æºçš„ api ç‰ˆæœ¬
    kind: Deployment                    # èµ„æºç±»å‹ï¼Œå¯ä»¥æ˜¯ Deploymentã€StatefulSet ç­‰
    name: myapp                         # ç›®æ ‡èµ„æºåç§°
  minReplicas: 2                        # æœ€å° Pod æ•°
  maxReplicas: 10                       # æœ€å¤§ Pod æ•°
  metrics:                              # æŒ‡æ ‡æ¥æºï¼ˆæ”¯æŒå¤šä¸ªï¼‰
  - type: Resource                      # ç±»å‹ä¸ºèµ„æºçº§åˆ«ï¼Œeg:Pods
    resource:
      name: cpu                         # èµ„æºç±»å‹ä¸º CPU
      target:
        type: Utilization               # æŒ‡æ ‡ç±»å‹ä¸ºåˆ©ç”¨ç‡
        averageUtilization: 75          # æœŸæœ› CPU åˆ©ç”¨ç‡ä¸º 75%
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
      - type: Pods
        value: 4
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
```

**å­—æ®µè¯¦ç»†è§£æ**

**âœ… `scaleTargetRef`**

- ç›®æ ‡å¯¹è±¡ï¼šå³è¢«æ‰©ç¼©å®¹çš„ Deployment æˆ– StatefulSetã€‚

**âœ… minReplicas` / `maxReplicas**

- æ§åˆ¶ Pod å‰¯æœ¬æ•°é‡ä¸Šä¸‹é™ï¼Œä¿è¯ç³»ç»Ÿä¸è¢«æ— é™æ‰©å±•æˆ–ç¼©å‡ã€‚

**âœ… `metrics` â€” æŒ‡æ ‡é…ç½®ï¼ˆèµ„æºå‹ï¼‰**

```yaml
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      type: Utilization
      averageUtilization: 75
```

- è¡¨ç¤ºï¼šå½“å¹³å‡ CPU ä½¿ç”¨ç‡è¶…å‡º 75%ï¼Œå°†è§¦å‘æ‰©å®¹æ“ä½œã€‚

**âœ… `behavior` â€” æ§åˆ¶æ‰©ç¼©å®¹é€Ÿç‡ä¸æŠ–åŠ¨æŠ‘åˆ¶**

```yaml
behavior:
  scaleUp:
    stabilizationWindowSeconds: 0
    policies:
    - type: Percent
      value: 100
      periodSeconds: 60
    - type: Pods
      value: 4
      periodSeconds: 60
```

ğŸŸ¢ **scaleUp**

- `stabilizationWindowSeconds: 0`
  - æ‰©å®¹æ—¶ä¸ç­‰å¾…ï¼Œç«‹å³æ ¹æ®æŒ‡æ ‡æ‰©å®¹ã€‚
- ä¸¤æ¡ç­–ç•¥å¹¶å­˜ï¼š
  - æ¯ 60 ç§’æœ€å¤šå¢åŠ  100% çš„ pod æ•°é‡ã€‚
  - æˆ–è€…æ¯ 60 ç§’æœ€å¤šå¢åŠ  4 ä¸ª Podã€‚
- **æœ€ç»ˆå€¼å–ä¸¤è€…ä¸­è¾ƒå°å€¼**ã€‚

```yaml
  scaleDown:
    stabilizationWindowSeconds: 300
    policies:
    - type: Percent
      value: 50
      periodSeconds: 60
    - type: Pods
      value: 2
      periodSeconds: 60
```

**ğŸ”´ scaleDown**

- `stabilizationWindowSeconds: 300`
  - è¿‡å» 5 åˆ†é’Ÿå†…å¦‚æœæ²¡æœ‰æŒç»­ä¸‹é™è¶‹åŠ¿ï¼Œåˆ™ä¸ç¼©å®¹ï¼Œ**é˜²æ­¢å› çªå‘æµé‡ä¸‹é™è€Œé¢‘ç¹ç¼©å®¹æŠ–åŠ¨**ã€‚
- ç­–ç•¥å«ä¹‰ï¼š
  - æ¯åˆ†é’Ÿæœ€å¤šç¼©å° 50% å‰¯æœ¬æ•°ï¼Œæˆ–è€…æ¯åˆ†é’Ÿæœ€å¤šç¼©å®¹ 2 ä¸ª Podã€‚
- ä¹Ÿæ˜¯å–ä¸¤è€…è¾ƒå°å€¼ã€‚



**æ¨èç”Ÿäº§é…ç½®å»ºè®®è¡¨**

| é¡¹ç›®                                   | å»ºè®®å€¼                | è¯´æ˜                                   |
| -------------------------------------- | --------------------- | -------------------------------------- |
| `minReplicas`                          | â‰¥2                    | å•å‰¯æœ¬å®¹æ˜“æ•…éšœï¼Œ2 æ˜¯é«˜å¯ç”¨èµ·æ­¥         |
| `scaleDown.stabilizationWindowSeconds` | 300                   | é˜²æ­¢æŠ–åŠ¨å»ºè®®è®¾ç½®ä¸º 300 ç§’              |
| `scaleUp.policies`                     | é™é€Ÿç­–ç•¥              | æ§åˆ¶æ‰©å®¹æ—¶ä¸ä¼šçŒ›å¢                     |
| `metrics`                              | CPU / Memory / è‡ªå®šä¹‰ | å¯ç»„åˆå¤šç§æŒ‡æ ‡ä¸€èµ·åˆ¤æ–­                 |
| `requests.cpu`                         | å¿…é¡»é…ç½®              | å¦åˆ™æ— æ³•åŸºäº `averageUtilization` ç”Ÿæ•ˆ |



**æ‰©å±•å»ºè®®ï¼šç»“åˆ VPA + HPA**

| æ¨¡å¼      | æè¿°                                                       |
| --------- | ---------------------------------------------------------- |
| HPA       | é€šè¿‡æŒ‡æ ‡è°ƒæ•´å‰¯æœ¬æ•°é‡ï¼ˆæ¨ªå‘æ‰©ç¼©å®¹ï¼‰                         |
| VPA       | é€šè¿‡æŒ‡æ ‡è°ƒæ•´ Pod çš„èµ„æºè§„æ ¼ï¼ˆçºµå‘æ‰©ç¼©å®¹ï¼‰                  |
| HPA + VPA | VPA è®¾ç½® mode ä¸º `"Initial"` åªæ¨èåˆå§‹å€¼ï¼Œé¿å…ä¸ HPA å†²çª |



#### æ­£ç¡®è®¾ç½®HPAï¼Œé˜²æ­¢æŠ–åŠ¨çš„æœ€ä½³å®è·µ

| åœºæ™¯               | æœ€ä½³å®è·µ                                             |
| ------------------ | ---------------------------------------------------- |
| æƒ³ç¨³å®šè¿è¡Œï¼Œå°‘ç¼©å®¹ | **æé«˜ `minReplicas`**ï¼ˆæœ€ç›´æ¥ã€æœ€æœ‰æ•ˆçš„é˜²æŠ–åŠ¨æ–¹å¼ï¼‰ |
| ä¸èƒ½æµªè´¹èµ„æº       | ç²¾ç»†è®¾ç½® `scaleDown` è¡Œä¸ºç­–ç•¥                        |
| åº”å¯¹çªå‘é«˜å³°       | è®¾å®šåˆç† `scaleUp` ç­–ç•¥                              |
| æŒ‡æ ‡æ³¢åŠ¨å‰§çƒˆ       | ä½¿ç”¨ PromQL å¹³æ»‘å‡½æ•° `avg_over_time()`               |



### VPA

**VPAï¼ˆå‚ç›´è‡ªåŠ¨æ‰©ç¼©å®¹å™¨ï¼‰** æ˜¯ Kubernetes ä¸­ä¸€ä¸ª **è‡ªåŠ¨ä¸º Pod åˆ†é…é€‚å½“ CPU å’Œå†…å­˜èµ„æºï¼ˆrequests/limitsï¼‰** çš„ç»„ä»¶ã€‚

å®ƒçš„ç›®æ ‡æ˜¯ï¼šæ ¹æ® Pod çš„å®é™…è¿è¡Œæƒ…å†µï¼Œ**è‡ªåŠ¨è°ƒæ•´èµ„æºè¯·æ±‚**ï¼Œä»è€Œæå‡èµ„æºåˆ©ç”¨ç‡ä¸åº”ç”¨æ€§èƒ½ã€‚



**å’Œ HPAï¼ˆHorizontal Pod Autoscalerï¼‰çš„åŒºåˆ«**

| ç‰¹æ€§     | HPAï¼ˆæ°´å¹³ï¼‰      | VPAï¼ˆå‚ç›´ï¼‰                      |
| -------- | ---------------- | -------------------------------- |
| è°ƒæ•´å¯¹è±¡ | Pod çš„å‰¯æœ¬æ•°é‡   | Pod çš„èµ„æºè¯·æ±‚ï¼ˆCPU/å†…å­˜ï¼‰       |
| è§¦å‘æ¡ä»¶ | CPU/å†…å­˜åˆ©ç”¨ç‡ç­‰ | å®é™…è¿è¡Œèµ„æºä½¿ç”¨ï¼ˆé€šè¿‡ Metricsï¼‰ |
| ä½¿ç”¨åœºæ™¯ | åº”å¯¹è´Ÿè½½æ³¢åŠ¨     | ä¿è¯å•ä¸ª Pod çš„æ€§èƒ½              |
| é‡å»º Pod | âŒ ä¸é‡å»º         | âœ… ä¼šé‡å»º Pod ä½¿æ–°èµ„æºç”Ÿæ•ˆ        |



**VPA çš„æ ¸å¿ƒç»„ä»¶**

VPA é€šå¸¸åŒ…å« 3 ä¸ªå­ç»„ä»¶ï¼ˆä¹Ÿå¯ä»¥é€šè¿‡ Helm æˆ– Operator å®‰è£…ï¼‰ï¼š

| ç»„ä»¶                     | åŠŸèƒ½æè¿°                              |
| ------------------------ | ------------------------------------- |
| **Recommender**          | æ”¶é›†å†å²æŒ‡æ ‡æ•°æ®ï¼Œè®¡ç®—èµ„æºå»ºè®®        |
| **Updater**              | åˆ¤æ–­å“ªäº› Pod éœ€è¦é‡å¯ä»¥åº”ç”¨å»ºè®®       |
| **Admission Controller** | åœ¨ Pod åˆ›å»ºæ—¶æ³¨å…¥æ¨èèµ„æºï¼ˆå¦‚æœå¼€å¯ï¼‰ |



**ä½¿ç”¨ç¤ºä¾‹**

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: myapp-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: myapp
  updatePolicy:
    updateMode: "Auto"   # å¯é€‰ï¼šAuto / "Off" / "Initial"
```

è¿™è¡¨ç¤ºä¼šç›‘æ§ `myapp` Deploymentï¼Œå¹¶è‡ªåŠ¨è°ƒæ•´å®ƒçš„ CPU å’Œå†…å­˜ request/limitã€‚



**updateMode ä¸‰ç§æ¨¡å¼**

| æ¨¡å¼      | å«ä¹‰                                 |
| --------- | ------------------------------------ |
| `Off`     | ä¸è¿›è¡Œä»»ä½•æ¨èæˆ–è‡ªåŠ¨æ›´æ–°             |
| `Initial` | åªåœ¨ **Pod ç¬¬ä¸€æ¬¡åˆ›å»ºæ—¶** æ³¨å…¥æ¨èå€¼ |
| `Auto`    | è‡ªåŠ¨æ›´æ–°èµ„æºå€¼å¹¶é‡å¯ Podï¼ˆæ…ç”¨ï¼‰     |



#### HAPå’ŒVPAçš„åº”ç”¨å¯¹æ¯”

HPAï¼ˆHorizontal Pod Autoscalerï¼‰å’Œ VPAï¼ˆVertical Pod Autoscalerï¼‰è™½ç„¶éƒ½æ˜¯è‡ªåŠ¨ä¼¸ç¼©ç»„ä»¶ï¼Œä½†å®ƒä»¬è§£å†³çš„é—®é¢˜ä¸åŒï¼Œ**åœºæ™¯å„æœ‰ä¾§é‡ï¼Œä¹Ÿå¯ä»¥ååŒå·¥ä½œ**ã€‚ä¸‹é¢ä» **åœºæ™¯å¯¹æ¯”**ã€**åä½œå»ºè®®**ã€**å®é™…æ¡ˆä¾‹** ä¸‰æ–¹é¢è¿›è¡Œå¯¹æ¯”



**HPA å’Œ VPA çš„åº”ç”¨åœºæ™¯å¯¹æ¯”**

| é¡¹ç›®             | HPAï¼ˆæ°´å¹³æ‰©ç¼©å®¹ï¼‰                         | VPAï¼ˆå‚ç›´æ‰©ç¼©å®¹ï¼‰                                          |
| ---------------- | ----------------------------------------- | ---------------------------------------------------------- |
| ğŸ”„ æ ¸å¿ƒåŠŸèƒ½       | è‡ªåŠ¨è°ƒæ•´ Pod å‰¯æœ¬æ•°                       | è‡ªåŠ¨è°ƒæ•´ Pod æ‰€éœ€çš„ CPU/å†…å­˜                               |
| ğŸ¯ é€‚ç”¨åœºæ™¯       | ç¬æ—¶è®¿é—®é‡æ¿€å¢çš„ Web æœåŠ¡ï¼ˆæ¯”å¦‚ç”µå•†ç§’æ€ï¼‰ | å¯åŠ¨åèµ„æºä½¿ç”¨å›ºå®šã€å¯¹æ€§èƒ½è¦æ±‚é«˜çš„æœåŠ¡ï¼ˆå¦‚æ•°æ®åº“ã€ä¸­é—´ä»¶ï¼‰ |
| ğŸ“ˆ æŒ‡æ ‡æ¥æº       | Metrics Serverï¼ˆCPUã€å†…å­˜ã€å®šåˆ¶æŒ‡æ ‡ï¼‰     | Recommender ç»„ä»¶ï¼ˆä» Prometheus/Metrics APIï¼‰              |
| âš ï¸ æ³¨æ„äº‹é¡¹       | éœ€è®¾ç½®èµ„æº requests/limitsï¼Œæ‰èƒ½ç”Ÿæ•ˆ      | è‡ªåŠ¨é‡å¯ Pod åº”ç”¨æ–°é…ç½®ï¼Œæ³¨æ„æ˜¯å¦å½±å“ä¸šåŠ¡                  |
| ğŸ¤ ä¸å¼¹æ€§èƒ½åŠ›å…³ç³» | æé«˜ç³»ç»Ÿå¼¹æ€§ï¼Œé€‚åº”æµé‡æ³¢åŠ¨                | æé«˜å•ä¸ª Pod çš„èµ„æºåˆ©ç”¨ç‡                                  |



**HPA å’Œ VPA èƒ½åä½œä½¿ç”¨å—ï¼Ÿ**

âœ… å¯ä»¥ï¼Œä½†è¦æ³¨æ„ï¼š

- **é»˜è®¤ä¸èƒ½åŒæ—¶æ§åˆ¶åŒä¸€ä¸ª Pod çš„ CPU request å€¼**
- Kubernetes å®˜æ–¹å»ºè®®ä¸¤è€…æ­é…æ—¶ï¼Œ**VPA åªè®¾ç½®å†…å­˜ requestï¼ŒHPA è´Ÿè´£å‰¯æœ¬æ‰©ç¼©å®¹**
- æˆ–è€…ä½¿ç”¨ VPA çš„ `updateMode: Initial` æ¨¡å¼ï¼Œä»…åœ¨åˆ›å»ºæ—¶æ³¨å…¥æ¨èå€¼



#### å®é™…åº”ç”¨æ¡ˆä¾‹

å½“ä½ æœ‰ä¸€ä¸ª **Java ç¨‹åº**ï¼Œå°¤å…¶æ˜¯åƒ Spring Boot è¿™ç±»åº”ç”¨ï¼Œ**å¯åŠ¨æ—¶éœ€è¦å¤§é‡å†…å­˜ï¼ˆJVM å¯åŠ¨ + ç±»åŠ è½½ + ç¼“å­˜ç­‰ï¼‰**ï¼Œè€Œä½ **åˆä¸ç¡®å®šåˆ°åº•éœ€è¦å¤šå°‘å†…å­˜æ‰åˆç†**ï¼Œæ­¤æ—¶å¯ä»¥ä½¿ç”¨ï¼š**VPA çš„ `updateMode: Initial` æ¨¡å¼**



**VPA Initial æ¨¡å¼çš„è¡Œä¸ºç‰¹ç‚¹ï¼š**

| ç‰¹æ€§           | è¯´æ˜                                                         |
| -------------- | ------------------------------------------------------------ |
| ğŸ’¡ ä¸€æ¬¡æ€§æ³¨å…¥   | åªåœ¨ Pod åˆ›å»ºæ—¶ä½¿ç”¨æ¨èçš„ `resources.requests/limits` è¿›è¡Œæ³¨å…¥ |
| ğŸ” ä¸ä¼šè‡ªåŠ¨æ›´æ–° | åç»­ä¸ä¼šåœ¨è¿è¡Œæ—¶åŠ¨æ€æ›´æ”¹ Pod çš„èµ„æºï¼Œä¹Ÿä¸ä¼šè§¦å‘ Pod é‡å¯     |
| ğŸ“ˆ ä¾èµ–å†å²æ•°æ® | **VPA ä¼šæ ¹æ®å†å²è¿è¡Œæ•°æ®æˆ–ç±»ä¼¼ Pod çš„èµ„æºä½¿ç”¨å»ºè®®è¿›è¡Œåˆå§‹åŒ–æ¨è** |
| ğŸ’¥ é¿å…å‰¯ä½œç”¨   | é¿å…å› èµ„æºå˜åŒ–å¸¦æ¥çš„è‡ªåŠ¨é‡å¯ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒæ…é‡æ‰©å®¹           |



**ç¤ºä¾‹é…ç½®**

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: java-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: java-app
  updatePolicy:
    updateMode: "Initial"   # åªåœ¨Podåˆ›å»ºæ—¶æ³¨å…¥æ¨èèµ„æº
```



**å®é™…å»ºè®®ï¼š**

1. **ç¬¬ä¸€æ¬¡éƒ¨ç½²æ—¶ç”¨ Initial æ¨¡å¼**ï¼Œè®© VPA å¸®ä½ â€œçŒœâ€ä¸€ä¸ªåˆé€‚çš„åˆå§‹èµ„æº
2. åç»­é€šè¿‡ç›‘æ§ï¼ˆæ¯”å¦‚ Prometheus + Grafanaï¼‰è§‚å¯Ÿ JVM ä½¿ç”¨ï¼Œå†å¾®è°ƒ
3. å¦‚éœ€é•¿æœŸè¿è¡Œå¹¶ä¿æŒèµ„æºé€‚é…ï¼Œå¯ä»¥è€ƒè™‘åæœŸåˆ‡æ¢ä¸º `Auto` æ¨¡å¼



#### Java åº”ç”¨è‡ªåŠ¨è°ƒå‚ + VPA é…ç½®å»ºè®®è¡¨

**åŸºç¡€çŸ¥è¯†ç†è§£**

| ç»„ä»¶             | å«ä¹‰                                      | å¤‡æ³¨                                   |
| ---------------- | ----------------------------------------- | -------------------------------------- |
| HPA              | Horizontal Pod Autoscaler                 | æ ¹æ®è´Ÿè½½æ°´å¹³è°ƒèŠ‚å‰¯æœ¬æ•°ï¼ˆscale out/inï¼‰ |
| VPA              | Vertical Pod Autoscaler                   | æ ¹æ®å†å²èµ„æºä½¿ç”¨å»ºè®®è°ƒæ•´ CPU / å†…å­˜    |
| VPA Initial æ¨¡å¼ | åªåœ¨ Pod åˆ›å»ºæ—¶è®¾ç½®æ¨èçš„ requests/limits | æ¨èç”Ÿäº§ç¯å¢ƒä½¿ç”¨                       |
| VPA Auto æ¨¡å¼    | è‡ªåŠ¨è§‚å¯Ÿ + è‡ªåŠ¨è°ƒèŠ‚ + è‡ªåŠ¨é‡å¯ Pod        | å»ºè®®éæ ¸å¿ƒæœåŠ¡æˆ–å¼€å‘ç¯å¢ƒç”¨             |
| JVM ç‰¹ç‚¹         | å¯åŠ¨ç¬é—´èµ„æºé«˜ï¼Œé•¿æœŸå†…å­˜é€æ¸é‡Šæ”¾          | å»ºè®®åˆå§‹è®¾ç½®ç•¥å®½è£•                     |



 **VPA æ¨èé…ç½®ï¼ˆç”¨äºç”Ÿäº§ Java åº”ç”¨ï¼‰**

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: java-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: java-app
  updatePolicy:
    updateMode: "Initial"  # ä»… Pod å¯åŠ¨æ—¶æ³¨å…¥èµ„æº
  resourcePolicy:
    containerPolicies:
      - containerName: java-container
        minAllowed:
          cpu: 200m
          memory: 512Mi
        maxAllowed:
          cpu: 2
          memory: 4Gi
        controlledResources: ["cpu", "memory"]
```



**Pod åˆå§‹èµ„æºè®¾ç½®å»ºè®®**

| èµ„æºé¡¹                      | æ¨èå€¼                        | åŸå›                   |
| --------------------------- | ----------------------------- | --------------------- |
| `resources.requests.cpu`    | 300m~500m                     | JVM å¯åŠ¨éè½»é‡        |
| `resources.requests.memory` | 512Mi~1Gi                     | JVM å¯åŠ¨å †å†…å­˜è¾ƒå¤§    |
| `resources.limits`          | å¯ç•¥é«˜äº requests             | é¿å…é™åˆ¶ JVM æ‰©å®¹ç©ºé—´ |
| JVM å‚æ•°                    | `-Xms` å’Œ `-Xmx` ä¸å»ºè®®é…ç½®æ­» | è®© JVM è‡ªé€‚åº”å®¹å™¨é™åˆ¶ |



**è¿è¡ŒæœŸè§‚å¯Ÿ**

é…åˆ VPA ä½¿ç”¨æ¨èç»“åˆå¦‚ä¸‹å·¥å…·ï¼š

- ğŸ” **Prometheus**ï¼šé‡‡é›† JVM CPU/å†…å­˜èµ„æºä½¿ç”¨
- ğŸ“Š **Grafana**ï¼šå®æ—¶å±•ç¤ºå®¹å™¨èµ„æºè¶‹åŠ¿
- ğŸ”§ **jvm-exporter**ï¼šå¯¼å‡ºå †å†…å­˜ã€GC ç­‰ JVM å†…éƒ¨æŒ‡æ ‡



**åæœŸä¼˜åŒ–å»ºè®®**

| åœºæ™¯           | å»ºè®®                              |
| -------------- | --------------------------------- |
| æœåŠ¡è¿è¡Œç¨³å®š   | å¯ä»¥è€ƒè™‘å°† VPA åˆ‡æ¢ä¸º Auto æ¨¡å¼   |
| å¯åŠ¨å†…å­˜ä»ä¸å¤Ÿ | é€‚å½“æ‰‹åŠ¨æå‡ minAllowed memory    |
| é¢‘ç¹ OOMKilled | è°ƒé«˜ memory limit æˆ–é…ç½® JVM å‚æ•° |
| å¤šå‰¯æœ¬éƒ¨ç½²     | HPA + VPA è”åˆä½¿ç”¨ï¼Œä½†éœ€è§„é¿å†²çª  |



### å„ç±»æœåŠ¡ç›‘æ§

#### harbor

```bash
# åˆ›å»ºharbor-values.yamlï¼Œæš´éœ²Prometheus
[root@master1 harbor]#cat harbor-values.yaml 
expose:
  type: ingress
  tls:
    enabled: true
    certSource: auto
  ingress:
    className: "nginx"
    hosts:
      core: harbor.mystical.org
    annotations:
      nginx.ingress.kubernetes.io/ssl-redirect: "true"

externalURL: https://harbor.mystical.org

persistence:
  enabled: true
  resourcePolicy: "keep"
  persistentVolumeClaim:
    registry:
      storageClass: "openebs-hostpath"
      accessMode: ReadWriteOnce
      size: 5Gi
    jobservice:
      storageClass: "openebs-hostpath"
      accessMode: ReadWriteOnce
      size: 1Gi
    database:
      storageClass: "openebs-hostpath"
      accessMode: ReadWriteOnce
      size: 1Gi
    redis:
      storageClass: "openebs-hostpath"
      accessMode: ReadWriteOnce
      size: 1Gi
    trivy:
      storageClass: "openebs-hostpath"
      accessMode: ReadWriteOnce
      size: 5Gi

harborAdminPassword: "Zyf646130"

metrics:
  enabled: true
  core:
    path: /metrics
    port: 8001
  registry:
    path: /metrics
    port: 8001
  jobservice:
    path: /metrics
    port: 8001
  exporter:
    path: /metrics
    port: 8001

core:
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8001"
    prometheus.io/path: "/metrics"

jobservice:
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8001"
    prometheus.io/path: "/metrics"

registry:
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8001"
    prometheus.io/path: "/metrics"

exporter:
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8001"
    prometheus.io/path: "/metrics"
    
# ä½¿ç”¨helméƒ¨ç½²
[root@master1 harbor]#helm install myharbor harbor/harbor --namespace harbor -f harbor-values.yaml 
NAME: myharbor
LAST DEPLOYED: Mon Mar 31 18:20:50 2025
NAMESPACE: harbor
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
Please wait for several minutes for Harbor deployment to complete.
Then you should be able to visit the Harbor portal at https://harbor.mystical.org
For more details, please visit https://github.com/goharbor/harbor
```



#### Gitlab

```bash
# åˆ›å»ºsecretç”¨äºå­˜æ”¾é‚®ä»¶å¯†ç 
[root@master1 ~]# kubectl create secret generic smtp-password-secret --from-literal=password='<passwd>' -n gitlab

# ç”Ÿæˆgitlab-valuesæ¸…å•
[root@master1 ~]# helm show values gitlab/gitlab > gitlab-values.yaml

# ä¿®æ”¹æ¸…å•
[root@master1 ~]#cat gitlab/gitlab-values.yaml |grep -Pv "^\s*#"
......
  hosts:
    domain: gitlab.mystical.org        # æ·»åŠ åŸŸå
    hostSuffix:
    https: true
    externalIP:
    ssh:
    gitlab: {}
    minio: {}
    registry: {}
    tls:                                # è‡ªåŠ¨æˆ–æ‰‹åŠ¨ç­¾å‘çš„ TLS secret åç§°
      enabled: true
      secretName: gitlab-gitlab-tls
    smartcard: {}
    kas: {}
    pages: {}

  ingress:
    apiVersion: ""
    configureCertmanager: true
    useNewIngressForCerts: false
    provider: nginx                  # ä½¿ç”¨nginx
    annotations: {}
    enabled: true
    tls: {}
    path: /
    pathType: Prefix

  monitoring:
    enabled: true                   # å¯ç”¨ç›‘æ§
    
......
    sidekiq:
       routingRules: []
       livenessProbe:
         timeoutSeconds: 300
         initialDelaySeconds: 20
 
       readinessProbe:
         timeoutSeconds: 300
         periodSeconds: 5
......
  webservice:
     workerTimeout: 60
 
     livenessProbe:
        timeoutSeconds: 300
        initialDelaySeconds: 20
        periodSeconds: 10
        failureThreshold: 5
 
      readinessProbe:
        timeoutSeconds: 300
        periodSeconds: 5
        successThreshold: 1

......
  smtp:                             # é…ç½®é‚®ä»¶
    enabled: true
    address: smtp.163.com
    port: 465
    user_name: "15104600741@163.com"
    password:
      secret: smtp-password-secret
      key: password
    authentication: "login"
    starttls_auto: true
    openssl_verify_mode: "peer"
    open_timeout: 30
    read_timeout: 60
    pool: false

  email:
    from: "15104600741@163.com"
    display_name: GitLab
    reply_to: "15104600741@163.com"
    subject_suffix: ""
    smime:
      enabled: false
      secretName: ""
      keyName: "tls.key"
      certName: "tls.crt"

......

prometheus:
  install: false           # ä¸å®‰è£…Prometheus
  rbac:
    create: true
  alertmanager:
    enabled: false
  alertmanagerFiles:
    alertmanager.yml: {}
  kubeStateMetrics:
    enabled: false
  nodeExporter:
    enabled: false
  pushgateway:
    enabled: false
  server:
    retention: 15d
    strategy:
      type: Recreate
    image:
      tag: v2.38.0
    containerSecurityContext:
      runAsUser: 1000
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      capabilities:
        drop: [ "ALL" ]
      seccompProfile:
        type: "RuntimeDefault"
  
redis:
  install: true
  image:
    tag: "7.0.15-debian-12-r20"
  auth:
    existingSecret: gitlab-redis-secret
    existingSecretKey: redis-password
    usePasswordFiles: true
  architecture: standalone
  cluster:
    enabled: false
  metrics:
    enabled: true               # å¯ç”¨æŒ‡æ ‡ç›‘æ§

postgresql:
  install: true
  auth:
    password: bogus-satisfy-upgrade
    postgresPassword: bogus-satisfy-upgrade
    usePasswordFiles: false
    existingSecret: '{{ include "gitlab.psql.password.secret" . }}'
    secretKeys:
      adminPasswordKey: postgresql-postgres-password
      userPasswordKey: '{{ include "gitlab.psql.password.key" $ }}'
  image:
    tag: 14.8.0
  primary:
    initdb:
      scriptsConfigMap: '{{ include "gitlab.psql.initdbscripts" $}}'
    extraVolumeMounts:
      - name: custom-init-scripts
        mountPath: /docker-entrypoint-preinitdb.d/init_revision.sh
        subPath: init_revision.sh
    podAnnotations:
      postgresql.gitlab/init-revision: "1"
  metrics:
    enabled: true                                 # å¯ç”¨æŒ‡æ ‡ç›‘æ§
    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9187"
        gitlab.com/prometheus_scrape: "true"
        gitlab.com/prometheus_port: "9187"


gitlab-runner:
  install: false                   # ç”¨ä¸åˆ°ï¼Œåªè¦gitlabç‹¬ç«‹æ‰§è¡Œcicdæ‰ä¼šç”¨åˆ°
  rbac:
    create: true
......

# ä½¿ç”¨helméƒ¨ç½²gitlab
[root@master1 ~]# helm install gitlab gitlab/gitlab --namespace gitlab --create-namespace -f ./gitlab-values.yaml

# å°†gitlab-webservice-defaultå’Œgitlab-sidekiq-all-in-1-v2çš„probeè¿›è¡Œä¿®æ”¹ï¼Œåé‡å¯
[root@master1 ~]# kubectl edit deployments.apps -n gitlab gitlab-sidekiq-all-in-1-v2
......
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /-/liveness
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 300   # æ”¹ä¸º300sï¼Œä½¿å…¶æœåŠ¡å¯åŠ¨åå†æ¢æµ‹
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 5
......
        readinessProbe:
          failureThreshold: 2
          httpGet:
            path: /-/readiness
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 300   # æ·»åŠ æ­¤è¡Œï¼Œä½¿å…¶æœåŠ¡å¯åŠ¨åå†æ¢æµ‹
          periodSeconds: 300
          successThreshold: 1
          timeoutSeconds: 10
          
# é‡å¯åŠ è½½æ›´æ”¹åçš„é…ç½®
[root@master1 ~]# kubectl rollout restart -n gitlab deployment gitlab-sidekiq-all-in-1-v2

[root@master1 ~]# kubectl edit deployments.apps -n gitlab gitlab-webservice-default 
......
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /-/liveness
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 300   # æ·»åŠ æ­¤è¡Œï¼Œä½¿å…¶æœåŠ¡å¯åŠ¨åå†æ¢æµ‹
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 5
......
        readinessProbe:
          failureThreshold: 2
          httpGet:
            path: /-/readiness
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 300   # æ·»åŠ æ­¤è¡Œï¼Œä½¿å…¶æœåŠ¡å¯åŠ¨åå†æ¢æµ‹
          periodSeconds: 300
          successThreshold: 1
          timeoutSeconds: 10
......

[root@master1 ~]# kubectl rollout restart -n gitlab deployment gitlab-webservice-default

# æœ€åæŸ¥çœ‹gitlabçš„èµ„æº
[root@master1 ~]#kubectl get all -n gitlab 
NAME                                                   READY   STATUS      RESTARTS      AGE
pod/gitlab-certmanager-cainjector-5b94bb559d-zv8fv     1/1     Running     0             97m
pod/gitlab-certmanager-cc885cb67-8tzfs                 1/1     Running     0             97m
pod/gitlab-certmanager-webhook-6c455f9fd-fzwh7         1/1     Running     0             97m
pod/gitlab-gitaly-0                                    1/1     Running     0             97m
pod/gitlab-gitlab-exporter-596cf46c54-rp64m            1/1     Running     0             97m
pod/gitlab-gitlab-shell-5d57f57c75-7z4ln               1/1     Running     0             96m
pod/gitlab-gitlab-shell-5d57f57c75-splnn               1/1     Running     0             97m
pod/gitlab-kas-68c8956f7f-5nsgr                        1/1     Running     2 (96m ago)   96m
pod/gitlab-kas-68c8956f7f-s6ll9                        1/1     Running     2 (96m ago)   97m
pod/gitlab-migrations-f35ac4f-ljbnx                    0/1     Completed   0             97m
pod/gitlab-minio-7bfcd7d6d8-5vxxz                      1/1     Running     0             97m
pod/gitlab-minio-create-buckets-4123c12-gtchx          0/1     Completed   0             97m
pod/gitlab-nginx-ingress-controller-7d9d8848c8-tmtrs   1/1     Running     0             97m
pod/gitlab-nginx-ingress-controller-7d9d8848c8-wzwfn   1/1     Running     0             97m
pod/gitlab-postgresql-0                                2/2     Running     0             97m
pod/gitlab-redis-master-0                              2/2     Running     0             97m
pod/gitlab-registry-bd6b97679-kps52                    1/1     Running     2 (96m ago)   96m
pod/gitlab-registry-bd6b97679-kvsgl                    1/1     Running     1 (96m ago)   97m
pod/gitlab-sidekiq-all-in-1-v2-7658ffbd85-5q8rm        1/1     Running     3 (65m ago)   72m
pod/gitlab-toolbox-df86f6f45-pwdnq                     1/1     Running     0             97m
pod/gitlab-webservice-default-5cbd9f9b45-9vwf2         2/2     Running     0             68m
pod/gitlab-webservice-default-5cbd9f9b45-m9xjt         2/2     Running     0             75m

NAME                                              TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                   AGE
service/gitlab-certmanager                        ClusterIP      10.101.32.235    <none>        9402/TCP                                  97m
service/gitlab-certmanager-webhook                ClusterIP      10.107.215.140   <none>        443/TCP                                   97m
service/gitlab-gitaly                             ClusterIP      None             <none>        8075/TCP,9236/TCP                         97m
service/gitlab-gitlab-exporter                    ClusterIP      10.106.244.139   <none>        9168/TCP                                  97m
service/gitlab-gitlab-shell                       ClusterIP      10.101.30.26     <none>        22/TCP                                    97m
service/gitlab-kas                                ClusterIP      10.108.54.136    <none>        8150/TCP,8153/TCP,8154/TCP,8151/TCP       97m
service/gitlab-minio-svc                          ClusterIP      10.104.163.204   <none>        9000/TCP                                  97m
service/gitlab-nginx-ingress-controller           LoadBalancer   10.103.231.66    10.0.0.12     80:31911/TCP,443:31577/TCP,22:30732/TCP   97m
service/gitlab-nginx-ingress-controller-metrics   ClusterIP      10.101.98.218    <none>        10254/TCP                                 97m
service/gitlab-postgresql                         ClusterIP      10.111.148.49    <none>        5432/TCP                                  97m
service/gitlab-postgresql-hl                      ClusterIP      None             <none>        5432/TCP                                  97m
service/gitlab-postgresql-metrics                 ClusterIP      10.105.53.96     <none>        9187/TCP                                  97m
service/gitlab-redis-headless                     ClusterIP      None             <none>        6379/TCP                                  97m
service/gitlab-redis-master                       ClusterIP      10.97.60.154     <none>        6379/TCP                                  97m
service/gitlab-redis-metrics                      ClusterIP      10.107.109.193   <none>        9121/TCP                                  97m
service/gitlab-registry                           ClusterIP      10.108.14.20     <none>        5000/TCP                                  97m
service/gitlab-webservice-default                 ClusterIP      10.110.52.164    <none>        8080/TCP,8181/TCP,8083/TCP                97m

NAME                                              READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/gitlab-certmanager                1/1     1            1           97m
deployment.apps/gitlab-certmanager-cainjector     1/1     1            1           97m
deployment.apps/gitlab-certmanager-webhook        1/1     1            1           97m
deployment.apps/gitlab-gitlab-exporter            1/1     1            1           97m
deployment.apps/gitlab-gitlab-shell               2/2     2            2           97m
deployment.apps/gitlab-kas                        2/2     2            2           97m
deployment.apps/gitlab-minio                      1/1     1            1           97m
deployment.apps/gitlab-nginx-ingress-controller   2/2     2            2           97m
deployment.apps/gitlab-registry                   2/2     2            2           97m
deployment.apps/gitlab-sidekiq-all-in-1-v2        1/1     1            1           97m
deployment.apps/gitlab-toolbox                    1/1     1            1           97m
deployment.apps/gitlab-webservice-default         2/2     2            2           97m

NAME                                                         DESIRED   CURRENT   READY   AGE
replicaset.apps/gitlab-certmanager-cainjector-5b94bb559d     1         1         1       97m
replicaset.apps/gitlab-certmanager-cc885cb67                 1         1         1       97m
replicaset.apps/gitlab-certmanager-webhook-6c455f9fd         1         1         1       97m
replicaset.apps/gitlab-gitlab-exporter-596cf46c54            1         1         1       97m
replicaset.apps/gitlab-gitlab-shell-5d57f57c75               2         2         2       97m
replicaset.apps/gitlab-kas-68c8956f7f                        2         2         2       97m
replicaset.apps/gitlab-minio-7bfcd7d6d8                      1         1         1       97m
replicaset.apps/gitlab-nginx-ingress-controller-7d9d8848c8   2         2         2       97m
replicaset.apps/gitlab-registry-bd6b97679                    2         2         2       97m
replicaset.apps/gitlab-sidekiq-all-in-1-v2-686d999f5c        0         0         0       97m
replicaset.apps/gitlab-sidekiq-all-in-1-v2-7658ffbd85        1         1         1       72m
replicaset.apps/gitlab-sidekiq-all-in-1-v2-79bd6cbbb5        0         0         0       84m
replicaset.apps/gitlab-sidekiq-all-in-1-v2-7cb69cb5d         0         0         0       84m
replicaset.apps/gitlab-sidekiq-all-in-1-v2-88696485c         0         0         0       72m
replicaset.apps/gitlab-sidekiq-all-in-1-v2-c5cc986db         0         0         0       72m
replicaset.apps/gitlab-toolbox-df86f6f45                     1         1         1       97m
replicaset.apps/gitlab-webservice-default-5cbd9f9b45         2         2         2       75m
replicaset.apps/gitlab-webservice-default-6b5cd877b5         0         0         0       97m
replicaset.apps/gitlab-webservice-default-6b9976799c         0         0         0       79m
replicaset.apps/gitlab-webservice-default-6cf64577cf         0         0         0       83m
replicaset.apps/gitlab-webservice-default-7558674d           0         0         0       79m
replicaset.apps/gitlab-webservice-default-89df84c7d          0         0         0       83m
replicaset.apps/gitlab-webservice-default-bdbddc85d          0         0         0       75m

NAME                                   READY   AGE
statefulset.apps/gitlab-gitaly         1/1     97m
statefulset.apps/gitlab-postgresql     1/1     97m
statefulset.apps/gitlab-redis-master   1/1     97m

NAME                                                             REFERENCE                               TARGETS               MINPODS   MAXPODS   REPLICAS   AGE
horizontalpodautoscaler.autoscaling/gitlab-gitlab-shell          Deployment/gitlab-gitlab-shell          cpu: <unknown>/100m   2         10        2          97m
horizontalpodautoscaler.autoscaling/gitlab-kas                   Deployment/gitlab-kas                   cpu: <unknown>/100m   2         10        2          97m
horizontalpodautoscaler.autoscaling/gitlab-registry              Deployment/gitlab-registry              cpu: <unknown>/75%    2         10        2          97m
horizontalpodautoscaler.autoscaling/gitlab-sidekiq-all-in-1-v2   Deployment/gitlab-sidekiq-all-in-1-v2   cpu: <unknown>/350m   1         10        1          97m
horizontalpodautoscaler.autoscaling/gitlab-webservice-default    Deployment/gitlab-webservice-default    cpu: <unknown>/1      2         10        2          97m

NAME                                            STATUS     COMPLETIONS   DURATION   AGE
job.batch/gitlab-migrations-f35ac4f             Complete   1/1           7m20s      97m
job.batch/gitlab-minio-create-buckets-4123c12   Complete   1/1           83s        97m
```



## Kubernetesè°ƒåº¦æ¡†æ¶

### Kubernetesçš„èµ„æºæ¨¡å‹ä¸èµ„æºç®¡ç†

#### Kubernetesçš„èµ„æºæ¨¡å‹

åœ¨ Kubernetes é‡Œï¼ŒPod æ˜¯æœ€å°çš„åŸå­è°ƒåº¦å•ä½ã€‚è¿™ä¹Ÿå°±æ„å‘³ç€ï¼Œæ‰€æœ‰è·Ÿè°ƒåº¦å’Œèµ„æºç®¡ç†ç›¸å…³çš„å±æ€§éƒ½åº”è¯¥æ˜¯å±äº **Pod å¯¹è±¡çš„å­—æ®µ**ï¼Œè€Œè¿™å…¶ä¸­æœ€é‡è¦çš„éƒ¨åˆ†ï¼Œå°±æ˜¯ Pod çš„ **CPU** å’Œ**å†…å­˜**é…ç½®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: frontend
spec:
  containers:
  - name: db
    image: mysql
    env:
    - name: MYSQL_ROOT_PASSWORD
      value: "password"
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
  - name: wp
    image: wordpress
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
```

åœ¨ Kubernetes ä¸­ï¼Œåƒ CPU è¿™æ ·çš„èµ„æºè¢«ç§°ä½œ**â€œå¯å‹ç¼©èµ„æºâ€ï¼ˆcompressible resourcesï¼‰**ã€‚å®ƒçš„å…¸å‹ç‰¹ç‚¹æ˜¯ï¼Œå½“å¯å‹ç¼©èµ„æºä¸è¶³æ—¶ï¼ŒPod åªä¼šâ€œé¥¥é¥¿â€ï¼Œä½†ä¸ä¼šé€€å‡ºã€‚

è€Œåƒå†…å­˜è¿™æ ·çš„èµ„æºï¼Œåˆ™è¢«ç§°ä½œâ€œ**ä¸å¯å‹ç¼©èµ„æºï¼ˆincompressible resourcesï¼‰**ã€‚å½“ä¸å¯å‹ç¼©èµ„æºä¸è¶³æ—¶ï¼ŒPod å°±ä¼šå› ä¸º OOMï¼ˆOut-Of-Memoryï¼‰è¢«å†…æ ¸æ€æ‰ã€‚

ç”±äº Pod å¯ä»¥ç”±å¤šä¸ª Container ç»„æˆï¼Œæ‰€ä»¥ CPU å’Œå†…å­˜èµ„æºçš„é™é¢ï¼Œæ˜¯è¦é…ç½®åœ¨æ¯ä¸ª Container çš„å®šä¹‰ä¸Šçš„ã€‚è¿™æ ·ï¼ŒPod æ•´ä½“çš„èµ„æºé…ç½®ï¼Œå°±ç”±è¿™äº› Container çš„é…ç½®å€¼ç´¯åŠ å¾—åˆ°ã€‚



##### CPUçš„è¡¨ç¤ºæ–¹æ³•

Kubernetes é‡Œä¸º CPU è®¾ç½®çš„å•ä½æ˜¯â€œCPU çš„ä¸ªæ•°â€ã€‚æ¯”å¦‚ï¼Œcpu=1 æŒ‡çš„å°±æ˜¯ï¼Œè¿™ä¸ª Pod çš„ CPU é™é¢æ˜¯ 1 ä¸ª CPUã€‚å½“ç„¶ï¼Œå…·ä½“â€œ1 ä¸ª CPUâ€åœ¨å®¿ä¸»æœºä¸Šå¦‚ä½•è§£é‡Šï¼Œæ˜¯ 1 ä¸ª CPU æ ¸å¿ƒï¼Œè¿˜æ˜¯ 1 ä¸ª vCPUï¼Œè¿˜æ˜¯ 1 ä¸ª CPU çš„è¶…çº¿ç¨‹ï¼ˆHyperthreadï¼‰ï¼Œå®Œå…¨å–å†³äºå®¿ä¸»æœºçš„ CPU å®ç°æ–¹å¼ã€‚Kubernetes åªè´Ÿè´£ä¿è¯ Pod èƒ½å¤Ÿä½¿ç”¨åˆ°â€œ1 ä¸ª CPUâ€çš„è®¡ç®—èƒ½åŠ›ã€‚

Kubernetes å…è®¸ä½ å°† CPU é™é¢è®¾ç½®ä¸ºåˆ†æ•°ï¼Œæ¯”å¦‚åœ¨æˆ‘ä»¬çš„ä¾‹å­é‡Œï¼Œ**CPU limits çš„å€¼å°±æ˜¯ 500m**ã€‚æ‰€è°“ 500mï¼ŒæŒ‡çš„å°±æ˜¯ 500 millicpuï¼Œä¹Ÿå°±æ˜¯ 0.5 ä¸ª CPU çš„æ„æ€ã€‚è¿™æ ·ï¼Œè¿™ä¸ª Pod å°±ä¼šè¢«åˆ†é…åˆ° 1 ä¸ª CPU ä¸€åŠçš„è®¡ç®—èƒ½åŠ›ã€‚

```ABAP
å¯ä»¥ç›´æ¥æŠŠè¿™ä¸ªé…ç½®å†™æˆ cpu=0.5ã€‚ä½†åœ¨å®é™…ä½¿ç”¨æ—¶ï¼Œæ¨èä½¿ç”¨ 500m çš„å†™æ³•ï¼Œæ¯•ç«Ÿè¿™æ‰æ˜¯ Kubernetes å†…éƒ¨é€šç”¨çš„ CPU è¡¨ç¤ºæ–¹å¼ã€‚
```



##### å†…å­˜çš„è¡¨ç¤ºæ–¹æ³•

å¯¹äºå†…å­˜èµ„æºæ¥è¯´ï¼Œå®ƒçš„å•ä½è‡ªç„¶å°±æ˜¯ bytesã€‚Kubernetes æ”¯æŒä½ ä½¿ç”¨ Eiã€Piã€Tiã€Giã€Miã€Kiï¼ˆæˆ–è€… Eã€Pã€Tã€Gã€Mã€Kï¼‰çš„æ–¹å¼æ¥ä½œä¸º bytes çš„å€¼ã€‚æ¯”å¦‚ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­é‡Œï¼ŒMemory requests çš„å€¼å°±æ˜¯ 64MiB (2 çš„ 26 æ¬¡æ–¹ bytes) ã€‚è¿™é‡Œè¦æ³¨æ„åŒºåˆ† **MiBï¼ˆmebibyteï¼‰**å’Œ **MBï¼ˆmegabyteï¼‰**çš„åŒºåˆ«ã€‚

```ABAP
å¤‡æ³¨ï¼š1Mi=1024*1024ï¼›1M=1000*1000
```



##### Limits å’Œ Requests

Kubernetes é‡Œ Pod çš„ CPU å’Œå†…å­˜èµ„æºï¼Œå®é™…ä¸Šè¿˜è¦åˆ†ä¸º limits å’Œ requests ä¸¤ç§æƒ…å†µï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```css
spec.containers[].resources.limits.cpu
spec.containers[].resources.limits.memory
spec.containers[].resources.requests.cpu
spec.containers[].resources.requests.memory
```

- åœ¨è°ƒåº¦çš„æ—¶å€™ï¼Œkube-scheduler åªä¼šæŒ‰ç…§ requests çš„å€¼è¿›è¡Œè®¡ç®—ã€‚
- åœ¨çœŸæ­£è®¾ç½® Cgroups é™åˆ¶çš„æ—¶å€™ï¼Œkubelet åˆ™ä¼šæŒ‰ç…§ limits çš„å€¼æ¥è¿›è¡Œè®¾ç½®ã€‚



**Kubernetes è¿™ç§å¯¹ CPU å’Œå†…å­˜èµ„æºé™é¢çš„è®¾è®¡ï¼Œå®é™…ä¸Šå‚è€ƒäº† Borg è®ºæ–‡ä¸­å¯¹â€œåŠ¨æ€èµ„æºè¾¹ç•Œâ€çš„å®šä¹‰**ï¼Œæ—¢ï¼šå®¹å™¨åŒ–ä½œä¸šåœ¨æäº¤æ—¶æ‰€è®¾ç½®çš„èµ„æºè¾¹ç•Œï¼Œå¹¶ä¸ä¸€å®šæ˜¯è°ƒåº¦ç³»ç»Ÿæ‰€å¿…é¡»ä¸¥æ ¼éµå®ˆçš„ï¼Œè¿™æ˜¯å› ä¸ºåœ¨å®é™…åœºæ™¯ä¸­ï¼Œå¤§å¤šæ•°ä½œä¸šä½¿ç”¨åˆ°çš„èµ„æºå…¶å®è¿œå°äºå®ƒæ‰€è¯·æ±‚çš„èµ„æºé™é¢ã€‚

åŸºäºè¿™ç§å‡è®¾ï¼ŒBorg åœ¨ä½œä¸šè¢«æäº¤åï¼Œä¼šä¸»åŠ¨å‡å°å®ƒçš„èµ„æºé™é¢é…ç½®ï¼Œä»¥ä¾¿å®¹çº³æ›´å¤šçš„ä½œä¸šã€æå‡èµ„æºåˆ©ç”¨ç‡ã€‚è€Œå½“ä½œä¸šèµ„æºä½¿ç”¨é‡å¢åŠ åˆ°ä¸€å®šé˜ˆå€¼æ—¶ï¼ŒBorg ä¼šé€šè¿‡â€œå¿«é€Ÿæ¢å¤â€è¿‡ç¨‹ï¼Œè¿˜åŸä½œä¸šåŸå§‹çš„èµ„æºé™é¢ï¼Œé˜²æ­¢å‡ºç°å¼‚å¸¸æƒ…å†µã€‚

è€Œ Kubernetes çš„ requests+limits çš„åšæ³•ï¼Œå…¶å®å°±æ˜¯ä¸Šè¿°æ€è·¯çš„ä¸€ä¸ªç®€åŒ–ç‰ˆï¼š**ç”¨æˆ·åœ¨æäº¤ Pod æ—¶ï¼Œå¯ä»¥å£°æ˜ä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„ requests å€¼ä¾›è°ƒåº¦å™¨ä½¿ç”¨ï¼Œè€Œ Kubernetes çœŸæ­£è®¾ç½®ç»™å®¹å™¨ Cgroups çš„ï¼Œåˆ™æ˜¯ç›¸å¯¹è¾ƒå¤§çš„ limits å€¼**ã€‚ä¸éš¾çœ‹åˆ°ï¼Œè¿™è·Ÿ Borg çš„æ€è·¯ç›¸é€šçš„ã€‚





#### Kubernetes çš„ QoS æ¨¡å‹

åœ¨ Kubernetes ä¸­ï¼Œä¸åŒçš„ requests å’Œ limits çš„è®¾ç½®æ–¹å¼ï¼Œå…¶å®ä¼šå°†è¿™ä¸ª Pod åˆ’åˆ†åˆ°ä¸åŒçš„ QoS çº§åˆ«å½“ä¸­ã€‚



##### Guaranteedçº§åˆ«

**å½“ Pod é‡Œçš„æ¯ä¸€ä¸ª Container éƒ½åŒæ—¶è®¾ç½®äº† requests å’Œ limitsï¼Œå¹¶ä¸” requests å’Œ limits å€¼ç›¸ç­‰çš„æ—¶å€™ï¼Œè¿™ä¸ª Pod å°±å±äº Guaranteed ç±»åˆ«**ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: qos-demo
  namespace: qos-example
spec:
  containers:
  - name: qos-demo-ctr
    image: nginx
    resources:
      limits:
        memory: "200Mi"
        cpu: "700m"
      requests:
        memory: "200Mi"
        cpu: "700m"
```

å½“è¿™ä¸ª Pod åˆ›å»ºä¹‹åï¼Œå®ƒçš„ qosClass å­—æ®µå°±ä¼šè¢« Kubernetes è‡ªåŠ¨è®¾ç½®ä¸º Guaranteedã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ**å½“ Pod ä»…è®¾ç½®äº† limits æ²¡æœ‰è®¾ç½® requests çš„æ—¶å€™ï¼ŒKubernetes ä¼šè‡ªåŠ¨ä¸ºå®ƒè®¾ç½®ä¸ limits ç›¸åŒçš„ requests å€¼ï¼Œæ‰€ä»¥ï¼Œè¿™ä¹Ÿå±äº Guaranteed æƒ…å†µ**ã€‚



##### Burstableç±»åˆ«

å½“ Pod ä¸æ»¡è¶³ Guaranteed çš„æ¡ä»¶ï¼Œä½†è‡³å°‘æœ‰ä¸€ä¸ª Container è®¾ç½®äº† requestsã€‚é‚£ä¹ˆè¿™ä¸ª Pod å°±ä¼šè¢«åˆ’åˆ†åˆ° Burstable ç±»åˆ«ã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: qos-demo-2
  namespace: qos-example
spec:
  containers:
  - name: qos-demo-2-ctr
    image: nginx
    resources:
      limits
        memory: "200Mi"
      requests:
        memory: "100Mi"
```



**BestEffort**

**å¦‚æœä¸€ä¸ª Pod æ—¢æ²¡æœ‰è®¾ç½® requestsï¼Œä¹Ÿæ²¡æœ‰è®¾ç½® limitsï¼Œé‚£ä¹ˆå®ƒçš„ QoS ç±»åˆ«å°±æ˜¯ BestEffortã€‚**æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: qos-demo-3
  namespace: qos-example
spec:
  containers:
  - name: qos-demo-3-ctr
    image: nginx
```



**QoS åˆ’åˆ†çš„ä¸»è¦åº”ç”¨åœºæ™¯ï¼Œæ˜¯å½“å®¿ä¸»æœºèµ„æºç´§å¼ çš„æ—¶å€™ï¼Œkubelet å¯¹ Pod è¿›è¡Œ Evictionï¼ˆå³èµ„æºå›æ”¶ï¼‰æ—¶éœ€è¦ç”¨åˆ°çš„**

å…·ä½“åœ°è¯´ï¼Œå½“ Kubernetes æ‰€ç®¡ç†çš„å®¿ä¸»æœºä¸Šä¸å¯å‹ç¼©èµ„æºçŸ­ç¼ºæ—¶ï¼Œå°±æœ‰å¯èƒ½è§¦å‘ Evictionã€‚æ¯”å¦‚ï¼Œå¯ç”¨å†…å­˜ï¼ˆmemory.availableï¼‰ã€å¯ç”¨çš„å®¿ä¸»æœºç£ç›˜ç©ºé—´ï¼ˆnodefs.availableï¼‰ï¼Œä»¥åŠå®¹å™¨è¿è¡Œæ—¶é•œåƒå­˜å‚¨ç©ºé—´ï¼ˆimagefs.availableï¼‰ç­‰ç­‰ã€‚

ç›®å‰ï¼ŒKubernetes ä¸ºä½ è®¾ç½®çš„ Eviction çš„é»˜è®¤é˜ˆå€¼å¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
memory.available<100Mi
nodefs.available<10%
nodefs.inodesFree<5%
imagefs.available<15%
```

å½“ç„¶ï¼Œä¸Šè¿°å„ä¸ªè§¦å‘æ¡ä»¶åœ¨ kubelet é‡Œéƒ½æ˜¯å¯é…ç½®çš„ã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼š

```bash
kubelet \
--eviction-hard=imagefs.available<10%,memory.available<500Mi,nodefs.available<5%,nodefs.inodesFree<5% \
--eviction-soft=imagefs.available<30%,nodefs.available<10% \
--eviction-soft-grace-period=imagefs.available=2m,nodefs.available=2m \
--eviction-max-pod-grace-period=600
```

åœ¨è¿™ä¸ªé…ç½®ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ° Eviction åœ¨ Kubernetes é‡Œå…¶å®åˆ†ä¸º **Soft å’Œ Hard ä¸¤ç§æ¨¡å¼**ã€‚

**Soft Eviction** å…è®¸ä½ ä¸º Eviction è¿‡ç¨‹è®¾ç½®ä¸€æ®µâ€œä¼˜é›…æ—¶é—´â€ï¼Œæ¯”å¦‚ä¸Šé¢ä¾‹å­é‡Œçš„ imagefs.available=2mï¼Œå°±æ„å‘³ç€å½“ imagefs ä¸è¶³çš„é˜ˆå€¼è¾¾åˆ° 2 åˆ†é’Ÿä¹‹åï¼Œkubelet æ‰ä¼šå¼€å§‹ Eviction çš„è¿‡ç¨‹ã€‚

**Hard Eviction** æ¨¡å¼ä¸‹ï¼ŒEviction è¿‡ç¨‹å°±ä¼šåœ¨é˜ˆå€¼è¾¾åˆ°ä¹‹åç«‹åˆ»å¼€å§‹ã€‚

```ABAP
Kubernetes è®¡ç®— Eviction é˜ˆå€¼çš„æ•°æ®æ¥æºï¼Œä¸»è¦ä¾èµ–äºä» Cgroups è¯»å–åˆ°çš„å€¼ï¼Œä»¥åŠä½¿ç”¨ cAdvisor ç›‘æ§åˆ°çš„æ•°æ®
```

å½“å®¿ä¸»æœºçš„ Eviction é˜ˆå€¼è¾¾åˆ°åï¼Œå°±ä¼šè¿›å…¥ MemoryPressure æˆ–è€… DiskPressure çŠ¶æ€ï¼Œä»è€Œé¿å…æ–°çš„ Pod è¢«è°ƒåº¦åˆ°è¿™å°å®¿ä¸»æœºä¸Šã€‚



##### Evictionå‘ç”Ÿæ—¶kubeleåˆ é™¤Podçš„æ–¹å¼

å‚è€ƒè¿™äº› Pod çš„ QoS ç±»åˆ«äº†

- é¦–å½“å…¶å†²çš„ï¼Œè‡ªç„¶æ˜¯ **BestEffort** ç±»åˆ«çš„ Pod
- å…¶æ¬¡ï¼Œæ˜¯å±äº **Burstable** ç±»åˆ«ã€å¹¶ä¸”å‘ç”Ÿâ€œé¥¥é¥¿â€çš„èµ„æºä½¿ç”¨é‡å·²ç»è¶…å‡ºäº† requests çš„ Podã€‚
- æœ€åï¼Œæ‰æ˜¯ **Guaranteed** ç±»åˆ«ã€‚å¹¶ä¸”ï¼ŒKubernetes ä¼šä¿è¯åªæœ‰å½“ Guaranteed ç±»åˆ«çš„ Pod çš„èµ„æºä½¿ç”¨é‡è¶…è¿‡äº†å…¶ limits çš„é™åˆ¶ï¼Œæˆ–è€…å®¿ä¸»æœºæœ¬èº«æ­£å¤„äº Memory Pressure çŠ¶æ€æ—¶ï¼ŒGuaranteed çš„ Pod æ‰å¯èƒ½è¢«é€‰ä¸­è¿›è¡Œ Eviction æ“ä½œã€‚

å¯¹äºåŒ QoS ç±»åˆ«çš„ Pod æ¥è¯´ï¼ŒKubernetes è¿˜ä¼šæ ¹æ® **Pod çš„ä¼˜å…ˆçº§**æ¥è¿›è¡Œè¿›ä¸€æ­¥åœ°æ’åºå’Œé€‰æ‹©ã€‚



##### cpusetè®¾ç½®

åœ¨ä½¿ç”¨å®¹å™¨çš„æ—¶å€™ï¼Œä½ å¯ä»¥é€šè¿‡è®¾ç½® cpuset æŠŠå®¹å™¨ç»‘å®šåˆ°æŸä¸ª CPU çš„æ ¸ä¸Šï¼Œè€Œä¸æ˜¯åƒ cpushare é‚£æ ·å…±äº« CPU çš„è®¡ç®—èƒ½åŠ›ã€‚

è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äºæ“ä½œç³»ç»Ÿåœ¨ CPU ä¹‹é—´è¿›è¡Œä¸Šä¸‹æ–‡åˆ‡æ¢çš„æ¬¡æ•°å¤§å¤§å‡å°‘ï¼Œå®¹å™¨é‡Œåº”ç”¨çš„æ€§èƒ½ä¼šå¾—åˆ°å¤§å¹…æå‡ã€‚äº‹å®ä¸Šï¼Œ**cpuset æ–¹å¼ï¼Œæ˜¯ç”Ÿäº§ç¯å¢ƒé‡Œéƒ¨ç½²åœ¨çº¿åº”ç”¨ç±»å‹çš„ Pod æ—¶ï¼Œéå¸¸å¸¸ç”¨çš„ä¸€ç§æ–¹å¼**

**Kubernetesä¸­çš„å®ç°æ–¹å¼**

- é¦–å…ˆï¼Œä½ çš„ Pod å¿…é¡»æ˜¯ Guaranteed çš„ QoS ç±»å‹ï¼›
- ç„¶åï¼Œä½ åªéœ€è¦å°† Pod çš„ CPU èµ„æºçš„ requests å’Œ limits è®¾ç½®ä¸ºåŒä¸€ä¸ªç›¸ç­‰çš„æ•´æ•°å€¼å³å¯ã€‚

æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­

```yaml
spec:
  containers:
  - name: nginx
    image: nginx
    resources:
      limits:
        memory: "200Mi"
        cpu: "2"
      requests:
        memory: "200Mi"
        cpu: "2"
```

è¿™æ—¶å€™ï¼Œè¯¥ Pod å°±ä¼šè¢«ç»‘å®šåœ¨ 2 ä¸ªç‹¬å çš„ CPU æ ¸ä¸Šã€‚å½“ç„¶ï¼Œå…·ä½“æ˜¯å“ªä¸¤ä¸ª CPU æ ¸ï¼Œæ˜¯ç”± kubelet ä¸ºä½ åˆ†é…çš„

```ABAP
çƒˆå»ºè®®ä½ å°† DaemonSet çš„ Pod éƒ½è®¾ç½®ä¸º Guaranteed çš„ QoS ç±»å‹ã€‚å¦åˆ™ï¼Œä¸€æ—¦ DaemonSet çš„ Pod è¢«å›æ”¶ï¼Œå®ƒåˆä¼šç«‹å³åœ¨åŸå®¿ä¸»æœºä¸Šè¢«é‡å»ºå‡ºæ¥ï¼Œè¿™å°±ä½¿å¾—å‰é¢èµ„æºå›æ”¶çš„åŠ¨ä½œï¼Œå®Œå…¨æ²¡æœ‰æ„ä¹‰äº†ã€‚
```





### Kubernetesé»˜è®¤è°ƒåº¦å™¨

#### Kubernetes çš„é»˜è®¤è°ƒåº¦å™¨ï¼ˆdefault schedulerï¼‰

åœ¨ Kubernetes é¡¹ç›®ä¸­ï¼Œ**é»˜è®¤è°ƒåº¦å™¨**çš„ä¸»è¦èŒè´£ï¼Œå°±æ˜¯**ä¸ºä¸€ä¸ªæ–°åˆ›å»ºå‡ºæ¥çš„ Podï¼Œå¯»æ‰¾ä¸€ä¸ªæœ€åˆé€‚çš„èŠ‚ç‚¹ï¼ˆNodeï¼‰**ã€‚

è¿™é‡Œâ€œ**æœ€åˆé€‚**â€çš„å«ä¹‰ï¼ŒåŒ…æ‹¬ä¸¤å±‚ï¼š

- ä»é›†ç¾¤æ‰€æœ‰çš„èŠ‚ç‚¹ä¸­ï¼Œæ ¹æ®è°ƒåº¦ç®—æ³•æŒ‘é€‰å‡ºæ‰€æœ‰å¯ä»¥è¿è¡Œè¯¥ Pod çš„èŠ‚ç‚¹
- ä»ç¬¬ä¸€æ­¥çš„ç»“æœä¸­ï¼Œå†æ ¹æ®è°ƒåº¦ç®—æ³•æŒ‘é€‰ä¸€ä¸ªæœ€ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹ä½œä¸ºæœ€ç»ˆç»“æœ

æ‰€ä»¥åœ¨å…·ä½“çš„è°ƒåº¦æµç¨‹ä¸­ï¼Œé»˜è®¤è°ƒåº¦å™¨ä¼š**é¦–å…ˆè°ƒç”¨ä¸€ç»„å«ä½œ Predicate çš„è°ƒåº¦ç®—æ³•**ï¼Œæ¥æ£€æŸ¥æ¯ä¸ª Nodeã€‚ç„¶åï¼Œ**å†è°ƒç”¨ä¸€ç»„å«ä½œ Priority çš„è°ƒåº¦ç®—æ³•**ï¼Œæ¥ç»™ä¸Šä¸€æ­¥å¾—åˆ°çš„ç»“æœé‡Œçš„æ¯ä¸ª Node æ‰“åˆ†ã€‚æœ€ç»ˆçš„è°ƒåº¦ç»“æœï¼Œå°±æ˜¯å¾—åˆ†æœ€é«˜çš„é‚£ä¸ª Nodeã€‚

```ABAP
è°ƒåº¦å™¨å¯¹ä¸€ä¸ª Pod è°ƒåº¦æˆåŠŸï¼Œå®é™…ä¸Šå°±æ˜¯å°†å®ƒçš„ spec.nodeName å­—æ®µå¡«ä¸Šè°ƒåº¦ç»“æœçš„èŠ‚ç‚¹åå­—ã€‚
```



åœ¨ Kubernetes ä¸­ï¼Œä¸Šè¿°è°ƒåº¦æœºåˆ¶çš„å·¥ä½œåŸç†ï¼Œå¯ä»¥ç”¨å¦‚ä¸‹æ‰€ç¤ºçš„ä¸€å¹…ç¤ºæ„å›¾æ¥è¡¨ç¤º

![image-20250401213029168](../markdown_img/image-20250401213029168.png)

å¯ä»¥çœ‹åˆ°ï¼ŒKubernetes çš„è°ƒåº¦å™¨çš„æ ¸å¿ƒï¼Œå®é™…ä¸Šå°±æ˜¯**ä¸¤ä¸ªç›¸äº’ç‹¬ç«‹çš„æ§åˆ¶å¾ªç¯**ã€‚

**ç¬¬ä¸€ä¸ªæ§åˆ¶å¾ªç¯ï¼Œæˆ‘ä»¬å¯ä»¥ç§°ä¹‹ä¸º Informer Path**ã€‚å®ƒçš„ä¸»è¦ç›®çš„ï¼Œæ˜¯å¯åŠ¨ä¸€ç³»åˆ— Informerï¼Œç”¨æ¥ç›‘å¬ï¼ˆWatchï¼‰Etcd ä¸­ Podã€Nodeã€Service ç­‰ä¸è°ƒåº¦ç›¸å…³çš„ API å¯¹è±¡çš„å˜åŒ–ã€‚æ¯”å¦‚ï¼Œå½“ä¸€ä¸ªå¾…è°ƒåº¦ Podï¼ˆå³ï¼šå®ƒçš„ nodeName å­—æ®µæ˜¯ç©ºçš„ï¼‰è¢«åˆ›å»ºå‡ºæ¥ä¹‹åï¼Œè°ƒåº¦å™¨å°±ä¼šé€šè¿‡ Pod Informer çš„ Handlerï¼Œå°†è¿™ä¸ªå¾…è°ƒåº¦ Pod æ·»åŠ è¿›è°ƒåº¦é˜Ÿåˆ—ã€‚

åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼ŒKubernetes çš„è°ƒåº¦é˜Ÿåˆ—æ˜¯ä¸€ä¸ª **PriorityQueueï¼ˆä¼˜å…ˆçº§é˜Ÿåˆ—ï¼‰**ï¼Œå¹¶ä¸”å½“æŸäº›é›†ç¾¤ä¿¡æ¯å‘ç”Ÿå˜åŒ–çš„æ—¶å€™ï¼Œè°ƒåº¦å™¨è¿˜ä¼šå¯¹è°ƒåº¦é˜Ÿåˆ—é‡Œçš„å†…å®¹è¿›è¡Œä¸€äº›ç‰¹æ®Šæ“ä½œã€‚è¿™é‡Œçš„è®¾è®¡ï¼Œä¸»è¦æ˜¯å‡ºäºè°ƒåº¦ä¼˜å…ˆçº§å’ŒæŠ¢å çš„è€ƒè™‘

æ­¤å¤–ï¼ŒKubernetes çš„é»˜è®¤è°ƒåº¦å™¨è¿˜è¦è´Ÿè´£å¯¹è°ƒåº¦å™¨ç¼“å­˜ï¼ˆå³ï¼šscheduler cacheï¼‰è¿›è¡Œæ›´æ–°ã€‚äº‹å®ä¸Šï¼ŒKubernetes è°ƒåº¦éƒ¨åˆ†è¿›è¡Œæ€§èƒ½ä¼˜åŒ–çš„ä¸€ä¸ªæœ€æ ¹æœ¬åŸåˆ™ï¼Œå°±æ˜¯**å°½æœ€å¤§å¯èƒ½å°†é›†ç¾¤ä¿¡æ¯ Cache åŒ–**ï¼Œä»¥ä¾¿ä»æ ¹æœ¬ä¸Šæé«˜ Predicate å’Œ Priority è°ƒåº¦ç®—æ³•çš„æ‰§è¡Œæ•ˆç‡ã€‚



**ç¬¬äºŒä¸ªæ§åˆ¶å¾ªç¯ï¼Œæ˜¯è°ƒåº¦å™¨è´Ÿè´£ Pod è°ƒåº¦çš„ä¸»å¾ªç¯ï¼Œæˆ‘ä»¬å¯ä»¥ç§°ä¹‹ä¸º Scheduling Path**

Scheduling Path çš„ä¸»è¦é€»è¾‘ï¼Œå°±æ˜¯ä¸æ–­åœ°ä»è°ƒåº¦é˜Ÿåˆ—é‡Œå‡ºé˜Ÿä¸€ä¸ª Podã€‚ç„¶åï¼Œè°ƒç”¨ **Predicates ç®—æ³•è¿›è¡Œâ€œè¿‡æ»¤â€**ã€‚è¿™ä¸€æ­¥â€œè¿‡æ»¤â€å¾—åˆ°çš„ä¸€ç»„ Nodeï¼Œå°±æ˜¯æ‰€æœ‰å¯ä»¥è¿è¡Œè¿™ä¸ª Pod çš„å®¿ä¸»æœºåˆ—è¡¨ã€‚å½“ç„¶ï¼ŒPredicates ç®—æ³•éœ€è¦çš„ Node ä¿¡æ¯ï¼Œéƒ½æ˜¯ä» Scheduler Cache é‡Œç›´æ¥æ‹¿åˆ°çš„ï¼Œè¿™æ˜¯è°ƒåº¦å™¨ä¿è¯ç®—æ³•æ‰§è¡Œæ•ˆç‡çš„ä¸»è¦æ‰‹æ®µä¹‹ä¸€ã€‚

ä¸‹æ¥ï¼Œè°ƒåº¦å™¨å°±ä¼šå†è°ƒç”¨ **Priorities ç®—æ³•ä¸ºä¸Šè¿°åˆ—è¡¨é‡Œçš„ Node æ‰“åˆ†**ï¼Œåˆ†æ•°ä» 0 åˆ° 10ã€‚å¾—åˆ†æœ€é«˜çš„ Nodeï¼Œå°±ä¼šä½œä¸ºè¿™æ¬¡è°ƒåº¦çš„ç»“æœ

è°ƒåº¦ç®—æ³•æ‰§è¡Œå®Œæˆåï¼Œè°ƒåº¦å™¨å°±éœ€è¦å°† Pod å¯¹è±¡çš„ nodeName å­—æ®µçš„å€¼ï¼Œä¿®æ”¹ä¸ºä¸Šè¿° Node çš„åå­—ã€‚è¿™ä¸ªæ­¥éª¤åœ¨ Kubernetes é‡Œé¢è¢«ç§°ä½œ **Bind**ã€‚

ä½†æ˜¯ï¼Œä¸ºäº†ä¸åœ¨å…³é”®è°ƒåº¦è·¯å¾„é‡Œè¿œç¨‹è®¿é—® APIServerï¼ŒKubernetes çš„é»˜è®¤è°ƒåº¦å™¨åœ¨ Bind é˜¶æ®µï¼Œåªä¼šæ›´æ–° Scheduler Cache é‡Œçš„ Pod å’Œ Node çš„ä¿¡æ¯ã€‚**è¿™ç§åŸºäºâ€œä¹è§‚â€å‡è®¾çš„ API å¯¹è±¡æ›´æ–°æ–¹å¼ï¼Œåœ¨ Kubernetes é‡Œè¢«ç§°ä½œ Assumeã€‚**

Assume ä¹‹åï¼Œè°ƒåº¦å™¨æ‰ä¼šåˆ›å»ºä¸€ä¸ª Goroutine æ¥å¼‚æ­¥åœ°å‘ APIServer å‘èµ·æ›´æ–° Pod çš„è¯·æ±‚ï¼Œæ¥çœŸæ­£å®Œæˆ Bind æ“ä½œã€‚å¦‚æœè¿™æ¬¡å¼‚æ­¥çš„ Bind è¿‡ç¨‹å¤±è´¥äº†ï¼Œå…¶å®ä¹Ÿæ²¡æœ‰å¤ªå¤§å…³ç³»ï¼Œç­‰ Scheduler Cache åŒæ­¥ä¹‹åä¸€åˆ‡å°±ä¼šæ¢å¤æ­£å¸¸

å½“ç„¶ï¼Œæ­£æ˜¯ç”±äºä¸Šè¿° Kubernetes è°ƒåº¦å™¨çš„â€œä¹è§‚â€ç»‘å®šçš„è®¾è®¡ï¼Œå½“ä¸€ä¸ªæ–°çš„ Pod å®Œæˆè°ƒåº¦éœ€è¦åœ¨æŸä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œèµ·æ¥ä¹‹å‰ï¼Œè¯¥èŠ‚ç‚¹ä¸Šçš„ kubelet è¿˜ä¼šé€šè¿‡ä¸€ä¸ªå«ä½œ **Admit** çš„æ“ä½œæ¥å†æ¬¡éªŒè¯è¯¥ Pod æ˜¯å¦ç¡®å®èƒ½å¤Ÿè¿è¡Œåœ¨è¯¥èŠ‚ç‚¹ä¸Šã€‚è¿™ä¸€æ­¥ Admit æ“ä½œï¼Œå®é™…ä¸Šå°±æ˜¯æŠŠä¸€ç»„å«ä½œ GeneralPredicates çš„ã€æœ€åŸºæœ¬çš„è°ƒåº¦ç®—æ³•ï¼Œæ¯”å¦‚ï¼šâ€œèµ„æºæ˜¯å¦å¯ç”¨â€â€œç«¯å£æ˜¯å¦å†²çªâ€ç­‰å†æ‰§è¡Œä¸€éï¼Œä½œä¸º **kubelet ç«¯çš„äºŒæ¬¡ç¡®è®¤**ã€‚

**é™¤äº†ä¸Šè¿°çš„â€œCache åŒ–â€å’Œâ€œä¹è§‚ç»‘å®šâ€ï¼ŒKubernetes é»˜è®¤è°ƒåº¦å™¨è¿˜æœ‰ä¸€ä¸ªé‡è¦çš„è®¾è®¡ï¼Œé‚£å°±æ˜¯â€œæ— é”åŒ–â€ã€‚**

åœ¨ Scheduling Path ä¸Šï¼Œè°ƒåº¦å™¨ä¼šå¯åŠ¨å¤šä¸ª Goroutine ä»¥èŠ‚ç‚¹ä¸ºç²’åº¦å¹¶å‘æ‰§è¡Œ Predicates ç®—æ³•ï¼Œä»è€Œæé«˜è¿™ä¸€é˜¶æ®µçš„æ‰§è¡Œæ•ˆç‡ã€‚è€Œä¸ä¹‹ç±»ä¼¼çš„ï¼ŒPriorities ç®—æ³•ä¹Ÿä¼šä»¥ MapReduce çš„æ–¹å¼å¹¶è¡Œè®¡ç®—ç„¶åå†è¿›è¡Œæ±‡æ€»ã€‚è€Œåœ¨è¿™äº›æ‰€æœ‰éœ€è¦å¹¶å‘çš„è·¯å¾„ä¸Šï¼Œè°ƒåº¦å™¨ä¼šé¿å…è®¾ç½®ä»»ä½•å…¨å±€çš„ç«äº‰èµ„æºï¼Œä»è€Œå…å»äº†ä½¿ç”¨é”è¿›è¡ŒåŒæ­¥å¸¦æ¥çš„å·¨å¤§çš„æ€§èƒ½æŸè€—ã€‚ 

æ‰€ä»¥ï¼Œåœ¨è¿™ç§æ€æƒ³çš„æŒ‡å¯¼ä¸‹ï¼Œå¦‚æœä½ å†å»æŸ¥çœ‹ä¸€ä¸‹å‰é¢çš„è°ƒåº¦å™¨åŸç†å›¾ï¼Œä½ å°±ä¼šå‘ç°ï¼ŒKubernetes è°ƒåº¦å™¨åªæœ‰å¯¹è°ƒåº¦é˜Ÿåˆ—å’Œ Scheduler Cache è¿›è¡Œæ“ä½œæ—¶ï¼Œæ‰éœ€è¦åŠ é”ã€‚è€Œè¿™ä¸¤éƒ¨åˆ†æ“ä½œï¼Œéƒ½ä¸åœ¨ Scheduling Path çš„ç®—æ³•æ‰§è¡Œè·¯å¾„ä¸Šã€‚

Kubernetes è°ƒåº¦å™¨çš„ä¸Šè¿°è®¾è®¡æ€æƒ³ï¼Œä¹Ÿæ˜¯åœ¨é›†ç¾¤è§„æ¨¡ä¸æ–­å¢é•¿çš„æ¼”è¿›è¿‡ç¨‹ä¸­é€æ­¥å®ç°çš„**ã€‚å°¤å…¶æ˜¯ â€œCache åŒ–â€ï¼Œè¿™ä¸ªå˜åŒ–å…¶å®æ˜¯æœ€è¿‘å‡ å¹´ Kubernetes è°ƒåº¦å™¨æ€§èƒ½å¾—ä»¥æå‡çš„ä¸€ä¸ªå…³é”®æ¼”åŒ–ã€‚**



#### Schedulerçš„å¯æ‰©å±•æ€§

éšç€ Kubernetes é¡¹ç›®å‘å±•åˆ°ä»Šå¤©ï¼Œå®ƒçš„é»˜è®¤è°ƒåº¦å™¨ä¹Ÿå·²ç»æ¥åˆ°äº†ä¸€ä¸ªå…³é”®çš„åå­—è·¯å£ã€‚äº‹å®ä¸Šï¼ŒKubernetes ç°ä»Šå‘å±•çš„ä¸»æ—‹å¾‹ï¼Œæ˜¯æ•´ä¸ªå¼€æºé¡¹ç›®çš„â€œæ°‘ä¸»åŒ–â€ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒKubernetes ä¸‹ä¸€æ­¥å‘å±•çš„æ–¹å‘ï¼Œæ˜¯ç»„ä»¶çš„è½»é‡åŒ–ã€æ¥å£åŒ–å’Œæ’ä»¶åŒ–ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬æ‰æœ‰äº† CRIã€CNIã€CSIã€CRDã€Aggregated APIServerã€Initializerã€Device Plugin ç­‰å„ä¸ªå±‚çº§çš„å¯æ‰©å±•èƒ½åŠ›ã€‚å¯æ˜¯ï¼Œé»˜è®¤è°ƒåº¦å™¨ï¼Œå´æˆäº† Kubernetes é¡¹ç›®é‡Œæœ€åä¸€ä¸ªæ²¡æœ‰å¯¹å¤–æš´éœ²å‡ºè‰¯å¥½å®šä¹‰è¿‡çš„ã€å¯æ‰©å±•æ¥å£çš„ç»„ä»¶ã€‚

è€Œç°åœ¨ï¼Œéšç€ Kubernetes é¡¹ç›®é€æ­¥è¶‹äºç¨³å®šï¼Œè¶Šæ¥è¶Šå¤šçš„ç”¨æˆ·å¼€å§‹æŠŠ Kubernetes ç”¨åœ¨è§„æ¨¡æ›´å¤§ã€ä¸šåŠ¡æ›´åŠ å¤æ‚çš„ç§æœ‰é›†ç¾¤å½“ä¸­ã€‚å¾ˆå¤šä»¥å‰çš„ Mesos ç”¨æˆ·ï¼Œä¹Ÿå¼€å§‹å°è¯•ä½¿ç”¨ Kubernetes æ¥æ›¿ä»£å…¶åŸæœ‰æ¶æ„ã€‚åœ¨è¿™äº›åœºæ™¯ä¸‹ï¼Œå¯¹é»˜è®¤è°ƒåº¦å™¨è¿›è¡Œæ‰©å±•å’Œé‡æ–°å®ç°ï¼Œå°±æˆäº†ç¤¾åŒºå¯¹ Kubernetes é¡¹ç›®æœ€ä¸»è¦çš„ä¸€ä¸ªè¯‰æ±‚ã€‚

æ‰€ä»¥ï¼ŒKubernetes çš„é»˜è®¤è°ƒåº¦å™¨ï¼Œæ˜¯ç›®å‰è¿™ä¸ªé¡¹ç›®é‡Œä¸ºæ•°ä¸å¤šçš„ã€æ­£åœ¨ç»å†å¤§é‡é‡æ„çš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ã€‚è¿™äº›æ­£åœ¨è¿›è¡Œçš„é‡æ„çš„ç›®çš„ï¼Œä¸€æ–¹é¢æ˜¯å°†é»˜è®¤è°ƒåº¦å™¨é‡Œå¤§é‡çš„â€œæŠ€æœ¯å€ºâ€æ¸…ç†å¹²å‡€ï¼›å¦ä¸€æ–¹é¢ï¼Œå°±æ˜¯ä¸ºé»˜è®¤è°ƒåº¦å™¨çš„å¯æ‰©å±•æ€§è®¾è®¡è¿›è¡Œé“ºå«ã€‚

è€Œ Kubernetes é»˜è®¤è°ƒåº¦å™¨çš„å¯æ‰©å±•æ€§è®¾è®¡ï¼Œå¯ä»¥ç”¨å¦‚ä¸‹æ‰€ç¤ºçš„ä¸€å¹…ç¤ºæ„å›¾æ¥æè¿°ï¼š

![image-20250401214905398](../markdown_img/image-20250401214905398.png)

é»˜è®¤è°ƒåº¦å™¨çš„å¯æ‰©å±•æœºåˆ¶ï¼Œåœ¨ Kubernetes é‡Œé¢å«ä½œ Scheduler Frameworkã€‚é¡¾åæ€ä¹‰ï¼Œè¿™ä¸ªè®¾è®¡çš„ä¸»è¦ç›®çš„ï¼Œå°±æ˜¯åœ¨è°ƒåº¦å™¨ç”Ÿå‘½å‘¨æœŸçš„å„ä¸ªå…³é”®ç‚¹ä¸Šï¼Œä¸ºç”¨æˆ·æš´éœ²å‡ºå¯ä»¥è¿›è¡Œæ‰©å±•å’Œå®ç°çš„æ¥å£ï¼Œä»è€Œå®ç°ç”±ç”¨æˆ·è‡ªå®šä¹‰è°ƒåº¦å™¨çš„èƒ½åŠ›ã€‚

ä¸Šå›¾ä¸­ï¼Œæ¯ä¸€ä¸ªç»¿è‰²çš„ç®­å¤´éƒ½æ˜¯ä¸€ä¸ªå¯ä»¥æ’å…¥è‡ªå®šä¹‰é€»è¾‘çš„æ¥å£ã€‚æ¯”å¦‚ï¼Œä¸Šé¢çš„ Queue éƒ¨åˆ†ï¼Œå°±æ„å‘³ç€ä½ å¯ä»¥åœ¨è¿™ä¸€éƒ¨åˆ†æä¾›ä¸€ä¸ªè‡ªå·±çš„è°ƒåº¦é˜Ÿåˆ—çš„å®ç°ï¼Œä»è€Œæ§åˆ¶æ¯ä¸ª Pod å¼€å§‹è¢«è°ƒåº¦ï¼ˆå‡ºé˜Ÿï¼‰çš„æ—¶æœºã€‚

è€Œ Predicates éƒ¨åˆ†ï¼Œåˆ™æ„å‘³ç€ä½ å¯ä»¥æä¾›è‡ªå·±çš„è¿‡æ»¤ç®—æ³•å®ç°ï¼Œæ ¹æ®è‡ªå·±çš„éœ€æ±‚ï¼Œæ¥å†³å®šé€‰æ‹©å“ªäº›æœºå™¨ã€‚

```ABAP
éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸Šè¿°è¿™äº›å¯æ’æ‹”å¼é€»è¾‘ï¼Œéƒ½æ˜¯æ ‡å‡†çš„ Go è¯­è¨€æ’ä»¶æœºåˆ¶ï¼ˆGo plugin æœºåˆ¶ï¼‰ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä½ éœ€è¦åœ¨ç¼–è¯‘çš„æ—¶å€™é€‰æ‹©æŠŠå“ªäº›æ’ä»¶ç¼–è¯‘è¿›å»ã€‚
```

äº†ä¸Šè¿°è®¾è®¡ä¹‹åï¼Œæ‰©å±•å’Œè‡ªå®šä¹‰ Kubernetes çš„é»˜è®¤è°ƒåº¦å™¨å°±å˜æˆäº†ä¸€ä»¶éå¸¸å®¹æ˜“å®ç°çš„äº‹æƒ…ã€‚è¿™ä¹Ÿæ„å‘³ç€é»˜è®¤è°ƒåº¦å™¨åœ¨åé¢çš„å‘å±•è¿‡ç¨‹ä¸­ï¼Œå¿…ç„¶ä¸ä¼šåœ¨ç°åœ¨çš„å®ç°ä¸Šå†æ·»åŠ å¤ªå¤šçš„åŠŸèƒ½ï¼Œåè€Œè¿˜ä¼šå¯¹ç°åœ¨çš„å®ç°è¿›è¡Œç²¾ç®€ï¼Œæœ€ç»ˆæˆä¸º Scheduler Framework çš„ä¸€ä¸ªæœ€å°å®ç°ã€‚è€Œè°ƒåº¦é¢†åŸŸæ›´å¤šçš„åˆ›æ–°å’Œå·¥ç¨‹å·¥ä½œï¼Œå°±å¯ä»¥äº¤ç»™æ•´ä¸ªç¤¾åŒºæ¥å®Œæˆäº†ã€‚è¿™ä¸ªæ€è·¯ï¼Œæ˜¯å®Œå…¨ç¬¦åˆæˆ‘åœ¨å‰é¢æåˆ°çš„ Kubernetes çš„â€œæ°‘ä¸»åŒ–â€è®¾è®¡çš„ã€‚





### Kubernetesé»˜è®¤è°ƒåº¦å™¨è°ƒåº¦ç­–ç•¥è§£æ

#### Predicatesé˜¶æ®µ

**Predicates åœ¨è°ƒåº¦è¿‡ç¨‹ä¸­çš„ä½œç”¨ï¼Œå¯ä»¥ç†è§£ä¸º Filter**ï¼Œå³ï¼šå®ƒæŒ‰ç…§è°ƒåº¦ç­–ç•¥ï¼Œä»å½“å‰é›†ç¾¤çš„æ‰€æœ‰èŠ‚ç‚¹ä¸­ï¼Œâ€œè¿‡æ»¤â€å‡ºä¸€ç³»åˆ—ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹ã€‚è¿™äº›èŠ‚ç‚¹ï¼Œéƒ½æ˜¯å¯ä»¥è¿è¡Œå¾…è°ƒåº¦ Pod çš„å®¿ä¸»æœºã€‚

**predicatesæ‰§è¡Œå…·ä½“è¿‡æ»¤æ“ä½œçš„æ˜¯ä¸€ç»„é¢„é€‰æ’ä»¶ï¼ˆpluginï¼‰**

**å‡ ä¸ªé‡è¦çš„Predicateè¯´æ˜**

- **PodFitsHostPorts**
  - æ£€æŸ¥Podçš„å„Containersä¸­å£°æ˜çš„Portsæ˜¯å¦å·²ç»è¢«èŠ‚ç‚¹ä¸Šç°æœ‰çš„Podæ‰€å ç”¨
- **MatchNodeSelector**
  - æ£€æŸ¥Podçš„`spec.affinity.nodeAffinity`å’Œspec.nodeSelectorçš„å®šä¹‰æ˜¯å¦é€šèŠ‚ç‚¹çš„æ ‡ç­¾ç›¸åŒ¹é…
- **PodFitsResources**
  - æ£€æŸ¥Podçš„èµ„æºéœ€æ±‚æ˜¯å¦èƒ½è¢«èŠ‚ç‚¹ä¸Šçš„å¯ç”¨èµ„æºé‡æ‰€æ»¡è¶³
- **PodToleratesNodeTaints**
  - æ£€æŸ¥Podæ˜¯å¦èƒ½å®¹å¿èŠ‚ç‚¹ä¸Šçš„æ±¡ç‚¹
- **MaxCSIVolumeCount**
  - æ£€æŸ¥Podä¾èµ–çš„ç”±æŸCSIæ’ä»¶çš„æä¾›çš„PVCï¼Œæ˜¯å¦è¶…è¿‡èŠ‚ç‚¹çš„å•æœºä¸Šé™
- **MatchInterPodAffinity**
  - æ£€æŸ¥Podé—´çš„äº²å’Œå’Œåäº²å’Œå®šä¹‰æ˜¯å¦å¾—åˆ°æ»¡è¶³
- **EvenPodsSpread**
  - ä¸ºä¸€ç»„Podè®¾å®šåœ¨æŒ‡å®šToplolgyKeyä¸Šçš„æ•£ç½®è¦æ±‚ï¼Œå³æ‰“æ•£ä¸€ç»„Podè‡³ä¸åŒçš„æ‹“æ‰‘ä½ç½®



åœ¨ Kubernetes ä¸­ï¼Œé»˜è®¤çš„è°ƒåº¦ç­–ç•¥æœ‰å¦‚ä¸‹å››ç§

1ï¸âƒ£ **ç¬¬ä¸€ç§ç±»å‹ï¼Œå«ä½œ GeneralPredicates**

é¡¾åæ€ä¹‰ï¼Œè¿™ä¸€ç»„è¿‡æ»¤è§„åˆ™ï¼Œè´Ÿè´£çš„æ˜¯æœ€åŸºç¡€çš„è°ƒåº¦ç­–ç•¥ã€‚æ¯”å¦‚ï¼ŒPodFitsResources è®¡ç®—çš„å°±æ˜¯å®¿ä¸»æœºçš„ CPU å’Œå†…å­˜èµ„æºç­‰æ˜¯å¦å¤Ÿç”¨ã€‚

**PodFitsResources** æ£€æŸ¥çš„åªæ˜¯ Pod çš„ requests å­—æ®µã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ**Kubernetes çš„è°ƒåº¦å™¨å¹¶æ²¡æœ‰ä¸º GPU ç­‰ç¡¬ä»¶èµ„æºå®šä¹‰å…·ä½“çš„èµ„æºç±»å‹ï¼Œè€Œæ˜¯ç»Ÿä¸€ç”¨ä¸€ç§åå« Extended Resource çš„ã€Key-Value æ ¼å¼çš„æ‰©å±•å­—æ®µæ¥æè¿°çš„**ã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: extended-resource-demo
spec:
  containers:
  - name: extended-resource-demo-ctr
    image: nginx
    resources:
      requests:
        alpha.kubernetes.io/nvidia-gpu: 2
      limits:
        alpha.kubernetes.io/nvidia-gpu: 2
```

å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬è¿™ä¸ª Pod é€šè¿‡alpha.kubernetes.io/nvidia-gpu=2è¿™æ ·çš„å®šä¹‰æ–¹å¼ï¼Œå£°æ˜ä½¿ç”¨äº†ä¸¤ä¸ª NVIDIA ç±»å‹çš„ GPUã€‚

åœ¨ PodFitsResources é‡Œé¢ï¼Œè°ƒåº¦å™¨å…¶å®å¹¶ä¸çŸ¥é“è¿™ä¸ªå­—æ®µ Key çš„å«ä¹‰æ˜¯ GPUï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨åé¢çš„ Value è¿›è¡Œè®¡ç®—ã€‚å½“ç„¶ï¼Œåœ¨ Node çš„ Capacity å­—æ®µé‡Œï¼Œä½ ä¹Ÿå¾—ç›¸åº”åœ°åŠ ä¸Šè¿™å°å®¿ä¸»æœºä¸Š GPU çš„æ€»æ•°ï¼Œæ¯”å¦‚ï¼šalpha.kubernetes.io/nvidia-gpu=4ã€‚è¿™äº›æµç¨‹ï¼Œåœ¨åé¢è®²è§£ Device Plugin çš„æ—¶å€™ä¼šè¯¦ç»†ä»‹ç»ã€‚

è€Œ **PodFitsHost** æ£€æŸ¥çš„æ˜¯ï¼Œå®¿ä¸»æœºçš„åå­—æ˜¯å¦è·Ÿ Pod çš„ spec.nodeName ä¸€è‡´ã€‚

**PodFitsHostPorts** æ£€æŸ¥çš„æ˜¯ï¼ŒPod ç”³è¯·çš„å®¿ä¸»æœºç«¯å£ï¼ˆspec.nodePortï¼‰æ˜¯ä¸æ˜¯è·Ÿå·²ç»è¢«ä½¿ç”¨çš„ç«¯å£æœ‰å†²çªã€‚

**PodMatchNodeSelector** æ£€æŸ¥çš„æ˜¯ï¼ŒPod çš„ nodeSelector æˆ–è€… nodeAffinity æŒ‡å®šçš„èŠ‚ç‚¹ï¼Œæ˜¯å¦ä¸å¾…è€ƒå¯ŸèŠ‚ç‚¹åŒ¹é…ï¼Œç­‰ç­‰

å¯ä»¥çœ‹åˆ°ï¼Œåƒä¸Šé¢è¿™æ ·ä¸€ç»„ GeneralPredicatesï¼Œæ­£æ˜¯ Kubernetes è€ƒå¯Ÿä¸€ä¸ª Pod èƒ½ä¸èƒ½è¿è¡Œåœ¨ä¸€ä¸ª Node ä¸Šæœ€åŸºæœ¬çš„è¿‡æ»¤æ¡ä»¶ã€‚æ‰€ä»¥ï¼ŒGeneralPredicates ä¹Ÿä¼šè¢«å…¶ä»–ç»„ä»¶ï¼ˆæ¯”å¦‚ kubeletï¼‰ç›´æ¥è°ƒç”¨ã€‚

**ä¹‹å‰å·²ç»æåˆ°è¿‡ï¼Œkubelet åœ¨å¯åŠ¨ Pod å‰ï¼Œä¼šæ‰§è¡Œä¸€ä¸ª Admit æ“ä½œæ¥è¿›è¡ŒäºŒæ¬¡ç¡®è®¤ã€‚è¿™é‡ŒäºŒæ¬¡ç¡®è®¤çš„è§„åˆ™ï¼Œå°±æ˜¯æ‰§è¡Œä¸€é GeneralPredicatesã€‚**



2ï¸âƒ£ **ç¬¬äºŒç§ç±»å‹ï¼Œæ˜¯ä¸ Volume ç›¸å…³çš„è¿‡æ»¤è§„åˆ™**ã€‚

è¿™ä¸€ç»„è¿‡æ»¤è§„åˆ™ï¼Œè´Ÿè´£çš„æ˜¯è·Ÿå®¹å™¨æŒä¹…åŒ– Volume ç›¸å…³çš„è°ƒåº¦ç­–ç•¥

å…¶ä¸­ï¼Œ**NoDiskConflict** æ£€æŸ¥çš„æ¡ä»¶ï¼Œæ˜¯å¤šä¸ª Pod å£°æ˜æŒ‚è½½çš„æŒä¹…åŒ– Volume æ˜¯å¦æœ‰å†²çªã€‚æ¯”å¦‚ï¼ŒAWS EBS ç±»å‹çš„ Volumeï¼Œæ˜¯ä¸å…è®¸è¢«ä¸¤ä¸ª Pod åŒæ—¶ä½¿ç”¨çš„ã€‚æ‰€ä»¥ï¼Œå½“ä¸€ä¸ªåå« A çš„ EBS Volume å·²ç»è¢«æŒ‚è½½åœ¨äº†æŸä¸ªèŠ‚ç‚¹ä¸Šæ—¶ï¼Œå¦ä¸€ä¸ªåŒæ ·å£°æ˜ä½¿ç”¨è¿™ä¸ª A Volume çš„ Podï¼Œå°±ä¸èƒ½è¢«è°ƒåº¦åˆ°è¿™ä¸ªèŠ‚ç‚¹ä¸Šäº†ã€‚

è€Œ **MaxPDVolumeCountPredicate** æ£€æŸ¥çš„æ¡ä»¶ï¼Œåˆ™æ˜¯ä¸€ä¸ªèŠ‚ç‚¹ä¸ŠæŸç§ç±»å‹çš„æŒä¹…åŒ– Volume æ˜¯ä¸æ˜¯å·²ç»è¶…è¿‡äº†ä¸€å®šæ•°ç›®ï¼Œå¦‚æœæ˜¯çš„è¯ï¼Œé‚£ä¹ˆå£°æ˜ä½¿ç”¨è¯¥ç±»å‹æŒä¹…åŒ– Volume çš„ Pod å°±ä¸èƒ½å†è°ƒåº¦åˆ°è¿™ä¸ªèŠ‚ç‚¹äº†

è€Œ **VolumeZonePredicate**ï¼Œåˆ™æ˜¯æ£€æŸ¥æŒä¹…åŒ– Volume çš„ Zoneï¼ˆé«˜å¯ç”¨åŸŸï¼‰æ ‡ç­¾ï¼Œæ˜¯å¦ä¸å¾…è€ƒå¯ŸèŠ‚ç‚¹çš„ Zone æ ‡ç­¾ç›¸åŒ¹é…

æ­¤å¤–ï¼Œè¿™é‡Œè¿˜æœ‰ä¸€ä¸ªå«ä½œ **VolumeBindingPredicate** çš„è§„åˆ™ã€‚å®ƒè´Ÿè´£æ£€æŸ¥çš„ï¼Œæ˜¯è¯¥ Pod å¯¹åº”çš„ PV çš„ nodeAffinity å­—æ®µï¼Œæ˜¯å¦è·ŸæŸä¸ªèŠ‚ç‚¹çš„æ ‡ç­¾ç›¸åŒ¹é…

Local Persistent Volumeï¼ˆæœ¬åœ°æŒä¹…åŒ–å·ï¼‰ï¼Œå¿…é¡»ä½¿ç”¨ nodeAffinity æ¥è·ŸæŸä¸ªå…·ä½“çš„èŠ‚ç‚¹ç»‘å®šã€‚è¿™å…¶å®ä¹Ÿå°±æ„å‘³ç€ï¼Œåœ¨ Predicates é˜¶æ®µï¼ŒKubernetes å°±å¿…é¡»èƒ½å¤Ÿæ ¹æ® Pod çš„ Volume å±æ€§æ¥è¿›è¡Œè°ƒåº¦ã€‚

æ­¤å¤–ï¼Œå¦‚æœè¯¥ Pod çš„ PVC è¿˜æ²¡æœ‰è·Ÿå…·ä½“çš„ PV ç»‘å®šçš„è¯ï¼Œè°ƒåº¦å™¨è¿˜è¦è´Ÿè´£æ£€æŸ¥æ‰€æœ‰å¾…ç»‘å®š PVï¼Œå½“æœ‰å¯ç”¨çš„ PV å­˜åœ¨å¹¶ä¸”è¯¥ PV çš„ nodeAffinity ä¸å¾…è€ƒå¯ŸèŠ‚ç‚¹ä¸€è‡´æ—¶ï¼Œè¿™æ¡è§„åˆ™æ‰ä¼šè¿”å›â€œæˆåŠŸâ€ã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼š

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: example-local-pv
spec:
  capacity:
    storage: 500Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /mnt/disks/vol1
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - my-node
```

å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ª PV å¯¹åº”çš„æŒä¹…åŒ–ç›®å½•ï¼Œåªä¼šå‡ºç°åœ¨åå« my-node çš„å®¿ä¸»æœºä¸Šã€‚æ‰€ä»¥ï¼Œä»»ä½•ä¸€ä¸ªé€šè¿‡ PVC ä½¿ç”¨è¿™ä¸ª PV çš„ Podï¼Œéƒ½å¿…é¡»è¢«è°ƒåº¦åˆ° my-node ä¸Šæ‰å¯ä»¥æ­£å¸¸å·¥ä½œã€‚VolumeBindingPredicateï¼Œæ­£æ˜¯è°ƒåº¦å™¨é‡Œå®Œæˆè¿™ä¸ªå†³ç­–çš„ä½ç½®ã€‚



3ï¸âƒ£ **ç¬¬ä¸‰ç§ç±»å‹ï¼Œæ˜¯å®¿ä¸»æœºç›¸å…³çš„è¿‡æ»¤è§„åˆ™ã€‚**

è¿™ä¸€ç»„è§„åˆ™ï¼Œä¸»è¦è€ƒå¯Ÿå¾…è°ƒåº¦ Pod æ˜¯å¦æ»¡è¶³ Node æœ¬èº«çš„æŸäº›æ¡ä»¶

æ¯”å¦‚ï¼Œ**PodToleratesNodeTaints**ï¼Œè´Ÿè´£æ£€æŸ¥çš„å°±æ˜¯æˆ‘ä»¬å‰é¢ç»å¸¸ç”¨åˆ°çš„ Node çš„â€œæ±¡ç‚¹â€æœºåˆ¶ã€‚åªæœ‰å½“ Pod çš„ **Toleration** å­—æ®µä¸ Node çš„ **Taint** å­—æ®µèƒ½å¤ŸåŒ¹é…çš„æ—¶å€™ï¼Œè¿™ä¸ª Pod æ‰èƒ½è¢«è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ä¸Š

è€Œ **NodeMemoryPressurePredicate**ï¼Œæ£€æŸ¥çš„æ˜¯å½“å‰èŠ‚ç‚¹çš„å†…å­˜æ˜¯ä¸æ˜¯å·²ç»ä¸å¤Ÿå……è¶³ï¼Œå¦‚æœæ˜¯çš„è¯ï¼Œé‚£ä¹ˆå¾…è°ƒåº¦ Pod å°±ä¸èƒ½è¢«è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ä¸Šã€‚



4ï¸âƒ£ **ç¬¬å››ç§ç±»å‹ï¼Œæ˜¯ Pod ç›¸å…³çš„è¿‡æ»¤è§„åˆ™ã€‚**

è¿™ä¸€ç»„è§„åˆ™ï¼Œè·Ÿ GeneralPredicates å¤§å¤šæ•°æ˜¯é‡åˆçš„ã€‚è€Œæ¯”è¾ƒç‰¹æ®Šçš„ï¼Œæ˜¯ **PodAffinityPredicate**ã€‚è¿™ä¸ªè§„åˆ™çš„ä½œç”¨ï¼Œæ˜¯**æ£€æŸ¥å¾…è°ƒåº¦ Pod ä¸ Node ä¸Šçš„å·²æœ‰ Pod ä¹‹é—´çš„äº²å¯†ï¼ˆaffinityï¼‰å’Œåäº²å¯†ï¼ˆanti-affinityï¼‰å…³ç³»**ã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: with-pod-antiaffinity
spec:
  affinity:
    podAntiAffinity: 
      requiredDuringSchedulingIgnoredDuringExecution: 
      - weight: 100  
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: security 
              operator: In 
              values:
              - S2
          topologyKey: kubernetes.io/hostname
  containers:
  - name: with-pod-affinity
    image: docker.io/ocpqe/hello-pod
```

è¿™ä¸ªä¾‹å­é‡Œçš„ **podAntiAffinity è§„åˆ™**ï¼Œå°±æŒ‡å®šäº†è¿™ä¸ª Pod ä¸å¸Œæœ›è·Ÿä»»ä½•æºå¸¦äº† security=S2 æ ‡ç­¾çš„ Pod å­˜åœ¨äºåŒä¸€ä¸ª Node ä¸Šã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒPodAffinityPredicate æ˜¯æœ‰ä½œç”¨åŸŸçš„ï¼Œæ¯”å¦‚ä¸Šé¢è¿™æ¡è§„åˆ™ï¼Œå°±ä»…å¯¹æºå¸¦äº† Key æ˜¯kubernetes.io/hostnameæ ‡ç­¾çš„ Node æœ‰æ•ˆã€‚è¿™æ­£æ˜¯ topologyKey è¿™ä¸ªå…³é”®è¯çš„ä½œç”¨

**è€Œä¸ podAntiAffinity ç›¸åçš„ï¼Œå°±æ˜¯ podAffinityï¼Œæ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: with-pod-affinity
spec:
  affinity:
    podAffinity: 
      requiredDuringSchedulingIgnoredDuringExecution: 
      - labelSelector:
          matchExpressions:
          - key: security 
            operator: In 
            values:
            - S1 
        topologyKey: failure-domain.beta.kubernetes.io/zone
  containers:
  - name: with-pod-affinity
    image: docker.io/ocpqe/hello-pod
```

è¿™ä¸ªä¾‹å­é‡Œçš„ Podï¼Œå°±åªä¼šè¢«è°ƒåº¦åˆ°å·²ç»æœ‰æºå¸¦äº† security=S1 æ ‡ç­¾çš„ Pod è¿è¡Œçš„ Node ä¸Šã€‚è€Œè¿™æ¡è§„åˆ™çš„ä½œç”¨åŸŸï¼Œåˆ™æ˜¯æ‰€æœ‰æºå¸¦ Key æ˜¯failure-domain.beta.kubernetes.io/zoneæ ‡ç­¾çš„ Node

æ­¤å¤–ï¼Œä¸Šé¢è¿™ä¸¤ä¸ªä¾‹å­é‡Œçš„ **requiredDuringSchedulingIgnoredDuringExecution** å­—æ®µçš„å«ä¹‰æ˜¯ï¼šè¿™æ¡è§„åˆ™å¿…é¡»åœ¨ Pod è°ƒåº¦æ—¶è¿›è¡Œæ£€æŸ¥ï¼ˆrequiredDuringSchedulingï¼‰ï¼›ä½†æ˜¯å¦‚æœæ˜¯å·²ç»åœ¨è¿è¡Œçš„ Pod å‘ç”Ÿå˜åŒ–ï¼Œæ¯”å¦‚ Label è¢«ä¿®æ”¹ï¼Œé€ æˆäº†è¯¥ Pod ä¸å†é€‚åˆè¿è¡Œåœ¨è¿™ä¸ª Node ä¸Šçš„æ—¶å€™ï¼ŒKubernetes ä¸ä¼šè¿›è¡Œä¸»åŠ¨ä¿®æ­£ï¼ˆIgnoredDuringExecutionï¼‰ã€‚

ä¸Šé¢è¿™å››ç§ç±»å‹çš„ Predicatesï¼Œå°±æ„æˆäº†è°ƒåº¦å™¨ç¡®å®šä¸€ä¸ª Node å¯ä»¥è¿è¡Œå¾…è°ƒåº¦ Pod çš„åŸºæœ¬ç­–ç•¥ã€‚

```ABAP
åœ¨å…·ä½“æ‰§è¡Œçš„æ—¶å€™ï¼Œ å½“å¼€å§‹è°ƒåº¦ä¸€ä¸ª Pod æ—¶ï¼ŒKubernetes è°ƒåº¦å™¨ä¼šåŒæ—¶å¯åŠ¨ 16 ä¸ª Goroutineï¼Œæ¥å¹¶å‘åœ°ä¸ºé›†ç¾¤é‡Œçš„æ‰€æœ‰ Node è®¡ç®— Predicatesï¼Œæœ€åè¿”å›å¯ä»¥è¿è¡Œè¿™ä¸ª Pod çš„å®¿ä¸»æœºåˆ—è¡¨ã€‚
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ä¸ºæ¯ä¸ª Node æ‰§è¡Œ Predicates æ—¶ï¼Œè°ƒåº¦å™¨ä¼šæŒ‰ç…§å›ºå®šçš„é¡ºåºæ¥è¿›è¡Œæ£€æŸ¥ã€‚è¿™ä¸ªé¡ºåºï¼Œæ˜¯æŒ‰ç…§ Predicates æœ¬èº«çš„å«ä¹‰æ¥ç¡®å®šçš„ã€‚æ¯”å¦‚ï¼Œå®¿ä¸»æœºç›¸å…³çš„ Predicates ä¼šè¢«æ”¾åœ¨ç›¸å¯¹é å‰çš„ä½ç½®è¿›è¡Œæ£€æŸ¥ã€‚è¦ä¸ç„¶çš„è¯ï¼Œåœ¨ä¸€å°èµ„æºå·²ç»ä¸¥é‡ä¸è¶³çš„å®¿ä¸»æœºä¸Šï¼Œä¸Šæ¥å°±å¼€å§‹è®¡ç®— PodAffinityPredicateï¼Œæ˜¯æ²¡æœ‰å®é™…æ„ä¹‰çš„ã€‚



#### **Priorities é˜¶æ®µ**

åœ¨ Predicates é˜¶æ®µå®Œæˆäº†èŠ‚ç‚¹çš„â€œè¿‡æ»¤â€ä¹‹åï¼ŒPriorities é˜¶æ®µçš„å·¥ä½œå°±æ˜¯ä¸ºè¿™äº›èŠ‚ç‚¹æ‰“åˆ†ã€‚è¿™é‡Œæ‰“åˆ†çš„èŒƒå›´æ˜¯ 0-10 åˆ†ï¼Œå¾—åˆ†æœ€é«˜çš„èŠ‚ç‚¹å°±æ˜¯æœ€åè¢« Pod ç»‘å®šçš„æœ€ä½³èŠ‚ç‚¹ã€‚

**Prioritiesç»å…¸ä¼˜é€‰ç®—æ³•çš„åˆ†ç±»**

- **èŠ‚ç‚¹èµ„æºåˆ†é…å€¾å‘**
  - **BalancedResourceAllocation**
  - **LeastRequestedPriority/MostRequestedPriority**
  - **ResourceLimitsPriority**
  - **RequestedToCapacityRatioPriority**
- **Podæ•£ç½®**
  - **SelectorSpreadPriority**
  - **EvenPodsSpreadPriority**
  - **ServiceSpreadingPriority**
- **Nodeäº²å’Œä¸åäº²å’Œ**
  - **NodeAffinityPriorityã€NodePreferSpreadPriority**
  - **TaintTolerationPriority**
  - **ImageLocalityPriority**
- **Podé—´çš„äº²å’Œä¸åäº²å’Œ**
  - **InterPodAffinityPriority**



Priorities é‡Œæœ€å¸¸ç”¨åˆ°çš„ä¸€ä¸ªæ‰“åˆ†è§„åˆ™ï¼Œæ˜¯ **LeastRequestedPriority**ã€‚å®ƒçš„è®¡ç®—æ–¹æ³•ï¼Œå¯ä»¥ç®€å•åœ°æ€»ç»“ä¸ºå¦‚ä¸‹æ‰€ç¤ºçš„å…¬å¼ï¼š

```ABAP
score = (cpu((capacity-sum(requested))10/capacity) + memory((capacity-sum(requested))10/capacity))/2
```

å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ªç®—æ³•å®é™…ä¸Šå°±æ˜¯åœ¨é€‰æ‹©ç©ºé—²èµ„æºï¼ˆCPU å’Œ Memoryï¼‰æœ€å¤šçš„å®¿ä¸»æœºã€‚

è€Œä¸ **LeastRequestedPriority** ä¸€èµ·å‘æŒ¥ä½œç”¨çš„ï¼Œè¿˜æœ‰ **BalancedResourceAllocation**ã€‚å®ƒçš„è®¡ç®—å…¬å¼å¦‚ä¸‹æ‰€ç¤ºï¼š

```ABAP
score = 10 - variance(cpuFraction,memoryFraction,volumeFraction)*10
```

ä¸­ï¼Œæ¯ç§èµ„æºçš„ Fraction çš„å®šä¹‰æ˜¯ ï¼šPod è¯·æ±‚çš„èµ„æº / èŠ‚ç‚¹ä¸Šçš„å¯ç”¨èµ„æºã€‚è€Œ variance ç®—æ³•çš„ä½œç”¨ï¼Œåˆ™æ˜¯è®¡ç®—æ¯ä¸¤ç§èµ„æº Fraction ä¹‹é—´çš„â€œè·ç¦»â€ã€‚è€Œæœ€åé€‰æ‹©çš„ï¼Œåˆ™æ˜¯èµ„æº Fraction å·®è·æœ€å°çš„èŠ‚ç‚¹ã€‚

æ‰€ä»¥è¯´ï¼Œ**BalancedResourceAllocation** é€‰æ‹©çš„ï¼Œå…¶å®æ˜¯è°ƒåº¦å®Œæˆåï¼Œæ‰€æœ‰èŠ‚ç‚¹é‡Œå„ç§èµ„æºåˆ†é…æœ€å‡è¡¡çš„é‚£ä¸ªèŠ‚ç‚¹ï¼Œä»è€Œé¿å…ä¸€ä¸ªèŠ‚ç‚¹ä¸Š CPU è¢«å¤§é‡åˆ†é…ã€è€Œ Memory å¤§é‡å‰©ä½™çš„æƒ…å†µã€‚

æ­¤å¤–ï¼Œè¿˜æœ‰ **NodeAffinityPriority**ã€**TaintTolerationPriority** å’Œ **InterPodAffinityPriority** è¿™ä¸‰ç§ Priorityã€‚é¡¾åæ€ä¹‰ï¼Œå®ƒä»¬ä¸å‰é¢çš„ **PodMatchNodeSelector**ã€**PodToleratesNodeTaints** å’Œ **PodAffinityPredicate** è¿™ä¸‰ä¸ª Predicate çš„å«ä¹‰å’Œè®¡ç®—æ–¹æ³•æ˜¯ç±»ä¼¼çš„ã€‚ä½†æ˜¯ä½œä¸º Priorityï¼Œä¸€ä¸ª Node æ»¡è¶³ä¸Šè¿°è§„åˆ™çš„å­—æ®µæ•°ç›®è¶Šå¤šï¼Œå®ƒçš„å¾—åˆ†å°±ä¼šè¶Šé«˜ã€‚

åœ¨é»˜è®¤ Priorities é‡Œï¼Œè¿˜æœ‰ä¸€ä¸ªå«ä½œ **ImageLocalityPriority** çš„ç­–ç•¥ã€‚å®ƒæ˜¯åœ¨ Kubernetes v1.12 é‡Œæ–°å¼€å¯çš„è°ƒåº¦è§„åˆ™ï¼Œå³ï¼šå¦‚æœå¾…è°ƒåº¦ Pod éœ€è¦ä½¿ç”¨çš„é•œåƒå¾ˆå¤§ï¼Œå¹¶ä¸”å·²ç»å­˜åœ¨äºæŸäº› Node ä¸Šï¼Œé‚£ä¹ˆè¿™äº› Node çš„å¾—åˆ†å°±ä¼šæ¯”è¾ƒé«˜

å½“ç„¶ï¼Œä¸ºäº†é¿å…è¿™ä¸ªç®—æ³•å¼•å‘è°ƒåº¦å †å ï¼Œè°ƒåº¦å™¨åœ¨è®¡ç®—å¾—åˆ†çš„æ—¶å€™è¿˜ä¼šæ ¹æ®é•œåƒçš„åˆ†å¸ƒè¿›è¡Œä¼˜åŒ–ï¼Œå³ï¼šå¦‚æœå¤§é•œåƒåˆ†å¸ƒçš„èŠ‚ç‚¹æ•°ç›®å¾ˆå°‘ï¼Œé‚£ä¹ˆè¿™äº›èŠ‚ç‚¹çš„æƒé‡å°±ä¼šè¢«è°ƒä½ï¼Œä»è€Œâ€œå¯¹å†²â€æ‰å¼•èµ·è°ƒåº¦å †å çš„é£é™©ã€‚



ä»¥ä¸Šï¼Œå°±æ˜¯ Kubernetes è°ƒåº¦å™¨çš„ Predicates å’Œ Priorities é‡Œé»˜è®¤è°ƒåº¦è§„åˆ™çš„ä¸»è¦å·¥ä½œåŸç†äº†ã€‚

```ABAP
åœ¨å®é™…çš„æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œè°ƒåº¦å™¨é‡Œå…³äºé›†ç¾¤å’Œ Pod çš„ä¿¡æ¯éƒ½å·²ç»ç¼“å­˜åŒ–ï¼Œæ‰€ä»¥è¿™äº›ç®—æ³•çš„æ‰§è¡Œè¿‡ç¨‹è¿˜æ˜¯æ¯”è¾ƒå¿«çš„
```



### Kubernetesé»˜è®¤è°ƒåº¦å™¨çš„ä¼˜å…ˆçº§å’ŒæŠ¢å æœºåˆ¶

é¦–å…ˆéœ€è¦æ˜ç¡®çš„æ˜¯ï¼Œä¼˜å…ˆçº§å’ŒæŠ¢å æœºåˆ¶ï¼Œè§£å†³çš„æ˜¯ **Pod è°ƒåº¦å¤±è´¥æ—¶è¯¥æ€ä¹ˆåŠçš„é—®é¢˜**ã€‚

æ­£å¸¸æƒ…å†µä¸‹ï¼Œå½“ä¸€ä¸ª Pod è°ƒåº¦å¤±è´¥åï¼Œå®ƒå°±ä¼šè¢«æš‚æ—¶â€œæç½®â€èµ·æ¥ï¼Œç›´åˆ° Pod è¢«æ›´æ–°ï¼Œæˆ–è€…é›†ç¾¤çŠ¶æ€å‘ç”Ÿå˜åŒ–ï¼Œè°ƒåº¦å™¨æ‰ä¼šå¯¹è¿™ä¸ª Pod è¿›è¡Œé‡æ–°è°ƒåº¦ã€‚

ä½†åœ¨æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬å¸Œæœ›çš„æ˜¯è¿™æ ·ä¸€ä¸ªåœºæ™¯ã€‚å½“ä¸€ä¸ªé«˜ä¼˜å…ˆçº§çš„ Pod è°ƒåº¦å¤±è´¥åï¼Œè¯¥ Pod å¹¶ä¸ä¼šè¢«â€œæç½®â€ï¼Œè€Œæ˜¯ä¼šâ€œæŒ¤èµ°â€æŸä¸ª Node ä¸Šçš„ä¸€äº›ä½ä¼˜å…ˆçº§çš„ Pod ã€‚è¿™æ ·å°±å¯ä»¥ä¿è¯è¿™ä¸ªé«˜ä¼˜å…ˆçº§ Pod çš„è°ƒåº¦æˆåŠŸã€‚è¿™ä¸ªç‰¹æ€§ï¼Œå…¶å®ä¹Ÿæ˜¯ä¸€ç›´ä»¥æ¥å°±å­˜åœ¨äº Borg ä»¥åŠ Mesos ç­‰é¡¹ç›®é‡Œçš„ä¸€ä¸ªåŸºæœ¬åŠŸèƒ½ã€‚

åœ¨ Kubernetes é‡Œï¼Œä¼˜å…ˆçº§å’ŒæŠ¢å æœºåˆ¶æ˜¯åœ¨ 1.10 ç‰ˆæœ¬åæ‰é€æ­¥å¯ç”¨çš„ã€‚è¦ä½¿ç”¨è¿™ä¸ªæœºåˆ¶ï¼Œä½ é¦–å…ˆéœ€è¦åœ¨ Kubernetes é‡Œæäº¤ä¸€ä¸ª **PriorityClass** çš„å®šä¹‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```yaml
apiVersion: scheduling.k8s.io/v1beta1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000
globalDefault: false
description: "This priority class should be used for high priority service pods only."
```

ä¸Šé¢è¿™ä¸ª YAML æ–‡ä»¶ï¼Œå®šä¹‰çš„æ˜¯ä¸€ä¸ªåå« high-priority çš„ PriorityClassï¼Œå…¶ä¸­ value çš„å€¼æ˜¯ 1000000 ï¼ˆä¸€ç™¾ä¸‡ï¼‰

**Kubernetes è§„å®šï¼Œä¼˜å…ˆçº§æ˜¯ä¸€ä¸ª 32 bit çš„æ•´æ•°ï¼Œæœ€å¤§å€¼ä¸è¶…è¿‡ 1000000000ï¼ˆ10 äº¿ï¼Œ1 billionï¼‰ï¼Œå¹¶ä¸”å€¼è¶Šå¤§ä»£è¡¨ä¼˜å…ˆçº§è¶Šé«˜**ã€‚è€Œè¶…å‡º 10 äº¿çš„å€¼ï¼Œå…¶å®æ˜¯è¢« Kubernetes ä¿ç•™ä¸‹æ¥åˆ†é…ç»™ç³»ç»Ÿ Pod ä½¿ç”¨çš„ã€‚æ˜¾ç„¶ï¼Œè¿™æ ·åšçš„ç›®çš„ï¼Œå°±æ˜¯ä¿è¯ç³»ç»Ÿ Pod ä¸ä¼šè¢«ç”¨æˆ·æŠ¢å æ‰ã€‚

è€Œä¸€æ—¦ä¸Šè¿° YAML æ–‡ä»¶é‡Œçš„ **globalDefault è¢«è®¾ç½®ä¸º true çš„è¯**ï¼Œ**é‚£å°±æ„å‘³ç€è¿™ä¸ª PriorityClass çš„å€¼ä¼šæˆä¸ºç³»ç»Ÿçš„é»˜è®¤å€¼**ã€‚è€Œå¦‚æœè¿™ä¸ªå€¼æ˜¯ falseï¼Œå°±è¡¨ç¤ºæˆ‘ä»¬åªå¸Œæœ›å£°æ˜ä½¿ç”¨è¯¥ PriorityClass çš„ Pod æ‹¥æœ‰å€¼ä¸º 1000000 çš„ä¼˜å…ˆçº§ï¼Œè€Œå¯¹äºæ²¡æœ‰å£°æ˜ PriorityClass çš„ Pod æ¥è¯´ï¼Œå®ƒä»¬çš„ä¼˜å…ˆçº§å°±æ˜¯ 0ã€‚

åœ¨åˆ›å»ºäº† PriorityClass å¯¹è±¡ä¹‹åï¼ŒPod å°±å¯ä»¥å£°æ˜ä½¿ç”¨å®ƒäº†ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  priorityClassName: high-priority
```

å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ª Pod é€šè¿‡ priorityClassName å­—æ®µï¼Œå£°æ˜äº†è¦ä½¿ç”¨åå« high-priority çš„ PriorityClassã€‚å½“è¿™ä¸ª Pod è¢«æäº¤ç»™ Kubernetes ä¹‹åï¼ŒKubernetes çš„ PriorityAdmissionController å°±ä¼šè‡ªåŠ¨å°†è¿™ä¸ª Pod çš„ spec.priority å­—æ®µè®¾ç½®ä¸º 1000000ã€‚

å‰æ–‡è®²è¿‡ï¼Œè°ƒåº¦å™¨é‡Œç»´æŠ¤ç€ä¸€ä¸ªè°ƒåº¦é˜Ÿåˆ—ã€‚æ‰€ä»¥ï¼Œå½“ Pod æ‹¥æœ‰äº†ä¼˜å…ˆçº§ä¹‹åï¼Œé«˜ä¼˜å…ˆçº§çš„ Pod å°±å¯èƒ½ä¼šæ¯”ä½ä¼˜å…ˆçº§çš„ Pod æå‰å‡ºé˜Ÿï¼Œä»è€Œå°½æ—©å®Œæˆè°ƒåº¦è¿‡ç¨‹ã€‚è¿™ä¸ªè¿‡ç¨‹ï¼Œå°±æ˜¯â€œä¼˜å…ˆçº§â€è¿™ä¸ªæ¦‚å¿µåœ¨ Kubernetes é‡Œçš„ä¸»è¦ä½“ç°ã€‚

```ABAP
å½“ä¸€ä¸ªé«˜ä¼˜å…ˆçº§çš„ Pod è°ƒåº¦å¤±è´¥çš„æ—¶å€™ï¼Œè°ƒåº¦å™¨çš„æŠ¢å èƒ½åŠ›å°±ä¼šè¢«è§¦å‘ã€‚è¿™æ—¶ï¼Œè°ƒåº¦å™¨å°±ä¼šè¯•å›¾ä»å½“å‰é›†ç¾¤é‡Œå¯»æ‰¾ä¸€ä¸ªèŠ‚ç‚¹ï¼Œä½¿å¾—å½“è¿™ä¸ªèŠ‚ç‚¹ä¸Šçš„ä¸€ä¸ªæˆ–è€…å¤šä¸ªä½ä¼˜å…ˆçº§ Pod è¢«åˆ é™¤åï¼Œå¾…è°ƒåº¦çš„é«˜ä¼˜å…ˆçº§ Pod å°±å¯ä»¥è¢«è°ƒåº¦åˆ°è¿™ä¸ªèŠ‚ç‚¹ä¸Šã€‚è¿™ä¸ªè¿‡ç¨‹ï¼Œå°±æ˜¯â€œæŠ¢å â€è¿™ä¸ªæ¦‚å¿µåœ¨ Kubernetes é‡Œçš„ä¸»è¦ä½“ç°
```

ä¸ºäº†æ–¹ä¾¿å™è¿°ï¼Œæˆ‘æ¥ä¸‹æ¥ä¼šæŠŠå¾…è°ƒåº¦çš„é«˜ä¼˜å…ˆçº§ Pod ç§°ä¸ºâ€œæŠ¢å è€…â€ï¼ˆPreemptorï¼‰ã€‚

å½“ä¸Šè¿°æŠ¢å è¿‡ç¨‹å‘ç”Ÿæ—¶ï¼ŒæŠ¢å è€…å¹¶ä¸ä¼šç«‹åˆ»è¢«è°ƒåº¦åˆ°è¢«æŠ¢å çš„ Node ä¸Šã€‚äº‹å®ä¸Šï¼Œè°ƒåº¦å™¨åªä¼šå°†æŠ¢å è€…çš„ spec.nominatedNodeName å­—æ®µï¼Œè®¾ç½®ä¸ºè¢«æŠ¢å çš„ Node çš„åå­—ã€‚ç„¶åï¼ŒæŠ¢å è€…ä¼šé‡æ–°è¿›å…¥ä¸‹ä¸€ä¸ªè°ƒåº¦å‘¨æœŸï¼Œç„¶ååœ¨æ–°çš„è°ƒåº¦å‘¨æœŸé‡Œæ¥å†³å®šæ˜¯ä¸æ˜¯è¦è¿è¡Œåœ¨è¢«æŠ¢å çš„èŠ‚ç‚¹ä¸Šã€‚è¿™å½“ç„¶ä¹Ÿå°±æ„å‘³ç€ï¼Œå³ä½¿åœ¨ä¸‹ä¸€ä¸ªè°ƒåº¦å‘¨æœŸï¼Œè°ƒåº¦å™¨ä¹Ÿä¸ä¼šä¿è¯æŠ¢å è€…ä¸€å®šä¼šè¿è¡Œåœ¨è¢«æŠ¢å çš„èŠ‚ç‚¹ä¸Šã€‚

è¿™æ ·è®¾è®¡çš„ä¸€ä¸ªé‡è¦åŸå› æ˜¯ï¼Œè°ƒåº¦å™¨åªä¼šé€šè¿‡æ ‡å‡†çš„ DELETE API æ¥åˆ é™¤è¢«æŠ¢å çš„ Podï¼Œæ‰€ä»¥ï¼Œè¿™äº› Pod å¿…ç„¶æ˜¯æœ‰ä¸€å®šçš„â€œä¼˜é›…é€€å‡ºâ€æ—¶é—´ï¼ˆé»˜è®¤æ˜¯ 30sï¼‰çš„ã€‚è€Œåœ¨è¿™æ®µæ—¶é—´é‡Œï¼Œå…¶ä»–çš„èŠ‚ç‚¹ä¹Ÿæ˜¯æœ‰å¯èƒ½å˜æˆå¯è°ƒåº¦çš„ï¼Œæˆ–è€…ç›´æ¥æœ‰æ–°çš„èŠ‚ç‚¹è¢«æ·»åŠ åˆ°è¿™ä¸ªé›†ç¾¤ä¸­æ¥ã€‚æ‰€ä»¥ï¼Œé‰´äºä¼˜é›…é€€å‡ºæœŸé—´ï¼Œé›†ç¾¤çš„å¯è°ƒåº¦æ€§å¯èƒ½ä¼šå‘ç”Ÿçš„å˜åŒ–ï¼Œ**æŠŠæŠ¢å è€…äº¤ç»™ä¸‹ä¸€ä¸ªè°ƒåº¦å‘¨æœŸå†å¤„ç†ï¼Œæ˜¯ä¸€ä¸ªéå¸¸åˆç†çš„é€‰æ‹©ã€‚**

è€Œåœ¨æŠ¢å è€…ç­‰å¾…è¢«è°ƒåº¦çš„è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæœ‰å…¶ä»–æ›´é«˜ä¼˜å…ˆçº§çš„ Pod ä¹Ÿè¦æŠ¢å åŒä¸€ä¸ªèŠ‚ç‚¹ï¼Œé‚£ä¹ˆè°ƒåº¦å™¨å°±ä¼šæ¸…ç©ºåŸæŠ¢å è€…çš„ spec.nominatedNodeName å­—æ®µï¼Œä»è€Œå…è®¸æ›´é«˜ä¼˜å…ˆçº§çš„æŠ¢å è€…æ‰§è¡ŒæŠ¢å ï¼Œå¹¶ä¸”ï¼Œè¿™ä¹Ÿå°±ä½¿å¾—åŸæŠ¢å è€…æœ¬èº«ï¼Œä¹Ÿæœ‰æœºä¼šå»é‡æ–°æŠ¢å å…¶ä»–èŠ‚ç‚¹ã€‚è¿™äº›ï¼Œéƒ½æ˜¯è®¾ç½® **nominatedNodeName** å­—æ®µçš„ä¸»è¦ç›®çš„



#### Kubernetes è°ƒåº¦å™¨é‡Œçš„æŠ¢å æœºåˆ¶

æŠ¢å å‘ç”Ÿçš„åŸå› ï¼Œä¸€å®šæ˜¯ä¸€ä¸ªé«˜ä¼˜å…ˆçº§çš„ Pod è°ƒåº¦å¤±è´¥ã€‚è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç§°è¿™ä¸ª Pod ä¸ºâ€œæŠ¢å è€…â€ï¼Œç§°è¢«æŠ¢å çš„ Pod ä¸ºâ€œç‰ºç‰²è€…â€ï¼ˆvictimsï¼‰ã€‚

è€Œ Kubernetes è°ƒåº¦å™¨å®ç°æŠ¢å ç®—æ³•çš„ä¸€ä¸ªæœ€é‡è¦çš„è®¾è®¡ï¼Œå°±æ˜¯åœ¨è°ƒåº¦é˜Ÿåˆ—çš„å®ç°é‡Œï¼Œä½¿ç”¨äº†**ä¸¤ä¸ªä¸åŒçš„é˜Ÿåˆ—ã€‚**

**ç¬¬ä¸€ä¸ªé˜Ÿåˆ—ï¼Œå«ä½œ activeQ**ã€‚å‡¡æ˜¯åœ¨ activeQ é‡Œçš„ Podï¼Œéƒ½æ˜¯ä¸‹ä¸€ä¸ªè°ƒåº¦å‘¨æœŸéœ€è¦è°ƒåº¦çš„å¯¹è±¡ã€‚æ‰€ä»¥ï¼Œå½“ä½ åœ¨ Kubernetes é›†ç¾¤é‡Œæ–°åˆ›å»ºä¸€ä¸ª Pod çš„æ—¶å€™ï¼Œè°ƒåº¦å™¨ä¼šå°†è¿™ä¸ª Pod å…¥é˜Ÿåˆ° activeQ é‡Œé¢ã€‚è€Œæˆ‘åœ¨å‰é¢æåˆ°è¿‡çš„ã€è°ƒåº¦å™¨ä¸æ–­ä»é˜Ÿåˆ—é‡Œå‡ºé˜Ÿï¼ˆPopï¼‰ä¸€ä¸ª Pod è¿›è¡Œè°ƒåº¦ï¼Œå®é™…ä¸Šéƒ½æ˜¯ä» activeQ é‡Œå‡ºé˜Ÿçš„ã€‚

**ç¬¬äºŒä¸ªé˜Ÿåˆ—ï¼Œå«ä½œ unschedulableQ**ï¼Œä¸“é—¨ç”¨æ¥å­˜æ”¾è°ƒåº¦å¤±è´¥çš„ Pod

è€Œè¿™é‡Œçš„ä¸€ä¸ªå…³é”®ç‚¹å°±åœ¨äºï¼Œå½“ä¸€ä¸ª unschedulableQ é‡Œçš„ Pod è¢«æ›´æ–°ä¹‹åï¼Œè°ƒåº¦å™¨ä¼šè‡ªåŠ¨æŠŠè¿™ä¸ª Pod ç§»åŠ¨åˆ° activeQ é‡Œï¼Œä»è€Œç»™è¿™äº›è°ƒåº¦å¤±è´¥çš„ Pod â€œé‡æ–°åšäººâ€çš„æœºä¼šã€‚

ç°åœ¨ï¼Œå›åˆ°æˆ‘ä»¬çš„æŠ¢å è€…è°ƒåº¦å¤±è´¥è¿™ä¸ªæ—¶é—´ç‚¹ä¸Šæ¥ã€‚

è°ƒåº¦å¤±è´¥ä¹‹åï¼ŒæŠ¢å è€…å°±ä¼šè¢«æ”¾è¿› unschedulableQ é‡Œé¢

ç„¶åï¼Œè¿™æ¬¡å¤±è´¥äº‹ä»¶å°±ä¼šè§¦å‘è°ƒåº¦å™¨ä¸ºæŠ¢å è€…å¯»æ‰¾ç‰ºç‰²è€…çš„æµç¨‹ã€‚

**ç¬¬ä¸€æ­¥**ï¼Œè°ƒåº¦å™¨ä¼šæ£€æŸ¥è¿™æ¬¡å¤±è´¥äº‹ä»¶çš„åŸå› ï¼Œæ¥ç¡®è®¤æŠ¢å æ˜¯ä¸æ˜¯å¯ä»¥å¸®åŠ©æŠ¢å è€…æ‰¾åˆ°ä¸€ä¸ªæ–°èŠ‚ç‚¹ã€‚è¿™æ˜¯å› ä¸ºæœ‰å¾ˆå¤š Predicates çš„å¤±è´¥æ˜¯ä¸èƒ½é€šè¿‡æŠ¢å æ¥è§£å†³çš„ã€‚æ¯”å¦‚ï¼ŒPodFitsHost ç®—æ³•ï¼ˆè´Ÿè´£çš„æ˜¯ï¼Œæ£€æŸ¥ Pod çš„ nodeSelector ä¸ Node çš„åå­—æ˜¯å¦åŒ¹é…ï¼‰ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œé™¤é Node çš„åå­—å‘ç”Ÿå˜åŒ–ï¼Œå¦åˆ™ä½ å³ä½¿åˆ é™¤å†å¤šçš„ Podï¼ŒæŠ¢å è€…ä¹Ÿä¸å¯èƒ½è°ƒåº¦æˆåŠŸã€‚

**ç¬¬äºŒæ­¥**ï¼Œå¦‚æœç¡®å®šæŠ¢å å¯ä»¥å‘ç”Ÿï¼Œé‚£ä¹ˆè°ƒåº¦å™¨å°±ä¼šæŠŠè‡ªå·±ç¼“å­˜çš„æ‰€æœ‰èŠ‚ç‚¹ä¿¡æ¯å¤åˆ¶ä¸€ä»½ï¼Œç„¶åä½¿ç”¨è¿™ä¸ªå‰¯æœ¬æ¥æ¨¡æ‹ŸæŠ¢å è¿‡ç¨‹

è¿™é‡Œçš„æŠ¢å è¿‡ç¨‹å¾ˆå®¹æ˜“ç†è§£ã€‚è°ƒåº¦å™¨ä¼šæ£€æŸ¥ç¼“å­˜å‰¯æœ¬é‡Œçš„æ¯ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç„¶åä»è¯¥èŠ‚ç‚¹ä¸Šæœ€ä½ä¼˜å…ˆçº§çš„ Pod å¼€å§‹ï¼Œé€ä¸€â€œåˆ é™¤â€è¿™äº› Podã€‚è€Œæ¯åˆ é™¤ä¸€ä¸ªä½ä¼˜å…ˆçº§ Podï¼Œè°ƒåº¦å™¨éƒ½ä¼šæ£€æŸ¥ä¸€ä¸‹æŠ¢å è€…æ˜¯å¦èƒ½å¤Ÿè¿è¡Œåœ¨è¯¥ Node ä¸Šã€‚ä¸€æ—¦å¯ä»¥è¿è¡Œï¼Œè°ƒåº¦å™¨å°±è®°å½•ä¸‹è¿™ä¸ª Node çš„åå­—å’Œè¢«åˆ é™¤ Pod çš„åˆ—è¡¨ï¼Œè¿™å°±æ˜¯ä¸€æ¬¡æŠ¢å è¿‡ç¨‹çš„ç»“æœäº†ã€‚

å½“éå†å®Œæ‰€æœ‰çš„èŠ‚ç‚¹ä¹‹åï¼Œè°ƒåº¦å™¨ä¼šåœ¨ä¸Šè¿°æ¨¡æ‹Ÿäº§ç”Ÿçš„æ‰€æœ‰æŠ¢å ç»“æœé‡Œåšä¸€ä¸ªé€‰æ‹©ï¼Œæ‰¾å‡ºæœ€ä½³ç»“æœã€‚è€Œè¿™ä¸€æ­¥çš„åˆ¤æ–­åŸåˆ™ï¼Œå°±æ˜¯å°½é‡å‡å°‘æŠ¢å å¯¹æ•´ä¸ªç³»ç»Ÿçš„å½±å“ã€‚æ¯”å¦‚ï¼Œéœ€è¦æŠ¢å çš„ Pod è¶Šå°‘è¶Šå¥½ï¼Œéœ€è¦æŠ¢å çš„ Pod çš„ä¼˜å…ˆçº§è¶Šä½è¶Šå¥½ï¼Œç­‰ç­‰ã€‚

**åœ¨å¾—åˆ°äº†æœ€ä½³çš„æŠ¢å ç»“æœä¹‹åï¼Œè¿™ä¸ªç»“æœé‡Œçš„ Nodeï¼Œå°±æ˜¯å³å°†è¢«æŠ¢å çš„ Nodeï¼›è¢«åˆ é™¤çš„ Pod åˆ—è¡¨ï¼Œå°±æ˜¯ç‰ºç‰²è€…ã€‚æ‰€ä»¥æ¥ä¸‹æ¥ï¼Œè°ƒåº¦å™¨å°±å¯ä»¥çœŸæ­£å¼€å§‹æŠ¢å çš„æ“ä½œäº†ï¼Œè¿™ä¸ªè¿‡ç¨‹ï¼Œå¯ä»¥åˆ†ä¸ºä¸‰æ­¥ã€‚**

**ç¬¬ä¸€æ­¥**ï¼Œè°ƒåº¦å™¨ä¼šæ£€æŸ¥ç‰ºç‰²è€…åˆ—è¡¨ï¼Œæ¸…ç†è¿™äº› Pod æ‰€æºå¸¦çš„ nominatedNodeName å­—æ®µã€‚

**ç¬¬äºŒæ­¥**ï¼Œè°ƒåº¦å™¨ä¼šæŠŠæŠ¢å è€…çš„ nominatedNodeNameï¼Œè®¾ç½®ä¸ºè¢«æŠ¢å çš„ Node çš„åå­—ã€‚

**ç¬¬ä¸‰æ­¥**ï¼Œè°ƒåº¦å™¨ä¼šå¼€å¯ä¸€ä¸ª Goroutineï¼ŒåŒæ­¥åœ°åˆ é™¤ç‰ºç‰²è€…ã€‚

è€Œç¬¬äºŒæ­¥å¯¹æŠ¢å è€… Pod çš„æ›´æ–°æ“ä½œï¼Œå°±ä¼šè§¦å‘åˆ°æˆ‘å‰é¢æåˆ°çš„â€œé‡æ–°åšäººâ€çš„æµç¨‹ï¼Œä»è€Œè®©æŠ¢å è€…åœ¨ä¸‹ä¸€ä¸ªè°ƒåº¦å‘¨æœŸé‡æ–°è¿›å…¥è°ƒåº¦æµç¨‹ã€‚

æ‰€ä»¥æ¥ä¸‹æ¥ï¼Œè°ƒåº¦å™¨å°±ä¼šé€šè¿‡æ­£å¸¸çš„è°ƒåº¦æµç¨‹æŠŠæŠ¢å è€…è°ƒåº¦æˆåŠŸã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆï¼Œæˆ‘å‰é¢ä¼šè¯´è°ƒåº¦å™¨å¹¶ä¸ä¿è¯æŠ¢å çš„ç»“æœï¼šåœ¨è¿™ä¸ªæ­£å¸¸çš„è°ƒåº¦æµç¨‹é‡Œï¼Œæ˜¯ä¸€åˆ‡çš†æœ‰å¯èƒ½çš„ã€‚

ä¸è¿‡ï¼Œå¯¹äºä»»æ„ä¸€ä¸ªå¾…è°ƒåº¦ Pod æ¥è¯´ï¼Œå› ä¸ºæœ‰ä¸Šè¿°æŠ¢å è€…çš„å­˜åœ¨ï¼Œå®ƒçš„è°ƒåº¦è¿‡ç¨‹ï¼Œå…¶å®æ˜¯æœ‰ä¸€äº›ç‰¹æ®Šæƒ…å†µéœ€è¦ç‰¹æ®Šå¤„ç†çš„

å…·ä½“æ¥è¯´ï¼Œåœ¨ä¸ºæŸä¸€å¯¹ Pod å’Œ Node æ‰§è¡Œ Predicates ç®—æ³•çš„æ—¶å€™ï¼Œå¦‚æœå¾…æ£€æŸ¥çš„ Node æ˜¯ä¸€ä¸ªå³å°†è¢«æŠ¢å çš„èŠ‚ç‚¹ï¼Œå³ï¼šè°ƒåº¦é˜Ÿåˆ—é‡Œæœ‰ nominatedNodeName å­—æ®µå€¼æ˜¯è¯¥ Node åå­—çš„ Pod å­˜åœ¨ï¼ˆå¯ä»¥ç§°ä¹‹ä¸ºï¼šâ€œæ½œåœ¨çš„æŠ¢å è€…â€ï¼‰ã€‚é‚£ä¹ˆï¼Œè°ƒåº¦å™¨å°±ä¼šå¯¹è¿™ä¸ª Node ï¼Œå°†åŒæ ·çš„ Predicates ç®—æ³•è¿è¡Œä¸¤éã€‚

**ç¬¬ä¸€é**ï¼Œ è°ƒåº¦å™¨ä¼šå‡è®¾ä¸Šè¿°â€œæ½œåœ¨çš„æŠ¢å è€…â€å·²ç»è¿è¡Œåœ¨è¿™ä¸ªèŠ‚ç‚¹ä¸Šï¼Œç„¶åæ‰§è¡Œ Predicates ç®—æ³•

ç¬¬äºŒéï¼Œ è°ƒåº¦å™¨ä¼šæ­£å¸¸æ‰§è¡Œ Predicates ç®—æ³•ï¼Œå³ï¼šä¸è€ƒè™‘ä»»ä½•â€œæ½œåœ¨çš„æŠ¢å è€…â€

è€Œåªæœ‰è¿™ä¸¤é Predicates ç®—æ³•éƒ½èƒ½é€šè¿‡æ—¶ï¼Œè¿™ä¸ª Pod å’Œ Node æ‰ä¼šè¢«è®¤ä¸ºæ˜¯å¯ä»¥ç»‘å®šï¼ˆbindï¼‰çš„ã€‚

ä¸éš¾æƒ³åˆ°ï¼Œè¿™é‡Œéœ€è¦æ‰§è¡Œç¬¬ä¸€é Predicates ç®—æ³•çš„åŸå› ï¼Œæ˜¯ç”±äº **InterPodAntiAffinity** è§„åˆ™çš„å­˜åœ¨ã€‚



### Kubernetes GPUç®¡ç†ä¸Device Pluginæœºåˆ¶

å¯¹äºäº‘çš„ç”¨æˆ·æ¥è¯´ï¼Œåœ¨ GPU çš„æ”¯æŒä¸Šï¼Œä»–ä»¬æœ€åŸºæœ¬çš„è¯‰æ±‚å…¶å®éå¸¸ç®€å•ï¼šæˆ‘åªè¦åœ¨ Pod çš„ YAML é‡Œé¢ï¼Œå£°æ˜æŸå®¹å™¨éœ€è¦çš„ GPU ä¸ªæ•°ï¼Œé‚£ä¹ˆ Kubernetes ä¸ºæˆ‘åˆ›å»ºçš„å®¹å™¨é‡Œå°±åº”è¯¥å‡ºç°å¯¹åº”çš„ GPU è®¾å¤‡ï¼Œä»¥åŠå®ƒå¯¹åº”çš„é©±åŠ¨ç›®å½•ã€‚

ä»¥ NVIDIA çš„ GPU è®¾å¤‡ä¸ºä¾‹ï¼Œä¸Šé¢çš„éœ€æ±‚å°±æ„å‘³ç€å½“ç”¨æˆ·çš„å®¹å™¨è¢«åˆ›å»ºä¹‹åï¼Œè¿™ä¸ªå®¹å™¨é‡Œå¿…é¡»å‡ºç°å¦‚ä¸‹ä¸¤éƒ¨åˆ†è®¾å¤‡å’Œç›®å½•ï¼š

1. GPU è®¾å¤‡ï¼Œæ¯”å¦‚ /dev/nvidia0ï¼›

2. GPU é©±åŠ¨ç›®å½•ï¼Œæ¯”å¦‚ /usr/local/nvidia/*ã€‚

å…¶ä¸­ï¼ŒGPU è®¾å¤‡è·¯å¾„ï¼Œæ­£æ˜¯è¯¥å®¹å™¨å¯åŠ¨æ—¶çš„ Devices å‚æ•°ï¼›è€Œé©±åŠ¨ç›®å½•ï¼Œåˆ™æ˜¯è¯¥å®¹å™¨å¯åŠ¨æ—¶çš„ Volume å‚æ•°ã€‚æ‰€ä»¥ï¼Œåœ¨ Kubernetes çš„ GPU æ”¯æŒçš„å®ç°é‡Œï¼Œkubelet å®é™…ä¸Šå°±æ˜¯å°†ä¸Šè¿°ä¸¤éƒ¨åˆ†å†…å®¹ï¼Œè®¾ç½®åœ¨äº†åˆ›å»ºè¯¥å®¹å™¨çš„ CRI ï¼ˆContainer Runtime Interfaceï¼‰å‚æ•°é‡Œé¢ã€‚è¿™æ ·ï¼Œç­‰åˆ°è¯¥å®¹å™¨å¯åŠ¨ä¹‹åï¼Œå¯¹åº”çš„å®¹å™¨é‡Œå°±ä¼šå‡ºç° GPU è®¾å¤‡å’Œé©±åŠ¨çš„è·¯å¾„äº†ã€‚

ä¸è¿‡ï¼ŒKubernetes åœ¨ Pod çš„ API å¯¹è±¡é‡Œï¼Œå¹¶æ²¡æœ‰ä¸º GPU ä¸“é—¨è®¾ç½®ä¸€ä¸ªèµ„æºç±»å‹å­—æ®µï¼Œè€Œæ˜¯ä½¿ç”¨äº†ä¸€ç§å«ä½œ **Extended Resourceï¼ˆERï¼‰**çš„ç‰¹æ®Šå­—æ®µæ¥è´Ÿè´£ä¼ é€’ GPU çš„ä¿¡æ¯ã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: cuda-vector-add
spec:
  restartPolicy: OnFailure
  containers:
    - name: cuda-vector-add
      image: "k8s.gcr.io/cuda-vector-add:v0.1"
      resources:
        limits:
          nvidia.com/gpu: 1
```

å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ä¸Šè¿° Pod çš„ limits å­—æ®µé‡Œï¼Œè¿™ä¸ªèµ„æºçš„åç§°æ˜¯nvidia.com/gpuï¼Œå®ƒçš„å€¼æ˜¯ 1ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ª Pod å£°æ˜äº†è‡ªå·±è¦ä½¿ç”¨ä¸€ä¸ª NVIDIA ç±»å‹çš„ GPUã€‚

è€Œåœ¨ kube-scheduler é‡Œé¢ï¼Œå®ƒå…¶å®å¹¶ä¸å…³å¿ƒè¿™ä¸ªå­—æ®µçš„å…·ä½“å«ä¹‰ï¼Œåªä¼šåœ¨è®¡ç®—çš„æ—¶å€™ï¼Œä¸€å¾‹å°†è°ƒåº¦å™¨é‡Œä¿å­˜çš„è¯¥ç±»å‹èµ„æºçš„å¯ç”¨é‡ï¼Œç›´æ¥å‡å» Pod å£°æ˜çš„æ•°å€¼å³å¯ã€‚æ‰€ä»¥è¯´ï¼ŒExtended Resourceï¼Œå…¶å®æ˜¯ Kubernetes ä¸ºç”¨æˆ·è®¾ç½®çš„ä¸€ç§å¯¹è‡ªå®šä¹‰èµ„æºçš„æ”¯æŒã€‚

å½“ç„¶ï¼Œä¸ºäº†èƒ½å¤Ÿè®©è°ƒåº¦å™¨çŸ¥é“è¿™ä¸ªè‡ªå®šä¹‰ç±»å‹çš„èµ„æºåœ¨æ¯å°å®¿ä¸»æœºä¸Šçš„å¯ç”¨é‡ï¼Œå®¿ä¸»æœºèŠ‚ç‚¹æœ¬èº«ï¼Œå°±å¿…é¡»èƒ½å¤Ÿå‘ API Server æ±‡æŠ¥è¯¥ç±»å‹èµ„æºçš„å¯ç”¨æ•°é‡ã€‚åœ¨ Kubernetes é‡Œï¼Œå„ç§ç±»å‹çš„èµ„æºå¯ç”¨é‡ï¼Œå…¶å®æ˜¯ Node å¯¹è±¡ Status å­—æ®µçš„å†…å®¹ï¼Œæ¯”å¦‚ä¸‹é¢è¿™ä¸ªä¾‹å­ï¼š

```yaml
apiVersion: v1
kind: Node
metadata:
  name: node-1
...
Status:
  Capacity:
   cpu:  2
   memory:  2049008Ki
```

è€Œä¸ºäº†èƒ½å¤Ÿåœ¨ä¸Šè¿° Status å­—æ®µé‡Œæ·»åŠ è‡ªå®šä¹‰èµ„æºçš„æ•°æ®ï¼Œä½ å°±å¿…é¡»ä½¿ç”¨ PATCH API æ¥å¯¹è¯¥ Node å¯¹è±¡è¿›è¡Œæ›´æ–°ï¼ŒåŠ ä¸Šä½ çš„è‡ªå®šä¹‰èµ„æºçš„æ•°é‡ã€‚è¿™ä¸ª PATCH æ“ä½œï¼Œå¯ä»¥ç®€å•åœ°ä½¿ç”¨ curl å‘½ä»¤æ¥å‘èµ·ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
# å¯åŠ¨ Kubernetes çš„å®¢æˆ·ç«¯ proxyï¼Œè¿™æ ·ä½ å°±å¯ä»¥ç›´æ¥ä½¿ç”¨ curl æ¥è·Ÿ Kubernetes  çš„API Server è¿›è¡Œäº¤äº’äº†
$ kubectl proxy

# æ‰§è¡Œ PACTH æ“ä½œ
$ curl --header "Content-Type: application/json-patch+json" \
--request PATCH \
--data '[{"op": "add", "path": "/status/capacity/nvidia.com/gpu", "value": "1"}]' \
http://localhost:8001/api/v1/nodes/<your-node-name>/status
```

PATCH æ“ä½œå®Œæˆåï¼Œä½ å°±å¯ä»¥çœ‹åˆ° Node çš„ Status å˜æˆäº†å¦‚ä¸‹æ‰€ç¤ºçš„å†…å®¹

```yaml
apiVersion: v1
kind: Node
...
Status:
  Capacity:
   cpu:  2
   memory:  2049008Ki
   nvidia.com/gpu: 1
```

è¿™æ ·åœ¨è°ƒåº¦å™¨é‡Œï¼Œå®ƒå°±èƒ½å¤Ÿåœ¨ç¼“å­˜é‡Œè®°å½•ä¸‹ node-1 ä¸Šçš„nvidia.com/gpuç±»å‹çš„èµ„æºçš„æ•°é‡æ˜¯ 1ã€‚

å½“ç„¶ï¼Œåœ¨ Kubernetes çš„ GPU æ”¯æŒæ–¹æ¡ˆé‡Œï¼Œä½ å¹¶ä¸éœ€è¦çœŸæ­£å»åšä¸Šè¿°å…³äº Extended Resource çš„è¿™äº›æ“ä½œã€‚åœ¨ Kubernetes ä¸­ï¼Œå¯¹æ‰€æœ‰ç¡¬ä»¶åŠ é€Ÿè®¾å¤‡è¿›è¡Œç®¡ç†çš„åŠŸèƒ½ï¼Œéƒ½æ˜¯ç”±ä¸€ç§å«ä½œ **Device Plugin** çš„æ’ä»¶æ¥è´Ÿè´£çš„ã€‚è¿™å…¶ä¸­ï¼Œå½“ç„¶ä¹Ÿå°±åŒ…æ‹¬äº†å¯¹è¯¥ç¡¬ä»¶çš„ **Extended Resource** è¿›è¡Œæ±‡æŠ¥çš„é€»è¾‘ã€‚

Kubernetes çš„ Device Plugin æœºåˆ¶ï¼Œæˆ‘å¯ä»¥ç”¨å¦‚ä¸‹æ‰€ç¤ºçš„ä¸€å¹…ç¤ºæ„å›¾æ¥å’Œä½ è§£é‡Šæ¸…æ¥šã€‚

![image-20250402104352183](../markdown_img/image-20250402104352183.png)

æˆ‘ä»¬å…ˆä»è¿™å¹…ç¤ºæ„å›¾çš„å³ä¾§å¼€å§‹çœ‹èµ·ã€‚

é¦–å…ˆï¼Œå¯¹äºæ¯ä¸€ç§ç¡¬ä»¶è®¾å¤‡ï¼Œéƒ½éœ€è¦æœ‰å®ƒæ‰€å¯¹åº”çš„ Device Plugin è¿›è¡Œç®¡ç†ï¼Œè¿™äº› Device Pluginï¼Œéƒ½é€šè¿‡ gRPC çš„æ–¹å¼ï¼ŒåŒ kubelet è¿æ¥èµ·æ¥ã€‚ä»¥ NVIDIA GPU ä¸ºä¾‹ï¼Œå®ƒå¯¹åº”çš„æ’ä»¶å«ä½œ**NVIDIA GPU device plugin**ã€‚

è¿™ä¸ª Device Plugin ä¼šé€šè¿‡ä¸€ä¸ªå«ä½œ ListAndWatch çš„ APIï¼Œå®šæœŸå‘ kubelet æ±‡æŠ¥è¯¥ Node ä¸Š GPU çš„åˆ—è¡¨ã€‚æ¯”å¦‚ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­é‡Œï¼Œä¸€å…±æœ‰ä¸‰ä¸ª GPUï¼ˆGPU0ã€GPU1 å’Œ GPU2ï¼‰ã€‚è¿™æ ·ï¼Œkubelet åœ¨æ‹¿åˆ°è¿™ä¸ªåˆ—è¡¨ä¹‹åï¼Œå°±å¯ä»¥ç›´æ¥åœ¨å®ƒå‘ APIServer å‘é€çš„å¿ƒè·³é‡Œï¼Œä»¥ Extended Resource çš„æ–¹å¼ï¼ŒåŠ ä¸Šè¿™äº› GPU çš„æ•°é‡ï¼Œæ¯”å¦‚nvidia.com/gpu=3ã€‚æ‰€ä»¥è¯´ï¼Œç”¨æˆ·åœ¨è¿™é‡Œæ˜¯ä¸éœ€è¦å…³å¿ƒ GPU ä¿¡æ¯å‘ä¸Šçš„æ±‡æŠ¥æµç¨‹çš„ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ**ListAndWatch å‘ä¸Šæ±‡æŠ¥çš„ä¿¡æ¯ï¼Œåªæœ‰æœ¬æœºä¸Š GPU çš„ ID åˆ—è¡¨ï¼Œè€Œä¸ä¼šæœ‰ä»»ä½•å…³äº GPU è®¾å¤‡æœ¬èº«çš„ä¿¡æ¯**ã€‚è€Œä¸” kubelet åœ¨å‘ API Server æ±‡æŠ¥çš„æ—¶å€™ï¼Œåªä¼šæ±‡æŠ¥è¯¥ GPU å¯¹åº”çš„ Extended Resource çš„æ•°é‡ã€‚å½“ç„¶ï¼Œkubelet æœ¬èº«ï¼Œä¼šå°†è¿™ä¸ª GPU çš„ ID åˆ—è¡¨ä¿å­˜åœ¨è‡ªå·±çš„å†…å­˜é‡Œï¼Œå¹¶é€šè¿‡ ListAndWatch API å®šæ—¶æ›´æ–°ã€‚

è€Œå½“ä¸€ä¸ª Pod æƒ³è¦ä½¿ç”¨ä¸€ä¸ª GPU çš„æ—¶å€™ï¼Œå®ƒåªéœ€è¦åƒæˆ‘åœ¨æœ¬æ–‡ä¸€å¼€å§‹ç»™å‡ºçš„ä¾‹å­ä¸€æ ·ï¼Œåœ¨ Pod çš„ limits å­—æ®µå£°æ˜nvidia.com/gpu: 1ã€‚é‚£ä¹ˆæ¥ä¸‹æ¥ï¼ŒKubernetes çš„è°ƒåº¦å™¨å°±ä¼šä»å®ƒçš„ç¼“å­˜é‡Œï¼Œå¯»æ‰¾ GPU æ•°é‡æ»¡è¶³æ¡ä»¶çš„ Nodeï¼Œç„¶åå°†ç¼“å­˜é‡Œçš„ GPU æ•°é‡å‡ 1ï¼Œå®Œæˆ Pod ä¸ Node çš„ç»‘å®šã€‚

è¿™ä¸ªè°ƒåº¦æˆåŠŸåçš„ Pod ä¿¡æ¯ï¼Œè‡ªç„¶å°±ä¼šè¢«å¯¹åº”çš„ kubelet æ‹¿æ¥è¿›è¡Œå®¹å™¨æ“ä½œã€‚è€Œå½“ kubelet å‘ç°è¿™ä¸ª Pod çš„å®¹å™¨è¯·æ±‚ä¸€ä¸ª GPU çš„æ—¶å€™ï¼Œkubelet å°±ä¼šä»è‡ªå·±æŒæœ‰çš„ GPU åˆ—è¡¨é‡Œï¼Œä¸ºè¿™ä¸ªå®¹å™¨åˆ†é…ä¸€ä¸ª GPUã€‚æ­¤æ—¶ï¼Œkubelet å°±ä¼šå‘æœ¬æœºçš„ Device Plugin å‘èµ·ä¸€ä¸ª Allocate() è¯·æ±‚ã€‚è¿™ä¸ªè¯·æ±‚æºå¸¦çš„å‚æ•°ï¼Œæ­£æ˜¯å³å°†åˆ†é…ç»™è¯¥å®¹å™¨çš„è®¾å¤‡ ID åˆ—è¡¨ã€‚

å½“ Device Plugin æ”¶åˆ° Allocate è¯·æ±‚ä¹‹åï¼Œå®ƒå°±ä¼šæ ¹æ® kubelet ä¼ é€’è¿‡æ¥çš„è®¾å¤‡ IDï¼Œä» Device Plugin é‡Œæ‰¾åˆ°è¿™äº›è®¾å¤‡å¯¹åº”çš„è®¾å¤‡è·¯å¾„å’Œé©±åŠ¨ç›®å½•ã€‚å½“ç„¶ï¼Œè¿™äº›ä¿¡æ¯ï¼Œæ­£æ˜¯ **Device Plugin å‘¨æœŸæ€§çš„ä»æœ¬æœºæŸ¥è¯¢åˆ°çš„ã€‚æ¯”å¦‚ï¼Œåœ¨ NVIDIA Device Plugin çš„å®ç°é‡Œï¼Œå®ƒä¼šå®šæœŸè®¿é—® nvidia-docker æ’ä»¶ï¼Œä»è€Œè·å–åˆ°æœ¬æœºçš„ GPU ä¿¡æ¯**

è€Œè¢«åˆ†é… GPU å¯¹åº”çš„è®¾å¤‡è·¯å¾„å’Œé©±åŠ¨ç›®å½•ä¿¡æ¯è¢«è¿”å›ç»™ kubelet ä¹‹åï¼Œkubelet å°±å®Œæˆäº†ä¸ºä¸€ä¸ªå®¹å™¨åˆ†é… GPU çš„æ“ä½œã€‚æ¥ä¸‹æ¥ï¼Œkubelet ä¼šæŠŠè¿™äº›ä¿¡æ¯è¿½åŠ åœ¨åˆ›å»ºè¯¥å®¹å™¨æ‰€å¯¹åº”çš„ CRI è¯·æ±‚å½“ä¸­ã€‚è¿™æ ·ï¼Œå½“è¿™ä¸ª CRI è¯·æ±‚å‘ç»™ Docker ä¹‹åï¼ŒDocker ä¸ºä½ åˆ›å»ºå‡ºæ¥çš„å®¹å™¨é‡Œï¼Œå°±ä¼šå‡ºç°è¿™ä¸ª GPU è®¾å¤‡ï¼Œå¹¶æŠŠå®ƒæ‰€éœ€è¦çš„é©±åŠ¨ç›®å½•æŒ‚è½½è¿›å»ã€‚

è‡³æ­¤ï¼ŒKubernetes ä¸ºä¸€ä¸ª Pod åˆ†é…ä¸€ä¸ª GPU çš„æµç¨‹å°±å®Œæˆäº†ã€‚

å¯¹äºå…¶ä»–ç±»å‹ç¡¬ä»¶æ¥è¯´ï¼Œè¦æƒ³åœ¨ Kubernetes æ‰€ç®¡ç†çš„å®¹å™¨é‡Œä½¿ç”¨è¿™äº›ç¡¬ä»¶çš„è¯ï¼Œä¹Ÿéœ€è¦éµå¾ªä¸Šè¿° Device Plugin çš„æµç¨‹æ¥å®ç°å¦‚ä¸‹æ‰€ç¤ºçš„ Allocate å’Œ ListAndWatch APIï¼š

```go
  service DevicePlugin {
        // ListAndWatch returns a stream of List of Devices
        // Whenever a Device state change or a Device disappears, ListAndWatch
        // returns the new list
        rpc ListAndWatch(Empty) returns (stream ListAndWatchResponse) {}
        // Allocate is called during container creation so that the Device
        // Plugin can run device specific operations and instruct Kubelet
        // of the steps to make the Device available in the container
        rpc Allocate(AllocateRequest) returns (AllocateResponse) {}
  }
```

ç›®å‰ï¼ŒKubernetes ç¤¾åŒºé‡Œå·²ç»å®ç°äº†å¾ˆå¤šç¡¬ä»¶æ’ä»¶ï¼Œæ¯”å¦‚FPGAã€SRIOVã€RDMAç­‰ç­‰ã€‚æ„Ÿå…´è¶£çš„è¯ï¼Œä½ å¯ä»¥ç‚¹å‡»è¿™äº›é“¾æ¥æ¥æŸ¥çœ‹è¿™äº› Device Plugin çš„å®ç°ã€‚



#### Kubernetesç®¡ç†GPUåº”ç”¨

å®˜æ–¹è¯´æ˜

```http
https://devblogs.nvidia.com/gpu-containers-runtime/
https://www.cnblogs.com/breezey/p/11801122.html
https://www.jianshu.com/p/8b84c597ce03
https://github.com/NVIDIA/nvidia-docker
https://github.com/NVIDIA/nvidia-container-runtime
https://github.com/NVIDIA/k8s-device-plugin
```



**åœ¨kubernetesä¸­ä½¿ç”¨GPUèµ„æº**

å®‰è£…æ­¥éª¤

1ï¸âƒ£ **èŠ‚ç‚¹å®‰è£…NVIDIAé©±åŠ¨**

```bash
rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
yum install -y kmod-nvidia

éªŒè¯
# nvidia-smi 
```

2ï¸âƒ£ **å®‰è£…nvidia-docker2 # æ³¨æ„ä¸æ˜¯nvidia-container-toolkit**

```bash
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo

yum install -y nvidia-docker2

pkill -SIGHUP dockerd
```

**3ï¸âƒ£ ä¿®æ”¹dockeré…ç½®æ–‡ä»¶**

```bash
# vim /etc/docker/daemon.json
{
    "default-runtime": "nvidia",
    "runtimes": {
        "nvidia": {
            "path": "/usr/bin/nvidia-container-runtime",
            "runtimeArgs": []
        }
}

# systemctl restart docker
```

4ï¸âƒ£ **å®‰è£…Nvidia-device-pluginæ’ä»¶**

```bash
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/1.0.0-beta4/nvidia-device-plugin.yml
# URL https://github.com/NVIDIA/k8s-device-plugin

éªŒè¯å®‰è£…
# kubectl get pod -n kube-system |grep nvidia
nvidia-device-plugin-daemonset-76gm6            1/1     Running   2          20d
```

5ï¸âƒ£ **éªŒè¯nodeæ˜¯å¦æˆåŠŸè¯†åˆ«gpuèµ„æº**

```bash
kubectl describe node nodeName
```

å¤šä¸ªpodå…±äº«ä¸€å¼ GPU

- ä¸è¡Œï¼Œpodåœ¨åˆ›å»ºçš„æ—¶å€™è¯·æ±‚gpuæœ€ä½æ˜¯å¡çº§åˆ«ï¼Œä¸€å¼ æ˜¾å¡åªèƒ½åˆ†é…ç»™ä¸€ä¸ªpodã€‚ä½†æ˜¯ä¸€ä¸ªpodæ˜¯ç”±å¤šä¸ªå®¹å™¨ç»„æˆçš„ï¼Œæ‰€ä»¥åŒä¸€ä¸ªpodçš„å®¹å™¨å¯ä»¥å…±äº«åˆ†é…ç»™å½“å‰podçš„æ‰€æœ‰GPUã€‚

å¤šä¸ªdockerå®¹å™¨å…±äº«ä¸€å¼ GPU

- å¯ä»¥ã€‚é€šè¿‡nvidia-dockerå¯åŠ¨çš„å®¹å™¨å¯ä»¥å…±äº«ä¸€å¼ GPUã€‚å› ä¸ºå®¹å™¨æ˜¯è¿›ç¨‹çº§çš„ç¨‹åºæ‰€ä»¥åˆ†é…GPUå¯ä»¥è¾¾åˆ°æ˜¾å­˜çº§ã€‚



### Kubernetesè°ƒåº¦æ¡†æ¶

**æ’ä»¶å¼è°ƒåº¦æ¡†æ¶**

- Kubernetesè‡ªv1.19ç‰ˆæä¾›çš„è°ƒåº¦æ¡†æ¶æä¾›äº†æ’ä»¶æ¶æ„ï¼Œä¸ºç°æœ‰çš„è°ƒåº¦å™¨æ·»åŠ äº†ä¸€ç»„æ–°çš„ "æ’ä»¶" API
- æ’ä»¶APIä¸­ï¼Œå¤§å¤šæ•°è°ƒåº¦åŠŸèƒ½éƒ½ä»¥æ’ä»¶å½¢å¼å®ç°

**æ¡†æ¶å·¥ä½œæµç¨‹**

- è°ƒåº¦æ¡†æ¶ä¸Šå®šä¹‰äº†ä¸€äº›æ‰©å±•ç‚¹ï¼Œè°ƒåº¦å™¨æ’ä»¶å®Œæˆæ³¨å†Œåå¯ä»¥ä¸€ä¸ªæˆ–å¤šä¸ªæ‰©å±•ç‚¹ä¸Šè¢«è°ƒç”¨
- æ¯æ¬¡è°ƒåº¦ä¸€ä¸ªPodçš„å°è¯•éƒ½å¯åˆ’åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œè°ƒåº¦å‘¨æœŸå’Œç»‘å®šå‘¨æœŸ
  - è°ƒåº¦å‘¨æœŸå®Œæˆä¸ºPodæŒ‘é€‰ä¸€ä¸ªæœ€ä½³åŒ¹é…çš„èŠ‚ç‚¹ï¼Œè¿™ç±»ä¼¼äºç»å…¸è°ƒåº¦æ¡†æ¶ä¸­çš„ Predicate å’Œ Priority ä¸¤é˜¶æ®µ
  - ç»‘å®šå‘¨æœŸåˆ™æ˜¯å°†è°ƒåº¦å†³ç­–åº”ç”¨äºé›†ç¾¤ä¸Šçš„è¿‡ç¨‹



### Kubernetes ä¸­çš„ Affinity Secheduling

#### Node Affinity

åŸºäº Pod å’Œ Node å…³ç³»çš„è°ƒåº¦ç­–ç•¥ï¼Œç§°ä¸º Node äº²å’Œåº¦

**ä½•æ—¶éœ€è¦ç”¨åˆ°Affinityè°ƒåº¦ï¼Ÿ**

- Pod çš„è¿è¡Œä¾èµ–äºç‰¹æ®Šç¡¬ä»¶ï¼Œä¾‹å¦‚ SSD æˆ– GPUï¼Œä½†è¿™äº›è®¾å¤‡ä»…éƒ¨åˆ†èŠ‚ç‚¹å…·å¤‡
- å…·æœ‰é«˜è®¡ç®—é‡è¦æ±‚çš„Podï¼Œä¹Ÿå¯èƒ½éœ€è¦é™åˆ¶è¿è¡Œåœ¨ç‰¹å®šçš„èŠ‚ç‚¹

**è®¾å®š Pod æ»¡è¶³èŠ‚ç‚¹äº²å’Œçš„æ–¹å¼**

- **Node Selector**

  - spec.nodeSelector
  - å®šå‘è°ƒåº¦æœºåˆ¶çš„ä¸€ç§å®ç°

  ```bash
  # å‡è®¾æœ‰ä¸€ä¸ªNodeï¼Œæ‰“äº†å¦‚ä¸‹æ ‡ç­¾
  kubectl label nodes node1 disktype=ssd
  ```

  ```yaml
  apiVersion: v1
  kind: Pod
  metadata:
    name: nginx-ssd
  spec:
    containers:
    - name: nginx
      image: nginx
    nodeSelector:
      disktype: ssd
  ```

- ****

  - spec.affinity.nodeAffinity
  - æ”¯æŒåŸºäºè½¯äº²å’Œå’Œç¡¬äº²å’Œä¸¤ç§é€»è¾‘æ¥å®ç°æ›´ç²¾ç»†çš„æ§åˆ¶

  - ç¡¬äº²å’Œï¼šå¿…é¡»æ»¡è¶³çš„äº²å’Œçº¦æŸï¼Œçº¦æŸè¯„ä¼°ä»…å‘ç”Ÿåœ¨è°ƒåº¦æœŸé—´
  - è½¯äº²å’Œï¼šæœ‰å€¾å‘æ€§çš„äº²å’Œçº¦æŸï¼Œä¸åŒçš„çº¦æŸæ¡ä»¶å­˜åœ¨ä¸åŒçš„æƒé‡ï¼Œçº¦æŸè¯„ä¼°åŒæ ·ä»…å‘ç”Ÿåœ¨è°ƒåº¦æœŸé—´



**ç¡¬äº²å’Œä¸è½¯äº²å’Œ**

Podä¸Nodeçš„äº²å’Œå…³ç³»å­˜åœ¨ä¸¤ç§çº¦æŸå¼ºåº¦

- **ç¡¬äº²å’Œ**ï¼šå¿…é¡»æ»¡è¶³çš„äº²å’Œçº¦æŸï¼Œçº¦æŸè¯„ä¼°ä»…å‘ç”Ÿåœ¨è°ƒåº¦æœŸé—´
  - **requiredDuringSchedulingIgnoredDuringExecution**
    - å¿…é¡»è°ƒåº¦è‡³æ»¡è¶³æ¡ä»¶çš„èŠ‚ç‚¹
- **è½¯äº²å’Œ**ï¼šæœ‰å€¾å‘æ€§çš„äº²å’Œçº¦æŸï¼Œä¸åŒçš„çº¦æŸæ¡ä»¶å­˜åœ¨ä¸åŒçš„æƒé‡ï¼Œçº¦æŸè¯„ä¼°åŒæ ·ä»…å‘ç”Ÿåœ¨è°ƒåº¦æœŸé—´
  - **preferredDuringSchedulingIgnoredDuringExecution**
    - ä¼˜å…ˆè°ƒåº¦è‡³æ›´ä¸ºæ»¡è¶³æ¡ä»¶ï¼ˆæƒé‡æ›´é«˜ï¼‰çš„èŠ‚ç‚¹

ç¤ºä¾‹ YAMLï¼šåŒæ—¶ä½¿ç”¨ä¸¤ç§ Node Affinity

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: affinity-pod
spec:
  containers:
  - name: nginx
    image: nginx
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:      # ç¡¬äº²å’Œ
        nodeSelectorTerms:        # èŠ‚ç‚¹é€‰æ‹©å™¨åˆ—è¡¨
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
      preferredDuringSchedulingIgnoredDuringExecution:     # è½¯äº²å’Œ 
      - weight: 1                 # ä¼˜é€‰é¡¹çš„æƒé‡ï¼Œè°ƒåº¦å™¨æ ¹æ®å¤šä¸ªä¼˜é€‰é¡¹æ‰“åˆ†
        preference:               # èŠ‚ç‚¹é€‰æ‹©å™¨
          matchExpressions:       # èŠ‚ç‚¹æ ‡ç­¾é€‰æ‹©å™¨è¡¨è¾¾å¼
          - key: zone             # é”®
            operator: In          # æ“ä½œç¬¦
            values:               # å€¼åˆ—è¡¨
            - zone-a
            - zone-b
```

**ğŸ” è§£è¯»ï¼š**

- `requiredDuringSchedulingIgnoredDuringExecution`ï¼š
  - è¡¨ç¤ºå¿…é¡»è°ƒåº¦åˆ°æœ‰æ ‡ç­¾ `disktype=ssd` çš„èŠ‚ç‚¹ã€‚
- `preferredDuringSchedulingIgnoredDuringExecution`ï¼š
  - è¡¨ç¤ºæœ€å¥½è°ƒåº¦åˆ° `zone` åœ¨ `zone-a` æˆ– `zone-b` çš„èŠ‚ç‚¹ï¼Œå¦‚æœæ²¡æœ‰ä¹Ÿæ²¡å…³ç³»ã€‚
- `matchExpressions` æ”¯æŒé«˜çº§é€»è¾‘åŒ¹é…ï¼Œä¼˜äºç®€å•çš„ `nodeSelector`ã€‚



**èŠ‚ç‚¹ä¸Šçš„é¢„å®šä¹‰æ ‡ç­¾**

- Kubernetes.io/hostname: èŠ‚ç‚¹åç§°
- beta.kubernetes.io/osï¼šæ“ä½œç³»ç»Ÿï¼Œv1.18ç‰ˆæœ¬å¼ƒç”¨
- beta.kubernetes.io/archï¼šå¹³å°æ¶æ„ç±»å‹ï¼Œv1.18ç‰ˆæœ¬å¼ƒç”¨
- kubernetes.io/osï¼šæ“ä½œç³»ç»Ÿ
- kubernetes.io/archï¼šå¹³å°æ¶æ„ç±»å‹
- topology.kubernetes.io/zoneï¼šå¯ç”¨åŒº
- topology.kubernetes.io/regionï¼šæ‰€æœ‰åŒºåŸŸ



**åŒ¹é…èŠ‚ç‚¹è¡¨è¾¾å¼ï¼ˆmatchExpressionsï¼‰æ”¯æŒæ“ä½œç¬¦**

- **In**ï¼šæŒ‡å®šçš„labelçš„å€¼å­˜åœ¨äºç»™å®šåˆ—è¡¨ä¸­
- **NotIn**: æŒ‡å®šçš„labelçš„å€¼æœªå­˜åœ¨äºç»™å®šåˆ—è¡¨ä¸­
- **Gt**ï¼šæŒ‡å®šçš„labelçš„å€¼å¤§äºç»™å®šå€¼
- **Lt**ï¼šæŒ‡å®šçš„labelçš„å€¼å°äºç»™å®šå€¼
- **Exists**ï¼šæŒ‡å®šlabelå­˜åœ¨äºèŠ‚ç‚¹ä¸Š
- **DoesNotExist**ï¼šæŒ‡å®šlabelæœªå­˜åœ¨äºèŠ‚ç‚¹ä¸Š



#### Pod Affinity å’Œ Anti Affinity

åŸºäºPodå’ŒPodé—´å…³ç³»çš„è°ƒåº¦ç­–ç•¥ï¼Œç§°ä¸º**Podäº²å’Œè°ƒåº¦ï¼ˆAffinityï¼‰**ï¼Œä»¥åŠ**Podåäº²å’Œè°ƒåº¦ï¼ˆAntiAffinityï¼‰**



**ä»€ä¹ˆæ˜¯ Pod äº²å’Œè°ƒåº¦ï¼Ÿ**

Pod äº²å’Œè°ƒåº¦æ˜¯ä¸€ç§ **æ ¹æ®å·²æœ‰ Pod çš„åˆ†å¸ƒï¼Œæ¥è°ƒåº¦æ–° Pod** çš„æœºåˆ¶ã€‚å®ƒå…è®¸ä½ è¡¨è¾¾â€œæˆ‘å¸Œæœ›ï¼ˆæˆ–å¿…é¡»ï¼‰å°†è¿™ä¸ª Pod å’ŒæŸäº›å…¶ä»–ç‰¹å®š Pod è°ƒåº¦åœ¨ä¸€èµ·ï¼ˆæˆ–è€…é¿å¼€ï¼‰â€ã€‚



**ä»€ä¹ˆæ˜¯æ‹“æ‰‘é”®ï¼ˆTopology Keyï¼‰ï¼Ÿ**

æ‹“æ‰‘é”®æ˜¯ä¸€ä¸ª **Node æ ‡ç­¾çš„é”®å**ï¼Œç”¨äºå‘Šè¯‰è°ƒåº¦å™¨ï¼šåœ¨å“ªç§ç»´åº¦ï¼ˆæ¯”å¦‚èŠ‚ç‚¹ã€æœºæ¶ã€åŒºåŸŸï¼‰ä¸Šè¿›è¡Œåˆ†ç»„ã€‚

å¸¸è§æ‹“æ‰‘é”®æœ‰ï¼š

| æ‹“æ‰‘é”®ï¼ˆTopology Keyï¼‰          | è¯´æ˜                 |
| ------------------------------- | -------------------- |
| `kubernetes.io/hostname`        | å•ä¸ªèŠ‚ç‚¹ï¼ˆåŒä¸€ä¸»æœºï¼‰ |
| `topology.kubernetes.io/zone`   | åŒä¸€å¯ç”¨åŒº           |
| `topology.kubernetes.io/region` | åŒä¸€åœ°åŸŸ             |



**ä»€ä¹ˆæ˜¯æ‹“æ‰‘åŸŸï¼ˆTopology Domainï¼‰ï¼Ÿ**

æ‹“æ‰‘åŸŸæ˜¯æŒ‡ **å…·æœ‰ç›¸åŒæ‹“æ‰‘é”®å€¼çš„ä¸€ç»„èŠ‚ç‚¹**ï¼Œæ¯”å¦‚ï¼š

- æ‰€æœ‰ `kubernetes.io/hostname=worker-1` çš„èŠ‚ç‚¹ â†’ åŒä¸€ä¸ªæ‹“æ‰‘åŸŸï¼ˆå³å•èŠ‚ç‚¹ï¼‰
- æ‰€æœ‰ `topology.kubernetes.io/zone=cn-east-1a` çš„èŠ‚ç‚¹ â†’ å±äºåŒä¸€ä¸ªâ€œå¯ç”¨åŒºâ€æ‹“æ‰‘åŸŸ



**Podäº²å’Œè°ƒåº¦**

- å¿…é¡»åŒæŸäº›Podè°ƒåº¦è‡³åŒä¸€ä½ç½®ï¼ˆæ‹“æ‰‘åŸŸï¼‰
  - **requiredDuringSchedulingIgnoredDuringExecution**
- ä¼˜å…ˆåŒæŸäº›Podè°ƒåº¦è‡³åŒä¸€ä½ç½®
  - **preferedDuringSchedulingIgnoredDuringExecution**



**ç¤ºä¾‹è®²è§£**

**1ï¸âƒ£ `requiredDuringSchedulingIgnoredDuringExecution` ç¤ºä¾‹**

**åœºæ™¯ï¼šè¦æ±‚ Pod å¿…é¡»éƒ¨ç½²åœ¨ä¸ â€œapp=webâ€ æ ‡ç­¾çš„ Pod ç›¸åŒçš„èŠ‚ç‚¹ä¸Šã€‚**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - web
          topologyKey: kubernetes.io/hostname      # å¿…é€‰é¡¹ï¼Œè°ƒèŠ‚é¢—ç²’åº¦ï¼ŒèŠ‚ç‚¹çº§æˆ–åŒºåŸŸçº§æˆ–åœ°åŒºçº§
  containers:
    - name: nginx
      image: nginx
```

**è¯´æ˜ï¼š**

- `labelSelector`ï¼šé€‰æ‹©å·²ç»å­˜åœ¨çš„ Podï¼Œæ ‡ç­¾ä¸º `app=web`
- `topologyKey: kubernetes.io/hostname`ï¼šè°ƒåº¦åˆ°è¿è¡Œè¿™ä¸ª Pod çš„ç›¸åŒèŠ‚ç‚¹
- æ˜¯ç¡¬æ€§è§„åˆ™ï¼šå¦‚æœæ²¡æœ‰ç¬¦åˆè¦æ±‚çš„èŠ‚ç‚¹ï¼ŒPod æ— æ³•è°ƒåº¦



**2ï¸âƒ£ `preferredDuringSchedulingIgnoredDuringExecution` ç¤ºä¾‹**

**åœºæ™¯ï¼šå¸Œæœ› Pod å’Œ â€œapp=webâ€ æ ‡ç­¾çš„ Pod å°½é‡è°ƒåº¦åœ¨åŒä¸€å¯ç”¨åŒºä¸­ã€‚**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  affinity:
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution: # ä¸æ˜¯å¼ºåˆ¶ï¼Œå¦‚æœæ²¡æœ‰ä¹Ÿèƒ½è°ƒåº¦
        - weight: 100            # weight: è¶Šå¤§ä»£è¡¨ä¼˜å…ˆçº§è¶Šé«˜ï¼ˆ1~100ï¼‰
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app
                  operator: In
                  values:
                    - web
            topologyKey: topology.kubernetes.io/zone # è¡¨ç¤ºå¸Œæœ›ä¸ web Pod åœ¨åŒä¸€ä¸ªå¯ç”¨åŒº
  containers:
    - name: nginx
      image: nginx
```



**ä»€ä¹ˆæ˜¯ Pod åäº²å’Œè°ƒåº¦ï¼Ÿ**

**é¿å…**æŸä¸ª Pod å’Œå…¶å®ƒå…·æœ‰ç‰¹å®šæ ‡ç­¾çš„ Pod è¢«è°ƒåº¦åˆ° **åŒä¸€ä¸ªæ‹“æ‰‘åŸŸï¼ˆæ¯”å¦‚ Nodeã€Zoneï¼‰** ä¸Šã€‚æ¢å¥è¯è¯´ï¼Œå®ƒæ˜¯ä¸€ç§â€œ**æˆ‘ä¸å¸Œæœ›å’ŒæŸç±» Pod æ”¾åœ¨ä¸€èµ·**â€çš„è°ƒåº¦ç­–ç•¥ï¼Œç›®çš„æ˜¯å¢å¼º**é«˜å¯ç”¨æ€§å’Œèµ„æºéš”ç¦»æ€§**ã€‚



**æ ¸å¿ƒå­—æ®µç»“æ„**

Pod åäº²å’Œè°ƒåº¦çš„ YAML é…ç½®ä½äº `.spec.affinity.podAntiAffinity` å­—æ®µä¸‹ï¼Œç»“æ„å¦‚ä¸‹

```yaml
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:    # å¼ºåˆ¶æ€§çº¦æŸ
      - labelSelector:
          matchLabels:
            app: my-app
        topologyKey: kubernetes.io/hostname
    preferredDuringSchedulingIgnoredDuringExecution:   # éå¼ºåˆ¶æ€§å»ºè®®
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: my-app
          topologyKey: kubernetes.io/hostname
```



**åº”ç”¨åœºæ™¯**

| åœºæ™¯             | è¯´æ˜                                                   |
| ---------------- | ------------------------------------------------------ |
| å¤šå‰¯æœ¬æœåŠ¡é«˜å¯ç”¨ | é¿å…å‰¯æœ¬éƒ½è°ƒåº¦åˆ°åŒä¸€ä¸ªèŠ‚ç‚¹ï¼Œä¸€æ—¦èŠ‚ç‚¹æ•…éšœï¼ŒæœåŠ¡å…¨éƒ¨ç˜«ç—ª |
| å‡å°‘çƒ­ç‚¹ç«äº‰     | åˆ†æ•£è®¡ç®—èµ„æºã€I/O æˆ–ç½‘ç»œå¸¦å®½çš„äº‰ç”¨                     |
| å®‰å…¨éš”ç¦»         | é¿å…é«˜æƒé™åº”ç”¨å’Œä½æƒé™åº”ç”¨åœ¨åŒä¸€èŠ‚ç‚¹è¿è¡Œ               |
| å¤šç§Ÿæˆ·æ¶æ„       | ä¸åŒç§Ÿæˆ·éƒ¨ç½²åœ¨ä¸åŒèŠ‚ç‚¹æˆ–åŒºåŸŸï¼Œå¢å¼ºå®‰å…¨æ€§               |



**å®æˆ˜å»ºè®®**

| ç±»å‹                                              | ç”¨æ³•å»ºè®®                                   |
| ------------------------------------------------- | ------------------------------------------ |
| `requiredDuringSchedulingIgnoredDuringExecution`  | å¤šå‰¯æœ¬ç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨ï¼Œä¿è¯æœ€å°æ•…éšœå½±å“é¢ |
| `preferredDuringSchedulingIgnoredDuringExecution` | å¼€å‘ç¯å¢ƒã€èµ„æºæ•æ„Ÿç¯å¢ƒä¼˜é€‰ï¼Œé¿å…è°ƒåº¦å¤±è´¥   |



#### Pod Topology Spread Constraint

**ä»€ä¹ˆæ˜¯ Pod Topology Spread Constraintsï¼Ÿ**

Pod æ‹“æ‰‘æ‰©å±•çº¦æŸï¼ˆTopology Spread Constraintsï¼Œç®€ç§° TSCï¼‰æ˜¯ Kubernetes ä¸­ä¸€ç§ç”¨äºæ§åˆ¶ Pod **å‰¯æœ¬åœ¨é›†ç¾¤ä¸­çš„åˆ†å¸ƒ**çš„æœºåˆ¶

```ABAP
ç›®çš„æ˜¯ï¼šåœ¨ä¸åŒçš„æ‹“æ‰‘åŸŸä¹‹é—´å‡åŒ€åˆ†å¸ƒ Podï¼Œæå‡é«˜å¯ç”¨æ€§ã€é¿å…å•ç‚¹é›†ä¸­ã€‚
```

å®ƒæ¯” PodAffinity/AntiAffinity æ›´çµæ´»ã€ç²¾ç»†ã€å¯æ§ã€‚



**åŸºæœ¬è¯­æ³•ç»“æ„**

TSC é…ç½®åœ¨ Pod çš„ `.spec.topologySpreadConstraints` å­—æ®µä¸­

```yaml
topologySpreadConstraints:
  - maxSkew: 1                                    # æŒ‡ Pod åœ¨ä¸åŒæ‹“æ‰‘åŸŸä¹‹é—´çš„æœ€å¤šå·®å¼‚æ•°é‡
    topologyKey: topology.kubernetes.io/zone      # æ‹“æ‰‘é”®ï¼Œè¡¨ç¤ºåˆ†å¸ƒç»´åº¦ï¼Œå¦‚ kubernetes.io/hostnameã€                                                                 topology.kubernetes.io/zone ç­‰
    whenUnsatisfiable: ScheduleAnyway             # è°ƒåº¦ä¸å¯æ»¡è¶³çº¦æŸæ—¶çš„è¡Œä¸ºï¼Œå€¼ä¸º DoNotScheduleï¼ˆç¡¬ç­–ç•¥ï¼‰æˆ–                                                           ScheduleAnywayï¼ˆè½¯ç­–ç•¥ï¼‰
    labelSelector:                                # ç”¨æ¥åŒ¹é…è¦åˆ†å¸ƒçš„ Podï¼Œé€šå¸¸ä¸ºæŸä¸ª Deployment çš„ Label
      matchLabels:
        app: web
```



**å®Œæ•´ç¤ºä¾‹**

å‡è®¾å¸Œæœ› `app=web` çš„ Pod å°½é‡å‡åŒ€åˆ†å¸ƒåœ¨æ‰€æœ‰èŠ‚ç‚¹ï¼ˆNodeï¼‰ä¸Šï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 6
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app: web
      containers:
        - name: nginx
          image: nginx:alpine
```

è¡¨ç¤ºï¼š

- Pod åº”å‡åŒ€åˆ†å¸ƒåœ¨ä¸åŒä¸»æœºï¼ˆhostnameï¼‰ä¸Šã€‚
- å¦‚æœä¸èƒ½æ»¡è¶³ maxSkew = 1 çš„åˆ†å¸ƒï¼Œåˆ™æ‹’ç»è°ƒåº¦ã€‚



**çœŸå®åº”ç”¨åœºæ™¯**

| åœºæ™¯           | æè¿°                                         |
| -------------- | -------------------------------------------- |
| é«˜å¯ç”¨å¾®æœåŠ¡   | å°†å‰¯æœ¬å°½é‡åˆ†å¸ƒåœ¨ä¸åŒèŠ‚ç‚¹æˆ– zone ä¸­           |
| å¤šç§Ÿæˆ·éš”ç¦»     | é¿å…æŸä¸ªç§Ÿæˆ·é›†ä¸­åœ¨ä¸€ä¸ª Node ä¸Šé€ æˆâ€œå™ªå£°â€å½±å“ |
| èµ„æºåˆ©ç”¨ç‡å‡è¡¡ | åœ¨èµ„æºåˆ©ç”¨ä¸å‡æ—¶ï¼Œé€šè¿‡è°ƒåº¦æ‰©æ•£è´Ÿè½½           |



#### Taints ä¸ Tolerations

**ä»€ä¹ˆæ˜¯ Taints ä¸ Tolerationsï¼Ÿ**

**Taintsï¼ˆæ±¡ç‚¹ï¼‰** æ˜¯å¯¹ Node çš„æ ‡è®°ï¼Œç”¨æ¥é˜»æ­¢ä¸æ»¡è¶³æ¡ä»¶çš„ Pod è¢«è°ƒåº¦ä¸Šæ¥ã€‚

**Tolerationsï¼ˆå®¹å¿ï¼‰** æ˜¯ Pod çš„å£°æ˜ï¼Œç”¨äºè¡¨æ˜â€œæˆ‘å¯ä»¥å®¹å¿å“ªäº›æ±¡ç‚¹â€ã€‚

```ABAP
ä½œç”¨ï¼šç”¨æ¥å®ç°ã€ŒèŠ‚ç‚¹é€‰æ‹©æ€§æ¥æ”¶ Podã€çš„èƒ½åŠ›ï¼Œæ˜¯ åå‘è°ƒåº¦æ§åˆ¶æœºåˆ¶ã€‚
```



**Taint çš„ç»“æ„**

Taint æ˜¯åŠ åœ¨ Node ä¸Šçš„ï¼Œæ ¼å¼å¦‚ä¸‹

```bash
key=value:effect

# keyï¼š   é”®
# valueï¼š å€¼
# effectï¼šæ•ˆæœï¼ˆè¡Œä¸ºï¼‰
```

`**effect` å¯é€‰å€¼ï¼š**

| effect å€¼          | å«ä¹‰                               |
| ------------------ | ---------------------------------- |
| `NoSchedule`       | ä¸å…è®¸è°ƒåº¦ä¸Šæ¥                     |
| `PreferNoSchedule` | å°½é‡åˆ«è°ƒåº¦                         |
| `NoExecute`        | è°ƒåº¦ä¸Šæ¥çš„ Pod ä¼šè¢«é©±é€ï¼ˆEvictedï¼‰ |



**Taint ç¤ºä¾‹ï¼ˆæ·»åŠ åœ¨ Node ä¸Šï¼‰**

ä»¥ä¸‹æ˜¯å‡ ç§å¸¸ç”¨çš„ Taint è®¾ç½®æ–¹å¼

ç¤ºä¾‹ 1ï¼šä¸ºèŠ‚ç‚¹æ·»åŠ å¼ºåˆ¶è°ƒåº¦é™åˆ¶ï¼ˆNoScheduleï¼‰

```bash
kubectl taint nodes node1 dedicated=gitlab:NoSchedule
```

è¯´æ˜ï¼š

- ç»™ `node1` æ·»åŠ ä¸€ä¸ª Taintï¼š
  - `key=dedicated`
  - `value=gitlab`
  - `effect=NoSchedule`
- æ„æ€æ˜¯ï¼šä¸å…è®¸è°ƒåº¦ä»»ä½• Podï¼Œ**é™¤éå®ƒå£°æ˜äº†å¯¹åº”çš„ Toleration**ã€‚



**ç¤ºä¾‹ 2ï¼šæ·»åŠ è½¯é™åˆ¶ï¼ˆPreferNoScheduleï¼‰**

```bash
kubectl taint nodes node2 test=true:PreferNoSchedule
```

è¯´æ˜ï¼š

- `PreferNoSchedule` è¡¨ç¤º **å°½é‡ä¸è°ƒåº¦**ï¼Œä½†è°ƒåº¦å™¨å¯ä»¥å¿½ç•¥ã€‚



**ç¤ºä¾‹ 3ï¼šæ·»åŠ å¼ºåˆ¶é©±é€è§„åˆ™ï¼ˆNoExecuteï¼‰**

```bash
kubectl taint nodes node3 quarantine=virus:NoExecute
```

è¯´æ˜ï¼š

- æ‰€æœ‰æ²¡æœ‰å®¹å¿è¿™ä¸ª `taint` çš„ Pod ä¼šè¢«é©±é€ï¼ˆEvictedï¼‰ã€‚
- æ–° Pod ä¹Ÿä¸èƒ½è°ƒåº¦è¿›æ¥ã€‚



**ç¤ºä¾‹ 4ï¼šåˆ é™¤ Taintï¼ˆç§»é™¤æ±¡ç‚¹ï¼‰**

```bash
kubectl taint nodes node1 dedicated:NoSchedule-
```

è¯´æ˜ï¼š

- åˆ é™¤ `dedicated=...:NoSchedule` è¿™ä¸ªæ±¡ç‚¹ã€‚
- æ³¨æ„æœ€åçš„ `-` æ˜¯å¿…é¡»çš„ï¼Œè¡¨ç¤º **ç§»é™¤æ“ä½œ**ã€‚



**æŸ¥çœ‹èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Taint**

```bash
kubectl describe node node1 | grep Taint
```



**Toleration çš„ç»“æ„**

```yaml
tolerations:
- key: "key1"                      # å®¹å¿çš„æ±¡ç‚¹é”®
  operator: "Equal"
  value: "value1"                  # å®¹å¿çš„å€¼
  effect: "NoSchedule"             # éœ€è¦åŒ¹é…çš„æ±¡ç‚¹è¡Œä¸º
  tolerationSeconds: 3600          # å®¹å¿æ—¶é—´ï¼Œä»…ç”¨äº NoExecute
```



**å®Œæ•´ YAML ç¤ºä¾‹**

Pod YAML ç¤ºä¾‹ï¼ˆå…·æœ‰ Tolerationï¼‰

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
  - name: nginx
    image: nginx
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "gitlab"
    effect: "NoSchedule"
    
# ç‰¹æ®Šæƒ…å†µ
# è‹¥æŸä¸ªå®¹å¿åº¦çš„keyä¸ºç©ºï¼Œä¸”operatorä¸ºExistsï¼Œè¡¨ç¤ºå…¶å¯ä»¥å®¹å¿ä»»æ„æ±¡ç‚¹
# è‹¥effectä¸ºç©ºï¼Œåˆ™å¯ä»¥åŒ¹é…æ‰€æœ‰é”®åç›¸åŒçš„æ±¡ç‚¹
```



**è°ƒåº¦è¡Œä¸ºåˆ†æ**

1. å¦‚æœ Node ä¸Šæœ‰æ±¡ç‚¹ï¼Œè€Œ Pod æ²¡æœ‰ç›¸åº” Toleration â†’ âŒ ä¸ä¼šè°ƒåº¦
2. å¦‚æœ Node ä¸Šæœ‰æ±¡ç‚¹ï¼Œè€Œ Pod æœ‰å¯¹åº” Toleration â†’ âœ… å…è®¸è°ƒåº¦
3. å¦‚æœ Pod å®¹å¿çš„æ˜¯ `NoExecute`ï¼Œä¸€æ—¦ä¸æ»¡è¶³ `tolerationSeconds` â†’ Pod ä¼šè¢«é©±é€



èŠ‚ç‚¹çŠ¶æ€ç›¸å…³çš„æŸäº›æ¡ä»¶ï¼ˆNode Conditionsï¼‰ä¸ºçœŸæ—¶ï¼ŒèŠ‚ç‚¹æ§åˆ¶å™¨ä¼šè‡ªåŠ¨ç»™èŠ‚ç‚¹æ·»åŠ ä¸€ä¸ªæ±¡ç‚¹

- node.kubernetes.io/not-readyï¼šèŠ‚ç‚¹æœªå°±ç»ªï¼Œå³èŠ‚ç‚¹çŠ¶å†µReadyçš„å€¼ä¸ºâ€œFalseâ€
- node.kubernetes.io/unreachableï¼šèŠ‚ç‚¹æ§åˆ¶å™¨è®¿é—®ä¸åˆ°èŠ‚ç‚¹ï¼Œå³èŠ‚ç‚¹çŠ¶å†µReadçš„å€¼ä¸º"Unknown"
- node.kubernetes.io/memory-pressureï¼šèŠ‚ç‚¹å†…å­˜èµ„æºç´§å¼ 
- node.kubernetes.io/disk-pressureï¼šèŠ‚ç‚¹ç£ç›˜ç©ºé—´ç´§å¼ 
- node.kubernetes.io/pid-pressureï¼šèŠ‚ç‚¹PIDèµ„æºç´§å¼ 
- node.kubernetes.io/network-unavailableï¼šèŠ‚ç‚¹ç½‘ç»œä¸å¯ç”¨
- node.kubernetes.io/unschedulableï¼šèŠ‚ç‚¹ä¸å¯ç”¨äºè°ƒåº¦
- node.cloudprovider.kubernetes.io/uninitializedï¼šcloud provider å°šæœªè¿›è¡Œåˆå§‹åŒ–



## å®é™…ç”Ÿäº§æ¡ˆä¾‹1 â€” ä¸šåŠ¡è¿ç§»

### ä¸šåŠ¡å®¹å™¨åŒ–æ¡ˆä¾‹ä¹‹ä¸€ï¼šä¸šåŠ¡è§„åˆ’åŠé•œåƒåˆ†å±‚æ„å»º

![image-20250419122548232](../markdown_img/image-20250419122548232.png)

![image-20250419122822891](../markdown_img/image-20250419122822891.png)



è¿™ç§â€œåˆ†å±‚å¤ç”¨ + è§„èŒƒåŒ–æ„å»ºâ€çš„é•œåƒæ¶æ„è®¾è®¡ï¼Œæœ‰éå¸¸å¤šçš„ **å®é™…å¥½å¤„**ï¼Œå°¤å…¶é€‚åˆä¼ä¸šçº§ã€DevOps è§„èŒƒçš„ç¯å¢ƒ



#### ä¼˜åŠ¿è§£æ

1ï¸âƒ£ **é•œåƒåˆ†å±‚å¤ç”¨ï¼Œæ˜¾è‘—æå‡æ„å»ºæ•ˆç‡**

- æ‰€æœ‰é•œåƒåŸºäºå®˜æ–¹é•œåƒï¼ˆå¦‚ Ubuntu/CentOSï¼‰å¼€å§‹ç»Ÿä¸€æ„å»ºã€‚
- å†æŠ½è±¡å‡º â€œ**ç»Ÿä¸€åŸºç¡€é•œåƒ**â€ï¼ˆå¦‚å«åŸºç¡€å·¥å…·ã€é…ç½®ã€å®‰å…¨ç»„ä»¶ç­‰ï¼‰ï¼Œè®©æ‰€æœ‰ä¸šåŠ¡é•œåƒæ„å»ºåŸºäºå®ƒã€‚
- **Pythonã€JDK8/11ã€Goã€Nginx** ç­‰æ„å»ºç¯å¢ƒåªéœ€è¦æ„å»ºä¸€æ¬¡ï¼Œå¤šä¸ªé¡¹ç›®å¤ç”¨ï¼š
  - æ¯”å¦‚ï¼šJDK11 + springåŸºç¡€é•œåƒ â†’ å¤šä¸ª Spring é¡¹ç›®å…±äº«ã€‚
  - é•œåƒæ„å»ºæ—¶ **Docker åˆ†å±‚ç¼“å­˜ç”Ÿæ•ˆ**ï¼Œåªæ”¹ä¸šåŠ¡ä»£ç å°±ä¸ä¼šé‡å»ºåŸºç¡€é•œåƒã€‚



2ï¸âƒ£ **æ„å»ºé“¾æ¸…æ™°ã€ä¾èµ–æ”¶æ•›**

- ä½ å¯ä»¥é€šè¿‡ Dockerfile `FROM` è·¯å¾„æ¸…æ¥šè¿½è¸ªåˆ°æ¯ä¸ªé•œåƒçš„ç¥–å…ˆé•œåƒã€‚
- è¿™æœ‰åˆ©äºï¼š
  - å®‰å…¨æ¼æ´ç»Ÿä¸€æ‰«æå’Œä¿®å¤ã€‚
  - ä¾èµ–å‡çº§æ—¶ç»Ÿä¸€æ›´æ–°åº•å±‚é•œåƒï¼Œä¸ç”¨æŒ¨ä¸ªå¤„ç†ä¸Šå±‚æœåŠ¡ã€‚



3ï¸âƒ£ **å¿«é€Ÿå‘å¸ƒä¸éƒ¨ç½²**

- Harbor é•œåƒä»“åº“ç¼“å­˜æ‰€æœ‰é•œåƒå±‚ï¼Œåœ¨ Kubernetes èŠ‚ç‚¹æ‹‰å–æ—¶ï¼š
  - å¦‚æœæŸå±‚é•œåƒå·²æœ‰ï¼ˆå¦‚åŸºç¡€å±‚ï¼‰ï¼Œåªéœ€è¦æ‹‰å–æœ€ä¸Šå±‚æ”¹åŠ¨éƒ¨åˆ† â†’ åŠ å¿«æ‹‰å–é€Ÿåº¦ã€‚
- èŠ‚çœå¸¦å®½å’Œæ—¶é—´ï¼Œå°¤å…¶é€‚ç”¨äº CI/CD é«˜é¢‘æ„å»ºã€‚



4ï¸âƒ£ **åˆ†å·¥åä½œæ›´æ¸…æ™°**

- è¿ç»´/å¹³å°å›¢é˜Ÿç»´æŠ¤åŸºç¡€é•œåƒï¼ˆæ¯”å¦‚ JDKã€Pythonã€Nginx å±‚ï¼‰ã€‚
- å¼€å‘å›¢é˜Ÿåªè´Ÿè´£ä¸šåŠ¡é•œåƒçš„ `Dockerfile`ï¼Œå…³æ³¨æœåŠ¡é€»è¾‘å³å¯ã€‚



5ï¸âƒ£ **å¯¹æ¥ CI/CD æ›´é«˜æ•ˆ**

- CI åªéœ€ build æœ€ä¸Šå±‚é•œåƒå³å¯ï¼Œæ„å»ºé“¾æ¡çŸ­ã€é€Ÿåº¦å¿«ã€‚
- æ”¯æŒ â€œå¤šé˜¶æ®µæ„å»ºâ€ å’Œ â€œé•œåƒç˜¦èº«â€



#### æ„å»ºåº•å±‚é•œåƒ

```bash
[root@worker-01 centos]# ls
build-command.sh  CentOS-repo.repo  Dockerfile  filebeat-7.6.2-x86_64.rpm

[root@worker-01 centos]#cat Dockerfile 
#è‡ªå®šä¹‰Centos åŸºç¡€é•œåƒ
FROM harbor.mysticalrecluse.com/myserver/centos:7.9.2009 
MAINTAINER Mystical mysticalrecluse@gmail.com

ADD filebeat-7.6.2-x86_64.rpm /tmp
RUN rm -rf /etc/yum.repos.d/
ADD CentOS-repo.repo /etc/yum.repos.d/
RUN yum makecache && yum install -y /tmp/filebeat-7.6.2-x86_64.rpm vim wget tree  lrzsz gcc gcc-c++ automake pcre pcre-devel zlib zlib-devel openssl openssl-devel iproute net-tools iotop &&  rm -rf /etc/localtime /tmp/filebeat-7.6.2-x86_64.rpm && ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && useradd  www -u 2020 && useradd nginx -u 2021

[root@worker-01 centos]#cat build-command.sh 
#!/bin/bash
nerdctl build -t  harbor.mysticalrecluse.com/baseimages/mystical-centos-base:7.9.2009 .

nerdctl push harbor.mysticalrecluse.com/baseimages/mystical-centos-base:7.9.2009

# æ‰§è¡Œè„šæœ¬ï¼Œæ„å»ºé•œåƒå¹¶ä¸Šä¼ harbor
[root@worker-01 centos]#bash build-command.sh
```



### ä¸šåŠ¡å®¹å™¨åŒ–æ¡ˆä¾‹ä¹‹äºŒï¼šNginx+Tomcat+NFSå®ç°åŠ¨é™åˆ†ç¦»

![image-20250419160043736](../markdown_img/image-20250419160043736.png)



#### å…¬å…±é•œåƒæ„å»º

```bash
# è®°å¾—æå‰é…ç½®å¥½nfsçš„åŠ¨æ€ç½®å¤‡
[root@worker-01 pub-images]# ls
jdk-1.8.212  nginx-base  nginx-base-wordpress  tomcat-base-8.5.43

[root@worker-01 pub-images]#cd jdk-1.8.212/

[root@worker-01 jdk-1.8.212]#ls
build-command.sh  Dockerfile  jdk-8u212-linux-x64.tar.gz  profile

[root@worker-01 jdk-1.8.212]#cat Dockerfile 
#JDK Base Image
FROM harbor.mysticalrecluse.com/baseimages/mystical-centos-base:7.9.2009

MAINTAINER Mystical "mysticalrecluse@gmail.com"


ADD jdk-8u212-linux-x64.tar.gz /usr/local/src/
RUN ln -sv /usr/local/src/jdk1.8.0_212 /usr/local/jdk
ADD profile /etc/profile


ENV JAVA_HOME /usr/local/jdk
ENV JRE_HOME $JAVA_HOME/jre
ENV CLASSPATH $JAVA_HOME/lib/:$JRE_HOME/lib/
ENV PATH $PATH:$JAVA_HOME/bin

[root@worker-01 jdk-1.8.212]#cat build-command.sh 
#!/bin/bash
nerdctl build -t harbor.mysticalrecluse.com/pub-images/jdk-base:v8.212  .
sleep 1
nerdctl push harbor.mysticalrecluse.com/pub-images/jdk-base:v8.212

# åœ¨å¦ä¸€ä¸ªä¸»æœºä¸Šï¼Œæµ‹è¯•é•œåƒçš„javaæ˜¯å¦æ­£ç¡®
[root@master-01 ~]#ssh haproxy1
[root@haproxy1 ~]#docker login harbor.mysticalrecluse.com
Authenticating with existing credentials...
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded

[root@haproxy1 ~]#docker pull  harbor.mysticalrecluse.com/pub-images/jdk-base:v8.212
[root@haproxy1 ~]#docker run -it --rm harbor.mysticalrecluse.com/pub-images/jdk-base:v8.212 bash
# æ£€æŸ¥javaç¯å¢ƒæ˜¯å¦æ­£å¸¸
[root@6674b5290219 /]# java -version
java version "1.8.0_212"
Java(TM) SE Runtime Environment (build 1.8.0_212-b10)
Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)

# æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æˆåŠŸåˆ›å»º
[root@6674b5290219 /]# id nginx
uid=2021(nginx) gid=2021(nginx) groups=2021(nginx)

# åœ¨jdké•œåƒçš„åŸºç¡€ä¸Šï¼Œæ„å»ºtomcaté•œåƒ
[root@worker-01 tomcat-base-8.5.43]#ls
apache-tomcat-8.5.43.tar.gz  build-command.sh  Dockerfile

[root@worker-01 tomcat-base-8.5.43]#cat Dockerfile 
#Tomcat 8.5.43åŸºç¡€é•œåƒ
FROM harbor.mysticalrecluse.com/pub-images/jdk-base:v8.212

MAINTAINER mystical "mysticalrecluse@gmail.com"

RUN mkdir /apps /data/tomcat/webapps /data/tomcat/logs -pv 
ADD apache-tomcat-8.5.43.tar.gz  /apps
RUN useradd tomcat -u 2022 && ln -sv /apps/apache-tomcat-8.5.43 /apps/tomcat && chown -R tomcat.tomcat /apps /data -R

[root@worker-01 tomcat-base-8.5.43]#cat build-command.sh 
#!/bin/bash
nerdctl build -t harbor.mysticalrecluse.com/pub-images/tomcat-base:v8.5.43  .
sleep 3
nerdctl push  harbor.mysticalrecluse.com/pub-images/tomcat-base:v8.5.43

# æ£€æŸ¥tomcaté•œåƒæ˜¯å¦æ­£å¸¸
[root@haproxy1 ~]#docker run -it --rm -p 8080:8080 harbor.mysticalrecluse.com/pub-images/tomcat-base:v8.5.43 bash
[root@2290a2e9187e /]# cd /apps/tomcat/
[root@2290a2e9187e tomcat]# bash bin/catalina.sh start
[root@2290a2e9187e tomcat]# ss -nlt
State       Recv-Q Send-Q Local Address:Port               Peer Address:Port              
LISTEN      0      100       [::]:8009                  [::]:*                  
LISTEN      0      100       [::]:8080                  [::]:*      # tomcatæˆåŠŸå¯åŠ¨


# æ‰“ä¸šåŠ¡é•œåƒ
[root@worker-01 ~]# cd /opt/k8s-data/dockerfile/web/magedu
[root@worker-01 magedu]#cd tomcat-app1/
[root@worker-01 tomcat-app1]#ls
app1.tar.gz       Dockerfile                 myapp
build-command.sh  filebeat-7.5.1-x86_64.rpm  run_tomcat.sh
catalina.sh       filebeat.yml               server.xml

# ç”Ÿäº§ä¸­ï¼Œè¿™ä¸ªè„šæœ¬é€šå¸¸ç”±å¼€å‘æä¾›
[root@worker-01 tomcat-app1]#cat run_tomcat.sh 
#!/bin/bash
#echo "nameserver 223.6.6.6" > /etc/resolv.conf
#echo "192.168.7.248 k8s-vip.example.com" >> /etc/hosts

#/usr/share/filebeat/bin/filebeat -e -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat &
su - nginx -c "/apps/tomcat/bin/catalina.sh start"
tail -f /etc/hosts

[root@worker-01 tomcat-app1]#cat Dockerfile 
#tomcat web1
FROM harbor.mysticalrecluse.com/pub-images/tomcat-base:v8.5.43 

ADD catalina.sh /apps/tomcat/bin/catalina.sh
ADD server.xml /apps/tomcat/conf/server.xml
#ADD myapp/* /data/tomcat/webapps/myapp/
ADD app1.tar.gz /data/tomcat/webapps/myapp/
ADD run_tomcat.sh /apps/tomcat/bin/run_tomcat.sh
#ADD filebeat.yml /etc/filebeat/filebeat.yml 
RUN chown  -R nginx.nginx /data/ /apps/
#ADD filebeat-7.5.1-x86_64.rpm /tmp/
#RUN cd /tmp && yum localinstall -y filebeat-7.5.1-amd64.deb

EXPOSE 8080 8443

CMD ["/apps/tomcat/bin/run_tomcat.sh"]

[root@worker-01 tomcat-app1]# vim build-command.sh
#!/bin/bash
TAG=$1
nerdctl build -t  harbor.mysticalrecluse.com/myserver/tomcat-app1:${TAG} .
sleep 3
nerdctl push  harbor.mysticalrecluse.com/myserver/tomcat-app1:${TAG}

# æ‰“ä¸šåŠ¡é•œåƒ
[root@worker-01 tomcat-app1]#bash build-command.sh v1

# éªŒè¯æ–°æ‰“çš„ä¸šåŠ¡é•œåƒ
[root@haproxy1 ~]#docker run -it -d --rm -p 8080:8080 harbor.mysticalrecluse.com/myserver/tomcat-app1:v1
a8f682fcf70a722ccd47d4bc6b780c91677318a239b2f9b2790deecbe1ae8516

[root@haproxy1 ~]#curl 10.0.0.209:8080/myapp/index.html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Magedu é—¨æˆ·ç½‘ç«™</title>
</head>
<body>
<h1>magedu linux40 v111111111111</h1>
<h1>magedu linux40 v222222222222</h1>
<h1>magedu linux40 v333333333333</h1>
<h1>magedu linux40 v444444444444</h1>
<h1>magedu linux40 v555555555555</h1>
<h1>magedu linux40 v666666666666</h1>
<h1>magedu linux40 v777777777777</h1>
<h1>magedu linux40 v888888888888</h1>
<h1>magedu linux40 v999999999999</h1>
<h1>magedu linux40 v100000000000</h1>
<h1>magedu linux40 v111111111111</h1>
<h1>magedu linux40 v222222222222</h1>
</body>
</html>

# ä¸šåŠ¡é•œåƒæˆåŠŸ

# é•œåƒæ‰“å®Œåï¼Œåˆ›å»ºyamlæ–‡ä»¶
[root@master-01 ~]#kubectl create ns proc-test
[root@worker-01 tomcat-app1]#cat tomcat-app1.yaml 
kind: Deployment
#apiVersion: extensions/v1beta1
apiVersion: apps/v1
metadata:
  labels:
    app: magedu-tomcat-app1-deployment-label
  name: magedu-tomcat-app1-deployment
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: magedu-tomcat-app1-selector
  template:
    metadata:
      labels:
        app: magedu-tomcat-app1-selector
    spec:
      containers:
      - name: magedu-tomcat-app1-container
        image: harbor.mysticalrecluse.com/myserver/tomcat-app1:v1
        #command: ["/apps/tomcat/bin/run_tomcat.sh"]
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          protocol: TCP
          name: http
        env:
        - name: "password"
          value: "123456"
        - name: "age"
          value: "18"
        resources:
          limits:
            cpu: 1
            memory: "512Mi"
          requests:
            cpu: 500m
            memory: "512Mi"
        volumeMounts:
        - name: magedu-images-pvc
          mountPath: /usr/local/nginx/html/webapp/images
          readOnly: false
        - name: magedu-static-pvc
          mountPath: /usr/local/nginx/html/webapp/static
          readOnly: false
      volumes:
      - name: magedu-images-pvc
        persistentVolumeClaim:
          claimName: magedu-images
      - name: magedu-static-pvc
        persistentVolumeClaim:
          claimName: magedu-static
#      nodeSelector:
#        project: magedu
#        app: tomcat
---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: magedu-tomcat-app1-service-label
  name: magedu-tomcat-app1-service
  namespace: proc-test
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
    nodePort: 30003
  selector:
    app: magedu-tomcat-app1-selector

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: magedu-images
  namespace: proc-test
spec:
  storageClassName: sc-nfs # éœ€è¦å’Œå‰é¢åˆ›å»ºçš„storageClassåç§°ç›¸åŒ
  accessModes: ["ReadWriteMany", "ReadOnlyMany"]
  resources:
    requests:
      storage: 2Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: magedu-static
  namespace: proc-test
spec:
  storageClassName: sc-nfs # éœ€è¦å’Œå‰é¢åˆ›å»ºçš„storageClassåç§°ç›¸åŒ
  accessModes: ["ReadWriteMany", "ReadOnlyMany"]
  resources:
    requests:
      storage: 2Gi

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get svc -n proc-test 
NAME                         TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
magedu-tomcat-app1-service   NodePort   10.100.229.89   <none>        80:30003/TCP   21s

[root@master-01 ~]#kubectl get pod -n proc-test 
NAME                                             READY   STATUS    RESTARTS   AGE
magedu-tomcat-app1-deployment-7495bc9c64-knwhn   1/1     Running   0          3m59s

# è®¿é—®svcè¿›è¡Œæµ‹è¯•
[root@master-01 ~]#curl 10.0.0.211:30003/myapp/index.html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Magedu é—¨æˆ·ç½‘ç«™</title>
</head>
<body>
<h1>magedu linux40 v111111111111</h1>
<h1>magedu linux40 v222222222222</h1>
<h1>magedu linux40 v333333333333</h1>
<h1>magedu linux40 v444444444444</h1>
<h1>magedu linux40 v555555555555</h1>
<h1>magedu linux40 v666666666666</h1>
<h1>magedu linux40 v777777777777</h1>
<h1>magedu linux40 v888888888888</h1>
<h1>magedu linux40 v999999999999</h1>
<h1>magedu linux40 v100000000000</h1>
<h1>magedu linux40 v111111111111</h1>
<h1>magedu linux40 v222222222222</h1>
</body>
</html>

# é…ç½®Nginxåšåå‘ä»£ç†å’Œé™æ€æœåŠ¡å™¨
# æ‰“ nginx base é•œåƒ
[root@worker-01 nginx-base]#ls
build-command.sh  Dockerfile  nginx-1.18.0.tar.gz

# æŸ¥çœ‹ Dockerfile æ–‡ä»¶
[root@worker-01 nginx-base]#cat Dockerfile 
#Nginx Base Image
FROM harbor.mysticalrecluse.com/baseimages/mystical-centos-base:7.9.2009

MAINTAINER  mystical mysticalrecluse@gmail.com

RUN yum install -y vim wget tree  lrzsz gcc gcc-c++ automake pcre pcre-devel zlib zlib-devel openssl openssl-devel iproute net-tools iotop
ADD nginx-1.18.0.tar.gz /usr/local/src/
RUN cd /usr/local/src/nginx-1.18.0 && ./configure  && make && make install && ln -sv  /usr/local/nginx/sbin/nginx /usr/sbin/nginx  &&rm -rf /usr/local/src/nginx-1.18.0.tar.gz 

# æŸ¥çœ‹ build-command.sh æ–‡ä»¶
[root@worker-01 nginx-base]#cat build-command.sh 
#!/bin/bash
nerdctl build -t harbor.mysticalrecluse.com/pub-images/nginx-base:v1.18.0  .
sleep 1
nerdctl push harbor.mysticalrecluse.com/pub-images/nginx-base:v1.18.0


# åœ¨nginx-baseé•œåƒçš„åŸºç¡€ä¸Šï¼Œæ‰“è‡ªå·±éœ€è¦çš„é•œåƒï¼ŒåŸºç¡€é•œåƒæ—¢æ²¡æœ‰èµ„æºä¹Ÿæ²¡æœ‰é…ç½®
[root@worker-01 nginx]#ls
app1.tar.gz  build-command.sh  Dockerfile  index.html  nginx.conf  webapp


# æŸ¥çœ‹Dockerfile
[root@worker-01 nginx]#cat Dockerfile 
#Nginx 1.18.0
FROM harbor.mysticalrecluse.com/pub-images/nginx-base:v1.18.0 

ADD nginx.conf /usr/local/nginx/conf/nginx.conf
ADD app1.tar.gz  /usr/local/nginx/html/webapp/
ADD index.html  /usr/local/nginx/html/index.html

#é™æ€èµ„æºæŒ‚è½½è·¯å¾„
RUN mkdir -p /usr/local/nginx/html/webapp/static /usr/local/nginx/html/webapp/images 

EXPOSE 80 443

CMD ["nginx"] 

# æŸ¥çœ‹nginx.conf
[root@worker-01 nginx]#cat nginx.conf 
user  nginx nginx;
worker_processes  auto;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;
daemon off;

events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

upstream  tomcat_webserver {
        server  magedu-tomcat-app1-service.proc-test.svc.cluster.local; # è¿™é‡Œå†™serviceåç§° 
}

    server {
        listen       80;
        server_name  localhost;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html;
            index  index.html index.htm;
        }

        location /webapp {
            root   html;
            index  index.html index.htm;
        }

        location /myapp {
             proxy_pass  http://tomcat_webserver;
             proxy_set_header   Host    $host;
             proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
             proxy_set_header X-Real-IP $remote_addr;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }

        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ {
        #    proxy_pass   http://127.0.0.1;
        #}

        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ {
        #    root           html;
        #    fastcgi_pass   127.0.0.1:9000;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}

        # deny access to .htaccess files, if Apache's document root
        # concurs with nginx's one
        #
        #location ~ /\.ht {
        #    deny  all;
        #}
    }


    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}


    # HTTPS server
    #
    #server {
    #    listen       443 ssl;
    #    server_name  localhost;

    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;

    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;

    #    ssl_ciphers  HIGH:!aNULL:!MD5;
    #    ssl_prefer_server_ciphers  on;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}

}


# æŸ¥çœ‹build-command.sh
[root@worker-01 nginx]#vim build-command.sh 
#!/bin/bash
TAG=$1
nerdctl build -t harbor.mysticalrecluse.com/myserver/nginx-web1:${TAG} .
echo "é•œåƒæ„å»ºå®Œæˆï¼Œå³å°†ä¸Šä¼ åˆ°harbor"
sleep 1
nerdctl push harbor.mysticalrecluse.com/myserver/nginx-web1:${TAG}
echo "é•œåƒä¸Šä¼ åˆ°harborå®Œæˆ"

# æ„å»ºé•œåƒ
[root@worker-01 nginx]#bash build-command.sh v1

# ç¼–å†™yamlæ–‡ä»¶ï¼Œå¹¶éƒ¨ç½²åœ¨Kubernetesä¸Š
[root@worker-01 nginx]#vim nginx.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  labels:
    app: magedu-nginx-deployment-label
  name: magedu-nginx-deployment
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: magedu-nginx-selector
  template:
    metadata:
      labels:
        app: magedu-nginx-selector
    spec:
      containers:
      - name: magedu-nginx-container
        image: harbor.magedu.net/magedu/nginx-web1:v3
        #command: ["/apps/tomcat/bin/run_tomcat.sh"]
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        ports:
        - containerPort: 80
          protocol: TCP
          name: http
        - containerPort: 443
          protocol: TCP
          name: https
        env:
        - name: "password"
          value: "123456"
        - name: "age"
          value: "20"
        resources:
          limits:
            cpu: 2
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi

        volumeMounts:
        - name: magedu-images-pvc
          mountPath: /usr/local/nginx/html/webapp/images
          readOnly: false
        - name: magedu-static-pvc
          mountPath: /usr/local/nginx/html/webapp/static
          readOnly: false
      volumes:
      - name: magedu-images-pvc
        persistentVolumeClaim:
          claimName: magedu-images
      - name: magedu-static-pvc
        persistentVolumeClaim:
          claimName: magedu-static

      #  group: magedu

---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: magedu-nginx-service-label
  name: magedu-nginx-service
  namespace: proc-test
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
    nodePort: 40002
  - name: https
    port: 443
    protocol: TCP
    targetPort: 443
    nodePort: 40443
  selector:
    app: magedu-nginx-selector

# å¯ç”¨pod
[root@master-01 ~]#kubectl apply -f nginx.yaml 

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get all -n proc-test 
NAME                                                 READY   STATUS    RESTARTS      AGE
pod/magedu-nginx-deployment-7455c575bc-92qs9         1/1     Running   0             34m
pod/magedu-tomcat-app1-deployment-7495bc9c64-knwhn   1/1     Running   1 (97m ago)   12h

NAME                                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/magedu-nginx-service         NodePort    10.100.135.150   <none>        80:30002/TCP,443:30443/TCP   34m
service/magedu-tomcat-app1-service   ClusterIP   10.100.229.89    <none>        80/TCP                       12h

# æµ‹è¯•
[root@master-01 ~]#curl 10.0.0.211:30002
nginx web1 n56 v1
```



### ä¸šåŠ¡å®¹å™¨åŒ–æ¡ˆä¾‹ä¹‹ä¸‰ï¼šPV/PVCåŠzookeeper

zookeeperé›†ç¾¤çš„æ¯ä¸ªå®ä¾‹çš„å­˜å‚¨æ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤å»ºè®®ä½¿ç”¨openebsçš„host-path



**æ•´ä½“æµç¨‹**

- æ„å»ºzookeeperé•œåƒ
- æµ‹è¯•zookeeperé•œåƒ
- åˆ›å»ºPV/PVC
- è¿è¡Œzookeeperé›†ç¾¤
- éªŒè¯é›†ç¾¤çŠ¶æ€

```bash
# æ‹‰å–slim_java:8,javaç¯å¢ƒçš„åŸºç¡€é•œåƒï¼Œå¹¶ä¸Šä¼ è‡³ç§æœ‰harbor
[root@worker-01 ~]#nerdctl pull elevy/slim_java:8
[root@worker-01 ~]#nerdctl tag elevy/slim_java:8 harbor.mysticalrecluse.com/baseimages/slim_java:8
[root@worker-01 ~]#nerdctl push harbor.mysticalrecluse.com/baseimages/slim_java:8

# æ‰“zookeeperçš„é•œåƒ
[root@worker-01 zookeeper]#ls
bin               entrypoint.sh                     zookeeper-3.4.14.tar.gz
build-command.sh  KEYS                              zookeeper-3.4.14.tar.gz.asc
conf              repositories
Dockerfile        zookeeper-3.12-Dockerfile.tar.gz

# æŸ¥çœ‹Dockerfile
[root@worker-01 zookeeper]#cat Dockerfile 
#FROM harbor-linux38.local.com/linux38/slim_java:8 
FROM harbor.mysticalrecluse.com/baseimages/slim_java:8

ENV ZK_VERSION 3.4.14
ADD repositories /etc/apk/repositories 
# Download Zookeeper
COPY zookeeper-3.4.14.tar.gz /tmp/zk.tgz
COPY zookeeper-3.4.14.tar.gz.asc /tmp/zk.tgz.asc
COPY KEYS /tmp/KEYS
RUN apk add --no-cache --virtual .build-deps \
      ca-certificates   \
      gnupg             \
      tar               \
      wget &&           \
    #
    # Install dependencies
    apk add --no-cache  \
      bash &&           \
    #
    #
    # Verify the signature
    export GNUPGHOME="$(mktemp -d)" && \
    gpg -q --batch --import /tmp/KEYS && \
    gpg -q --batch --no-auto-key-retrieve --verify /tmp/zk.tgz.asc /tmp/zk.tgz && \
    #
    # Set up directories
    #
    mkdir -p /zookeeper/data /zookeeper/wal /zookeeper/log && \
    #
    # Install
    tar -x -C /zookeeper --strip-components=1 --no-same-owner -f /tmp/zk.tgz && \
    #
    # Slim down
    cd /zookeeper && \
    cp dist-maven/zookeeper-${ZK_VERSION}.jar . && \
    rm -rf \
      *.txt \
      *.xml \
      bin/README.txt \
      bin/*.cmd \
      conf/* \
      contrib \
      dist-maven \
      docs \
      lib/*.txt \
      lib/cobertura \
      lib/jdiff \
      recipes \
      src \
      zookeeper-*.asc \
      zookeeper-*.md5 \
      zookeeper-*.sha1 && \
    #
    # Clean up
    apk del .build-deps && \
    rm -rf /tmp/* "$GNUPGHOME"

COPY conf /zookeeper/conf/
COPY bin/zkReady.sh /zookeeper/bin/
COPY entrypoint.sh /

ENV PATH=/zookeeper/bin:${PATH} \
    ZOO_LOG_DIR=/zookeeper/log \
    ZOO_LOG4J_PROP="INFO, CONSOLE, ROLLINGFILE" \
    JMXPORT=9010

ENTRYPOINT [ "/entrypoint.sh" ]

CMD [ "zkServer.sh", "start-foreground" ]

EXPOSE 2181 2888 3888 9010


# æŸ¥çœ‹entrypoint.sh
[root@worker-01 zookeeper]#cat entrypoint.sh 
#!/bin/bash

echo ${MYID:-1} > /zookeeper/data/myid

if [ -n "$SERVERS" ]; then
	IFS=\, read -a servers <<<"$SERVERS"
	for i in "${!servers[@]}"; do 
		printf "\nserver.%i=%s:2888:3888" "$((1 + $i))" "${servers[$i]}" >> /zookeeper/conf/zoo.cfg
	done
fi

cd /zookeeper
exec "$@"

[root@worker-01 zookeeper]#cat build-command.sh 
#!/bin/bash
TAG=$1
nerdctl build -t harbor.mysticalrecluse.com/myserver/zookeeper:${TAG} .
sleep 1
nerdctl push  harbor.mysticalrecluse.com/myserver/zookeeper:${TAG}

# æ‰“é•œåƒ
[root@worker-01 zookeeper]#bash build-command.sh 
```

```yaml
# å‡†å¤‡yamlæ–‡ä»¶
[root@worker-01 zookeeper]#cat zookeeper.yaml 
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: proc-test
spec:
  ports:
    - name: client
      port: 2181
  selector:
    app: zookeeper
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper1
  namespace: proc-test
spec:
  type: NodePort        
  ports:
    - name: client
      port: 2181
      nodePort: 32181
    - name: followers
      port: 2888
    - name: election
      port: 3888
  selector:
    app: zookeeper
    server-id: "1"
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper2
  namespace: proc-test
spec:
  type: NodePort        
  ports:
    - name: client
      port: 2181
      nodePort: 32182
    - name: followers
      port: 2888
    - name: election
      port: 3888
  selector:
    app: zookeeper
    server-id: "2"
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper3
  namespace: proc-test
spec:
  type: NodePort        
  ports:
    - name: client
      port: 2181
      nodePort: 32183
    - name: followers
      port: 2888
    - name: election
      port: 3888
  selector:
    app: zookeeper
    server-id: "3"
---
kind: Deployment
#apiVersion: extensions/v1beta1
apiVersion: apps/v1
metadata:
  name: zookeeper1
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
        server-id: "1"
    spec:
      volumes:
        - name: data
          emptyDir: {}
        - name: wal
          emptyDir:
            medium: Memory
      containers:
        - name: server
          image: harbor.mysticalrecluse.com/myserver/zookeeper:v3.4.14
          imagePullPolicy: Always
          env:
            - name: MYID
              value: "1"
            - name: SERVERS
              value: "zookeeper1,zookeeper2,zookeeper3"
            - name: JVMFLAGS
              value: "-Xmx2G"
          ports:
            - containerPort: 2181
            - containerPort: 2888
            - containerPort: 3888
          volumeMounts:
          - mountPath: "/zookeeper/data"
            name: zookeeper-datadir-pvc-1 
      volumes:
        - name: zookeeper-datadir-pvc-1 
          persistentVolumeClaim:
            claimName: zookeeper-datadir-pvc-1
---
kind: Deployment
#apiVersion: extensions/v1beta1
apiVersion: apps/v1
metadata:
  name: zookeeper2
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
        server-id: "2"
    spec:
      volumes:
        - name: data
          emptyDir: {}
        - name: wal
          emptyDir:
            medium: Memory
      containers:
        - name: server
          image: harbor.mysticalrecluse.com/myserver/zookeeper:v3.4.14
          imagePullPolicy: Always
          env:
            - name: MYID
              value: "2"
            - name: SERVERS
              value: "zookeeper1,zookeeper2,zookeeper3"
            - name: JVMFLAGS
              value: "-Xmx2G"
          ports:
            - containerPort: 2181
            - containerPort: 2888
            - containerPort: 3888
          volumeMounts:
          - mountPath: "/zookeeper/data"
            name: zookeeper-datadir-pvc-2 
      volumes:
        - name: zookeeper-datadir-pvc-2
          persistentVolumeClaim:
            claimName: zookeeper-datadir-pvc-2
---
kind: Deployment
#apiVersion: extensions/v1beta1
apiVersion: apps/v1
metadata:
  name: zookeeper3
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
        server-id: "3"
    spec:
      volumes:
        - name: data
          emptyDir: {}
        - name: wal
          emptyDir:
            medium: Memory
      containers:
        - name: server
          image: harbor.mysticalrecluse.com/myserver/zookeeper:v3.4.14
          imagePullPolicy: Always
          env:
            - name: MYID
              value: "3"
            - name: SERVERS
              value: "zookeeper1,zookeeper2,zookeeper3"
            - name: JVMFLAGS
              value: "-Xmx2G"
          ports:
            - containerPort: 2181
            - containerPort: 2888
            - containerPort: 3888
          volumeMounts:
          - mountPath: "/zookeeper/data"
            name: zookeeper-datadir-pvc-3
      volumes:
        - name: zookeeper-datadir-pvc-3
          persistentVolumeClaim:
           claimName: zookeeper-datadir-pvc-3
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: zookeeper-datadir-pvc-1
  namespace: proc-test
spec:
  storageClassName: openebs-hostpath-dynamic
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: zookeeper-datadir-pvc-2
  namespace: proc-test
spec:
  storageClassName: openebs-hostpath-dynamic
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: zookeeper-datadir-pvc-3
  namespace: proc-test
spec:
  storageClassName: openebs-hostpath-dynamic
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
      
# åˆ›å»º
[root@master-01 ~] # kubectl apply -f zookeeper.yaml

# æŸ¥çœ‹
[root@master-01 ~] # kubectl get all -n proc-test 
NAME                                                 READY   STATUS    RESTARTS     AGE
pod/magedu-nginx-deployment-7455c575bc-92qs9         1/1     Running   0            8h
pod/magedu-tomcat-app1-deployment-7495bc9c64-knwhn   1/1     Running   1 (9h ago)   20h
pod/zookeeper1-98785f44d-xr7cs                       1/1     Running   0            3m32s
pod/zookeeper2-54d4775745-hrnrc                      1/1     Running   0            3m32s
pod/zookeeper3-5d699cb6d6-pvv8m                      1/1     Running   0            3m31s

NAME                                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                        AGE
service/magedu-nginx-service         NodePort    10.100.135.150   <none>        80:30002/TCP,443:30443/TCP                     8h
service/magedu-tomcat-app1-service   ClusterIP   10.100.229.89    <none>        80/TCP                                         20h
service/zookeeper                    ClusterIP   10.100.62.34     <none>        2181/TCP                                       3m32s
service/zookeeper1                   NodePort    10.100.222.44    <none>        2181:32181/TCP,2888:30203/TCP,3888:30170/TCP   2m38s
service/zookeeper2                   NodePort    10.100.42.100    <none>        2181:32182/TCP,2888:32757/TCP,3888:32659/TCP   2m37s
service/zookeeper3                   NodePort    10.100.194.154   <none>        2181:32183/TCP,2888:30362/TCP,3888:30488/TCP   2m37s

NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/magedu-nginx-deployment         1/1     1            1           8h
deployment.apps/magedu-tomcat-app1-deployment   1/1     1            1           20h
deployment.apps/zookeeper1                      1/1     1            1           3m32s
deployment.apps/zookeeper2                      1/1     1            1           3m32s
deployment.apps/zookeeper3                      1/1     1            1           3m32s

NAME                                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/magedu-nginx-deployment-7455c575bc         1         1         1       8h
replicaset.apps/magedu-tomcat-app1-deployment-7495bc9c64   1         1         1       20h
replicaset.apps/zookeeper1-98785f44d                       1         1         1       3m32s
replicaset.apps/zookeeper2-54d4775745                      1         1         1       3m32s
replicaset.apps/zookeeper3-5d699cb6d6                      1         1         1       3m31s

# æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
[root@master-01 ~]#kubectl exec -it -n proc-test zookeeper1-98785f44d-xr7cs -- bash
bash-4.3# cd /zookeeper/bin/
bash-4.3# ls
zkCleanup.sh        zkEnv.sh            zkServer.sh
zkCli.sh            zkReady.sh          zkTxnLogToolkit.sh
bash-4.3# zkServer.sh status
ZooKeeper JMX enabled by default
ZooKeeper remote JMX Port set to 9010
ZooKeeper remote JMX authenticate set to false
ZooKeeper remote JMX ssl set to false
ZooKeeper remote JMX log4j set to true
Using config: /zookeeper/bin/../conf/zoo.cfg
Mode: follower
```



### ä¸šåŠ¡å®¹å™¨åŒ–æ¡ˆä¾‹ä¹‹å››ï¼šRedis Cluster â€” StatefulSet

```bash
# æ„å»ºredisé•œåƒ
# æŸ¥çœ‹ç›®å½•æ–‡ä»¶
[root@worker-01 redis]#ls
build-command.sh  Dockerfile  redis-4.0.14.tar.gz  redis.conf  run_redis.sh

# æŸ¥çœ‹Dockerfile
[root@worker-01 redis]#cat Dockerfile 
#Redis Image
FROM harbor.mysticalrecluse.com/baseimages/mystical-centos-base:7.9.2009 

MAINTAINER mystical "mysticalrecluse@gmail.com"

ADD redis-4.0.14.tar.gz /usr/local/src
RUN ln -sv /usr/local/src/redis-4.0.14 /usr/local/redis && cd /usr/local/redis && make && cp src/redis-cli /usr/sbin/ && cp src/redis-server  /usr/sbin/ && mkdir -pv /data/redis-data 
ADD redis.conf /usr/local/redis/redis.conf 
ADD run_redis.sh /usr/local/redis/run_redis.sh

EXPOSE 6379

CMD ["/usr/local/redis/run_redis.sh"]

# æŸ¥çœ‹run_redis.sh
[root@worker-01 redis]#cat run_redis.sh 
#!/bin/bash

/usr/sbin/redis-server /usr/local/redis/redis.conf

tail -f  /etc/hosts

# æŸ¥çœ‹build-command.sh
[root@worker-01 redis]#cat build-command.sh 
#!/bin/bash
TAG=$1
nerdctl build -t harbor.mysticalrecluse.com/myserver/redis:${TAG} .
sleep 3
nerdctl push  harbor.mysticalrecluse.com/myserver/redis:${TAG}

[root@worker-01 redis]# bash build-command.sh v4.0.14
```

```bash
[root@worker-01 redis]#ls
pv  pvc.yaml  redis.conf  redis.yaml

# æŸ¥çœ‹redis.conf
[root@worker-01 redis]#cat redis.conf 
appendonly yes
cluster-enabled yes
cluster-config-file /var/lib/redis/nodes.conf
cluster-node-timeout 5000
port 6379


# åŸºäºredis.confåˆ›å»ºconfigmap
[root@master-01 ~]#kubectl create cm -n proc-test redis-conf --from-file=redis.conf
configmap/redis-conf created

# æŸ¥çœ‹redis-cluster.yaml
[root@master-01 ~]#cat redis-cluster.yaml 
apiVersion: v1
kind: Service
metadata:
  name: redis              # æ— å¤´æœåŠ¡çš„åç§°å¿…é¡»å’Œstsçš„åç§°ä¸€è‡´
  namespace: proc-test
  labels:
    app: redis
spec:
  clusterIP: None    # è¿™é‡Œå¿…é¡»æ˜¯æ— å¤´æœåŠ¡ï¼Œå¦åˆ™podçš„åç§°æ— æ³•è¢«è§£æ
  selector:
    app: redis
    appCluster: redis-cluster
  ports:
  - name: redis-access
    protocol: TCP
    port: 6379
    targetPort: 6379

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
  namespace: proc-test
spec:
  serviceName: redis
  replicas: 6
  selector:
    matchLabels:
      app: redis
      appCluster: redis-cluster
  template:
    metadata:
      labels:
        app: redis
        appCluster: redis-cluster
    spec:
      terminationGracePeriodSeconds: 20  # æ§åˆ¶ Pod ä¼˜é›…ç»ˆæ­¢ï¼ˆgraceful terminationï¼‰ çš„æ—¶é•¿
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values: 
                  - redis
              topologyKey: kubernetes.io/hostname
      containers:
      - name: redis
        image:  harbor.mysticalrecluse.com/myserver/redis:v4.0.14
        command:
        - "redis-server"
        args:
        - "/etc/redis/redis.conf"
        - "--protected-mode"
        - "no"
        resources:
          requests:
            cpu: "500m"
            memory: "500Mi"
        ports:
        - containerPort: 6379
          name: redis
          protocol: TCP
        - containerPort: 16379
          name: cluster
          protocol: TCP
        volumeMounts:
        - name: conf
          mountPath: /etc/redis
        - name: data
          mountPath: /var/lib/redis
      volumes:
      - name: conf
        configMap:
          name: redis-conf
          items:
          - key: redis.conf
            path: redis.conf
  volumeClaimTemplates:
  - metadata:
      name: data
      namespace: proc-test
    spec:
      storageClassName: sc-nfs
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 2Gi

# åˆ›å»ºåˆå§‹åŒ–podï¼Œæ¥åˆå§‹åŒ–redis-clusteré›†ç¾¤
# æ³¨æ„redis-clusteréœ€è¦æ‰‹åŠ¨åˆå§‹åŒ–ï¼Œæˆ–è€…è‡ªå·±å†™è‡ªåŠ¨äº¤äº’çš„è„šæœ¬
# å°†Robyå‡çº§åˆ° >= 2.5
# å®‰è£…ä¾èµ–
yum install -y git gcc bzip2 openssl-devel readline-devel zlib-devel

# å®‰è£… rbenv å’Œ ruby-build
cd /usr/local/
git clone https://github.com/rbenv/rbenv.git ~/.rbenv
echo 'export PATH="$HOME/.rbenv/bin:$PATH"' >> ~/.bashrc
echo 'eval "$(rbenv init - bash)"' >> ~/.bashrc
source ~/.bashrc

# å®‰è£… ruby-build æ’ä»¶
git clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build

# å®‰è£…æ–°ç‰ˆæœ¬ Rubyï¼ˆæ¯”å¦‚ 2.7.8ï¼‰
rbenv install 2.7.8
rbenv global 2.7.8

# ç¡®è®¤ç‰ˆæœ¬
ruby -v

# æ‰§è¡Œå‘½ä»¤åŠ å…¥ï¼Œæ„å»ºredis-clusteré›†ç¾¤
[root@redis-0 local]# /usr/local/redis/src/redis-trib.rb create --replicas 1 `dig +short redis-0.redis.proc-test.svc.cluster.local`:6379 `dig +short redis-1.redis.proc-test.svc.cluster.local`:6379 `dig +short redis-2.redis.proc-test.svc.cluster.local`:6379 `dig +short redis-3.redis.proc-test.svc.cluster.local`:6379 `dig +short redis-4.redis.proc-test.svc.cluster.local`:6379 `dig +short redis-5.redis.proc-test.svc.cluster.local`:6379
>>> Creating cluster
>>> Performing hash slots allocation on 6 nodes...
Using 3 masters:
10.200.129.54:6379
10.200.171.22:6379
10.200.37.196:6379
Adding replica 10.200.129.55:6379 to 10.200.129.54:6379
Adding replica 10.200.37.197:6379 to 10.200.171.22:6379
Adding replica 10.200.171.24:6379 to 10.200.37.196:6379
M: 39e9771fd059575af855f2efda5e5112948a41e8 10.200.129.54:6379
   slots:0-5460 (5461 slots) master
M: 26f2ce3bcfd07f4b87e01898c54439a0811af48a 10.200.171.22:6379
   slots:5461-10922 (5462 slots) master
M: 218842546042fac985f2402879e9c314e4dbbee8 10.200.37.196:6379
   slots:10923-16383 (5461 slots) master
S: 6c69be742223206fa3ce23726569be32a56ac4c6 10.200.171.24:6379
   replicates 218842546042fac985f2402879e9c314e4dbbee8
S: e70cedcbbb13fc6e387c1e959238526848d529d1 10.200.129.55:6379
   replicates 39e9771fd059575af855f2efda5e5112948a41e8
S: 7ce117f59196f58de867ab06456e4aee578b6496 10.200.37.197:6379
   replicates 26f2ce3bcfd07f4b87e01898c54439a0811af48a
Can I set the above configuration? (type 'yes' to accept): yes    # é€‰æ‹©yes
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join...
>>> Performing Cluster Check (using node 10.200.129.54:6379)
M: 39e9771fd059575af855f2efda5e5112948a41e8 10.200.129.54:6379
   slots:0-5460 (5461 slots) master
   1 additional replica(s)
S: e70cedcbbb13fc6e387c1e959238526848d529d1 10.200.129.55:6379
   slots: (0 slots) slave
   replicates 39e9771fd059575af855f2efda5e5112948a41e8
M: 218842546042fac985f2402879e9c314e4dbbee8 10.200.37.196:6379
   slots:10923-16383 (5461 slots) master
   1 additional replica(s)
S: 6c69be742223206fa3ce23726569be32a56ac4c6 10.200.171.24:6379
   slots: (0 slots) slave
   replicates 218842546042fac985f2402879e9c314e4dbbee8
S: 7ce117f59196f58de867ab06456e4aee578b6496 10.200.37.197:6379
   slots: (0 slots) slave
   replicates 26f2ce3bcfd07f4b87e01898c54439a0811af48a
M: 26f2ce3bcfd07f4b87e01898c54439a0811af48a 10.200.171.22:6379
   slots:5461-10922 (5462 slots) master
   1 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.

# æ£€æŸ¥redisé›†ç¾¤æ•ˆæœï¼Œ-cå¯ç”¨é›†ç¾¤æ¨¡å¼ï¼ŒRedis CLI ä¼šè‡ªåŠ¨è·Ÿéš MOVED è·³è½¬åˆ°æ­£ç¡®çš„èŠ‚ç‚¹ã€‚
root@redis-0 local]# redis-cli -c -a 123456
Warning: Using a password with '-a' option on the command line interface may not be safe.
127.0.0.1:6379> set key1 value1
-> Redirected to slot [9189] located at 10.200.171.22:6379
OK
10.200.171.22:6379> set key2 value2
-> Redirected to slot [4998] located at 10.200.129.54:6379
OK
10.200.129.54:6379> get key1
-> Redirected to slot [9189] located at 10.200.171.22:6379
"value1"
10.200.171.22:6379> get key1
"value1"
10.200.171.22:6379> get key2
-> Redirected to slot [4998] located at 10.200.129.54:6379
"value2"
```



### ä¸šåŠ¡å®¹å™¨åŒ–æ¡ˆä¾‹ä¹‹äº”ï¼šMySQLä¸€ä¸»å¤šä»

![image-20250421171035342](../markdown_img/image-20250421171035342.png)



#### å‡†å¤‡é•œåƒ

```bash
# ä¸Šä¼ mysqlé•œåƒ
[root@worker-01 mysql]#nerdctl pull mysql:5.7.36
[root@worker-01 mysql]#nerdctl tag mysql:5.7.36 harbor.mysticalrecluse.com/myserver/mysql:5.7.36
[root@worker-01 mysql]#nerdctl push harbor.mysticalrecluse.com/myserver/mysql:5.7.36

# ä¸Šä¼ xtrabackupé•œåƒ
[root@worker-01 mysql]#nerdctl pull yizhiyong/xtrabackup:latest
[root@worker-01 mysql]#nerdctl tag yizhiyong/xtrabackup:latest harbor.mysticalrecluse.com/myserver/xtrabackup:1.0
[root@worker-01 mysql]#nerdctl push harbor.mysticalrecluse.com/myserver/xtrabackup:1.0
```



####  å‡†å¤‡yamlæ¸…å•æ–‡ä»¶

```bash
# configmapæ–‡ä»¶
[root@worker-01 mysql]#cat mysql-configmap.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql
  namespace: magedu
  labels:
    app: mysql
data:
  master.cnf: |
    # Apply this config only on the master.
    [mysqld]
    log-bin
    log_bin_trust_function_creators=1
    lower_case_table_names=1
  slave.cnf: |
    # Apply this config only on slaves.
    [mysqld]
    super-read-only
    log_bin_trust_function_creators=1
    
# å‡†å¤‡statefulSet
[root@worker-01 mysql]#cat mysql-statefulset.yaml 
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
  namespace: proc-test
spec:
  selector:
    matchLabels:
      app: mysql
  serviceName: mysql
  replicas: 3
  template:
    metadata:
      labels:
        app: mysql
    spec:
      initContainers:
      - name: init-mysql
        image: harbor.mysticalrecluse.com/myserver/mysql:5.7.36
        command:
        - bash
        - "-c"
        - |
          set -ex
          # Generate mysql server-id from pod ordinal index.
          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
          # BASH_REMATCH æ˜¯ Bash çš„ä¸€ä¸ªå†…ç½®å˜é‡ï¼Œåªæœ‰åœ¨ä½¿ç”¨ [[ string =~ regex ]] æ­£åˆ™åŒ¹é…è¯­æ³•æ—¶æ‰ä¼šè‡ªåŠ¨åˆ›å»ºå’Œèµ‹å€¼ã€‚
          # BASH_REMATCH[0]ï¼šæ•´ä¸ªæ­£åˆ™åŒ¹é…åˆ°çš„å†…å®¹
          # BASH_REMATCH[1]ï¼šç¬¬ä¸€ä¸ªæ‹¬å·æ•è·ç»„
          ordinal=${BASH_REMATCH[1]}
          echo [mysqld] > /mnt/conf.d/server-id.cnf
          # Add an offset to avoid reserved server-id=0 value.
          echo server-id=$((100 + $ordinal)) >> /mnt/conf.d/server-id.cnf
          # Copy appropriate conf.d files from config-map to emptyDir.
          if [[ $ordinal -eq 0 ]]; then
            cp /mnt/config-map/master.cnf /mnt/conf.d/
          else
            cp /mnt/config-map/slave.cnf /mnt/conf.d/
          fi
        volumeMounts:
        - name: conf
          mountPath: /mnt/conf.d
        - name: config-map
          mountPath: /mnt/config-map
      - name: clone-mysql
        image: harbor.mysticalrecluse.com/myserver/xtrabackup:1.0 
        command:
        - bash
        - "-c"
        - |
          set -ex
          # Skip the clone if data already exists.
          [[ -d /var/lib/mysql/mysql ]] && exit 0
          # Skip the clone on master (ordinal index 0).
          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
          ordinal=${BASH_REMATCH[1]}
          [[ $ordinal -eq 0 ]] && exit 0
          # Clone data from previous peer.
          ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql
          # Prepare the backup.
          xtrabackup --prepare --target-dir=/var/lib/mysql
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
      containers:
      - name: mysql
        image: harbor.mysticalrecluse.com/myserver/mysql:5.7.36 
        env:
        - name: MYSQL_ALLOW_EMPTY_PASSWORD
          value: "1"
        ports:
        - name: mysql
          containerPort: 3306
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
        livenessProbe:
          exec:
            command: ["mysqladmin", "ping"]
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          exec:
            # Check we can execute queries over TCP (skip-networking is off).
            command: ["mysql", "-h", "127.0.0.1", "-e", "SELECT 1"]
          initialDelaySeconds: 5
          periodSeconds: 2
          timeoutSeconds: 1
      - name: xtrabackup
        image: harbor.mysticalrecluse.com/myserver/xtrabackup:1.0 
        ports:
        - name: xtrabackup
          containerPort: 3307
        command:
        - bash
        - "-c"
        - |
          set -ex
          cd /var/lib/mysql
          # Determine binlog position of cloned data, if any.
          if [[ -f xtrabackup_slave_info ]]; then
            # XtraBackup already generated a partial "CHANGE MASTER TO" query
            # because we're cloning from an existing slave.
            mv xtrabackup_slave_info change_master_to.sql.in
            # Ignore xtrabackup_binlog_info in this case (it's useless).
            rm -f xtrabackup_binlog_info
          elif [[ -f xtrabackup_binlog_info ]]; then
            # We're cloning directly from master. Parse binlog position.
            [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1
            rm xtrabackup_binlog_info
            echo "CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\
                  MASTER_LOG_POS=${BASH_REMATCH[2]}" > change_master_to.sql.in
          fi
          # Check if we need to complete a clone by starting replication.
          if [[ -f change_master_to.sql.in ]]; then
            echo "Waiting for mysqld to be ready (accepting connections)"
            until mysql -h 127.0.0.1 -e "SELECT 1"; do sleep 1; done
            echo "Initializing replication from clone position"
            # In case of container restart, attempt this at-most-once.
            mv change_master_to.sql.in change_master_to.sql.orig
            mysql -h 127.0.0.1 <<EOF
          $(<change_master_to.sql.orig),
            MASTER_HOST='mysql-0.mysql',
            MASTER_USER='root',
            MASTER_PASSWORD='',
            MASTER_CONNECT_RETRY=10;
          START SLAVE;
          EOF
          fi
          # Start a server to send backups when requested by peers.
          exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \
            "xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root"
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
      volumes:
      - name: conf
        emptyDir: {}
      - name: config-map
        configMap:
          name: mysql
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      storageClassName: openebs-hostpath-dynamic
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 2Gi

# å‡†å¤‡service
[root@worker-01 mysql]#cat mysql-services.yaml 
# Headless service for stable DNS entries of StatefulSet members.
apiVersion: v1
kind: Service
metadata:
  namespace: proc-test
  name: mysql
  labels:
    app: mysql
spec:
  ports:
  - name: mysql
    port: 3306
  clusterIP: None
  selector:
    app: mysql
---
# Client service for connecting to any MySQL instance for reads.
# For writes, you must instead connect to the master: mysql-0.mysql.
apiVersion: v1
kind: Service
metadata:
  name: mysql-read
  namespace: proc-test
  labels:
    app: mysql
spec:
  ports:
  - name: mysql
    port: 3306
  selector:
    app: mysql
```

```bash
# å¯ç”¨æ¸…å•æ–‡ä»¶
[root@master-01 ~]# kubectl apply -f mysql-cm.yaml 
[root@master-01 ~]#kubectl apply -f mysql-sts.yaml
[root@master-01 ~]#kubectl apply -f mysql-service.yaml

# æµ‹è¯•é›†ç¾¤æ˜¯å¦ok
[root@master-01 ~]#kubectl exec -it -n proc-test mysql-0 bash
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
Defaulted container "mysql" out of: mysql, xtrabackup, init-mysql (init), clone-mysql (init)
root@mysql-0:/# mysql
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 124
Server version: 5.7.36-log MySQL Community Server (GPL)

Copyright (c) 2000, 2021, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show processlist;
+-----+------+---------------------+------+-------------+------+---------------------------------------------------------------+------------------+
| Id  | User | Host                | db   | Command     | Time | State                                                         | Info             |
+-----+------+---------------------+------+-------------+------+---------------------------------------------------------------+------------------+
|  44 | root | 10.200.129.57:57592 | NULL | Binlog Dump |  137 | Master has sent all binlog to slave; waiting for more updates | NULL             |
|  87 | root | 10.200.37.199:58828 | NULL | Binlog Dump |   67 | Master has sent all binlog to slave; waiting for more updates | NULL             |
| 124 | root | localhost           | NULL | Query       |    0 | starting                                                      | show processlist |
+-----+------+---------------------+------+-------------+------+---------------------------------------------------------------+------------------+
3 rows in set (0.00 sec)

mysql> exit
Bye
```



### ä¸šåŠ¡å®¹å™¨åŒ–æ¡ˆä¾‹ä¹‹å…­ï¼šJavaåº”ç”¨-Jenkins



![image-20250421222125054](../markdown_img/image-20250421222125054.png)



#### æ„å»ºjava17åŸºç¡€é•œåƒ

```bash
[root@worker-01 jdk-17]#ls
build-command.sh  Dockerfile  jdk-17.0.15_linux-x64_bin.tar.gz  profile

# æŸ¥çœ‹profile
[root@worker-01 jdk-17]#cat profile 
# /etc/profile

# System wide environment and startup programs, for login setup
# Functions and aliases go in /etc/bashrc

# It's NOT a good idea to change this file unless you know what you
# are doing. It's much better to create a custom.sh shell script in
# /etc/profile.d/ to make custom changes to your environment, as this
# will prevent the need for merging in future updates.

pathmunge () {
    case ":${PATH}:" in
        *:"$1":*)
            ;;
        *)
            if [ "$2" = "after" ] ; then
                PATH=$PATH:$1
            else
                PATH=$1:$PATH
            fi
    esac
}


if [ -x /usr/bin/id ]; then
    if [ -z "$EUID" ]; then
        # ksh workaround
        EUID=`/usr/bin/id -u`
        UID=`/usr/bin/id -ru`
    fi
    USER="`/usr/bin/id -un`"
    LOGNAME=$USER
    MAIL="/var/spool/mail/$USER"
fi

# Path manipulation
if [ "$EUID" = "0" ]; then
    pathmunge /usr/sbin
    pathmunge /usr/local/sbin
else
    pathmunge /usr/local/sbin after
    pathmunge /usr/sbin after
fi

HOSTNAME=`/usr/bin/hostname 2>/dev/null`
HISTSIZE=1000
if [ "$HISTCONTROL" = "ignorespace" ] ; then
    export HISTCONTROL=ignoreboth
else
    export HISTCONTROL=ignoredups
fi

export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL

# By default, we want umask to get set. This sets it for login shell
# Current threshold for system reserved uid/gids is 200
# You could check uidgid reservation validity in
# /usr/share/doc/setup-*/uidgid file
if [ $UID -gt 199 ] && [ "`/usr/bin/id -gn`" = "`/usr/bin/id -un`" ]; then
    umask 002
else
    umask 022
fi

for i in /etc/profile.d/*.sh /etc/profile.d/sh.local ; do
    if [ -r "$i" ]; then
        if [ "${-#*i}" != "$-" ]; then 
            . "$i"
        else
            . "$i" >/dev/null
        fi
    fi
done

unset i
unset -f pathmunge
export LANG=en_US.UTF-8
export HISTTIMEFORMAT="%F %T `whoami` "

export JAVA_HOME=/usr/local/jdk
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib

# æŸ¥çœ‹Dockerfile
[root@worker-01 jdk-17]#cat Dockerfile 
#JDK Base Image
FROM harbor.mysticalrecluse.com/baseimages/mystical-centos-base:7.9.2009

MAINTAINER Mystical "mysticalrecluse@gmail.com"

ADD jdk-17.0.15_linux-x64_bin.tar.gz /usr/local/src/
RUN ln -sv /usr/local/src/jdk-17.0.15 /usr/local/jdk
ADD profile /etc/profile


ENV JAVA_HOME /usr/local/jdk
ENV CLASSPATH $JAVA_HOME/lib/
ENV PATH $PATH:$JAVA_HOME/bin

# æŸ¥çœ‹build-command.sh
[root@worker-01 jdk-17]#cat build-command.sh 
#!/bin/bash
nerdctl build -t harbor.mysticalrecluse.com/pub-images/jdk-base:v17.0.15 .
sleep 1
nerdctl push harbor.mysticalrecluse.com/pub-images/jdk-base:v17.0.15

# æ„å»ºé•œåƒ
[root@worker-01 jdk-17]#bash build-command.sh

# æµ‹è¯•é•œåƒ
[root@worker-01 jdk-17]#nerdctl run -it --rm --name jdk17 harbor.mysticalrecluse.com/pub-images/jdk-base:v17.0.15 /bin/bash
[root@af6cab8c3b75 /]# 
[root@af6cab8c3b75 /]# 
[root@af6cab8c3b75 /]# java -version 
java version "17.0.15" 2025-04-15 LTS
Java(TM) SE Runtime Environment (build 17.0.15+9-LTS-241)
Java HotSpot(TM) 64-Bit Server VM (build 17.0.15+9-LTS-241, mixed mode, sharing)
[root@af6cab8c3b75 /]# exit
exit
```



#### æ„å»ºä¸šåŠ¡é•œåƒ

```bash
# ä½¿ç”¨ç‰ˆæœ¬ä¸ºjava17 + jenkins2.492
[root@worker-01 jenkins]#ls
build-command.sh  Dockerfile  jenkins.war  run_jenkins.sh

#æŸ¥çœ‹Dockerfile
[root@worker-01 jenkins]#cat Dockerfile 
#Jenkins Version 2.492
FROM harbor.mysticalrecluse.com/pub-images/jdk-base:v17.0.15

MAINTAINER mystical mysticalrecluse@gmail.com

RUN yum install -y \
    freetype \
    freetype-devel \
    fontconfig \
    fontconfig-devel && \
    yum clean all

ADD jenkins.war /apps/jenkins/
ADD run_jenkins.sh /usr/bin/
RUN chmod +x /usr/bin/run_jenkins.sh


EXPOSE 8080 

CMD ["/usr/bin/run_jenkins.sh"]

# æŸ¥çœ‹run_jenkins.sh
[root@worker-01 jenkins]#cat run_jenkins.sh 
#!/bin/bash
# æ³¨æ„ï¼š --webroot=/apps/jenkins/jenkins-dataï¼Œè¿™ä¸ªç›®å½•ä¸èƒ½ä½œä¸ºæŒ‚è½½å·ï¼Œæ¯”å¦‚pv/pvcï¼Œå› ä¸ºjenkinsåœ¨åˆå§‹åŒ–çš„æ—¶å€™ï¼Œä¼šæ¸…ç©ºè¯¥ç›®å½•ï¼Œè€Œä¸”é‡Œé¢é€šå¸¸ä¿æŒçš„éƒ½æ˜¯jenkinsçš„ç¼“å­˜ä¸´æ—¶æ–‡ä»¶ï¼Œæ²¡æœ‰æŒä¹…åŒ–çš„å¿…è¦
cd /apps/jenkins && java -server -Xms1024m -Xmx1024m -Xss512k -jar jenkins.war --webroot=/apps/jenkins/jenkins-data --httpPort=8080

# æŸ¥çœ‹build-command.sh
[root@worker-01 jenkins]#cat build-command.sh 
#!/bin/bash
nerdctl build -t  harbor.mysticalrecluse.com/myserver/jenkins:v2.492 .
echo "é•œåƒåˆ¶ä½œå®Œæˆï¼Œå³å°†ä¸Šä¼ è‡³HarboræœåŠ¡å™¨"
sleep 1
nerdctl push harbor.mysticalrecluse.com/myserver/jenkins:v2.492
echo "é•œåƒä¸Šä¼ å®Œæˆ"
```



#### åˆ›å»ºyamlæ¸…å•æ–‡ä»¶

```yaml
[root@master-01 ~]#cat jenkins.yaml 
kind: Deployment
#apiVersion: extensions/v1beta1
apiVersion: apps/v1
metadata:
  labels:
    app: magedu-jenkins
  name: magedu-jenkins-deployment
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: magedu-jenkins
  template:
    metadata:
      labels:
        app: magedu-jenkins
    spec:
      containers:
      - name: magedu-jenkins-container
        image: harbor.mysticalrecluse.com/myserver/jenkins:v2.492
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          protocol: TCP
          name: http
        volumeMounts:
        - mountPath: "/root/.jenkins"
          name: jenkins-root-datadir
      securityContext:                          # è¿™é‡Œè¦æˆæƒï¼Œå¦åˆ™jenkinsæ²¡æœ‰æƒé™ä¼š403
        runAsUser: 0
      volumes:
        - name: jenkins-root-datadir
          persistentVolumeClaim:
            claimName: jenkins-root-data-pvc

---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: magedu-jenkins
  name: magedu-jenkins-service
  namespace: proc-test
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
    nodePort: 30880
  selector:
    app: magedu-jenkins

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: jenkins-root-data-pvc
  namespace: proc-test
spec:
  storageClassName: sc-nfs
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
```



#### åœ¨Kubernetesèµ·jenminsæœåŠ¡

```bash
[root@master-01 ~]#kubectl apply -f jenkins.yaml

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get pod -n proc-test magedu-jenkins-deployment-666d865657-f5ctn 
NAME                                         READY   STATUS    RESTARTS   AGE
magedu-jenkins-deployment-666d865657-f5ctn   1/1     Running   0          14m
```



### ä¸šåŠ¡å®¹å™¨åŒ–æ¡ˆä¾‹ä¹‹ä¸ƒï¼šdubboå¾®æœåŠ¡

![image-20250422103507993](../markdown_img/image-20250422103507993.png)



#### å¾®æœåŠ¡ç›®å½•ç»“æ„

```bash
[root@worker-01 dubbo]#ls
consumer  dubboadmin  provider
```



#### æ„å»ºç”Ÿäº§è€…Provideré•œåƒ

```bash
# provideré•œåƒç›®å½•
[root@worker-01 provider]#ls
build-command.sh  dubbo-demo-provider-2.1.5                  run_java.sh
Dockerfile        dubbo-demo-provider-2.1.5-assembly.tar.gz

# ä¿®æ”¹providerçš„é…ç½®ï¼Œé…åˆ¶æ³¨å†Œä¸­å¿ƒçš„åœ°å€
[root@worker-01 conf]#pwd
/opt/k8s-data/dockerfile/web/magedu/dubbo/provider/dubbo-demo-provider-2.1.5/conf

[root@worker-01 conf]#cat dubbo.properties 
##
# Copyright 1999-2011 Alibaba Group.
#  
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#  
#      http://www.apache.org/licenses/LICENSE-2.0
#  
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##
dubbo.container=log4j,spring
dubbo.application.name=demo-provider
dubbo.application.owner=
#dubbo.registry.address=multicast://224.5.6.7:1234
# è¿™é‡Œçš„åœ°å€å†™çš„æ˜¯zookeeperçš„service
dubbo.registry.address=zookeeper://zookeeper1.proc-test.svc.cluster.local:2181 | zookeeper://zookeeper2.proc-test.svc.cluster.local:2181 | zookeeper://zookeeper3.proc-test.svc.cluster.local:2181
#dubbo.registry.address="zookeeper://zookeeper1.linux36.svc.linux36.local:2181,"
#dubbo.registry.address=zookeeper://zookeeper1.linux36.svc.linux36.local:2181 | zookeeper2.linux36.svc.linux36.local:2181 | zookeeper3.linux36.svc.linux36.local:2181
#dubbo.registry.address=redis://127.0.0.1:6379
#dubbo.registry.address=dubbo://127.0.0.1:9090
dubbo.monitor.protocol=registry
dubbo.protocol.name=dubbo
dubbo.protocol.port=20880
dubbo.log4j.file=logs/dubbo-demo-provider.log
dubbo.log4j.level=WARN

# æŸ¥çœ‹Dockerfile
[root@worker-01 provider]#cat Dockerfile 
#Dubbo provider
FROM harbor.mysticalrecluse.com/pub-images/jdk-base:v8.212 

MAINTAINER mystical "mysticalrecluse@gmail.com"

RUN yum install file nc -y
RUN mkdir -p /apps/dubbo/provider
ADD dubbo-demo-provider-2.1.5/  /apps/dubbo/provider
ADD run_java.sh /apps/dubbo/provider/bin 
RUN chown nginx.nginx /apps -R
RUN chmod a+x /apps/dubbo/provider/bin/*.sh

CMD ["/apps/dubbo/provider/bin/run_java.sh"]


# æŸ¥çœ‹
[root@worker-01 provider]#cat run_java.sh 
#!/bin/bash
#echo "nameserver 223.6.6.6" > /etc/resolv.conf
#/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat  &
su - nginx -c "/apps/dubbo/provider/bin/start.sh"
tail -f /etc/hosts

# æŸ¥çœ‹build-command.sh
[root@worker-01 provider]#cat build-command.sh 
#!/bin/bash
nerdctl build -t harbor.mysticalrecluse.com/myserver/dubbo-demo-provider:v1  .
sleep 3
nerdctl push harbor.mysticalrecluse.com/myserver/dubbo-demo-provider:v1

# æ„å»ºé•œåƒ
[root@worker-01 provider]#bash build-command.sh
```



#### ä½¿ç”¨yamlæ¸…å•æ–‡ä»¶å¯ç”¨Provider

```bash
[root@worker-01 provider]#cat provider.yaml 
kind: Deployment
#apiVersion: extensions/v1beta1
apiVersion: apps/v1
metadata:
  labels:
    app: magedu-provider
  name: magedu-provider-deployment
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: magedu-provider
  template:
    metadata:
      labels:
        app: magedu-provider
    spec:
      containers:
      - name: magedu-provider-container
        image: harbor.mysticalrecluse.com/myserver/dubbo-demo-provider:v1 
        #command: ["/apps/tomcat/bin/run_tomcat.sh"]
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        ports:
        - containerPort: 20880
          protocol: TCP
          name: http

---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: magedu-provider
  name: magedu-provider-spec
  namespace: proc-test
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 20880
    #nodePort: 30001
  selector:
    app: magedu-provider
    
# å¯ç”¨
[root@master-01 ~]#kubectl apply -f provider.yaml
```



#### æ„å»ºæ¶ˆè´¹è€…consumeré•œåƒ

```bash
# æŸ¥çœ‹ç›®å½•ç»“æ„
[root@worker-01 consumer]#ls
build-command.sh  dubbo-demo-consumer-2.1.5                  run_java.sh
Dockerfile        dubbo-demo-consumer-2.1.5-assembly.tar.gz

# æŸ¥çœ‹Dockerfile
[root@worker-01 consumer]#cat Dockerfile 
#Dubbo consumer
FROM harbor.mysticalrecluse.com/pub-images/jdk-base:v8.212 

MAINTAINER mystical "mysticalrecluse@gmail.com"

RUN yum install file -y
RUN mkdir -p /apps/dubbo/consumer 
ADD dubbo-demo-consumer-2.1.5  /apps/dubbo/consumer
ADD run_java.sh /apps/dubbo/consumer/bin 
RUN chown nginx.nginx /apps -R
RUN chmod a+x /apps/dubbo/consumer/bin/*.sh

CMD ["/apps/dubbo/consumer/bin/run_java.sh"]

# æ›´æ”¹consumeré…ç½®é›†ä¸­çš„æ³¨å†Œä¸­å¿ƒåœ°å€
[root@worker-01 consumer]#cat dubbo-demo-consumer-2.1.5/conf/dubbo.properties 
##
# Copyright 1999-2011 Alibaba Group.
#  
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#  
#      http://www.apache.org/licenses/LICENSE-2.0
#  
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##
dubbo.container=log4j,spring
dubbo.application.name=demo-consumer
dubbo.application.owner=
#dubbo.registry.address=multicast://224.5.6.7:1234
# è¿™é‡Œæ›´æ”¹ä¸ºzookeeperçš„serviceåœ°å€
dubbo.registry.address=zookeeper://zookeeper1.proc-test.svc.cluster.local:2181 | zookeeper://zookeeper2.proc-test.svc.cluster.local:2181 | zookeeper://zookeeper3.proc-test.svc.cluster.local:2181
#dubbo.registry.address=redis://127.0.0.1:6379
#dubbo.registry.address=dubbo://127.0.0.1:9090
dubbo.monitor.protocol=registry
dubbo.log4j.file=logs/dubbo-demo-consumer.log
dubbo.log4j.level=WARN

# æŸ¥çœ‹å¯åŠ¨è„šæœ¬run_java.sh 
[root@worker-01 consumer]#cat run_java.sh 
#!/bin/bash
#echo "nameserver 223.6.6.6" > /etc/resolv.conf
#/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat  &
su - nginx -c "/apps/dubbo/consumer/bin/start.sh"
tail -f /etc/hosts

# æŸ¥çœ‹ä»£ç æ„å»ºè„šæœ¬
[root@worker-01 consumer]#cat build-command.sh 
#!/bin/bash
nerdctl build -t harbor.mysticalrecluse.com/myserver/dubbo-demo-consumer:v1  .
sleep 3
nerdctl push harbor.mysticalrecluse.com/myserver/dubbo-demo-consumer:v1

# æ„å»ºé•œåƒ
[root@worker-01 consumer]#bash build-command.sh
```



#### ä½¿ç”¨æ¸…å•æ–‡ä»¶å¯ç”¨consumer

```yaml
[root@worker-01 consumer]#cat consumer.yaml 
kind: Deployment
#apiVersion: extensions/v1beta1
apiVersion: apps/v1
metadata:
  labels:
    app: magedu-consumer
  name: magedu-consumer-deployment
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: magedu-consumer
  template:
    metadata:
      labels:
        app: magedu-consumer
    spec:
      containers:
      - name: magedu-consumer-container
        image: harbor.mysticalrecluse.com/myserver/dubbo-demo-consumer:v1 
        #command: ["/apps/tomcat/bin/run_tomcat.sh"]
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        ports:
        - containerPort: 80
          protocol: TCP
          name: http

---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: magedu-consumer
  name: magedu-consumer-server
  namespace: proc-test
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
    #nodePort: 30001
  selector:
    app: magedu-consumer
```

```bash
# å¯ç”¨consumerï¼Œå¹¶æµ‹è¯•
[root@master-01 ~]#kubectl apply -f consumer.yaml
[root@master-01 ~]#kubectl exec -it -n proc-test magedu-consumer-deployment-c98b7cb48-5bkc7 -- bash
[root@magedu-consumer-deployment-c98b7cb48-5bkc7 /]# cd /apps/dubbo/consumer/
[root@magedu-consumer-deployment-c98b7cb48-5bkc7 consumer]# ls
bin  conf  lib  logs
[root@magedu-consumer-deployment-c98b7cb48-5bkc7 consumer]# cd logs
[root@magedu-consumer-deployment-c98b7cb48-5bkc7 logs]# ls
dubbo-demo-consumer.log  stdout.log
[root@magedu-consumer-deployment-c98b7cb48-5bkc7 logs]# tail -f stdout.log 
[11:37:17] Hello world71, response form provider: 10.200.171.42:20880
[11:37:19] Hello world72, response form provider: 10.200.171.42:20880
[11:37:21] Hello world73, response form provider: 10.200.171.42:20880
[11:37:23] Hello world74, response form provider: 10.200.171.42:20880

# å¢åŠ ç”Ÿäº§è€…providerçš„å‰¯æœ¬æ•°
[root@master-01 ~]#kubectl scale deployment -n proc-test magedu-provider-deployment --replicas 3
deployment.apps/magedu-provider-deployment scaled

# æŸ¥çœ‹æ¶ˆè´¹è€…ï¼Œæ¶ˆè´¹è€…ä¼šè‡ªåŠ¨ä»é…ç½®ä¸­å¿ƒæ‰¾åˆ°ç”Ÿäº§è€…çš„åœ°å€ï¼Œå¹¶è¿›è¡Œæ¶ˆè´¹
[root@master-01 ~]#kubectl exec -it -n proc-test magedu-consumer-deployment-c98b7cb48-5bkc7 -- bash
[root@magedu-consumer-deployment-c98b7cb48-5bkc7 /]# tail -f /apps/dubbo/consumer/logs/stdout.log 
[11:40:26] Hello world165, response form provider: 10.200.171.42:20880
[11:40:28] Hello world166, response form provider: 10.200.129.3:20880
[11:40:30] Hello world167, response form provider: 10.200.171.42:20880
[11:40:32] Hello world168, response form provider: 10.200.37.210:20880
[11:40:34] Hello world169, response form provider: 10.200.129.3:20880
[11:40:36] Hello world170, response form provider: 10.200.171.42:20880
[11:40:38] Hello world171, response form provider: 10.200.37.210:20880
[11:40:40] Hello world172, response form provider: 10.200.129.3:20880
[11:40:42] Hello world173, response form provider: 10.200.171.42:20880
[11:40:44] Hello world174, response form provider: 10.200.37.210:20880
[11:40:46] Hello world175, response form provider: 10.200.129.3:20880
[11:40:48] Hello world176, response form provider: 10.200.171.42:20880
[11:40:50] Hello world177, response form provider: 10.200.37.210:20880

```



#### æ„å»ºç”Ÿäº§è€…/æ¶ˆè´¹è€…çš„ç®¡ç†ç«¯é•œåƒ

```bash
# æŸ¥çœ‹ç›®å½•
[root@worker-01 dubboadmin]#ls
build-command.sh  Dockerfile  dubboadmin.war      logging.properties  server.xml
catalina.sh       dubboadmin  dubboadmin.war.bak  run_tomcat.sh

# æŸ¥çœ‹Dockerfile
[root@worker-01 dubboadmin]#cat Dockerfile 
#Dubbo dubboadmin
#FROM harbor.magedu.local/pub-images/tomcat-base:v8.5.43 
FROM harbor.mysticalrecluse.com/pub-images/tomcat-base:v8.5.43 

MAINTAINER mystical "mysticalrecluse@gmail.com"

RUN yum install unzip -y  
ADD server.xml /apps/tomcat/conf/server.xml
ADD logging.properties /apps/tomcat/conf/logging.properties
ADD catalina.sh /apps/tomcat/bin/catalina.sh
ADD run_tomcat.sh /apps/tomcat/bin/run_tomcat.sh
RUN chmod +x /apps/tomcat/bin/run_tomcat.sh
RUN chmod +x /apps/tomcat/bin/catalina.sh
ADD dubboadmin.war  /data/tomcat/webapps/dubboadmin.war
RUN cd /data/tomcat/webapps && unzip dubboadmin.war && rm -rf dubboadmin.war && chown -R nginx.nginx /data /apps
RUN sed -ir 's@dubbo.registry.address=zookeeper://zookeeper1.magedu.svc.magedu.local:2181@dubbo.registry.address=zookeeper://zookeeper1.proc-test.svc.cluster.local:2181@' /data/tomcat/webapps/dubboadmin/WEB-INF/dubbo.properties

EXPOSE 8080 8443

CMD ["/apps/tomcat/bin/run_tomcat.sh"]


# æŸ¥çœ‹run_tomcat.sh
[root@worker-01 dubboadmin]#cat run_tomcat.sh 
#!/bin/bash

su - nginx -c "/apps/tomcat/bin/catalina.sh start"
su - nginx -c "tail -f /etc/hosts"

# æŸ¥çœ‹logging.properties 
[root@worker-01 dubboadmin]#cat logging.properties 
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

handlers = 1catalina.org.apache.juli.AsyncFileHandler, 2localhost.org.apache.juli.AsyncFileHandler, 3manager.org.apache.juli.AsyncFileHandler, 4host-manager.org.apache.juli.AsyncFileHandler, java.util.logging.ConsoleHandler

.handlers = 1catalina.org.apache.juli.AsyncFileHandler, java.util.logging.ConsoleHandler

############################################################
# Handler specific properties.
# Describes specific configuration info for Handlers.
############################################################

1catalina.org.apache.juli.AsyncFileHandler.level = FINE
1catalina.org.apache.juli.AsyncFileHandler.directory = /data/tomcat/logs
1catalina.org.apache.juli.AsyncFileHandler.prefix = catalina.

2localhost.org.apache.juli.AsyncFileHandler.level = FINE
2localhost.org.apache.juli.AsyncFileHandler.directory = /data/tomcat/logs 
2localhost.org.apache.juli.AsyncFileHandler.prefix = localhost.

3manager.org.apache.juli.AsyncFileHandler.level = FINE
3manager.org.apache.juli.AsyncFileHandler.directory = /data/tomcat/logs
3manager.org.apache.juli.AsyncFileHandler.prefix = manager.

4host-manager.org.apache.juli.AsyncFileHandler.level = FINE
4host-manager.org.apache.juli.AsyncFileHandler.directory = /data/tomcat/logs
4host-manager.org.apache.juli.AsyncFileHandler.prefix = host-manager.

java.util.logging.ConsoleHandler.level = FINE
java.util.logging.ConsoleHandler.formatter = org.apache.juli.OneLineFormatter


############################################################
# Facility specific properties.
# Provides extra control for each logger.
############################################################

org.apache.catalina.core.ContainerBase.[Catalina].[localhost].level = INFO
org.apache.catalina.core.ContainerBase.[Catalina].[localhost].handlers = 2localhost.org.apache.juli.AsyncFileHandler

org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].level = INFO
org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].handlers = 3manager.org.apache.juli.AsyncFileHandler

org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].level = INFO
org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].handlers = 4host-manager.org.apache.juli.AsyncFileHandler

# For example, set the org.apache.catalina.util.LifecycleBase logger to log
# each component that extends LifecycleBase changing state:
#org.apache.catalina.util.LifecycleBase.level = FINE

# To see debug messages in TldLocationsCache, uncomment the following line:
#org.apache.jasper.compiler.TldLocationsCache.level = FINE

# æŸ¥çœ‹server.xml
[root@worker-01 dubboadmin]#cat server.xml 
<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
--><!-- Note:  A "Server" is not itself a "Container", so you may not
     define subcomponents such as "Valves" at this level.
     Documentation at /docs/config/server.html
 --><Server port="8005" shutdown="SHUTDOWN">
  <Listener className="org.apache.catalina.startup.VersionLoggerListener"/>
  <!-- Security listener. Documentation at /docs/config/listeners.html
  <Listener className="org.apache.catalina.security.SecurityListener" />
  -->
  <!--APR library loader. Documentation at /docs/apr.html -->
  <Listener SSLEngine="on" className="org.apache.catalina.core.AprLifecycleListener"/>
  <!-- Prevent memory leaks due to use of particular java/javax APIs-->
  <Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener"/>
  <Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener"/>
  <Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener"/>

  <!-- Global JNDI resources
       Documentation at /docs/jndi-resources-howto.html
  -->
  <GlobalNamingResources>
    <!-- Editable user database that can also be used by
         UserDatabaseRealm to authenticate users
    -->
    <Resource auth="Container" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" name="UserDatabase" pathname="conf/tomcat-users.xml" type="org.apache.catalina.UserDatabase"/>
  </GlobalNamingResources>

  <!-- A "Service" is a collection of one or more "Connectors" that share
       a single "Container" Note:  A "Service" is not itself a "Container",
       so you may not define subcomponents such as "Valves" at this level.
       Documentation at /docs/config/service.html
   -->
  <Service name="Catalina">

    <!--The connectors can use a shared executor, you can define one or more named thread pools-->
    <!--
    <Executor name="tomcatThreadPool" namePrefix="catalina-exec-"
        maxThreads="150" minSpareThreads="4"/>
    -->


    <!-- A "Connector" represents an endpoint by which requests are received
         and responses are returned. Documentation at :
         Java HTTP Connector: /docs/config/http.html (blocking & non-blocking)
         Java AJP  Connector: /docs/config/ajp.html
         APR (HTTP/AJP) Connector: /docs/apr.html
         Define a non-SSL/TLS HTTP/1.1 Connector on port 8080
    -->
    <Connector connectionTimeout="20000" port="8080" protocol="HTTP/1.1" redirectPort="8443"/>
    <!-- A "Connector" using the shared thread pool-->
    <!--
    <Connector executor="tomcatThreadPool"
               port="8080" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" />
    -->
    <!-- Define a SSL/TLS HTTP/1.1 Connector on port 8443
         This connector uses the NIO implementation that requires the JSSE
         style configuration. When using the APR/native implementation, the
         OpenSSL style configuration is required as described in the APR/native
         documentation -->
    <!--
    <Connector port="8443" protocol="org.apache.coyote.http11.Http11NioProtocol"
               maxThreads="150" SSLEnabled="true" scheme="https" secure="true"
               clientAuth="false" sslProtocol="TLS" />
    -->

    <!-- Define an AJP 1.3 Connector on port 8009 -->
    <Connector port="8009" protocol="AJP/1.3" redirectPort="8443"/>


    <!-- An Engine represents the entry point (within Catalina) that processes
         every request.  The Engine implementation for Tomcat stand alone
         analyzes the HTTP headers included with the request, and passes them
         on to the appropriate Host (virtual host).
         Documentation at /docs/config/engine.html -->

    <!-- You should set jvmRoute to support load-balancing via AJP ie :
    <Engine name="Catalina" defaultHost="localhost" jvmRoute="jvm1">
    -->
    <Engine defaultHost="localhost" name="Catalina">

      <!--For clustering, please take a look at documentation at:
          /docs/cluster-howto.html  (simple how to)
          /docs/config/cluster.html (reference documentation) -->
      <!--
      <Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"/>
      -->

      <!-- Use the LockOutRealm to prevent attempts to guess user passwords
           via a brute-force attack -->
      <Realm className="org.apache.catalina.realm.LockOutRealm">
        <!-- This Realm uses the UserDatabase configured in the global JNDI
             resources under the key "UserDatabase".  Any edits
             that are performed against this UserDatabase are immediately
             available for use by the Realm.  -->
        <Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/>
      </Realm>

      <Host appBase="/data/tomcat/webapps" autoDeploy="true" name="localhost" unpackWARs="true">

        <!-- SingleSignOn valve, share authentication between web applications
             Documentation at: /docs/config/valve.html -->
        <!--
        <Valve className="org.apache.catalina.authenticator.SingleSignOn" />
        -->

        <!-- Access log processes all example.
             Documentation at: /docs/config/valve.html
             Note: The pattern used is equivalent to using pattern="common" -->
        <Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" pattern="%h %l %u %t &quot;%r&quot; %s %b" prefix="localhost_access_log" suffix=".txt"/>

        <Context docBase="dubboadmin" path="/" reloadable="true" source="org.eclipse.jst.jee.server:dubboadmin"/>

	</Host>
    </Engine>
  </Service>
</Server>

# æŸ¥çœ‹catalina.sh
[root@worker-01 dubboadmin]#cat catalina.sh 
#!/bin/sh

# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# -----------------------------------------------------------------------------
# Control Script for the CATALINA Server
#
# Environment Variable Prerequisites
#
#   Do not set the variables in this script. Instead put them into a script
#   setenv.sh in CATALINA_BASE/bin to keep your customizations separate.
#
#   CATALINA_HOME   May point at your Catalina "build" directory.
#
#   CATALINA_BASE   (Optional) Base directory for resolving dynamic portions
#                   of a Catalina installation.  If not present, resolves to
#                   the same directory that CATALINA_HOME points to.
#
#   CATALINA_OUT    (Optional) Full path to a file where stdout and stderr
#                   will be redirected.
#                   Default is $CATALINA_BASE/logs/catalina.out
#
#   CATALINA_OPTS   (Optional) Java runtime options used when the "start",
#                   "run" or "debug" command is executed.
#                   Include here and not in JAVA_OPTS all options, that should
#                   only be used by Tomcat itself, not by the stop process,
#                   the version command etc.
#                   Examples are heap size, GC logging, JMX ports etc.
#
#   CATALINA_TMPDIR (Optional) Directory path location of temporary directory
#                   the JVM should use (java.io.tmpdir).  Defaults to
#                   $CATALINA_BASE/temp.
#
#   JAVA_HOME       Must point at your Java Development Kit installation.
#                   Required to run the with the "debug" argument.
#
#   JRE_HOME        Must point at your Java Runtime installation.
#                   Defaults to JAVA_HOME if empty. If JRE_HOME and JAVA_HOME
#                   are both set, JRE_HOME is used.
#
#   JAVA_OPTS       (Optional) Java runtime options used when any command
#                   is executed.
#                   Include here and not in CATALINA_OPTS all options, that
#                   should be used by Tomcat and also by the stop process,
#                   the version command etc.
#                   Most options should go into CATALINA_OPTS.
#
#   JAVA_ENDORSED_DIRS (Optional) Lists of of colon separated directories
#                   containing some jars in order to allow replacement of APIs
#                   created outside of the JCP (i.e. DOM and SAX from W3C).
#                   It can also be used to update the XML parser implementation.
#                   Defaults to $CATALINA_HOME/endorsed.
#
#   JPDA_TRANSPORT  (Optional) JPDA transport used when the "jpda start"
#                   command is executed. The default is "dt_socket".
#
#   JPDA_ADDRESS    (Optional) Java runtime options used when the "jpda start"
#                   command is executed. The default is localhost:8000.
#
#   JPDA_SUSPEND    (Optional) Java runtime options used when the "jpda start"
#                   command is executed. Specifies whether JVM should suspend
#                   execution immediately after startup. Default is "n".
#
#   JPDA_OPTS       (Optional) Java runtime options used when the "jpda start"
#                   command is executed. If used, JPDA_TRANSPORT, JPDA_ADDRESS,
#                   and JPDA_SUSPEND are ignored. Thus, all required jpda
#                   options MUST be specified. The default is:
#
#                   -agentlib:jdwp=transport=$JPDA_TRANSPORT,
#                       address=$JPDA_ADDRESS,server=y,suspend=$JPDA_SUSPEND
#
#   CATALINA_PID    (Optional) Path of the file which should contains the pid
#                   of the catalina startup java process, when start (fork) is
#                   used
#
#   LOGGING_CONFIG  (Optional) Override Tomcat's logging config file
#                   Example (all one line)
#                   LOGGING_CONFIG="-Djava.util.logging.config.file=$CATALINA_BASE/conf/logging.properties"
#
#   LOGGING_MANAGER (Optional) Override Tomcat's logging manager
#                   Example (all one line)
#                   LOGGING_MANAGER="-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager"
# -----------------------------------------------------------------------------
# ä¼˜åŒ–jvm
JAVA_OPTS="-server -Xms512m -Xmx512m -Xss512k -Xmn1g -XX:CMSInitiatingOccupancyFraction=65  -XX:+UseFastAccessorMethods -XX:+AggressiveOpts -XX:+UseBiasedLocking -XX:+DisableExplicitGC -XX:MaxTenuringThreshold=10 -XX:NewSize=2048M -XX:MaxNewSize=2048M -XX:NewRatio=2 -XX:PermSize=128m -XX:MaxPermSize=512m -XX:CMSFullGCsBeforeCompaction=5 -XX:+ExplicitGCInvokesConcurrent -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods"

# OS specific support.  $var _must_ be set to either true or false.
cygwin=false
darwin=false
os400=false
case "`uname`" in
CYGWIN*) cygwin=true;;
Darwin*) darwin=true;;
OS400*) os400=true;;
esac

# resolve links - $0 may be a softlink
PRG="$0"

while [ -h "$PRG" ]; do
  ls=`ls -ld "$PRG"`
  link=`expr "$ls" : '.*-> \(.*\)$'`
  if expr "$link" : '/.*' > /dev/null; then
    PRG="$link"
  else
    PRG=`dirname "$PRG"`/"$link"
  fi
done

# Get standard environment variables
PRGDIR=`dirname "$PRG"`

# Only set CATALINA_HOME if not already set
[ -z "$CATALINA_HOME" ] && CATALINA_HOME=`cd "$PRGDIR/.." >/dev/null; pwd`

# Copy CATALINA_BASE from CATALINA_HOME if not already set
[ -z "$CATALINA_BASE" ] && CATALINA_BASE="$CATALINA_HOME"

# Ensure that neither CATALINA_HOME nor CATALINA_BASE contains a colon
# as this is used as the separator in the classpath and Java provides no
# mechanism for escaping if the same character appears in the path.
case $CATALINA_HOME in
  *:*) echo "Using CATALINA_HOME:   $CATALINA_HOME";
       echo "Unable to start as CATALINA_HOME contains a colon (:) character";
       exit 1;
esac
case $CATALINA_BASE in
  *:*) echo "Using CATALINA_BASE:   $CATALINA_BASE";
       echo "Unable to start as CATALINA_BASE contains a colon (:) character";
       exit 1;
esac

# Ensure that any user defined CLASSPATH variables are not used on startup,
# but allow them to be specified in setenv.sh, in rare case when it is needed.
CLASSPATH=

if [ -r "$CATALINA_BASE/bin/setenv.sh" ]; then
  . "$CATALINA_BASE/bin/setenv.sh"
elif [ -r "$CATALINA_HOME/bin/setenv.sh" ]; then
  . "$CATALINA_HOME/bin/setenv.sh"
fi

# For Cygwin, ensure paths are in UNIX format before anything is touched
if $cygwin; then
  [ -n "$JAVA_HOME" ] && JAVA_HOME=`cygpath --unix "$JAVA_HOME"`
  [ -n "$JRE_HOME" ] && JRE_HOME=`cygpath --unix "$JRE_HOME"`
  [ -n "$CATALINA_HOME" ] && CATALINA_HOME=`cygpath --unix "$CATALINA_HOME"`
  [ -n "$CATALINA_BASE" ] && CATALINA_BASE=`cygpath --unix "$CATALINA_BASE"`
  [ -n "$CLASSPATH" ] && CLASSPATH=`cygpath --path --unix "$CLASSPATH"`
fi

# For OS400
if $os400; then
  # Set job priority to standard for interactive (interactive - 6) by using
  # the interactive priority - 6, the helper threads that respond to requests
  # will be running at the same priority as interactive jobs.
  COMMAND='chgjob job('$JOBNAME') runpty(6)'
  system $COMMAND

  # Enable multi threading
  export QIBM_MULTI_THREADED=Y
fi

# Get standard Java environment variables
if $os400; then
  # -r will Only work on the os400 if the files are:
  # 1. owned by the user
  # 2. owned by the PRIMARY group of the user
  # this will not work if the user belongs in secondary groups
  . "$CATALINA_HOME"/bin/setclasspath.sh
else
  if [ -r "$CATALINA_HOME"/bin/setclasspath.sh ]; then
    . "$CATALINA_HOME"/bin/setclasspath.sh
  else
    echo "Cannot find $CATALINA_HOME/bin/setclasspath.sh"
    echo "This file is needed to run this program"
    exit 1
  fi
fi

# Add on extra jar files to CLASSPATH
if [ ! -z "$CLASSPATH" ] ; then
  CLASSPATH="$CLASSPATH":
fi
CLASSPATH="$CLASSPATH""$CATALINA_HOME"/bin/bootstrap.jar

if [ -z "$CATALINA_OUT" ] ; then
  CATALINA_OUT="$CATALINA_BASE"/logs/catalina.out
fi

if [ -z "$CATALINA_TMPDIR" ] ; then
  # Define the java.io.tmpdir to use for Catalina
  CATALINA_TMPDIR="$CATALINA_BASE"/temp
fi

# Add tomcat-juli.jar to classpath
# tomcat-juli.jar can be over-ridden per instance
if [ -r "$CATALINA_BASE/bin/tomcat-juli.jar" ] ; then
  CLASSPATH=$CLASSPATH:$CATALINA_BASE/bin/tomcat-juli.jar
else
  CLASSPATH=$CLASSPATH:$CATALINA_HOME/bin/tomcat-juli.jar
fi

# Bugzilla 37848: When no TTY is available, don't output to console
have_tty=0
if [ "`tty`" != "not a tty" ]; then
    have_tty=1
fi

# For Cygwin, switch paths to Windows format before running java
if $cygwin; then
  JAVA_HOME=`cygpath --absolute --windows "$JAVA_HOME"`
  JRE_HOME=`cygpath --absolute --windows "$JRE_HOME"`
  CATALINA_HOME=`cygpath --absolute --windows "$CATALINA_HOME"`
  CATALINA_BASE=`cygpath --absolute --windows "$CATALINA_BASE"`
  CATALINA_TMPDIR=`cygpath --absolute --windows "$CATALINA_TMPDIR"`
  CLASSPATH=`cygpath --path --windows "$CLASSPATH"`
  JAVA_ENDORSED_DIRS=`cygpath --path --windows "$JAVA_ENDORSED_DIRS"`
fi

# Set juli LogManager config file if it is present and an override has not been issued
if [ -z "$LOGGING_CONFIG" ]; then
  if [ -r "$CATALINA_BASE"/conf/logging.properties ]; then
    LOGGING_CONFIG="-Djava.util.logging.config.file=$CATALINA_BASE/conf/logging.properties"
  else
    # Bugzilla 45585
    LOGGING_CONFIG="-Dnop"
  fi
fi

if [ -z "$LOGGING_MANAGER" ]; then
  LOGGING_MANAGER="-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager"
fi

# Uncomment the following line to make the umask available when using the
# org.apache.catalina.security.SecurityListener
#JAVA_OPTS="$JAVA_OPTS -Dorg.apache.catalina.security.SecurityListener.UMASK=`umask`"

# ----- Execute The Requested Command -----------------------------------------

# Bugzilla 37848: only output this if we have a TTY
if [ $have_tty -eq 1 ]; then
  echo "Using CATALINA_BASE:   $CATALINA_BASE"
  echo "Using CATALINA_HOME:   $CATALINA_HOME"
  echo "Using CATALINA_TMPDIR: $CATALINA_TMPDIR"
  if [ "$1" = "debug" ] ; then
    echo "Using JAVA_HOME:       $JAVA_HOME"
  else
    echo "Using JRE_HOME:        $JRE_HOME"
  fi
  echo "Using CLASSPATH:       $CLASSPATH"
  if [ ! -z "$CATALINA_PID" ]; then
    echo "Using CATALINA_PID:    $CATALINA_PID"
  fi
fi

if [ "$1" = "jpda" ] ; then
  if [ -z "$JPDA_TRANSPORT" ]; then
    JPDA_TRANSPORT="dt_socket"
  fi
  if [ -z "$JPDA_ADDRESS" ]; then
    JPDA_ADDRESS="localhost:8000"
  fi
  if [ -z "$JPDA_SUSPEND" ]; then
    JPDA_SUSPEND="n"
  fi
  if [ -z "$JPDA_OPTS" ]; then
    JPDA_OPTS="-agentlib:jdwp=transport=$JPDA_TRANSPORT,address=$JPDA_ADDRESS,server=y,suspend=$JPDA_SUSPEND"
  fi
  CATALINA_OPTS="$JPDA_OPTS $CATALINA_OPTS"
  shift
fi

if [ "$1" = "debug" ] ; then
  if $os400; then
    echo "Debug command not available on OS400"
    exit 1
  else
    shift
    if [ "$1" = "-security" ] ; then
      if [ $have_tty -eq 1 ]; then
        echo "Using Security Manager"
      fi
      shift
      exec "$_RUNJDB" "$LOGGING_CONFIG" $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \
        -Djava.endorsed.dirs="$JAVA_ENDORSED_DIRS" -classpath "$CLASSPATH" \
        -sourcepath "$CATALINA_HOME"/../../java \
        -Djava.security.manager \
        -Djava.security.policy=="$CATALINA_BASE"/conf/catalina.policy \
        -Dcatalina.base="$CATALINA_BASE" \
        -Dcatalina.home="$CATALINA_HOME" \
        -Djava.io.tmpdir="$CATALINA_TMPDIR" \
         -Djava.awt.headless=true \
        org.apache.catalina.startup.Bootstrap "$@" start
    else
      exec "$_RUNJDB" "$LOGGING_CONFIG" $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \
        -Djava.endorsed.dirs="$JAVA_ENDORSED_DIRS" -classpath "$CLASSPATH" \
        -sourcepath "$CATALINA_HOME"/../../java \
        -Dcatalina.base="$CATALINA_BASE" \
        -Dcatalina.home="$CATALINA_HOME" \
        -Djava.io.tmpdir="$CATALINA_TMPDIR" \
         -Djava.awt.headless=true \
        org.apache.catalina.startup.Bootstrap "$@" start
    fi
  fi

elif [ "$1" = "run" ]; then

  shift
  if [ "$1" = "-security" ] ; then
    if [ $have_tty -eq 1 ]; then
      echo "Using Security Manager"
    fi
    shift
    eval exec "\"$_RUNJAVA\"" "\"$LOGGING_CONFIG\"" $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \
      -Djava.endorsed.dirs="\"$JAVA_ENDORSED_DIRS\"" -classpath "\"$CLASSPATH\"" \
      -Djava.security.manager \
      -Djava.security.policy=="\"$CATALINA_BASE/conf/catalina.policy\"" \
      -Dcatalina.base="\"$CATALINA_BASE\"" \
      -Dcatalina.home="\"$CATALINA_HOME\"" \
      -Djava.io.tmpdir="\"$CATALINA_TMPDIR\"" \
       -Djava.awt.headless=true \
      org.apache.catalina.startup.Bootstrap "$@" start
  else
    eval exec "\"$_RUNJAVA\"" "\"$LOGGING_CONFIG\"" $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \
      -Djava.endorsed.dirs="\"$JAVA_ENDORSED_DIRS\"" -classpath "\"$CLASSPATH\"" \
      -Dcatalina.base="\"$CATALINA_BASE\"" \
      -Dcatalina.home="\"$CATALINA_HOME\"" \
      -Djava.io.tmpdir="\"$CATALINA_TMPDIR\"" \
       -Djava.awt.headless=true \
      org.apache.catalina.startup.Bootstrap "$@" start
  fi

elif [ "$1" = "start" ] ; then

  if [ ! -z "$CATALINA_PID" ]; then
    if [ -f "$CATALINA_PID" ]; then
      if [ -s "$CATALINA_PID" ]; then
        echo "Existing PID file found during start."
        if [ -r "$CATALINA_PID" ]; then
          PID=`cat "$CATALINA_PID"`
          ps -p $PID >/dev/null 2>&1
          if [ $? -eq 0 ] ; then
            echo "Tomcat appears to still be running with PID $PID. Start aborted."
            echo "If the following process is not a Tomcat process, remove the PID file and try again:"
            ps -f -p $PID
            exit 1
          else
            echo "Removing/clearing stale PID file."
            rm -f "$CATALINA_PID" >/dev/null 2>&1
            if [ $? != 0 ]; then
              if [ -w "$CATALINA_PID" ]; then
                cat /dev/null > "$CATALINA_PID"
              else
                echo "Unable to remove or clear stale PID file. Start aborted."
                exit 1
              fi
            fi
          fi
        else
          echo "Unable to read PID file. Start aborted."
          exit 1
        fi
      else
        rm -f "$CATALINA_PID" >/dev/null 2>&1
        if [ $? != 0 ]; then
          if [ ! -w "$CATALINA_PID" ]; then
            echo "Unable to remove or write to empty PID file. Start aborted."
            exit 1
          fi
        fi
      fi
    fi
  fi

  shift
  touch "$CATALINA_OUT"
  if [ "$1" = "-security" ] ; then
    if [ $have_tty -eq 1 ]; then
      echo "Using Security Manager"
    fi
    shift
    eval "\"$_RUNJAVA\"" "\"$LOGGING_CONFIG\"" $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \
      -Djava.endorsed.dirs="\"$JAVA_ENDORSED_DIRS\"" -classpath "\"$CLASSPATH\"" \
      -Djava.security.manager \
      -Djava.security.policy=="\"$CATALINA_BASE/conf/catalina.policy\"" \
      -Dcatalina.base="\"$CATALINA_BASE\"" \
      -Dcatalina.home="\"$CATALINA_HOME\"" \
      -Djava.io.tmpdir="\"$CATALINA_TMPDIR\"" \
       -Djava.awt.headless=true \
      org.apache.catalina.startup.Bootstrap "$@" start \
      >> "$CATALINA_OUT" 2>&1 "&"

  else
    eval "\"$_RUNJAVA\"" "\"$LOGGING_CONFIG\"" $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \
      -Djava.endorsed.dirs="\"$JAVA_ENDORSED_DIRS\"" -classpath "\"$CLASSPATH\"" \
      -Dcatalina.base="\"$CATALINA_BASE\"" \
      -Dcatalina.home="\"$CATALINA_HOME\"" \
      -Djava.io.tmpdir="\"$CATALINA_TMPDIR\"" \
       -Djava.awt.headless=true \
      org.apache.catalina.startup.Bootstrap "$@" start \
      >> "$CATALINA_OUT" 2>&1 "&"

  fi

  if [ ! -z "$CATALINA_PID" ]; then
    echo $! > "$CATALINA_PID"
  fi

  echo "Tomcat started."

elif [ "$1" = "stop" ] ; then

  shift

  SLEEP=5
  if [ ! -z "$1" ]; then
    echo $1 | grep "[^0-9]" >/dev/null 2>&1
    if [ $? -gt 0 ]; then
      SLEEP=$1
      shift
    fi
  fi

  FORCE=0
  if [ "$1" = "-force" ]; then
    shift
    FORCE=1
  fi

  if [ ! -z "$CATALINA_PID" ]; then
    if [ -f "$CATALINA_PID" ]; then
      if [ -s "$CATALINA_PID" ]; then
        kill -0 `cat "$CATALINA_PID"` >/dev/null 2>&1
        if [ $? -gt 0 ]; then
          echo "PID file found but no matching process was found. Stop aborted."
          exit 1
        fi
      else
        echo "PID file is empty and has been ignored."
      fi
    else
      echo "\$CATALINA_PID was set but the specified file does not exist. Is Tomcat running? Stop aborted."
      exit 1
    fi
  fi

  eval "\"$_RUNJAVA\"" $LOGGING_MANAGER $JAVA_OPTS \
    -Djava.endorsed.dirs="\"$JAVA_ENDORSED_DIRS\"" -classpath "\"$CLASSPATH\"" \
    -Dcatalina.base="\"$CATALINA_BASE\"" \
    -Dcatalina.home="\"$CATALINA_HOME\"" \
    -Djava.io.tmpdir="\"$CATALINA_TMPDIR\"" \
     -Djava.awt.headless=true \
    org.apache.catalina.startup.Bootstrap "$@" stop

  # stop failed. Shutdown port disabled? Try a normal kill.
  if [ $? != 0 ]; then
    if [ ! -z "$CATALINA_PID" ]; then
      echo "The stop command failed. Attempting to signal the process to stop through OS signal."
      kill -15 `cat "$CATALINA_PID"` >/dev/null 2>&1
    fi
  fi

  if [ ! -z "$CATALINA_PID" ]; then
    if [ -f "$CATALINA_PID" ]; then
      while [ $SLEEP -ge 0 ]; do
        kill -0 `cat "$CATALINA_PID"` >/dev/null 2>&1
        if [ $? -gt 0 ]; then
          rm -f "$CATALINA_PID" >/dev/null 2>&1
          if [ $? != 0 ]; then
            if [ -w "$CATALINA_PID" ]; then
              cat /dev/null > "$CATALINA_PID"
              # If Tomcat has stopped don't try and force a stop with an empty PID file
              FORCE=0
            else
              echo "The PID file could not be removed or cleared."
            fi
          fi
          echo "Tomcat stopped."
          break
        fi
        if [ $SLEEP -gt 0 ]; then
          sleep 1
        fi
        if [ $SLEEP -eq 0 ]; then
          echo "Tomcat did not stop in time."
          if [ $FORCE -eq 0 ]; then
            echo "PID file was not removed."
          fi
          echo "To aid diagnostics a thread dump has been written to standard out."
          kill -3 `cat "$CATALINA_PID"`
        fi
        SLEEP=`expr $SLEEP - 1 `
      done
    fi
  fi

  KILL_SLEEP_INTERVAL=5
  if [ $FORCE -eq 1 ]; then
    if [ -z "$CATALINA_PID" ]; then
      echo "Kill failed: \$CATALINA_PID not set"
    else
      if [ -f "$CATALINA_PID" ]; then
        PID=`cat "$CATALINA_PID"`
        echo "Killing Tomcat with the PID: $PID"
        kill -9 $PID
        while [ $KILL_SLEEP_INTERVAL -ge 0 ]; do
            kill -0 `cat "$CATALINA_PID"` >/dev/null 2>&1
            if [ $? -gt 0 ]; then
                rm -f "$CATALINA_PID" >/dev/null 2>&1
                if [ $? != 0 ]; then
                    if [ -w "$CATALINA_PID" ]; then
                        cat /dev/null > "$CATALINA_PID"
                    else
                        echo "The PID file could not be removed."
                    fi
                fi
                echo "The Tomcat process has been killed."
                break
            fi
            if [ $KILL_SLEEP_INTERVAL -gt 0 ]; then
                sleep 1
            fi
            KILL_SLEEP_INTERVAL=`expr $KILL_SLEEP_INTERVAL - 1 `
        done
        if [ $KILL_SLEEP_INTERVAL -lt 0 ]; then
            echo "Tomcat has not been killed completely yet. The process might be waiting on some system call or might be UNINTERRUPTIBLE."
        fi
      fi
    fi
  fi

elif [ "$1" = "configtest" ] ; then

    eval "\"$_RUNJAVA\"" $LOGGING_MANAGER $JAVA_OPTS \
      -Djava.endorsed.dirs="\"$JAVA_ENDORSED_DIRS\"" -classpath "\"$CLASSPATH\"" \
      -Dcatalina.base="\"$CATALINA_BASE\"" \
      -Dcatalina.home="\"$CATALINA_HOME\"" \
      -Djava.io.tmpdir="\"$CATALINA_TMPDIR\"" \
       -Djava.awt.headless=true \
      org.apache.catalina.startup.Bootstrap configtest
    result=$?
    if [ $result -ne 0 ]; then
        echo "Configuration error detected!"
    fi
    exit $result

elif [ "$1" = "version" ] ; then

    "$_RUNJAVA"   \
      -classpath "$CATALINA_HOME/lib/catalina.jar" \
      org.apache.catalina.util.ServerInfo

else

  echo "Usage: catalina.sh ( commands ... )"
  echo "commands:"
  if $os400; then
    echo "  debug             Start Catalina in a debugger (not available on OS400)"
    echo "  debug -security   Debug Catalina with a security manager (not available on OS400)"
  else
    echo "  debug             Start Catalina in a debugger"
    echo "  debug -security   Debug Catalina with a security manager"
  fi
  echo "  jpda start        Start Catalina under JPDA debugger"
  echo "  run               Start Catalina in the current window"
  echo "  run -security     Start in the current window with security manager"
  echo "  start             Start Catalina in a separate window"
  echo "  start -security   Start in a separate window with security manager"
  echo "  stop              Stop Catalina, waiting up to 5 seconds for the process to end"
  echo "  stop n            Stop Catalina, waiting up to n seconds for the process to end"
  echo "  stop -force       Stop Catalina, wait up to 5 seconds and then use kill -KILL if still running"
  echo "  stop n -force     Stop Catalina, wait up to n seconds and then use kill -KILL if still running"
  echo "  configtest        Run a basic syntax check on server.xml - check exit code for result"
  echo "  version           What version of tomcat are you running?"
  echo "Note: Waiting for the process to end and use of the -force option require that \$CATALINA_PID is defined"
  exit 1

fi

# æŸ¥çœ‹å¯åŠ¨è„šæœ¬
[root@worker-01 dubboadmin]#cat build-command.sh 
#!/bin/bash
TAG=$1
nerdctl build -t harbor.mysticalrecluse.com/myserver/dubboadmin:${TAG}  .
sleep 3
nerdctl push  harbor.mysticalrecluse.com/myserver/dubboadmin:${TAG}

# æ‰§è¡Œæ„å»º
[root@worker-01 dubboadmin]#bash build-command.sh v1
```



#### ä½¿ç”¨æ¸…å•æ–‡ä»¶å¯ç”¨ç®¡ç†é•œåƒ

```yaml
[root@worker-01 dubboadmin]#cat dubboadmin.yaml 
kind: Deployment
#apiVersion: extensions/v1beta1
apiVersion: apps/v1
metadata:
  labels:
    app: magedu-dubboadmin
  name: magedu-dubboadmin-deployment
  namespace: proc-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: magedu-dubboadmin
  template:
    metadata:
      labels:
        app: magedu-dubboadmin
    spec:
      containers:
      - name: magedu-dubboadmin-container
        image: harbor.mysticalrecluse.com/myserver/dubboadmin:v1 
        #command: ["/apps/tomcat/bin/run_tomcat.sh"]
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          protocol: TCP
          name: http

---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: magedu-dubboadmin
  name: magedu-dubboadmin-service
  namespace: proc-test
spec:
  type: NodePort
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8080
    nodePort: 30080
  selector:
    app: magedu-dubboadmin
    
# å¯ç”¨
[root@master-01 ~]#kubectl apply -f dubboadmin.yaml

# æŸ¥çœ‹æœåŠ¡ç«¯å£æ˜¯å¦æ‰“å¼€
[root@master-01 ~]#kubectl exec -n proc-test magedu-dubboadmin-deployment-55859f66-nvvxw -- ss -nlt
State      Recv-Q Send-Q Local Address:Port               Peer Address:Port              
LISTEN     0      100       [::]:8009                  [::]:*                  
LISTEN     2      100       [::]:8080                  [::]:*  

# æœåŠ¡å¯åŠ¨æˆåŠŸï¼Œè®¿é—®èŠ‚ç‚¹IP:30080,è¾“å…¥è´¦å·å¯†ç ï¼šroot/rootï¼Œå³å¯ç™»å½•ç®¡ç†é¡µé¢
```



## veleroæ¶æ„åŠå¤‡ä»½æµç¨‹



### Veleroç®€ä»‹

![image-20250422145402150](../markdown_img/image-20250422145402150.png)

- Veleroæ˜¯vmwareå¼€æºçš„ä¸€ä¸ªäº‘åŸç”Ÿçš„ç¾éš¾æ¢å¤å’Œè¿ç§»å·¥å…·ï¼Œå®ƒæœ¬èº«ä¹Ÿæ˜¯å¼€æºçš„ï¼Œé‡‡ç”¨GOè¯­è¨€ç¼–å†™ï¼Œå¯ä»¥å®‰å…¨çš„å¤‡ä»½ï¼Œæ¢å¤å’Œè¿ç§»Kubernetesé›†ç¾¤èµ„æºæ•°æ®ï¼Œå®˜ç½‘ï¼šhttps://velero.io/
- Veleroæ˜¯è¥¿ç­ç‰™è¯­æ„æ€æ˜¯å¸†èˆ¹ï¼Œéå¸¸ç¬¦åˆKubernetesç¤¾åŒºçš„å‘½åé£æ ¼ï¼ŒVeleroçš„å¼€å‘å…¬å¸Heotioï¼Œå·²è¢«Vmwareæ”¶è´­
- Veleroæ”¯æŒæ ‡å‡†çš„K8Sé›†ç¾¤ï¼Œæ—¢å¯ä»¥æ˜¯ç§æœ‰äº‘å¹³å°ä¹Ÿå¯ä»¥æ˜¯å…¬æœ‰äº‘ï¼Œé™¤äº†ç¾å¤‡ä¹‹å¤–å®ƒè¿˜èƒ½åšèµ„æºè½¬ç§»ï¼Œæ”¯æŒæŠŠå®¹å™¨åº”ç”¨ä»ä¸€ä¸ªé›†ç¾¤è¿ç§»åˆ°å¦ä¸€ä¸ªé›†ç¾¤ã€‚
- Veleroçš„å·¥ä½œæ–¹å¼å°±æ˜¯æŠŠKubernetesä¸­çš„æ•°æ®å¤‡ä»½åˆ°å¯¹è±¡å­˜å‚¨ä»¥å®ç°é«˜å¯ç”¨å’ŒæŒä¹…åŒ–ï¼Œé»˜è®¤çš„å¤‡ä»½ä¿å­˜æ—¶é—´ä¸º720å°æ—¶ï¼Œå¹¶åœ¨éœ€è¦çš„æ—¶å€™è¿›è¡Œä¸‹è½½å’Œæ¢å¤



### Velero ä¸ etcd å¿«ç…§å¤‡ä»½çš„åŒºåˆ«

- etcdå¿«ç…§æ˜¯å…¨å±€å®Œæˆå¤‡ä»½ï¼ˆç±»ä¼¼äºMySQLå…¨é‡å¤‡ä»½ï¼‰ï¼Œå³ä½¿éœ€è¦æ¢å¤ä¸€ä¸ªèµ„æºå¯¹è±¡ï¼ˆç±»ä¼¼äºåªæ¢å¤MySQLçš„ä¸€ä¸ªåº“ï¼‰ï¼Œä½†æ˜¯ä¹Ÿéœ€è¦åšå…¨å±€æ¢å¤åˆ°å¤‡ä»½çš„çŠ¶æ€ï¼ˆç±»ä¼¼äºMySQLçš„å…¨åº“æ¢å¤ï¼‰ï¼Œå³ä¼šå½±å“å…¶å®ƒnamespaceä¸­podè¿è¡ŒæœåŠ¡ï¼ˆç±»ä¼¼äºä¼šå½±å“MySQLå…¶ä»–æ•°æ®åº“çš„æ•°æ®ï¼‰
- Veleroå¯ä»¥æœ‰é’ˆå¯¹æ€§çš„å¤‡ä»½ï¼Œæ¯”å¦‚æŒ‰ç…§namespaceå•ç‹¬å¤‡ä»½ï¼Œåªå¤‡ä»½å•ç‹¬çš„èµ„æºå¯¹è±¡ç­‰ï¼Œåœ¨æ¢å¤çš„æ—¶å€™å¯ä»¥æ ¹æ®å¤‡ä»½åªæ¢å¤å•ç‹¬çš„namespaceæˆ–èµ„æºå¯¹è±¡ï¼Œè€Œä¸å½±å“å…¶å®ƒnamespaceä¸­podè¿è¡ŒæœåŠ¡
- Veleroæ”¯æŒcephï¼ŒOSSç­‰å¯¹è±¡å­˜å‚¨ï¼Œetcdå¿«ç…§æ˜¯ä¸€ä¸ªæœ¬åœ°æ–‡ä»¶
- Veleroæ”¯æŒä»»åŠ¡è®¡åˆ’å®ç°å‘¨æœŸå¤‡ä»½ï¼Œä½†etcdå¿«ç…§ä¹Ÿå¯ä»¥åŸºäºcronjobå®ç°
- Veleroæ”¯æŒå¯¹AWS EBSåˆ›å»ºå¿«ç…§åŠè¿˜åŸ
  - https://www.qloudx.com/velero-for-kubernetes-backup-restore-stateful-workloads-with-aws-ebs-snapshots/
  - https://github.com/vmware-tanzu/velero-plugin-for-aws #Elastic Block Store



### Veleroæ•´ä½“æ¶æ„åŠå¤‡ä»½æµç¨‹

![image-20250422154257242](../markdown_img/image-20250422154257242.png)



#### å¤‡ä»½æµç¨‹

```bash
velero backup create myserver-ns-backup-${DATE} --include-namespace myserver --kubeconfig=./awsuser.kubeconfig --namespace velero-system
```

- Velero å®¢æˆ·ç«¯è°ƒç”¨Kubernetes API Server åˆ›å»º Backup ä»»åŠ¡
- Backup æ§åˆ¶å™¨åŸºäºwatchæœºåˆ¶é€šè¿‡API Serverè·å–åˆ°å¤‡ä»½ä»»åŠ¡
- Backup æ§åˆ¶å™¨å¼€å§‹æ‰§è¡Œå¤‡ä»½åŠ¨ä½œï¼Œå…¶ä¼šé€šè¿‡è¯·æ±‚ API Server è·å–éœ€è¦å¤‡ä»½çš„æ•°æ®
- Backup æ§åˆ¶å™¨å°†è·å–åˆ°çš„æ•°æ®å¤‡ä»½åˆ°æŒ‡å®šçš„å¯¹è±¡å­˜å‚¨Serverç«¯

![image-20250422155242438](../markdown_img/image-20250422155242438.png)



#### éƒ¨ç½²ç¯å¢ƒ

![image-20250422155906511](../markdown_img/image-20250422155906511.png)





#### éƒ¨ç½²minio

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
[root@minio ~]#docker pull minio/minio:RELEASE.2022-04-12T06-55-35Z
[root@minio ~]#mkdir -p /data/minio

[root@minio ~]#docker run --name minio   -p 9000:9000 -p 9999:9999   -e "MINIO_ROOT_USER=admin"   -e "MINIO_ROOT_PASSWORD=admin123"   -v /data/minio/data:/data   --restart=always   -d minio/minio   server /data --console-address ":9999"

# æŸ¥çœ‹å®¹å™¨
[root@minio ~]#docker ps
CONTAINER ID   IMAGE         COMMAND                   CREATED         STATUS         PORTS                                                                                  NAMES
d335ed0e9a7e   minio/minio   "/usr/bin/docker-entâ€¦"   8 seconds ago   Up 6 seconds   0.0.0.0:9000->9000/tcp, :::9000->9000/tcp, 0.0.0.0:9999->9999/tcp, :::9999->9999/tcp   minio

# æœåŠ¡èµ·æ¥ä¹‹åï¼Œåˆ›å»ºbucket,èµ·åä¸ºKubernetes-velero-backup
```



#### éƒ¨ç½² Velero

åœ¨éƒ¨ç½²å‰ï¼Œè¦å…ˆæŸ¥çœ‹veleroä¸Kubernetesçš„å¯¹åº”ç‰ˆæœ¬

![image-20250422174148735](D:\git_repository\cyber_security_learning\markdown_img\image-20250422174148735.png)

```bash
# ä¸‹è½½veleroï¼ˆVeleroå®¢æˆ·ç«¯ï¼‰
[root@master-01 src]#wget https://github.com/vmware-tanzu/velero/releases/download/v1.16.0/velero-v1.16.0-linux-amd64.tar.gz -O /usr/local/src/velero-v1.16.0-linux-amd64.tar.gz

[root@master-01 src]#tar xf velero-v1.16.0-linux-amd64.tar.gz 
[root@master-01 src]#mv velero-v1.16.0-linux-amd64/velero /usr/local/bin

# æµ‹è¯•
[root@master-01 src]#velero version
Client:
	Version: v1.16.0
	Git commit: 8f31599fe4af5453dee032beaf8a16bd75de91a5
```



#### é…ç½®Veleroè®¤è¯ç¯å¢ƒ

```bash
# å·¥ä½œç›®å½•ï¼š
[root@master-01 src]#mkdir -p /data/velero
[root@master-01 src]#cd /data/velero/

# è®¿é—®minioçš„è®¤è¯æ–‡ä»¶ï¼š
[root@master-01 velero]#vim velero-auth.txt
[default]
aws_access_key_id = admin
aws_secret_access_key = 12345678

# å‡†å¤‡user-csræ–‡ä»¶
[root@master-01 velero]#vim awsuser-csr.json
{
  "CN": "awsuser",
  "hosts": [],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
  ]
}

# å‡†å¤‡è¯ä¹¦ç­¾å‘ç¯å¢ƒ
[root@master-01 velero]#apt install golang-cfssl -y
[root@master-01 velero]#wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64
[root@master-01 velero]#wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64
[root@master-01 velero]#wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.1_linux_amd64
[root@master-01 velero]#mv cfssl-certinfo_1.6.1_linux_amd64 cfssl-certinfo
[root@master-01 velero]#mv cfssl_1.6.1_linux_amd64 cfssl
[root@master-01 velero]#mv cfssljson_1.6.1_linux_amd64 cfssljson
[root@master-01 velero]#cp cfssl-certinfo cfssljson cfssl /usr/local/bin/
[root@master-01 velero]#chmod a+x /usr/local/bin/cfssl*

# æ‰§è¡Œè¯ä¹¦ç­¾å‘
# kubernetesç‰ˆæœ¬ >= 1.24
[root@haproxy1 ssl]#scp /etc/kubeasz/clusters/k8s-cluster1/ssl/ca-config.json master1:/data/valero

[root@master-01 velero]#cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem -ca-key=/etc/kubernetes/ssl/ca-key.pem -config=./ca-config.json -profile=kubernetes ./awsuser-csr.json |cfssljson -bare awsuser
2025/04/22 19:57:35 [INFO] generate received request
2025/04/22 19:57:35 [INFO] received CSR
2025/04/22 19:57:35 [INFO] generating key: rsa-2048
2025/04/22 19:57:36 [INFO] encoded CSR
2025/04/22 19:57:36 [INFO] signed certificate with serial number 486780908032241703022092215985611021871723081777
2025/04/22 19:57:36 [WARNING] This certificate lacks a "hosts" field. This makes it unsuitable for
websites. For more information see the Baseline Requirements for the Issuance and Management
of Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);
specifically, section 10.2.3 ("Information Requirements").

[root@master-01 velero]#ll
æ€»è®¡ 40264
drwxr-xr-x 2 root root     4096  4æœˆ 22 19:57 ./
drwxr-xr-x 3 root root     4096  4æœˆ 22 19:55 ../
-rw-r--r-- 1 root root      997  4æœˆ 22 19:57 awsuser.csr
-rw-r--r-- 1 root root      220  4æœˆ 22 18:05 awsuser-csr.json
-rw------- 1 root root     1675  4æœˆ 22 19:57 awsuser-key.pem     # ç§é’¥
-rw-r--r-- 1 root root     1391  4æœˆ 22 19:57 awsuser.pem         # è¯ä¹¦
-rw-r--r-- 1 root root      459  4æœˆ 22 19:55 ca-config.json
-rw-r--r-- 1 root root 16659824 12æœˆ  7  2021 cfssl
-rw-r--r-- 1 root root 13502544 12æœˆ  7  2021 cfssl-certinfo
-rw-r--r-- 1 root root 11029744 12æœˆ  7  2021 cfssljson
-rw-r--r-- 1 root root       69  4æœˆ 22 17:58 velero-auth.txt

# åˆ†å‘è¯ä¹¦åˆ°api-serverè¯ä¹¦è·¯å¾„
[root@master-01 velero]#cp awsuser-key.pem /etc/kubernetes/ssl/
[root@master-01 velero]#cp awsuser.pem /etc/kubernetes/ssl/

# ç”Ÿæˆé›†ç¾¤è®¤è¯configæ–‡ä»¶
[root@master-01 velero]# export KUBE_APISERVER="https://10.0.0.201:6443"
[root@master-01 velero]# kubectl config set-cluster kubernetes --certificate-authority=/etc/kubernetes/ssl/ca.pem --embed-certs=true --server=${KUBE_APISERVER} --kubeconfig=./awsuser.kubeconfig

# è®¾ç½®å®¢æˆ·ç«¯è¯ä¹¦è®¤è¯
[root@master-01 velero]#kubectl config set-credentials awsuser --client-certificate=/etc/kubernetes/ssl/awsuser.pem --client-key=/etc/kubernetes/ssl/awsuser-key.pem --embed-certs=true --kubeconfig=./awsuser.kubeconfig

# è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•°
[root@master-01 velero]#kubectl config set-context kubernetes --cluster=kubernetes --user=awsuser --namespace=velero-system --kubeconfig=./awsuser.kubeconfig 
Context "kubernetes" created.

# è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡
[root@master-01 velero]#kubectl config use-context kubernetes --kubeconfig=awsuser.kubeconfig 
Switched to context "kubernetes".

# k8sé›†ç¾¤ä¸­åˆ›å»ºawsuserè´¦æˆ·
[root@master-01 velero]#kubectl create clusterrolebinding awsuser --clusterrole=admin --user=awsuser
clusterrolebinding.rbac.authorization.k8s.io/awsuser created

# åˆ›å»ºåç§°ç©ºé—´
[root@master-01 velero]#kubectl create ns velero-system
namespace/velero-system created

# åˆ›å»ºsa
[root@master-01 velero]#kubectl create sa --namespace velero-system awsuser
serviceaccount/awsuser created

# æµ‹è¯•åˆ›å»ºçš„kube-configæ–‡ä»¶,awsuser.kubeconfigæƒé™æ˜¯å¦ok
[root@master-01 velero]#kubectl --kubeconfig=./awsuser.kubeconfig get nodes
NAME             STATUS                        ROLES    AGE   VERSION
k8s-10-0-0-203   NotReady,SchedulingDisabled   master   14d   v1.30.11
k8s-10-0-0-213   Ready                         node     14d   v1.30.11
master-01        Ready,SchedulingDisabled      master   14d   v1.30.11
master-02        NotReady,SchedulingDisabled   master   14d   v1.30.11
worker-01        Ready                         node     14d   v1.30.11
worker-02        Ready                         node     14d   v1.30.11

# æ‰§è¡Œå®‰è£…
[root@master-01 velero]#velero --kubeconfig ./awsuser.kubeconfig install --provider aws --plugins velero/velero-plugin-for-aws:v1.5.5 --bucket kubernetes-velero-backup --secret-file ./velero-auth.txt --use-volume-snapshots=false --namespace velero-system --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=http://10.0.0.205:9000

# å¸è½½velero
# velero uninstall --kubeconfig ./awsuser.kubeconfig --namespace velero-system


# æŸ¥çœ‹
[root@master-01 velero]#kubectl get pod -n velero-system 
NAME                      READY   STATUS    RESTARTS   AGE
velero-8569494b66-mkj5c   1/1     Running   0          2m12s

# æµ‹è¯•
[root@master-01 velero]#velero --namespace velero-system backup-location get
NAME      PROVIDER   BUCKET/PREFIX              PHASE       LAST VALIDATED                  ACCESS MODE   DEFAULT
default   aws        kubernetes-velero-backup   Available   2025-04-22 22:42:52 +0800 CST   ReadWrite     true

```



#### å¯¹ default ns è¿›è¡Œå¤‡ä»½

```bash
[root@master-01 velero]#pwd
/data/velero

[root@master-01 ~]#DATE=`date +%Y%m%d%H%M%S`
[root@master-01 velero]#velero backup create default-backup-${DATE} \
--include-cluster-resources=true \          # å¯¼å…¥é›†ç¾¤èµ„æº
--include-namespaces default \              # å¯¼å…¥ï¼ˆå¤‡ä»½ï¼‰å“ªä¸ªnamespaceçš„èµ„æºï¼Œé»˜è®¤*,ä»£è¡¨å…¨éƒ¨
--kubeconfig=./awsuser.kubeconfig \
--namespace velero-system                   # æŒ‡å®šserverç«¯çš„namespace

# éªŒè¯å¤‡ä»½
[root@master-01 velero]#velero backup describe default-backup-20250422224724 --kubeconfig=./awsuser.kubeconfig --namespace velero-system
Name:         default-backup-20250422224724
Namespace:    velero-system
Labels:       velero.io/storage-location=default
Annotations:  velero.io/resource-timeout=10m0s
              velero.io/source-cluster-k8s-gitversion=v1.30.11
              velero.io/source-cluster-k8s-major-version=1
              velero.io/source-cluster-k8s-minor-version=30

Phase:  Completed


Namespaces:
  Included:  default
  Excluded:  <none>

Resources:
  Included:        *
  Excluded:        <none>
  Cluster-scoped:  included

Label selector:  <none>

Or label selector:  <none>

Storage Location:  default

Velero-Native Snapshot PVs:  auto
Snapshot Move Data:          false
Data Mover:                  velero

TTL:  720h0m0s

CSISnapshotTimeout:    10m0s
ItemOperationTimeout:  4h0m0s

Hooks:  <none>

Backup Format Version:  1.1.0

Started:    2025-04-22 22:51:28 +0800 CST
Completed:  2025-04-22 22:51:33 +0800 CST

Expiration:  2025-05-22 22:51:28 +0800 CST

Total items to be backed up:  298
Items backed up:              298

Backup Volumes:
  Velero-Native Snapshots: <none included>

  CSI Snapshots: <none included>

  Pod Volume Backups: <none included>

HooksAttempted:  0
HooksFailed:     0
```



#### åˆ é™¤Podå¹¶éªŒè¯æ•°æ®æ¢å¤

```bash
# åˆ é™¤pod
[root@master-01 velero]#kubectl delete deployments.apps -n default deployment-pod-test 
deployment.apps "deployment-pod-test" deleted

# æ¢å¤pod
[root@master-01 velero]#velero restore create --from-backup default-backup-20250422224724 --wait --kubeconfig=./awsuser.kubeconfig --namespace velero-system
Restore request "default-backup-20250422224724-20250422225706" submitted successfully.
Waiting for restore to complete. You may safely press ctrl-c to stop waiting - your restore will continue in the background.
....
Restore completed with status: Completed. You may check for more information using the commands `velero restore describe default-backup-20250422224724-20250422225706` and `velero restore logs default-backup-20250422224724-20250422225706`.

# æŸ¥çœ‹å·²æ¢å¤çš„pod
[root@master-01 velero]#kubectl get pod
NAME                                   READY   STATUS    RESTARTS   AGE
deployment-pod-test-587f5cfffb-97pgb   1/1     Running   0          7s
deployment-pod-test-587f5cfffb-mdqjx   1/1     Running   0          7s
deployment-pod-test-587f5cfffb-zszsh   1/1     Running   0          7s
```



#### å¤‡ä»½æŒ‡å®šèµ„æºå¯¹è±¡

```bash
# å¤‡ä»½æŒ‡å®šnamespaceä¸­çš„podæˆ–ç‰¹å®šèµ„æº
[root@master-01 ~]#kubectl run net-test1 --image=harbor.mysticalrecluse.com/baseimages/mystical-centos-base@sha256:037c2b37ec9acc9c48077f88b573bd15f67c6b4401d9f0ba20eb53d78831b2a4 sleep 100000000
pod/net-test1 created

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get pod
NAME                                   READY   STATUS    RESTARTS      AGE
deployment-pod-test-587f5cfffb-97pgb   1/1     Running   1 (23m ago)   10h
deployment-pod-test-587f5cfffb-mdqjx   1/1     Running   1 (23m ago)   10h
deployment-pod-test-587f5cfffb-zszsh   1/1     Running   1 (23m ago)   10h
net-test1                              1/1     Running   0             4s

[root@master-01 ~]#kubectl run net-test1 --image=harbor.mysticalrecluse.com/baseimages/mystical-centos-base@sha256:037c2b37ec9acc9c48077f88b573bd15f67c6b4401d9f0ba20eb53d78831b2a4 sleep 100000000 -n proc-test
pod/net-test1 created

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get pod -n proc-test net-test1 
NAME        READY   STATUS    RESTARTS   AGE
net-test1   1/1     Running   0          2m31s


# å¤‡ä»½æŒ‡å®špod:net-test1,åˆ†åˆ«ä½äºdefaultå’Œproc-teståç§°ç©ºé—´ä¸‹
[root@master-01 ~]#DATE=`date +%Y%m%d%H%M%S`
[root@master-01 ~]#velero backup create pod-backup-${DATE} --include-cluster-resources=true --ordered-resources 'pods=proc-test/net-test1,default/net-test1' --namespace velero-system --include-namespaces=proc-test,default
Backup request "pod-backup-20250423093402" submitted successfully.
Run `velero backup describe pod-backup-20250423093402` or `velero backup logs pod-backup-20250423093402` for more details.

# å¦‚æœè¦å¤‡ä»½ä¸åŒç±»å‹èµ„æºè¦ç”¨åˆ†å·éš”å¼€
# ç¤ºä¾‹ï¼š--ordered-resources string                           Mapping Kinds to an ordered list of specific resources of that Kind.  Resource names are separated by commas and their names are in format 'namespace/resourcename'. For cluster scope resource, simply use resource name. Key-value pairs in the mapping are separated by semi-colon.  Example: 'pods=ns1/pod1,ns1/pod2;persistentvolumeclaims=ns1/pvc4,ns1/pvc8'.  Optional.
```



#### æ‰¹é‡å¤‡ä»½æ‰€æœ‰namespace

```bash
[root@master-01 ~]#cat /data/velero/ns-back.sh
#!/bin/bash
NS_NAME=`kubectl get ns|awk '{if(NR>2)print}'|awk '{print $1}'`
DATE=`date +%Y%m%d%H%M%S`
cd /data/velero

for i in $NS_NAME; do
velero backup create ${i}-ns-backup-${DATE} \
--include-cluster-resources=true \
--include-namespaces ${i} \
--kubeconfig=/root/.kube/config \
--namespace velero-system
done

[root@master-01 ~]#bash /data/velero/ns-back.sh
```



### ä½¿ç”¨ Velero å®ç° **Kubernetes é›†ç¾¤è¿ç§»** çš„å®Œæ•´å®æˆ˜æµç¨‹

ç›®æ ‡ï¼šä»ä¸€ä¸ªé›†ç¾¤ï¼ˆæºé›†ç¾¤ï¼‰è¿ç§»å…¨éƒ¨æˆ–éƒ¨åˆ†èµ„æºåˆ°å¦ä¸€ä¸ªé›†ç¾¤ï¼ˆç›®æ ‡é›†ç¾¤ï¼‰



#### åœºæ™¯è¯´æ˜

- **æºé›†ç¾¤**ï¼šå·²æœ‰ä¸šåŠ¡è¿è¡Œåœ¨å…¶ä¸­ï¼Œéœ€è¦è¿ç§»ã€‚

- **ç›®æ ‡é›†ç¾¤**ï¼šå…¨æ–°é›†ç¾¤ï¼Œç¯å¢ƒå·²æ­å»ºå®Œæˆã€‚

- ä½¿ç”¨å¯¹è±¡å­˜å‚¨ï¼ˆå¦‚ MinIOã€S3ï¼‰ä½œä¸ºä¸­è½¬ä»“åº“ã€‚

- å·¥å…·ï¼šVelero + MinIOï¼ˆæˆ– S3 å…¼å®¹å­˜å‚¨ï¼‰



#### å‡†å¤‡å·¥ä½œ

**1. ä¸¤ä¸ªé›†ç¾¤éƒ½èƒ½è®¿é—®åŒä¸€ä¸ªå¯¹è±¡å­˜å‚¨**

å¦‚ MinIO æä¾›æœåŠ¡ `http://10.0.0.205:9000`ï¼Œå·²é…ç½®å¥½æ¡¶ `kubernetes-velero-backup`

**2. åˆ›å»ºå¯¹è±¡å­˜å‚¨è®¤è¯æ–‡ä»¶ï¼ˆä¸¤è¾¹ä¸€æ ·ï¼‰**

```bash
cat > velero-auth.txt <<EOF
[default]
aws_access_key_id = admin
aws_secret_access_key = 12345678
EOF
```

**3. åœ¨ä¸¤ä¸ªé›†ç¾¤ä¸­éƒ½å®‰è£… Velero**

å®‰è£…ï¼ˆæºé›†ç¾¤ & ç›®æ ‡é›†ç¾¤éƒ½æ‰§è¡Œï¼‰

```bash
velero install \
  --provider aws \
  --plugins velero/velero-plugin-for-aws:v1.5.5 \
  --bucket kubernetes-velero-backup \
  --secret-file ./velero-auth.txt \
  --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=http://10.0.0.205:9000 \
  --use-volume-snapshots=false \
  --namespace velero-system

```



#### åœ¨æºé›†ç¾¤æ‰§è¡Œå¤‡ä»½

**1. å¤‡ä»½æŒ‡å®š namespaceï¼ˆä¾‹å¦‚ï¼š`prod-app`ï¼‰**

```bash
velero backup create prod-app-backup --include-namespaces prod-app
```

**2. æŸ¥çœ‹å¤‡ä»½çŠ¶æ€**

```bash
velero backup get
velero backup describe prod-app-backup
```

å¦‚æœçœ‹åˆ° `Completed`ï¼Œè¯´æ˜å¤‡ä»½æˆåŠŸã€‚



#### åœ¨ç›®æ ‡é›†ç¾¤æ‰§è¡Œæ¢å¤

**1. ç¡®ä¿ Velero åœ¨ç›®æ ‡é›†ç¾¤éƒ¨ç½²æ­£å¸¸ï¼Œå¹¶è¿æ¥ç›¸åŒçš„å¯¹è±¡å­˜å‚¨**

**2. æŸ¥çœ‹å·²å­˜åœ¨çš„å¤‡ä»½**

```bash
velero backup get
```

**3. æ‰§è¡Œè¿˜åŸæ“ä½œ**

```bash
velero restore create --from-backup prod-app-backup
```

æŸ¥çœ‹è¿˜åŸçŠ¶æ€



#### æˆåŠŸæ ‡å¿—

- Pod/Service/Ingress ç­‰èµ„æºåœ¨ç›®æ ‡é›†ç¾¤æ¢å¤æˆåŠŸã€‚
- PVC æ¢å¤è§†åº•å±‚å­˜å‚¨æ”¯æŒæƒ…å†µï¼Œå¦‚ä½¿ç”¨ NFSã€Ceph æˆ– OpenEBS ä¼šæœ‰æ›´é«˜çš„æˆåŠŸç‡ã€‚
- é…ç½®å»ºè®®æå‰åˆ›å»ºå¥½ `StorageClass`



#### æ³¨æ„äº‹é¡¹

1. å¦‚æœä½¿ç”¨äº†é»˜è®¤ `ReadWriteOnce` çš„ PVCï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ `--volume-snapshot`ã€‚
2. å¯ä»¥å€ŸåŠ© label/namespace è¿›è¡Œèµ„æºç²¾ç¡®æ§åˆ¶ã€‚
3. å¤‡ä»½å†…å®¹é»˜è®¤åŒ…æ‹¬ï¼š
   - Deploymentã€Serviceã€ConfigMapã€Secretã€PVC ç­‰
   - å¯é€šè¿‡ `--include-resources` å’Œ `--exclude-resources` æ§åˆ¶
4. `velero backup describe` è¾“å‡º YAML å¯åˆ†æå¤‡ä»½è¯¦æƒ…





# çŸ¥è¯†æ‰©å±•



## Watchæœºåˆ¶



**watch æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªåŸºäº HTTPS çš„é•¿è¿æ¥è¯·æ±‚**ã€‚åœ¨è¿™ä¸ªé•¿è¿æ¥ä¸­ï¼Œ**API Server ä¼šå‘å®¢æˆ·ç«¯ä¸»åŠ¨æ¨é€èµ„æºå˜æ›´äº‹ä»¶**ï¼Œä½†è¦æ³¨æ„çš„æ˜¯ï¼Œ**å®¢æˆ·ç«¯åœ¨å‘èµ· watch è¯·æ±‚åä¸ä¼šåå¤å‘é€è¯·æ±‚ï¼Œåç»­çš„æ‰€æœ‰æ•°æ®éƒ½æ˜¯ç”± API Server ä¸»åŠ¨æ¨é€çš„**ã€‚



### HTTP/2å®ç°

#### **1. æŠ€æœ¯æ ¸å¿ƒï¼šHTTP/2 çš„ç‰¹æ€§**

Kubernetes çš„ watch æœºåˆ¶ä¾èµ–äº**HTTP/2 åè®®**çš„**å¤šè·¯å¤ç”¨å’Œæµå¼æ•°æ®ä¼ è¾“**ã€‚å’Œä¼ ç»Ÿçš„ HTTP/1.1 ä¸åŒï¼Œ**HTTP/2 æä¾›äº†æŒä¹…çš„åŒå‘æ•°æ®æµ**ï¼Œè¿™æ˜¯å®ç°â€œ**ä¸€æ¬¡è¯·æ±‚ï¼Œå¤šæ¬¡å“åº”**â€çš„æ ¸å¿ƒã€‚



##### **HTTP/2 çš„å…³é”®ç‰¹æ€§**

| **ç‰¹æ€§**            | **æè¿°**                                   | **åœ¨ watch ä¸­çš„ä½œç”¨**                                  |
| ------------------- | ------------------------------------------ | ------------------------------------------------------ |
| **å¤šè·¯å¤ç”¨**        | å•ä¸ª TCP è¿æ¥ä¸­å…è®¸å¤šä¸ªæµçš„å¹¶è¡Œäº¤ä»˜        | å…è®¸ kubelet å’Œ apiserver é€šè¿‡å•è¿æ¥ä¼ è¾“å¤šä¸ªè¯·æ±‚å’Œå“åº” |
| **æ•°æ®æµ (Stream)** | æ•°æ®ä»¥æµçš„å½¢å¼å‘é€ï¼Œæµ ID ç”¨äºæ ‡è¯†æ•°æ®æ®µ   | kube-apiserver ä¸æ–­å‘ kubelet å‘é€æµæ•°æ®               |
| **æµå¼å“åº”**        | ä¸å¿…ç­‰å¾…è¯·æ±‚å®Œæˆï¼Œå¯ä»¥å¤šæ¬¡ä¼ è¾“åˆ†æ®µå“åº”æ•°æ® | åœ¨ watch ä¸­ï¼Œæ¯æ¬¡ Pod å˜åŒ–éƒ½ä¼šç«‹åˆ»æ¨é€åˆ°å®¢æˆ·ç«¯         |
| **é•¿è¿æ¥**          | è¿æ¥ä¸å…³é—­ï¼Œç»´æŒå®¢æˆ·ç«¯ä¸æœåŠ¡ç«¯çš„é•¿è¿æ¥     | å®¢æˆ·ç«¯çš„ watch è¯·æ±‚ä¸€ç›´ä¿æŒè¿æ¥ï¼Œç›´åˆ°ä¸­æ–­              |
| **å¤´éƒ¨å‹ç¼©**        | HTTP å¤´çš„ HPACK å‹ç¼©ï¼Œå‡å°‘ç½‘ç»œæµé‡æ¶ˆè€—     | kube-apiserver çš„è¯·æ±‚å’Œå“åº”çš„å¤´éƒ¨å˜å°ï¼Œå‡å°‘å»¶è¿Ÿ        |



##### **HTTP/2 æ˜¯å¦‚ä½•å®ç°â€œè¯·æ±‚-å¤šæ¬¡å“åº”â€çš„ï¼Ÿ**

1. **å¤šè·¯å¤ç”¨**ï¼š
   - åœ¨ HTTP/2 ä¸­ï¼Œå®¢æˆ·ç«¯ä¸æœåŠ¡ç«¯ä¹‹é—´åªå»ºç«‹ä¸€ä¸ª TCP è¿æ¥ï¼Œä½†å¯ä»¥åœ¨è¯¥è¿æ¥ä¸ŠåŒæ—¶å¤„ç†å¤šä¸ª HTTP è¯·æ±‚ã€‚
   - watch è¯·æ±‚ï¼ˆ`GET /api/v1/pods?watch=true`ï¼‰**åªå ç”¨ä¸€ä¸ª HTTP æµ**ï¼Œå³ä½¿æœ‰å…¶ä»–è¯·æ±‚ï¼ˆä¾‹å¦‚ List Podsï¼‰ä¹Ÿä¸ä¼šå½±å“ watch æµã€‚
2. **æ•°æ®æµ (Stream)**ï¼š
   - HTTP/2 ä½¿ç”¨â€œ**æ•°æ®æµ**â€çš„æ¦‚å¿µã€‚
   - å½“ kube-apiserver ç›‘æµ‹åˆ° Pod å˜åŒ–æ—¶ï¼Œ**å°†å˜åŒ–çš„äº‹ä»¶æ‰“åŒ…ä¸ºä¸€æ¡æ¶ˆæ¯**ï¼Œæ¨é€åˆ°ä¸å®¢æˆ·ç«¯çš„æµä¸­ã€‚
   - **å®¢æˆ·ç«¯ç›‘å¬åˆ°äº‹ä»¶åå¯ä»¥ç«‹åˆ»æ¥æ”¶å¹¶å¤„ç†ï¼Œè€Œä¸éœ€è¦å…³é—­æˆ–é‡æ–°è¯·æ±‚ã€‚**
3. **æµå¼å“åº”**ï¼š
   - åœ¨ HTTP/1.1 ä¸­ï¼Œå“åº”æ•°æ®å¿…é¡»ç­‰å¾…è¯·æ±‚å®Œæˆåï¼Œæ‰èƒ½å®Œæ•´è¿”å›ã€‚
   - åœ¨ HTTP/2 ä¸­ï¼ŒæœåŠ¡ç«¯å¯ä»¥**ä¸€æ®µä¸€æ®µåœ°å°†æ•°æ®å‘é€å›å®¢æˆ·ç«¯**ï¼Œè¿™æ­£æ˜¯ Kubernetes ä¸­ watch æœºåˆ¶çš„å…³é”®ã€‚
   - **æ¯æ¬¡ Pod çŠ¶æ€å˜åŒ–æ—¶ï¼ŒAPI Server ä¼šå°†äº‹ä»¶æ¨é€åˆ°å®¢æˆ·ç«¯ï¼Œå®¢æˆ·ç«¯ç«‹å³æ”¶åˆ°å˜åŒ–æ•°æ®ã€‚**



#### **2. åœ¨ Kubernetes ä¸­çš„å®ç°**

##### **Watch è¯·æ±‚**

``` 
GET /api/v1/pods?watch=true&resourceVersion=123456 HTTP/2
Host: kube-apiserver:6443
```

- **GET** è¯·æ±‚ï¼Œè·¯å¾„æ˜¯ `/api/v1/pods`ï¼Œå¸¦æœ‰å‚æ•° `watch=true`ã€‚
- `resourceVersion=123456`ï¼šè¿™è¡¨ç¤ºå®¢æˆ·ç«¯å¸Œæœ›**ä»ç‰ˆæœ¬ 123456 ä¹‹åçš„äº‹ä»¶å¼€å§‹ç›‘å¬**ã€‚
- è¿™æ˜¯ä¸€ä¸ª HTTP/2 è¯·æ±‚ï¼Œå®ƒ**ä¸å…³é—­è¿æ¥**ï¼Œç›¸å½“äºåœ¨ TCP ä¸Šåˆ›å»ºä¸€ä¸ª**é•¿è¿æ¥**ï¼Œå¹¶ä¿æŒæ•°æ®æµã€‚



##### **å“åº”æ•°æ®**

API Server æ£€æµ‹åˆ° Pod å˜åŒ–åï¼Œä¼šä¸æ–­åœ°**æµå¼ä¼ è¾“**å˜æ›´äº‹ä»¶ã€‚

```json
jsonCopy code{
  "type": "ADDED",
  "object": {
    "metadata": {
      "name": "nginx-pod",
      "namespace": "default",
      "resourceVersion": "123457"
    },
    "status": {
      "phase": "Running"
    }
  }
}
{
  "type": "MODIFIED",
  "object": {
    "metadata": {
      "name": "nginx-pod",
      "namespace": "default",
      "resourceVersion": "123458"
    },
    "status": {
      "phase": "Terminating"
    }
  }
}
{
  "type": "DELETED",
  "object": {
    "metadata": {
      "name": "nginx-pod",
      "namespace": "default",
      "resourceVersion": "123459"
    }
  }
}
```

- è¿™äº›äº‹ä»¶æ˜¯**åˆ†æ®µè¿”å›çš„ JSON æ¶ˆæ¯**ã€‚
- æ¯æ¡äº‹ä»¶éƒ½æœ‰ä¸€ä¸ª**äº‹ä»¶ç±»å‹ (type)**ï¼Œå¯ä»¥æ˜¯ `ADDED`, `MODIFIED`, `DELETED`ã€‚
- **æµå¼æ•°æ®ä¼ è¾“**ï¼šæ¯ä¸ªäº‹ä»¶éƒ½æ˜¯ç‹¬ç«‹çš„ JSON å—ï¼Œkubelet ç«‹åˆ»èƒ½è¯»å–è¿™äº›æ•°æ®ï¼Œè€Œä¸éœ€è¦ç­‰å¾…æ‰€æœ‰æ•°æ®è¿”å›ã€‚
- **ä¸å…³é—­è¿æ¥**ï¼šAPI Server **åªä¼šåœ¨è¿æ¥æ–­å¼€æ—¶å…³é—­æµ**ï¼Œå¦åˆ™ä¼šæŒç»­å‘é€æ•°æ®ã€‚



#### **3. è¿™ä¸ WebSocket çš„å¯¹æ¯”**

| **ç‰¹æ€§**     | **HTTP/2**               | **WebSocket**              |
| ------------ | ------------------------ | -------------------------- |
| **è¿æ¥ç±»å‹** | HTTP/2 é•¿è¿æ¥ï¼Œæµå¼å“åº”  | TCP é•¿è¿æ¥ï¼Œç±»ä¼¼åŒå·¥é€šä¿¡   |
| **åè®®å±‚**   | TCP + HTTP/2             | TCP + WebSocket (ws://)    |
| **å¤šè·¯å¤ç”¨** | æ”¯æŒ                     | ä¸æ”¯æŒï¼ˆä¸€ä¸ªè¯·æ±‚ä¸€ä¸ªé€šé“ï¼‰ |
| **å¹¶å‘æ€§**   | é«˜å¹¶å‘ï¼Œå¤šè¯·æ±‚ä¸€ä¸ª TCP   | éœ€è¦å¤šä¸ª TCP è¿æ¥          |
| **æ•°æ®ä¼ è¾“** | ä»¥**æ•°æ®æµ**ä¼ è¾“åˆ†æ®µæ•°æ® | ä»¥æ•°æ®åŒ…/æ¶ˆæ¯æ–¹å¼ä¼ è¾“      |
| **ä½¿ç”¨åœºæ™¯** | Kubernetes watchã€APIæµ  | èŠå¤©å®¤ã€æ¸¸æˆç­‰åŒå·¥é€šä¿¡     |
| **ç½‘ç»œæ•ˆç‡** | è¾ƒé«˜ï¼Œèµ„æºåˆ©ç”¨ç‡é«˜       | è¾ƒé«˜ï¼Œé€‚åˆåŒå·¥é€šä¿¡         |



#### **4. å…³é”®çš„ç½‘ç»œåè®®ç‰¹æ€§**

| **ç½‘ç»œåè®®/ç‰¹æ€§** | **HTTP/2** | **æè¿°**                             |
| ----------------- | ---------- | ------------------------------------ |
| **TCP**           | éœ€è¦       | HTTP/2 æ˜¯åŸºäº TCP ä¼ è¾“çš„ï¼ˆTLS/SSLï¼‰  |
| **TLS/SSL**       | å¿…é¡»       | ä¼ è¾“æ—¶ä½¿ç”¨ TLS åŠ å¯†ï¼Œå¢å¼ºæ•°æ®å®‰å…¨    |
| **å¤šè·¯å¤ç”¨**      | æ”¯æŒ       | å•ä¸ª TCP è¿æ¥å¯ä¼ è¾“å¤šä¸ª HTTP è¯·æ±‚    |
| **æµæ§åˆ¶**        | æ”¯æŒ       | æ§åˆ¶æ¯ä¸ªæµçš„æµé‡ï¼Œé¿å…æŸä¸ªæµå æ»¡å¸¦å®½ |
| **åˆ†æ®µä¼ è¾“**      | æ”¯æŒ       | ä¸å¿…ç­‰å¾…æ‰€æœ‰æ•°æ®ï¼Œæµå¼ä¼ è¾“å“åº”ç‰‡æ®µ   |
| **å¤´éƒ¨å‹ç¼©**      | æ”¯æŒ       | ä½¿ç”¨ HPACK å‹ç¼©å¤´éƒ¨ï¼Œå‡å°‘å¸¦å®½        |



#### **5. å…³é”®é—®é¢˜è§£ç­”**

1. **â€œä¸€æ¬¡è¯·æ±‚ï¼Œå¤šæ¬¡å“åº”â€ æ˜¯æ€ä¹ˆå®ç°çš„ï¼Ÿ**

- ä½¿ç”¨**HTTP/2 ä¸­çš„æµå¼å“åº”**ã€‚
- é€šè¿‡åœ¨ HTTP/2 ä¸­ç»´æŒä¸€ä¸ª**é•¿è¿æ¥**ï¼ŒæœåŠ¡ç«¯ API Server ä¼šä¸æ–­åœ°å°†äº‹ä»¶æ¨é€ç»™å®¢æˆ·ç«¯ã€‚
- è¿™äº›äº‹ä»¶æ˜¯ä¸€ä¸ªä¸ª**åˆ†æ®µçš„ JSON æ•°æ®å—**ï¼Œæµå¼è¿”å›ç»™å®¢æˆ·ç«¯ã€‚
- **å®¢æˆ·ç«¯åªéœ€è¦å‘èµ·ä¸€æ¬¡è¯·æ±‚**ï¼ŒAPI Server ä¼šä¸»åŠ¨æ¨é€èµ„æºçš„å˜åŒ–æ•°æ®ã€‚



2. **watch æœºåˆ¶ä¸ä¼ ç»Ÿçš„â€œè½®è¯¢ (polling)â€ æœ‰ä½•ä¸åŒï¼Ÿ**

- **ä¼ ç»Ÿè½®è¯¢**ï¼šå®¢æˆ·ç«¯å®šæœŸå‘é€è¯·æ±‚ï¼Œè·å–å…¨é‡èµ„æºåˆ—è¡¨ï¼Œå¼€é”€å¤§ï¼Œå»¶è¿Ÿé«˜ã€‚
- **watch æœºåˆ¶**ï¼šå®¢æˆ·ç«¯åªå‘é€ä¸€æ¬¡è¯·æ±‚ï¼ŒAPI Server æŒç»­æ¨é€å˜æ›´ï¼Œå®æ—¶æ€§å¼ºï¼Œèµ„æºå¼€é”€å°ã€‚



3. **å¦‚æœè¿æ¥æ–­å¼€äº†æ€ä¹ˆåŠï¼Ÿ**

- å®¢æˆ·ç«¯ä¼šæ£€æµ‹åˆ°æ–­å¼€ï¼Œå¹¶è‡ªåŠ¨é‡æ–°å‘èµ· watch è¯·æ±‚ã€‚
- å¦‚ä½•é¿å…ä¸¢å¤±æ•°æ®ï¼Ÿ
  - å®¢æˆ·ç«¯ä¼šä½¿ç”¨æœ€åçš„ `resourceVersion` æ¥æ¢å¤ã€‚
  - å¦‚æœ `resourceVersion` å¤ªæ—§ï¼ŒAPI Server ä¼šè¿”å›**HTTP 410 Gone**ï¼Œè¿™æ—¶å®¢æˆ·ç«¯ä¼šè§¦å‘**List + Watch**æ“ä½œæ¥é‡æ–°åŒæ­¥æ•°æ®ã€‚



#### **æ€»ç»“**

- **ä¸€æ¬¡è¯·æ±‚ã€å¤šæ¬¡å“åº”**çš„å…³é”®åœ¨äº**HTTP/2 çš„é•¿è¿æ¥å’Œæµå¼ä¼ è¾“**ã€‚
- watch ä½¿ç”¨çš„**HTTP/2 åè®®ã€æµå¼å“åº”ã€å¤šè·¯å¤ç”¨å’Œé•¿è¿æ¥**æŠ€æœ¯ï¼Œé¿å…äº†å®¢æˆ·ç«¯çš„é‡å¤è¯·æ±‚ï¼Œæå‡äº†æ€§èƒ½ã€‚
- **ä¸éœ€è¦å®¢æˆ·ç«¯åå¤è¯·æ±‚**ï¼Œä¸€æ¡è¯·æ±‚ï¼ŒAPI Server æŒç»­æ¨é€ã€‚
- **ç½‘ç»œåè®®çš„æ”¯æ’‘**ï¼šHTTP/2 æµã€é•¿è¿æ¥ã€TLS åŠ å¯†å’Œæ•°æ®åˆ†æ®µä¼ è¾“ã€‚





### å„ç»„ä»¶åœ¨HTTP/2çš„è§’è‰²

#### **1. å„ç»„ä»¶åœ¨ HTTP/2 è¯·æ±‚ä¸­çš„è§’è‰²**

| **ç»„ä»¶å¯¹**                 | **å®¢æˆ·ç«¯ (Client)** | **æœåŠ¡ç«¯ (Server)** | **åè®®**   | **æ˜¯å¦ä½¿ç”¨é•¿è¿æ¥** | **é•¿è¿æ¥çš„ä½œç”¨**                           |
| -------------------------- | ------------------- | ------------------- | ---------- | ------------------ | ------------------------------------------ |
| **Scheduler - API Server** | **Scheduler**       | **API Server**      | **HTTP/2** | æ˜¯                 | Scheduler å‘ API Server ç”³è¯·è°ƒåº¦çš„èµ„æºæ›´æ–° |
| **Kubelet - API Server**   | **Kubelet**         | **API Server**      | **HTTP/2** | æ˜¯                 | Kubelet ç›‘å¬ Pod å˜æ›´ (watch)              |
| **API Server - etcd**      | **API Server**      | **etcd**            | **gRPC**   | æ˜¯                 | API Server æŸ¥è¯¢/æ›´æ–° etcd æ•°æ®             |

------

#### **2. è§’è‰²è§£æ**

##### **(1) Scheduler - API Server**

- **å®¢æˆ·ç«¯**ï¼šScheduler æ˜¯å®¢æˆ·ç«¯ã€‚

- **æœåŠ¡ç«¯**ï¼šAPI Server æ˜¯æœåŠ¡ç«¯ã€‚

- **é€šä¿¡æ–¹å¼**ï¼šScheduler é€šè¿‡**HTTP/2 é•¿è¿æ¥**è¯·æ±‚ API Serverã€‚

- **è¯·æ±‚ç±»å‹**ï¼š

  - Scheduler å‘ API Server å‘é€è¯·æ±‚ï¼Œç­›é€‰å‡ºæœªç»‘å®šçš„ Podã€‚

  - å½“ Scheduler å†³å®šå°† Pod ç»‘å®šåˆ°æŸä¸ªèŠ‚ç‚¹æ—¶ï¼Œå®ƒä¼šå‘ API Server å‘é€ **Bind API è¯·æ±‚**ã€‚

  - è¯·æ±‚ç¤ºä¾‹ï¼š

    ```http
    POST /api/v1/namespaces/default/pods/<pod-name>/binding HTTP/2
    ```

- **é•¿è¿æ¥ä½œç”¨**ï¼š

  - ç”±äº Scheduler ä¸éœ€è¦**watch**èµ„æºï¼ˆä¸åƒ kubelet ç›‘å¬ Pod å˜æ›´ï¼‰ï¼Œæ‰€ä»¥ Scheduler çš„é•¿è¿æ¥æ›´å¤šæ˜¯ä¸ºäº†**æé«˜è¯·æ±‚æ€§èƒ½**ï¼Œé¿å…é¢‘ç¹å»ºç«‹å’Œå…³é—­ TCP è¿æ¥ã€‚
  - å½“æœ‰å¤šä¸ªè°ƒåº¦è¯·æ±‚æ—¶ï¼Œé•¿è¿æ¥çš„**å¤šè·¯å¤ç”¨**ç‰¹æ€§æ˜¾è‘—æé«˜äº†æ•ˆç‡ã€‚



##### **(2) Kubelet - API Server**

- **å®¢æˆ·ç«¯**ï¼šKubelet æ˜¯å®¢æˆ·ç«¯ã€‚

- **æœåŠ¡ç«¯**ï¼šAPI Server æ˜¯æœåŠ¡ç«¯ã€‚

- **é€šä¿¡æ–¹å¼**ï¼š**HTTP/2 é•¿è¿æ¥**ï¼Œ**watch æœºåˆ¶**ã€‚

- **è¯·æ±‚ç±»å‹**ï¼š

  - kubelet ç›‘å¬ç‰¹å®šçš„èµ„æºï¼ˆå¦‚ Podsï¼‰ï¼š

    ```http
    GET /api/v1/nodes/<node-name>/pods?watch=true&resourceVersion=<RV> HTTP/2
    ```

  - é€šè¿‡ watch æœºåˆ¶ï¼ŒKubelet å¯ä»¥**å®æ—¶ç›‘å¬ Pod çš„å˜åŒ–**ï¼ˆæ–°å¢ã€ä¿®æ”¹ã€åˆ é™¤ï¼‰ã€‚

  - watch æœºåˆ¶é€šè¿‡**æµå¼å“åº”**ï¼ŒAPI Server åœ¨èµ„æºå˜æ›´æ—¶ï¼Œ**ä¸»åŠ¨æ¨é€å˜æ›´äº‹ä»¶**åˆ° Kubeletã€‚

- **é•¿è¿æ¥ä½œç”¨**ï¼š

  - Kubelet åªå‘é€**ä¸€æ¬¡è¯·æ±‚**ï¼ŒAPI Server ä¿æŒé•¿è¿æ¥ï¼Œæ¨é€èµ„æºå˜æ›´äº‹ä»¶ã€‚
  - å¦‚æœ watch è¿æ¥æ–­å¼€ï¼ŒKubelet ä¼šä½¿ç”¨æœ€åçš„ `resourceVersion` é‡æ–°å‘èµ· watch è¯·æ±‚ã€‚



##### **(3) API Server - etcd**

- **å®¢æˆ·ç«¯**ï¼šAPI Server æ˜¯å®¢æˆ·ç«¯ã€‚

- **æœåŠ¡ç«¯**ï¼šetcd æ˜¯æœåŠ¡ç«¯ã€‚

- **é€šä¿¡æ–¹å¼**ï¼š**gRPC é•¿è¿æ¥**ï¼ˆHTTP/2ï¼‰ã€‚

- **è¯·æ±‚ç±»å‹**ï¼š

  - è¯»æ“ä½œï¼š

    ```go
    etcdClient.Get(ctx, "/registry/pods/default/nginx-pod")
    ```

  - å†™æ“ä½œï¼š

    ```go
    etcdClient.Put(ctx, "/registry/pods/default/nginx-pod", "<pod-data>")
    ```

- **é•¿è¿æ¥ä½œç”¨**ï¼š

  - gRPC æ˜¯åŸºäº **HTTP/2** çš„è¿œç¨‹è¿‡ç¨‹è°ƒç”¨ï¼ˆRPCï¼‰æ¡†æ¶ã€‚
  - **API Server ä¸ä¼šåœ¨æ¯æ¬¡è¯·æ±‚æ—¶é‡æ–°åˆ›å»º TCP è¿æ¥**ï¼Œè€Œæ˜¯ç»´æŒä¸€ä¸ª**æŒä¹…çš„ HTTP/2 è¿æ¥**ï¼Œè¿™æ˜¾è‘—å‡å°‘äº† etcd å’Œ API Server ä¹‹é—´çš„ç½‘ç»œå¼€é”€ã€‚
  - **etcd ä½¿ç”¨ MVCCï¼ˆå¤šç‰ˆæœ¬å¹¶å‘æ§åˆ¶ï¼‰** æœºåˆ¶ï¼Œæ¯ä¸ªå˜æ›´éƒ½ä¼šç”Ÿæˆä¸€ä¸ª**æ–°çš„ revision**ï¼ŒAPI Server ä½¿ç”¨è¿™ä¸ª revision æ¥è¿›è¡Œå¢é‡ç›‘å¬ã€‚



#### **3. HTTPS è¯ä¹¦çš„ä½¿ç”¨**

> **åœ¨ Kubernetes ä¸­çš„ "ä¸‰å¥—è¯ä¹¦" æ˜¯æŒ‡ï¼š**

1. **ETCD ç»„ä»¶é€šä¿¡è¯ä¹¦**ï¼ˆAPI Server â†” ETCDï¼‰
2. **Kubernetes ç»„ä»¶ä¹‹é—´çš„é€šä¿¡è¯ä¹¦**ï¼ˆAPI Serverã€Schedulerã€Kubeletã€Controller Managerï¼‰
3. **å¤–éƒ¨ç”¨æˆ·çš„é€šä¿¡è¯ä¹¦**ï¼ˆkubectlã€å¤–éƒ¨ API è¯·æ±‚ï¼‰



##### **(1) Scheduler - API Server**

- **è¯ä¹¦ç±»å‹**ï¼š**Kubernetes ç»„ä»¶å†…éƒ¨é€šä¿¡è¯ä¹¦**
- è¯ä¹¦è¯´æ˜ï¼š
  - Scheduler éœ€è¦ä¸ API Server è¿›è¡Œ HTTPS è®¤è¯ã€‚
  - API Server å…¬å¼€äº†**kube-apiserver.crt** å’Œ **kube-apiserver.key**ã€‚
  - Scheduler ä½¿ç”¨ **kube-controller-manager.crt** å’Œ **kube-controller-manager.key** æ¥ä¸ API Server é€šä¿¡ã€‚
  - è¿™äº›è¯ä¹¦å­˜å‚¨åœ¨ **/etc/kubernetes/pki** ç›®å½•ä¸‹ã€‚
  - ç»„ä»¶ä¹‹é—´çš„**å®¢æˆ·ç«¯è¯ä¹¦**å’Œ**æœåŠ¡å™¨è¯ä¹¦**å‡ç”± **Kubernetes CA è¯ä¹¦**ç­¾åã€‚



##### **(2) Kubelet - API Server**

- **è¯ä¹¦ç±»å‹**ï¼š**Kubernetes ç»„ä»¶å†…éƒ¨é€šä¿¡è¯ä¹¦**
- è¯ä¹¦è¯´æ˜ï¼š
  - Kubelet éœ€è¦ä¸ API Server é€šä¿¡ä»¥è·å– Pod ä¿¡æ¯ã€‚
  - Kubelet è¯ä¹¦ï¼š**kubelet.crt** å’Œ **kubelet.key**ã€‚
  - Kubelet ä½¿ç”¨ **client-certificate-data** å’Œ **client-key-data** è¿›è¡Œå®¢æˆ·ç«¯èº«ä»½éªŒè¯ã€‚
  - API Server ç«¯çš„ **kube-apiserver.crt** å’Œ **kube-apiserver.key** ç”¨äºæä¾› HTTPS è¿æ¥çš„æœåŠ¡ç«¯è¯ä¹¦ã€‚



##### **(3) API Server - etcd**

- **è¯ä¹¦ç±»å‹**ï¼š**ETCD ç»„ä»¶é€šä¿¡è¯ä¹¦**

- è¯ä¹¦è¯´æ˜

  ï¼š

  - API Server ä½œä¸º**å®¢æˆ·ç«¯**ï¼Œetcd ä½œä¸º**æœåŠ¡ç«¯**ã€‚
  - etcd è¯ä¹¦ï¼š**etcd-server.crt** å’Œ **etcd-server.key**ã€‚
  - API Server ä½œä¸ºå®¢æˆ·ç«¯å‘èµ·è¯·æ±‚æ—¶ï¼Œä½¿ç”¨ **etcd-client.crt** å’Œ **etcd-client.key** è¿›è¡ŒåŒå‘è®¤è¯ã€‚
  - è¿™ä¹Ÿæ˜¯ä¸‰å¥—è¯ä¹¦ä¸­**ä¸“é—¨ä¸º ETCD ç»„ä»¶é€šä¿¡ç”Ÿæˆçš„è¯ä¹¦**ã€‚



##### **æ€»ç»“ä¸‰å¥—è¯ä¹¦çš„ä½œç”¨**

| **è¯ä¹¦ç±»å‹**      | **é€šä¿¡åœºæ™¯**                    | **è¯ä¹¦è·¯å¾„**               | **ä½œç”¨**                                  |
| ----------------- | ------------------------------- | -------------------------- | ----------------------------------------- |
| **ETCD ç»„ä»¶è¯ä¹¦** | API Server â†” etcd               | /etc/kubernetes/pki/etcd/  | etcd å’Œ API Server ä¹‹é—´çš„åŠ å¯†é€šä¿¡         |
| **K8s ç»„ä»¶è¯ä¹¦**  | kubeletã€Scheduler â†” API Server | /etc/kubernetes/pki/       | Kubeletã€Schedulerã€API Server ä¹‹é—´çš„é€šä¿¡ |
| **ç”¨æˆ· API è¯ä¹¦** | kubectl â†” API Server            | /etc/kubernetes/admin.conf | ç”¨æˆ·ä½¿ç”¨ kubectl è®¿é—® API Server          |



#### **4. å…³é”®æ€»ç»“**

1. **è°æ˜¯å®¢æˆ·ç«¯ï¼Œè°æ˜¯æœåŠ¡ç«¯ï¼Ÿ**
   - **Scheduler â†” API Server**: Scheduler æ˜¯å®¢æˆ·ç«¯ï¼ŒAPI Server æ˜¯æœåŠ¡ç«¯ã€‚
   - **Kubelet â†” API Server**: Kubelet æ˜¯å®¢æˆ·ç«¯ï¼ŒAPI Server æ˜¯æœåŠ¡ç«¯ã€‚
   - **API Server â†” etcd**: API Server æ˜¯å®¢æˆ·ç«¯ï¼Œetcd æ˜¯æœåŠ¡ç«¯ã€‚
2. **é•¿è¿æ¥**
   - **Scheduler å’Œ API Server ä¹‹é—´**ï¼šHTTP/2 é•¿è¿æ¥ã€‚
   - **Kubelet å’Œ API Server ä¹‹é—´**ï¼šHTTP/2 é•¿è¿æ¥ï¼ˆwatch æœºåˆ¶ï¼Œæ¨é€å˜åŒ–äº‹ä»¶ï¼‰ã€‚
   - **API Server å’Œ etcd ä¹‹é—´**ï¼šgRPCï¼ˆåŸºäº HTTP/2 çš„é•¿è¿æ¥ï¼‰ã€‚
3. **ä¸‰å¥—è¯ä¹¦çš„ä½¿ç”¨**
   - **ETCD è¯ä¹¦**ï¼šAPI Server â†” etcd é€šä¿¡ã€‚
   - **Kubernetes ç»„ä»¶è¯ä¹¦**ï¼šSchedulerã€Kubeletã€Controller Manager ä¸ API Server ä¹‹é—´çš„é€šä¿¡ã€‚
   - **ç”¨æˆ· API è¯ä¹¦**ï¼šå¤–éƒ¨ç”¨æˆ·ï¼ˆå¦‚ kubectlï¼‰ä¸ API Server ä¹‹é—´çš„é€šä¿¡ã€‚





## Controller Managerè¯¦è§£

æ§åˆ¶å™¨æœ‰å¾ˆå¤šç§ï¼Œä½†æ˜¯é‡Œé¢çš„é€»è¾‘æ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯thinkloop, æ¯ä¸€ä¸ªControlleréƒ½æ˜¯ä¸€ä¸ªç”Ÿäº§è€…ï¼Œæ¶ˆè´¹è€…æ¨¡å‹ï¼Œä¸€è¾¹ç›‘æ§API Serverçš„å˜åŒ–ï¼ŒAPI Serveræ”¯æŒwatchable,ä»»ä½•äº‹ä»¶å‘ç”Ÿäº†å˜åŒ–ï¼Œé€šè¿‡watchæœºåˆ¶å°±ä¼šé€šçŸ¥ï¼Œcontroller managerä¸­çš„ç”Ÿäº§è€…å°±ä¼šè§‚æµ‹åˆ°è¿™äº›å˜åŒ–ï¼Œè¿™äº›å˜åŒ–å‘ç”Ÿåï¼Œä¼šæœ‰å°†å…¶æ”¾å…¥ä¸­å¿ƒé˜Ÿåˆ—ä¸­ï¼Œæ¶ˆè´¹è€…ä»è¿™é‡Œå–æ•°æ®ï¼Œå–å‡ºæ¥ä¹‹åå»åšé…ç½®ï¼Œæ‰€ä»¥ä»»ä½•æ§åˆ¶å™¨éƒ½æ˜¯ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å‹

- Controller Manageræ˜¯é›†ç¾¤å¤§è„‘ï¼Œæ˜¯ç¡®ä¿æ•´ä¸ªé›†ç¾¤åŠ¨èµ·æ¥çš„å…³é”®ï¼›
- ä½œç”¨æ˜¯ç¡®ä¿Kuberneteséµå¾ªå£°æ˜å¼ç³»ç»Ÿè§„èŒƒï¼Œç¡®ä¿ç³»ç»Ÿçš„çœŸå®çŠ¶æ€(Actual State)ä¸ç”¨æˆ·å®šä¹‰çš„æœŸæœ›çŠ¶æ€ï¼ˆDesired Stateï¼‰ä¸€è‡´ï¼›
- Controller Manageræ˜¯å¤šä¸ªæ§åˆ¶å™¨çš„ç»„åˆï¼Œæ¯ä¸ªControlleräº‹å®ä¸Šéƒ½æ˜¯ä¸€ä¸ªControll loopï¼Œè´Ÿè´£ä¾¦å¬å…¶ç®¡æ§çš„å¯¹è±¡ï¼Œå½“å¯¹è±¡å‘ç”Ÿå˜æ›´æ—¶å®Œæˆé…ç½®ï¼›
- Controlleré…ç½®å¤±è´¥é€šå¸¸ä¼šè§¦å‘è‡ªåŠ¨é‡è¯•ï¼Œæ•´ä¸ªé›†ç¾¤ä¼šåœ¨æ§åˆ¶å™¨ä¸æ–­é‡è¯•çš„æœºåˆ¶ä¸‹ç¡®ä¿æœ€ç»ˆä¸€è‡´æ€§ï¼ˆEventual Consistencyï¼‰



### æ§åˆ¶å™¨å·¥ä½œæµç¨‹

![image-20241220161159816](../markdown_img/image-20241220161159816.png)

Informer and lister Overview

- Informer: Informers are responsible for watching Kubernetes resources and reacting to changes(events).They efficiently monitor resouces state by subscribing to API events like `add`,`update`and`Delete`.These events are produced by the Kubernetes API Server whenever relevant objects changed

- Lister: Listers provide cached access to resources. Instead of directly querying the API server, they interact with a local cache that is populated by informers. This makes controllers more efficient by reducing the number of API requests needed to get the current state of objects

Event Handling with Informers

- Event Registration: Informers register event handlers to listen for changes(like add, update,delete)to resources. Whenerver an event occurs (e.g.,a Pod is added or deleted), the informer triggers the corresponding handler

- Key Extraction: The handler processes the event by extracting the key of the affected object, typically composed of its namespace and name. This key uniquely identifies the object in the cluster

Queue and Rate-Limited Queue

- Work Queues: when an event occurs, instead of processing it immediately, the object's key is placed into a rate-limited queue. the rate-limiting aspect helps prevent overwhelming the controllers with too many requests, especially if there are repeated failures. if a failure occurs, the item can be re-enqueued after a delay based on the rate-limiting policy

- Rate Limiting: Rate limiting is crucial for handing failures gracefully. If processing an event fails (e.g., due to a temporary error or unavailability of resources),the object is re-enqueued after a backoff period, allowing the controller to retry the operation without overloading the system.

Worker and Consumer Logic:

- Workers: On the other side of the queue, worker goroutines continuously dequeue and process these events.Each worker pull a key from the queue and reconclies the state of the corresponding object by querying its details using the lister and then performing the required actions to converge the cluster's state towards the desired configuration.
- Reconciliation Loop: The worker performs a reconciliation loop,which consists of checking the current state of the resource,comparing it to the desired state, and taking corrective action if there is a discrepancy.For instance, if a Pod should be running but isn't the controller will take steps to start it.

Error Handling and Retry

- If the processing of an event fails, the key is re-queued with a delay(rate limiting) so that the controller can retry later. This mechanism helps handle transient error without discarding events and ensures that all objects eventually converge to their desired state.

Producer-Consumer Model

- THis entire flow is a classic producer-consumer model:
  - Producers: The informers produce events and enqueue the affected objects'keys.
  - Consumers: Workers act as consumers, dequeueing keys, and processing them until the queue is empty.

- æ³¨æ„ï¼š
  - Informer ç›‘å¬çš„æ˜¯å½“å‰çŠ¶æ€çš„å˜åŒ–ï¼Œé€šè¿‡å¤„ç† API Server æ¨é€çš„äº‹ä»¶ï¼Œç¡®ä¿æœ¬åœ°ç¼“å­˜ä¸­çš„æ•°æ®å§‹ç»ˆä¸ Kubernetes é›†ç¾¤ä¸­çš„å®é™…çŠ¶æ€ä¿æŒåŒæ­¥ã€‚
  - Lister æä¾›çš„æ˜¯å¯¹å½“å‰çŠ¶æ€çš„è®¿é—®ï¼Œä½†è¿™ä¸ªçŠ¶æ€æ˜¯ä» informer çš„ç¼“å­˜ä¸­è·å–çš„ã€‚å®ƒæ˜¯ä¸ºäº†å‡å°‘é¢‘ç¹çš„ API è¯·æ±‚ï¼Œæå‡è®¿é—®æ€§èƒ½ã€‚



### Informerçš„å†…éƒ¨æœºåˆ¶

![image-20241220161252961](../markdown_img/image-20241220161252961.png)



- kubernetesæä¾›äº†ä¸€ç³»åˆ—çš„é¡¹ç›®ï¼Œè¯¥é¡¹ç›®å«code generatorï¼Œï¼ˆKubernetes æä¾›äº†å·¥å…·ï¼Œå¦‚ code-generatorï¼Œå¯ä»¥è‡ªåŠ¨ä¸ºä½ ç”Ÿæˆ Go è¯­è¨€çš„å®¢æˆ·ç«¯ã€informerã€lister å’Œæ·±åº¦æ‹·è´å‡½æ•°ã€‚è¿™äº›å·¥å…·èƒ½å¤§å¤§ç®€åŒ–è‡ªå®šä¹‰æ§åˆ¶å™¨çš„å¼€å‘ã€‚ä½ åªéœ€ä¸“æ³¨äºå®šä¹‰è‡ªå®šä¹‰èµ„æºçš„ç»“æ„ä½“ï¼Œå‰©ä¸‹çš„ä»£ç ç”Ÿæˆå·¥ä½œäº¤ç”± code-generator å®Œæˆã€‚ï¼‰è¿™ä¸ªé¡¹ç›®çš„ä½œç”¨å°±æ˜¯ä½ è¦å®šä¹‰ä»»ä½•Kuberneteså¯¹è±¡ï¼Œå®šä¹‰è¿™äº›å¯¹è±¡æ—¶ï¼Œåªéœ€è¦å»å®šä¹‰å®ƒçš„æ•°æ®ç»“æ„ï¼Œè¿™ä¸ªæ•°æ®ç»“æ„ä¸€æ—¦åˆ›å»ºå¥½ï¼Œåœ¨API Serverè¿™è¾¹å‘å¸ƒï¼Œä½ å°±å¯ä»¥é€šè¿‡api Serverå»è®¿é—®è¿™ä¸ªæ•°æ®

- Informeré¦–å…ˆä¼šæä¾›ä¸€ä¸ªlist&watchæœºåˆ¶ï¼ˆinformeråœ¨å¯åŠ¨åä¼šå‘èµ·ä¸€ä¸ªé•¿è¿æ¥åˆ°API serverï¼Œé€šå¸¸æ¥è®²ï¼Œä¼šåœ¨ç¬¬ä¸€æ—¶é—´listä¸€ä¸‹ï¼Œæ¯”å¦‚ä¸€ä¸ªpod list&watchï¼Œå®ƒä¼šæŠŠå½“å‰æ‰€æœ‰çš„podlistä¸‹æ¥ï¼Œç„¶åå›åˆ›å»ºwatchè¿æ¥ï¼Œé‚£ä¹ˆapi serverä¸Šæœ‰å“ªäº›podçš„å˜åŒ–ï¼Œå°±ä¼šå‘Šè¯‰informerï¼‰
  - API Serveræ˜¯ä¸€ä¸ªæ ‡å‡†çš„RESTfulAPIï¼Œ å®ƒæä¾›äº†ä¸€ä¸ªstringï¼Œä¸€ä¸ªjsonæ ¼å¼çš„åºåˆ—åŒ–æ•°æ®ï¼Œå¦‚æœæˆ‘ä»¬çš„ç¨‹åºè¦å»æ¶ˆè´¹è¿™ä¸ªåºåˆ—åŒ–çš„æ•°æ®ï¼Œé‚£ä¹ˆå°±è¦ååºåˆ—åŒ–ï¼Œï¼ˆå°±æ˜¯æŠŠè¿™ä¸ªå­—ç¬¦ä¸²è½¬æ¢ä¸ºä¸€ä¸ªä¸ªgoå¯¹è±¡ï¼Œè¿™é‡Œä½¿ç”¨åå°„æœºåˆ¶å®ç°ï¼Œåå°„æœºåˆ¶å›å»è§£æapi serverä¸­çš„keyï¼Œæ¯ä¸€ä¸ªå¯¹è±¡çš„å®šä¹‰ï¼Œå®ƒéƒ½ä¼šæœ‰json_tagï¼Œé€šè¿‡json tagï¼Œæˆ‘ä»¬å°±ä¼šçŸ¥é“ï¼Œè¿™ä¸ªjsonçš„key,å¯¹åº”goè¯­è¨€ä¸­çš„å“ªä¸ªå±æ€§ï¼Œé€šè¿‡è¿™ç§åå°„æœºåˆ¶ï¼Œå°±æŠŠä¸€ä¸ªåºåˆ—åŒ–çš„å¯¹è±¡ï¼Œè½¬æ¢ä¸ºgoçš„structï¼‰
  - åç»­æœ‰ä¸€ä¸ªDelta buffï¼Œä¸€ä¸ªç¯çŠ¶å†…å­˜ç»“æ„ï¼ˆä»»ä½•æ—¶å€™éƒ½å¯ä»¥ä¸€ç›´å¾€é‡Œå†™ï¼‰ï¼Œå¦‚æœæˆ‘çš„bufferæ»¡äº†ï¼Œå°±ä¼šè‡ªåŠ¨è¦†ç›–æœ€è€çš„æ•°æ®çš„
  - ç„¶åä»–ä¼šåšä¸€ä¸ªé€šçŸ¥ï¼Œè®©informeræ¥å¤„ç†è¿™äº›æ•°æ®
  - informerä¼šæŠŠè¿™äº›ååºåˆ—åŒ–å¥½çš„æ•°æ®ï¼Œæ”¾å…¥thread Safe Storeé‡Œé¢ï¼Œè¿™é‡Œæœ‰indexerï¼Œä¼šæœ‰ç´¢å¼•ï¼Œæˆ‘ä»¬åœ¨æœªæ¥è¦å»è®¿é—®è¿™äº›Kuberneteå¯¹è±¡çš„æ—¶å€™ï¼Œå°±ä¸éœ€è¦å»api serverå»è®¿é—®äº†ï¼Œæˆ‘ä»¬åªéœ€è¦å¯¹local storeè®¿é—®ï¼Œå‡å°‘å¯¹api serverçš„è®¿é—®ï¼Œç„¶ååŒæ—¶è¿™ä¸ªå¯¹è±¡çš„å˜åŒ–ä¼šé€šè¿‡eventå‘ç»™event handlerï¼Œç„¶åå°†å¯¹åº”çš„keyæå–å‡ºæ¥æ”¾å…¥queueä¸­ï¼Œç”±å¦ä¸€è¾¹çš„wokerå°†å…¶å–èµ°è¿›è¡Œå¤„ç†


- ä»»ä½•çš„æ§åˆ¶å™¨éƒ½åº”è¯¥ä½¿ç”¨shareinformerçš„freemokeï¼Œæ‰€æœ‰çš„å¯¹è±¡åªè¦ç”¨äº†shareinformerçš„freemokeï¼Œæ‰€æœ‰å¯¹è±¡åœ¨å®¢æˆ·ç«¯ï¼Œæ¯”æ–¹ä½ è¦å†™ä¸ªæ§åˆ¶å™¨ï¼Œåœ¨ä½ æ§åˆ¶å™¨ç«¯ï¼Œæ‰€æœ‰api serverå¯¹è±¡å·²ç»æœ‰ä¸€ä»½æœ¬åœ°çš„ç¼“å­˜äº†ï¼Œç”±shareinformerä¿è¯æœ¬åœ°ç¼“å­˜å’Œapiserverä¸­å¯¹è±¡çš„ç‰ˆæœ¬ä¸€è‡´æ€§ï¼Œæ‰€ä»¥å½“æˆ‘ä»¬å†™æ§åˆ¶å™¨ä»£ç çš„æ—¶å€™ï¼Œåº”è¯¥é¿å…ç›´æ¥è®¿é—®api serverã€‚è¯»å–ä»»ä½•å¯¹è±¡éƒ½åº”è¯¥å»local storeå»è¯»å–ï¼ˆThread safe storeï¼‰ï¼Œè€Œä¸æ˜¯ç›´æ¥å»api serverå»è¯»ã€‚ä¸€èˆ¬æ¥è®²ï¼Œåªæœ‰æ›´æ–°ä¸€ä¸ªå¯¹è±¡çš„æ—¶å€™æ‰ä¼šå»apiserverä¸­æ›´æ–°ï¼Œè¦å»è°ƒç”¨api server. 

- æ³¨æ„ä¸Šè¿°çš„local storeæŒ‡çš„æ˜¯ä»£ç é‡Œï¼Œå†…å­˜é‡Œçš„storeä¸æ˜¯æœ¬åœ°çš„é‚£ä¸ªcacheç›®å½•ï¼Œé‚£ä¸ªåœ°æ–¹åªæ˜¯å»æ‹‰å–ä¸€ä¸‹å½“å‰æ”¯æŒçš„apiï¼Œå®ƒä¸ä¼šå­˜å‚¨å¯¹è±¡ï¼ŒçœŸå®çš„å¯¹è±¡æ˜¯å­˜åœ¨æ§åˆ¶å™¨çš„local storeçš„




### æ§åˆ¶å™¨çš„ååŒå·¥ä½œåŸç†

![image-20241220161329298](../markdown_img/image-20241220161329298.png)

- åˆ›å»ºä¸€ä¸ªdeploymentçš„èµ„æºæ¸…å•ï¼Œä½¿ç”¨kubectlåœ¨å®¢æˆ·ç«¯åˆ›å»ºåï¼Œå‘ç»™API Server

```shell
kubectl apply -f myapp-deployment.yaml
```

- API Serverå¯¹æˆ‘è¿›è¡Œè®¤è¯ï¼ˆé€šè¿‡è¯»æœ¬åœ°é…ç½®æ–‡ä»¶ï¼ŒçŸ¥é“æˆ‘æ˜¯è°ï¼‰ï¼Œç„¶åé‰´æƒï¼Œå› ä¸ºæˆ‘ç”¨çš„æ˜¯adminçš„èº«ä»½å»ç™»å½•çš„ï¼Œæ‰€ä»¥æˆ‘æ˜¯æœ‰åˆ›å»ºdeploymentçš„æƒé™çš„ï¼Œç„¶åæˆ‘çš„deploymentåˆæ˜¯åˆæ³•çš„ï¼Œæ‰€ä»¥æˆ‘å¾—deploymentå¯¹è±¡è¢«API Serveræ¥æ”¶ï¼Œå¹¶å­˜å…¥etcdä¸­
- `kube-controller-manager`é‡Œé¢æœ‰ä¸€ä¸ªdeployment controllerï¼Œé¡¾åæ€ä¹‰ï¼Œå®ƒæ„Ÿå…´è¶£çš„å¯¹è±¡æ˜¯deploymentï¼Œå®ƒå›å»æ ¹æ®èµ„æºæ¸…å•çš„å±æ€§ï¼Œå»åˆ›å»ºä¸€ä¸ªreplicasetçš„å¯¹è±¡

```shell
# æŸ¥çœ‹deploymentå¯¹è±¡
kubectl describe deployment myapp -n learn01
Name:                   myapp
Namespace:              learn01
CreationTimestamp:      Tue, 01 Oct 2024 16:02:31 +0800
Labels:                 app=myapp
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=myapp
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=myapp
  Containers:
   pod-test2:
    Image:         registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   myapp-7547f4df6 (3/3 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  6m31s  deployment-controller  Scaled up replica set myapp-7547f4df6 to 3
```

- `kube-controller-manager`é‡Œé¢åˆæœ‰ReplicaSet Controllerï¼Œå®ƒä¹Ÿåœ¨ç›‘å¬API Serverï¼Œç„¶åå®ƒç›‘å¬åˆ°éœ€è¦åˆ›å»º3ä¸ªpodï¼Œç„¶åå½“å‰podä¸å­˜åœ¨ï¼Œä¸€æ¬¡å°±éœ€è¦å®ƒå»åˆ›å»ºè¿™3ä¸ªpodï¼Œç„¶åè¿™ä¸ªpodçš„å¯¹è±¡ç”±replicasetå‘åˆ°API Server

```shell
[root@master201 iventory]#kubectl get replicaset -n learn01
NAME              DESIRED   CURRENT   READY   AGE
myapp-7547f4df6   3         3         3       7m37s
[root@master201 iventory]#kubectl describe replicaset -n learn01
Name:           myapp-7547f4df6
Namespace:      learn01
Selector:       app=myapp,pod-template-hash=7547f4df6
Labels:         app=myapp
                pod-template-hash=7547f4df6
Annotations:    deployment.kubernetes.io/desired-replicas: 3
                deployment.kubernetes.io/max-replicas: 4
                deployment.kubernetes.io/revision: 1
Controlled By:  Deployment/myapp
Replicas:       3 current / 3 desired
Pods Status:    3 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  app=myapp
           pod-template-hash=7547f4df6
  Containers:
   pod-test2:
    Image:         registry.cn-beijing.aliyuncs.com/wangxiaochun/pod-test:v0.1
    Port:          <none>
    Host Port:     <none>
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Events:
  Type    Reason            Age   From                   Message
  ----    ------            ----  ----                   -------
  Normal  SuccessfulCreate  8m5s  replicaset-controller  Created pod: myapp-7547f4df6-fr2hh
  Normal  SuccessfulCreate  8m5s  replicaset-controller  Created pod: myapp-7547f4df6-nkgnd
  Normal  SuccessfulCreate  8m5s  replicaset-controller  Created pod: myapp-7547f4df6-s74wv
```

- API Serverå°†è¯¥POdå¯¹è±¡å›ºåŒ–ä¸‹æ¥ï¼Œå­˜å…¥etcd
- Podå¯¹è±¡è¢«åˆ›å»ºä¸‹æ¥åï¼Œåœ¨åˆå§‹çŠ¶æ€ä¸‹ï¼Œpodå†…çš„nodenameå±æ€§æ˜¯æ²¡æœ‰è¢«å†™å€¼çš„

```shell
kubectl get pod myapp-7547f4df6-fr2hh -n learn01 -o yaml|grep -i nodename
nodeName: node205.feng.org
```

- è¿™ä¸ªæ—¶å€™ç”±äºnodenameæ˜¯ç©ºï¼Œæ­¤æ—¶è°ƒåº¦å™¨Schedulerå°±ä¼šå»åšè°ƒåº¦ï¼Œè°ƒåº¦å™¨åœ¨API Serverä¸Šwatchäº†æ²¡æœ‰è°ƒåº¦è¿‡çš„(nodenameä¸ºç©º)podå¯¹è±¡ï¼Œä»¥åŠå½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œç„¶åæ ¹æ®è°ƒåº¦ç­–ç•¥ï¼Œåˆ¤æ–­å½“å‰é‚£ä¸ªèŠ‚ç‚¹æœ€é€‚åˆè¿™ä¸ªpodï¼Œç„¶åå°†è¿™ä¸ªèŠ‚ç‚¹å’Œpodåšç»‘å®šï¼Œå¹¶å°†ç»“æœå†™å…¥API Server

- å†™å›åˆ°API Serveråï¼ŒèŠ‚ç‚¹ä¸Šçš„kubeletä¼šå…³æ³¨å½“å‰API Serverä¸­ï¼Œè·Ÿæˆ‘çš„èŠ‚ç‚¹ç›¸å…³çš„podæœ‰å“ªäº›ï¼Œè¯¥èŠ‚ç‚¹å‘ç”Ÿäº†ä¸€ä¸ªpodç»‘å®šåï¼Œä¼šè¢«kubeletå‘ç°ï¼Œå°±ä¼šå»æœ¬åœ°æŸ¥å½“å‰è¿è¡Œçš„podæœ‰æ²¡æœ‰è¿™ä¸ªpodï¼Œå¦‚æœæ²¡æœ‰ï¼Œå°±ä¼šè¿›å…¥create podçš„æµç¨‹ï¼Œèµ·podï¼Œå¦‚æœpodæ²¡æœ‰å¤–æŒ‚å­˜å‚¨ï¼Œå°±ä¼šä½¿ç”¨runtimeæ‹‰èµ·podï¼Œå¹¶è°ƒç”¨ç½‘ç»œæ’ä»¶ä¸ºpod setupç½‘ç»œï¼Œå¦‚æœéœ€è¦å¤–æŒ‚å­˜å‚¨ï¼Œå°±éœ€è¦ä½¿ç”¨csiï¼Œä¸ºè¿™ä¸ªpodæŒ‚è½½ç£ç›˜


- å¦‚æœæˆ‘åˆ é™¤ä¸€ä¸ªpodï¼Œæ­¤æ—¶ä¾ç„¶ä¼šäº§ç”Ÿä¸€ä¸ªäº‹ä»¶eventï¼Œè¿™ä¸ªäº‹ä»¶æ˜¯pod deleteäº‹ä»¶ï¼Œè¯¥äº‹ä»¶è¢«replicaset controllerç›‘å¬åˆ°ï¼Œå®ƒçš„èŒè´£æ˜¯é‡Œé¢çš„æ‰€æœ‰podçš„æ•°é‡ä¹Ÿç”¨æˆ·çš„æœŸæœ›çš„æ•°é‡åº”è¯¥æ˜¯ä¸€æ ·çš„ï¼Œæˆ‘åˆ é™¤äº†ä¸€ä¸ªï¼Œæ­¤æ—¶å®é™…podæ•°é‡å’ŒæœŸæœ›æ•°é‡ä¸ç­‰ï¼Œå°±ä¼šè¢«replicasetç›‘æµ‹åˆ°ï¼Œæ­¤æ—¶ä¸ºäº†ç¡®ä¿ä¸€è‡´ï¼Œä»–å°±ä¼šå»åˆ›å»ºä¸€ä¸ªæ–°çš„pod







## SRVè®°å½•è¯¦è§£

SRVï¼ˆ**Service Locator Record**ï¼‰æ˜¯ DNS ä¸­çš„ä¸€ç§è®°å½•ç±»å‹ï¼Œç”¨äº**æŒ‡å®šæŸä¸ªæœåŠ¡çš„ä¸»æœºåï¼ˆhostnameï¼‰å’Œç«¯å£å·ï¼ˆport numberï¼‰**ï¼Œä»¥ä¾¿å®¢æˆ·ç«¯å¯ä»¥é€šè¿‡å®ƒæ‰¾åˆ°æŒ‡å®šæœåŠ¡çš„å®ä¾‹ã€‚å®ƒçš„**ä¸»è¦ä½œç”¨æ˜¯æ”¯æŒåŸºäºæœåŠ¡çš„å‘ç°**ï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­éå¸¸æœ‰ç”¨ã€‚



### SRV è®°å½•çš„ç»“æ„

SRV è®°å½•çš„ç»“æ„ç”±ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ç»„æˆï¼š

```kotlin
_service._protocol.name TTL class SRV priority weight port target
```

| **å­—æ®µ**    | **å«ä¹‰**                                                     |
| ----------- | ------------------------------------------------------------ |
| `_service`  | æœåŠ¡åç§°ï¼Œä»¥ `_` å¼€å¤´ã€‚ä¾‹å¦‚ï¼Œ`_http` è¡¨ç¤º HTTP æœåŠ¡ã€‚        |
| `_protocol` | ä½¿ç”¨çš„åè®®ï¼Œä¾‹å¦‚ `_tcp` è¡¨ç¤º TCP åè®®ï¼Œ`_udp` è¡¨ç¤º UDP åè®®ã€‚ |
| `name`      | æœåŠ¡çš„åŸŸåï¼Œè¡¨ç¤ºæ­¤æœåŠ¡æ‰€å±çš„åŸŸã€‚ä¾‹å¦‚ï¼Œ`service-test.default.svc.cluster.local`ã€‚ |
| `TTL`       | è®°å½•çš„ç”Ÿå­˜æ—¶é—´ï¼ˆTime To Liveï¼‰ï¼Œä»¥ç§’ä¸ºå•ä½ï¼Œè¡¨ç¤ºè¯¥è®°å½•åœ¨ DNS ç¼“å­˜ä¸­çš„æœ‰æ•ˆæœŸã€‚ |
| `class`     | é€šå¸¸ä¸º `IN`ï¼Œè¡¨ç¤º Internet ç±»åˆ«çš„è®°å½•ã€‚                      |
| `SRV`       | è¡¨ç¤ºè¯¥è®°å½•æ˜¯ SRV ç±»å‹ã€‚                                      |
| `priority`  | ä¼˜å…ˆçº§ï¼Œæ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼Œå®¢æˆ·ç«¯åº”ä¼˜å…ˆä½¿ç”¨ä¼˜å…ˆçº§è¾ƒé«˜çš„ç›®æ ‡æœåŠ¡å™¨ã€‚ |
| `weight`    | æƒé‡ï¼Œç”¨äºåœ¨åŒä¸€ä¼˜å…ˆçº§ä¸‹çš„è´Ÿè½½å‡è¡¡ã€‚æƒé‡è¶Šé«˜ï¼Œè¯¥æœåŠ¡å™¨è¢«é€‰ä¸­çš„æ¦‚ç‡è¶Šé«˜ã€‚ |
| `port`      | æœåŠ¡è¿è¡Œçš„ç«¯å£å·ã€‚ä¾‹å¦‚ï¼ŒHTTP é€šå¸¸æ˜¯ `80`ï¼ŒHTTPS æ˜¯ `443`ã€‚   |
| `target`    | æœåŠ¡å¯¹åº”çš„ä¸»æœºåï¼ˆåŸŸåï¼‰ï¼ŒæŒ‡å‘æä¾›æ­¤æœåŠ¡çš„ä¸»æœºï¼ˆå¯ä»¥æ˜¯ Service çš„åç§°æˆ– Pod çš„ IPï¼‰ã€‚ |



### **SRV è®°å½•çš„ç¤ºä¾‹**

å‡è®¾ Kubernetes ä¸­æœ‰ä¸€ä¸ªåä¸º `service-test` çš„ **Service**ï¼Œä½äº `default` å‘½åç©ºé—´ï¼ŒåŸŸååç¼€ä¸º `cluster.local`ï¼Œå…¶ IP ä¸º `10.97.72.1`ï¼Œå¹¶æä¾› TCP åè®®çš„ HTTP æœåŠ¡ï¼Œç›‘å¬ç«¯å£ `80`ã€‚å¯¹åº”çš„ SRV è®°å½•å¦‚ä¸‹ï¼š

```kotlin
_http._tcp.service-test.default.svc.cluster.local. 30 IN SRV 0 100 80 service-test.default.svc.cluster.local.
```



### SRVè®°å½•çš„ä½œç”¨å’Œç”¨é€”

**æœåŠ¡å‘ç°ï¼š**

- SRV è®°å½•å¯ä»¥è®©å®¢æˆ·ç«¯åŠ¨æ€å‘ç°æœåŠ¡çš„ä¸»æœºåå’Œç«¯å£ï¼Œè€Œæ— éœ€ç¡¬ç¼–ç ã€‚
- åœ¨ Kubernetes ä¸­ï¼ŒService çš„ SRV è®°å½•ç”¨äºå®¢æˆ·ç«¯é€šè¿‡ DNS æŸ¥è¯¢æ‰¾åˆ°ç›¸åº”çš„æœåŠ¡å®ä¾‹ã€‚

**è´Ÿè½½å‡è¡¡ï¼š**

- SRV è®°å½•æ”¯æŒé€šè¿‡ **priority** å’Œ **weight** å­—æ®µå®ç°ç®€å•çš„è´Ÿè½½å‡è¡¡ã€‚
- åŒä¸€ä¼˜å…ˆçº§çš„æœåŠ¡å®ä¾‹æŒ‰ç…§æƒé‡åˆ†é…æµé‡ï¼Œä¼˜å…ˆçº§è¾ƒé«˜çš„æœåŠ¡ä¼šè¢«ä¼˜å…ˆé€‰æ‹©ã€‚

**åŠ¨æ€åˆ†å¸ƒå¼ç³»ç»Ÿï¼š**

- åœ¨å¾®æœåŠ¡æ¶æ„æˆ–åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼ŒæœåŠ¡çš„å®ä¾‹å¯èƒ½åŠ¨æ€æ‰©ç¼©å®¹ã€‚SRV è®°å½•å…è®¸å®¢æˆ·ç«¯æ ¹æ® DNS åŠ¨æ€è·å–æœåŠ¡çš„æœ€æ–°ä¿¡æ¯ã€‚

**çµæ´»æ€§ï¼š**

- SRV è®°å½•å¯ä»¥ä¸ºæœåŠ¡å®šä¹‰å¤šä¸ªå®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹çš„ä¼˜å…ˆçº§å’Œæƒé‡å¯ä»¥çµæ´»è°ƒæ•´ï¼Œä»è€Œå®ç°æ›´å¤æ‚çš„è´Ÿè½½åˆ†é…ç­–ç•¥ã€‚





## K8Sä¸­å®‰å…¨æœºåˆ¶çš„è¯ä¹¦ä½“ç³»



### Kubelet å’Œ apiServerä¹‹é—´é€šä¿¡

Kubernetes ä¸­ **kubelet å’Œ API Server ä¹‹é—´çš„é€šä¿¡**ç¡®å®å¾ˆå¥½åœ°ä½“ç°äº† Kubernetes **åŒå‘ TLSï¼ˆmTLSï¼ŒMutual TLSï¼‰**çš„åŠ å¯†æœºåˆ¶ã€‚è¿™ç§æœºåˆ¶é€šè¿‡åŒå‘éªŒè¯ç¡®ä¿äº†é€šä¿¡çš„å®‰å…¨æ€§å’Œèº«ä»½çš„å¯ä¿¡æ€§ã€‚



#### Kubernetes åŒå‘ TLS é€šä¿¡çš„å·¥ä½œæœºåˆ¶

**åŒå‘ TLS åŠ å¯†ï¼š**

- åŒå‘ TLS æ„å‘³ç€ï¼š
  - **å®¢æˆ·ç«¯ï¼ˆkubeletï¼‰éªŒè¯æœåŠ¡ç«¯ï¼ˆAPI Serverï¼‰çš„èº«ä»½**ã€‚
  - **æœåŠ¡ç«¯ï¼ˆAPI Serverï¼‰éªŒè¯å®¢æˆ·ç«¯ï¼ˆkubeletï¼‰çš„èº«ä»½**ã€‚
- è¿™ç§åŒå‘è®¤è¯ç¡®ä¿äº†åŒæ–¹éƒ½æ˜¯å¯ä¿¡ä»»çš„ï¼Œå¹¶é˜²æ­¢äº†ä¸­é—´äººæ”»å‡»ï¼ˆMitMï¼‰ã€‚



**æ¶‰åŠçš„è¯ä¹¦ï¼š**

- **kubelet çš„å®¢æˆ·ç«¯è¯ä¹¦** 

  ```bash
  [root@node1 pki]# ls /var/lib/kubelet/pki/kubelet-client-current.pem
  
  [root@node1 pki]# openssl x509 -in /var/lib/kubelet/pki/kubelet-client-current.pem -text -noout
  Certificate:
      Data:
          Version: 3 (0x2)
          Serial Number:
              f4:4c:9d:a8:f2:82:e8:fd:07:5a:3b:64:57:45:ed:cc
          Signature Algorithm: sha256WithRSAEncryption
          Issuer: CN = kubernetes            # ä¸Šçº§CA
          Validity
              Not Before: Jan  4 01:40:29 2025 GMT
              Not After : Jan  4 01:40:29 2026 GMT
          Subject: O = system:nodes, CN = system:node:node1
          Subject Public Key Info:
              Public Key Algorithm: id-ecPublicKey
              ......
  ```

  - kubelet ç”¨äºå‘ API Server è¯æ˜è‡ªå·±çš„èº«ä»½ã€‚

- **API Server çš„æœåŠ¡ç«¯è¯ä¹¦**

  ```bash
  /etc/kubernetes/pki/apiserver.crt
  
  [root@master1 pki]#openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout
  Certificate:
      Data:
          Version: 3 (0x2)
          Serial Number: 8495257128868470889 (0x75e5375951cf6069)
          Signature Algorithm: sha256WithRSAEncryption
          Issuer: CN = kubernetes            # ä¸Šçº§CA
          Validity
              Not Before: Jan  4 01:39:06 2025 GMT
              Not After : Jan  4 01:44:06 2026 GMT
          Subject: CN = kube-apiserver
          Subject Public Key Info:
          ......
  ```

  - API Server ç”¨äºå‘ kubelet è¯æ˜è‡ªå·±çš„èº«ä»½ã€‚

- **CA è¯ä¹¦**

  ```bash
  /etc/kubernetes/pki/ca.crt
  
  [root@node1 pki]# openssl x509 -in ca.crt -text -noout
  Certificate:
      Data:
          Version: 3 (0x2)
          Serial Number: 1575855922115436521 (0x15de909ca6e2dfe9)
          Signature Algorithm: sha256WithRSAEncryption
          Issuer: CN = kubernetes            # ä¸Šçº§CA
          Validity
              Not Before: Jan  4 01:39:06 2025 GMT
              Not After : Jan  2 01:44:06 2035 GMT
          Subject: CN = kubernetes          # ä¸Šçº§CAä¸€è‡´ï¼Œå› æ­¤æ˜¯è‡ªç­¾è¯ä¹¦
          Subject Public Key Info:
          ......
  ```

  - kubelet å’Œ API Server éƒ½é€šè¿‡è¯¥ CA è¯ä¹¦éªŒè¯å¯¹æ–¹çš„è¯ä¹¦æ˜¯å¦åˆæ³•ã€‚



**é€šä¿¡è¿‡ç¨‹ï¼š**

- kubelet è¿æ¥åˆ° API Serverï¼š
  1. kubelet å‘èµ· HTTPS è¯·æ±‚ï¼Œå¹¶å‘é€è‡ªå·±çš„å®¢æˆ·ç«¯è¯ä¹¦å’Œç§é’¥ã€‚
  2. API Server éªŒè¯ kubelet çš„å®¢æˆ·ç«¯è¯ä¹¦æ˜¯å¦ç”±å¯ä¿¡ CA ç­¾å‘ã€‚
  3. éªŒè¯é€šè¿‡åï¼ŒAPI Server ç¡®è®¤ kubelet æ˜¯ä¸€ä¸ªå¯ä¿¡çš„å®¢æˆ·ç«¯ã€‚

- API Server è¿”å›å“åº”ï¼š
  1. API Server è¿”å›è‡ªå·±çš„æœåŠ¡ç«¯è¯ä¹¦ã€‚
  2. kubelet ä½¿ç”¨æœ¬åœ°çš„ CA è¯ä¹¦éªŒè¯ API Server çš„æœåŠ¡ç«¯è¯ä¹¦ã€‚
  3. éªŒè¯é€šè¿‡åï¼Œkubelet ç¡®è®¤ API Server æ˜¯å¯ä¿¡çš„æœåŠ¡ç«¯ã€‚

- æœ€ç»ˆï¼ŒåŒå‘ TLS éªŒè¯å®Œæˆï¼Œé€šä¿¡å»ºç«‹ã€‚





### Kubectl å’Œ apiServerä¹‹é—´é€šä¿¡

`Kubectl` æ˜¯ Kubernetes çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºä¸é›†ç¾¤çš„ API Server é€šä¿¡ã€‚å®ƒæ˜¯ç”¨æˆ·å’Œ Kubernetes é›†ç¾¤ä¹‹é—´çš„æ¡¥æ¢ï¼Œæ‰€æœ‰å¯¹é›†ç¾¤çš„æ“ä½œéƒ½æ˜¯é€šè¿‡ `kubectl` å‘å‡ºçš„è¯·æ±‚å®ç°çš„ã€‚ä»¥ä¸‹æ˜¯ `kubectl` å’Œ API Server ä¹‹é—´é€šä¿¡çš„è¯¦ç»†è®²è§£ï¼š



#### é€šä¿¡çš„åŸºç¡€æ¦‚å¿µ

**kubectl çš„å·¥ä½œåŸç†ï¼š**

- `kubectl` é€šè¿‡ **REST API** ä¸ API Server é€šä¿¡ã€‚
- `kubectl` ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ **`~/.kube/config`**ï¼‰æ¥ç¡®å®šéœ€è¦è¿æ¥çš„ API Server çš„åœ°å€ã€è®¤è¯ä¿¡æ¯ã€å‘½åç©ºé—´ç­‰ã€‚



**API Server çš„èŒè´£**

- API Server æ˜¯ Kubernetes æ§åˆ¶å¹³é¢çš„æ ¸å¿ƒç»„ä»¶ã€‚
- å®ƒæ¥æ”¶ `kubectl` å‘å‡ºçš„ REST è¯·æ±‚ï¼ŒéªŒè¯ã€æˆæƒè¯·æ±‚ï¼Œå¹¶å°†å…¶è·¯ç”±åˆ°ç›¸åº”çš„æ§åˆ¶å™¨æˆ– etcd å­˜å‚¨ã€‚



**ä½¿ç”¨çš„åè®®**

- `kubectl` å’Œ API Server çš„é€šä¿¡ä½¿ç”¨ **HTTPS** åè®®ã€‚
- é€šä¿¡é€šè¿‡ **åŒå‘ TLSï¼ˆmTLSï¼‰** è®¤è¯è¿›è¡ŒåŠ å¯†å’Œèº«ä»½éªŒè¯ã€‚



#### é€šä¿¡è¿‡ç¨‹è¯¦è§£

**åŠ è½½é…ç½®æ–‡ä»¶**

- `kubectl` åœ¨è¿è¡Œæ—¶ï¼Œä¼šè¯»å–é»˜è®¤çš„ `~/.kube/config` æ–‡ä»¶ï¼ŒåŠ è½½ä»¥ä¸‹ä¿¡æ¯ï¼š
  - **API Server çš„åœ°å€ï¼š** å¦‚ `https://<api-server-ip>:6443`ã€‚
  - **è®¤è¯ä¿¡æ¯ï¼š** åŒ…æ‹¬å®¢æˆ·ç«¯è¯ä¹¦ã€å¯†é’¥ã€æˆ– Bearer Tokenã€‚
  - **å‘½åç©ºé—´ï¼š** å¦‚æœæœªæŒ‡å®šï¼Œé»˜è®¤æ˜¯ `default`ã€‚
  - **ä¸Šä¸‹æ–‡ï¼š** ç”¨äºé€‰æ‹©å½“å‰é›†ç¾¤çš„é…ç½®ã€‚



**è®¤è¯ä¸æˆæƒ**

- **è®¤è¯ï¼š**
  - `kubectl` æä¾›å®¢æˆ·ç«¯è¯ä¹¦æˆ– Token ç»™ API Serverã€‚
  - API Server ä½¿ç”¨ CA è¯ä¹¦ï¼ˆå¦‚ `/etc/kubernetes/pki/ca.crt`ï¼‰éªŒè¯å®¢æˆ·ç«¯è¯ä¹¦çš„åˆæ³•æ€§
  - è‹¥éªŒè¯æˆåŠŸï¼ŒAPI Server è¯†åˆ«ç”¨æˆ·èº«ä»½
- **æˆæƒ**
  - API Server æ ¹æ®ç”¨æˆ·èº«ä»½å’ŒRBACï¼ˆRole-Based Access Controlï¼‰ç­–ç•¥ï¼Œæ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™æ‰§è¡Œè¯¥æ“ä½œã€‚

- **è¯·æ±‚çš„å…·ä½“å¤„ç†**
  - è¯·æ±‚å¯ä»¥æ˜¯ `kubectl get pods`ã€`kubectl apply -f deployment.yaml` ç­‰ã€‚
  - API Server å¤„ç†æµç¨‹ï¼š
    - **è§£æè¯·æ±‚ï¼š** æ ¹æ®è¯·æ±‚è·¯å¾„å’Œæ–¹æ³•ï¼ˆå¦‚ GETã€POSTã€DELETEï¼‰åˆ¤æ–­æ“ä½œç›®æ ‡å’Œç±»å‹ã€‚
    - **éªŒè¯è¯·æ±‚ï¼š** æ£€æŸ¥è¯·æ±‚ä½“æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚
    - **è·¯ç”±è¯·æ±‚ï¼š** å°†è¯·æ±‚è½¬å‘ç»™å¯¹åº”çš„æ§åˆ¶å™¨æˆ–ç»„ä»¶ï¼ˆå¦‚ Schedulerã€Controller Managerï¼‰ã€‚
    - **è¿”å›å“åº”ï¼š** è¿”å›æ“ä½œç»“æœæˆ–æ•°æ®ï¼ˆå¦‚ Pod åˆ—è¡¨ï¼‰ã€‚
- **ä¼ è¾“å®‰å…¨æ€§**
  - é€šä¿¡ä½¿ç”¨ **TLS åŠ å¯†**ï¼Œé˜²æ­¢æ•°æ®è¢«çªƒå¬æˆ–ç¯¡æ”¹ã€‚
  - åŒå‘ TLS ç¡®ä¿ï¼š
    - **API Server çš„èº«ä»½ï¼š** `kubectl` ä½¿ç”¨ CA è¯ä¹¦éªŒè¯ API Server çš„æœåŠ¡ç«¯è¯ä¹¦ã€‚
    - **kubectl çš„èº«ä»½ï¼š** API Server ä½¿ç”¨ CA éªŒè¯ `kubectl` çš„å®¢æˆ·ç«¯è¯ä¹¦ã€‚



#### åŒå‘ TLS å®ç°ç»†èŠ‚

**kubectl å®¢æˆ·ç«¯è¯ä¹¦ï¼š**

- é€šå¸¸å­˜å‚¨åœ¨ `~/.kube/config` æ–‡ä»¶ä¸­ï¼ŒæŒ‡å‘ä»¥ä¸‹å­—æ®µï¼š
  - `client-certificate`ï¼šå®¢æˆ·ç«¯è¯ä¹¦è·¯å¾„ã€‚
  - `client-key`ï¼šå®¢æˆ·ç«¯ç§é’¥è·¯å¾„ã€‚
  - `certificate-authority`ï¼šCA è¯ä¹¦è·¯å¾„ï¼Œç”¨äºéªŒè¯ API Server çš„æœåŠ¡ç«¯è¯ä¹¦ã€‚



**API Server æœåŠ¡ç«¯è¯ä¹¦ï¼š**

- å­˜å‚¨åœ¨ `/etc/kubernetes/pki/apiserver.crt`ã€‚
- é…ç½®åœ¨ API Server çš„å¯åŠ¨å‚æ•°ä¸­ï¼Œç”¨äºå¯¹å¤–æä¾› HTTPS æœåŠ¡ã€‚



**äº¤äº’è¿‡ç¨‹**

- `kubectl` ä½¿ç”¨è‡ªå·±çš„å®¢æˆ·ç«¯è¯ä¹¦ä¸ API Server æ¡æ‰‹ï¼Œè¯æ˜èº«ä»½ã€‚
- API Server ä½¿ç”¨æœåŠ¡ç«¯è¯ä¹¦æä¾› HTTPS æœåŠ¡ï¼Œ`kubectl` éªŒè¯å…¶èº«ä»½



#### é€šä¿¡ç¤ºä¾‹

**kubectl å‘½ä»¤ï¼š**

```bash
kubectl get pods
```

**å®Œæ•´é€šä¿¡æµç¨‹ï¼š**

- **kubectl å‘èµ·è¯·æ±‚ï¼š**
  - è¯·æ±‚åœ°å€ï¼šä»é…ç½®æ–‡ä»¶ä¸­è¯»å–ï¼Œå¦‚ `https://<api-server-ip>:6443/api/v1/pods`ã€‚
  - è¯·æ±‚æ–¹æ³•ï¼š`GET`ã€‚
  - é™„å¸¦è®¤è¯ä¿¡æ¯ï¼ˆå®¢æˆ·ç«¯è¯ä¹¦æˆ– Tokenï¼‰ã€‚
- **API Server éªŒè¯èº«ä»½ï¼š**
  - éªŒè¯ `kubectl` æä¾›çš„å®¢æˆ·ç«¯è¯ä¹¦æ˜¯å¦ç”±å¯ä¿¡ CA ç­¾å‘ã€‚
  - æ ¹æ® RBAC æƒé™æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰ `list pods` çš„æƒé™ã€‚

- **API Server æ‰§è¡Œæ“ä½œï¼š**
  - æŸ¥è¯¢ etcd æ•°æ®åº“ä¸­çš„ Pod ä¿¡æ¯ã€‚
  - æ ¼å¼åŒ–æŸ¥è¯¢ç»“æœä¸º JSONã€‚
- **API Server è¿”å›ç»“æœï¼š**
  - å°† JSON æ•°æ®é€šè¿‡ HTTPS è¿”å›ç»™ `kubectl`ã€‚
  - `kubectl` æ ¼å¼åŒ–å¹¶åœ¨ç»ˆç«¯æ˜¾ç¤ºç»“æœã€‚



#### é…ç½®æ–‡ä»¶ç¤ºä¾‹

**`~/.kube/config` æ–‡ä»¶ï¼š**

```yaml
apiVersion: v1
kind: Config
clusters:
- cluster:
    certificate-authority: /etc/kubernetes/pki/ca.crt # CA è¯ä¹¦è·¯å¾„ï¼Œç”¨äºéªŒè¯ API Server çš„æœåŠ¡ç«¯è¯ä¹¦ã€‚
    server: https://<api-server-ip>:6443
  name: kubernetes
users:
- name: admin
  user:
    client-certificate: /etc/kubernetes/pki/admin.crt   # å®¢æˆ·ç«¯è¯ä¹¦è·¯å¾„
    client-key: /etc/kubernetes/pki/admin.key
contexts:
- context:
    cluster: kubernetes
    user: admin
  name: admin@kubernetes
current-context: admin@kubernetes

```



## å®é™…ç”Ÿäº§ä¸­çš„æœåŠ¡ç‰ˆæœ¬



| ä¸­é—´ä»¶        | ç‰ˆæœ¬       | æ˜¯å¦ä¾èµ–å…¶ä»–ä¸­é—´ä»¶ | ä¾èµ–ä¸­é—´ä»¶  | æ˜¯å¦æ”¯æŒå®¹å™¨åŒ– | æ˜¯å¦æ”¯æŒUbuntu |
| ------------- | ---------- | ------------------ | ----------- | -------------- | -------------- |
| rabbitmq      | 3.7.27     | å¦                 |             | æ˜¯             | æ˜¯             |
| redis         | 5.0.14     | å¦                 |             | æ˜¯             | æ˜¯             |
| nacos         | 1.4.2      | æ˜¯                 | mysql.nginx | æ˜¯             | æ˜¯             |
| tomcat        | 8.5.65     | å¦                 |             | æ˜¯             | æ˜¯             |
| kafka         | 2.13_2.6.0 | æ˜¯                 | zookeeper   | æ˜¯             | æ˜¯             |
| zookeeper     | 3.8.0      | å¦                 |             | æ˜¯             | æ˜¯             |
| elasticsearch | 7.10.2     | å¦                 |             | æ˜¯             | æ˜¯             |
| tengine       | 2.3.3      | å¦                 |             | æ˜¯             | æ˜¯             |



| è½¯ä»¶åç§°   | è½¯ä»¶ç‰ˆæœ¬        | ä½¿ç”¨ç±»å‹  | å¤‡æ³¨         |
| ---------- | --------------- | --------- | ------------ |
| JDK/JRE    | 1.8             | å¹³å°      | Java         |
| CEPH       | 13.2.10         | å¹³å°/ä¸šåŠ¡ | åˆ†å¸ƒå¼å­˜å‚¨   |
| DOCKER     | 20.10.7         | å¹³å°      | é•œåƒå®¹å™¨     |
| K8S        | 1.18.19         | å¹³å°      | å®¹å™¨ç¼–æ’     |
| KUBESPHERE | 3.1.0           | å¹³å°      | å¯è§†åŒ–å®¹å™¨   |
| HARBOR     | 2.2.0-ecobal116 | å¹³å°      | é•œåƒä»“åº“     |
| ZOOKEEPER  | 3.4.5           | å¹³å°      | åˆ†å¸ƒå¼æœåŠ¡   |
| KAFKA      | 2.2.2           | ä¸šåŠ¡      | é˜Ÿåˆ—         |
| REDIS      | 6.2.4           | ä¸šåŠ¡      | ç¼“å­˜åº“       |
| ORACLE     | 12CåŠä»¥ä¸Š       | ä¸šåŠ¡      | æ•°æ®åº“       |
| NACOS      | 2.0.3           | å¹³å°      | æœåŠ¡é…ç½®     |
| SFTP       | /               | ä¸šåŠ¡      | æ–‡ä»¶         |
| NGINX      | 1.18.0          | ä¸šåŠ¡      | æœåŠ¡ä»£ç†     |
| XX_JOB     | /               | ä¸šåŠ¡      | ä»»åŠ¡è°ƒåº¦å¹³å° |



## BGPåè®®

### BGPæ¦‚è¿°

#### BGPç®€ä»‹

åŠ¨æ€è·¯ç”±åè®®å¯ä»¥æŒ‰ç…§å·¥ä½œèŒƒå›´åˆ†ä¸º **IGP (Internal Gateway Protocol)** ä»¥åŠ **EGP (External Gateway Protocol)**ã€‚IGP å·¥ä½œåœ¨åŒä¸€ä¸ªASå†…ï¼Œä¸»è¦ç”¨æ¥å‘ç°å’Œè®¡ç®—è·¯ç”±ï¼Œä¸ºASå†…æä¾›è·¯ç”±ä¿¡æ¯çš„äº¤æ¢ï¼›è€Œ EGPå·¥ä½œåœ¨ AS ä¸ AS ä¹‹é—´ï¼Œåœ¨ AS é—´æä¾›æ— ç¯è·¯çš„è·¯ç”±ä¿¡æ¯äº¤æ¢ï¼Œ**BGP åˆ™æ˜¯ EGP çš„ä¸€ç§**



#### è‡ªæ²»ç³»ç»Ÿ

![image-20250327153920164](../markdown_img/image-20250327153920164.png)

è‡ªæ²»ç³»ç»Ÿï¼ˆASï¼‰ï¼šç”±åŒä¸€ä¸ªæŠ€æœ¯ç®¡ç†æœºæ„ç®¡ç†ï¼Œä½¿ç”¨ç»Ÿä¸€é€‰è·¯ç­–ç•¥çš„ä¸€äº›è·¯ç”±å™¨çš„é›†åˆ

è‡ªæ²»ç³»ç»Ÿå†…éƒ¨çš„è·¯ç”±åè®®ï¼šIGPï¼ˆé™æ€è·¯ç”±ï¼ŒOSPFï¼ŒISISï¼ŒRIP...ï¼‰

è‡ªæ²»ç³»ç»Ÿä¹‹é—´çš„è·¯ç”±åè®®ï¼šEGPï¼ˆBGPï¼‰



#### IGP ä¸ EGP

**IGP**

- è¿è¡ŒäºASå†…éƒ¨çš„è·¯ç”±åè®®ï¼Œä¸»è¦æœ‰RIPï¼ŒOSPFï¼Œ ISISç­‰
- IGPç€é‡äº**å¿«é€Ÿ**å‘ç°å’Œè®¡ç®—è·¯ç”±

**EGP**

- è¿è¡ŒäºASä¹‹é—´çš„è·¯ç”±åè®®ï¼Œç°é€šå¸¸æŒ‡BGP
- BGPç€é‡äº**æ§åˆ¶è·¯ç”±çš„ä¼ æ’­ **å’Œ **é€‰æ‹©æœ€ä¼˜çš„è·¯ç”±**ï¼ˆBGPçš„æœ€ä½³è·¯å¾„å¹¶ä¸ä»¥å¸¦å®½ä¸ºæœ€ä½³ï¼Œä¹Ÿä¸ä»¥è·³æ•°ä¸ºæœ€ä½³ï¼Œç®—æ³•å¤æ‚ï¼‰

```ABAP
GBPå‘å±•è·¯å¾„ï¼šEGP -> BGP/v1 -> BGP/v4
```



#### BGPç‰¹å¾

- BGPæ˜¯å¤–éƒ¨è·¯ç”±åè®®ï¼ˆ**ç”¨æ¥æ‰¿è½½å¤§å®¹é‡çš„è·¯ç”±æ¡ç›®**ï¼Œæ•°ä»¥æ•°åä¸‡è®¡çš„è·¯ç”±æ¯«æ— é—®é¢˜ï¼‰ï¼Œç”¨æ¥åœ¨ASä¹‹é—´ä¼ é€’è·¯ç”±ä¿¡æ¯
- æ˜¯ä¸€ç§å¢å¼ºçš„è·ç¦»çŸ¢é‡è·¯ç”±åè®®
  - å¯é çš„è·¯ç”±æ›´æ–°æœºåˆ¶
  - ä¸°å¯Œçš„Metricé‡åº¦æ–¹æ³•
  - ä»è®¾è®¡ä¸Šé¿å…äº†ç¯è·¯çš„å‘ç”Ÿ
- ä¸ºè·¯ç”±é™„å¸¦å±æ€§ä¿¡æ¯
- æ”¯æŒCIDRï¼ˆæ— ç±»åˆ«åŸŸé—´é€‰è·¯ï¼‰
- ä¸°å¯Œçš„è·¯ç”±è¿‡æ»¤å’Œè·¯ç”±ç­–ç•¥



#### ASå·

ASå·èŒƒå›´æ˜¯1~65535ï¼Œå…¶ä¸­

- 1 ~ 64512 æ˜¯å…¬æœ‰ASå·ï¼ˆå·²åˆ†é…å®Œï¼Œæ— å‰©ä½™ï¼‰ï¼Œéœ€è¦è¿è¥å•†æä¾›
- 64513 ~65535æ˜¯ç§æœ‰ASå·ï¼Œå¤§å®¶éƒ½èƒ½ç”¨ï¼Œç±»ä¼¼äº192.168...çš„å†…ç½‘Ip



### BGPå¯é çš„è·¯ç”±æ›´æ–°

- ä¼ è¾“åè®®ï¼šTCPï¼Œç«¯å£å·179ï¼ˆBGPåè®®çš„å¯é ï¼Œä½“ç°åœ¨ä½¿ç”¨TCPï¼‰ï¼ŒBGPæ˜¯åŸºäºTCPçš„åè®®
  - BGPéœ€è¦å…ˆæœ‰IGPä¿è¯ç«¯åˆ°ç«¯çš„å¯è¾¾æ€§ï¼Œåœ¨IGPçš„åŸºç¡€ä¸Šï¼Œæ‰èƒ½å®ç°å¤§å®¹é‡è·¯ç”±çš„ä¼ é€’
  - å³åªéœ€è¦ä¿è¯ä¸¤ä¸ªASä¹‹é—´çš„è¾¹ç•Œè·¯ç”±é—´çš„å¯è¾¾æ€§å³å¯ï¼ˆé€šå¸¸ç”¨é™æ€è·¯ç”±ä¿è¯ï¼‰ï¼ŒASå†…çš„è·¯ç”±æ— éœ€ä¿è¯
  - BGPæƒ³é€šï¼ŒIGPå…ˆé€š
- æ— éœ€å‘¨æœŸæ€§æ›´æ–°
- è·¯ç”±æ›´æ–°ï¼šåªå‘é€å¢é‡è·¯ç”±ï¼Œå³åªåšå¢é‡æ›´æ–°
- å‘¨æœŸæ€§å‘é€KeepalivedæŠ¥æ–‡ï¼ˆå¾ˆå°ï¼Œä¸åˆ°1Kï¼‰æ£€æµ‹TCPçš„è¿é€šæ€§
  - æ¯60sï¼Œå‘é€ä¸€ä¸ªKeepalivedæŠ¥æ–‡



#### BGPæŠ¥æ–‡ç§ç±»

BGPæŠ¥æ–‡æœ‰äº”ç§ç±»å‹ï¼š

- **Open**ï¼šè´Ÿè´£å’Œå¯¹ç­‰ä½“å»ºç«‹é‚»å±…å…³ç³»
- **Keepalive**ï¼šè¯¥æ¶ˆæ¯åœ¨å¯¹ç­‰ä½“ä¹‹é—´å‘¨æœŸæ€§åœ°å‘é€ï¼Œç”¨ä»¥ç»´æŠ¤è¿æ¥
- **Update**ï¼šè¯¥æ¶ˆæ¯è¢«ç”¨æ¥åœ¨BGPå¯¹ç­‰ä½“ä¹‹é—´ä¼ é€’è·¯ç”±ä¿¡æ¯
- **Notification**ï¼šå½“BGP Speakeræ£€æµ‹åˆ°é”™è¯¯çš„æ—¶å€™ï¼Œå°±å‘é€è¯¥æ¶ˆæ¯ç»™å¯¹ç­‰ä½“
- **Route-refresh**ï¼šç”¨æ¥é€šçŸ¥å¯¹ç­‰ä½“è‡ªå·±æ”¯æŒè·¯ç”±åˆ·æ–°èƒ½åŠ›



##### **BGPæŠ¥æ–‡**

![image-20250327165527701](../markdown_img/image-20250327165527701.png)



##### **OpenæŠ¥æ–‡**

![image-20250327165659260](../markdown_img/image-20250327165659260.png) 

- Version(1B)
  - ç°åœ¨åŸºæœ¬éƒ½æ˜¯BGP/v4ï¼Œå› æ­¤Versionè¿™é‡Œé€šå¸¸æ˜¯4
- My Autonomous Systemï¼ˆ2Bï¼‰
  - æˆ‘è‡ªå·±çš„ASå·
- Hold Time (ä¿å­˜æ—¶é—´)ï¼ˆ2Bï¼‰
- BGP Identifierï¼ˆ4Bï¼‰
- Opt Param Lenï¼ˆ1Bï¼‰
  - å¯é€‰å‚æ•°
- Optional Parametersï¼ˆvariableï¼‰
  - è¿™é‡Œä¼šæºå¸¦ä¸€äº›é¢å¤–çš„èƒ½åŠ›çš„åå•†



##### **Keepalive æŠ¥æ–‡**

![image-20250327170137460](../markdown_img/image-20250327170137460.png)

keepaliveæŠ¥æ–‡éå¸¸å°ï¼Œæˆ‘å‘é€ä¸€ä¸ªKeepaliveæŠ¥æ–‡ï¼Œç„¶åæ”¶åˆ°ä¸€ä¸ªackæŠ¥æ–‡ç¡®è®¤å³å¯ï¼Œåªè¦æŠ¥å¤´å°±å¤Ÿäº†



##### **Update æŠ¥æ–‡**

![image-20250327170412622](../markdown_img/image-20250327170412622.png)

updateæŠ¥æ–‡æ˜¯æœ€å¤§çš„ï¼Œå› ä¸ºæ¯ä¸€ä¸ªæŠ¥æ–‡è¦è£…åœ¨ä¸€ä¸ªupdateé‡Œé¢

- Withdrawn Routes Lengthï¼ˆ2Bï¼‰
  - è·¯ç”±é•¿åº¦
- Withdrawn Routesï¼ˆå¯å˜é•¿åº¦ï¼‰
  - è·¯ç”±æ¡ç›®
- Path Attribute Lengthï¼ˆ2Bï¼‰
  - å„ç§è·¯å¾„å±æ€§çš„é•¿åº¦
- Path Attributeï¼ˆå¯å˜é•¿åº¦ï¼‰
  - å„ç§è·¯å¾„å±æ€§
- Network Layer Reachability Informationï¼ˆå¯å˜é•¿åº¦ï¼‰
  - è·¯ç”±çš„æœ€ç»ˆå½¢æ€ï¼ˆåœ°å€ï¼‰



##### Notification æŠ¥æ–‡

![image-20250327170904903](../markdown_img/image-20250327170904903.png)

è°å‘ç°çš„é”™è¯¯ï¼Œè°å»å‘é€NotificationæŠ¥æ–‡



##### Route-refreshæŠ¥æ–‡

![image-20250327171036666](../markdown_img/image-20250327171036666.png)



#### BGPåè®®ä¸­æ¶ˆæ¯çš„åº”ç”¨

- é€šè¿‡TCPå»ºç«‹BGPè¿æ¥æ—¶ï¼Œå‘é€OPENæ¶ˆæ¯ï¼ˆTCPè¿æ¥å…ˆå»ºç«‹å¥½ï¼Œç„¶åå‘é€OPENæŠ¥æ–‡ï¼‰
- è¿æ¥å»ºç«‹åï¼Œå¦‚æœæœ‰è·¯ç”±éœ€è¦å‘é€æˆ–è·¯ç”±å˜åŒ–æ—¶ï¼Œå‘é€UPDATEæ¶ˆæ¯é€šå‘Šå¯¹ç«¯
- ç¨³å®šåå®šæ—¶å‘é€KEEPALIVEæ¶ˆæ¯ä»¥ä¿æŒBGPè¿æ¥çš„æœ‰æ•ˆæ€§
- å½“æœ¬åœ°BGPåœ¨è¿è¡Œä¸­å‘ç°é”™è¯¯æ—¶ï¼Œè¦å‘é€Notificationæ¶ˆæ¯é€šå‘ŠBGPå¯¹ç­‰ä½“
- ROUTE-REFRESHæ¶ˆæ¯ç”¨æ¥é€šçŸ¥å¯¹ç­‰ä½“è‡ªå·±æ”¯æŒè·¯ç”±åˆ·æ–°



### BGPè·¯ç”±ä¿¡æ¯å¤„ç†

#### BGPçŠ¶æ€æœº

![image-20250327171628874](../markdown_img/image-20250327171628874.png)

- BGPä¸€æ—¦åœ¨ä¸€ä¸ªè®¾å¤‡ä¸Šå¯åŠ¨ï¼Œé¦–å…ˆè¿›å…¥**IdleçŠ¶æ€**ï¼Œå³ç©ºé—²çŠ¶æ€
- å¼€å§‹å°è¯•å»ºç«‹ï¼Œè¿›å…¥**ConnectçŠ¶æ€**ï¼ˆå°è¯•å»ºç«‹TCPè¿æ¥ï¼‰
- å¦‚æœè¿æ¥çŠ¶æ€å¤±è´¥ï¼Œè¿›å…¥ **ActiveçŠ¶æ€**ï¼ˆç­‰å¾…å†æ¬¡è¿æ¥ï¼‰
- ç›´åˆ°TCPè¿æ¥çŠ¶æ€å»ºç«‹ï¼Œè¿›å…¥**Open-SentçŠ¶æ€**
- **ä¸Šè¿° Idle çŠ¶æ€ï¼ŒConnect çŠ¶æ€å’Œ Active çŠ¶æ€éƒ½æ˜¯åœ¨åš TCPï¼Œä» Open-sent å¼€å§‹æ‰æ˜¯åœ¨åšBGP**
- Openæ¶ˆæ¯æŠ¥æ–‡å‘å‡ºï¼Œç„¶åæ¥æ”¶åˆ°è¿”å›çš„æ­£ç¡®çš„OpenæŠ¥æ–‡åï¼Œè¿›å…¥**Open-confirmçŠ¶æ€**
- åœ¨è¿›å…¥Open-confirmçŠ¶æ€åï¼Œåˆæ¥å—åˆ°KeepaliveæŠ¥æ–‡ï¼Œè¯´æ˜è¿™ä¸ªé‚»å±…ä¸€ç›´æ²¡æœ‰æ–­ï¼Œå› æ­¤è¿›å…¥**ESTABLISHçŠ¶æ€**
- ESTABLISHçŠ¶æ€è¯´æ˜BGPå»ºç«‹å®Œæˆï¼Œå¹¶ä¸æ–­åœ°å‘¨æœŸæ€§å‘é€KeepaliveæŠ¥æ–‡
- åœ¨åæœŸä»»ä½•ä¸€ä¸ªBGPçš„çŠ¶æ€ä¸­ï¼Œä¸€ä½†æ”¶åˆ°NotificationæŠ¥æ–‡ï¼Œå³é”™è¯¯é€šå‘Šï¼Œåˆ™ç›´æ¥æ–­æ‰TCPè¿æ¥ï¼Œè¿›å…¥IdleçŠ¶æ€



#### BGPçš„æ•°æ®åº“

åœ¨é‚»å±…å»ºç«‹å®Œåï¼ŒBGPè¦ç»´æŠ¤è‡ªå·±çš„æ•°æ®åº“ï¼ŒBGPçš„æ•°æ®åº“æœ‰

- **IPè·¯ç”±è¡¨ï¼ˆIP-RIBï¼‰**
  - å…¨å±€è·¯ç”±ä¿¡æ¯åº“ï¼ŒåŒ…æ‹¬æ‰€æœ‰IPè·¯ç”±ä¿¡æ¯
- **BGPè·¯ç”±è¡¨ï¼ˆLoc-RIBï¼‰**
  - BGPè·¯ç”±ä¿¡æ¯åº“ï¼ŒåŒ…æ‹¬æœ¬åœ°BGP Speakeré€‰æ‹©çš„è·¯ç”±ä¿¡æ¯
  - è¿™é‡ŒåŒ…å«æ‰€æœ‰è·¯å¾„ä¿¡æ¯ï¼Œä¸æ­¢æ˜¯æœ€ä½³è·¯å¾„ï¼Œè€Œæœ€ä½³è·¯å¾„ä¿¡æ¯å¯èƒ½ä¼šè®°å½•åˆ°IPè·¯ç”±è¡¨ä¸­
  - éå¸¸å¤§
- **é‚»å±…è¡¨**
  - å¯¹ç­‰ä½“é‚»å±…æ¸…å•åˆ—è¡¨
- **Adj-RIB-In**
  - å¯¹ç­‰ä½“å®£å‘Šç»™æœ¬åœ°Speakerçš„æœªå¤„ç†çš„è·¯ç”±ä¿¡æ¯åº“
  - é€šå¸¸æ˜¯æˆ‘ä»é‚»å±…é‚£é‡Œæ”¶åˆ°çš„æœªå¤„ç†çš„è¡¨é¡¹ï¼Œè¿™é‡Œçš„è¡¨é¡¹æ˜¯å¤„ç†ç»™BGPï¼Œå¤„ç†åï¼Œä¼šå°†å¤„ç†åçš„è¡¨é¡¹åˆ æ‰
- **Adj-RIB-Out**
  - æœ¬åœ°Speakerå®£å‘Šç»™æŒ‡å®šå¯¹ç­‰ä½“çš„è·¯ç”±ä¿¡æ¯åº“
  - å³æˆ‘è¦æŠŠé‚£äº›è·¯ç”±å‘é€ç»™åˆ«äºº



#### BGPè·¯ç”±ä¿¡æ¯å¤„ç†

![image-20250327173658157](../markdown_img/image-20250327173658157.png)

```ABAP
BGPçš„å¯¹ç­‰ä½“ == BGPçš„é‚»å±…ï¼Œæ˜¯ä¸€ä¸ªæ¦‚å¿µ
BGP Speaker æŒ‡çš„æ˜¯è¿è¡Œäº†BGPçš„ç½‘ç»œè®¾å¤‡
```

- ä»é‚»å±…é‚£é‡Œæ”¶åˆ°çš„è·¯ç”±ä¿¡æ¯ï¼Œé¦–å…ˆæ”¾åˆ° `Adj-RIB-IN` ä¸­
- ç„¶åé€šè¿‡è¾“å…¥ç­–ç•¥å¼•æ“ï¼Œå°†éœ€è¦çš„è·¯ç”±ä¿¡æ¯æ”¾å…¥`Loc-RIBï¼Œå³BGPè¡¨`ä¸­
- å¤„ç†å®Œçš„ä¿¡æ¯ï¼Œåœ¨ `Adj-RIB-IN` ä¸­æ¸…é™¤
- `BGPè¡¨ä¸­` é€‰å‡ºæœ€ä¼˜è·¯å¾„ï¼Œç„¶åæ”¾å…¥ `IP-RIBï¼Œå³IPè¡¨ä¸­` ä¾›æˆ‘çš„è·¯ç”±å™¨è¿›è¡Œä½¿ç”¨
- åŒæ—¶å°†é€‰å‡ºçš„æœ€ä¼˜è·¯å¾„ï¼Œé€šè¿‡è¾“å‡ºç­–ç•¥å¼•æ“å‘ç»™åˆ«äººï¼Œå‘ç»™åˆ«äººçš„è¡¨ä¸º`Adj-RIB-Out`ï¼Œå‘å‡ºçš„ä¸€å®šæ˜¯æœ€ä¼˜çš„è·¯ç”±
- BGP åªå®£å‘Šæœ€ä¼˜è·¯å¾„



### BGPçš„å·¥ä½œåŸç†

#### BGPé‚»å±…å…³ç³»

BGPæ˜¯åŸºäºTCPè¿æ¥çš„é‚»å±…å…³ç³»ï¼Œè€ŒTCPåˆæ˜¯åŸºäºIPå¯è¾¾æ€§å®ç°çš„ï¼Œå› æ­¤

- BGPé‚»å±…å…³ç³»å»ºç«‹åœ¨TPCè¿æ¥çš„åŸºç¡€ä¹‹ä¸Š
- å¯ä»¥é€šè¿‡IGPæˆ–é™æ€è·¯ç”±æ¥æä¾›TCPè¿æ¥çš„IPå¯è¾¾æ€§



**BGPä¸¤ç§é‚»å±…å…³ç³» â€” IBGP å’Œ EBGP**

![image-20250327175014500](../markdown_img/image-20250327175014500.png)

å¦‚æœä¸¤ä¸ªé‚»å±…ï¼Œæˆ–è€…ä¸¤ä¸ªè®¾å¤‡éƒ½åœ¨åŒä¸€ä¸ªASï¼Œé‚£ä¹ˆå°±å«åš**IBGP**

å¦‚æœä¸¤ä¸ªè®¾åˆ«åœ¨ä¸åŒçš„ASï¼Œé‚£ä¹ˆå°±å«åš**EBGP**é‚»å±…å…³ç³»

```ABAP
é—®é¢˜ï¼šä¸ºä»€ä¹ˆåœ¨åŒä¸€ä¸ªASå†…ï¼Œè¦å»ºç«‹IBGPé‚»å±…å…³ç³»
```

- IBGPçš„ç¬¬ä¸€ä¸ªä½œç”¨ï¼šä¼ é€’å¤§å®¹é‡çš„è·¯ç”±ä¿¡æ¯
- IBGPçš„ç¬¬äºŒä¸ªä½œç”¨ï¼šå½“éœ€è¦è·¨è¶Šå¤šä¸ªASä¼ é€’è·¯ç”±ä¿¡æ¯æ—¶ï¼ŒIBGPå¯ä»¥å°†BGPåè®®çš„å±æ€§ä¼ é€’è¿‡å»ï¼Œä¹Ÿå¯ä»¥æ›´é«˜çš„é˜²æ­¢ç¯è·¯ï¼Œå±æ€§çš„ä¸¢å¤±å¯¹ç¯è·¯çš„ç”Ÿæˆå½±å“å¾ˆå¤§ã€‚
- IGPä¸ºIBGPæä¾›TCP/IPçš„å¯è¾¾æ€§









#### BGPé€šå‘ŠåŸåˆ™

#### BGPè·¯ç”±é€šå‘Š



## Git ç›¸å…³ç”¨æ³•è¡¥å……

### ç»•è¿‡ Git çš„ SSL è¯ä¹¦éªŒè¯æ–¹æ³•



#### ä¸´æ—¶ç¦ç”¨ SSL éªŒè¯ï¼ˆä»…å½“å‰å‘½ä»¤ï¼‰

```bash
# è¿™ä¸ªæ–¹æ³• ä»…å¯¹å½“å‰å‘½ä»¤ç”Ÿæ•ˆï¼Œä¸ä¼šå½±å“å…¶ä»– Git æ“ä½œ
GIT_SSL_NO_VERIFY=true git clone http://gitlab.mygitlab.mystical.org/devops/meta.git
```



#### å…¨å±€ç¦ç”¨ Git SSL è¯ä¹¦éªŒè¯

```bash
# è¿™ä¼šå¯¹ æ‰€æœ‰ Git æ“ä½œ å…³é—­ SSL éªŒè¯ï¼Œä½†å¹¶ä¸æ¨èï¼Œå› ä¸ºå¯èƒ½ä¼šè®©ä½ å¯¹ MITMï¼ˆä¸­é—´äººæ”»å‡»ï¼‰æ›´è„†å¼±
git config --global http.sslVerify false
```



#### ä»…å¯¹ç‰¹å®š GitLab åŸŸåç¦ç”¨ SSL éªŒè¯

```bash
# åªæƒ³å¯¹ gitlab.mygitlab.mystical.org ç¦ç”¨ SSL éªŒè¯
git config --global http."http://gitlab.mygitlab.mystical.org".sslVerify false
```



#### ä¸º GitLab æ·»åŠ è‡ªç­¾è¯ä¹¦

å¦‚æœä½ çš„ GitLab ä½¿ç”¨äº†è‡ªç­¾åè¯ä¹¦ï¼Œæ¨èæŠŠå®ƒçš„ CA è¯ä¹¦æ·»åŠ åˆ°ç³»ç»Ÿæˆ– Git çš„ CA è¯ä¹¦åˆ—è¡¨ï¼Œè€Œä¸æ˜¯ç¦ç”¨ SSL éªŒè¯

**è·å– GitLab è¯ä¹¦**

```bash
openssl s_client -showcerts -connect gitlab.mygitlab.mystical.org:443 < /dev/null | openssl x509 -outform PEM > gitlab-cert.pem
```

**æŠŠè¯ä¹¦åŠ å…¥ Git ä¿¡ä»»**

```bash
git config --global http.sslCAInfo ~/gitlab-cert.pem
```



### è§£å†³ GitHub ä¸Šä¼ å¤§æ–‡ä»¶é—®é¢˜

GItHub ä¸å…è®¸å•ä¸ªæ–‡ä»¶è¶…è¿‡ 100MB

#### æ–¹æ³•ï¼šä½¿ç”¨ Git LFS (æ¨è)

GitHub æä¾›äº† **Git LFSï¼ˆLarge File Storageï¼‰**ï¼Œä¸“é—¨ç”¨äºç®¡ç†è¶…è¿‡ 100MB çš„å¤§æ–‡ä»¶ã€‚

**1ï¸âƒ£ å®‰è£… Git LFS**

å¦‚æœä½ å°šæœªå®‰è£… Git LFSï¼Œå¯ä»¥è¿è¡Œ

```bash
git lfs install
```

**2ï¸âƒ£ è®© Git è¿½è¸ªå¤§æ–‡ä»¶**

```bash
git lfs track "*.pdf"
```

**3ï¸âƒ£ é‡æ–°æ·»åŠ å¹¶æäº¤**

```bash
git add .gitattributes
git add "AI/NVIDIA GPU æ¦‚è®º.pdf"
git commit -m "Track large PDF file with Git LFS"
git push origin master
```

è¿™æ · GitHub å°±ä¸ä¼šå› ä¸ºæ–‡ä»¶å¤§å°æ‹’ç»ä½ çš„ push äº†ã€‚





## Kubernetes GPU é›†ç¾¤éƒ¨ç½²

### **æœ€å°éƒ¨ç½²æ–¹æ¡ˆ**

| è§’è‰²                      | æœºå™¨æ•°é‡ | è§„æ ¼å»ºè®®                                       | è¯´æ˜                                |
| ------------------------- | -------- | ---------------------------------------------- | ----------------------------------- |
| **Master èŠ‚ç‚¹ï¼ˆæ§åˆ¶é¢ï¼‰** | 1 å°     | `ecs.c6.large`ï¼ˆ2 vCPU 4 GiB RAMï¼‰             | è¿è¡Œ K8s æ§åˆ¶é¢ï¼Œä¸éœ€è¦ GPU         |
| **GPU Worker èŠ‚ç‚¹**       | 2 å°     | `ecs.sgn7i-vws-m2s.xlarge`ï¼ˆ4 vCPU 8 GiB RAMï¼‰ | è¿è¡Œ AI è®¡ç®—ä»»åŠ¡ï¼Œæ”¯æŒ K8s GPU è°ƒåº¦ |

------



### **æ›´æ¨èçš„ç”Ÿäº§æ¨¡æ‹Ÿæ–¹æ¡ˆ**

å¦‚æœä½ æƒ³è¦ **æ›´æ¥è¿‘ç”Ÿäº§ç¯å¢ƒ**ï¼Œå»ºè®®ï¼š

- é€‰æ‹© **ç‹¬å å‹ GPU å®ä¾‹**ï¼Œå¦‚ `ecs.gn6e-c12g1.2xlarge`ï¼ˆTesla T4 GPUï¼‰
- å¢åŠ  **å¤š GPU Worker èŠ‚ç‚¹**ï¼Œæ¨¡æ‹Ÿå®é™… K8s GPU è´Ÿè½½å‡è¡¡è°ƒåº¦
- ä½¿ç”¨ **é˜¿é‡Œäº‘ ACKï¼ˆæ‰˜ç®¡ K8sï¼‰**ï¼Œç®€åŒ–ç®¡ç†





## GitLab CPUå’Œå†…å­˜ä½¿ç”¨ç‡å¾ˆé«˜ï¼Œå¦‚ä½•è§£å†³

### å¿«é€Ÿè¯Šæ–­ GitLab èµ„æºå ç”¨



**ä¸»è¦æ£€æŸ¥4ä¸ªç»„ä»¶**

- **WebServer: Puma**
- **Sidekiq**
- **PostgreSQL**
- **Redis**



å…ˆé€šè¿‡ä»¥ä¸‹å‘½ä»¤ **æ£€æŸ¥ CPU å’Œå†…å­˜å ç”¨æƒ…å†µ**ï¼š

#### **1ï¸âƒ£ æ£€æŸ¥ GitLab ä¸»è¦è¿›ç¨‹**

```bash
ps aux --sort=-%mem | grep gitlab
```

- **æŸ¥æ‰¾ CPU å’Œå†…å­˜å ç”¨æœ€é«˜çš„è¿›ç¨‹**ï¼ˆå¦‚ `puma`, `postgres`, `sidekiq`ï¼‰ã€‚
- ç¡®ä¿ GitLab æ²¡æœ‰åƒµå°¸è¿›ç¨‹ã€‚

#### **2ï¸âƒ£ ç›‘æ§ GitLab è¿›ç¨‹è´Ÿè½½**

```bash
top -o %CPU
```

- **æŸ¥çœ‹ CPU å¯†é›†çš„è¿›ç¨‹**ï¼ˆç‰¹åˆ«æ˜¯ `puma`, `sidekiq`ï¼‰ã€‚
- **è§‚å¯Ÿ PostgreSQL è´Ÿè½½**ï¼ˆGitLab å†…ç½®æ•°æ®åº“ï¼Œå®¹æ˜“å¯¼è‡´é«˜è´Ÿè½½ï¼‰ã€‚

#### **3ï¸âƒ£ ç›‘æ§ Sidekiq é˜Ÿåˆ—ä»»åŠ¡ï¼ˆæ˜¯å¦ä»»åŠ¡å †ç§¯ï¼Ÿï¼‰**

```bash
gitlab-rake gitlab:sidekiq:queue
```

- å¦‚æœ Sidekiq ä»»åŠ¡ç§¯å‹ï¼ˆé˜Ÿåˆ—è¿‡é•¿ï¼‰ï¼Œå¯èƒ½å¯¼è‡´ GitLab å˜æ…¢ã€‚

#### **4ï¸âƒ£ æ£€æŸ¥ PostgreSQL æ•°æ®åº“æŸ¥è¯¢ï¼ˆå“ªäº› SQL è´Ÿè½½é«˜ï¼Ÿï¼‰**

```bash
gitlab-psql -d gitlabhq_production -c "SELECT pid, age(clock_timestamp(), query_start), usename, query FROM pg_stat_activity WHERE state = 'active' ORDER BY query_start;"
```

- æ‰¾åˆ°æ‰§è¡Œæ—¶é—´è¿‡é•¿çš„ SQL æŸ¥è¯¢ï¼Œå¯èƒ½å½±å“ GitLab æ€§èƒ½ã€‚



### GitLab èµ„æºä¼˜åŒ–æ–¹æ¡ˆ

#### æ–¹æ¡ˆ 1ï¼šä¼˜åŒ– Pumaï¼ˆWeb æœåŠ¡å™¨ï¼‰

GitLab é»˜è®¤ä½¿ç”¨ `puma` ä½œä¸º Web æœåŠ¡å™¨ï¼Œå®ƒå¯èƒ½å ç”¨å¤§é‡ CPU èµ„æºã€‚

**âœ… é™ä½ Puma è¿›ç¨‹æ•°**

ç¼–è¾‘ `/etc/gitlab/gitlab.rb`ï¼š

```bash
puma['worker_processes'] = 2   # é»˜è®¤ 2ï¼Œé€‚å½“å‡å°‘
puma['worker_timeout'] = 30    # é»˜è®¤ 60sï¼Œå¯å‡å°‘
```

ç„¶å **åº”ç”¨é…ç½®**ï¼š

```bash
gitlab-ctl reconfigure
gitlab-ctl restart puma
```

------

#### **æ–¹æ¡ˆ 2ï¼šä¼˜åŒ– Sidekiqï¼ˆåå°ä»»åŠ¡é˜Ÿåˆ—ï¼‰**

**Sidekiq** è´Ÿè´£ GitLab çš„å¼‚æ­¥ä»»åŠ¡ï¼ˆå¦‚ CI/CD ä»»åŠ¡ã€é‚®ä»¶é€šçŸ¥ç­‰ï¼‰ï¼Œå®¹æ˜“å¯¼è‡´é«˜ CPU/å†…å­˜å ç”¨ã€‚

**âœ… é™ä½ Sidekiq è¿›ç¨‹æ•°**

ç¼–è¾‘ `/etc/gitlab/gitlab.rb`ï¼š

```bash
sidekiq['concurrency'] = 10  # é»˜è®¤ 25ï¼Œå¯å‡å°‘
```

ç„¶å **åº”ç”¨é…ç½®**ï¼š

```
bashCopyEditgitlab-ctl reconfigure
gitlab-ctl restart sidekiq
```

**âœ… æ¸…ç†ç§¯å‹ä»»åŠ¡**

å¦‚æœ Sidekiq é˜Ÿåˆ—è¿‡é•¿ï¼š

```bash
gitlab-rake gitlab:sidekiq:queue:clear
```

------

#### **æ–¹æ¡ˆ 3ï¼šä¼˜åŒ– PostgreSQLï¼ˆæ•°æ®åº“æ€§èƒ½ï¼‰**

GitLab çš„ PostgreSQL é»˜è®¤é…ç½®é€‚ç”¨äºå°å‹ç¯å¢ƒï¼Œ**å¤§è§„æ¨¡ GitLab éœ€è¦ä¼˜åŒ–æ•°æ®åº“å‚æ•°**ã€‚

**âœ… è°ƒæ•´ PostgreSQL è¿æ¥æ•°**

ç¼–è¾‘ `/var/opt/gitlab/postgresql/data/postgresql.conf`ï¼š

```bash
max_connections = 100        # é»˜è®¤ 200ï¼Œå‡å°‘æ•°æ®åº“å‹åŠ›
shared_buffers = 2GB         # è°ƒæ•´ä¸ºæ€»å†…å­˜çš„ 25%
work_mem = 64MB              # é™åˆ¶æ¯ä¸ªæŸ¥è¯¢ä½¿ç”¨çš„å†…å­˜
maintenance_work_mem = 512MB # é™åˆ¶ VACUUM æ“ä½œçš„å†…å­˜
```

ç„¶å **é‡å¯æ•°æ®åº“**ï¼š

```bash
gitlab-ctl restart postgresql
```

------

#### **æ–¹æ¡ˆ 4ï¼šä¼˜åŒ– GitLab æ—¥å¿—**

**âœ… æ¸…ç† GitLab æ—¥å¿—**

```bash
gitlab-rake gitlab:cleanup:logs
```

**âœ… å…³é—­ Debug æ—¥å¿—**

ç¼–è¾‘ `/etc/gitlab/gitlab.rb`ï¼š

```bash
gitlab_rails['log_level'] = "info"  # é»˜è®¤ "debug"ï¼Œå‡å°‘æ—¥å¿—é‡
```

ç„¶å **åº”ç”¨é…ç½®**ï¼š

```bash
gitlab-ctl reconfigure
gitlab-ctl restart
```

------

#### **æ–¹æ¡ˆ 5ï¼šä¼˜åŒ– GitLab ç¼“å­˜**

GitLab é»˜è®¤ä½¿ç”¨ **Redis ä½œä¸ºç¼“å­˜**ï¼Œä½†é»˜è®¤ Redis å¯èƒ½å ç”¨è¿‡å¤šå†…å­˜ã€‚

**âœ… é™åˆ¶ Redis å†…å­˜**

ç¼–è¾‘ `/etc/gitlab/gitlab.rb`ï¼š

```bash
redis['maxmemory'] = "512MB"
redis['maxmemory_policy'] = "allkeys-lru"
```

ç„¶å **åº”ç”¨é…ç½®**ï¼š

```bash
gitlab-ctl reconfigure
gitlab-ctl restart redis
```

------

#### **æ–¹æ¡ˆ 6ï¼šå…³é—­ä¸å¿…è¦çš„ GitLab ç»„ä»¶**

GitLab æœ‰ä¸€äº› **é»˜è®¤å¯ç”¨ä½†å¯èƒ½ä¸éœ€è¦çš„ç»„ä»¶**ï¼Œå¯ä»¥ç¦ç”¨å®ƒä»¬æ¥èŠ‚çœèµ„æºã€‚

**âœ… ç¦ç”¨ä¸ä½¿ç”¨çš„åŠŸèƒ½**

ç¼–è¾‘ `/etc/gitlab/gitlab.rb`ï¼š

```bash
gitlab_rails['gitlab_default_projects_features_issues'] = false
gitlab_rails['gitlab_default_projects_features_wiki'] = false
gitlab_rails['gitlab_default_projects_features_snippets'] = false
```

ç„¶å **åº”ç”¨é…ç½®**ï¼š

```bash
gitlab-ctl reconfigure
gitlab-ctl restart
```

------



### **è¿›é˜¶æ–¹æ¡ˆ**ï¼ˆæ¨èï¼‰

#### **æ–¹æ¡ˆ 7ï¼šä½¿ç”¨å¤–éƒ¨æ•°æ®åº“**

å¦‚æœ GitLab **PostgreSQL å‹åŠ›è¿‡å¤§**ï¼Œå¯ä»¥ä½¿ç”¨ **ç‹¬ç«‹æ•°æ®åº“æœåŠ¡å™¨**ï¼ˆå¦‚ AWS RDS æˆ–ç‹¬ç«‹ç‰©ç†æœºï¼‰ã€‚

```bash
gitlab_rails['db_adapter'] = 'postgresql'
gitlab_rails['db_host'] = 'db.example.com'
gitlab_rails['db_port'] = 5432
gitlab_rails['db_username'] = 'gitlab'
gitlab_rails['db_password'] = 'yourpassword'
```

------

#### **æ–¹æ¡ˆ 8ï¼šä½¿ç”¨å¤–éƒ¨å¯¹è±¡å­˜å‚¨**

GitLab é»˜è®¤ä½¿ç”¨æœ¬åœ°å­˜å‚¨æ¥ç®¡ç† **LFSï¼ˆå¤§æ–‡ä»¶å­˜å‚¨ï¼‰ã€CI/CD äº§ç‰©**ï¼Œå¯æ”¹ä¸º S3 å…¼å®¹å¯¹è±¡å­˜å‚¨ï¼š

```
bashCopyEditgitlab_rails['object_store']['enabled'] = true
gitlab_rails['object_store']['connection'] = {
  'provider' => 'AWS',
  'region' => 'us-east-1',
  'aws_access_key_id' => 'your-access-key',
  'aws_secret_access_key' => 'your-secret-key',
  'endpoint' => 'https://s3.example.com'
}
```

------

### **ç›‘æ§ GitLab**

ä¼˜åŒ–åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ **ç›‘æ§ GitLab èµ„æºä½¿ç”¨æƒ…å†µ**ï¼š

**âœ… 1. GitLab è‡ªå¸¦ç›‘æ§**

```bash
gitlab-ctl prometheus
```

ç„¶åè®¿é—® `http://gitlab-server:9090` æŸ¥çœ‹ç›‘æ§æŒ‡æ ‡ã€‚

**âœ… 2. é€šè¿‡ `systemd` ç›‘æ§æœåŠ¡çŠ¶æ€**

```
systemctl status gitlab-runsvdir
```

**âœ… 3. é€šè¿‡ `htop` ç›‘æ§**

```bash
htop
```

------

### **æ€»ç»“**

| **ä¼˜åŒ–æ–¹å‘**          | **æ–¹æ³•**                                    |
| --------------------- | ------------------------------------------- |
| **é™ä½ CPU/å†…å­˜å ç”¨** | **å‡å°‘ Puma è¿›ç¨‹**ã€ä¼˜åŒ– Sidekiq å¹¶æ¸…ç†ä»»åŠ¡ |
| **ä¼˜åŒ–æ•°æ®åº“**        | **è°ƒæ•´ PostgreSQL è¿æ¥æ•°ã€åˆ†ç¦»æ•°æ®åº“**      |
| **ä¼˜åŒ–ç¼“å­˜**          | **å‡å°‘ Redis å†…å­˜å ç”¨**                     |
| **æ¸…ç†æ—¥å¿—**          | **å…³é—­ Debug æ—¥å¿—ã€å®šæœŸæ¸…ç†**               |
| **ä½¿ç”¨å¤–éƒ¨å­˜å‚¨**      | **ç‹¬ç«‹ PostgreSQLã€å¯¹è±¡å­˜å‚¨ï¼ˆS3ï¼‰**         |
| **ç›‘æ§ GitLab èµ„æº**  | **Prometheus + htop + systemctl**           |

ğŸ’¡ **å¦‚æœ GitLab è¿è¡Œè§„æ¨¡è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨** **å¤–éƒ¨ PostgreSQL + å¯¹è±¡å­˜å‚¨ï¼ˆS3ï¼‰+ ç‹¬ç«‹ Redis** æ¥ä¼˜åŒ–æ€§èƒ½ã€‚ğŸš€
ä½ å½“å‰ GitLab çš„ **CPU ä¸»è¦å ç”¨åœ¨å“ªä¸ªè¿›ç¨‹ä¸Šï¼Ÿï¼ˆPuma, Sidekiq, PostgreSQLï¼‰** æˆ‘å¯ä»¥æä¾›æ›´å…·ä½“çš„ä¼˜åŒ–å»ºè®®ï¼ğŸ’ª





## å­˜æ”¾ä¸šåŠ¡çš„æ•°æ®åº“æ˜¯å¦èƒ½æ”¾åœ¨K8Sä¸Š

å…·ä½“æ˜¯å¦æŠŠæ•°æ®åº“éƒ¨ç½²åœ¨ Kubernetesï¼ˆK8sï¼‰ä¸Šï¼Œå–å†³äº **ä¸šåŠ¡éœ€æ±‚ã€æ€§èƒ½è¦æ±‚ã€å­˜å‚¨æ¶æ„**ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œ**æ•°æ®åº“çš„é«˜æ€§èƒ½å’Œç¨³å®šæ€§æ˜¯æ ¸å¿ƒå…³æ³¨ç‚¹**ï¼Œè€Œ K8s çš„å­˜å‚¨è™šæ‹ŸåŒ–ç¡®å®å¯èƒ½å¯¼è‡´ **æ€§èƒ½æŸè€—**ã€‚ä½† Kubernetes ä¹Ÿæœ‰æˆç†Ÿçš„æ–¹æ¡ˆæ¥ä¼˜åŒ–æ•°æ®åº“éƒ¨ç½²



### æ•°æ®åº“å¯ä»¥æ”¾åœ¨ K8s ä¸Šå—ï¼Ÿ

âœ… **å¯ä»¥ï¼Œä½†æœ‰å‰æ**ï¼š

- **å¯¹æ€§èƒ½è¦æ±‚ä¸é«˜** çš„å°å‹ä¸šåŠ¡æ•°æ®åº“å¯ä»¥è¿è¡Œåœ¨ K8sï¼ˆå¦‚è½»é‡çº§ MySQLã€PostgreSQLï¼‰ã€‚
- **é€‚ç”¨äºäº‘åŸç”Ÿæ•°æ®åº“ï¼ˆå¦‚ Vitess, TiDB, CockroachDBï¼‰**ï¼Œè¿™äº›æ•°æ®åº“å¤©ç”Ÿæ”¯æŒ Kubernetes è¿è¡Œã€‚
- **é€‚ç”¨äºé«˜å¯ç”¨åœºæ™¯ï¼ˆå¦‚ Operator ç®¡ç†çš„ MySQLã€PostgreSQL é›†ç¾¤ï¼‰**ã€‚

ğŸš¨ **ä½†è¦æ…é‡è€ƒè™‘ä»¥ä¸‹æƒ…å†µ**ï¼š

- ä¼ ç»Ÿå•ä½“æ•°æ®åº“ï¼ˆå¦‚å•æœº MySQL / PostgreSQL / Oracleï¼‰å¯¹ **ä½å»¶è¿Ÿã€é«˜åå** è¦æ±‚å¾ˆé«˜ï¼Œå­˜å‚¨è™šæ‹ŸåŒ–å¯èƒ½å½±å“æ€§èƒ½ã€‚
- **K8s å…±äº«å­˜å‚¨ï¼ˆå¦‚ Cephã€NFSï¼‰å¯èƒ½å¯¼è‡´ IOPS ä¸‹é™ï¼Œå½±å“æ•°æ®åº“å†™å…¥æ€§èƒ½ã€‚**
- **Pod è°ƒåº¦ã€é‡å¯å¯èƒ½å¯¼è‡´æ•°æ®æ¢å¤æ—¶é—´è¿‡é•¿**ï¼Œä¸é€‚åˆä¸šåŠ¡é«˜å¯ç”¨åœºæ™¯ã€‚



### **ä¸»è¦æ€§èƒ½é—®é¢˜åˆ†æ**

K8s æœ¬èº«ä¸æä¾›å­˜å‚¨ï¼Œè€Œæ˜¯ä¾èµ– **CSIï¼ˆContainer Storage Interfaceï¼‰**ï¼Œå¸¸è§çš„å­˜å‚¨æ–¹å¼åŒ…æ‹¬ï¼š

| **å­˜å‚¨æ–¹æ¡ˆ**                            | **IOPS/æ€§èƒ½æŸè€—**      | **é€‚ç”¨åœºæ™¯**                                                 |
| --------------------------------------- | ---------------------- | ------------------------------------------------------------ |
| **æœ¬åœ° SSD ç›´æŒ‚ï¼ˆhostPath, Local PVï¼‰** | **æŸè€—ä½ï¼ˆæ¥è¿‘è£¸æœºï¼‰** | é«˜æ€§èƒ½æ•°æ®åº“ï¼ˆå¦‚ OLTPï¼‰è§£å†³æ–¹æ¡ˆï¼šå¦‚ä½•ä¼˜åŒ– K8s ä¸Šçš„æ•°æ®åº“å­˜å‚¨ |
| **Ceph / Rook / GlusterFS**             | **æŸè€— 10%~30%**       | é€‚åˆåˆ†å¸ƒå¼å­˜å‚¨ï¼ˆå¤§æ•°æ®ã€å¯¹è±¡å­˜å‚¨ï¼‰                           |
| **NFS / EFS / SMBï¼ˆè¿œç¨‹å­˜å‚¨ï¼‰**         | **æŸè€— 30%+ï¼Œé«˜å»¶è¿Ÿ**  | ä½æ€§èƒ½è¦æ±‚ï¼Œå¦‚æ—¥å¿—ã€å¤‡ä»½                                     |
| **iSCSI / FCï¼ˆSAN å­˜å‚¨ï¼‰**              | **æŸè€— 5~15%**         | é€‚åˆä¼ ç»Ÿä¼ä¸šæ•°æ®åº“                                           |

å¦‚æœé‡‡ç”¨ K8s æä¾›çš„ **Persistent Volumeï¼ˆPVï¼‰+ StorageClass** è¿›è¡Œå­˜å‚¨è™šæ‹ŸåŒ–ï¼Œ**IOPSï¼ˆæ¯ç§’è¾“å…¥è¾“å‡ºæ“ä½œï¼‰** å¯èƒ½å¤§å¹…ä¸‹é™ï¼Œå½±å“æ•°æ®åº“çš„ **TPSï¼ˆååé‡ï¼‰** å’Œ **æŸ¥è¯¢å»¶è¿Ÿ**ã€‚



### è§£å†³æ–¹æ¡ˆï¼šå¦‚ä½•ä¼˜åŒ– K8s ä¸Šçš„æ•°æ®åº“å­˜å‚¨

#### **æ–¹æ¡ˆ 1ï¼šæœ¬åœ° SSD ç›´æŒ‚ï¼ˆæœ€ä½³æ€§èƒ½ï¼‰**

âœ… **é€‚ç”¨äºé«˜æ€§èƒ½æ•°æ®åº“ï¼ˆå¦‚ MySQL, PostgreSQL, MongoDBï¼‰**

- ç›´æ¥ä½¿ç”¨ **ç‰©ç†æœºä¸Šçš„ NVMe SSDï¼ˆæœ¬åœ°æŒä¹…åŒ–å­˜å‚¨ï¼‰**ï¼Œé¿å…å­˜å‚¨è™šæ‹ŸåŒ–æŸè€—ã€‚

- **ä½¿ç”¨ `hostPath` æˆ– `Local Persistent Volume`ï¼ˆLocal PVï¼‰ï¼Œç»‘å®šæ•°æ®åº“åˆ°å›ºå®šèŠ‚ç‚¹**ï¼Œä¿è¯é«˜ IO è®¿é—®ã€‚

- ç¤ºä¾‹ï¼šLocal PV æ–¹å¼

  ```yaml
  apiVersion: v1
  kind: PersistentVolume
  metadata:
    name: local-pv-db
  spec:
    capacity:
      storage: 500Gi
    volumeMode: Filesystem
    accessModes:
      - ReadWriteOnce
    persistentVolumeReclaimPolicy: Retain
    storageClassName: local-storage
    local:
      path: /mnt/disks/local-db
    nodeAffinity:
      required:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/hostname
            operator: In
            values:
            - db-node-1
  ```

- é—®é¢˜ï¼š

  - Pod åªèƒ½è¿è¡Œåœ¨å›ºå®šçš„ **æ•°æ®åº“ä¸“ç”¨èŠ‚ç‚¹**ï¼Œç¼ºä¹è°ƒåº¦çµæ´»æ€§ã€‚
  - ä¸èƒ½è·¨èŠ‚ç‚¹é«˜å¯ç”¨ï¼ˆé€‚åˆ **å•æœºæ•°æ®åº“**ï¼Œä½†ä¸é€‚åˆåˆ†å¸ƒå¼æ•°æ®åº“ï¼‰ã€‚

------

#### **æ–¹æ¡ˆ 2ï¼šä¸“ç”¨ç‰©ç†æœºå­˜å‚¨ + K8s è®¿é—®ï¼ˆæ¨èï¼‰**

âœ… **é€‚ç”¨äºé«˜åå OLTP/OLAP æ•°æ®åº“ï¼ˆå¦‚ MySQL, TiDB, ClickHouseï¼‰**

- **ç”¨ç‹¬ç«‹ç‰©ç†æœºéƒ¨ç½²æ•°æ®åº“ï¼ˆè£¸æœº SSD / RAID å­˜å‚¨ï¼‰**ï¼Œé€šè¿‡ **K8s Service è®¿é—®**ï¼Œé¿å…å­˜å‚¨è™šæ‹ŸåŒ–æŸè€—ã€‚

- **æ•°æ®åº“ä»ç„¶è¿è¡Œåœ¨ç‰©ç†æœºä¸Šï¼Œä½†åº”ç”¨è·‘åœ¨ Kubernetes å†…**ï¼Œé€šè¿‡ **ClusterIP / Headless Service** è¿æ¥æ•°æ®åº“ã€‚

- **ç¤ºä¾‹ï¼šå¤–éƒ¨æ•°æ®åº“é›†ç¾¤**

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: external-mysql
  spec:
    type: ExternalName
    externalName: mysql-db.example.com
  ```

- **ä¼˜ç‚¹**ï¼š

  - æ•°æ®åº“ä¸å— K8s è°ƒåº¦å½±å“ï¼Œ**é«˜æ€§èƒ½ã€ç¨³å®š**ã€‚
  - **é€‚åˆé«˜å¹¶å‘ã€è¯»å†™åˆ†ç¦»æ•°æ®åº“æ¶æ„**ï¼ˆå¦‚ MySQL + è¯»å†™åˆ†ç¦»ï¼‰ã€‚

- **ç¼ºç‚¹**ï¼š

  - éœ€è¦ **é¢å¤–ç®¡ç†æ•°æ®åº“ç‰©ç†æœº**ï¼Œä¸èƒ½å®Œå…¨äº‘åŸç”ŸåŒ–ã€‚

------

#### **æ–¹æ¡ˆ 3ï¼šåˆ†å¸ƒå¼æ•°æ®åº“ï¼ˆäº‘åŸç”Ÿæ¶æ„ï¼‰**

âœ… **é€‚ç”¨äºäº‘åŸç”Ÿç¯å¢ƒã€å¼¹æ€§æ‰©å±•éœ€æ±‚**

- **ä½¿ç”¨ K8s Operator éƒ¨ç½² TiDB, Vitess, CockroachDB, YugabyteDB**ï¼Œè®©æ•°æ®åº“å¤©ç„¶é€‚é… K8sã€‚

- **ç‰¹ç‚¹**ï¼š

  - **æ°´å¹³æ‰©å±•ï¼ˆScale-Outï¼‰**ï¼Œæ•°æ®åº“å¯å¼¹æ€§å¢é•¿ã€‚
  - **åˆ†å¸ƒå¼å­˜å‚¨**ï¼ˆå¦‚ TiKV, FoundationDBï¼‰ã€‚
  - **æ•°æ®åº“è‡ªåŠ¨æ•…éšœæ¢å¤**ï¼Œé¿å… Pod é‡å¯å¯¼è‡´æ•°æ®ä¸¢å¤±ã€‚

- **ç¤ºä¾‹ï¼šä½¿ç”¨ Vitess è¿è¡Œ MySQL åˆ†å¸ƒå¼é›†ç¾¤**

  ```yaml
  apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    name: vitess-mysql
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: vitess-mysql
    template:
      metadata:
        labels:
          app: vitess-mysql
      spec:
        containers:
        - name: mysql
          image: vitess/lite:v12.0
  ```

- **é€‚ç”¨åœºæ™¯**ï¼š

  - äº’è”ç½‘å¤§è§„æ¨¡æ•°æ®åº“ï¼Œå¦‚ **TiDB, Vitessï¼ˆYouTube çš„ MySQL æ‰©å±•æ–¹æ¡ˆï¼‰**ã€‚
  - **éœ€è¦ Kubernetes åŸç”Ÿè°ƒåº¦çš„äº‘æ•°æ®åº“**ã€‚

------

#### **4. ç»“è®ºï¼šæ˜¯å¦åœ¨ K8s ä¸Šéƒ¨ç½²æ•°æ®åº“ï¼Ÿ**

| **æ–¹æ¡ˆ**                         | **é€‚ç”¨åœºæ™¯**             | **æ€§èƒ½æŸè€—**           | **æ˜¯å¦æ¨èï¼Ÿ** |
| -------------------------------- | ------------------------ | ---------------------- | -------------- |
| **æœ¬åœ° SSD + Local PV**          | é«˜æ€§èƒ½æ•°æ®åº“ï¼Œä½å»¶è¿Ÿ     | **æŸè€—æä½ï¼ˆâ‰ˆ è£¸æœºï¼‰** | âœ… æ¨è         |
| **ç‹¬ç«‹æ•°æ®åº“ + K8s è®¿é—®**        | ä¼ ç»Ÿæ•°æ®åº“ï¼Œä¼ä¸šç”Ÿäº§ç¯å¢ƒ | **æ— æŸè€—ï¼ˆç‰©ç†æœºï¼‰**   | âœ… å¼ºçƒˆæ¨è     |
| **Ceph / Rook å­˜å‚¨**             | åˆ†å¸ƒå¼å­˜å‚¨ï¼ŒAI å¤§æ•°æ®    | **æŸè€— 10~30%**        | ğŸŸ¡ ä¸€èˆ¬æ¨è     |
| **NFS / è¿œç¨‹å­˜å‚¨**               | ä½æ€§èƒ½æ•°æ®åº“             | **æŸè€— 30%+**          | âŒ ä¸æ¨è       |
| **åˆ†å¸ƒå¼æ•°æ®åº“ï¼ˆTiDB, Vitessï¼‰** | äº‘åŸç”Ÿæ•°æ®åº“             | **æ€§èƒ½ä¼˜åŒ–å¥½**         | âœ… æ¨è         |

------

**æœ€ä½³å®è·µ**

1. **æ€§èƒ½è¦æ±‚é«˜çš„æ•°æ®åº“ï¼ˆå¦‚ MySQL, PostgreSQLï¼‰** â†’ **è¿è¡Œåœ¨ç‰©ç†æœº**ï¼ŒK8s è®¿é—®ã€‚
2. **äº‘åŸç”Ÿæ•°æ®åº“ï¼ˆå¦‚ TiDB, Vitessï¼‰** â†’ **å¯ä»¥è·‘åœ¨ K8s ä¸Š**ã€‚
3. **K8s æœ¬åœ° SSD ç›´æŒ‚ï¼ˆLocal PVï¼‰** â†’ **é€‚åˆ OLTP ä¸šåŠ¡**ï¼Œä½† Pod éœ€ç»‘å®šç‰¹å®šèŠ‚ç‚¹ã€‚

ğŸ’¡ **ä½ ä»¬çš„ä¸šåŠ¡æ›´å€¾å‘å“ªç§æ–¹æ¡ˆï¼Ÿæ˜¯å¦æœ‰æ•°æ®åº“å­˜å‚¨ä¼˜åŒ–çš„éœ€æ±‚ï¼Ÿ** ğŸš€





## ç”Ÿäº§ç¯å¢ƒä¸‹ï¼Œå¤šé¡¹ç›®æ„å»º CI/CD ä½“ç³»

å¦‚æœä½ çš„å…¬å¸æœ‰ **80ä¸ªé¡¹ç›®**ï¼Œåœ¨ **Jenkins** ä¸Šè¿›è¡Œ CI/CDï¼Œå¿…é¡»è€ƒè™‘ **é«˜æ•ˆç®¡ç†ã€èµ„æºä¼˜åŒ–ã€å¯ç»´æŠ¤æ€§å’Œè‡ªåŠ¨åŒ–**ã€‚ä¸‹é¢æä¾› **æœ€ä½³å®è·µ**ï¼Œå¸®åŠ©ä½ æ„å»ºä¸€ä¸ªå¯æ‰©å±•ã€ç¨³å®šçš„ **Jenkins CI/CD ä½“ç³»**ã€‚



### Jenkins CI/CD è®¾è®¡æ¶æ„

å¯¹äº **80ä¸ªé¡¹ç›®**ï¼Œåº”é‡‡ç”¨ **å¤šå±‚æ¬¡çš„ Jenkins ç»“æ„**ï¼š

```lua
                         +---------------------+
                         |   GitLab / GitHub   |
                         +---------------------+
                                   â”‚
                    GitLab Webhook â”‚
                    +--------------+-------------+
                    | Jenkins ä¸»æ§æœåŠ¡å™¨ï¼ˆMasterï¼‰|
                    +--------------+-------------+
                    |         |         |       |
            +----------------+--------------------+
            |     Jenkins Agent Nodesï¼ˆSlaveï¼‰    |
            |  - è¿è¡Œæ„å»ºä»»åŠ¡                      |
            |  - è¿è¡Œå®¹å™¨ï¼ˆDockerï¼‰                |
            +------------------------------------+
                     â”‚        â”‚        â”‚
              +-----------------------------+
              |  éƒ¨ç½²åˆ°æµ‹è¯• / ç”Ÿäº§ç¯å¢ƒ (K8s)  |
              +-----------------------------+
```

**æ ¸å¿ƒåŸåˆ™**

âœ… **ä¸»ä»æ¶æ„ï¼ˆMaster-Slaveï¼‰**
âœ… **æµæ°´çº¿ç®¡ç†ï¼ˆPipeline as Codeï¼‰**
âœ… **å…±äº« Agent èµ„æºï¼ŒåŠ¨æ€åˆ†é…ä»»åŠ¡**
âœ… **è‡ªåŠ¨è§¦å‘ CI/CDï¼ˆWebhookï¼‰**
âœ… **ç»Ÿä¸€æ—¥å¿— & ç›‘æ§**



### Jenkins æœåŠ¡å™¨æ¶æ„

**1ï¸âƒ£ Jenkins Masterï¼ˆç®¡ç†ä¸­å¿ƒï¼‰**

- ä¸»è¦è´Ÿè´£ï¼š
  - è§¦å‘æ„å»ºä»»åŠ¡ï¼ˆJobï¼‰
  - ä»»åŠ¡è°ƒåº¦ï¼ˆåˆ†é…åˆ°ä¸åŒçš„ Jenkins Agentï¼‰
  - ç›‘æ§ CI/CD è¿è¡ŒçŠ¶æ€
- é€‚ç”¨äºï¼šç®¡ç† **80ä¸ªé¡¹ç›®**ï¼Œä½†ä¸æ‰§è¡Œå…·ä½“æ„å»ºä»»åŠ¡ã€‚

ğŸ’¡ **ä¼˜åŒ–å»ºè®®**ï¼š

- **åˆ†ç¦» Master & Agent**ï¼ˆé¿å… Master è¿‡è½½ï¼‰
- **Jenkins æŒä¹…åŒ–å­˜å‚¨**ï¼ˆå¦‚ NFSã€S3 å¤‡ä»½ï¼‰

------

**2ï¸âƒ£ Jenkins Agentï¼ˆæ‰§è¡Œä»»åŠ¡ï¼‰**

- é€‚ç”¨äºï¼šè¿è¡Œ **æ„å»ºä»»åŠ¡**ï¼Œé¿å… Master è¿‡è½½
- **å¯ä»¥éƒ¨ç½²åœ¨ Kubernetes / Docker / ç‰©ç†æœº**
- **æŒ‰è¯­è¨€å’ŒæŠ€æœ¯æ ˆåˆ’åˆ†ï¼ˆNode.jsã€Pythonã€Javaç­‰ï¼‰**
- **æ”¯æŒåŠ¨æ€æ‰©å±•**

ğŸ’¡ **ä¼˜åŒ–å»ºè®®**ï¼š

- ä½¿ç”¨ **Kubernetes ä½œä¸º Jenkins Agent**ï¼ˆåŠ¨æ€ä¼¸ç¼©ï¼‰
- ä½¿ç”¨ **Docker + Jenkins Agent**ï¼ˆæ„å»ºç¯å¢ƒéš”ç¦»ï¼‰
- é‡‡ç”¨ **Label æ ‡ç­¾** åˆ†é…ä¸åŒä»»åŠ¡ï¼ˆJavaã€Pythonï¼‰



### å¤šé¡¹ç›®ç®¡ç†ç­–ç•¥

å¦‚æœä½ æœ‰ **80ä¸ªé¡¹ç›®**ï¼Œä½ å¯ä»¥ç”¨ä»¥ä¸‹æ–¹æ³•é«˜æ•ˆç®¡ç†ï¼š

#### æ–¹æ¡ˆ 1ï¼šä½¿ç”¨å¤šçº§æ–‡ä»¶å¤¹ç»„ç»‡é¡¹ç›®ï¼ˆæ¨èï¼‰

åœ¨ Jenkins **ä½¿ç”¨æ–‡ä»¶å¤¹ï¼ˆFolderï¼‰åˆ†ç±»ç®¡ç†**ï¼š

```scss
Jenkins
 â”œâ”€â”€ Backend Projects
 â”‚   â”œâ”€â”€ project-a (Pipeline)
 â”‚   â”œâ”€â”€ project-b (Pipeline)
 â”‚   â”œâ”€â”€ project-c (Pipeline)
 â”œâ”€â”€ Frontend Projects
 â”‚   â”œâ”€â”€ project-d (Pipeline)
 â”‚   â”œâ”€â”€ project-e (Pipeline)
 â”œâ”€â”€ Mobile Projects
 â”‚   â”œâ”€â”€ project-f (Pipeline)
 â”œâ”€â”€ DevOps Tools
 â”‚   â”œâ”€â”€ Infrastructure (Terraform)
 â”‚   â”œâ”€â”€ Monitoring (Prometheus)
```

**âœ… å¥½å¤„**ï¼š

- **ç®¡ç†æ›´æ¸…æ™°**ï¼ˆä¸åŒç±»å‹çš„é¡¹ç›®åˆ†å±‚ï¼‰
- **æƒé™ç®¡ç†æ›´æ–¹ä¾¿**ï¼ˆä¸åŒå›¢é˜Ÿç®¡ç†è‡ªå·±çš„ Pipelineï¼‰

ğŸ’¡ **å¦‚ä½•åˆ›å»ºæ–‡ä»¶å¤¹**

```bash
Jenkins -> New Item -> Folder
```



#### æ–¹æ¡ˆ 2ï¼šä½¿ç”¨å…±äº« Pipeline æ¨¡æ¿

å¦‚æœ **80ä¸ªé¡¹ç›®æœ‰ç›¸ä¼¼çš„ CI/CD é€»è¾‘**ï¼Œä½ å¯ä»¥ç”¨ **å…±äº« Pipeline æ¨¡æ¿** é¿å…é‡å¤å†™æµæ°´çº¿ä»£ç ã€‚

ğŸ’¡ **ä½¿ç”¨ `Jenkins Shared Library`**

1. **åˆ›å»ºä¸€ä¸ª Git ä»“åº“ï¼Œå­˜æ”¾ Jenkins é€šç”¨ Pipeline**
2. **åœ¨ `Jenkinsfile` é‡Œè°ƒç”¨å®ƒ**

**ç¤ºä¾‹ï¼š`Jenkinsfile`**

```groovy
@Library('cicd-shared-library') _
pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                buildApp()
            }
        }
        stage('Test') {
            steps {
                runTests()
            }
        }
        stage('Deploy') {
            steps {
                deployToK8s()
            }
        }
    }
}
```

âœ… **å¥½å¤„**ï¼š

- åªéœ€è¦ç»´æŠ¤ **ä¸€ä¸ª CI/CD é€»è¾‘**ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½å¯ä»¥å¤ç”¨ï¼
- **é€‚åˆç®¡ç†å¤šä¸ªé¡¹ç›®**ï¼Œå‡å°‘é‡å¤ä»£ç ã€‚



#### æ–¹æ¡ˆ 3ï¼šä½¿ç”¨ Jenkins Job DSL è‡ªåŠ¨åˆ›å»º 80 ä¸ª Job

å¦‚æœä½ æœ‰ **80ä¸ªé¡¹ç›®**ï¼Œå¯ä»¥ç”¨ **Jenkins Job DSL** è‡ªåŠ¨åˆ›å»ºæ‰€æœ‰ Jobï¼Œè€Œä¸éœ€è¦æ‰‹åŠ¨é…ç½®ã€‚

**ç¤ºä¾‹ï¼šJob DSL**

```groovy
pipelineJob('my-app') {
    definition {
        cps {
            script(readFileFromWorkspace('Jenkinsfile'))
            sandbox()
        }
    }
}
```

ç„¶å **æ‰¹é‡åˆ›å»º 80 ä¸ª Job**ï¼Œæ‰€æœ‰é¡¹ç›®éƒ½å¯ä»¥è‡ªåŠ¨é…ç½®ã€‚

âœ… **å¥½å¤„**ï¼š

- **æ‰€æœ‰é¡¹ç›®é…ç½®ä¸€è‡´**ï¼Œæ–¹ä¾¿æ‰¹é‡ç®¡ç†ã€‚
- **è‡ªåŠ¨åŒ–åˆ›å»º**ï¼Œé¿å…æ‰‹åŠ¨æ“ä½œã€‚



### å¦‚ä½•ä¼˜åŒ– CI/CD æ„å»ºæ•ˆç‡

å½“ä½ æœ‰ **80ä¸ªé¡¹ç›®** æ—¶ï¼Œéœ€è¦ä¼˜åŒ– **CI/CD æ‰§è¡Œé€Ÿåº¦**ã€‚

#### 1ï¸âƒ£ ä½¿ç”¨ Jenkins Agent å¹¶è¡Œæ„å»º

- **æ¯ä¸ª Job è¿è¡Œåœ¨ä¸åŒçš„ Jenkins Agent**
- **é¿å… Master è¿‡è½½**
- **æé«˜å¹¶å‘å¤„ç†èƒ½åŠ›**

ğŸ’¡ **ä½¿ç”¨ Label ç»‘å®šç‰¹å®š Agent**

```groovy
pipeline {
    agent {
        label 'java-agent'
    }
    stages {
        stage('Build') {
            steps {
                sh './gradlew build'
            }
        }
    }
}
```



#### 2ï¸âƒ£ ä½¿ç”¨ Docker åŠ é€Ÿæ„å»º

ä½¿ç”¨ **Docker æ„å»ºç¯å¢ƒ** é¿å… Jenkins å®‰è£…è¿‡å¤šä¾èµ–ï¼š

```groovy
pipeline {
    agent {
        docker {
            image 'maven:3.8.1-jdk-11'
        }
    }
    stages {
        stage('Build') {
            steps {
                sh 'mvn clean install'
            }
        }
    }
}
```

âœ… **å¥½å¤„**ï¼š

- **æ„å»ºç¯å¢ƒéš”ç¦»**ï¼Œé˜²æ­¢ä¾èµ–å†²çªã€‚
- **æ”¯æŒå¤šè¯­è¨€**ï¼ˆNode.js, Java, Pythonï¼‰ã€‚
- **åŠ¨æ€æ‹‰å–æœ€æ–°ç¯å¢ƒ**ã€‚



#### 3ï¸âƒ£ ä»£ç å˜æ›´æœ€å°åŒ–è§¦å‘

é¿å… **æ¯æ¬¡æ¨é€å…¨é‡æ„å»º**ï¼Œåªæ„å»º **å˜æ›´çš„éƒ¨åˆ†**

```groovy
pipeline {
    triggers {
        pollSCM('* * * * *') // ä»…æ‹‰å–æœ‰å˜æ›´çš„ä»£ç 
    }
}
```



### ç”Ÿäº§ç¯å¢ƒçš„ CI/CD æµç¨‹

ä½ çš„ 80 ä¸ªé¡¹ç›®å¯ä»¥éµå¾ªä»¥ä¸‹ **CI/CD æµç¨‹**

#### **âœ… 1. CIï¼ˆæŒç»­é›†æˆï¼‰**

1. **å¼€å‘è€…æäº¤ä»£ç ï¼ˆGitLabï¼‰**
2. **GitLab Webhook è§¦å‘ Jenkins**
3. **ä»£ç æ£€æŸ¥ï¼ˆSonarQubeï¼‰**
4. **å•å…ƒæµ‹è¯•ï¼ˆJUnit, PyTestï¼‰**
5. **æ„å»º Docker é•œåƒ**
6. **æ¨é€åˆ° Harbor / Docker Hub**

#### **âœ… 2. CDï¼ˆæŒç»­éƒ¨ç½²ï¼‰**

1. **éƒ¨ç½²åˆ° Kubernetes / ç‰©ç†æœº**
2. **è‡ªåŠ¨åŒ–æµ‹è¯•ï¼ˆSelenium, API Testï¼‰**
3. **äººå·¥å®¡æ‰¹**
4. **å‘å¸ƒåˆ°ç”Ÿäº§**
5. **ç›‘æ§ & å›æ»šï¼ˆPrometheus, ArgoCDï¼‰**



### è¿›é˜¶æ¨¡æ‹Ÿç”Ÿäº§æ¶æ„

**ä¸‰ç§æ¶æ„æ¨¡å¼**

- **Jenkins + ä¼ ç»ŸCICD**
- **Jenkins + docker + K8S**
- **Tekton + docker + K8S**





## Java ç‰ˆæœ¬ç®¡ç†æ–¹æ¡ˆ



### ä½¿ç”¨ update-alternatives

å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ **Ubuntu / Debian / Rocky Linux / CentOS**ï¼Œå¯ä»¥ä½¿ç”¨ `update-alternatives` **ç®¡ç†å¤šä¸ª Java ç‰ˆæœ¬**ã€‚



#### 1ï¸âƒ£ æŸ¥çœ‹å·²å®‰è£…çš„ Java ç‰ˆæœ¬

```bash
update-alternatives --list java
```

**è¾“å‡ºç¤ºä¾‹**

```bash
/usr/lib/jvm/java-8-openjdk-amd64/bin/java
/usr/lib/jvm/java-11-openjdk-amd64/bin/java
/usr/lib/jvm/java-17-openjdk-amd64/bin/java
```

#### 2ï¸âƒ£ è®¾ç½®é»˜è®¤ Java ç‰ˆæœ¬

```bash
sudo update-alternatives --config java
```

**ç»ˆç«¯ä¼šæ˜¾ç¤º**

```bash
There are 3 choices for the alternative java (providing /usr/bin/java).

  Selection    Path                                     Priority   Status
------------------------------------------------------------
  0            /usr/lib/jvm/java-17-openjdk-amd64/bin/java   200       auto mode
  1            /usr/lib/jvm/java-8-openjdk-amd64/bin/java    100       manual mode
  2            /usr/lib/jvm/java-11-openjdk-amd64/bin/java   150       manual mode
  3            /usr/lib/jvm/java-17-openjdk-amd64/bin/java   200       manual mode

Press <enter> to keep the current choice[*], or type selection number:
```

**è¾“å…¥ `1` é€‰æ‹© Java 8ï¼Œæˆ–è€…è¾“å…¥ `2` é€‰æ‹© Java 11**

#### 3ï¸âƒ£ ç¡®ä¿ `javac` ä¹Ÿåˆ‡æ¢

```bash
sudo update-alternatives --config javac
```

#### 4ï¸âƒ£ éªŒè¯ Java ç‰ˆæœ¬

```bash
java -version
```

**é€‚ç”¨äºå…¨å±€ Java ç‰ˆæœ¬åˆ‡æ¢ï¼**



### ä½¿ç”¨ç¯å¢ƒå˜é‡  JAVA_HOMEï¼ˆé€‚ç”¨äºç‰¹å®šç”¨æˆ·ï¼‰

å¦‚æœä½ æƒ³è®©**ä¸åŒé¡¹ç›®æˆ–ç”¨æˆ·ä½¿ç”¨ä¸åŒçš„ Java ç‰ˆæœ¬**ï¼Œå¯ä»¥ä½¿ç”¨ `JAVA_HOME` å˜é‡ã€‚

#### 1ï¸âƒ£ æ‰¾åˆ° JDK ç›®å½•

```bash
ls /usr/lib/jvm/
```

**å¯èƒ½çš„è¾“å‡º**

```bash
java-8-openjdk-amd64
java-11-openjdk-amd64
java-17-openjdk-amd64
```

#### 2ï¸âƒ£ è®¾ç½® Java ç‰ˆæœ¬

**ä¸´æ—¶åˆ‡æ¢**

```bash
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
```

**éªŒè¯**

```bash
java -version
```

**è®©è®¾ç½®æ°¸ä¹…ç”Ÿæ•ˆï¼ˆé’ˆå¯¹å½“å‰ç”¨æˆ·ï¼‰**

```bash
echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> ~/.bashrc
echo "export PATH=\$JAVA_HOME/bin:\$PATH" >> ~/.bashrc
source ~/.bashrc
```

âœ… **é€‚ç”¨äºä¸åŒ Java ç¨‹åºä½¿ç”¨ä¸åŒçš„ JDK ç‰ˆæœ¬ã€‚**



### ä½¿ç”¨ sdkmanï¼ˆæ¨èç”¨äºå¼€å‘ç¯å¢ƒï¼‰

å¦‚æœä½ é¢‘ç¹åˆ‡æ¢ JDKï¼Œ`sdkman` æ˜¯ä¸€ä¸ª **æ›´ä¾¿æ·çš„å·¥å…·**ã€‚

#### 1ï¸âƒ£ å®‰è£… `sdkman`

```bash
curl -s "https://get.sdkman.io" | bash
source "$HOME/.sdkman/bin/sdkman-init.sh"
```

#### 2ï¸âƒ£ å®‰è£…ä¸åŒç‰ˆæœ¬çš„ Java

```bash
sdk install java 8.0.292-open
sdk install java 11.0.16-open
sdk install java 17.0.5-open
```

#### 3ï¸âƒ£ åˆ‡æ¢ Java ç‰ˆæœ¬

```bash
sdk use java 11.0.16-open
```

**æˆ–è€…è®¾ç½®é»˜è®¤ JDK**

```baash
sdk default java 11.0.16-open
```

#### 4ï¸âƒ£ éªŒè¯ Java ç‰ˆæœ¬

```bash
java -version
```

âœ… **é€‚ç”¨äºå¼€å‘ç¯å¢ƒï¼Œå¿«é€Ÿåˆ‡æ¢ JDK ç‰ˆæœ¬ï¼**



## Mutating Admission Webhook æ•™ç¨‹ï¼ˆè‡ªåŠ¨æ³¨å…¥ `imagePullSecrets`ï¼‰

**ğŸ§ ä¸ºä»€ä¹ˆä½¿ç”¨ Mutating Admission Webhookï¼Ÿ**

Kubernetes **ä¸å…è®¸è·¨å‘½åç©ºé—´ç›´æ¥ä½¿ç”¨ Secret**ï¼Œæ‰€ä»¥ `imagePullSecrets` ä¸èƒ½å¼•ç”¨ `default` å‘½åç©ºé—´çš„ Secretã€‚ä½†å¦‚æœä½ çš„ **å¤šä¸ªå‘½åç©ºé—´éƒ½è¦æ‹‰å– Harbor é•œåƒ**ï¼Œæ‰‹åŠ¨å¤åˆ¶ Secret ä¸æ˜¯æœ€ä½³æ–¹æ¡ˆã€‚

**âœ… Mutating Admission Webhook å¯ä»¥åœ¨ Pod åˆ›å»ºæ—¶è‡ªåŠ¨æ³¨å…¥ `imagePullSecrets`ï¼Œé¿å…æ‰‹åŠ¨ç®¡ç† Secretï¼**



### ğŸ“Œ Step 1: ç¼–å†™ Webhook æœåŠ¡å™¨

Webhook éœ€è¦æ¥æ”¶ Kubernetes å‘é€çš„ `AdmissionReview` è¯·æ±‚ï¼Œå¹¶è¿”å›ä¿®æ”¹åçš„ `imagePullSecrets`

#### 1ï¸âƒ£ ç¼–å†™ Webhook ä»£ç 

ğŸ“‚ **åˆ›å»º `mutating-webhook.go`**

```go
package main

import (
	"encoding/json"
	"fmt"
	"io/ioutil"
	"net/http"

	admissionv1 "k8s.io/api/admission/v1"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

const imagePullSecret = "my-secret" // éœ€è¦è‡ªåŠ¨æ³¨å…¥çš„ Secret åç§°

func mutatePods(w http.ResponseWriter, r *http.Request) {
	// è§£æ AdmissionReview è¯·æ±‚
	body, err := ioutil.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request", http.StatusBadRequest)
		return
	}

	var admissionReviewReq admissionv1.AdmissionReview
	if err := json.Unmarshal(body, &admissionReviewReq); err != nil {
		http.Error(w, "Failed to unmarshal request", http.StatusBadRequest)
		return
	}

	// ç¡®ä¿æ˜¯ Pod èµ„æº
	if admissionReviewReq.Request.Kind.Kind != "Pod" {
		http.Error(w, "This webhook only handles Pod resources", http.StatusBadRequest)
		return
	}

	// è§£æ Pod
	var pod v1.Pod
	if err := json.Unmarshal(admissionReviewReq.Request.Object.Raw, &pod); err != nil {
		http.Error(w, "Failed to unmarshal Pod", http.StatusBadRequest)
		return
	}

	// æ£€æŸ¥æ˜¯å¦å·²æœ‰ imagePullSecrets
	for _, secret := range pod.Spec.ImagePullSecrets {
		if secret.Name == imagePullSecret {
			// å¦‚æœ Secret å·²ç»å­˜åœ¨ï¼Œåˆ™ä¸ä¿®æ”¹
			sendAdmissionResponse(w, admissionReviewReq, nil)
			return
		}
	}

	// åˆ›å»º Patch ä»¥æ·»åŠ  imagePullSecrets
	patch := `[{"op":"add","path":"/spec/imagePullSecrets","value":[{"name":"` + imagePullSecret + `"}]}]`
	sendAdmissionResponse(w, admissionReviewReq, &patch)
}

func sendAdmissionResponse(w http.ResponseWriter, req admissionv1.AdmissionReview, patch *string) {
	resp := admissionv1.AdmissionReview{
		TypeMeta: req.TypeMeta,
		Response: &admissionv1.AdmissionResponse{
			UID:     req.Request.UID,
			Allowed: true,
		},
	}

	if patch != nil {
		patchType := admissionv1.PatchTypeJSONPatch
		resp.Response.PatchType = &patchType
		resp.Response.Patch = []byte(*patch)
	}

	respBytes, _ := json.Marshal(resp)
	w.Header().Set("Content-Type", "application/json")
	w.Write(respBytes)
}

func main() {
	http.HandleFunc("/mutate", mutatePods)
	fmt.Println("Webhook server started on :8443")
	http.ListenAndServeTLS(":8443", "/etc/webhook/certs/tls.crt", "/etc/webhook/certs/tls.key", nil)
}
```



### ğŸ“Œ Step 2: ç”Ÿæˆ Webhook è¯ä¹¦

Kubernetes Webhook éœ€è¦ **TLS è¯ä¹¦**ï¼Œä½ å¯ä»¥ä½¿ç”¨ `openssl` ç”Ÿæˆè‡ªç­¾åè¯ä¹¦ï¼š

```bash
mkdir certs && cd certs

# ç”Ÿæˆ CA è¯ä¹¦
openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -subj "/CN=webhook-ca" -days 365 -out ca.crt

# ç”Ÿæˆ Webhook æœåŠ¡å™¨è¯ä¹¦
openssl genrsa -out webhook.key 2048
openssl req -new -key webhook.key -subj "/CN=mutating-webhook.default.svc" -out webhook.csr

# ç­¾å‘ Webhook è¯ä¹¦
openssl x509 -req -in webhook.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out webhook.crt -days 365
```

ç„¶ååˆ›å»º Kubernetes Secret å­˜æ”¾è¯ä¹¦ï¼š

```bash
kubectl create secret tls webhook-secret --cert=webhook.crt --key=webhook.key -n default
```



### ğŸ“Œ Step 3: éƒ¨ç½² Webhook æœåŠ¡å™¨

ğŸ“‚ **åˆ›å»º `webhook-deployment.yaml`**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webhook-server
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webhook
  template:
    metadata:
      labels:
        app: webhook
    spec:
      containers:
        - name: webhook
          image: my-webhook:latest  # ä½ éœ€è¦æ„å»ºè¿™ä¸ª Go Webhook é•œåƒ
          ports:
            - containerPort: 8443
          volumeMounts:
            - name: tls-certs
              mountPath: "/etc/webhook/certs"
              readOnly: true
      volumes:
        - name: tls-certs
          secret:
            secretName: webhook-secret
```



### ğŸ“Œ Step 4: é…ç½® MutatingWebhookConfiguration

ğŸ“‚ **åˆ›å»º `mutating-webhook.yaml`**

```yaml
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: pod-mutating-webhook
webhooks:
  - name: pod-imagepullsecrets.my-webhook.com
    admissionReviewVersions: ["v1"]
    sideEffects: None
    rules:
      - apiGroups: [""]
        apiVersions: ["v1"]
        operations: ["CREATE"]
        resources: ["pods"]
    clientConfig:
      service:
        name: webhook-server
        namespace: default
        path: "/mutate"
      caBundle: $(cat certs/ca.crt | base64 | tr -d '\n')
    failurePolicy: Ignore

```



### ğŸ“Œ Step 5: æµ‹è¯• Webhook

åˆ›å»º Pod **ä¸æŒ‡å®š `imagePullSecrets`**ï¼Œç„¶åçœ‹çœ‹ Webhook æ˜¯å¦è‡ªåŠ¨æ³¨å…¥

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
  namespace: my-namespace
spec:
  containers:
    - name: test
      image: harbor.mystical.org/my-image:latest
```

åº”ç”¨

```bash
kubectl apply -f test-pod.yaml
```

ç„¶åæ£€æŸ¥

```bash
kubectl get pod test-pod -o yaml | grep imagePullSecrets -A 2
```

å¦‚æœæˆåŠŸï¼Œä¼šçœ‹åˆ°

```yaml
imagePullSecrets:
  - name: my-secret
```



### **ğŸ“Œ æ€»ç»“**

âœ… **Pod è‡ªåŠ¨æ³¨å…¥ `imagePullSecrets`**ï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç† Secretã€‚
âœ… **Webhook é€‚ç”¨äºæ‰€æœ‰æ–°åˆ›å»ºçš„ Pod**ï¼Œä¸éœ€è¦ä¿®æ”¹ Deploymentã€‚
âœ… **å¯ä»¥æ‰©å±•ä¸ºå…¶ä»–ç”¨é€”**ï¼Œå¦‚è‡ªåŠ¨è®¾ç½® `labels`ã€`annotations` ç­‰ã€‚

è¿™å°±æ˜¯ **Kubernetes Mutating Admission Webhook** **è‡ªåŠ¨æ³¨å…¥ `imagePullSecrets`** çš„å®Œæ•´æ•™ç¨‹ï¼ğŸš€



## CICD æ–¹æ¡ˆå®Œæ•´ pipeline æ¡†æ¶

### **ğŸ¯ ç›®æ ‡**

1. **æ”¯æŒ Javaã€Goã€å‰ç«¯ï¼ˆNode.jsï¼‰åº”ç”¨**
2. **ä½¿ç”¨åŠ¨æ€ Jenkins Agent è¿›è¡Œæ„å»º**
3. **å°† `.jar`ã€`Go` äºŒè¿›åˆ¶ã€`Node.js` å‰ç«¯æ‰“åŒ…æˆ Docker é•œåƒ**
4. **æ¨é€ Docker é•œåƒåˆ° Nexus/Harbor**
5. **éƒ¨ç½²åˆ° Kubernetes**
6. **ä¸Šä¼  `.jar`ã€`.deb`ã€`tar.gz` åˆ¶å“åˆ° Nexus è¿›è¡Œå½’æ¡£**



### **1ï¸âƒ£ Jenkins Pipeline**

```groovy
pipeline {
    agent none  // è®©æ‰€æœ‰ä»»åŠ¡åœ¨åŠ¨æ€ Agent ä¸Šè¿è¡Œ

    parameters {
        choice(name: 'APP_TYPE', choices: ['java', 'go', 'node'], description: 'Choose the application type')
        string(name: 'BRANCH_NAME', defaultValue: 'main', description: 'Git branch to build')
        choice(name: 'DEPLOY_ENV', choices: ['dev', 'staging', 'prod'], description: 'Deployment Environment')
    }

    environment {
        DOCKER_REGISTRY = 'nexus.mycompany.com:5000'
        IMAGE_NAME = "mycompany/${params.APP_TYPE}-app"
    }

    stages {
        stage('Checkout Code') {
            agent { docker 'alpine/git' }
            steps {
                script {
                    git branch: params.BRANCH_NAME, url: 'https://github.com/my-org/my-app.git'
                    stash name: 'source', includes: '**'
                }
            }
        }

        stage('Build Application') {
            agent {
                docker {
                    image params.APP_TYPE == 'java' ? 'maven:3.8.5' :
                          params.APP_TYPE == 'go' ? 'golang:1.19' :
                          'node:18'
                    reuseNode true
                }
            }
            steps {
                unstash 'source'
                script {
                    if (params.APP_TYPE == 'java') {
                        sh 'mvn clean package -DskipTests'
                        stash name: 'artifact', includes: 'target/*.jar'
                    } else if (params.APP_TYPE == 'go') {
                        sh 'go build -o myapp'
                        stash name: 'artifact', includes: 'myapp'
                    } else if (params.APP_TYPE == 'node') {
                        sh 'npm install && npm run build'
                        stash name: 'artifact', includes: 'dist/**'
                    }
                }
            }
        }

        stage('Build Docker Image') {
            agent { docker 'docker:24.0.5' }
            steps {
                unstash 'artifact'
                script {
                    sh "cp -r * /workspace/"
                    sh """
                        docker build -t ${DOCKER_REGISTRY}/${IMAGE_NAME}:latest -f Dockerfile .
                        docker push ${DOCKER_REGISTRY}/${IMAGE_NAME}:latest
                    """
                }
            }
        }

        stage('Upload to Nexus') {
            agent { docker 'curlimages/curl' }
            steps {
                unstash 'artifact'
                script {
                    if (params.APP_TYPE == 'java') {
                        sh 'curl -u user:password --upload-file target/my-app.jar http://nexus.mycompany.com/repository/maven-releases/com/mycompany/app/my-app.jar'
                    } else if (params.APP_TYPE == 'go') {
                        sh 'curl -u user:password --upload-file myapp http://nexus.mycompany.com/repository/go-releases/myapp'
                    } else if (params.APP_TYPE == 'node') {
                        sh 'tar -czf frontend.tar.gz dist'
                        sh 'curl -u user:password --upload-file frontend.tar.gz http://nexus.mycompany.com/repository/frontend-releases/frontend.tar.gz'
                    }
                }
            }
        }

        stage('Deploy to Kubernetes') {
            agent { docker 'bitnami/kubectl' }
            steps {
                script {
                    if (params.DEPLOY_ENV == 'prod') {
                        sh "kubectl set image deployment/${params.APP_TYPE}-app ${params.APP_TYPE}-app=${DOCKER_REGISTRY}/${IMAGE_NAME}:latest"
                    } else {
                        sh "kubectl set image deployment/${params.APP_TYPE}-app ${params.APP_TYPE}-app=${DOCKER_REGISTRY}/${IMAGE_NAME}:latest"
                    }
                }
            }
        }
    }

    post {
        always {
            cleanWs()
        }
        success {
            echo "Deployment Successful!"
        }
        failure {
            echo "Deployment Failed!"
        }
    }
}
```



### 2ï¸âƒ£ Dockerfileï¼ˆæ¯ç§åº”ç”¨ç±»å‹éƒ½æœ‰è‡ªå·±çš„ `Dockerfile`ï¼‰

#### Javaï¼ˆSpring Bootï¼‰

```dockerfile
FROM openjdk:17
WORKDIR /app
COPY target/*.jar app.jar
CMD ["java", "-jar", "app.jar"]
```

#### **Go**

```dockerfile
FROM golang:1.19-alpine
WORKDIR /app
COPY myapp .
CMD ["./myapp"]
```

#### Node.jsï¼ˆReact/Vueï¼‰

```dockerfile
FROM node:18-alpine
WORKDIR /usr/share/nginx/html
COPY dist/ .
CMD ["nginx", "-g", "daemon off;"]
```



### 3ï¸âƒ£ Kubernetes `Deployment`

åœ¨ Kubernetes é‡Œï¼Œæ¯ç§åº”ç”¨éƒ¨ç½²ä¸åŒçš„å®¹å™¨

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: nexus.mycompany.com:5000/mycompany/my-app:latest
        ports:
        - containerPort: 8080
```



### 4ï¸âƒ£ Nexus å­˜å‚¨è·¯å¾„

```bash
nexus.mycompany.com/repository/
 â”œâ”€â”€ maven-releases/        # å­˜æ”¾ Java JAR åŒ…
 â”œâ”€â”€ go-releases/           # å­˜æ”¾ Go å¯æ‰§è¡Œæ–‡ä»¶
 â”œâ”€â”€ frontend-releases/     # å­˜æ”¾å‰ç«¯ tar.gz
 â”œâ”€â”€ docker-registry/       # å­˜æ”¾ Docker é•œåƒ
```



### **5ï¸âƒ£ å…³é”®ä¼˜åŒ–**

| ä»»åŠ¡                  | æ–¹æ¡ˆ                                                         |
| --------------------- | ------------------------------------------------------------ |
| **åŠ¨æ€ Agent é€‰æ‹©**   | `agent { docker "maven:3.8.5" }`                             |
| **ä»£ç æ‹‰å–**          | `git branch: params.BRANCH_NAME, url: 'https://github.com/my-org/my-app.git'` |
| **æ”¯æŒä¸åŒè¯­è¨€æ„å»º**  | `mvn package` / `go build` / `npm install && npm run build`  |
| **ä¸Šä¼ åˆ¶å“åˆ° Nexus**  | `curl --upload-file`                                         |
| **æ‰“åŒ… Docker é•œåƒ**  | `docker build` & `docker push`                               |
| **éƒ¨ç½²åˆ° Kubernetes** | `kubectl set image`                                          |

ğŸš€ **æœ€ç»ˆï¼Œè¿™ä¸ª CI/CD æµæ°´çº¿èƒ½å¤Ÿè‡ªåŠ¨æ„å»ºã€ä¸Šä¼ åˆ¶å“åˆ° Nexusï¼Œå¹¶æ‰“åŒ…æˆ Docker é•œåƒåéƒ¨ç½²åˆ° Kubernetesï¼Œå®ç°å®Œæ•´çš„ DevOpsï¼** ğŸš€







## å®Œæ•´çš„ä¼ä¸šçº§ CICD æ–¹æ¡ˆ 

Jenkinsã€GitLabã€Nexusã€Harborã€Kubernetesã€MySQL ç»„æˆ CI/CD åŸºç¡€è®¾æ–½ï¼Œå¹¶é€šè¿‡ Prometheus è¿›è¡Œç›‘æ§



### 1ï¸âƒ£ CI/CD ç»„ä»¶

| ç»„ä»¶                     | ä½œç”¨                                     | è¿è¡Œç¯å¢ƒ                                |
| ------------------------ | ---------------------------------------- | --------------------------------------- |
| **Jenkins**              | **CI/CD ä»»åŠ¡è°ƒåº¦ï¼ˆæµæ°´çº¿æ‰§è¡Œï¼‰**         | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**ï¼ˆä¿è¯é«˜å¯ç”¨ & æ€§èƒ½ï¼‰ |
| **GitLab**               | **ä»£ç ç®¡ç† & Webhook è§¦å‘ Jenkins**      | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**                      |
| **Nexus**                | **å­˜å‚¨ JARã€Go å¯æ‰§è¡Œæ–‡ä»¶ã€å‰ç«¯ tar.gz** | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**                      |
| **Harbor**               | **å­˜å‚¨ Docker é•œåƒ**                     | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**                      |
| **Kubernetes (K8s)**     | **å®¹å™¨ç¼–æ’ & åº”ç”¨éƒ¨ç½²**                  | **é›†ç¾¤**                                |
| **MySQL**                | **å­˜å‚¨ Jenkinsã€Harborã€GitLab æ•°æ®**    | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**                      |
| **Prometheus + Grafana** | **CI/CD ç›‘æ§ & é¢„è­¦**                    | **K8s å†…éƒ¨ç½²**                          |

ğŸ“Œ **ä¸ºä»€ä¹ˆ Jenkinsã€Harborã€Nexus ç­‰ CI/CD ç»„ä»¶éƒ¨ç½²åœ¨ Kubernetes å¤–ï¼Ÿ**

- é¿å… **CI/CD ä»»åŠ¡å ç”¨ K8s èµ„æºï¼Œå½±å“ä¸šåŠ¡åº”ç”¨**
- **Jenkinsã€Harborã€Nexus éœ€è¦æŒä¹…åŒ–å­˜å‚¨**ï¼Œç‹¬ç«‹éƒ¨ç½²æ›´ç¨³å®š
- **K8s ä¸»è¦è´Ÿè´£ä¸šåŠ¡åº”ç”¨**ï¼ŒCI/CD ç»„ä»¶æ›´é€‚åˆç‹¬ç«‹ç»´æŠ¤



### 2ï¸âƒ£ ç»„ä»¶æ‰©å±•

#### Prometheus ç›‘æ§ CI/CD æµç¨‹

ä½ çš„ **Prometheus ä¸»è¦ç”¨äºç›‘æ§æ•´ä¸ª CI/CD æµç¨‹**ï¼Œä½†å¯ä»¥ç»†åŒ–åˆ°ï¼š

| ç›‘æ§é¡¹                      | é‡‡é›†æ–¹å¼             |
| --------------------------- | -------------------- |
| **Jenkins Job çŠ¶æ€**        | `Jenkins Exporter`   |
| **Kubernetes Pod èµ„æº**     | `kube-state-metrics` |
| **MySQL ç›‘æ§**              | `mysqld_exporter`    |
| **Harbor é•œåƒæ‹‰å– & å­˜å‚¨**  | `Harbor Exporter`    |
| **Nexus åˆ¶å“ä»“åº“å¤§å°**      | `Nexus Exporter`     |
| **GitLab Webhook è°ƒç”¨æƒ…å†µ** | `GitLab Exporter`    |

ğŸ“Œ **æ¨èæ–¹æ¡ˆ**

- **Prometheus + Grafana** ä½œä¸ºç›‘æ§ç³»ç»Ÿ
- **Alertmanager** å®ç° CI/CD æ•…éšœæŠ¥è­¦ï¼ˆå¦‚ Jenkins ä»»åŠ¡å¤±è´¥ã€Nexus å­˜å‚¨ä¸è¶³ï¼‰
- **Loki + Fluentd** æ”¶é›† **Jenkinsã€GitLabã€Harbor** æ—¥å¿—



#### Webhook è§¦å‘ä¼˜åŒ–

ä½ çš„ **GitLab è§¦å‘ Jenkins** å¯ä»¥ä¼˜åŒ–ï¼š âœ… **WebHook ç›´è¿ Jenkins**

```http
http://jenkins-server-url/project/job-name
```

âœ… **GitLab Runner è§¦å‘**

- **åœ¨ GitLab CI é‡ŒåŠ  Jobï¼Œè§¦å‘ Jenkins**

```yaml
stages:
  - trigger-jenkins

trigger_jenkins:
  script:
    - curl -X POST http://jenkins-server-url/job/job-name/build
```

ğŸ“Œ **å¯¹æ¯”**

| è§¦å‘æ–¹å¼                        | ä¼˜ç‚¹             | ç¼ºç‚¹               |
| ------------------------------- | ---------------- | ------------------ |
| **GitLab Webhook ç›´è¿ Jenkins** | ä½å»¶è¿Ÿ           | æ— æ³•æºå¸¦å‚æ•°       |
| **GitLab Runner è§¦å‘ Jenkins**  | å¯ä»¥åŠ¨æ€ä¼ é€’å‚æ•° | éœ€è¦ GitLab Runner |



#### API Gateway ç»Ÿä¸€ç®¡ç† CI/CD

**é—®é¢˜**ï¼šç°åœ¨ **GitLab â†’ Jenkins â†’ Nexus â†’ Harbor â†’ K8s**ï¼Œå¤šä¸ªç»„ä»¶ä¹‹é—´äº¤äº’è¾ƒå¤šï¼Œè°ƒç”¨åœ°å€åˆ†æ•£

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ **API Gatewayï¼ˆå¦‚ Kongã€Traefikï¼‰**

```http
https://cicd.mycompany.com/gitlab    -> GitLab
https://cicd.mycompany.com/jenkins   -> Jenkins
https://cicd.mycompany.com/nexus     -> Nexus
https://cicd.mycompany.com/harbor    -> Harbor
```

**å®‰å…¨**ï¼šå¯ä»¥åŠ  RBAC è®¤è¯

**ç®¡ç†æ–¹ä¾¿**ï¼šæ‰€æœ‰ CI/CD ç»„ä»¶é€šè¿‡ `cicd.mycompany.com` è®¿é—®



### 3ï¸âƒ£ é¡¹ç›®ä¼˜åŒ–å»ºè®®

#### Nexus & Harbor è´Ÿè½½å‡è¡¡

| **ç»„ä»¶**    | **è´Ÿè½½å‡è¡¡æ–¹å¼**                                         |
| ----------- | -------------------------------------------------------- |
| **Jenkins** | Nginx åå‘ä»£ç† + è´Ÿè½½å‡è¡¡                                |
| **Nexus**   | Nginx ä»£ç†ä»“åº“è¯·æ±‚                                       |
| **Harbor**  | **Harbor æœ¬èº«æ”¯æŒ HA**ï¼Œå¯ç”¨ **Keepalived + Nginx ä»£ç†** |
| **MySQL**   | **MySQL ä¸»ä» + ProxySQL è¯»å†™åˆ†ç¦»**                       |

ğŸ“Œ **é«˜å¹¶å‘ä¼˜åŒ–**

- **Harbor/Nexus éœ€è¦æŒä¹…åŒ–å­˜å‚¨**ï¼Œæ¨è **NFS/GlusterFS/MinIO**
- **Kubernetes StorageClass æä¾›åŠ¨æ€å­˜å‚¨**



#### Jenkins Master & Agent æ‹“å±•

**ç›®å‰ Jenkins åªæ”¯æŒå• Master + å¤š Agentï¼Œå¯ä»¥ä¼˜åŒ–ï¼š**

**Jenkins HAï¼ˆå¤š Masterï¼‰**

- ä½¿ç”¨ **Kubernetes Operator è¿è¡Œ Jenkins**
- **Jenkins Master + StatefulSet + PVC**

**Agent è¿è¡Œæ–¹å¼**

- **åŠ¨æ€ Agent**

```groovy
agent {
    kubernetes {
        yamlFile 'jenkins-agent.yaml'
    }
}
```

- **é™æ€ Agentï¼ˆç‰©ç†æœº / è™šæ‹Ÿæœºï¼‰**

```groovy
agent {
    label 'linux-node'
}
```



#### Jenkinsfile ç»“æ„ä¼˜åŒ–

ç›®å‰ä½ çš„ **Jenkinsfile æ˜¯æ‰€æœ‰åº”ç”¨å…±ç”¨ä¸€ä¸ª Pipeline**ï¼Œå¯ä»¥ä¼˜åŒ–æˆï¼š âœ… **æ‹†åˆ†å¤šä¸ª Jenkinsfile**

```bash
Jenkinsfile-java
Jenkinsfile-go
Jenkinsfile-node
```

 **ä¸€ä¸ª Pipeline é€‰æ‹©ä¸åŒçš„æ„å»ºæ–¹å¼**

```groovy
if (params.APP_TYPE == 'java') {
    buildJava()
} else if (params.APP_TYPE == 'go') {
    buildGo()
}
```



#### Kubernetes éƒ¨ç½²ä¼˜åŒ–

**HPA è‡ªåŠ¨æ‰©ç¼©å®¹**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 80
```



### 4ï¸âƒ£ ç»“è®º

| ä»»åŠ¡                    | æ–¹æ¡ˆ                        |
| ----------------------- | --------------------------- |
| **Jenkins ä»»åŠ¡ä¼˜åŒ–**    | å¤š Master + å¤š Agent        |
| **GitLab è§¦å‘ Jenkins** | WebHook + GitLab Runner     |
| **å­˜å‚¨ä¼˜åŒ–**            | Nexus å­˜åˆ¶å“ã€Harbor å­˜é•œåƒ |
| **ç›‘æ§**                | Prometheus + Grafana        |
| **æ—¥å¿—æ”¶é›†**            | Loki + Fluentd              |
| **K8s èµ„æºç®¡ç†**        | HPA è‡ªåŠ¨æ‰©ç¼©å®¹              |

ğŸš€ **æœ€ç»ˆï¼Œè¿™ä¸ª DevOps æ–¹æ¡ˆå¯ä»¥é«˜æ•ˆæ„å»ºã€æµ‹è¯•ã€å‘å¸ƒï¼Œæ”¯æŒé«˜å¯ç”¨ã€ç›‘æ§ã€è‡ªåŠ¨æ‰©å®¹ï¼Œé€‚åˆä¼ä¸šçº§ CI/CDï¼** ğŸš€





## ä¼ä¸šçº§ DevOps å…¨æµç¨‹è®¾è®¡

### ğŸ¯ ç›®æ ‡

âœ… **ä½¿ç”¨ Ansible è¿›è¡ŒåŸºç¡€è®¾æ–½è‡ªåŠ¨åŒ–éƒ¨ç½²**
âœ… **GitLab Webhook è§¦å‘ Jenkins Pipeline**ï¼Œè‡ªåŠ¨æ‰§è¡Œ Ansible Playbook
âœ… **Jenkins Pipeline æ”¯æŒåŠ¨æ€ Agentï¼Œæ ¹æ®åº”ç”¨ç±»å‹ï¼ˆJavaã€Goã€Node.jsï¼‰é€‰æ‹©ä¸åŒçš„æ„å»ºç¯å¢ƒ**
âœ… **åˆ¶å“ï¼ˆJARã€Go å¯æ‰§è¡Œæ–‡ä»¶ã€å‰ç«¯ tar.gzï¼‰ä¸Šä¼ åˆ° Nexus**ï¼ŒDocker é•œåƒå­˜å…¥ Harbor
âœ… **éƒ¨ç½²åˆ° Kubernetes**ï¼Œå¹¶æ”¯æŒ**è‡ªåŠ¨æ‰©ç¼©å®¹**
âœ… **æ—¥å¿—æ”¶é›†ä½¿ç”¨ ELKï¼ˆElasticsearch + Logstash + Kibanaï¼‰**ï¼Œå¹¶ç»“åˆ **Prometheus + Grafana** è¿›è¡Œç›‘æ§



### 1ï¸âƒ£ DevOps ç»„ä»¶æ¶æ„

```bash
+----------------------+
|  Developer Push Code |
+----------------------+
         |
         v
+---------------------+       +--------------------+
|  GitLab Repository |------>|  GitLab Webhook   |
+---------------------+       +--------------------+
         |                         |
         | (Triggers Jenkins)       | (Triggers CI/CD)
         v                         v
+-----------------------+   +------------------------+
|  Jenkins Master      |   |  Ansible (Infrastructure) |
+-----------------------+   +------------------------+
         |                         |
         v                         v
+-------------------------------+  +----------------------------+
|  Dynamic Jenkins Agent        |  |  Infrastructure Components |
|  (Build, Test, Package)       |  |  (Jenkins, GitLab, Nexus,  |
+-------------------------------+  |  Harbor, K8s, MySQL)        |
         |                          +----------------------------+
         v
+--------------------------+
|  Nexus (Traditional Artifacts)  |
+--------------------------+
         |
         v
+----------------------+
|  Harbor (Docker Images) |
+----------------------+
         |
         v
+------------------------+
|  Kubernetes (Deploy)  |
+------------------------+
         |
         v
+----------------------+
|  ELK (Logging)      |
+----------------------+
         |
         v
+----------------------------+
|  Prometheus + Grafana (Monitoring) |
+----------------------------+
```



### **2ï¸âƒ£ ç»„ä»¶åŠŸèƒ½**

| ç»„ä»¶                                         | ä½œç”¨                                               | è¿è¡Œæ–¹å¼                  |
| -------------------------------------------- | -------------------------------------------------- | ------------------------- |
| **GitLab**                                   | **ä»£ç ç®¡ç† & Webhook è§¦å‘ Jenkins**                | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**        |
| **Jenkins**                                  | **CI/CD ä»»åŠ¡è°ƒåº¦ & æ‰§è¡Œ Ansible**                  | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**        |
| **Ansible**                                  | **è‡ªåŠ¨åŒ–éƒ¨ç½² Jenkinsã€GitLabã€Nexusã€Harborã€K8s** | **Jenkins æ‰§è¡Œ Playbook** |
| **Nexus**                                    | **å­˜å‚¨ JARã€Go å¯æ‰§è¡Œæ–‡ä»¶ã€å‰ç«¯ tar.gz**           | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**        |
| **Harbor**                                   | **å­˜å‚¨ Docker é•œåƒ**                               | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**        |
| **Kubernetes**                               | **å®¹å™¨ç¼–æ’ & åº”ç”¨éƒ¨ç½²**                            | **K8s Cluster**           |
| **MySQL**                                    | **å­˜å‚¨ Jenkinsã€GitLabã€Harbor æ•°æ®**              | **K8s å¤–ç‹¬ç«‹éƒ¨ç½²**        |
| **ELKï¼ˆElasticsearch + Logstash + Kibanaï¼‰** | **æ”¶é›† & åˆ†æ CI/CD æ—¥å¿—**                         | **K8s å†…éƒ¨éƒ¨ç½²**          |
| **Prometheus + Grafana**                     | **ç›‘æ§ CI/CD & é¢„è­¦**                              | **K8s å†…éƒ¨éƒ¨ç½²**          |



### **3ï¸âƒ£ GitLab Webhook è§¦å‘ Jenkins**

**åœ¨ GitLab é…ç½® Webhook**ï¼Œè§¦å‘ Jenkinsï¼š

```http
http://jenkins.mycompany.com/project/deploy-ansible-pipeline
```

- **è§¦å‘äº‹ä»¶**ï¼š`Push Events`
- **Jenkins ç›‘å¬ Webhookï¼Œæ‰§è¡Œ Ansible Playbook**



### 4ï¸âƒ£ Jenkins Pipelineï¼ˆè§¦å‘ Ansible è‡ªåŠ¨éƒ¨ç½² CI/CD ç»„ä»¶ï¼‰

```groovy
pipeline {
    agent any

    stages {
        stage('Checkout Ansible Playbook') {
            steps {
                git branch: 'main', url: 'https://gitlab.mycompany.com/devops/ansible-playbooks.git'
            }
        }

        stage('Run Ansible Playbook') {
            steps {
                sh '''
                ansible-playbook -i inventory.ini playbook.yml \
                --extra-vars "env=prod"
                '''
            }
        }
    }
}
```



### 5ï¸âƒ£ Ansible Playbookï¼ˆè‡ªåŠ¨åŒ–éƒ¨ç½² CI/CD ç»„ä»¶ï¼‰

```yaml
- name: Deploy CI/CD Infrastructure
  hosts: all
  become: true
  tasks:
    - name: Install Docker
      apt:
        name: docker.io
        state: present

    - name: Install Kubernetes (k3s)
      shell: |
        curl -sfL https://get.k3s.io | sh -

    - name: Deploy Jenkins
      docker_container:
        name: jenkins
        image: jenkins/jenkins:lts
        ports:
          - "8080:8080"

    - name: Deploy GitLab
      docker_container:
        name: gitlab
        image: gitlab/gitlab-ce
        ports:
          - "80:80"

    - name: Deploy Nexus
      docker_container:
        name: nexus
        image: sonatype/nexus3
        ports:
          - "8081:8081"

    - name: Deploy Harbor
      docker_container:
        name: harbor
        image: goharbor/harbor-core
        ports:
          - "443:443"
```



### 6ï¸âƒ£ Jenkins Pipelineï¼ˆCI/CD æµç¨‹ï¼‰

**æ”¯æŒåŠ¨æ€ Agent ç¼–è¯‘ä¸åŒç±»å‹åº”ç”¨**

```groovy
pipeline {
    agent none
    parameters {
        choice(name: 'APP_TYPE', choices: ['java', 'go', 'node'], description: 'Choose the application type')
    }
    environment {
        NEXUS_URL = 'http://nexus.mycompany.com/repository'
        HARBOR_URL = 'harbor.mycompany.com'
        IMAGE_NAME = "mycompany/${params.APP_TYPE}-app"
    }

    stages {
        stage('Build & Upload to Nexus') {
            agent { docker 'maven:3.8.5' }
            steps {
                sh 'mvn clean package -DskipTests'
                sh "curl -u user:password --upload-file target/my-app.jar ${NEXUS_URL}/maven-releases/com/mycompany/app/my-app.jar"
            }
        }

        stage('Build & Push Docker Image to Harbor') {
            agent { docker 'docker:24.0.5' }
            steps {
                sh """
                    docker build -t ${HARBOR_URL}/${IMAGE_NAME}:latest .
                    docker login ${HARBOR_URL} -u admin -p Harbor12345
                    docker push ${HARBOR_URL}/${IMAGE_NAME}:latest
                """
            }
        }

        stage('Deploy to Kubernetes') {
            agent { docker 'bitnami/kubectl' }
            steps {
                sh "kubectl set image deployment/${params.APP_TYPE}-app ${params.APP_TYPE}-app=${HARBOR_URL}/${IMAGE_NAME}:latest"
            }
        }
    }
}
```



### 7ï¸âƒ£ ç›‘æ§ & æ—¥å¿—

#### **ğŸ”¹ æ—¥å¿—æ”¶é›†ï¼ˆELKï¼‰**

ğŸ“Œ **`logstash.conf`**

```
plaintextCopyEditinput {
  file {
    path => "/var/log/jenkins/jenkins.log"
    type => "jenkins"
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
  }
}
```

#### **ğŸ”¹ ç›‘æ§**

| ç›‘æ§é¡¹              | é‡‡é›†æ–¹å¼             |
| ------------------- | -------------------- |
| **Jenkins çŠ¶æ€**    | `Jenkins Exporter`   |
| **Kubernetes çŠ¶æ€** | `kube-state-metrics` |
| **Nexus å­˜å‚¨æƒ…å†µ**  | `Nexus Exporter`     |
| **Harbor é•œåƒæƒ…å†µ** | `Harbor Exporter`    |



### **8ï¸âƒ£ ç»“è®º**

ğŸš€ **ä½ çš„ DevOps æ–¹æ¡ˆå®ç°äº†å®Œæ•´çš„è‡ªåŠ¨åŒ–ï¼š**

- **Ansible è‡ªåŠ¨éƒ¨ç½² CI/CD ç»„ä»¶**
- **GitLab Webhook è§¦å‘ Jenkins**
- **CI/CD æµç¨‹æ”¯æŒåŠ¨æ€ Agent**
- **åˆ¶å“å­˜å…¥ Nexusï¼ŒDocker é•œåƒå­˜å…¥ Harbor**
- **Kubernetes è‡ªåŠ¨éƒ¨ç½²**
- **ELK + Prometheus ç›‘æ§æ—¥å¿— & è¿è¡ŒçŠ¶æ€**



## æ­å»º Prometheus ç›‘æ§ç¯å¢ƒï¼Œä½¿ç”¨ SNMP Exporter ç›‘æ§äº¤æ¢æœº

ä½¿ç”¨ **Prometheus + SNMP Exporter** æ¥ç›‘æ§ **äº¤æ¢æœºï¼ˆSwitchï¼‰**ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„ **ç½‘ç»œè®¾å¤‡ç›‘æ§æ–¹æ¡ˆ**

**ç›®æ ‡**

- **æ­å»º Prometheus ç›‘æ§ç¯å¢ƒ**
- **ä½¿ç”¨ SNMP Exporter è·å–äº¤æ¢æœºæ•°æ®**
- **é…ç½® Prometheus é‡‡é›† SNMP æ•°æ®**
- **åœ¨ Grafana å¯è§†åŒ–äº¤æ¢æœºæŒ‡æ ‡**



### SNMP ç›‘æ§äº¤æ¢æœºçš„åŸç†

**SNMPï¼ˆSimple Network Management Protocolï¼Œç®€å•ç½‘ç»œç®¡ç†åè®®ï¼‰** æ˜¯ç½‘ç»œè®¾å¤‡ï¼ˆå¦‚ **äº¤æ¢æœºã€è·¯ç”±å™¨ã€é˜²ç«å¢™**ï¼‰çš„æ ‡å‡†ç›‘æ§åè®®ã€‚

**SNMP Exporter** è´Ÿè´£ï¼š

- **ä»äº¤æ¢æœº SNMP ç«¯å£æŠ“å–æ•°æ®**
- **è½¬æ¢æˆ Prometheus å¯è¯†åˆ«çš„æ ¼å¼**
- **Prometheus å®šæœŸæŠ“å–å¹¶å­˜å‚¨æ•°æ®**

**ç›‘æ§ç¤ºæ„å›¾**

```lua
+------------------------+        +----------------+        +-----------------+
|  äº¤æ¢æœºï¼ˆSNMP è®¾å¤‡ï¼‰   | ----> | SNMP Exporter  | ----> |  Prometheus  |
+------------------------+        +----------------+        +-----------------+
                                                         |
                                                         V
                                                     +-----------+
                                                     |  Grafana  |
                                                     +-----------+
```



### Prometheus ä½¿ç”¨ SNMP_exporter æŠ“å–äº¤æ¢æœºæŒ‡æ ‡çš„è¯¦ç»†æµç¨‹

**Prometheus æŒ‰ç…§ `prometheus.yml` é‡Œçš„ `targets` å‘é€ HTTP è¯·æ±‚åˆ° `snmp_exporter`**

- `prometheus.yml` é‡Œé…ç½®

  ```yaml
  scrape_configs:
    - job_name: 'snmp_huawei_switch'
      static_configs:
        - targets:
          - "192.168.1.1"  # äº¤æ¢æœº A
          - "192.168.1.2"  # äº¤æ¢æœº B
      metrics_path: /snmp
      params:
        module: [huawei_acc]  # é‡‡é›†è§„åˆ™ï¼Œsnmp_exporter ä¼šç”¨å®ƒåŒ¹é… yml æ–‡ä»¶
      relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - target_label: instance
          source_labels: [__address__]
        - target_label: __address__
          replacement: "localhost:9116"  # Prometheus ç›´æ¥è¯·æ±‚æœ¬æœºçš„ snmp_exporte
  ```

- `Prometheus` æœ€ç»ˆä¼šè¯·æ±‚

  ```bash
  http://localhost:9116/snmp?module=huawei_acc&target=192.168.1.1
  http://localhost:9116/snmp?module=huawei_acc&target=192.168.1.2
  ```

- `localhost:9116` æ˜¯ `snmp_exporter`ï¼Œå®ƒä¼šè§£æ `target=192.168.1.1`ï¼Œç„¶åå»è®¿é—® `192.168.1.1` çš„ SNMP ç«¯å£

**`snmp_exporter` æ”¶åˆ°è¯·æ±‚åï¼ŒæŒ‰ç…§ `snmp_huawei_switch.yml` é‡Œçš„ `modules` è§„åˆ™å»æŠ“å– `OID` æ•°æ®**

- **ä¾‹å¦‚**

  ```yaml
  modules:
    huawei_acc:
      walk:
      - 1.3.6.1.2.1.2.2.1.13
      - 1.3.6.1.2.1.2.2.1.14
      get:
      - 1.3.6.1.4.1.2011.5.25.42.2.1.1.0
  ```

- `snmp_exporter` çŸ¥é“ **ç›®æ ‡ IP æ˜¯ `192.168.1.1`**ï¼Œç„¶åå®ƒä¼š

  - **å‘ `192.168.1.1:161` å‘é€ SNMP è¯·æ±‚**
  -  **`walk` å’Œ `get` æŒ‡å®šçš„ `OID` æŠ“å– SNMP æŒ‡æ ‡**
  - **è¿”å›ç»™ `Prometheus`**

**Prometheus æ”¶åˆ° `snmp_exporter` é‡‡é›†çš„æ•°æ®ï¼Œå¹¶å­˜å…¥æ—¶åºæ•°æ®åº“**

- ä½ å¯ä»¥åœ¨ Prometheus UI (`http://localhost:9090/targets`) æŸ¥çœ‹ `snmp_exporter` æ˜¯å¦æ­£å¸¸è¿”å›æ•°æ®ã€‚



### éƒ¨ç½² SNMP Exporter

SNMP Exporter éœ€è¦ **`snmp.yml`** æ–‡ä»¶æ¥å®šä¹‰ç›‘æ§é¡¹ï¼Œé»˜è®¤ä¸åŒ…å« **äº¤æ¢æœº** é…ç½®ï¼Œä½ éœ€è¦ç”Ÿæˆã€‚

#### ç¼–è¯‘ç”Ÿæˆ generator äºŒè¿›åˆ¶æ–‡ä»¶ å’Œ snmp_exporter äºŒè¿›åˆ¶æ–‡ä»¶

æºç ç¼–è¯‘ generator ç”¨æ¥ç”Ÿæˆ **`snmp_*.yml`** æ–‡ä»¶

```bash
# clone æºç 
[root@ubuntu2204 ~]# git clone https://github.com/prometheus/snmp_exporter.git

[root@ubuntu2204 ~]#cd snmp_exporter
[root@ubuntu2204 snmp_exporter]#ls
auth-split-migration.md  config_test.go   go.mod          Makefile         SECURITY.md
CHANGELOG.md             CONTRIBUTING.md  go.sum          Makefile.common  snmp-mixin
CODE_OF_CONDUCT.md       Dockerfile       LICENSE         NOTICE           snmp.yml
collector                examples         main.go         README.md        testdata
config                   generator        MAINTAINERS.md  scraper          VERSION

# æŸ¥çœ‹ç‰ˆæœ¬
[root@ubuntu2204 snmp_exporter]#cat VERSION 
0.28.0

# æ³¨æ„: å› ä¸ºè¿™é‡Œçš„ç‰ˆæœ¬æ˜¯0.28.0ï¼Œå› æ­¤åç»­ç”Ÿæˆçš„snmp.ymlï¼Œéœ€è¦â€œsnmp_exporter-0.28.0â€æ‰§è¡Œï¼Œå¦åˆ™ä¼šæŠ¥é”™
# æŠ¥é”™å†…å®¹å¦‚ä¸‹ï¼Œå³æ— æ³•å†config.plainé‡Œæ‰¾åˆ°å¯¹åº”çš„æ¨¡å—
level=info ts=2025-03-08T05:08:46.677Z caller=main.go:149 msg="Starting snmp_exporter" version="(version=bc02f59648b21fcf632de1b62a30df70f4649)"
level=info ts=2025-03-08T05:08:46.677Z caller=main.go:150 build_context="(go=go1.14.7, user=root@387afaad
level=error ts=2025-03-08T05:08:46.679Z caller=main.go:156 msg="Error parsing config file" err="yaml: unmublic_v2 not found in type config.plain\n  line 10: field huawei_acc not found in type config.plain\n  lid in type config.plain\n  line 717: field huawei_common not found in type config.plain\n  line 889: fieldnfig.plain"

# æŸ¥çœ‹å»ºè®®ç¼–è¯‘ç‰ˆæœ¬
[root@ubuntu2204 snmp_exporter]# cat go.mod | grep go
go 1.22
toolchain go1.23.1
	github.com/gosnmp/gosnmp v1.38.0
	github.com/itchyny/timefmt-go v0.1.6
	github.com/prometheus/client_golang v1.21.0
	gopkg.in/yaml.v2 v2.4.0
	github.com/coreos/go-systemd/v22 v22.5.0 // indirect
	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
	github.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f // indirect
	github.com/xhit/go-str2duration/v2 v2.1.0 // indirect
	golang.org/x/crypto v0.32.0 // indirect
	golang.org/x/net v0.33.0 // indirect
	golang.org/x/oauth2 v0.24.0 // indirect
	golang.org/x/sync v0.10.0 // indirect
	golang.org/x/sys v0.29.0 // indirect
	golang.org/x/text v0.21.0 // indirect
	google.golang.org/protobuf v1.36.1 // indirect

# ä¸Šè¿°è¯´æ˜æ¨è Go 1.22.1+ æˆ– Go 1.23.1

# éƒ¨ç½²GOè¯­è¨€ç¼–è¯‘ç¯å¢ƒ
[root@ubuntu2204 snmp_exporter]# wget -P /usr/local/src https://go.dev/dl/go1.23.1.linux-amd64.tar.gz
[root@ubuntu2204 snmp_exporter]# tar xf /usr/local/src/go1.23.1.linux-amd64.tar.gz -C /usr/local

# /etc/profileæ–‡ä»¶ä¸‹æ·»åŠ ä¸‰æ¡è¯­å¥
[root@ubuntu2204 snmp_exporter]# vim /etc/profile
export GOROOT=/usr/local/go
export PATH=$PATH:$GOROOT/bin
export GOPATH=$HOME/goprojects

[root@ubuntu2204 snmp_exporter]# . /etc/profile

# æ£€æŸ¥go
[root@ubuntu2204 snmp_exporter]# go version
go version go1.23.1 linux/amd64

# generatoræ˜¯äº¤å‰ç¼–è¯‘ï¼Œå› æ­¤é™¤äº†goä¹‹å¤–ï¼Œè¿˜è¦ä¸‹è½½gccå’Œlibsnmp-dev
[root@ubuntu2204 generator]# apt install -y gcc
[root@ubuntu2204 generator]# apt install -y libsnmp-dev

# goç¼–è¯‘
[root@ubuntu2204 snmp_exporter]# go build .

# æŸ¥çœ‹ç¼–è¯‘ç»“æœ
[root@ubuntu2204 snmp_exporter]# ls
auth-split-migration.md  CONTRIBUTING.md  LICENSE          README.md      testdata
CHANGELOG.md             Dockerfile       main.go          scraper        VERSION
CODE_OF_CONDUCT.md       examples         MAINTAINERS.md   SECURITY.md
collector                generator        Makefile         snmp_exporter #ï¼ˆç¼–è¯‘çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼‰
config                   go.mod           Makefile.common  snmp-mixin
config_test.go           go.sum           NOTICE           snmp.yml

[root@ubuntu2204 snmp_exporter]# cd generator/
[root@ubuntu2204 generator]# go build .
[root@ubuntu2204 generator]#ls
config.go   Dockerfile-local  generator #ï¼ˆç¼–è¯‘çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼‰      
huawei   Makefile  net_snmp.go  test.sh  tree_test.go
Dockerfile  FORMAT.md         generator.yml  main.go  mibs      README.md    tree.go
```



#### å¯¼å…¥ MIB ä½¿ç”¨  generator ç”Ÿæˆ snmp_*.yml é…ç½®æ–‡ä»¶

```bash
[root@ubuntu2204 ~]# cd snmp_exporter/generator
[root@ubuntu2204 generator]# mkdir -pv huawei/mibs/switch
[root@ubuntu2204 generator]# mkdir -pv huawei/switch

# /root/snmp_exporter/generator/huawei/mibs/switch ç›®å½•ä¸­éœ€è¦æ”¾ç½® MIB åç¼€çš„ MIB æ–‡ä»¶
[root@ubuntu2204 switch]# ls
ATM-TC-MIB.mib                         HUAWEI-QINQ-MIB.mib
BGP4-MIB.mib                           HUAWEI-RIPV2-EXT-MIB.mib
BRIDGE-MIB.mib                         HUAWEI-RM-EXT-MIB.mib
DIFFSERV-DSCP-TC.mib                   HUAWEI-RRPP-MIB.mib
DIFFSERV-MIB.mib                       HUAWEI-RSVPTE-MIB.mib
DISMAN-NSLOOKUP-MIB.mib                HUAWEI-RUMNG-MIB.mib
DISMAN-PING-MIB.mib                    HUAWEI-SECURITY-IPSEC-MIB.mib
DISMAN-TRACEROUTE-MIB.mib              HUAWEI-SECURITY-MIB.mib
ENTITY-MIB.mib                         HUAWEI-SECURITY-PKI-MIB.mib
......

# /root/snmp_exporter/generator/huawei/switch ç›®å½•ä¸­éœ€è¦æ”¾ç½® generator_huawei_switch.yml ç”Ÿæˆå™¨é…ç½®æ–‡ä»¶ 
```

#### **generator_huawei_switch.yml é…ç½®æ–‡ä»¶**

```bash
[root@ubuntu2204 generator]# vim huawei/switch/generator_huawei_switch.yml
auths:
  public_v2:  # è®¤è¯æ¨¡å—åç§°
    version: 2  # snmp v2cç‰ˆæœ¬
    community: public  # snmp å›¢ä½“å

modules:
  huawei_common:  # åä¸ºå…¬å…±æŒ‡æ ‡æ¨¡å—åç§°
    walk:
      # äº¤æ¢æœºåŸºç¡€ä¿¡æ¯ æ¸©åº¦ä¿¡æ¯ é£æ‰‡ä¿¡æ¯ ç”µæºä¿¡æ¯
      - 1.3.6.1.2.1.1.1                       # sysDescr ç³»ç»Ÿçš„æ–‡å­—æè¿°
      - 1.3.6.1.2.1.1.5                       # sysName äº¤æ¢æœºåç§°
      - 1.3.6.1.4.1.2011.5.25.31.1.1.6.1.1    # hwEntPowerUsedInfoBoardName æ¿å¡å®ä½“åç§°
      - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.10   # hwEntityUpTime æ¿å¡å®ä½“å¯åŠ¨æ—¶é—´ å•ä½ç§’
      - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.11   # hwEntityTemperature å®ä½“æ¸©åº¦ å•ä½Â°C
      - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.12   # hwEntityTemperatureThreshold å®ä½“æ¸©åº¦é«˜é—¨é™ å•ä½Â°C
      - 1.3.6.1.4.1.2011.5.25.31.1.1.10.1.7   # hwEntityFanState é£æ‰‡çŠ¶æ€
      - 1.3.6.1.4.1.2011.5.25.31.1.1.10.1.6   # hwEntityFanPresent é£æ‰‡çš„åœ¨ä½çŠ¶æ€
      - 1.3.6.1.4.1.2011.5.25.31.1.1.10.1.5   # hwEntityFanSpeed é£æ‰‡çš„è½¬é€Ÿ
      #- 1.3.6.1.4.1.2011.5.25.31.1.1.18.1.1  # hwEntityPwrSlot ç”µæºçš„æ§½ä½å·
      - 1.3.6.1.4.1.2011.5.25.31.1.1.18.1.6   # hwEntityPwrState ç”µæºçš„çŠ¶æ€
      - 1.3.6.1.4.1.2011.6.157.1.6            # hwCurrentPower å½“å‰åŠŸç‡mW
      - 1.3.6.1.4.1.2011.6.157.1.3            # hwAveragePower å¹³å‡åŠŸç‡mW
      # äº¤æ¢æœºCPUå’Œå†…å­˜ä¿¡æ¯
      - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.5    # hwEntityCpuUsage å®ä½“CPUä½¿ç”¨ç‡
      - 1.3.6.1.4.1.2011.5.25.31.1.1.1.1.7    # hwEntityMemUsage å®ä½“å†…å­˜ä½¿ç”¨ç‡
      - 1.3.6.1.4.1.2011.6.9.1.4.2.1.3        # hwStorageSpace Flashè®¾å¤‡ç©ºé—´çš„å¤§å° å•ä½æ˜¯åƒå­—èŠ‚
      - 1.3.6.1.4.1.2011.6.9.1.4.2.1.4        # hwStorageSpaceFree Flashè®¾å¤‡å‰©ä½™ç©ºé—´ å•ä½æ˜¯åƒå­—èŠ‚
      - 1.3.6.1.4.1.2011.6.9.1.4.2.1.5        # hwStorageName Flashè®¾å¤‡åç§°
      #- 1.3.6.1.4.1.2011.6.3.4.1.2            # hwCpuDevDuty 5ç§’é’Ÿå†…çš„CPUçš„å¹³å‡ä½¿ç”¨ç‡
      #- 1.3.6.1.4.1.2011.6.3.4.1.3            # hwCpuDuty1min 1åˆ†é’Ÿå†…çš„CPUçš„å¹³å‡ä½¿ç”¨ç‡
      #- 1.3.6.1.4.1.2011.6.3.4.1.4            # hwCpuDuty5min 5åˆ†é’Ÿå†…çš„CPUçš„å¹³å‡ä½¿ç”¨ç‡
      #- 1.3.6.1.4.1.2011.6.3.5.1.1.2          # hwMemoryDevSize æ¯å—æ¿ä¸Šå†…å­˜æ€»é‡
      #- 1.3.6.1.4.1.2011.6.3.5.1.1.3          # hwMemoryDevFree æ¯å—æ¿ä¸Šç©ºé—²çš„å†…å­˜æ€»é‡
      #- 1.3.6.1.4.1.2011.6.3.5.1.1.4          # hwMemoryDevRawSliceUsed æ¯å—æ¿ä¸Šå·²å ç”¨çš„raw sliceå†…å­˜æ€»é‡

    max_repetitions: 50
    retries: 3
    timeout: 5s

    lookups:
      - source_indexes: [hwEntityFanSlot, hwEntityFanSn]
        lookup: hwEntityFanPresent
      - source_indexes: [hwEntityFanSlot, hwEntityFanSn]
        lookup: hwEntityFanState
      - source_indexes: [entPhysicalIndex]
        lookup: 1.3.6.1.4.1.2011.5.25.31.1.1.6.1.1
        #drop_source_indexes: true
      - source_indexes: [hwStorageIndex]
        lookup: hwStorageName

    overrides:
      hwEntityFanPresent:
        ignore: true
      hwEntityFanState:
        ignore: true
      hwEntPowerUsedInfoBoardName:
        ignore: true
        type: DisplayString
      hwStorageName:
        ignore: true
        type: DisplayString
  
  huawei_core:  # åä¸ºæ ¸å¿ƒäº¤æ¢æœºæ¨¡å—æŒ‡æ ‡ åŸºäºCloudEngine S12700E-4
    walk:
      # æ¥å£ä¿¡æ¯
      #- 1.3.6.1.2.1.2.2.1.1                  # ifIndex æ¥å£ç´¢å¼• è¯¥å€¼å¤§äºé›¶ä¸”å…¨å±€å”¯ä¸€
      #- 1.3.6.1.2.1.2.2.1.2                  # ifDescr æè¿°æ¥å£çš„å­—ç¬¦ä¸²
      - 1.3.6.1.2.1.31.1.1.1.1                # ifName ç”±æœ¬åœ°è®¾å¤‡åˆ†é…çš„æ¥å£å åŒä¸ŠæŒ‡æ ‡ å–å…¶ä¸­ä¹‹ä¸€
      - 1.3.6.1.2.1.2.2.1.7                   # ifAdminStatus ç†æƒ³çš„æ¥å£çŠ¶æ€
      - 1.3.6.1.2.1.2.2.1.8                   # ifOperStatus æ¥å£å½“å‰çš„çŠ¶æ€
      - 1.3.6.1.2.1.31.1.1.1.18               # ifAlias è¯¥èŠ‚ç‚¹æ˜¯ç”±ç½‘ç»œç®¡ç†å‘˜æŒ‡å®šçš„æ¥å£åˆ«å descriptionå‘½ä»¤
      - 1.3.6.1.2.1.31.1.1.1.15               # ifHighSpeed æ¥å£å½“å‰å¸¦å®½ å•ä½ Mbit/s
      - 1.3.6.1.2.1.31.1.1.1.6                # ifHCInOctets æ¥å£ä¸Šæ¥æ”¶åˆ°çš„å­—èŠ‚æ€»æ•° byte/s
      - 1.3.6.1.2.1.31.1.1.1.10               # ifHCOutOctets æ¥å£å‘é€çš„å­—èŠ‚æ€»æ•° byte/s
      - 1.3.6.1.2.1.2.2.1.13                  # ifInDiscards å…¥æ–¹å‘çš„è¢«ä¸¢å¼ƒçš„æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.19                  # ifOutDiscards å‡ºæ–¹å‘çš„è¢«ä¸¢å¼ƒçš„æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.14                  # ifInErrors å…¥æ–¹å‘å‡ºé”™æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.20                  # ifOutErrors å‡ºæ–¹å‘å‡ºé”™æŠ¥æ–‡ä¸ªæ•°
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.2    # hwIfMonitorCrcErrorStatistics CRCé”™åŒ…ç»Ÿè®¡å€¼
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.8    # hwIfMonitorInputRate æ¥å£å…¥æ–¹å‘å¸¦å®½å ç”¨ç‡
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.10   # hwIfMonitorOutputRate æ¥å£å‡ºæ–¹å‘å¸¦å®½å ç”¨ç‡

      # å…‰æ¨¡å—ä¿¡æ¯
      #- 1.3.6.1.2.1.47.1.1.1.1.1             # entPhysicalIndex ç‰©ç†å®ä½“ç´¢å¼•
      - 1.3.6.1.2.1.47.1.1.1.1.7              # entPhysicalName ç‰©ç†å®ä½“å å…‰æ¨¡å—æ¥å£åç§°
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.8    # hwEntityOpticalRxPower å…‰æ¨¡å—æ¥æ”¶åŠŸç‡ å•ä½ uW
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.9    # hwEntityOpticalTxPower å…‰æ¨¡å—å‘é€åŠŸç‡ å•ä½ uW
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.20   # hwEntityOpticalRxLowWarnThreshold å…‰æ¨¡å—æ¥æ”¶åŠŸç‡è¿‡ä½çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.21   # hwEntityOpticalRxHighWarnThreshold å…‰æ¨¡å—æ¥æ”¶åŠŸç‡è¿‡é«˜çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.22   # hwEntityOpticalTxLowWarnThreshold å…‰æ¨¡å—å‘é€åŠŸç‡è¿‡ä½çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.23   # hwEntityOpticalTxHighWarnThreshold å…‰æ¨¡å—å‘é€åŠŸç‡è¿‡é«˜çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      # CSSé›†ç¾¤çŠ¶æ€ 
      - 1.3.6.1.4.1.2011.5.25.183.3.1.1       # hwCssEnable ä½¿èƒ½è®¾å¤‡é›†ç¾¤åŠŸèƒ½
      - 1.3.6.1.4.1.2011.5.25.183.3.2.1.8     # hwCssMemberRole é›†ç¾¤è§’è‰²
      - 1.3.6.1.4.1.2011.5.25.183.3.2.1.7     # hwCssMemberConfigEnable é›†ç¾¤ä½¿èƒ½çŠ¶æ€
      - 1.3.6.1.4.1.2011.5.25.42.2.1.14       # hwMacGlobalStatistics è·å–è®¾å¤‡ä¸Šçš„MACåœ°å€æ•°
      - 1.3.6.1.4.1.2011.5.25.42.2.1.1        # hwL2MaxMacLimit MACåœ°å€é™å®šçš„æœ€å¤§è§„åˆ™æ•°
    
    max_repetitions: 50
    retries: 3
    timeout: 5s
    
    lookups:
      - source_indexes: [ifIndex]
        lookup: ifAlias
        # å¦‚æœæ–°çš„ç´¢å¼•å”¯ä¸€ å¯ä»¥åˆ é™¤åŸæ¥çš„ç´¢å¼• true
        #drop_source_indexes: false
      - source_indexes: [ifIndex]
        lookup: ifName
      - source_indexes: [ifIndex]
        lookup: ifOperStatus
      - source_indexes: [ifIndex]
        lookup: ifHighSpeed
      - source_indexes: [entPhysicalIndex]
        lookup: entPhysicalName
    
    overrides:
      ifAlias:
        ignore: true # æŸ¥æ‰¾çš„æŒ‡æ ‡åœ¨snmp_exporterè¾“å‡ºæ§åˆ¶å°ç›´æ¥ä¸æ˜¾ç¤ºè¯¥æŒ‡æ ‡
        #regex_extracts:  # æ ¹æ®æ­£åˆ™è¡¨è¾¾å¼å’ŒæŒ‡æ ‡å€¼åˆ›å»ºæ–°æŒ‡æ ‡
        #   Temp: 
        #     - regex: '(.*)' # æ­£åˆ™è¡¨è¾¾å¼ä»è¿”å›çš„ SNMP walks å€¼ä¸­æå–ä¸€ä¸ªå€¼
        #       value: '$1' # ç»“æœå°†è¢«è§£æä¸º float64ï¼Œé»˜è®¤ä¸º $1
        #   Status:
        #     - regex: '.*Example'
        #       value: '1' # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä¸”å€¼è§£æçš„ç¬¬ä¸€ä¸ªæ¡ç›®è·èƒœ
        #     - regex: '.*'
        #       value: '0'
        #type: DisplayString
      ifName:
        ignore: true
      ifOperStatus:
        ignore: true
      ifHighSpeed:
        ignore: true
      entPhysicalName:
        ignore: true
    
    filters:
      # static:
      #   - targets:
      #     - ifIndex
      #     indices: ["2","3","4"]
      dynamic:  # æ ¹æ®æ¥å£å½“å‰çŠ¶æ€æ”¶é›†æ¥å£æŒ‡æ ‡
        - oid: 1.3.6.1.2.1.2.2.1.7
          targets:
            - "1.3.6.1.2.1.31.1.1.1.6"
            - "1.3.6.1.2.1.31.1.1.1.10"
            - "1.3.6.1.2.1.2.2.1.13"
            - "1.3.6.1.2.1.2.2.1.19"
            - "1.3.6.1.2.1.2.2.1.14"
            - "1.3.6.1.2.1.2.2.1.20"
          values: ["1"]
  
  huawei_agg:  # åä¸ºæ±‡èšå’Œæ¥å…¥äº¤æ¢æœºæ¨¡å—æŒ‡æ ‡
    walk:
      # æ¥å£ä¿¡æ¯
      #- 1.3.6.1.2.1.2.2.1.1                  # ifIndex æ¥å£ç´¢å¼• è¯¥å€¼å¤§äºé›¶ä¸”å…¨å±€å”¯ä¸€
      #- 1.3.6.1.2.1.2.2.1.2                  # ifDescr æè¿°æ¥å£çš„å­—ç¬¦ä¸²
      - 1.3.6.1.2.1.31.1.1.1.1                # ifName ç”±æœ¬åœ°è®¾å¤‡åˆ†é…çš„æ¥å£å åŒä¸ŠæŒ‡æ ‡ å–å…¶ä¸­ä¹‹ä¸€
      - 1.3.6.1.2.1.2.2.1.7                   # ifAdminStatus ç†æƒ³çš„æ¥å£çŠ¶æ€
      - 1.3.6.1.2.1.2.2.1.8                   # ifOperStatus æ¥å£å½“å‰çš„çŠ¶æ€
      - 1.3.6.1.2.1.31.1.1.1.18               # ifAlias è¯¥èŠ‚ç‚¹æ˜¯ç”±ç½‘ç»œç®¡ç†å‘˜æŒ‡å®šçš„æ¥å£åˆ«å descriptionå‘½ä»¤
      - 1.3.6.1.2.1.31.1.1.1.15               # ifHighSpeed æ¥å£å½“å‰å¸¦å®½ å•ä½ Mbit/s
      - 1.3.6.1.2.1.31.1.1.1.6                # ifHCInOctets æ¥å£ä¸Šæ¥æ”¶åˆ°çš„å­—èŠ‚æ€»æ•° byte/s
      - 1.3.6.1.2.1.31.1.1.1.10               # ifHCOutOctets æ¥å£å‘é€çš„å­—èŠ‚æ€»æ•° byte/s
      - 1.3.6.1.2.1.2.2.1.13                  # ifInDiscards å…¥æ–¹å‘çš„è¢«ä¸¢å¼ƒçš„æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.19                  # ifOutDiscards å‡ºæ–¹å‘çš„è¢«ä¸¢å¼ƒçš„æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.14                  # ifInErrors å…¥æ–¹å‘å‡ºé”™æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.20                  # ifOutErrors å‡ºæ–¹å‘å‡ºé”™æŠ¥æ–‡ä¸ªæ•°
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.2    # hwIfMonitorCrcErrorStatistics CRCé”™åŒ…ç»Ÿè®¡å€¼
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.8    # hwIfMonitorInputRate æ¥å£å…¥æ–¹å‘å¸¦å®½å ç”¨ç‡
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.10   # hwIfMonitorOutputRate æ¥å£å‡ºæ–¹å‘å¸¦å®½å ç”¨ç‡

      # å…‰æ¨¡å—ä¿¡æ¯
      #- 1.3.6.1.2.1.47.1.1.1.1.1             # entPhysicalIndex ç‰©ç†å®ä½“ç´¢å¼•
      - 1.3.6.1.2.1.47.1.1.1.1.7              # entPhysicalName ç‰©ç†å®ä½“å å…‰æ¨¡å—æ¥å£åç§°
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.8    # hwEntityOpticalRxPower å…‰æ¨¡å—æ¥æ”¶åŠŸç‡ å•ä½ uW
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.9    # hwEntityOpticalTxPower å…‰æ¨¡å—å‘é€åŠŸç‡ å•ä½ uW
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.20   # hwEntityOpticalRxLowWarnThreshold å…‰æ¨¡å—æ¥æ”¶åŠŸç‡è¿‡ä½çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.21   # hwEntityOpticalRxHighWarnThreshold å…‰æ¨¡å—æ¥æ”¶åŠŸç‡è¿‡é«˜çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.22   # hwEntityOpticalTxLowWarnThreshold å…‰æ¨¡å—å‘é€åŠŸç‡è¿‡ä½çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.23   # hwEntityOpticalTxHighWarnThreshold å…‰æ¨¡å—å‘é€åŠŸç‡è¿‡é«˜çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      # å †å çŠ¶æ€ 
      - 1.3.6.1.4.1.2011.5.25.183.1.1         # hwStackRun å †å æ˜¯å¦ä½¿èƒ½
      - 1.3.6.1.4.1.2011.5.25.183.1.2         # hwStackTopoType ç¯å½¢æ‹“æ‰‘è¿˜æ˜¯é“¾å¼æ‹“æ‰‘
      - 1.3.6.1.4.1.2011.5.25.183.1.4         # hwStackSystemMac å †å ç³»ç»ŸMAC
      - 1.3.6.1.4.1.2011.5.25.183.1.5         # hwStackIsStackDevice è®¾å¤‡æ˜¯å¦åœ¨å †å ç¯å¢ƒ
      - 1.3.6.1.4.1.2011.5.25.42.2.1.14       # hwMacGlobalStatistics è·å–è®¾å¤‡ä¸Šçš„MACåœ°å€æ•°
      - 1.3.6.1.4.1.2011.5.25.42.2.1.1        # hwL2MaxMacLimit MACåœ°å€é™å®šçš„æœ€å¤§è§„åˆ™æ•°
    
    max_repetitions: 50
    retries: 3
    timeout: 5s
    
    lookups:
      - source_indexes: [ifIndex]
        lookup: ifAlias
        # å¦‚æœæ–°çš„ç´¢å¼•å”¯ä¸€ å¯ä»¥åˆ é™¤åŸæ¥çš„ç´¢å¼• true
        #drop_source_indexes: false
      - source_indexes: [ifIndex]
        lookup: ifName
      - source_indexes: [ifIndex]
        lookup: ifOperStatus
      - source_indexes: [ifIndex]
        lookup: ifHighSpeed
      - source_indexes: [entPhysicalIndex]
        lookup: entPhysicalName
    
    overrides:
      ifAlias:
        ignore: true # æŸ¥æ‰¾çš„æŒ‡æ ‡åœ¨snmp_exporterè¾“å‡ºæ§åˆ¶å°ç›´æ¥ä¸æ˜¾ç¤ºè¯¥æŒ‡æ ‡
        #regex_extracts:  # æ ¹æ®æ­£åˆ™è¡¨è¾¾å¼å’ŒæŒ‡æ ‡å€¼åˆ›å»ºæ–°æŒ‡æ ‡
        #   Temp: 
        #     - regex: '(.*)' # æ­£åˆ™è¡¨è¾¾å¼ä»è¿”å›çš„ SNMP walks å€¼ä¸­æå–ä¸€ä¸ªå€¼
        #       value: '$1' # ç»“æœå°†è¢«è§£æä¸º float64ï¼Œé»˜è®¤ä¸º $1
        #   Status:
        #     - regex: '.*Example'
        #       value: '1' # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä¸”å€¼è§£æçš„ç¬¬ä¸€ä¸ªæ¡ç›®è·èƒœ
        #     - regex: '.*'
        #       value: '0'
        #type: DisplayString
      ifName:
        ignore: true
      ifOperStatus:
        ignore: true
      ifHighSpeed:
        ignore: true
      entPhysicalName:
        ignore: true
    
    filters:
      # static:
      #   - targets:
      #     - ifIndex
      #     indices: ["2","3","4"]
      dynamic:  # æ ¹æ®æ¥å£å½“å‰çŠ¶æ€æ”¶é›†æ¥å£æŒ‡æ ‡
        - oid: 1.3.6.1.2.1.2.2.1.7
          targets:
            - "1.3.6.1.2.1.31.1.1.1.6"
            - "1.3.6.1.2.1.31.1.1.1.10"
            - "1.3.6.1.2.1.2.2.1.13"
            - "1.3.6.1.2.1.2.2.1.19"
            - "1.3.6.1.2.1.2.2.1.14"
            - "1.3.6.1.2.1.2.2.1.20"
          values: ["1"]

  huawei_acc:  # åä¸ºæ¥å…¥äº¤æ¢æœºæ¨¡å—æŒ‡æ ‡ æœªå †å 
    walk:
      # æ¥å£ä¿¡æ¯
      #- 1.3.6.1.2.1.2.2.1.1                  # ifIndex æ¥å£ç´¢å¼• è¯¥å€¼å¤§äºé›¶ä¸”å…¨å±€å”¯ä¸€
      #- 1.3.6.1.2.1.2.2.1.2                  # ifDescr æè¿°æ¥å£çš„å­—ç¬¦ä¸²
      - 1.3.6.1.2.1.31.1.1.1.1                # ifName ç”±æœ¬åœ°è®¾å¤‡åˆ†é…çš„æ¥å£å åŒä¸ŠæŒ‡æ ‡ å–å…¶ä¸­ä¹‹ä¸€
      - 1.3.6.1.2.1.2.2.1.7                   # ifAdminStatus ç†æƒ³çš„æ¥å£çŠ¶æ€
      - 1.3.6.1.2.1.2.2.1.8                   # ifOperStatus æ¥å£å½“å‰çš„çŠ¶æ€
      - 1.3.6.1.2.1.31.1.1.1.18               # ifAlias è¯¥èŠ‚ç‚¹æ˜¯ç”±ç½‘ç»œç®¡ç†å‘˜æŒ‡å®šçš„æ¥å£åˆ«å descriptionå‘½ä»¤
      - 1.3.6.1.2.1.31.1.1.1.15               # ifHighSpeed æ¥å£å½“å‰å¸¦å®½ å•ä½ Mbit/s
      - 1.3.6.1.2.1.31.1.1.1.6                # ifHCInOctets æ¥å£ä¸Šæ¥æ”¶åˆ°çš„å­—èŠ‚æ€»æ•° byte/s
      - 1.3.6.1.2.1.31.1.1.1.10               # ifHCOutOctets æ¥å£å‘é€çš„å­—èŠ‚æ€»æ•° byte/s
      - 1.3.6.1.2.1.2.2.1.13                  # ifInDiscards å…¥æ–¹å‘çš„è¢«ä¸¢å¼ƒçš„æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.19                  # ifOutDiscards å‡ºæ–¹å‘çš„è¢«ä¸¢å¼ƒçš„æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.14                  # ifInErrors å…¥æ–¹å‘å‡ºé”™æŠ¥æ–‡ä¸ªæ•°
      - 1.3.6.1.2.1.2.2.1.20                  # ifOutErrors å‡ºæ–¹å‘å‡ºé”™æŠ¥æ–‡ä¸ªæ•°
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.2    # hwIfMonitorCrcErrorStatistics CRCé”™åŒ…ç»Ÿè®¡å€¼
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.8    # hwIfMonitorInputRate æ¥å£å…¥æ–¹å‘å¸¦å®½å ç”¨ç‡
      #- 1.3.6.1.4.1.2011.5.25.41.1.7.1.1.10   # hwIfMonitorOutputRate æ¥å£å‡ºæ–¹å‘å¸¦å®½å ç”¨ç‡

      # å…‰æ¨¡å—ä¿¡æ¯
      #- 1.3.6.1.2.1.47.1.1.1.1.1             # entPhysicalIndex ç‰©ç†å®ä½“ç´¢å¼•
      - 1.3.6.1.2.1.47.1.1.1.1.7              # entPhysicalName ç‰©ç†å®ä½“å å…‰æ¨¡å—æ¥å£åç§°
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.8    # hwEntityOpticalRxPower å…‰æ¨¡å—æ¥æ”¶åŠŸç‡ å•ä½ uW
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.9    # hwEntityOpticalTxPower å…‰æ¨¡å—å‘é€åŠŸç‡ å•ä½ uW
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.20   # hwEntityOpticalRxLowWarnThreshold å…‰æ¨¡å—æ¥æ”¶åŠŸç‡è¿‡ä½çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.21   # hwEntityOpticalRxHighWarnThreshold å…‰æ¨¡å—æ¥æ”¶åŠŸç‡è¿‡é«˜çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.22   # hwEntityOpticalTxLowWarnThreshold å…‰æ¨¡å—å‘é€åŠŸç‡è¿‡ä½çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.31.1.1.3.1.23   # hwEntityOpticalTxHighWarnThreshold å…‰æ¨¡å—å‘é€åŠŸç‡è¿‡é«˜çš„é¢„è­¦é—¨é™å€¼ å•ä½ dBm
      - 1.3.6.1.4.1.2011.5.25.42.2.1.14       # hwMacGlobalStatistics è·å–è®¾å¤‡ä¸Šçš„MACåœ°å€æ•°
      - 1.3.6.1.4.1.2011.5.25.42.2.1.1        # hwL2MaxMacLimit MACåœ°å€é™å®šçš„æœ€å¤§è§„åˆ™æ•°
    
    max_repetitions: 50
    retries: 3
    timeout: 5s
    
    lookups:
      - source_indexes: [ifIndex]
        lookup: ifAlias
        # å¦‚æœæ–°çš„ç´¢å¼•å”¯ä¸€ å¯ä»¥åˆ é™¤åŸæ¥çš„ç´¢å¼• true
        #drop_source_indexes: false
      - source_indexes: [ifIndex]
        lookup: ifName
      - source_indexes: [ifIndex]
        lookup: ifOperStatus
      - source_indexes: [ifIndex]
        lookup: ifHighSpeed
      - source_indexes: [entPhysicalIndex]
        lookup: entPhysicalName
    
    overrides:
      ifAlias:
        ignore: true # æŸ¥æ‰¾çš„æŒ‡æ ‡åœ¨snmp_exporterè¾“å‡ºæ§åˆ¶å°ç›´æ¥ä¸æ˜¾ç¤ºè¯¥æŒ‡æ ‡
        #regex_extracts:  # æ ¹æ®æ­£åˆ™è¡¨è¾¾å¼å’ŒæŒ‡æ ‡å€¼åˆ›å»ºæ–°æŒ‡æ ‡
        #   Temp: 
        #     - regex: '(.*)' # æ­£åˆ™è¡¨è¾¾å¼ä»è¿”å›çš„ SNMP walks å€¼ä¸­æå–ä¸€ä¸ªå€¼
        #       value: '$1' # ç»“æœå°†è¢«è§£æä¸º float64ï¼Œé»˜è®¤ä¸º $1
        #   Status:
        #     - regex: '.*Example'
        #       value: '1' # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä¸”å€¼è§£æçš„ç¬¬ä¸€ä¸ªæ¡ç›®è·èƒœ
        #     - regex: '.*'
        #       value: '0'
        #type: DisplayString
      ifName:
        ignore: true
      ifOperStatus:
        ignore: true
      ifHighSpeed:
        ignore: true
      entPhysicalName:
        ignore: true
    
    filters:
      # static:
      #   - targets:
      #     - ifIndex
      #     indices: ["2","3","4"]
      dynamic:  # æ ¹æ®æ¥å£å½“å‰çŠ¶æ€æ”¶é›†æ¥å£æŒ‡æ ‡
        - oid: 1.3.6.1.2.1.2.2.1.7
          targets:
            - "1.3.6.1.2.1.31.1.1.1.6"
            - "1.3.6.1.2.1.31.1.1.1.10"
            - "1.3.6.1.2.1.2.2.1.13"
            - "1.3.6.1.2.1.2.2.1.19"
            - "1.3.6.1.2.1.2.2.1.14"
            - "1.3.6.1.2.1.2.2.1.20"
          values: ["1"]
```

#### **æ‰§è¡Œå‘½ä»¤é‡‡é›†é…ç½®**

```bash
[root@ubuntu2204 generator]#/root/snmp_exporter/generator/generator --fail-on-parse-errors generate -m /root/snmp_exporter/generator/huawei/mibs/switch -g /root/snmp_exporter/generator/huawei/switch/generator_huawei_switch.yml -o /root/snmp_exporter/generator/huawei/switch/snmp_huawei_switch.yml

# æŸ¥çœ‹
[root@ubuntu2204 generator]#ls /root/snmp_exporter/generator/huawei/switch/snmp_huawei_switch.yml 
/root/snmp_exporter/generator/huawei/switch/snmp_huawei_switch.yml
```

#### é…ç½® Service æ–‡ä»¶

```bash
[root@ubuntu2204 generator]#cat /lib/systemd/system/snmp_exporter.service
[Unit]
Description=snmp_exporter
After=network.target

[Service]
ExecStart=/root/snmp_exporter/snmp_exporter --config.file=/root/snmp_exporter/generator/huawei/switch/snmp_huawei_switch.yml
Restart=on-failure
user=root

[Install]
WantedBy=multi-user.target

# å¯åŠ¨æœåŠ¡
[root@ubuntu2204 generator]#systemctl daemon-reload 
[root@ubuntu2204 generator]#systemctl start snmp_exporter.service 

# æŸ¥çœ‹ç«¯å£
[root@ubuntu2204 generator]#ss -nlt
State     Recv-Q    Send-Q       Local Address:Port        Peer Address:Port    Process                   
LISTEN    0         4096                     *:9116                   *:*  

# æµè§ˆå™¨è®¿é—®æŸ¥çœ‹
```

![image-20250308175533760](../markdown_img/image-20250308175533760.png)

![image-20250308175739262](../markdown_img/image-20250308175739262.png)





### é…ç½® Prometheus é‡‡é›† SNMP æ•°æ®

ç¼–è¾‘ Prometheus é…ç½®æ–‡ä»¶ **`prometheus.yml`**ï¼š

```yaml
[root@ubuntu2204 generator]#cat /usr/local/prometheus/conf/prometheus.yml 
......
  - job_name: 'snmp_huawei_switch'
    static_configs:
      - targets:
        - "10.0.0.206"  # äº¤æ¢æœº A
    metrics_path: /snmp
    params:
      module: [huawei_acc]  # é‡‡é›†è§„åˆ™ï¼Œsnmp_exporter ä¼šç”¨å®ƒåŒ¹é… yml æ–‡ä»¶
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - target_label: instance
        source_labels: [__address__]
      - target_label: __address__
        replacement: "localhost:9116"  # Prometheus ç›´æ¥è¯·æ±‚æœ¬æœºçš„ snmp_exporte
        
# é‡å¯æœåŠ¡
[root@ubuntu2204 snmp_exporter]#systemctl restart prometheus.service 

# æµè§ˆå™¨æŸ¥çœ‹
```

![image-20250308181238527](../markdown_img/image-20250308181238527.png)

### åœ¨ Grafana å¯è§†åŒ–

**æ·»åŠ  Prometheus æ•°æ®æº**

- **æ‰“å¼€ Grafana**
- **è¿›å…¥ â€œSettingsâ€ â†’ â€œData Sourcesâ€**
- **æ·»åŠ  Prometheus**
  - URL: `http://localhost:9090`
  - Click **"Save & Test"**

**åˆ›å»º SNMP ç›‘æ§é¢æ¿**

- **è¿›å…¥ "Dashboard" â†’ "Create" â†’ "New Panel"**

- **åœ¨ PromQL è¾“å…¥**ï¼š

  ```bash
  snmp_scrape_walk_duration_seconds{instance="10.0.0.206", job="snmp_huawei_switch", module="huawei_acc"}
  ```

- **ä¿®æ”¹å•ä½**

  - åœ¨ **Panel â†’ Visualization** é€‰æ‹© **"Time Series"**
  - åœ¨ **Axes â†’ Unit** é€‰æ‹© **"bits/sec"**

- **ç‚¹å‡» "Apply" ä¿å­˜é¢æ¿**

**å»ºè®®ç›´æ¥ä½¿ç”¨æ¨¡ç‰ˆï¼Œåœ¨æ¨¡ç‰ˆä¸Šä¿®æ”¹**

![image-20250308182313444](../markdown_img/image-20250308182313444.png)





### åœ¨ VMware è™šæ‹Ÿæœºä¸­æ¨¡æ‹Ÿ SNMP äº¤æ¢æœº

**ç›®æ ‡ï¼š**

- åœ¨ **VMware** å†…åˆ›å»ºä¸€ä¸ª **Linux è™šæ‹Ÿæœº**
- **å®‰è£… SNMP æœåŠ¡å™¨ï¼ˆsnmpdï¼‰**
- **é…ç½® SNMP å…è®¸ Prometheus è®¿é—®**
- **ä½¿ç”¨ Prometheus + SNMP Exporter è¿›è¡Œç›‘æ§**



### é…ç½® SNMP æœåŠ¡å™¨ï¼ˆåœ¨ Linux è™šæ‹Ÿæœºä¸Šï¼‰

**åœ¨ VMware å†…å®‰è£… Linuxï¼ˆæ¨è Ubuntu æˆ– CentOSï¼‰**

**åˆ›å»ºä¸€å°è™šæ‹Ÿæœº**

- æ“ä½œç³»ç»Ÿé€‰æ‹© **Ubuntu 22.04 æˆ– CentOS 7**
- **ç½‘ç»œæ¨¡å¼é€‰æ‹© "æ¡¥æ¥æ¨¡å¼"**ï¼ˆBridgeï¼‰ï¼Œè¿™æ · Prometheus å¯ä»¥è®¿é—® SNMP è®¾å¤‡
- **åˆ†é…å›ºå®š IP**ï¼ˆæ–¹ä¾¿ Prometheus ç›‘æ§ï¼‰

**å®‰è£… SNMP æœåŠ¡å™¨**

```bash
# Ubuntu
sudo apt update && sudo apt install -y snmp snmpd

# ï¼ˆCentOS/RHELï¼‰
sudo yum install -y net-snmp net-snmp-utils
```



### é…ç½® `snmpd` ä½œä¸º SNMP äº¤æ¢æœº

**ä¿®æ”¹ `snmpd` é…ç½®**

```bash
vim /etc/snmp/snmpd.conf
```

**æ›¿æ¢ä»¥ä¸‹å†…å®¹**

```yaml
agentAddress udp:161  # ç›‘å¬ SNMP 161 ç«¯å£
rocommunity public     # å…è®¸ä½¿ç”¨ "public" è¯»å– SNMP æ•°æ®
syslocation "VMware Simulated Switch"
syscontact "admin@example.com"
```

**æ·»åŠ æ¥å£æµé‡ç›‘æ§**

```yaml
view all included .1 80
```

**é‡å¯ SNMP æœåŠ¡**

```bash
sudo systemctl restart snmpd
sudo systemctl enable snmpd
```

**éªŒè¯ SNMP æ˜¯å¦æ­£å¸¸å·¥ä½œ** åœ¨è™šæ‹Ÿæœº **æœ¬åœ°æµ‹è¯• SNMP å“åº”**

```bash
snmpwalk -v2c -c public localhost
```

**å¦‚æœè¿”å›äº† SNMP æ•°æ®ï¼Œè¯´æ˜ SNMP äº¤æ¢æœºæ¨¡æ‹ŸæˆåŠŸï¼**





## SNMPã€OID å’Œ MIB

SNMPï¼ˆSimple Network Management Protocolï¼Œç®€å•ç½‘ç»œç®¡ç†åè®®ï¼‰æ˜¯ä¸€ç§ç”¨äºç®¡ç†å’Œç›‘æ§ç½‘ç»œè®¾å¤‡ï¼ˆå¦‚äº¤æ¢æœºã€è·¯ç”±å™¨ã€æœåŠ¡å™¨ç­‰ï¼‰çš„åè®®ã€‚å®ƒä¾èµ– **OIDï¼ˆå¯¹è±¡æ ‡è¯†ç¬¦ï¼‰** å’Œ **MIBï¼ˆç®¡ç†ä¿¡æ¯åº“ï¼‰** è¿›è¡Œæ•°æ®æŸ¥è¯¢å’Œç»„ç»‡ã€‚



### OIDï¼ˆå¯¹è±¡æ ‡è¯†ç¬¦ï¼ŒObject Identifierï¼‰

**OID æ˜¯ SNMP è®¾å¤‡ä¸­æ¯ä¸ªå¯ç®¡ç†å¯¹è±¡ï¼ˆæŒ‡æ ‡ï¼‰çš„å”¯ä¸€ç¼–å·**ï¼Œå®ƒæ˜¯ä¸€ç»„ä»¥ **`.`ï¼ˆç‚¹å·ï¼‰åˆ†éš”çš„æ•°å­—**ï¼Œæ¯”å¦‚ï¼š

```ABAP
1.3.6.1.2.1.1.3.0
```

å®ƒç±»ä¼¼äº **è·¯å¾„** æˆ– **åœ°å€**ï¼Œå¯ä»¥å”¯ä¸€åœ°æ ‡è¯†æŸä¸ª SNMP è®¾å¤‡ä¸Šçš„ä¸€ä¸ªå˜é‡ï¼ˆæ¯”å¦‚ CPU ä½¿ç”¨ç‡ã€ç«¯å£çŠ¶æ€ã€æµé‡ç»Ÿè®¡ç­‰ï¼‰ã€‚

**ä¾‹å­**

| **OID**                  | **æè¿°**                               |
| ------------------------ | -------------------------------------- |
| `1.3.6.1.2.1.1.3.0`      | è®¾å¤‡çš„ç³»ç»Ÿå¯åŠ¨æ—¶é—´ï¼ˆ`sysUpTime`ï¼‰      |
| `1.3.6.1.2.1.2.2.1.10.1` | ç«¯å£ 1 çš„æ¥æ”¶å­—èŠ‚æ•°ï¼ˆ`ifInOctets.1`ï¼‰  |
| `1.3.6.1.2.1.2.2.1.16.2` | ç«¯å£ 2 çš„å‘é€å­—èŠ‚æ•°ï¼ˆ`ifOutOctets.2`ï¼‰ |

**OID ä½œç”¨**ï¼š

- **SNMP åªèƒ½é€šè¿‡ OID è®¿é—®æ•°æ®**ï¼Œä½ æ— æ³•ç›´æ¥ç”¨ `"CPU ä½¿ç”¨ç‡"` è¿™æ ·çš„å­—ç¬¦ä¸²å»æŸ¥è¯¢è®¾å¤‡ï¼Œåªèƒ½ç”¨ `1.3.6.1.4.1.xxxxxx` è¿™ç§ OIDã€‚
- **OID ç»„ç»‡æ–¹å¼æ˜¯æ ‘çŠ¶ç»“æ„**ï¼Œæ‰€æœ‰ SNMP è®¾å¤‡éµå¾ªç›¸åŒçš„å±‚æ¬¡ç»“æ„ï¼Œæ¯ä¸ªè®¾å¤‡å‚å•†åœ¨ `1.3.6.1.4.1` ä¸‹é¢æ³¨å†Œè‡ªå·±çš„ OIDã€‚



### MIBï¼ˆç®¡ç†ä¿¡æ¯åº“ï¼ŒManagement Information Baseï¼‰

MIB **æ˜¯ä¸€ç§æè¿° OID ç»“æ„çš„æ–‡æœ¬æ–‡ä»¶**ï¼Œç”¨æ¥è§£é‡Š OID ä»£è¡¨çš„å†…å®¹ã€‚ä¾‹å¦‚

```ABAP
sysUpTime OBJECT-TYPE
    SYNTAX  TimeTicks
    ACCESS  read-only
    STATUS  current
    DESCRIPTION "The time since the network management portion of the system was last re-initialized."
    ::= { 1.3.6.1.2.1.1.3 }
```

ğŸ“Œ è¿™ä¸ª MIB å®šä¹‰äº† `sysUpTime`ï¼š

- `1.3.6.1.2.1.1.3` å¯¹åº” **è®¾å¤‡è¿è¡Œæ—¶é—´**
- **MIB è®© OID æ›´æ˜“è¯»**ï¼ˆå¦åˆ™æˆ‘ä»¬åªèƒ½è®° `1.3.6.1.2.1.1.3`ï¼‰



### OID å’Œ MIB çš„å…³ç³»

**MIB = OID çš„â€œç¿»è¯‘å­—å…¸â€**

- MIB åªæ˜¯æ–‡æœ¬æ–‡ä»¶ï¼Œä¸åŒ…å«æ•°æ®
- è®¾å¤‡é‡Œçš„ **çœŸå®æ•°æ®** åªèƒ½é€šè¿‡ **OID** è·å–
- **OID æ˜¯æ•°å€¼åŒ–çš„åœ°å€ï¼ŒMIB åªæ˜¯ç»™ OID èµ·äº†ä¸ªæ˜“è¯»çš„åå­—**
- SNMP é€šè¿‡ OID æŸ¥è¯¢è®¾å¤‡æ•°æ®ï¼ŒMIB åªæ˜¯å¸®åŠ©æˆ‘ä»¬ç†è§£è¿™äº›æ•°æ®

ğŸ‘‰ **ä¾‹å­**

| **OID**                  | **MIB å˜é‡**    | **ä½œç”¨**            |
| ------------------------ | --------------- | ------------------- |
| `1.3.6.1.2.1.1.3.0`      | `sysUpTime.0`   | è®¾å¤‡è¿è¡Œæ—¶é—´        |
| `1.3.6.1.2.1.2.2.1.10.1` | `ifInOctets.1`  | ç«¯å£ 1 çš„æ¥æ”¶å­—èŠ‚æ•° |
| `1.3.6.1.2.1.2.2.1.16.2` | `ifOutOctets.2` | ç«¯å£ 2 çš„å‘é€å­—èŠ‚æ•° |

ğŸ“Œ **æ²¡æœ‰ MIBï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥ç”¨ OID è®¿é—®æ•°æ®**ï¼Œä½†åªèƒ½çœ‹åˆ°æ•°å­— OIDï¼Œä¸çŸ¥é“å®ƒå…·ä½“ä»£è¡¨ä»€ä¹ˆã€‚



### **æ€»ç»“**

âœ… **OIDï¼ˆå¯¹è±¡æ ‡è¯†ç¬¦ï¼‰**ï¼šæ¯ä¸ª SNMP æŒ‡æ ‡çš„å”¯ä¸€ç¼–å·ï¼Œæ¯”å¦‚ `1.3.6.1.2.1.1.3`
 âœ… **MIBï¼ˆç®¡ç†ä¿¡æ¯åº“ï¼‰**ï¼šOID çš„æ–‡æœ¬æè¿°æ–‡ä»¶ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£ OID ä»£è¡¨ä»€ä¹ˆ
 âœ… **SNMP å¿…é¡»é€šè¿‡ OID æŠ“å–æ•°æ®**ï¼ŒMIB åªæ˜¯è®© OID æ›´æ˜“è¯»

ğŸš€ **`snmp_exporter` ä¾èµ– `snmp_huawei_switch.yml` é‡Œçš„ OID è§„åˆ™å»æŠ“å–äº¤æ¢æœºæ•°æ®**ï¼Œè€Œ Prometheus é€šè¿‡ `snmp_exporter` è·å–äº¤æ¢æœºçš„ç›‘æ§æŒ‡æ ‡ï¼



## Gossipåè®®

### Gossipæ˜¯ä»€ä¹ˆ

Gossipåè®®æ˜¯ä¸€ä¸ªé€šä¿¡åè®®ï¼Œä¸€ç§ä¼ æ’­æ¶ˆæ¯çš„æ–¹å¼ï¼Œçµæ„Ÿæ¥è‡ªäºï¼šç˜Ÿç–«ã€ç¤¾äº¤ç½‘ç»œç­‰ã€‚ä½¿ç”¨Gossipåè®®çš„æœ‰ï¼šRedis Clusterã€Consulã€Apache Cassandraç­‰ã€‚



### å…­åº¦åˆ†éš”ç†è®º

è¯´åˆ°ç¤¾äº¤ç½‘ç»œï¼Œå°±ä¸å¾—ä¸æè‘—åçš„**å…­åº¦åˆ†éš”ç†è®º**ã€‚1967å¹´ï¼Œå“ˆä½›å¤§å­¦çš„å¿ƒç†å­¦æ•™æˆStanley Milgramæƒ³è¦æç»˜ä¸€ä¸ªè¿ç»“äººä¸ç¤¾åŒºçš„äººé™…è¿ç³»ç½‘ã€‚åšè¿‡ä¸€æ¬¡è¿é”ä¿¡å®éªŒï¼Œç»“æœå‘ç°äº†â€œå…­åº¦åˆ†éš”â€ç°è±¡ã€‚ç®€å•åœ°è¯´ï¼šâ€œä½ å’Œä»»ä½•ä¸€ä¸ªé™Œç”Ÿäººä¹‹é—´æ‰€é—´éš”çš„äººä¸ä¼šè¶…è¿‡å…­ä¸ªï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæœ€å¤šé€šè¿‡å…­ä¸ªäººä½ å°±èƒ½å¤Ÿè®¤è¯†ä»»ä½•ä¸€ä¸ªé™Œç”Ÿäºº

æ•°å­¦è§£é‡Šè¯¥ç†è®ºï¼šè‹¥æ¯ä¸ªäººå¹³å‡è®¤è¯†260äººï¼Œå…¶å…­åº¦å°±æ˜¯260â†‘6 =1,188,137,600,000ã€‚æ¶ˆé™¤ä¸€äº›èŠ‚ç‚¹é‡å¤ï¼Œé‚£ä¹Ÿå‡ ä¹**è¦†ç›–**äº†æ•´ä¸ªåœ°çƒäººå£è‹¥å¹²å¤šå¤šå€ï¼Œè¿™ä¹Ÿæ˜¯Gossipåè®®çš„é›å½¢ã€‚



### åŸç†

Gossipåè®®åŸºæœ¬æ€æƒ³å°±æ˜¯ï¼šä¸€ä¸ªèŠ‚ç‚¹æƒ³è¦åˆ†äº«ä¸€äº›ä¿¡æ¯ç»™ç½‘ç»œä¸­çš„å…¶ä»–çš„ä¸€äº›èŠ‚ç‚¹ã€‚äºæ˜¯ï¼Œå®ƒ**å‘¨æœŸæ€§**çš„**éšæœº**é€‰æ‹©ä¸€äº›èŠ‚ç‚¹ï¼Œå¹¶æŠŠä¿¡æ¯ä¼ é€’ç»™è¿™äº›èŠ‚ç‚¹ã€‚è¿™äº›æ”¶åˆ°ä¿¡æ¯çš„èŠ‚ç‚¹æ¥ä¸‹æ¥ä¼šåšåŒæ ·çš„äº‹æƒ…ï¼Œå³æŠŠè¿™äº›ä¿¡æ¯ä¼ é€’ç»™å…¶ä»–ä¸€äº›éšæœºé€‰æ‹©çš„èŠ‚ç‚¹ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œä¿¡æ¯ä¼šå‘¨æœŸæ€§çš„ä¼ é€’ç»™Nä¸ªç›®æ ‡èŠ‚ç‚¹ï¼Œè€Œä¸åªæ˜¯ä¸€ä¸ªã€‚è¿™ä¸ªNè¢«ç§°ä¸º**fanout**ï¼ˆè¿™ä¸ªå•è¯çš„æœ¬æ„æ˜¯æ‰‡å‡ºï¼‰ã€‚



### ç”¨é€”

Gossipåè®®çš„ä¸»è¦ç”¨é€”å°±æ˜¯**ä¿¡æ¯ä¼ æ’­å’Œæ‰©æ•£**ï¼šå³æŠŠä¸€äº›å‘ç”Ÿçš„äº‹ä»¶ä¼ æ’­åˆ°å…¨ä¸–ç•Œã€‚å®ƒä»¬ä¹Ÿè¢«ç”¨äºæ•°æ®åº“å¤åˆ¶ï¼Œä¿¡æ¯æ‰©æ•£ï¼Œé›†ç¾¤æˆå‘˜èº«ä»½ç¡®è®¤ï¼Œæ•…éšœæ¢æµ‹ç­‰ã€‚

åŸºäºGossipåè®®çš„ä¸€äº›æœ‰åçš„ç³»ç»Ÿï¼šApache Cassandraï¼ŒRedisï¼ˆClusteræ¨¡å¼ï¼‰ï¼ŒConsulç­‰ã€‚



### å›¾è§£

æ¥ä¸‹æ¥é€šè¿‡å¤šå¼ å›¾ç‰‡å‰–æGossipåè®®æ˜¯å¦‚ä½•è¿è¡Œçš„ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒGossipåè®®æ˜¯å‘¨æœŸå¾ªç¯æ‰§è¡Œçš„ã€‚å›¾ä¸­çš„å…¬å¼è¡¨ç¤ºGossipåè®®æŠŠä¿¡æ¯ä¼ æ’­åˆ°æ¯ä¸€ä¸ªèŠ‚ç‚¹éœ€è¦å¤šå°‘æ¬¡å¾ªç¯åŠ¨ä½œï¼Œéœ€è¦è¯´æ˜çš„æ˜¯ï¼Œå…¬å¼ä¸­çš„20è¡¨ç¤ºæ•´ä¸ªé›†ç¾¤æœ‰20ä¸ªèŠ‚ç‚¹ï¼Œ4è¡¨ç¤ºæŸä¸ªèŠ‚ç‚¹ä¼šå‘4ä¸ªç›®æ ‡èŠ‚ç‚¹ä¼ æ’­æ¶ˆæ¯ï¼š

![image-20250311142008701](../markdown_img/image-20250311142008701.png)

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œçº¢è‰²çš„èŠ‚ç‚¹è¡¨ç¤ºå…¶å·²ç»â€œå—åˆ°æ„ŸæŸ“â€ï¼Œå³æ¥ä¸‹æ¥è¦ä¼ æ’­ä¿¡æ¯çš„æºå¤´ï¼Œè¿çº¿è¡¨ç¤ºè¿™ä¸ªåˆå§‹åŒ–æ„ŸæŸ“çš„èŠ‚ç‚¹èƒ½æ­£å¸¸è¿æ¥çš„èŠ‚ç‚¹ï¼ˆå…¶ä¸èƒ½è¿æ¥çš„èŠ‚ç‚¹åªèƒ½é æ¥ä¸‹æ¥æ„ŸæŸ“çš„èŠ‚ç‚¹å‘å…¶ä¼ æ’­æ¶ˆæ¯ï¼‰ã€‚å¹¶ä¸”Nç­‰äº4ï¼Œæˆ‘ä»¬å‡è®¾4æ ¹è¾ƒç²—çš„çº¿è·¯ï¼Œå°±æ˜¯å®ƒç¬¬ä¸€æ¬¡ä¼ æ’­æ¶ˆæ¯çš„çº¿è·¯ï¼š

![image-20250311142120703](../markdown_img/image-20250311142120703.png)

ç¬¬ä¸€æ¬¡æ¶ˆæ¯å®Œæˆä¼ æ’­åï¼Œæ–°å¢äº†4ä¸ªèŠ‚ç‚¹ä¼šè¢«â€œæ„ŸæŸ“â€ï¼Œå³è¿™4ä¸ªèŠ‚ç‚¹ä¹Ÿæ”¶åˆ°äº†æ¶ˆæ¯ã€‚è¿™æ—¶å€™ï¼Œæ€»è®¡æœ‰5ä¸ªèŠ‚ç‚¹å˜æˆçº¢è‰²ï¼š

![image-20250311142302631](../markdown_img/image-20250311142302631.png)



é‚£ä¹ˆåœ¨ä¸‹ä¸€æ¬¡ä¼ æ’­å‘¨æœŸæ—¶ï¼Œæ€»è®¡æœ‰5ä¸ªèŠ‚ç‚¹ï¼Œä¸”è¿™5ä¸ªèŠ‚ç‚¹æ¯ä¸ªèŠ‚ç‚¹éƒ½ä¼šå‘4ä¸ªèŠ‚ç‚¹ä¼ æ’­æ¶ˆæ¯ã€‚æœ€åï¼Œç»è¿‡3æ¬¡å¾ªç¯ï¼Œ20ä¸ªèŠ‚ç‚¹å…¨éƒ¨è¢«æ„ŸæŸ“ï¼ˆéƒ½å˜æˆçº¢è‰²èŠ‚ç‚¹ï¼‰ï¼Œå³è¯´æ˜éœ€è¦ä¼ æ’­çš„æ¶ˆæ¯å·²ç»ä¼ æ’­ç»™äº†æ‰€æœ‰èŠ‚ç‚¹ï¼š

![image-20250311142358338](../markdown_img/image-20250311142358338.png)

éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œ20ä¸ªèŠ‚ç‚¹ä¸”è®¾ç½®fanout=4ï¼Œå…¬å¼ç»“æœæ˜¯2.16ï¼Œè¿™åªæ˜¯ä¸ªè¿‘ä¼¼å€¼ã€‚**çœŸå®ä¼ é€’æ—¶ï¼Œå¯èƒ½éœ€è¦3æ¬¡ç”šè‡³4æ¬¡å¾ªç¯æ‰èƒ½è®©æ‰€æœ‰èŠ‚ç‚¹æ”¶åˆ°æ¶ˆæ¯**ã€‚è¿™æ˜¯å› ä¸ºæ¯ä¸ªèŠ‚ç‚¹åœ¨ä¼ æ’­æ¶ˆæ¯çš„æ—¶å€™ï¼Œæ˜¯éšæœºé€‰æ‹©Nä¸ªèŠ‚ç‚¹çš„ï¼Œè¿™æ ·çš„è¯ï¼Œå°±æœ‰å¯èƒ½æŸä¸ªèŠ‚ç‚¹ä¼šè¢«é€‰ä¸­2æ¬¡ç”šè‡³æ›´å¤šæ¬¡



### å‘é€æ¶ˆæ¯

ç”±å‰é¢å¯¹Gossipåè®®å›¾è§£åˆ†æå¯çŸ¥ï¼ŒèŠ‚ç‚¹ä¼ æ’­æ¶ˆæ¯æ˜¯å‘¨æœŸæ€§çš„ï¼Œå¹¶ä¸”**æ¯ä¸ªèŠ‚ç‚¹æœ‰å®ƒè‡ªå·±çš„å‘¨æœŸ**ã€‚å¦å¤–ï¼ŒèŠ‚ç‚¹å‘é€æ¶ˆæ¯æ—¶çš„**ç›®æ ‡èŠ‚ç‚¹æ•°**ç”±å‚æ•°fanoutå†³å®šã€‚è‡³äºå¾€å“ªäº›ç›®æ ‡èŠ‚ç‚¹å‘é€ï¼Œåˆ™æ˜¯**éšæœº**çš„ã€‚

ä¸€æ—¦æ¶ˆæ¯è¢«å‘é€åˆ°ç›®æ ‡èŠ‚ç‚¹ï¼Œé‚£ä¹ˆç›®æ ‡èŠ‚ç‚¹ä¹Ÿä¼šè¢«æ„ŸæŸ“ã€‚ä¸€æ—¦æŸä¸ªèŠ‚ç‚¹è¢«æ„ŸæŸ“ï¼Œé‚£ä¹ˆå®ƒä¹Ÿä¼šå‘å…¶ä»–èŠ‚ç‚¹ä¼ æ’­æ¶ˆæ¯ï¼Œè¯•å›¾æ„ŸæŸ“æ›´å¤šçš„èŠ‚ç‚¹ã€‚æœ€ç»ˆï¼Œæ¯ä¸€ä¸ªèŠ‚ç‚¹éƒ½ä¼šè¢«æ„ŸæŸ“ï¼Œå³æ¶ˆæ¯è¢«åŒæ­¥ç»™äº†æ‰€æœ‰èŠ‚ç‚¹ï¼š



### å¯æ‰©å±•æ€§ä¸å¤±è´¥å®¹é”™

Gossipåè®®æ˜¯å¯æ‰©å±•çš„ï¼Œå› ä¸ºå®ƒåªéœ€è¦O(logN) ä¸ªå‘¨æœŸå°±èƒ½æŠŠæ¶ˆæ¯ä¼ æ’­ç»™æ‰€æœ‰èŠ‚ç‚¹ã€‚æŸä¸ªèŠ‚ç‚¹åœ¨å¾€å›ºå®šæ•°é‡èŠ‚ç‚¹ä¼ æ’­æ¶ˆæ¯è¿‡ç¨‹ä¸­ï¼Œå¹¶ä¸éœ€è¦ç­‰å¾…ç¡®è®¤ï¼ˆackï¼‰ï¼Œå¹¶ä¸”ï¼Œå³ä½¿æŸæ¡æ¶ˆæ¯ä¼ æ’­è¿‡ç¨‹ä¸­ä¸¢å¤±ï¼Œå®ƒä¹Ÿä¸éœ€è¦åšä»»ä½•è¡¥å¿æªæ–½ã€‚æ‰“ä¸ªæ¯”æ–¹ï¼ŒæŸä¸ªèŠ‚ç‚¹æœ¬æ¥éœ€è¦å°†æ¶ˆæ¯ä¼ æ’­ç»™4ä¸ªèŠ‚ç‚¹ï¼Œä½†æ˜¯ç”±äºç½‘ç»œæˆ–è€…å…¶ä»–åŸå› ï¼Œåªæœ‰3ä¸ªæ¶ˆæ¯æ¥æ”¶åˆ°æ¶ˆæ¯ï¼Œå³ä½¿è¿™æ ·ï¼Œè¿™å¯¹æœ€ç»ˆæ‰€æœ‰èŠ‚ç‚¹æ¥æ”¶åˆ°æ¶ˆæ¯æ˜¯æ²¡æœ‰ä»»ä½•å½±å“çš„ã€‚

å¦‚ä¸‹è¡¨æ ¼æ‰€ç¤ºï¼Œå‡å®šfanout=4ï¼Œé‚£ä¹ˆåœ¨èŠ‚ç‚¹æ•°åˆ†åˆ«æ˜¯20ã€40ã€80ã€160æ—¶ï¼Œæ¶ˆæ¯ä¼ æ’­åˆ°æ‰€æœ‰èŠ‚ç‚¹éœ€è¦çš„å¾ªç¯æ¬¡æ•°å¯¹æ¯”ï¼Œåœ¨èŠ‚ç‚¹æˆå€æ‰©å¤§çš„æƒ…å†µä¸‹ï¼Œå¾ªç¯æ¬¡æ•°å¹¶æ²¡æœ‰å¢åŠ å¾ˆå¤šã€‚æ‰€ä»¥ï¼ŒGossipåè®®å…·å¤‡å¯æ‰©å±•æ€§ï¼š

| èŠ‚ç‚¹æ•°       | 20   | 40   | 80   | 160  | 320  |
| ------------ | ---- | ---- | ---- | ---- | ---- |
| **å¾ªç¯æ¬¡æ•°** | 2.16 | 2.66 | 3.16 | 3.44 | 4.16 |





## Raftåè®®

â€‹        åœ¨åˆ†å¸ƒå¼çš„ä¸–ç•Œé‡Œï¼Œè¦è¯´æœ€æ ¸å¿ƒæœ€å¤æ‚çš„åŠŸèƒ½ï¼Œ**ä¸€è‡´æ€§**çš„å®ç°æ— å‡ºå…¶å³ï¼Œä¹‹å‰çš„paxosç®—æ³•å ªç§°ç»å…¸ï¼Œè¢«è®¤ä¸ºæ˜¯åŒç±»ç®—æ³•ä¸­æ•ˆæœæœ€å¥½çš„ï¼ŒåŸºæœ¬ä¸Šæˆä¸ºåˆ†å¸ƒå¼ä¸€è‡´æ€§çš„ä»£åè¯ï¼Œä½†æ˜¯paxosç®—æ³•ä¹Ÿæ˜¯å‡ºäº†åçš„éš¾ç†è§£ï¼Œè€Œä¸”ç›¸å½“ä¸å¥½å®ç°ã€‚æœ¬äººä¹ŸèŠ±äº†å¾ˆå¤šæ—¶é—´ã€çœ‹äº†å¾ˆå¤šææ–™ä¹Ÿæ²¡æœ‰çœŸæ­£ç†è§£ã€‚æ‰€ä»¥åŸºäºpaxosçš„æ€æƒ³è¿›è¡Œçš„ä¸€è‡´æ€§ç®—æ³•çš„ç®€åŒ–å’Œå®ç°å°±æˆä¸ºäº†ç°å®çš„éœ€æ±‚ï¼Œåœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œæœ¬æ–‡çš„ä¸»è§’Raftå°±å‡ºç°äº†ã€‚
â€‹        **Raftç®—æ³•çš„å¤´å·ç›®æ ‡å°±æ˜¯å®¹æ˜“ç†è§£ï¼ˆUnderStandableï¼‰**ï¼Œè¿™ä»è®ºæ–‡ä¸­å°±å¯ä»¥çœ‹å‡ºæ¥ã€‚å½“ç„¶ï¼ŒRaftå¢å¼ºäº†å¯ç†è§£æ€§ï¼Œåœ¨æ€§èƒ½ã€å¯é æ€§ã€å¯ç”¨æ€§æ–¹é¢æ˜¯ä¸è¾“äºPaxosçš„ã€‚å»ºè®®å¤§å®¶æ‹œè¯»ä¸‹ä½œè€…çš„è®ºæ–‡[Raftè®ºæ–‡](https://docs.qq.com/doc/DY0VxSkVGWHFYSlZJ)ï¼Œä¸‹é¢å°†è¯¦ç»†è¯´æ˜raftçš„æ€æƒ³ä»¥åŠå®ç°çš„è¿‡ç¨‹



â€‹        raftä¸ºäº†å®ç°å®¹æ˜“ç†è§£çš„ç›®æ ‡ï¼Œåœ¨paxosçš„åŸºç¡€ä¸Šè¿›è¡Œçš„çŠ¶æ€ç®€åŒ–ä»¥åŠé—®é¢˜æ‹†åˆ†ï¼Œå°†ä¹‹å‰å¤æ‚çš„é€»è¾‘æ‹†æˆè‹¥å¹²ä¸ªå­é—®é¢˜ï¼ŒåŸºæœ¬ä¸Šå¯ä»¥æ€»ç»“æˆä¸‹é¢å‡ ä¸ªæ–¹é¢ï¼š

- **leader election**ï¼šé€‰å–ä¸»èŠ‚ç‚¹
- **log replication**ï¼šæ—¥å¿—å¤‡ä»½ï¼Œæ•°æ®åŒæ­¥
- **safety**ï¼šä¸ºäº†å®ç°ä¸Šè¿°ä¸¤ç‚¹è€Œäº§ç”Ÿçš„ä¸€äº›çº¦æŸæ¡ä»¶å’Œä¿éšœæ¡ä»¶



### å‰ç½®çŸ¥è¯†è¡¥å……ï¼š

#### Raft åè®®ä¸­çš„ `term`ï¼ˆä»»æœŸï¼‰è¯¦è§£

##### **1ï¸âƒ£ ä»€ä¹ˆæ˜¯ `term`ï¼ˆä»»æœŸï¼‰ï¼Ÿ**

åœ¨ Raft åè®®ä¸­ï¼Œ**`term`ï¼ˆä»»æœŸï¼‰æ˜¯ä¸€ä¸ªå•è°ƒé€’å¢çš„æ•´æ•°**ï¼Œç”¨äºæ ‡è¯†é›†ç¾¤å½“å‰æ‰€å¤„çš„ **æ—¶é—´æ®µ** æˆ– **é€‰ä¸¾å‘¨æœŸ**ã€‚Raft é€‰ä¸¾çš„åŸºæœ¬è§„åˆ™æ˜¯ï¼š

- **æ¯æ¬¡æ–°çš„é€‰ä¸¾å¼€å§‹ï¼Œ`term +1`**ï¼ˆæ„å‘³ç€è¿›å…¥äº†æ–°çš„ä¸€è½®é€‰ä¸¾ï¼‰ã€‚

- **æ¯ä¸ª Leader åœ¨ä»»æœŸå†…ä¿æŒæœ‰æ•ˆï¼Œç›´åˆ°è¢«æ–°çš„ Leader å–ä»£**ã€‚

- **å¦‚æœä¸€ä¸ªèŠ‚ç‚¹å‘ç°è‡ªå·±è½åäºå…¶ä»–èŠ‚ç‚¹çš„ `term`ï¼Œå®ƒä¼šç«‹å³æ›´æ–°è‡ªå·±çš„ `term`ï¼Œå¹¶è½¬å˜ä¸º Follower**ã€‚

**ğŸ“Œ é‡ç‚¹ï¼š**

- `term` **ä¿è¯äº†æ•´ä¸ªé›†ç¾¤çš„çº¿æ€§æ—¶é—´é¡ºåº**ï¼Œç¡®ä¿ä¸åŒ Leader çš„é€‰ä¸¾ä¸ä¼šå‘ç”Ÿå†²çªã€‚
- `term` **æ°¸è¿œé€’å¢**ï¼Œä¸ä¼šå›é€€ã€‚
- **Leader åªèƒ½åœ¨æŸä¸ªç‰¹å®š `term` å†…å­˜æ´»**ï¼Œå¦‚æœ `term` å˜åŒ–ï¼Œåˆ™ Leader å¤±æ•ˆï¼Œéœ€è¦é‡æ–°é€‰ä¸¾ã€‚



##### **2ï¸âƒ£ `term` å˜åŒ–çš„æ—¶æœº**

åœ¨ Raft ä¸­ï¼Œ`term` ä¸»è¦åœ¨ **é€‰ä¸¾è¿‡ç¨‹ä¸­å˜åŒ–**ã€‚ä»¥ä¸‹æ˜¯ `term` å‘ç”Ÿå˜åŒ–çš„åœºæ™¯ï¼š

**(1) Follower è¶…æ—¶ï¼Œå‘èµ·é€‰ä¸¾ï¼ˆ`term +1`ï¼‰**

å¦‚æœ Follower **è¶…è¿‡é€‰ä¸¾è¶…æ—¶æ—¶é—´**ï¼ˆ150ms-300msï¼‰ï¼Œä½† **æ²¡æœ‰æ”¶åˆ° Leader çš„å¿ƒè·³**ï¼Œå®ƒä¼šï¼š

1. **è¿›å…¥ Candidate çŠ¶æ€**ã€‚
2. **`term +1`**ï¼ˆè¿›å…¥æ–°çš„ä»»æœŸï¼‰ã€‚
3. **å‘é€ `RequestVote RPC` ç»™å…¶ä»–èŠ‚ç‚¹**ï¼Œè¯·æ±‚æŠ•ç¥¨

âœ… ä¾‹å­ï¼š

- å½“å‰ `term = 3`ï¼ŒFollower è¶…æ—¶ï¼Œæˆä¸º Candidateã€‚
- Candidate `term +1`ï¼Œå˜æˆ `term = 4`ã€‚
- å‘å…¶ä»–èŠ‚ç‚¹è¯·æ±‚æŠ•ç¥¨ã€‚

**(2) Candidate å¤±è´¥ï¼Œé‡æ–°è¿›å…¥ä¸‹ä¸€è½®é€‰ä¸¾ï¼ˆ`term +1`ï¼‰**

å¦‚æœ Candidate åœ¨æŸä¸ª `term` å†… **æœªèƒ½è·å¾—åŠæ•°é€‰ç¥¨**ï¼ˆæ¯”å¦‚ä¸¤ä¸ª Candidate ç«äº‰ï¼Œå¯¼è‡´é€‰ç¥¨åˆ†è£‚ï¼‰ï¼Œå®ƒä¼šï¼š

1. **ç­‰å¾…ä¸€ä¸ªéšæœºè¶…æ—¶æ—¶é—´**ï¼ˆä»¥é¿å…å†æ¬¡åˆ†è£‚ï¼‰ã€‚
2. **`term +1`ï¼Œé‡æ–°å°è¯•é€‰ä¸¾**ã€‚
3. **ç»§ç»­å‘å…¶ä»–èŠ‚ç‚¹å‘é€ `RequestVote RPC`**ã€‚

âœ… ä¾‹å­ï¼š

- `term = 4` çš„é€‰ä¸¾å¤±è´¥ã€‚
- è¿›å…¥ä¸‹ä¸€è½®é€‰ä¸¾ï¼Œ`term +1`ï¼Œå˜æˆ `term = 5`ã€‚

**(3) å‘ç°æ›´å¤§çš„ `term`ï¼Œæ›´æ–°è‡ªå·±**

Raft çš„è§„åˆ™ï¼š**å¦‚æœæŸä¸ªèŠ‚ç‚¹æ”¶åˆ°ä¸€ä¸ªæ¯”è‡ªå·±å¤§çš„ `term`ï¼Œå®ƒå¿…é¡»æ›´æ–°è‡ªå·±çš„ `term` å¹¶é™çº§ä¸º Follower**ã€‚

- å¦‚æœ Candidate æˆ– Leader **æ”¶åˆ°ä¸€ä¸ªæ›´å¤§çš„ `term`**ï¼ˆæ¯”å¦‚ `RequestVote RPC` æˆ– `AppendEntries RPC` ä¸­çš„ `term` æ›´å¤§ï¼‰ï¼Œå®ƒä¼šï¼š
  - **æ›´æ–°è‡ªå·±çš„ `term`**
  - **å˜æˆ Follower**
  - **é‡ç½®é€‰ä¸¾è¶…æ—¶ï¼Œç­‰å¾…æ–°çš„ Leader**

âœ… ä¾‹å­ï¼š

- å½“å‰ `term = 5`ï¼ŒLeader æ­£åœ¨å·¥ä½œã€‚
- çªç„¶æ”¶åˆ°æ¥è‡ªå…¶ä»–èŠ‚ç‚¹çš„ `AppendEntries RPC`ï¼Œå‘ç° `term = 6`ã€‚
- è¯´æ˜é›†ç¾¤å·²ç»æœ‰äº†æ–°çš„ Leaderï¼ˆè‡ªå·±æ˜¯è¿‡æœŸçš„ï¼‰ã€‚
- äºæ˜¯ Leader **å›é€€ä¸º Follower**ï¼Œå¹¶æ›´æ–° `term = 6`ã€‚



##### 3ï¸âƒ£ `term` åœ¨ Raft ä¸­çš„ä½œç”¨

**(1) ç»´æŒå…¨å±€æ—¶åº**
 `term` **ä¿è¯äº†é›†ç¾¤çš„æ—¶é—´é¡ºåº**ï¼Œä½¿å¾—ä¸åŒ Leader ä¹‹é—´ä¸ä¼šäº§ç”Ÿæ··ä¹±ï¼š

- **ä¸åŒ `term` ä»£è¡¨ä¸åŒ Leader é€‰ä¸¾å‘¨æœŸ**ã€‚
- **åŒä¸€ä¸ª `term` å†…æœ€å¤šåªèƒ½æœ‰ä¸€ä¸ª Leader**ã€‚

**(2) é€‰ä¸¾åˆæ³•æ€§åˆ¤æ–­**

- **Follower åªä¼šæŠ•ç¥¨ç»™ `term` å¤§äºç­‰äºè‡ªå·±çš„ Candidate**ï¼Œç¡®ä¿ Leader å§‹ç»ˆæ˜¯æœ€æ–°çš„ã€‚
- **å¦‚æœ Candidate `term` è¿‡å°ï¼ŒFollower æ‹’ç»æŠ•ç¥¨**ã€‚

**(3) ä¿æŠ¤é›†ç¾¤ä¸€è‡´æ€§**

- **å¦‚æœ Leader `term` è¿‡æœŸï¼Œå®ƒä¸èƒ½æäº¤æ—¥å¿—**ï¼Œé¿å…æäº¤æ— æ•ˆæ—¥å¿—ã€‚
- **å¦‚æœ Leader å‘ç°æ›´é«˜çš„ `term`ï¼Œå¿…é¡»ç«‹å³é€€ä½**ï¼Œé¿å…å‡ºç°å¤šä¸ª Leaderã€‚



##### 4ï¸âƒ£ `term` çš„å­˜å‚¨

- `term` **å¿…é¡»æŒä¹…åŒ–å­˜å‚¨åˆ°ç£ç›˜**ï¼Œé¿å…èŠ‚ç‚¹é‡å¯åä¸¢å¤±çŠ¶æ€ã€‚
- `term` ä½œä¸º **Raft å…ƒæ•°æ®** å­˜å‚¨åœ¨ `etcd` æˆ– `Kubernetes` çš„ `WAL`ï¼ˆWrite Ahead Logï¼‰æ—¥å¿—ä¸­ã€‚



##### **5ï¸âƒ£ ä¸¾ä¾‹ï¼šRaft é€‰ä¸¾æµç¨‹ï¼ˆå¸¦ `term`ï¼‰**

å‡è®¾ä¸€ä¸ª **5 èŠ‚ç‚¹é›†ç¾¤ï¼ˆA, B, C, D, Eï¼‰**ï¼ŒLeader A å´©æºƒåï¼Œä¼šå‘ç”Ÿå¦‚ä¸‹æƒ…å†µï¼š

1. **åˆå§‹çŠ¶æ€**
   - **æ‰€æœ‰èŠ‚ç‚¹çš„ `term = 1`**
   - **Leader = `A`**
   - **Follower = `B, C, D, E`**
   - `A` å‘é€å¿ƒè·³ (`AppendEntries(term=1)`)
   - `B, C, D, E` æ­£å¸¸æ¥å—å¿ƒè·³ï¼Œç»´æŒ Follower çŠ¶æ€
2. `A` **å´©æºƒ**
   - `B` ç­‰å¾…äº†ä¸€æ®µæ—¶é—´ï¼Œæ²¡æœ‰æ”¶åˆ° `A` çš„å¿ƒè·³ï¼Œè¶…æ—¶è§¦å‘é€‰ä¸¾ã€‚
3. **`B` è¿›å…¥ Candidate çŠ¶æ€**
   - `B.term + 1`ï¼Œ**ä» `1` å˜ä¸º `2`**
   - `B` å‘æ‰€æœ‰èŠ‚ç‚¹ **`C, D, E` å‘é€ `RequestVote(term=2)`**
   - **`C, D, E` å‘ç° `term = 2` å¤§äº `1`ï¼Œäºæ˜¯æ›´æ–° `term = 2`ï¼Œå¹¶æŠŠç¥¨æŠ•ç»™ `B`**
4. **`E` ä¹Ÿè¶…æ—¶ï¼Œè¿›å…¥ Candidate çŠ¶æ€**
   - `E` **è¶…æ—¶ç¨å¾®æ™šäº `B`**ï¼Œæ­¤æ—¶ `B` è¿˜æœªå½“é€‰ Leader
   - `E` è¿›å…¥ **Candidate çŠ¶æ€**ï¼ŒæŒ‰ç…§ Raft è§„åˆ™ï¼š
     - `E.term + 1`ï¼Œä» `2` å˜ä¸º `3`
     - `E` å‘é€ `RequestVote(term=3)` ç»™ `B, C, D`
   - `B, C, D` å‘ç° `term = 3` å¤§äºå½“å‰çš„ `2`ï¼Œäºæ˜¯
     - **æ›´æ–° `term = 3`**
     - **æŠŠç¥¨æŠ•ç»™ `E`**
   - `B` å‘ç° `term = 3` å¤§äºè‡ªå·±çš„ `2`ï¼Œäºæ˜¯
     - **é€€å› Follower çŠ¶æ€**
     - **ä¸å†å‚ä¸æœ¬è½®é€‰ä¸¾**



**ğŸ“Œ å…³é”®ç‚¹æ€»ç»“**

1. **Raft è§„å®šï¼šæ¯ä¸ª Candidate è¿›å…¥é€‰ä¸¾æ—¶ï¼Œå¿…é¡» `term +1`**ã€‚
   - `B` å…ˆå‘èµ·é€‰ä¸¾ï¼Œ`term = 2`
   - `E` ç”±äºè¶…æ—¶æ—¶é—´è¾ƒé•¿ï¼Œæ¯” `B` æ™šï¼Œå‘èµ·é€‰ä¸¾æ—¶ `term = 3`
2. **Follower åœ¨æ¥æ”¶åˆ°æ›´å¤§çš„ `term` æ—¶ï¼Œå¿…é¡»æ›´æ–°è‡ªå·±çš„ `term` å¹¶æŠ•ç¥¨ç»™æ›´é«˜çš„ `term`ã€‚**
   - `E` å‘èµ· `RequestVote(term=3)` æ—¶ï¼Œ`B, C, D` å‘ç° `term = 3 > 2`ï¼Œäºæ˜¯éƒ½æ”¹æˆ `3` å¹¶æŠ•ç¥¨ã€‚
3. **`term` åªä¼šé€’å¢ï¼Œä¸ä¼šå›é€€ã€‚**
   - å¦‚æœ `B` é€‰ä¸¾å¤±è´¥ï¼ˆå¾—ç¥¨ä¸å¤Ÿï¼‰ï¼Œå®ƒä¸ä¼šé™ä½ `term`ï¼Œè€Œæ˜¯ç­‰ `E` å½“é€‰ Leader æˆ–é‡æ–°å‘èµ·é€‰ä¸¾ã€‚
4. **Raft é€šè¿‡ `term` é€’å¢æœºåˆ¶ï¼Œç¡®ä¿æœ€ç»ˆèƒ½é€‰å‡ºä¸€ä¸ª Leader**
   - å¦‚æœ `E` ä¹Ÿå¤±è´¥äº†ï¼ˆé€‰ç¥¨åˆ†è£‚ï¼‰ï¼Œå¯èƒ½è¿˜ä¼šæœ‰ `term = 4`ã€`term = 5` ç›´åˆ°é€‰ä¸¾æˆåŠŸã€‚



**ğŸ“Œ å®è·µä¸­çš„å½±å“**

- **å¦‚æœå¤šä¸ªèŠ‚ç‚¹åŒæ—¶è¶…æ—¶è¿›å…¥ Candidateï¼Œä¼šé€ æˆé€‰ç¥¨åˆ†è£‚ã€‚**
- **Raft é€šè¿‡éšæœºè¶…æ—¶é™ä½ Split Vote å‘ç”Ÿçš„æ¦‚ç‡ï¼Œä½†ä»å¯èƒ½å‘ç”Ÿï¼Œéœ€è¦ç»§ç»­é€‰ä¸¾ã€‚**
- **Raft çš„ `term` é€’å¢æœºåˆ¶ç¡®ä¿äº†æ‰€æœ‰èŠ‚ç‚¹æœ€ç»ˆä¼šæ”¶æ•›åˆ°ä¸€ä¸ª Leader**ã€‚



#### Raft é€‰ä¸¾ä¸­çš„ RequestVote RPC è¯¦è§£

åœ¨ Raft é€‰ä¸¾è¿‡ç¨‹ä¸­ï¼Œå½“ä¸€ä¸ª **Follower è¶…æ—¶** æ²¡æœ‰æ”¶åˆ° **Leader çš„å¿ƒè·³** æ—¶ï¼Œå®ƒä¼šå˜æˆ **Candidate** å¹¶å‘èµ·é€‰ä¸¾ï¼Œå°è¯•æˆä¸ºæ–°çš„ **Leader**ã€‚å‘èµ·é€‰ä¸¾çš„å…³é”®æ­¥éª¤ä¹‹ä¸€æ˜¯ **RequestVote RPC**ï¼Œå³ **å‘å…¶ä»–èŠ‚ç‚¹å‘é€è¯·æ±‚ï¼Œäº‰å–é€‰ç¥¨**ã€‚



##### 1ï¸âƒ£ é€‰ä¸¾è§¦å‘

æ¯ä¸ª **Follower** ç»´æŠ¤ä¸€ä¸ª **é€‰ä¸¾è¶…æ—¶æ—¶é—´ï¼ˆElection Timeoutï¼‰**ï¼Œä¸€èˆ¬ä¸º **150ms ~ 300ms çš„éšæœºæ—¶é—´**ã€‚å¦‚æœåœ¨æ­¤æ—¶é—´å†…ï¼š

- **Follower æ²¡æœ‰æ”¶åˆ° Leader çš„å¿ƒè·³ï¼ˆAppendEntries RPC**ï¼‰
- **æ²¡æœ‰å…¶ä»–èŠ‚ç‚¹å½“é€‰ Leader**

é‚£ä¹ˆ Follower **è¶…æ—¶**ï¼Œå®ƒå°†ï¼š

- **åˆ‡æ¢ä¸º Candidate**
- **å¼€å§‹ä¸€ä¸ªæ–°çš„ Termï¼ˆä»»æœŸç¼–å· +1ï¼‰**
- **ç»™è‡ªå·±æŠ•ç¥¨**
- **å‘å…¶ä»–èŠ‚ç‚¹å‘é€ RequestVote RPC è¿›è¡Œæ‹‰ç¥¨**



##### 2ï¸âƒ£ RequestVote RPC å·¥ä½œåŸç†

åœ¨ Raft ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹åœ¨é€‰ä¸¾è¿‡ç¨‹ä¸­ä¼šå‘é€ **RequestVote RPC** è¯·æ±‚ç»™å…¶ä»–èŠ‚ç‚¹ï¼Œæ‹‰å–é€‰ç¥¨

 **(1) å‘é€æŠ•ç¥¨è¯·æ±‚**

Candidate å‘é›†ç¾¤ä¸­**æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹** å‘é€ `RequestVote` RPC è¯·æ±‚ï¼Œè¯·æ±‚æŠ•ç¥¨ï¼š

```go
RequestVote(term, candidateId, lastLogIndex, lastLogTerm)
```

| å‚æ•°           | è¯´æ˜                     |
| -------------- | ------------------------ |
| `term`         | Candidate çš„å½“å‰ä»»æœŸ     |
| `candidateId`  | Candidate è‡ªå·±çš„ ID      |
| `lastLogIndex` | Candidate æœ€æ–°æ—¥å¿—çš„ç´¢å¼• |
| `lastLogTerm`  | Candidate æœ€æ–°æ—¥å¿—çš„ä»»æœŸ |

æ¯ä¸ª **Follower** æ”¶åˆ° `RequestVote` è¯·æ±‚åï¼Œä¼šè¿›è¡Œ**æŠ•ç¥¨åˆ¤æ–­**ã€‚

 **(2) Follower å¤„ç†æŠ•ç¥¨è¯·æ±‚**

å½“ Follower æ”¶åˆ° **Candidate** çš„ `RequestVote RPC` è¯·æ±‚åï¼Œä¼šæ‰§è¡Œå¦‚ä¸‹é€»è¾‘ï¼š

**âœ… æŠ•ç¥¨ç»™ Candidateï¼ˆåŒæ„ï¼‰**

å¦‚æœæ»¡è¶³ä»¥ä¸‹ **æ‰€æœ‰æ¡ä»¶**ï¼ŒFollower **åŒæ„æŠ•ç¥¨**ï¼š

1. **Candidate çš„ä»»æœŸå·ï¼ˆtermï¼‰** **å¤§äºç­‰äº** Follower å½“å‰çš„ `currentTerm`ï¼ˆä»»æœŸå·å¿…é¡»æ–°ï¼‰ã€‚

2. **Follower è¿˜æ²¡æœ‰æŠ•è¿‡ç¥¨ï¼ˆvotedFor == nilï¼‰**ï¼Œæˆ–è€…å·²ç»æŠ•ç¥¨ç»™è¿™ä¸ª Candidateã€‚

3. Candidate çš„æ—¥å¿—æ¯”è‡ªå·±æ–°ï¼š

   - `lastLogTerm` æ›´å¤§ï¼Œæˆ–è€…
- `lastLogTerm` ç›¸ç­‰ï¼Œä½† `lastLogIndex` æ›´å¤§ï¼ˆä¿è¯ Leader æ‹¥æœ‰æœ€æ–°çš„æ—¥å¿—ï¼‰ã€‚

å¦‚æœä»¥ä¸Šæ¡ä»¶æˆç«‹ï¼ŒFollower **æŠ•ç¥¨ç»™ Candidate**ï¼Œå¹¶æ›´æ–°ï¼š

- `votedFor = candidateId`
- `currentTerm = term`
- å›å¤ `VoteGranted = true`

**Follower è¿”å›å“åº”ç»™ Candidate**

```go
RequestVoteResponse(term, VoteGranted)
```

| å‚æ•°          | è¯´æ˜                 |
| ------------- | -------------------- |
| `term`        | Follower å½“å‰çš„ä»»æœŸ  |
| `VoteGranted` | æ˜¯å¦æŠ•ç¥¨ç»™ Candidate |

**âŒ æ‹’ç»æŠ•ç¥¨**

Follower åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ **æ‹’ç»æŠ•ç¥¨**ï¼š

1. **Candidate çš„ term è¿‡æ—§ï¼ˆterm < currentTermï¼‰**
   - è¯´æ˜ Candidate ä¸æ˜¯æœ€æ–°çš„ Leader å€™é€‰è€…ã€‚
   - ç›´æ¥è¿”å› `VoteGranted = false`ï¼Œæ‹’ç»æŠ•ç¥¨ã€‚
2. **Follower ä¹‹å‰å·²ç»æŠ•ç¥¨ç»™å¦ä¸€ä¸ª Candidateï¼ˆvotedFor â‰  nilï¼‰**
   - Raft é€‰ä¸¾è§„åˆ™è§„å®šï¼Œä¸€ä¸ª Follower åœ¨ä¸€ä¸ª Term **åªèƒ½æŠ•ä¸€æ¬¡ç¥¨**ã€‚
   - å¦‚æœ Follower å·²ç»æŠ•è¿‡ç¥¨ï¼Œåˆ™æ‹’ç»æŠ•ç¥¨ã€‚
3. **Candidate çš„æ—¥å¿—æ¯”è‡ªå·±è½å**
   - å¦‚æœ Candidate **æ—¥å¿—æ²¡æœ‰è‡ªå·±æ–°**ï¼Œæ‹’ç»æŠ•ç¥¨ã€‚
   - è¿™æ ·å¯ä»¥é¿å…é€‰å‡ºä¸€ä¸ªæ—¥å¿—è¿‡æ—¶çš„ Leaderã€‚



##### 3ï¸âƒ£ é€‰ä¸¾æˆåŠŸä¸å¤±è´¥

**ğŸ“ é€‰ä¸¾æˆåŠŸ**

- å¦‚æœ Candidate **æ”¶åˆ°è¶…è¿‡åŠæ•°ï¼ˆ>N/2ï¼‰** é€‰ç¥¨ï¼Œåˆ™å®ƒå½“é€‰ä¸º **Leader**ã€‚

- ç«‹å³å¼€å§‹å‘é€ **å¿ƒè·³ï¼ˆAppendEntries RPCï¼‰**ï¼Œé€šçŸ¥å…¶ä»–èŠ‚ç‚¹ï¼š

   ```go
   AppendEntries(term, leaderId, prevLogIndex, prevLogTerm, entries, leaderCommit)
   ```

- Follower æ”¶åˆ°åï¼Œé‡ç½®è¶…æ—¶æ—¶é—´ï¼Œç»§ç»­ä½œä¸º Followerã€‚

**ğŸ“ é€‰ä¸¾å¤±è´¥** å¦‚æœ Candidate **æ²¡æœ‰è·å¾—å¤šæ•°ç¥¨**ï¼Œé€‰ä¸¾å¤±è´¥ï¼š

1. **å¤šä¸ª Candidate ç«äº‰å¯¼è‡´ç¥¨æ•°åˆ†è£‚**ï¼ˆSplit Voteï¼‰
2. **éƒ¨åˆ† Follower æ‹’ç»æŠ•ç¥¨**
3. **ç½‘ç»œé—®é¢˜å¯¼è‡´éƒ¨åˆ†èŠ‚ç‚¹æ— æ³•æŠ•ç¥¨**

è¿™ç§æƒ…å†µä¸‹ï¼ŒCandidate è¿›å…¥æ–°çš„**éšæœºè¶…æ—¶æ—¶é—´**å **å†æ¬¡å‘èµ·æ–°ä¸€è½®é€‰ä¸¾**ï¼ˆTerm +1ï¼‰ã€‚



##### 4ï¸âƒ£ é€‰ä¸¾è¿‡ç¨‹ç¤ºä¾‹

å‡è®¾æœ‰ **5 ä¸ªèŠ‚ç‚¹ï¼ˆAã€Bã€Cã€Dã€Eï¼‰**ï¼ŒLeader **A å´©æºƒ**ï¼Œé€‰ä¸¾æµç¨‹å¦‚ä¸‹ï¼š

**ğŸ”¹ Step 1: è§¦å‘é€‰ä¸¾**

1. **Leader A å´©æºƒ**ï¼Œå…¶ä»–èŠ‚ç‚¹ç­‰å¾… **Election Timeout**ã€‚
2. ç”±äºæ²¡æœ‰æ”¶åˆ° Leader å¿ƒè·³ï¼Œ**C å˜æˆ Candidate**ï¼š
   - `term = 2`
   - `votedFor = C`
   - ç»™è‡ªå·±æŠ•ç¥¨
   - å‘é€ `RequestVote RPC` ç»™ Bã€Dã€E

**ğŸ”¹ Step 2: å…¶ä»– Follower æŠ•ç¥¨**

- Bã€Dã€E **æ£€æŸ¥ term å’Œæ—¥å¿—**ï¼Œå‘ç° C çš„æ—¥å¿—æ˜¯æœ€æ–°çš„ï¼ŒæŠ•ç¥¨ç»™ Cã€‚
- C **è·å¾— 3/5 ç¥¨**ï¼ˆè¶…è¿‡åŠæ•° 5/2ï¼‰ï¼Œå½“é€‰ä¸º Leaderã€‚

**ğŸ”¹ Step 3: Leader å¼€å§‹å·¥ä½œ**

- C å‘é€ **å¿ƒè·³ï¼ˆAppendEntries RPCï¼‰** ç»™æ‰€æœ‰ Followerã€‚
- å…¶ä»– Follower é‡ç½®é€‰ä¸¾è¶…æ—¶ï¼Œç»§ç»­ä½œä¸º Followerã€‚
- é€‰ä¸¾å®Œæˆï¼



##### 5ï¸âƒ£ è§£å†³ Split Voteï¼ˆå¹³ç¥¨ï¼‰çš„æœºåˆ¶

æœä¸¤ä¸ª Candidate ç«äº‰ï¼Œç¥¨æ•°å¯èƒ½ä¼š **å¹³åˆ†**ï¼ˆSplit Voteï¼‰ï¼Œå¯¼è‡´æ— æ³•é€‰å‡º Leaderã€‚

**ğŸ“ è§£å†³æ–¹æ¡ˆ**

- **éšæœºé€‰ä¸¾è¶…æ—¶ï¼ˆElection Timeout éšæœº 150ms-300msï¼‰**
  - é¿å…æ‰€æœ‰ Follower **åŒæ—¶è¶…æ—¶å¹¶å˜æˆ Candidate**ã€‚
  - è®©æŸä¸ª Follower **æ›´æ—©å‘èµ·é€‰ä¸¾**ï¼Œå¢åŠ èµ¢å¾—é€‰ä¸¾çš„æ¦‚ç‡ã€‚
- **æ—¥å¿—ä¸€è‡´æ€§æ£€æŸ¥**
  - åªæœ‰æ—¥å¿—æœ€æ–°çš„ Candidate æ‰èƒ½èµ¢å¾—é€‰ä¸¾ã€‚
- **Term é€’å¢**
  - æ²¡æœ‰å½“é€‰çš„ Candidate **ç­‰å¾…æ–°çš„è¶…æ—¶**ï¼Œè¿›å…¥ä¸‹ä¸€è½®é€‰ä¸¾ï¼ˆTerm +1ï¼‰ã€‚
  - è¿™æ ·æœ€ç»ˆä¼šæœ‰ä¸€ä¸ªèŠ‚ç‚¹è·å¾—å¤šæ•°ç¥¨ï¼Œæˆä¸º Leaderã€‚



##### **6ï¸âƒ£ æ€»ç»“**

- **RequestVote RPC ä½œç”¨**ï¼šåœ¨é€‰ä¸¾è¿‡ç¨‹ä¸­ï¼ŒCandidate **å‘å…¶ä»–èŠ‚ç‚¹è¯·æ±‚æŠ•ç¥¨**ã€‚
- **æŠ•ç¥¨æ¡ä»¶**ï¼š
  - Candidate çš„ term å¿…é¡»å¤§äºç­‰äºå½“å‰ Follower çš„ termã€‚
  - Candidate çš„æ—¥å¿—å¿…é¡»æ˜¯æœ€æ–°çš„ã€‚
  - Follower **åªèƒ½æŠ•ä¸€æ¬¡ç¥¨**ï¼Œä¸”åªèƒ½æŠ•ç»™ä¸€ä¸ª Candidateã€‚
- **èµ¢å¾—é€‰ä¸¾çš„æ¡ä»¶**ï¼š
  - å¿…é¡»è·å¾— **è¶…è¿‡åŠæ•°ï¼ˆN/2ï¼‰** é€‰ç¥¨ã€‚
- **Split Vote è§£å†³æ–¹æ¡ˆ**ï¼š
  - é€‰ä¸¾è¶…æ—¶æ—¶é—´éšæœºåŒ–ã€‚
  - é€‰æœ€æ–°æ—¥å¿—çš„ Candidateã€‚
  - è¿›å…¥ä¸‹ä¸€è½®é€‰ä¸¾ï¼ˆTerm +1ï¼‰ã€‚



#### å¤åˆ¶çŠ¶æ€æœºï¼ˆRSMï¼‰è¯¦è§£

Raft åè®®ä¸­çš„ **å¤åˆ¶çŠ¶æ€æœºï¼ˆReplicated State Machine, RSMï¼‰** æ˜¯åˆ†å¸ƒå¼ä¸€è‡´æ€§æ ¸å¿ƒæ€æƒ³çš„ä½“ç°ã€‚å®ƒä¿è¯å³ä½¿å¤šä¸ªèŠ‚ç‚¹ååŒå¤„ç†è¯·æ±‚ï¼Œå®ƒä»¬ä»èƒ½ä¿æŒä¸€è‡´çš„çŠ¶æ€ã€‚è¿™ä¸€æ¦‚å¿µæ˜¯ç†è§£ Raft ä»¥åŠ Paxos ç­‰ä¸€è‡´æ€§åè®®çš„å…³é”®ã€‚



##### å¤åˆ¶çŠ¶æ€æœºçš„æ ¸å¿ƒå®šä¹‰

å°†åŒä¸€ä¸ªåˆå§‹çŠ¶æ€çš„çŠ¶æ€æœºå¤åˆ¶åˆ°å¤šä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹æ¥æ”¶ç›¸åŒçš„æ“ä½œæŒ‡ä»¤åºåˆ—ï¼Œæœ€ç»ˆæ‰€æœ‰çŠ¶æ€æœºçŠ¶æ€ä¿æŒä¸€è‡´ã€‚

ç®€å•æ¥è¯´

- æ¯ä¸ªèŠ‚ç‚¹è¿è¡ŒåŒä¸€ä¸ªâ€œç¨‹åºâ€ï¼ˆçŠ¶æ€æœºï¼‰ã€‚
- æ‰€æœ‰èŠ‚ç‚¹éƒ½æ¥æ”¶åˆ°ä¸€æ ·çš„æ“ä½œé¡ºåºï¼ˆé€šè¿‡ Raft åè®®è¾¾æˆå…±è¯†ï¼‰ã€‚
- å› ä¸ºçŠ¶æ€æœºæ˜¯**ç¡®å®šæ€§**çš„ï¼Œæ‰€ä»¥æœ€ç»ˆæ‰€æœ‰èŠ‚ç‚¹çš„çŠ¶æ€æ˜¯ä¸€æ ·çš„ã€‚



##### ä¸ºä»€ä¹ˆéœ€è¦å¤åˆ¶çŠ¶æ€æœºï¼Ÿ

åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œå°¤å…¶æ˜¯ä¸»ä»ç»“æ„ä¸­ï¼Œä¸»èŠ‚ç‚¹å¤„ç†è¯·æ±‚åå¿…é¡»æŠŠçŠ¶æ€â€œå¤åˆ¶â€åˆ°ä»èŠ‚ç‚¹ã€‚é—®é¢˜æ˜¯ï¼š

- ç½‘ç»œå¯èƒ½ä¸¢åŒ…
- èŠ‚ç‚¹å¯èƒ½å´©æºƒ
- ä¸»èŠ‚ç‚¹å¯èƒ½åˆ‡æ¢

ä¸ºäº†è®©æ–°ä¸»èŠ‚ç‚¹çŸ¥é“ä¹‹å‰å‘ç”Ÿäº†ä»€ä¹ˆï¼Œå°±å¿…é¡»**å‡†ç¡®åœ°é‡æ”¾ä¹‹å‰çš„æ“ä½œ**ï¼Œè¿™å°±éœ€è¦å¤åˆ¶çŠ¶æ€æœºã€‚



##### Raft åè®®ä¸­å¦‚ä½•å®ç°å¤åˆ¶çŠ¶æ€æœºï¼Ÿ

æˆ‘ä»¬æ¥çœ‹ä¸‹ Raft çš„å‡ ä¸ªå…³é”®è§’è‰²ä¸æ­¥éª¤ï¼š

**æ—¥å¿—ï¼ˆLogï¼‰**

- æ¯ä¸ªèŠ‚ç‚¹æœ‰ä¸€ä»½æ—¥å¿—ï¼ˆlogï¼‰ï¼Œæ¯æ¡ log æ˜¯å®¢æˆ·ç«¯çš„ä¸€æ¡æŒ‡ä»¤ï¼Œä¾‹å¦‚ `SET x=1`ã€‚
- Leader æ¥æ”¶å®¢æˆ·ç«¯å‘½ä»¤ï¼Œå°†å…¶ä½œä¸ºæ–°çš„æ—¥å¿—é¡¹å†™å…¥æœ¬åœ°ï¼Œå¹¶**å¤åˆ¶**ç»™æ‰€æœ‰ Followerã€‚

**æ—¥å¿—å¤åˆ¶è¿‡ç¨‹**

- Leader å°†æ—¥å¿—å¹¿æ’­ç»™æ‰€æœ‰ Followerã€‚
- Follower æ”¶åˆ°åæš‚å­˜åœ¨æœ¬åœ°ï¼ˆæœªæäº¤çŠ¶æ€ï¼‰ã€‚
- ä¸€æ—¦å¤šæ•°èŠ‚ç‚¹ç¡®è®¤æ¥å—ï¼ŒLeader æäº¤è¯¥æ—¥å¿—æ¡ç›®ï¼Œå¹¶å‘Šè¯‰æ‰€æœ‰ Followerâ€œå¯ä»¥æäº¤äº†â€ã€‚

**åº”ç”¨åˆ°çŠ¶æ€æœº**

- æ—¥å¿—æäº¤åï¼ŒèŠ‚ç‚¹å°±ä¼š**é¡ºåºåœ°å°†æ—¥å¿—åº”ç”¨åˆ°çŠ¶æ€æœº**ä¸­
- åº”ç”¨åçš„çŠ¶æ€å˜æ›´å°±æ˜¯ç³»ç»ŸçŠ¶æ€ï¼Œæ¯”å¦‚å˜é‡ `x=1`ã€‚

```ABAP
åªåº”ç”¨â€œå·²æäº¤â€çš„æ—¥å¿—åˆ°çŠ¶æ€æœºï¼Œç¡®ä¿ä¸€è‡´æ€§ã€‚
```



##### ç¤ºä¾‹è®²è§£

å‡è®¾æˆ‘ä»¬æœ‰ 3 ä¸ªèŠ‚ç‚¹ï¼š`Node A`ï¼ˆLeaderï¼‰ã€`Node B`ã€`Node C`ï¼Œç³»ç»Ÿæ˜¯ä¸€ä¸ªç®€å•çš„ KV å­˜å‚¨ï¼ˆkey-valueï¼‰ã€‚

**å®¢æˆ·ç«¯æ“ä½œï¼š**

```bash
Client -> Leader: SET x = 1
```

**Raft å†…éƒ¨æ­¥éª¤ï¼š**

1. Leaderï¼ˆNode Aï¼‰æ¥æ”¶åˆ°æ“ä½œ `SET x=1`ï¼Œå†™å…¥æœ¬åœ°æ—¥å¿—ï¼š

   ```sql
   log[1]: SET x = 1
   ```

2. Leader å°†è¯¥æ—¥å¿—å¹¿æ’­ç»™ Bã€C èŠ‚ç‚¹ã€‚

   - Bã€C ä¹Ÿå†™å…¥äº† `log[1]: SET x=1`ã€‚

3. Bã€C å›å¤ Leaderï¼šå†™å…¥æˆåŠŸã€‚

4. Leader æ”¶åˆ°â€œå¤šæ•°æˆåŠŸâ€ï¼ˆè‡ªå·± + Bï¼‰ï¼Œè®¤ä¸ºè¯¥æ—¥å¿—å·²**æäº¤**ã€‚

5. Leader åº”ç”¨ `SET x=1` åˆ°æœ¬åœ°çŠ¶æ€æœºï¼š

   ```bash
   çŠ¶æ€æœº: x = 1
   ```

6. Leader é€šçŸ¥ Bã€C ä¹Ÿâ€œæäº¤â€è¯¥æ—¥å¿—ã€‚

7. Bã€C åº”ç”¨ `SET x=1` åˆ°è‡ªå·±çš„çŠ¶æ€æœºã€‚

æœ€ç»ˆæ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€ï¼š

```sql
log[1]: SET x=1
# çŠ¶æ€æœº: x = 1
```



##### ä¸ºä»€ä¹ˆçŠ¶æ€æœºå¿…é¡»æ˜¯â€œç¡®å®šæ€§çš„â€ï¼Ÿ

å¦‚æœçŠ¶æ€æœºæ˜¯éç¡®å®šæ€§çš„ï¼ˆå¦‚ä¾èµ–ç³»ç»Ÿæ—¶é—´ã€éšæœºæ•°ç­‰ï¼‰ï¼Œå³ä½¿æ—¥å¿—ä¸€æ ·ï¼Œæœ€ç»ˆçŠ¶æ€ä¹Ÿä¼šä¸åŒ â†’ ä¸€è‡´æ€§å°±å¤±æ•ˆäº†ã€‚

æ‰€ä»¥ï¼Œ**å¤åˆ¶çŠ¶æ€æœºå¿…é¡»æ˜¯ï¼š

- åˆå§‹çŠ¶æ€ä¸€è‡´
- æ¥æ”¶ç›¸åŒé¡ºåºçš„å‘½ä»¤
- çŠ¶æ€è½¬ç§»é€»è¾‘æ˜¯ç¡®å®šæ€§çš„



##### å¤åˆ¶çŠ¶æ€æœº vs æ•°æ®å¤åˆ¶

| æ¦‚å¿µ       | æè¿°                                                     |
| ---------- | -------------------------------------------------------- |
| æ•°æ®å¤åˆ¶   | æŠŠæ–‡ä»¶/æ•°æ®å—æ‹·è´åˆ°å¤šä¸ªèŠ‚ç‚¹ï¼ˆå¦‚ HDFSï¼‰                   |
| å¤åˆ¶çŠ¶æ€æœº | æŠŠâ€œæ“ä½œâ€å¤åˆ¶åˆ°å¤šä¸ªèŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹ç‹¬ç«‹æ‰§è¡Œç›¸åŒæ“ä½œä»¥ä¿æŒä¸€è‡´æ€§ |

å¤åˆ¶çŠ¶æ€æœºæ˜¯**å¼ºä¸€è‡´æ€§**çš„åŸºç¡€ã€‚





### leader election

#### Role

é¦–å…ˆå…ˆè¯´æ˜ä¸‹Raftç®—æ³•ä¸­èŠ‚ç‚¹çš„è§’è‰²ï¼Œåˆ†ä¸ºä»¥ä¸‹ä¸‰ç§ï¼š

- **leader**ï¼šç”±æ‰€æœ‰èŠ‚ç‚¹é€‰ä¸¾ï¼Œåœ¨candidateä¸­äº§ç”Ÿï¼Œè´Ÿè´£æ•´ä¸ªé›†ç¾¤çš„çŠ¶æ€ä»¥åŠå…ƒæ•°æ®ç®¡ç†ï¼Œå½“å‘ç°æ›´å¤§çš„termæ—¶ï¼Œè½¬åŒ–ä¸ºfollower
- **candidate**ï¼šç”±followeråœ¨é›†ç¾¤é€‰ä¸¾æ—¶è½¬åŒ–è€Œæˆï¼Œé€‰ä¸¾æ—¶å¾—åˆ°å¤šæ•°é€‰ç¥¨ï¼Œåˆ™è½¬åŒ–ä¸ºleaderï¼Œè‹¥å‘ç°ä¸»èŠ‚ç‚¹æˆ–è€…æ›´å¤§çš„termåˆ™è½¬åŒ–ä¸ºfollower
- **follower**ï¼šé›†ç¾¤åˆå§‹åŒ–æ—¶æ‰€æœ‰èŠ‚ç‚¹çš„è§’è‰²éƒ½æ˜¯followerï¼Œè‹¥æœªå‘ç°leaderå¿ƒè·³ï¼Œåˆ™å‘èµ·leaderé€‰ä¸¾ï¼Œå¹¶å°†è§’è‰²è½¬åŒ–ä¸ºcandidateï¼›leaderä»¥åŠcandidateåœ¨æŸäº›æ¡ä»¶ä¸‹ä¹Ÿä¼šè½¬åŒ–æˆfollower

ç»™å‡ºçŠ¶æ€æœºï¼ŒååŠ©å¤§å®¶ç†è§£

![image-20250312140445473](../markdown_img/image-20250312140445473.png)

#### leader election process

ä¸‹é¢å°±æ¥è¯´è¯´leaderé€‰ä¸¾çš„è¯¦ç»†è¿‡ç¨‹ï¼Œä»ä¸Šé¢çš„çŠ¶æ€æœºå¯ä»¥çœ‹å‡ºï¼Œé›†ç¾¤åˆå§‹åŒ–æ—¶ï¼Œå¤§å®¶éƒ½æ˜¯followerï¼Œå½“æœªå‘ç°leaderå¿ƒè·³å¹¶è¶…æ—¶åï¼Œåˆ™followerå˜æˆcandidateï¼Œå¹¶å‘èµ·leader electionã€‚æ¯ä¸ªcandidateçš„åŠ¨ä½œå¦‚ä¸‹ï¼š

- ç»™è‡ªå·±æŠ•ä¸€ç¥¨
- å‘å…¶ä»–èŠ‚ç‚¹å‘èµ·RequestVote RPCæ¥è¿›è¡Œæ‹‰ç¥¨
- ç­‰å¾…å…¶ä»–èŠ‚ç‚¹çš„å“åº”

**åœ¨æ­¤è¿‡ç¨‹ä¸­ä¼šå‡ºç°ä¸‰ç§æƒ…å†µ**

- è¯¥candidateæ”¶åˆ°äº†å¤šæ•°ï¼ˆmajorityï¼‰çš„é€‰ç¥¨å½“é€‰äº†leaderï¼Œå¹¶å‘é€leaderå¿ƒè·³å‘ŠçŸ¥å…¶ä»–èŠ‚ç‚¹ï¼Œå…¶ä»–èŠ‚ç‚¹å…¨éƒ¨å˜æˆfollowerï¼Œé›†ç¾¤é€‰ä¸»æˆåŠŸ

- è¯¥candidateæ”¶åˆ°äº†å…¶ä»–èŠ‚ç‚¹å‘æ¥çš„leaderå¿ƒè·³ï¼Œè¯´æ˜ä¸»èŠ‚ç‚¹å·²ç»é€‰ä¸¾æˆåŠŸï¼Œè¯¥candidateå˜æˆfollowerï¼Œé›†ç¾¤é€‰ä¸»æˆåŠŸ
- ä¸€æ®µæ—¶é—´å†…ï¼ˆelection timeoutï¼‰ï¼Œè¯¥candidateæœªæ”¶åˆ°è¶…è¿‡åŠæ•°çš„é€‰ç¥¨ï¼Œä¹Ÿæœªæ”¶åˆ°leaderå¿ƒè·³ï¼Œåˆ™è¯´æ˜è¯¥è½®é€‰ä¸»å¤±è´¥ï¼Œé‡å¤è¿›è¡Œleader electionï¼Œç›´åˆ°é€‰ä¸»æˆåŠŸ

**ä¸Šè¿°æƒ…å†µçš„äº§ç”Ÿéœ€è¦æ»¡è¶³ä¸‹é¢å‡ ä¸ªçº¦æŸï¼š**

- åœ¨æ¯ä¸ªä»»æœŸä¸­æ¯ä¸ªäººåªèƒ½æŠ•å‡ºä¸€ç¥¨ï¼šæ³¨æ„æ˜¯æ¯ä¸ªä»»æœŸï¼Œä»»æœŸå˜äº†ï¼ˆå‡†ç¡®çš„è¯´æ³•æ˜¯ä»»æœŸå¢åŠ äº†ï¼‰å°±å¯ä»¥é‡æ–°æŠ•ç¥¨
- æŠ•ç¥¨çš„è§„åˆ™ï¼šcandidateè‚¯å®šæŠ•ç»™è‡ªå·±ï¼Œfolloweræ˜¯å…ˆåˆ°å…ˆå¾—
- å½“é€‰leaderçš„æ¡ä»¶æ˜¯å¾—åˆ°å¤šæ•°ï¼ˆN/2+1ï¼‰é€‰ç¥¨ï¼šæ­¤å¤„çš„å¤šæ•°é€‰ç¥¨æ˜¯ä¸ºäº†é¿å…è„‘è£‚è€Œå‡ºç°å¤šleaderçš„æƒ…å†µè€Œè¿›è¡Œçš„çº¦æŸï¼Œä¿è¯äº†æ•´ä¸ªé›†ç¾¤ä¸­leaderçš„å”¯ä¸€æ€§
- leaderçš„æ¶ˆæ¯æ˜¯æœ€æ–°çš„ï¼ˆå…¶å®å°±æ˜¯termæœ€å¤§ï¼Œindexä¹Ÿæ˜¯æœ€å¤§çš„ï¼Œåé¢çš„log replicationæ¨¡å—è¿›è¡Œè¯¦ç»†åˆ†æï¼‰

**ä¸¾ä¾‹è¯´æ˜**

æœ‰äº”ä¸ªå°ä¼™ä¼´è¦é€‰å–ä¸€ä¸ªç»„é•¿ï¼Œé€‰ä¸¾è¿‡ç¨‹å¦‚ä¸‹ï¼š

æ³¨ï¼šF,C,Låˆ†åˆ«å¯¹åº”çš„æ˜¯followerï¼Œcandidateå’Œleaderè§’è‰²ï¼Œåœ¨æœ¬ä¾‹ä¸­å°±æ˜¯ç»„å‘˜ï¼Œå€™é€‰äººå’Œç»„é•¿ï¼›åå­—æ˜¯ç”¨æ¥åŒºåˆ†èŠ‚ç‚¹çš„æ ‡è¯†ï¼›è€Œæ‹¬å·ä¸­çš„æ•°å­—åˆ™ä»£è¡¨ç€termçš„å€¼

![image-20250312142930650](../markdown_img/image-20250312142930650.png)

1. åˆå§‹çŠ¶æ€å¤§å®¶éƒ½æ˜¯ç»„å‘˜ï¼Œç­‰å¾…ç»„é•¿è”ç³»è‡ªå·±
2. ç­‰å¾…ä¸€æ®µæ—¶é—´åï¼ˆleader heartbeat timeoutï¼‰ï¼Œæ˜Œå¦ï¼Œç»§ä¸œå’Œå‘ˆç¥¥å‘ç°æ²¡æœ‰ç»„é•¿æˆ–è€…ç»„é•¿æ‰çº¿äº†ï¼Œè¿™ä¸‰ä¸ªäººå°±å˜æˆäº†å€™é€‰äººï¼Œç„¶åå‘èµ·äº†ç»„é•¿é€‰ä¸¾çš„æµç¨‹
3. é€‰ä¸¾å¼€å§‹åï¼Œä¸‰ä¸ªå€™é€‰äººéƒ½å°†è‡ªå·±çš„ä»»æœŸåŠ 1å˜æˆäº†2ï¼Œç„¶åæŠ•äº†è‡ªå·±ä¸€ç¥¨ï¼Œè€Œç»„å‘˜æ™“é€šé€‰äº†æ˜Œå¦ï¼Œç»„å‘˜æºªæ³½é€‰äº†å‘ˆç¥¥ï¼Œä¸‰ä¸ªå€™é€‰äººçš„ç¥¨æ•°æ¯”æ˜¯2ï¼š1ï¼š2ï¼Œæœªèƒ½è¾¾åˆ°æ³•å®šçš„åŠæ•°ä»¥ä¸Šçš„å¤šæ•°ç¥¨ï¼Œæœªèƒ½é€‰å‡ºç»„é•¿
4. æ¼«é•¿çš„ç­‰å¾…åï¼ˆelection timeoutï¼‰ï¼Œæ˜Œå¦å‘ç°è‡ªå·±æ²¡æœ‰è·å¾—å¤šæ•°é€‰ç¥¨ï¼Œä¹Ÿæ²¡æœ‰æ”¶åˆ°å…¶ä»–å€™é€‰äººå½“é€‰ç»„é•¿çš„æ¶ˆæ¯ï¼ˆleader heartbeatï¼‰ï¼Œæ„è¯†åˆ°äº†æ­¤æ¬¡é€‰ä¸¾å¤±è´¥ï¼Œç„¶åå°†è‡ªå·±çš„ä»»æœŸåŠ 1å˜æˆ3ï¼Œå†æ¬¡å‘èµ·é€‰ä¸¾ï¼Œç»„å‘˜æ™“é€šå’Œæºªæ³½å‘ç°è¯¥ä»»æœŸä¸­æœªæŠ•ç¥¨ ï¼Œå…ˆåˆ°å…ˆå¾—ï¼Œç›´æ¥æŠ•ç»™äº†æ˜Œå¦ï¼Œè€Œå€™é€‰äººç»§ä¸œå’Œå‘ˆç¥¥å‘ç°æ˜Œå¦çš„ä»»æœŸæ¯”è‡ªå·±å¤§ï¼Œåˆ™æ”¾å¼ƒå€™é€‰äººçš„è§’è‰²å˜æˆäº†ç»„å‘˜å¹¶æŠ•ç¥¨ç»™æ˜Œå¦ï¼ˆæ­¤å¤„ä»å€™é€‰äººå˜æˆç»„å‘˜ä¹Ÿå¯èƒ½æ˜¯æ”¶åˆ°äº†æ˜Œå¦å½“é€‰ç»„é•¿çš„æ¶ˆæ¯åè½¬å˜çš„ï¼Œå› ä¸ºç»„é•¿çš„å½“é€‰å¹¶ä¸éœ€è¦å…¨ç¥¨ï¼Œåªè¦è¾¾åˆ°å¤šæ•°é€‰ç¥¨å³å¯ï¼‰
5. æ˜Œå¦å…¨ç¥¨å½“é€‰ç»„é•¿ï¼Œå¹¶å‘å…¶ä»–ç»„å‘˜é€šæŠ¥äº†è‡ªå·±æˆä¸ºç»„é•¿çš„æ¶ˆæ¯ï¼Œåç»­æ‰€æœ‰çš„ç»„å†…ç®¡ç†ä»¥åŠæ¶ˆæ¯åŒæ­¥éƒ½é€šè¿‡ç»„é•¿æ˜Œå¦å‘å…¶ä»–ç»„å‘˜ä¼ è¾¾



æ•´ä¸ªleader electionæµç¨‹å°±æ˜¯è¿™æ ·ï¼Œæ˜¯ä¸æ˜¯å¾ˆå¥½ç†è§£ï¼ŒåŸºæœ¬ä¸Šç¬¦åˆç°å®ç”Ÿæ´»ä¸­çš„ç†è§£ã€‚ä½†æ˜¯ä¸Šè¿°çš„æµç¨‹å¯èƒ½æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œåˆ†ä¸ºä»¥ä¸‹ä¸¤ç§æƒ…å†µï¼š

- å¦‚æœåœ¨ç¬¬ä¸‰é˜¶æ®µä¸‰ä¸ªå€™é€‰äººåŒæ—¶å‘ç°é€‰ä¸¾æœªæˆåŠŸï¼ŒåŒæ—¶å‘èµ·äºŒæ¬¡é€‰ä¸¾ï¼Œè€Œæ°å¥½æ˜Œå¦å’Œæ™“é€šçš„å…³ç³»å¾ˆå¥½ï¼Œå‘ˆç¥¥å’Œæºªæ³½çš„å…³ç³»å¾ˆå¥½ï¼ˆå…³ç³»å¥½å¯ä»¥ç†è§£ä¸ºç½‘ç»œè¿‘ï¼Œä¼˜å…ˆåˆ°è¾¾ï¼Œä¼˜å…ˆè·å¾—æŠ•ç¥¨ï¼‰ï¼Œåˆ™å¯èƒ½å‡ºç°å¤šæ¬¡2ï¼š1ï¼š2ï¼Œæ— æ³•è¾¾åˆ°å¤šæ•°ï¼ˆmajorityï¼‰çš„æƒ…å†µ
- å¦‚æœå½“å‰çš„ç»„å‘˜ä¸æ˜¯5ä¸ªäººï¼Œè€Œæ˜¯4ä¸ªäººæˆ–è€…6ä¸ªäººï¼Œè€Œå€™é€‰äººæ˜¯2ä¸ªï¼Œåˆ™ä¼šå‡ºç°2ï¼š2æˆ–è€…3ï¼š3çš„æƒ…å†µï¼Œæ— æ³•è¾¾åˆ°å¤šæ•°ï¼ˆmajorityï¼‰çš„æƒ…å†µ

ä¸Šè¿°çš„ä¸¤ç§æƒ…å†µä¼šå½±å“åˆ°leader electionçš„æˆåŠŸç‡å’Œæ•ˆç‡ï¼Œåœ¨è®¾è®¡ä¸­åº”è¯¥è¢«è§„é¿ï¼Œé¢å¯¹è¿™ä¸¤ç§æƒ…å†µï¼ŒRaftç»™å‡ºäº†è‡ªå·±çš„è§£å†³æ–¹æ¡ˆï¼š

- èŠ‚ç‚¹æ•°å°½é‡æ˜¯å¥‡æ•°ä¸ªï¼Œå°½é‡ä¿è¯majorityçš„äº§ç”Ÿ
- æ¯ä¸ªcandidateçš„election timeoutæ—¶é—´åœ¨æŸä¸€ä¸ªæ—¶é—´æ®µå†…éšæœºï¼Œå¦‚150ms-300ms,è¿™æ ·èƒ½æœ€å¤§ç¨‹åº¦ä¸Šé¿å…åŒæ—¶å†æ¬¡å‘èµ·é€‰ä¸¾çš„æ¦‚ç‡ï¼ŒæŸä¸ªcandidateå¯ä»¥ç‡å…ˆå‘ç°election timeoutç„¶åå¢åŠ termå¹¶é‡æ–°å‘èµ·é€‰ä¸¾ï¼Œå¤§æ¦‚ç‡èƒ½è·å¾—å¤šæ•°é€‰ç¥¨è€Œå½“é€‰ï¼Œå¦å¤–æ¯ä¸€æ¬¡é€‰ä¸¾æ¯ä¸ªcandidateéƒ½ä¼šåˆ·æ–°election timeoutï¼Œæ¥ä¿è¯majorityçš„äº§ç”Ÿ



### log replication

æ­£å¦‚å‰é¢çš„å†…å®¹æåˆ°çš„çŠ¶æ€å¤åˆ¶æœºï¼Œåªè¦ä¿è¯èŠ‚ç‚¹logçš„ä¸€è‡´æ€§ï¼Œå°±å¯ä»¥ä¿è¯æœ€ç»ˆçš„ä¸€è‡´æ€§ã€‚Raftèµ‹äºˆäº†leaderèŠ‚ç‚¹æ›´å¼ºçš„é¢†å¯¼åŠ›ï¼Œæ‰€æœ‰çš„logéƒ½å¿…é¡»äº¤ç»™leaderèŠ‚ç‚¹å¤„ç†ï¼Œå¹¶ç”±leaderèŠ‚ç‚¹å¤åˆ¶ç»™å…¶å®ƒèŠ‚ç‚¹ã€‚è¿™ä¸ªè¿‡ç¨‹ï¼Œå°±å«åšæ—¥å¿—å¤åˆ¶ï¼ˆLog replicationï¼‰

**ä¸‹å›¾å°±æ˜¯è¯·æ±‚å†™å…¥å¤„ç†çš„ç›¸å…³æµç¨‹ï¼š**

![image-20250312143959304](../markdown_img/image-20250312143959304.png)

1. å®¢æˆ·ç«¯å‘leaderæäº¤å†™å…¥è¯·æ±‚
2. leaderæ¥æ”¶åˆ°å®¢æˆ·ç«¯è¯·æ±‚åå°è£…RPCå¹¶è¡Œå°†ä¿®æ”¹å‘é€åˆ°follower
3. followeråœ¨æ¥æ”¶åˆ°leaderå‘é€çš„RPCåï¼Œå›å¤leaderå·²ç»æ”¶åˆ°è¯¥è¯·æ±‚
4. åœ¨leaderæ¥æ”¶åˆ°å¤šæ•°ï¼ˆmajorityï¼Œå«leaderï¼‰followerçš„å›å¤åï¼Œå›å¤å®¢æˆ·ç«¯æ¥æ”¶æˆåŠŸï¼Œå°†å˜æ›´çŠ¶æ€è®¾ç½®ä¸º***\*commited\****ï¼Œç„¶åå°†å˜æ›´å†™å…¥åˆ°çŠ¶æ€æœºï¼Œæ­¤æ—¶å†™å…¥å®é™…ä¸Šå·²ç»ç”Ÿæ•ˆï¼Œæ— æ³•å›æ»š
5. leaderä¸followeré€šä¿¡ï¼ŒååŠ©followerå®Œæˆå˜æ›´çš„æäº¤ï¼Œå½“å˜æ›´æäº¤å®Œæ¯•åï¼Œfollowerä¼šå°†å˜æ›´å†™å…¥åˆ°çŠ¶æ€æœºï¼Œæ­¤æ—¶å˜æ›´æ‰çœŸæ­£çš„å½±å“åˆ°èŠ‚ç‚¹ï¼Œæ­¤æ—¶çš„çŠ¶æ€å¯ä»¥ç†è§£ä¸ºappliedã€‚æ­¤è¿‡ç¨‹ä¸­ï¼Œå¯èƒ½ä¼šå‡ºç°å„ç§é—®é¢˜ï¼Œæ¯”å¦‚è¯´ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œå‘½ä»¤æ‰§è¡Œä¸æˆåŠŸç­‰é—®é¢˜ï¼Œleaderä¼šæŒç»­å’Œfollowerè¿›è¡Œé€šä¿¡ï¼Œä¿è¯followeræœ€ç»ˆå®Œæˆæ‰€æœ‰çš„æ“ä½œï¼Œä¸leaderè¾¾æˆæœ€ç»ˆä¸€è‡´æ€§ã€‚è¿™ç§æœ€ç»ˆä¸€è‡´æ€§æ˜¯å¯¹å†…çš„ï¼Œå¯¹å¤–éƒ¨çš„clientçš„é€æ˜çš„ï¼Œå¤–éƒ¨çš„clientåªä¼šçœ‹åˆ°leaderä¸ŠçŠ¶æ€çš„å¼ºä¸€è‡´æ€§ã€‚è¿™ç§å¼ºä¸€è‡´æ€§å’Œæœ€ç»ˆä¸€è‡´æ€§çš„é…åˆä½¿ç”¨ï¼Œä¸ä»…é™ä½äº†ä¸€è‡´æ€§å®ç°çš„å„ç§æˆæœ¬ï¼Œè¿˜ä¿è¯äº†ç³»ç»Ÿçš„å¥å£®æ€§ï¼Œèƒ½ä¿è¯åœ¨å„ç§å¼‚å¸¸æƒ…å†µä¸‹çš„æ¢å¤ä¸çŠ¶æ€åŒæ­¥ã€‚
   

![image-20250409154633366](../markdown_img/image-20250409154633366.png)

æ—¥å¿—çš„ç»“æ„é€šå¸¸å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæ¯ä¸ªæ—¥å¿—æ¡ç›®éƒ½åŒ…å«leaderæ”¶åˆ°è¯¥æ¡ç›®æ—¶çš„ä»»æœŸå’ŒçŠ¶æ€æœºçš„å‘½ä»¤ï¼Œä»»æœŸå·å¯ä»¥ç”¨äºæ£€æµ‹æ—¥å¿—ä¹‹é—´çš„ä¸ä¸€è‡´ã€‚æ¯ä¸ªæ—¥å¿—æ¡ç›®è¿˜æœ‰ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°ç´¢å¼•å€¼ï¼ˆlog indexï¼‰ï¼Œå¯ä»¥ç”¨äºæ ‡è¯†å…¶åœ¨æ—¥å¿—é›†åˆä¸­çš„ä½ç½®ã€‚æ­¤å¤–ï¼Œæ¯æ¡æ—¥å¿—è¿˜ä¼šå­˜å‚¨ä¸€ä¸ªterm numberï¼ˆæ—¥å¿—æ¡ç›®æ–¹å—æœ€ä¸Šæ–¹çš„æ•°å­—ï¼Œç›¸åŒé¢œè‰²ä»»æœŸå·ç›¸åŒï¼‰ï¼Œè¯¥termè¡¨ç¤ºleaderæ”¶åˆ°è¿™æ¡æŒ‡ä»¤æ—¶çš„å½“å‰ä»»æœŸï¼Œtermç›¸åŒçš„logæ˜¯ç”±åŒä¸€ä¸ªleaderåœ¨å…¶ä»»æœŸå†…å‘é€çš„ã€‚
ä¸€æ—¦Leaderè¢«é€‰ä¸¾å‡ºæ¥ï¼Œåç»­çš„æ¥å—å®¢æˆ·ç«¯è¯·æ±‚ä»¥åŠæ—¥å¿—å¤åˆ¶ç­‰æ“ä½œä¸»è¦ç”±leaderè´Ÿè´£ã€‚å®¢æˆ·ç«¯çš„æ¯ä¸ªè¯·æ±‚éƒ½åŒ…å«äº†éœ€è¦ç”±å¤åˆ¶çŠ¶æ€æœºæ‰§è¡Œçš„å‘½ä»¤ï¼Œleaderä¼šå°†å‘½ä»¤ä½œä¸ºæ–°æ¡ç›®é™„åŠ åˆ°å…¶æ—¥å¿—ä¸­ï¼Œç„¶åå‘å…¶ä»–æœåŠ¡å™¨å¹¶è¡Œå‘å‡ºAppendEntries RPCä»¥ä¾¿å®ƒä»¬å¤åˆ¶è¯¥æ¡ç›®åˆ°ç›¸åº”çš„æ—¥å¿—ä¸­ã€‚

å¦‚æœfollowerèŠ‚ç‚¹å®•æœºæˆ–è€…è¿è¡Œç¼“æ…¢ï¼Œå†æˆ–è€…ç½‘ç»œæ•°æ®åŒ…ä¸¢å¤±ï¼Œleaderä¼šä¸æ–­åœ°é‡è¯•AppendEntries RPCï¼Œç›´åˆ°followerèŠ‚ç‚¹æœ€åå­˜å‚¨äº†æ‰€æœ‰çš„æ—¥å¿—æ¡ç›®ã€‚
ä¸€æ—¦Leaderæ”¶åˆ°è¶…è¿‡ä¸€åŠfollowerçš„ç¡®è®¤ï¼Œåˆ™è¡¨æ˜è¯¥æ¡ç›®å·²è¢«æˆåŠŸå¤åˆ¶ï¼ˆæ¯”å¦‚ä¸Šå›¾ä¸­çš„log index 7ï¼‰ã€‚Leaderå°†è¯¥æ¡ç›®åº”ç”¨ï¼ˆapply)åˆ°å…¶æœ¬åœ°çŠ¶æ€æœºï¼ˆè¢«è§†ä¸ºcommittedï¼‰å¹¶å°†æ‰§è¡Œç»“æœè¿”å›ç»™å®¢æˆ·ç«¯ã€‚æ­¤äº‹ä»¶è¿˜ä¼šæäº¤leaderæ—¥å¿—ä¸­ä¹‹å‰å­˜åœ¨çš„æ¡ç›®ï¼ŒåŒ…æ‹¬å‰ä»»leaderåˆ›å»ºçš„æ¡ç›®ã€‚
Leaderä¼šæŒç»­å‘é€å¿ƒè·³åŒ…ç»™ followersï¼Œå¿ƒè·³åŒ…ä¸­ä¼šæºå¸¦å½“å‰å·²ç»å®‰å…¨å¤åˆ¶ï¼ˆæˆ‘ä»¬ç§°ä¹‹ä¸ºcommittedï¼‰çš„æ—¥å¿—ç´¢å¼•ï¼Œä»¥ä¾¿å…¶ä»–æœåŠ¡å™¨çŸ¥æ™“ã€‚ä¸€æ—¦followerå¾—çŸ¥æ—¥å¿—æ¡ç›®å·²æäº¤ï¼Œå®ƒå°±ä¼šå°†è¯¥æ¡ç›®åº”ç”¨åˆ°å…¶æœ¬åœ°çŠ¶æ€æœºï¼ˆæŒ‰æ—¥å¿—é¡ºåºï¼‰ã€‚



Raftçš„æ—¥å¿—æœºåˆ¶ï¼ˆå®‰å…¨è§„åˆ™ï¼šæ—¥å¿—åŒ¹é…å±æ€§ï¼‰ç¡®ä¿äº†é›†ç¾¤ä¸­æ‰€æœ‰æœåŠ¡å™¨ä¹‹é—´æ—¥å¿—çš„é«˜åº¦ä¸€è‡´æ€§ã€‚æ—¥å¿—åŒ¹é…æŒ‡çš„æ˜¯è¯´ï¼š

- å¦‚æœä¸åŒæ—¥å¿—ä¸­çš„ä¸¤ä¸ªæ¡ç›®æ‹¥æœ‰ç›¸åŒçš„termå’Œindexï¼Œåˆ™å®ƒä»¬å­˜å‚¨ç€ç›¸åŒçš„å‘½ä»¤ã€‚åŸå› å°±æ˜¯å› ä¸ºraftè¦æ±‚leaderåœ¨ä¸€ä¸ªtermå†…é’ˆå¯¹åŒä¸€ä¸ªindexåªèƒ½åˆ›å»ºä¸€æ¡æ—¥å¿—ï¼Œå¹¶ä¸”æ°¸è¿œä¸ä¼šä¿®æ”¹ï¼Œä¿è¯â€œæŒä¹…åŒ–â€ï¼›

- å½“å‘é€AppendEntries RPCæ—¶ï¼Œleaderåœ¨å…¶æ—¥å¿—ä¸­ä¼šé¢å¤–åŒ…å«ç´§é‚»æ–°æ¡ç›®ä¹‹å‰çš„æ—¥å¿—çš„indexå’Œtermä¿¡æ¯ã€‚å¦‚æœfollowersåœ¨å…¶æ—¥å¿—ä¸­æ‰¾ä¸åˆ°å…·æœ‰ç›¸åŒç´¢å¼•å’Œä»»æœŸçš„æ—¥å¿—æ¡ç›®ï¼Œåˆ™å®ƒä¼šæ‹’ç»æ–°çš„æ—¥å¿—æ¡ç›®ã€‚å› æ­¤ï¼Œå¦‚æœä¸åŒæ—¥å¿—ä¸­çš„ä¸¤ä¸ªæ¡ç›®å¦‚æœæ‹¥æœ‰ç›¸åŒçš„indexå’Œtermï¼Œåˆ™æ‰€æœ‰å…ˆå‰æ¡ç›®ä¸­çš„æ—¥å¿—ä¹Ÿéƒ½æ˜¯ç›¸åŒçš„ï¼›

  **Raft çš„ AppendEntriesï¼ˆå¿ƒè·³æˆ–æ—¥å¿—åŒæ­¥ï¼‰è¯·æ±‚ä¸­ï¼Œå…³é”®å­—æ®µåŒ…æ‹¬ï¼š**

  | å­—æ®µå         | è¯´æ˜                                                       |
  | -------------- | ---------------------------------------------------------- |
  | `term`         | Leader çš„å½“å‰ä»»æœŸ                                          |
  | `leaderId`     | Leader çš„ ID                                               |
  | `prevLogIndex` | æœ¬æ¬¡è¦è¿½åŠ çš„æ—¥å¿—æ¡ç›®å‰ä¸€æ¡çš„æ—¥å¿—ç´¢å¼•ï¼ˆå³å‰ç½®æ—¥å¿—çš„ indexï¼‰ |
  | `prevLogTerm`  | ä¸ `prevLogIndex` å¯¹åº”çš„æ—¥å¿—æ¡ç›®çš„ä»»æœŸï¼ˆtermï¼‰             |
  | `entries[]`    | æœ¬æ¬¡è¦è¿½åŠ çš„æ—¥å¿—æ¡ç›®æ•°ç»„ï¼ˆå¯èƒ½ä¸ºç©ºï¼Œè¡¨ç¤ºä»…å¿ƒè·³ï¼‰           |
  | `leaderCommit` | Leader å½“å‰çš„ commitIndex                                  |

- **ä¸ºä»€ä¹ˆéœ€è¦ `prevLogIndex` å’Œ `prevLogTerm`ï¼Ÿ**

  è¿™ä¸ªæœºåˆ¶æ˜¯ Raft ä¿è¯æ—¥å¿—ä¸€è‡´æ€§çš„å…³é”®ï¼š

  **ä½œç”¨ï¼š**

  - ç¡®ä¿ Follower çš„æ—¥å¿—ä¸ Leader ä¹‹é—´æ˜¯â€œæ— ç¼å¯¹æ¥â€çš„ã€‚
  - é˜²æ­¢ Follower æ¥å—å’Œ Leader ä¸ä¸€è‡´çš„æ—¥å¿—æ¡ç›®ã€‚

  **ä¸¾ä¾‹è¯´æ˜ï¼š**

  å‡è®¾ Leader æƒ³è¦å‘é€ index=5 çš„æ—¥å¿—æ¡ç›®ç»™ Followerï¼Œ é‚£ä¹ˆå®ƒä¼šåœ¨è¯·æ±‚é‡Œå¸¦ä¸Šï¼š

  ```sql
  prevLogIndex = 4
  prevLogTerm = <term of log[4]>
  ```

  Follower æ”¶åˆ°åä¼šæ£€æŸ¥ï¼š

  - å®ƒçš„æ—¥å¿—ä¸­æ˜¯å¦å­˜åœ¨ index=4
  - å¹¶ä¸”è¯¥ä½ç½®çš„ term æ˜¯å¦ç­‰äº `prevLogTerm`

  å¦‚æœéƒ½ **åŒ¹é…**ï¼Œè¯´æ˜æ—¥å¿—å‰åä¸€è‡´ï¼ŒFollower å°±ä¼šæ¥å—åç»­æ—¥å¿—æ¡ç›®ã€‚

  å¦åˆ™ï¼Œå°±ä¼š **æ‹’ç»**æ­¤æ¬¡æ—¥å¿—è¿½åŠ è¯·æ±‚ï¼ˆè¿”å› falseï¼‰ï¼Œ Leader ä¼šå‘å‰å›é€€ indexï¼Œç›´åˆ°æ‰¾åˆ°åŒ¹é…ç‚¹ä¸ºæ­¢ã€‚

  

**AppendEntriesä¼šæ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥ä¿ç•™ä¸Šè¿°å±æ€§**

æ¯å½“ AppendEntries æˆåŠŸè¿”å›æ—¶ï¼Œleaderå°±å¯ä»¥çŸ¥é“followerçš„æ—¥å¿—ä¸è‡ªå·±çš„æ—¥å¿—ç›¸åŒã€‚æ­£å¸¸è¿è¡Œæ—¶ï¼Œleaderå’Œfollowerçš„æ—¥å¿—ä¿æŒä¸€è‡´ï¼Œå› æ­¤AppendEntriesä¸€è‡´æ€§æ£€æŸ¥ä¸ä¼šå¤±è´¥ï¼Œåªä¼šæˆåŠŸã€‚

ä½†æ˜¯ï¼Œåœ¨leaderå´©æºƒçš„æƒ…å†µä¸‹ï¼Œæ—¥å¿—å¯èƒ½ä¼šä¸ä¸€è‡´ï¼Œå‰ä»»leaderå¯èƒ½æ²¡æœ‰å®Œå…¨å¤åˆ¶å…¶æ—¥å¿—ä¸­çš„æ‰€æœ‰æ¡ç›®ã€‚è¿™äº›ä¸ä¸€è‡´å¯èƒ½ä¼šå¼•èµ·ä¸€ç³»åˆ—é—®é¢˜å¼•èµ·å¤±è´¥ï¼Œæ¯”å¦‚ä¸‹å›¾æ‰€ç¤ºçš„å†…å®¹ï¼Œfollowersçš„æ¡ç›®ä¸leaderä¸å®Œå…¨ä¸€è‡´ï¼Œè¦ä¹ˆå¤šäº†ï¼Œè¦ä¹ˆç¼ºå°‘ã€‚



ä¸ºäº†é¿å…ä¸Šè¿°æƒ…å†µçš„å‘ç”Ÿï¼Œ**Leaderé€šè¿‡å¼ºåˆ¶followerå¤åˆ¶è‡ªå·±çš„æ—¥å¿—æ¥å¤„ç†ä¸ä¸€è‡´çš„é—®é¢˜**

- æ—¢ç„¶è¦ä¿è¯followerçš„æ—¥å¿—ä¸å…¶è‡ªå·±çš„ä¸€è‡´ï¼Œleaderéœ€è¦å°†å…¶æ—¥å¿—ä¸followeræ—¥å¿—è¿›è¡Œæ¯”è¾ƒï¼Œæ‰¾åˆ°å®ƒä»¬ä¹‹é—´æœ€åä¸€æ¬¡è¾¾åˆ°ä¸€è‡´çš„æ¡ç›®ï¼Œå°±åƒå‰é¢æåˆ°çš„æ—¥å¿—åŒ¹é…å±æ€§ï¼Œå› æ­¤è¿™ä¸ªæ¡ç›®å¦‚æœä¸€è‡´ï¼Œä¹‹å‰çš„æ—¥å¿—ä¹Ÿä¸€å®šéƒ½æ˜¯ä¸€è‡´çš„ã€‚ç„¶åæ¥ä¸‹æ¥åˆ é™¤followeræ—¥å¿—ä¸­æ­¤å…³é”®æ¡ç›®ä¹‹åçš„æ‰€æœ‰æ¡ç›®ï¼Œå¹¶å‘followerå‘é€è¯¥ç‚¹ä¹‹åè‡ªå·±çš„æ‰€æœ‰æ¡ç›®è¿›è¡ŒåŒæ­¥
- Leaderä¼šé’ˆå¯¹æ¯ä¸ªfolloweréƒ½ç»´æŠ¤ä¸€ä¸ªnextindexï¼Œè¡¨ç¤ºä¸‹ä¸€æ¡éœ€è¦å‘é€ç»™è¯¥followerçš„æ—¥å¿—ç´¢å¼•ã€‚åœ¨leaderé€‰ä¸¾æˆåŠŸä¸Šä»»çš„æ—¶å€™ï¼Œä¼šå°†æ‰€æœ‰çš„nextIndexå€¼åˆå§‹åŒ–ä¸ºå…¶æ—¥å¿—ä¸­æœ€åä¸€æ¡æ—¥å¿—çš„çš„æ—¥å¿—ç´¢å¼•+1ï¼›
- å¦‚æœfollowerå’Œleaderçš„æ—¥å¿—ä¸ä¸€è‡´ï¼Œåˆ™ä¸‹æ¬¡AppendEntries RPCä¸­çš„AppendEntriesä¸€è‡´æ€§æ£€æŸ¥å°†å¤±è´¥ï¼ŒLeaderå°†é€’å‡nextIndexå¹¶é‡è¯•AppendEntries RPCï¼Œç›´åˆ°nextIndexè¾¾åˆ°Leaderå’Œfolloweræ—¥å¿—åŒ¹é…çš„ç‚¹ä¸ºæ­¢ï¼›
- è‡³æ­¤ï¼ŒAppendEntriesæˆåŠŸï¼Œç„¶åå°†åˆ é™¤followeræ—¥å¿—ä¸­ä»»ä½•å†²çªçš„æ¡ç›®ï¼Œå¹¶é™„åŠ é¢†å¯¼è€…æ—¥å¿—ä¸­çš„æ¡ç›®ï¼ˆå¦‚æœæœ‰ï¼‰



è¿™æ ·çš„è¯ï¼Œleaderä»¥åŠfollowerçš„æ—¥å¿—å°±ä¼šä¿æŒä¸€è‡´ç›´åˆ°termä»»æœŸç»“æŸéƒ½ä¼šä¿æŒè¿™ç§çŠ¶æ€ã€‚

å›¾è§£

![image-20250409163205999](../markdown_img/image-20250409163205999.png)

![image-20250409163331571](../markdown_img/image-20250409163331571.png)

æ³¨æ„ï¼šLeaderæ°¸è¿œä¸ä¼šè¦†ç›–æˆ–åˆ é™¤å…¶æ—¥å¿—ä¸­çš„æ¡ç›®ï¼Œå®ƒåªä¼šè¿½åŠ æ–°æ¡ç›®ã€‚



### **å®‰å…¨å±æ€§ï¼ˆSafetyï¼‰**

å‰é¢çš„éƒ¨åˆ†ä¸»è¦æè¿°äº†Raftçš„æ ¸å¿ƒæµç¨‹ï¼Œä¹ŸæåŠäº†ä¸ªåˆ«æœºåˆ¶æ¯”å¦‚è¯´åœ¨ç»™å®šä»»æœŸå†…æœ€å¤šåªèƒ½é€‰ä¸¾ä¸€åé¢†å¯¼äººã€‚ä½†æ˜¯åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­æœ‰å¾ˆå¤šç§æƒ…å†µå¯èƒ½å‘ç”Ÿï¼Œè¿˜éœ€è¦æ›´ä¸ºè¯¦ç»†çš„å®‰å…¨æœºåˆ¶æ¥ç¡®ä¿æ¯ä¸ªçŠ¶æ€æœºéƒ½å¯ä»¥ä»¥ç›¸åŒçš„é¡ºåºæ‰§è¡Œå®Œå…¨ç›¸åŒçš„å‘½ä»¤ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦é’ˆå¯¹â€œé¢†å¯¼è€…é€‰ä¸¾â€ä»¥åŠâ€œæ—¥å¿—å¤åˆ¶â€é¢å¤–åŠ ä¸Šä¸€äº›å®‰å…¨å±æ€§ï¼Œæ¥å®Œå–„æ•´ä¸ªRaftç®—æ³•ã€‚

#### **é€‰ä¸¾é™åˆ¶**

ç»¼ä¸Šæ‰€è¿°ï¼ŒLeaderåœ¨æ•´ä¸ªRaftæœºåˆ¶ä¸­çœŸçš„å……å½“ç€éå¸¸é‡è¦å¿…ä¸å¯å°‘çš„è§’è‰²ï¼Œå› æ­¤Leaderçš„é€‰ä¸¾é‡ä¸­ä¹‹é‡

æˆ‘ä»¬æ¥è¯•æƒ³ä¸€ä¸ªåœºæ™¯ï¼šå½“leaderæäº¤äº†å¤šä¸ªæ—¥å¿—æ¡ç›®æ—¶ï¼Œfollowerå¦‚æœæ­¤æ—¶ä¸å¯ç”¨ï¼Œè¿˜æ²¡æ¥å¾—åŠå¤åˆ¶è¿™äº›æ—¥å¿—ï¼Œå°±è¢«é€‰ä¸¾ä¸ºæ–°ä»»leaderäº†ï¼Œç„¶åè¿™ä¸ªæ–°ä»»leaderå‘¢ï¼Œåˆç”¨æ–°çš„æ—¥å¿—æ¡ç›®è¦†ç›–äº†å…¶ä»–èŠ‚ç‚¹ä¸Šé¢ä¸Šä»»leader committedçš„æ—¥å¿—æ¡ç›®ã€‚é‚£ä¹ˆå°±ä¼šå¯¼è‡´å¤šä¸ªä¸åŒçš„çŠ¶æ€æœºå¯èƒ½æ‰§è¡Œä¸åŒçš„å‘½ä»¤åºåˆ—
å› æ­¤ï¼Œæ ¸å¿ƒé—®é¢˜è¿˜æ˜¯åœ¨äºleaderé€‰ä¸¾å‡ºç°äº†é—®é¢˜ï¼Œå¯¹äºå“ªäº›æœåŠ¡å™¨æœ‰èµ„æ ¼å½“é€‰leaderçš„é™åˆ¶å¯¹äºRaftç®—æ³•çš„å®Œå–„ååˆ†é‡è¦ï¼Œå‰é¢æˆ‘ä»¬å·²ç»æè¿‡äº†ä¸ªåˆ«çš„é™åˆ¶ï¼Œä¸‹é¢æˆ‘ä»¬å†æ˜ç¡®ç»†åŒ–ä¸€ä¸‹ï¼š

- æ—¥å¿—æ¡ç›®ä»…æœä¸€ä¸ªæ–¹å‘æµåŠ¨ï¼Œleaderæ°¸è¿œä¸ä¼šè¦†ç›–å…¶æ—¥å¿—ä¸­çš„ç°æœ‰æ¡ç›®ï¼Œä¹Ÿä¸ä¼šåˆ é™¤å…¶æ—¥å¿—ä¸­çš„æ¡ç›®ï¼Œåªèƒ½å°†æ–°æ¡ç›®è¿½åŠ åˆ°å…¶æ—¥å¿—ä¸­ï¼ˆLeader Append-Onlyï¼‰ï¼›
- åœ¨é€‰ä¸¾è¿‡ç¨‹ä¸­ï¼ŒCandidateä¸ºäº†èµ¢å¾—é€‰ä¸¾ï¼Œå…¶æ—¥å¿—ä¸­å¿…é¡»åŒ…å«æ‰€æœ‰å·²æäº¤çš„æ¡ç›®ã€‚ä¸ºäº†å½“é€‰ï¼ŒCandidateå¿…é¡»è·å¾—å¤§å¤šæ•°æœåŠ¡å™¨çš„æŠ•ç¥¨æ‰èƒ½å½“é€‰æ–°ä»»leaderï¼ŒRequestVote RPCä¸­åŒ…å«æœ‰å…³Candidateæ—¥å¿—çš„ä¿¡æ¯ï¼ˆterm, indexï¼‰ï¼Œå¦‚æœå…¶ä»–æœåŠ¡å™¨å‘ç°è‡ªå·±çš„æ—¥å¿—æ¯”Candidateçš„æ—¥å¿—æ–°ï¼Œé‚£ä¹ˆå°†æ‹’ç»æŠ•ç¥¨ï¼›

å¦‚ä½•åˆ¤å®šæ—¥å¿—æ–°æ—§ï¼ŸRafté€šè¿‡æ¯”è¾ƒæ—¥å¿—ä¸­æœ€åä¸€ä¸ªæ¡ç›®çš„indexä»¥åŠtermæ¥ç¡®å®šä¸¤ä¸ªæ—¥å¿—ä¸­å“ªä¸€ä¸ªæ›´æ–°ã€‚å¦‚æœæ—¥å¿—çš„æœ€åä¸€ä¸ªæ¡ç›®æœ‰ä¸åŒçš„termï¼Œé‚£ä¹ˆæ›´å¤§çš„termå¯¹åº”çš„æ—¥å¿—æ¯”è¾ƒæ–°ã€‚å¦‚æœæ—¥å¿—çš„terméƒ½ç›¸åŒï¼Œé‚£ä¹ˆindexå¤§çš„æ—¥å¿—æ›´æ–°ã€‚



#### Commité™åˆ¶

Commité™åˆ¶ï¼šé€šè¿‡è®¡ç®—å‰¯æœ¬æ•°ï¼Œä»…æäº¤leaderå½“å‰termçš„æ—¥å¿—æ¡ç›®ã€‚

![image-20250409164114264](../markdown_img/image-20250409164114264.png)ä¸ºä»€ä¹ˆè¦å¢åŠ è¿™ä¸ªé™åˆ¶ï¼Ÿæˆ‘ä»¬åŒæ ·åŸºäºè¿™ä¸ªå›¾è¿›è¡Œåœºæ™¯æ¨¡æ‹Ÿå°±çŸ¥é“äº†

- é˜¶æ®µï¼ˆaï¼‰ï¼šS1æ˜¯leaderï¼Œæ”¶åˆ°è¯·æ±‚åä»…å¤åˆ¶index2çš„æ—¥å¿—ç»™äº†S2ï¼Œå°šæœªå¤åˆ¶ç»™S3 ~ S5ï¼›
- é˜¶æ®µï¼ˆbï¼‰ï¼šS1å´©æºƒï¼ŒS5å‡­å€Ÿ S3ã€S4 å’Œè‡ªèº«çš„æŠ•ç¥¨å½“é€‰ä¸ºterm3çš„leaderï¼Œæ”¶åˆ°è¯·æ±‚åä¿å­˜äº†ä¸index2ä¸åŒçš„æ¡ç›®ï¼ˆterm3ï¼‰ï¼Œæ­¤æ—¶å°šæœªå¤åˆ¶ç»™å…¶ä»–èŠ‚ç‚¹ï¼›
- é˜¶æ®µï¼ˆcï¼‰ï¼šS5å´©æºƒ,S1é‡æ–°å¯åŠ¨ï¼Œå½“é€‰ä¸ºæ–°ä»»leaderï¼ˆterm4ï¼‰ï¼Œå¹¶ç»§ç»­å¤åˆ¶ï¼Œå°†term2, index2å¤åˆ¶ç»™äº† S3ã€‚è¿™ä¸ªæ—¶å€™term2,index2å·²ç»çš„æ—¥å¿—æ¡ç›®å·²å¤åˆ¶åˆ°å¤§å¤šæ•°çš„æœåŠ¡å™¨ä¸Šï¼Œä½†æ˜¯è¿˜æ²¡æäº¤ã€‚
- é˜¶æ®µï¼ˆdï¼‰ï¼šå¦‚æœS1å¦‚dé˜¶æ®µæ‰€ç¤ºï¼Œåˆå´©æºƒäº†ï¼ŒS5é‡æ–°å½“é€‰äº†leaderï¼ˆè·å¾—S2ã€S3ã€S4çš„é€‰ç¥¨ï¼‰ç„¶åå°† term3, index2çš„æ¡ç›®èµ‹å€¼ç»™äº†æ‰€æœ‰çš„èŠ‚ç‚¹å¹¶commitã€‚é‚£è¿™ä¸ªæ—¶å€™ï¼Œå·²ç» committed çš„ term2, index2è¢« term3, index2è¦†ç›–äº†

```ABAP
å› æ­¤ï¼Œä¸ºäº†é¿å…ä¸Šè¿°æƒ…å†µï¼Œcommitéœ€è¦å¢åŠ ä¸€ä¸ªé¢å¤–çš„é™åˆ¶ï¼šä»…commit leaderå½“å‰termçš„æ—¥å¿—æ¡ç›®ã€‚
```

ä¸¾ä¸ªä¾‹å­ï¼Œæ¯”å¦‚åœ¨cé˜¶æ®µï¼Œå³ä½¿term4çš„æ—¶å€™S1å·²ç»æŠŠterm2, index2å¤åˆ¶ç»™äº†å¤§å¤šæ•°èŠ‚ç‚¹ï¼Œä½†æ˜¯å®ƒä¹Ÿä¸èƒ½ç›´æ¥å°†å…¶commitï¼Œå¿…é¡»ç­‰å¾…term4çš„æ—¥å¿—å¹¶æˆåŠŸå¤åˆ¶åä¸€èµ·commitã€‚

æ‰€ä»¥é™¤éè¯´é˜¶æ®µcä¸­term2, index2å§‹ç»ˆæ²¡æœ‰è¢« commitï¼Œè¿™æ ·S5åœ¨é˜¶æ®µdå°†å…¶è¦†ç›–å°±æ˜¯å®‰å…¨çš„ï¼Œåœ¨è¦ä¹ˆå°±æ˜¯åƒé˜¶æ®µeä¸€æ ·ï¼Œterm2, index2è·Ÿterm4, index3ä¸€èµ·è¢« commitï¼Œè¿™æ ·S5æ ¹æœ¬å°±æ— æ³•å½“é€‰leaderï¼Œå› ä¸ºå¤§å¤šæ•°èŠ‚ç‚¹çš„æ—¥å¿—éƒ½æ¯”å®ƒæ–°ï¼Œä¹Ÿå°±ä¸å­˜åœ¨å‰è¾¹çš„é—®é¢˜äº†ã€‚



#### Follower å’Œ Candidate å´©æºƒ

Followerå’ŒCandidateå´©æºƒç›¸å¯¹æ¥è¯´æ¯”LeaderèŠ‚ç‚¹å´©æºƒæ›´å¥½å¤„ç†ï¼Œå¦‚æœFollowerå’ŒCandidateå‡ºç°äº†é—®é¢˜ï¼Œé‚£ä¹ˆä¹Ÿå°±æ„å‘³ç€RequestVoteå’ŒAppendEntries RPCå°†å¤±è´¥ã€‚Raftä¼šæ— é™æœŸçš„é‡è¯•ï¼Œç›´åˆ°æœåŠ¡å™¨é‡æ–°å¯åŠ¨ï¼ŒRPCå°†æˆåŠŸå®Œæˆã€‚å¦‚æœå¾ˆä¸å‡‘å·§ï¼ŒFollowerå’ŒCandidateèŠ‚ç‚¹æ˜¯åœ¨å®ŒæˆRPCä¹‹åä½†åœ¨å“åº”ä¹‹å‰å´©æºƒï¼Œé‚£ä¹ˆå®ƒå°†åœ¨é‡æ–°å¯åŠ¨åå†æ¬¡æ”¶åˆ°ç›¸åŒçš„ RPCã€‚



#### æ—¶é—´å®‰æ’å’Œå¯ç”¨æ€§

Raftçš„å®‰å…¨æœºåˆ¶ä¸èƒ½ä¾èµ–äºæ—¶é—´ï¼ˆå¦‚æœä¸é¢„æœŸæ—¶é—´ä¸ç¬¦ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸€ç³»åˆ—é—®é¢˜ï¼‰ï¼Œä½†æ˜¯å¯ç”¨æ€§ï¼ˆç³»ç»ŸåŠæ—¶å“åº”å®¢æˆ·ç«¯çš„èƒ½åŠ›ï¼‰å¿…ç„¶å–å†³äºæ—¶é—´ï¼Œæ¯”å¦‚é¢†å¯¼è€…é€‰ä¸¾å¿…é¡»æœ‰æ—¶é—´é™åˆ¶ï¼Œå¦åˆ™ç³»ç»Ÿæ— æ³•è¿è¡Œä¸‹å»ã€‚

é¢†å¯¼è€…é€‰ä¸¾æ˜¯Raftæœºåˆ¶ä¸­æœ€å…³é”®çš„ä¸€ä¸ªæ¨¡å—ã€‚åªè¦ç³»ç»Ÿæ»¡è¶³ä»¥ä¸‹æ—¶é—´å®‰æ’ï¼ŒRaftå°±èƒ½å¤Ÿé¡ºåˆ©é€‰ä¸¾åˆä¸€ä¸ªç¨³å®šçš„Leaderï¼š

```bash
broadcastTime < electionTimeout < MTBF
```

- BroadcastTimeï¼šæ˜¯æœåŠ¡å™¨å‘é›†ç¾¤ä¸­çš„æ¯ä¸ªæœåŠ¡å™¨å¹¶è¡Œå‘é€ RPC å¹¶æ¥æ”¶å…¶å“åº”æ‰€éœ€çš„å¹³å‡æ—¶é—´ï¼›
- ElectionTimeoutï¼šæ˜¯å‰é¢æ‰€æè¿°çš„é€‰ä¸¾è¶…æ—¶æ—¶é—´ï¼›
- MTBFï¼šæ˜¯å•ä¸ªæœåŠ¡å™¨çš„å¹³å‡æ•…éšœé—´éš”æ—¶é—´ï¼›

åœ¨æ—¶é—´é•¿çŸ­æ¥çœ‹ï¼Œå¹¿æ’­æ—¶é—´æ˜¯æœ€çŸ­çš„ï¼Œä»¥ä¾¿leaderåœ¨å½“é€‰åèƒ½å¤Ÿæ›´å¯é å¿«é€Ÿåœ°å‘é€å¿ƒè·³æ¶ˆæ¯ï¼Œä»¥ä¾¿é˜»æ­¢followeré€‰ä¸¾å†²çªï¼›ç”±äºé€‰ä¸¾è¶…æ—¶é‡‡ç”¨çš„æ˜¯éšå³æ–¹æ³•ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥é™ä½åˆ†æ•£é€‰ç¥¨çš„å‡ ç‡ï¼Œé€‰ä¸¾è¶…æ—¶æ—¶é—´æ¯”MTBFä¼šå°å‡ ä¸ªæ•°é‡çº§ã€‚å½“leaderèŠ‚ç‚¹å´©æºƒæ—¶ï¼Œç³»ç»Ÿåœ¨é€‰ä¸¾è¶…æ—¶æ—¶é—´å†…ä¸å¯ç”¨ã€‚å› æ­¤ï¼Œä¸ºäº†ç»´æŒæ•´ä¸ªç³»ç»Ÿçš„å®Œç¾å¯ç”¨æ€§ï¼Œé€‰ä¸¾è¶…æ—¶æ—¶é—´ä»…å æ€»æ—¶é—´çš„ä¸€å°éƒ¨åˆ†ï¼Œé˜²æ­¢å½±å“ç³»ç»Ÿè¿è¡Œã€‚

BroadcastTimeä»¥åŠMTBFçš„æ—¶é—´å…·ä½“ç”±åº•å±‚ç³»ç»Ÿå†³å®šï¼Œä½†æ˜¯ElectionTimeoutæ—¶é—´æ˜¯æˆ‘ä»¬éœ€è¦è‡ªè¡Œè®¾å®šçš„ã€‚ 



#### å¿«ç…§

æ­£å¦‚å‰é¢æ‰€ä»‹ç»çš„å†…å®¹ï¼ŒRaftæ ¸å¿ƒç®—æ³•ç»´æŠ¤äº†æ—¥å¿—çš„ä¸€è‡´æ€§ï¼Œé€šè¿‡applyæ—¥å¿—æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°ä¸€è‡´çš„çŠ¶æ€æœºï¼Œå®¢æˆ·ç«¯çš„æ“ä½œå‘½ä»¤ä¼šè¢«åŒ…è£…æˆæ—¥å¿—äº¤ç»™ Raft å¤„ç†ã€‚ä½†æ˜¯å¤§å®¶æœ‰æ²¡æœ‰æƒ³è¿‡ä¸€ä¸ªé—®é¢˜ï¼Œéšç€å®¢æˆ·ç«¯è¯·æ±‚çš„å¢å¤šï¼Œè¿™äº›æ—¥å¿—æ˜¯ä¸æ˜¯ä¼šè¶Šæ¥è¶Šé•¿ï¼Œå ç”¨è¶Šæ¥è¶Šé«˜çš„å­˜å‚¨ç©ºé—´ï¼Ÿè€Œä¸”ï¼Œæ¯æ¬¡ç³»ç»Ÿé‡å¯æ—¶éƒ½éœ€è¦å®Œæ•´å›æ”¾ä¸€éæ‰€æœ‰æ—¥å¿—æ‰èƒ½å¾—åˆ°æœ€æ–°çš„çŠ¶æ€æœºã€‚å¦‚æœæ²¡æœ‰æŸç§æœºåˆ¶æ¥æ¸…é™¤æ—¥å¿—ä¸­ç§¯ç´¯çš„é™ˆæ—§ä¿¡æ¯ï¼Œæœ€ç»ˆå°±ä¼šå¯¼è‡´å¯ç”¨æ€§é—®é¢˜å½±å“æ•´ä¸ªç³»ç»Ÿçš„è¿è¡Œã€‚

æ‰€ä»¥ï¼Œä¸ºäº†é¿å…è¿™ä¸€æƒ…å†µçš„å‘ç”Ÿï¼ŒRafté‡‡ç”¨äº†æœ€ç®€å•çš„æ—¥å¿—å‹ç¼©æ–¹æ³•--å¿«ç…§ï¼ˆSnapshotï¼‰ã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯å°†æŸä¸€æ—¶åˆ»ç³»ç»Ÿçš„çŠ¶æ€ dump ä¸‹æ¥å¹¶è½åœ°å­˜å‚¨ï¼Œè¿™æ ·è¯¥æ—¶åˆ»ä¹‹å‰çš„æ‰€æœ‰æ—¥å¿—æ¡ç›®å°±éƒ½å¯ä»¥ä¸¢å¼ƒäº†ï¼ˆä¹ŸåŒ…æ‹¬å…ˆå‰çš„å¿«ç…§ï¼‰ã€‚æ¯ä¸ªæœåŠ¡å™¨ç‹¬ç«‹æ‹æ‘„å¿«ç…§ï¼Œä»…è¦†ç›–committedå®Œæˆçš„æ—¥å¿—ï¼Œå› ä¸ºåªæœ‰committedæ—¥å¿—æ‰æ˜¯ç¡®ä¿æœ€ç»ˆä¼šåº”ç”¨åˆ°çŠ¶æ€æœºçš„ã€‚

![image-20250409165057392](../markdown_img/image-20250409165057392.png)

ä¸Šå›¾å±•ç¤ºäº†æœåŠ¡å™¨ç”¨æ–°å¿«ç…§æ›¿æ¢äº†å…¶æ—¥å¿—ä¸­å·²æäº¤çš„æ¡ç›®ï¼ˆindex1-index5ï¼‰ï¼Œæ–°å¿«ç…§ä»…å­˜å‚¨å½“å‰çŠ¶æ€ï¼ˆå˜é‡xã€yï¼‰ã€‚å¿«ç…§ä¸­æ˜¾ç¤ºçš„last included indexä»¥åŠçš„last included termç”¨äºå®šä½æ—¥å¿—ä½ç½®ä»¥åŠæ”¯æŒAppendEntriesä¸€è‡´æ€§æ£€æŸ¥

Followerå¯ä»¥ä¿æŒæœ€æ–°çŠ¶æ€çš„æ–¹æ³•å°±æ˜¯leaderé€šè¿‡ç½‘ç»œå‘å…¶å‘é€æœ€æ–°å¿«ç…§ã€‚æ¯”å¦‚ï¼Œå½“followerè½åçš„æ—¶å€™ï¼Œleaderéœ€è¦å‘å…¶åŒæ­¥æ—¥å¿—ï¼Œä½†æ˜¯è¿™ä¸ªæ—¶å€™å‡è®¾leaderå·²ç»åšäº†å¿«ç…§ï¼Œæ—§çš„æ—¥å¿—å·²ç»è¢«åˆ é™¤ï¼Œleaderå°±å¯ä»¥ä½¿ç”¨InstallSnapshot RPCå‘è½åçš„followerå‘é€å¿«ç…§ï¼Œå…¶ä¸­å°†åŒ…å«è¯¥followeræœªåŒ…å«çš„æ–°ä¿¡æ¯ã€‚åŒæ ·ï¼Œå½“é›†ç¾¤ä¸­æœ‰æ–°èŠ‚ç‚¹åŠ å…¥ï¼Œæˆ–è€…æŸä¸ªèŠ‚ç‚¹å®•æœºå¤ªä¹…è½åäº†å¤ªå¤šæ—¥å¿—æ—¶ï¼Œleaderä¹Ÿå¯ä»¥ç›´æ¥å‘é€å¿«ç…§ï¼ŒèŠ‚çº¦äº†å¤§é‡æ—¥å¿—ä¼ è¾“å’Œå›æ”¾æ—¶é—´ã€‚




## å®Œæ•´çš„ Prometheus ç›‘æ§æ¶æ„è®¾è®¡ï¼ˆé€‚ç”¨äº K8s é›†ç¾¤å†… & é›†ç¾¤å¤–ï¼‰

### **ç›‘æ§æ¶æ„çš„ä¸‰å¤§å±‚æ¬¡**

ä½ çš„ Prometheus ç›‘æ§æ¶æ„ï¼Œå¤§è‡´å¯ä»¥åˆ†ä¸ºä»¥ä¸‹ä¸‰å±‚ï¼š

1. **é›†ç¾¤å†…éƒ¨ç›‘æ§ï¼ˆK8s å†…éƒ¨ Prometheusï¼‰**
   - ç›‘æ§ **Kubernetes èµ„æº**ï¼ˆPodã€Nodeã€Serviceã€Ingressã€Networkï¼‰ã€‚
   - ç›‘æ§ **åº”ç”¨ç¨‹åºæŒ‡æ ‡**ï¼ˆHTTP è¯·æ±‚ã€QPSã€é”™è¯¯ç‡ï¼‰ã€‚
   - é€šè¿‡ **æœåŠ¡å‘ç°ï¼ˆKubernetes SDï¼‰** è‡ªåŠ¨å‘ç°ç›®æ ‡ã€‚
2. **é›†ç¾¤å¤–éƒ¨ç›‘æ§ï¼ˆä¼ ç»Ÿç‰©ç†æœº/VM ç›‘æ§ï¼‰**
   - ç›‘æ§ **ç‰©ç†æœºã€æ•°æ®åº“ã€ç¬¬ä¸‰æ–¹ APIã€é»‘ç›’æ¢æµ‹**ã€‚
   - ç›‘æ§ **è‡ªå»ºæœåŠ¡ï¼ˆé K8s åº”ç”¨ï¼‰**ã€‚
   - éœ€è¦ **æ‰‹åŠ¨é…ç½®ç›®æ ‡** æˆ– **ä½¿ç”¨ Consul / DNS è¿›è¡ŒæœåŠ¡å‘ç°**ã€‚
3. **ç»Ÿä¸€æ±‡æ€»å±‚ï¼ˆä¸­å¤® Prometheus / Thanos / Cortexï¼‰**
   - æ±‡æ€» **Kubernetes é›†ç¾¤ + ç‰©ç†æœºæ•°æ®**ã€‚4
   - è¿›è¡Œ **å…¨å±€æŸ¥è¯¢ã€ç»Ÿä¸€å­˜å‚¨ã€é•¿æœŸå­˜å‚¨**ã€‚
   - å®ç° **å¤šæ•°æ®ä¸­å¿ƒè”é‚¦**ã€‚



## ã€Œå‘½åç©ºé—´åˆ é™¤å¡ä½ã€é—®é¢˜

å‘½åç©ºé—´åœ¨åˆ é™¤å‰ï¼ŒKubernetes ä¼šå°è¯•**ä¼˜é›…åœ°æ¸…ç†å…¶ä¸­æ‰€æœ‰èµ„æºå¯¹è±¡ï¼ˆPodã€CRDã€Finalizer ç­‰ï¼‰**ã€‚å¦‚æœå…¶ä¸­æœ‰ä¸€äº›èµ„æºï¼š

- å­˜åœ¨ **`finalizers`** æ²¡æœ‰æ¸…é™¤
- æˆ–æŸäº›èµ„æºå…³è”çš„æ§åˆ¶å™¨å·²ç»å¤±æ•ˆï¼ˆå¦‚æŸä¸ª Operator çš„ CRD æ²¡å“åº”ï¼‰
- æˆ–ä¸€äº›æŒ‚è½½ã€ç½‘ç»œæ— æ³•å›æ”¶

å°±ä¼šå¯¼è‡´å‘½åç©ºé—´åˆ é™¤è¢«**â€œæŒ‚èµ·â€**ã€‚



### å¿«é€Ÿæ’æŸ¥æ€è·¯

ä½ å¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹è¯¦ç»†çš„åˆ é™¤ä¿¡æ¯

```bash
kubectl get namespace gitlab -o json | jq '.spec.finalizers'
```



### è§£å†³æ–¹æ³•

#### å¼ºåˆ¶æ¸…ç†1

**ç¼–è¾‘ namespace æ¸…é™¤ finalizers**

```bash
kubectl get namespace gitlab -o json > gitlab-ns.json
```

**ç¼–è¾‘æ–‡ä»¶ `gitlab-ns.json`ï¼Œæ‰¾åˆ°è¿™ä¸€æ®µ**

```bash
"spec": {
  "finalizers": [
    "kubernetes"
  ]
}
```

æŠŠ `"finalizers"` æ•´æ®µåˆ é™¤ï¼ˆæˆ–è®¾ä¸ºç©ºæ•°ç»„ï¼š`[]`ï¼‰ã€‚

**ä½¿ç”¨ `kubectl proxy` å¯åŠ¨ä»£ç†ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œï¼‰**

```bash
kubectl proxy
```

**ç„¶ååœ¨ä¸»ç»ˆç«¯æ‰§è¡Œå¼ºåˆ¶åˆ é™¤å‘½ä»¤**

```bash
curl -k -H "Content-Type: application/json" -X PUT \
--data-binary @gitlab-ns.json \
http://127.0.0.1:8001/api/v1/namespaces/gitlab/finalize
```



#### æ›´å¼ºåŠ›ç‰ˆæœ¬ï¼šå¼ºåˆ¶åˆ é™¤ stuck å‘½åç©ºé—´ `gitlab`

**ç¬¬ä¸€æ­¥ï¼šåˆ é™¤ finalizers**

```bash
# å°† finalizers æ¸…ç©º
kubectl get namespace gitlab -o json | jq '.spec.finalizers = []' > /tmp/gitlab-finalize.json
```

**ç¬¬äºŒæ­¥ï¼šé€šè¿‡ REST æ¥å£æ›¿æ¢**

```bash
kubectl replace --raw "/api/v1/namespaces/gitlab/finalize" -f /tmp/gitlab-finalize.json
```

è¿™æ¡å‘½ä»¤çš„ä½œç”¨æ˜¯ç›´æ¥è°ƒç”¨ API æ¥ finalize å‘½åç©ºé—´ï¼Œè€Œä¸æ˜¯ç­‰å¾… controller æ¥æ¸…ç†ã€‚

**ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥æ˜¯å¦æˆåŠŸ**

```bash
kubectl get ns gitlab
```

å¦‚æœè¾“å‡ºæ˜¯ï¼š

```
Error from server (NotFound): namespaces "gitlab" not found
```

è¯´æ˜ä½ å·²ç»æˆåŠŸå¼ºåˆ¶åˆ é™¤äº† stuck çš„å‘½åç©ºé—´ 



### å¼ºåˆ¶åˆ é™¤åŸç†

ä» **finalizers çš„ä½œç”¨åŸç†** åˆ° **REST æ¥å£æ›¿æ¢å®ç°å¼ºåˆ¶åˆ é™¤** çš„å®Œæ•´æµç¨‹

#### ä»€ä¹ˆæ˜¯ Finalizers

åœ¨ Kubernetes ä¸­ï¼Œ`finalizers` æ˜¯ä¸€ç§ **èµ„æºåˆ é™¤ä¿æŠ¤æœºåˆ¶**ï¼Œç”¨äºåœ¨èµ„æºè¢«åˆ é™¤å‰æ‰§è¡Œä¸€äº›æ¸…ç†æ“ä½œ

- æ¯ä¸ª Kubernetes èµ„æºå¯¹è±¡éƒ½æœ‰ä¸€ä¸ª `metadata.finalizers` å­—æ®µ
- å½“ä½ æ‰§è¡Œ `kubectl delete` åˆ é™¤æŸä¸ªèµ„æºæ—¶
  - è¿™ä¸ªå¯¹è±¡ä¸ä¼šç«‹åˆ»è¢«ä» etcd ä¸­ç§»é™¤
  - è€Œæ˜¯è¢«è®¾ç½®ä¸º `"deletionTimestamp"`
  - ç„¶å Kubernetes ä¼š **ç­‰å¾… finalizers æ¸…ç†é€»è¾‘å®Œæˆ**ï¼Œå†çœŸæ­£åˆ é™¤è¿™ä¸ªå¯¹è±¡



#### ç¤ºä¾‹ï¼šNamespace ä¸­çš„ Finalizer

å‘½åç©ºé—´ä¸­å¸¸è§çš„ finalizer

```json
"finalizers": [
  "kubernetes"
]
```

è¿™ä¸ª `kubernetes` finalizer è¡¨ç¤º **æ§åˆ¶å™¨éœ€è¦æ¸…ç†è¯¥å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰èµ„æº**ï¼ˆPodã€PVCã€Secretsã€CRDsç­‰ï¼‰ï¼Œå®Œæˆåæ‰å…è®¸åˆ é™¤ã€‚

ä½†æ˜¯ï¼š

- å¦‚æœæŸäº›èµ„æº **æ— æ³•æ­£å¸¸æ¸…ç†ï¼ˆæ¯”å¦‚ stuck çš„ cert-manager èµ„æºï¼‰**
- å°±ä¼šå¯¼è‡´ namespace å¤„äº **"Terminating" å¡æ­»çŠ¶æ€**



#### ä¸ºä»€ä¹ˆç”¨ REST æ¥å£æ›¿æ¢å¯ä»¥å¼ºåˆ¶åˆ é™¤

Kubernetes çš„ `kubectl replace --raw` å®é™…ä¸Šæ˜¯ç›´æ¥è®¿é—® Kubernetes API çš„ä¸€ç§æ–¹å¼ï¼Œå®ƒè·³è¿‡äº†æ§åˆ¶å™¨çš„è¡Œä¸ºï¼Œä» **èµ„æºå¯¹è±¡å±‚é¢ç›´æ¥ä¿®æ”¹å­—æ®µ**

**å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š**

1. æˆ‘ä»¬ä½¿ç”¨ `kubectl get namespace <ns> -o json` å¾—åˆ°å®Œæ•´çš„èµ„æºå¯¹è±¡ã€‚

2. ç„¶åç”¨ `jq` åˆ é™¤ `.spec.finalizers` å­—æ®µã€‚

3. æ¥ç€ä½¿ç”¨ `kubectl replace --raw` è°ƒç”¨ API æ¥å£ï¼š

   ```bash
   /api/v1/namespaces/gitlab/finalize
   ```

   

**è¿™ä¸ªæ¥å£çš„ä½œç”¨æ˜¯**ï¼š

- **å‘Šè¯‰ apiserver å¼ºåˆ¶ finalize å‘½åç©ºé—´å¯¹è±¡**
- å³ä½¿ Kubernetes æ§åˆ¶å™¨æ²¡èƒ½æˆåŠŸæ¸…ç†å®Œèµ„æºï¼Œä¹Ÿå¯ä»¥ä» etcd ä¸­ç›´æ¥æ¸…é™¤è¯¥èµ„æº



#### æ€»ç»“å›¾ç¤ºç†è§£

```css
kubectl delete ns gitlab
   â”‚
   â””â”€â”€â”€> Kubernetes æ ‡è®° gitlab ä¸º "Terminating"
              â”‚
              â”œâ”€â”€ æŸ¥æ‰¾ gitlab æ‰€æœ‰å­èµ„æºï¼ˆPodã€PVC ç­‰ï¼‰
              â”œâ”€â”€ æ‰§è¡Œå„æ§åˆ¶å™¨çš„æ¸…ç†ä»»åŠ¡
              â””â”€â”€ é‡åˆ° stuck resource â‡’ æ— æ³•å®Œæˆ â‡’ å¡ä½

ğŸ›  å¼ºåˆ¶æ‰‹åŠ¨æ–¹å¼ï¼š
kubectl get ns gitlab -o json
    â†“
jq åˆ é™¤ .spec.finalizers
    â†“
kubectl replace --raw "/api/v1/namespaces/gitlab/finalize" -f updated.json
    â†“
ğŸ’¥ å‘½åç©ºé—´ç«‹å³ä» etcd åˆ é™¤ï¼ˆå³ä½¿èµ„æºæ²¡æ¸…å®Œï¼‰
```



#### å¼ºåˆ¶åˆ é™¤ Namespace çš„éšæ‚£

â—**èµ„æºæ®‹ç•™åœ¨ etcd**

è™½ç„¶ namespace çœ‹ä¼¼åˆ é™¤äº†ï¼Œä½†å®é™…ä¸Šé‡Œé¢çš„æŸäº›èµ„æºï¼ˆPodã€PVCã€Secretã€CRD ç­‰ï¼‰å¯èƒ½ **è¿˜ä¿ç•™åœ¨ etcd ä¸­**ï¼Œä½†æ²¡æœ‰è¢« controller å½»åº•æ¸…ç†ã€‚

- æ¯”å¦‚ï¼š
  - è¢« cert-manager åˆ›å»ºçš„ `challenge` èµ„æº
  - è¢« PVC åˆ›å»ºçš„ `VolumeAttachment` å¯¹è±¡
  - æ²¡æœ‰ç»‘å®šæˆåŠŸçš„ PV ä»ç„¶å­˜åœ¨

 âŒ **æ§åˆ¶å™¨çŠ¶æ€ä¸ä¸€è‡´**

Kubernetes æ§åˆ¶å™¨ï¼ˆå¦‚ controller-managerã€cert-managerã€csi-controller ç­‰ï¼‰åœ¨ç›‘å¬ç›¸å…³èµ„æºæ—¶ï¼Œå¯èƒ½ä¼šæ£€æµ‹åˆ°ä¸€äº›èµ„æºâ€œä¸ä¸€è‡´â€ï¼Œå¹¶æ‰“å°å¤§é‡æŠ¥é”™æ—¥å¿—ã€‚

ä¾‹å¦‚ï¼š

- æŸä¸ª PVC ä»å¼•ç”¨å·²è¢«åˆ é™¤çš„ namespace
- æŸä¸ª pod çš„ finalizer æ°¸è¿œå¾—ä¸åˆ°å¤„ç†

ğŸš« **èµ„æºè¢«å­¤ç«‹ï¼ˆOrphanï¼‰**

å¦‚æœæœ‰èµ„æºè„±ç¦»äº† namespace ç®¡ç†ä½†ä»å­˜åœ¨ï¼Œå®ƒä»¬å¯èƒ½å˜æˆæ‰€è°“çš„ â€œ**å­¤å„¿èµ„æº**â€ï¼ˆOrphanï¼‰ï¼Œåç»­å¯èƒ½ä¼šå¯¼è‡´ï¼š

- å ç”¨å­˜å‚¨èµ„æº
- å½±å“è°ƒåº¦ï¼ˆè°ƒåº¦å™¨ä»¥ä¸º Pod è¿˜å­˜åœ¨ï¼‰
- æ§åˆ¶å™¨ä¸æ–­é‡è¯•æˆ–æŠ¥é”™



#### åº”å¯¹æªæ–½ï¼šæ¸…ç†åƒåœ¾ & å–„åå»ºè®®

| æ“ä½œæ­¥éª¤                                  | è¯´æ˜                                                         |
| ----------------------------------------- | ------------------------------------------------------------ |
| âœ… **1. æ‰‹åŠ¨å®¡æŸ¥èµ„æºæ®‹ç•™**                 | ä¾‹å¦‚ï¼š`kubectl get pv` / `kubectl get crd` / `kubectl get secrets --all-namespaces` ç­‰æŸ¥çœ‹æ˜¯å¦æœ‰é—ç•™èµ„æº |
| âœ… **2. æ¸…ç†æ— ä¸»çš„èµ„æºï¼ˆOrphansï¼‰**        | æŸ¥çœ‹èµ„æºçš„ `metadata.namespace` æ˜¯å¦ä¸ºç©ºæˆ–å·²ä¸å­˜åœ¨çš„ namespaceï¼Œå¦‚æœæ˜¯å°±æ‰‹åŠ¨åˆ é™¤ |
| âœ… **3. æŸ¥çœ‹æ§åˆ¶å™¨æ—¥å¿—**                   | `kubectl logs -n kube-system <controller-pod>` ç›‘æµ‹æ˜¯å¦æœ‰ç›¸å…³é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯ cert-managerã€volume ç›¸å…³ç»„ä»¶ |
| âœ… **4. æ£€æŸ¥ PVC å’Œ PV**                   | `kubectl get pvc,pv --all-namespaces`ï¼Œæ‰‹åŠ¨åˆ é™¤å¤±æ•ˆæˆ–å¤„äº `Released` çŠ¶æ€çš„ PV |
| âœ… **5. æ£€æŸ¥å­˜å‚¨ç³»ç»Ÿï¼ˆå¦‚ OpenEBSã€Cephï¼‰** | å¦‚æœä½ ä½¿ç”¨çš„æ˜¯åŠ¨æ€å­˜å‚¨ï¼Œè¿˜è¦å»å­˜å‚¨åç«¯æ£€æŸ¥æ˜¯å¦æœ‰ volume æ®‹ç•™ |
| âœ… **6. å®šæœŸæ‰«ææ— æ•ˆèµ„æºï¼ˆæ¨èè„šæœ¬å·¥å…·ï¼‰** | ä½¿ç”¨ `kubectl unused`ã€`kubecleaner`ã€`kubectl-resource_cleaner.sh` è„šæœ¬åšè‡ªåŠ¨åŒ–å¤„ç† |



## çœŸå®åœºæ™¯ä¸‹çš„k8sèµ„æºé…ç½®

### æµ‹è¯•åŠå°å‹çš„ç”Ÿäº§ç¯å¢ƒ

3å°master  4CPU8Gå†…å­˜60Gç¡¬ç›˜ å·®ä¸å¤šèƒ½è·‘æ•°ç™¾ä¸ªpod

### ä¸­ç­‰ç¯å¢ƒä¸ŠåƒPod

3å°master 8CPU16Gå†…å­˜60Gç¡¬ç›˜

### å¤§å‹ç¯å¢ƒä¸Šä¸‡Pod

3å°master 16CPU32Gå†…å­˜60Gç¡¬ç›˜

### ETCD

ä¸€å®šè¦ä½¿ç”¨ssdï¼Œéå¸¸æ¶ˆè€—ç£ç›˜IOï¼Œç£ç›˜IOä¸€å®šè¦å¿«ï¼Œå¦åˆ™æ— è®ºåˆ é™¤è¿˜æ˜¯åˆ›å»ºèµ„æºéƒ½ä¼šå¾ˆæ…¢

ETCDåŸºäºå†…å­˜åšç¼“å­˜ï¼Œå› æ­¤ETCDæ˜¯æ¯”è¾ƒæ¶ˆè€—å†…å­˜çš„

![image-20250409121720741](../markdown_img/image-20250409121720741.png)

ä¸Šè¿°IOPSä¸Šåƒçš„éƒ½æ˜¯å›ºæ€ç¡¬ç›˜ï¼Œé€šå¸¸æœºæ¢°ç›˜çš„IOPSä¹Ÿå°±å‡ ç™¾

é€šå¸¸ä¸€ä¸ªé¡¹ç›®ï¼Œéƒ½æœ‰è¿‘ç™¾-200ç™¾å·¦å³çš„pod

å›½å†…é€šå¸¸å°ç¯å¢ƒä¸‹ï¼ˆå‡ ç™¾podï¼‰ï¼š4C8G60Gå›ºæ€ç›˜ï¼Œä¸­ç­‰ç¯å¢ƒï¼ˆä¸Šåƒpodï¼‰ï¼š8C32Gï¼Œå¤§å‹ç¯å¢ƒï¼š16/32C32/64G



### Node

æŒ‰ç…§ä¸»æœºç»„è¿›è¡Œè‡ªå®šä¹‰é…ç½®

CPUå¯†é›†å‹ä¸šåŠ¡ï¼ˆæ¯”å¦‚ï¼šæ•°æ®åº“MySQLï¼Œäººå·¥æ™ºèƒ½ï¼Œè§†é¢‘è½¬ç ï¼Œæ•°æ®è®¡ç®—ï¼Œï¼ˆå¯èƒ½192C96Gï¼‰

MEMROYç±»å‹æœåŠ¡å™¨ï¼ˆæ¯”å¦‚ï¼šJavaæœåŠ¡ï¼Œå¯èƒ½512G128Cï¼‰

GPUä¸šåŠ¡ï¼ˆäººå·¥æ™ºèƒ½ï¼Œæ¨¡å‹è®­ç»ƒï¼Œå¤šæ¨¡æ€ï¼Œæ™ºèƒ½å®¢æœç­‰ï¼‰



# Kubernetes æ’é”™æ¡ˆä¾‹

## æ’é”™æ¡ˆä¾‹1

### é—®é¢˜èƒŒæ™¯

#### **è¿è¡Œç¯å¢ƒ**

- **å• Master èŠ‚ç‚¹**ï¼šå³ **etcdã€schedulerã€controller-managerã€apiserver** éƒ½è¿è¡Œåœ¨ **å•ä¸ª Master èŠ‚ç‚¹**ã€‚
- **Kubernetes CNI**ï¼šCalico
- **Service ç½‘ç»œæ¨¡å¼**ï¼šIPVS
- **å…³é”®ç»„ä»¶**ï¼šetcdã€kube-apiserverã€kube-schedulerã€kube-proxyã€CNIï¼ˆCalicoï¼‰

#### **é—®é¢˜èµ·å› **

ç®¡ç†å‘˜ä¸ºäº†ä¿®å¤ Kubernetes é›†ç¾¤è®¿é—®å¼‚å¸¸ï¼Œè¿›è¡Œäº†ä»¥ä¸‹æ“ä½œï¼š

1. **å¤‡ä»½** äº† **3 å¤©å‰çš„ etcd æ•°æ®**
2. **é‡å¯** äº† **Docker**
3. **æ¢å¤** äº† **3 å¤©å‰çš„ etcd æ•°æ®**
4. **è®¿é—®æœåŠ¡ä¾ç„¶å¼‚å¸¸**

**é”™è¯¯ç‚¹ï¼š**

- **etcd æ•°æ®å›æ»š 3 å¤©å‰**ï¼Œæ„å‘³ç€ **æ‰€æœ‰ Kubernetes èµ„æºï¼ˆDeploymentsã€Servicesã€Endpointsï¼‰éƒ½æ¢å¤åˆ°äº† 3 å¤©å‰çš„çŠ¶æ€**ï¼Œè¿™ä¼šå¯¼è‡´èµ„æºç‰ˆæœ¬ï¼ˆResourceVersionï¼‰ä¸åŒ¹é…ï¼Œç”šè‡³ pod å¤±æ•ˆã€‚



### æ•…éšœæ’æŸ¥ä¸ä¿®å¤

æ•…éšœæ¢å¤è¿‡ç¨‹åˆ†ä¸º **ä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µ**ï¼š

1. **Deployment èµ„æºç‰ˆæœ¬ä¸åŒ¹é…**
2. **Iptables ä¸¢å¤±å¯¼è‡´ Service è®¿é—®å¼‚å¸¸**
3. **CNI è¿æ¥å¼‚å¸¸å¯¼è‡´ Pod ç½‘ç»œä¸å¯ç”¨**



#### é˜¶æ®µ 1ï¼šDeployment èµ„æºç‰ˆæœ¬ä¸åŒ¹é…

**é—®é¢˜è¡¨ç°**

- Pod å¤„äº **`Pending`** çŠ¶æ€
- **æ— æ³•è°ƒåº¦åˆ°èŠ‚ç‚¹**
- **åˆ é™¤ pod åæ— æ³•é‡å»º**
- **å°è¯•åˆ é™¤ `kube-scheduler`ï¼Œå‘ç°æ— æ³•é‡æ–°åˆ›å»º**
- **`kubectl rollout history` å‘ç° Deployment ç‰ˆæœ¬ä¸åŒ¹é…**
- **`kube-apiserver` æ—¥å¿—ä¸­å‡ºç° reversion ç‰ˆæœ¬ä¸åŒ¹é…**

**æ’æŸ¥æ€è·¯**

**æ£€æŸ¥è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰**

- **åˆ é™¤ kube-scheduler Pod** ä½†æœªèƒ½è‡ªåŠ¨é‡å»º
- **æ‰‹åŠ¨ç§»é™¤å¹¶æ¢å¤ `/etc/kubernetes/manifests/kube-scheduler.yaml`** é‡æ–°åˆ›å»º `kube-scheduler`
  - æ­¤æ—¶ä»ç„¶æ— æ³•è°ƒåº¦podï¼Œå› æ­¤æ€€ç–‘æ˜¯åœ¨schedulerä¹‹å‰å‡ºç°äº†é—®é¢˜ï¼ŒæŸ¥çœ‹api-serverçš„æ—¥å¿—ï¼Œå‘ç°æœ‰å¾ˆå¤šreversionç‰ˆæœ¬ä¸åŒ¹é…çš„é”™è¯¯ï¼Œåº”è¯¥æ˜¯é›†ç¾¤ä¸­çš„èµ„æºç‰ˆæœ¬å’Œetcdä¸­çš„èµ„æºç‰ˆæœ¬ä¸åŒ¹é…å¯¼è‡´çš„

**æ£€æŸ¥ API Server**

- ä½¿ç”¨ `kubectl logs -n kube-system kube-apiserver` æŸ¥çœ‹æ—¥å¿—
- å‘ç° **èµ„æºç‰ˆæœ¬ä¸åŒ¹é…**ï¼Œè¯´æ˜ etcd ç‰ˆæœ¬ä¸ API Server ä¸­çš„å¯¹è±¡ç‰ˆæœ¬å¯¹ä¸ä¸Š

**æ£€æŸ¥ etcd å¥åº·çŠ¶å†µ**

```bash
etcdctl endpoint health
etcdctl endpoint status --write-out=table
```

ç»“æœæ˜¾ç¤º etcd æ­£å¸¸

**æŸ¥çœ‹ Deployment ç‰ˆæœ¬**

```bash
kubectl rollout history deployment/<deployment_name>
```

**å›æ»š Deployment ç‰ˆæœ¬ï¼ˆæœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼‰**

```bash
kubectl rollout undo deployment/<deployment_name> --to-revision=<version>
```

**è§£å†³æ–¹æ¡ˆ**

- é€šè¿‡ **å›æ»š Deployment** è§£å†³èµ„æºç‰ˆæœ¬ä¸åŒ¹é…é—®é¢˜ã€‚
- **è§‚å¯Ÿ Pod é‡æ–°åˆ›å»ºæƒ…å†µï¼Œç¡®ä¿å¯ä»¥è°ƒåº¦ã€‚**
- **Pod è¿è¡Œåï¼Œæ£€æŸ¥è®¿é—®æ˜¯å¦æ¢å¤ã€‚**



#### é˜¶æ®µ 2ï¼šiptables ä¸¢å¤±å¯¼è‡´ Service è®¿é—®å¼‚å¸¸

**é—®é¢˜è¡¨ç°**

- Service æ— æ³•è®¿é—®
- `kubectl describe service` å‘ç° **æ²¡æœ‰ endpoints**
- `iptables-save` å‘ç° **ä¸¢å¤± Kubernetes ç›¸å…³è§„åˆ™**
- `ipvsadm -l -n` å‘ç° **æ²¡æœ‰ Service å¯¹åº”çš„ Pod IP**

**æ’æŸ¥æ€è·¯**

1. **æ£€æŸ¥ Service æ˜¯å¦å­˜åœ¨**

   ```bash
   kubectl get svc -A
   ```

2. **æ£€æŸ¥ Endpoint æ˜¯å¦è¢«æ­£ç¡®åˆ†é…**

   ```bash
   kubectl get endpoints -A
   ```

3. **æ£€æŸ¥ iptables è§„åˆ™**

   ```bash
   iptables-save | grep KUBE
   ```

4. **æ£€æŸ¥ ipvs è§„åˆ™**

   ```bash
   ipvsadm -l -n  # å‘ç°serviceçš„cluster IPæ²¡æœ‰å¯¹åº”çš„pod IP
   ```

5. **æ£€æŸ¥ kube-proxy æ—¥å¿—**

   ```bash
   kubectl logs -n kube-system -l k8s-app=kube-proxy  # å¹¶æœªå‘ç°ä»»ä½•å¼‚å¸¸
   ```

**è§£å†³æ–¹æ¡ˆ**

- å‘ç° **iptables è§„åˆ™ä¸¢å¤±ï¼Œé‡æ–°åˆå§‹åŒ– kube-proxy**

  ```bash
  kubeadm init phase addon kube-proxy --kubeconfig ~/.kube/config --apiserver-advertise-address <api-server-ip>
  ```

- **é‡å¯ kube-proxy**

  ```bash
  kubectl delete pod -n kube-system -l k8s-app=kube-proxy
  ```

- **é‡æ–°åˆ›å»º Service**

  ```bash
  kubectl delete svc <service-name>
  kubectl apply -f <service-yaml>
  ```

  

#### é˜¶æ®µ 3ï¼šCNI è¿æ¥å¼‚å¸¸

**é—®é¢˜è¡¨ç°**

- `kubectl describe pod <pod>` æ˜¾ç¤º CNI è¿æ¥é”™è¯¯

  ```bash
  networkPlugin cni failed to set up pod "webhook-1" network: Get "https://[10.233.0.1]:443/api/v1/namespaces/volcano-system": dial tcp 10.233.0.1:443: i/o timeout
  ```

- **calico-node pod å¤„äºé Ready çŠ¶æ€**

- `telnet 10.233.0.1 443` å‘ç° API Server æ— æ³•è®¿é—®

**æ’æŸ¥æ€è·¯**

- **æ£€æŸ¥ CNI é…ç½®**

  ```bash
  # calicoçš„/etc/cni/net.d/10-calico.conflisté…ç½®æ–‡ä»¶ä¸­å®šä¹‰äº†è¿æ¥apiserveræ‰€éœ€çš„kubeconfigæ–‡ä»¶
  cat /etc/cni/net.d/10-calico.conflist
  ```

- **æ£€æŸ¥ CNI è®¿é—® API Server**

  ```bash
  # /etc/cni/net.d/calico-kubeconfigä¸­å°±å®šä¹‰äº†è¿æ¥apiserveræ‰€éœ€çš„åœ°å€å’Œç«¯å£
  cat /etc/cni/net.d/calico-kubeconfig
  ```

- **æ£€æŸ¥ calico-node æ—¥å¿—**

  ```bash
  kubectl logs -n kube-system -l k8s-app=calico-node
  ```

- **æŸ¥çœ‹ API Server åœ°å€**

  ```bash
  kubectl get endpoints -n default kubernetes
  ```

  

**è§£å†³æ–¹æ¡ˆ**

- **ä¿®å¤ Calico CNI é…ç½®**

  ```yaml
  - name: KUBERNETES_SERVICE_HOST
    value: <api-server-pod-ip>
  - name: KUBERNETES_SERVICE_PORT
    value: <api-server-pod-port>
  ```

- **åˆ é™¤å¹¶é‡æ–°åˆ›å»º calico-node**

  ```bash
  kubectl delete pod -n kube-system -l k8s-app=calico-node
  ```

- **ç¡®è®¤ CNI è¿æ¥æ¢å¤**

  ```bash
  telnet 10.233.0.1 443
  ```



### æ¡ˆä¾‹çŸ¥è¯†ç‚¹è¡¥å……

#### ä¸ºä»€ä¹ˆ etcd æ•°æ®å›æ»šä¼šå¯¼è‡´èµ„æºç‰ˆæœ¬ä¸åŒ¹é…ï¼Ÿ

åœ¨ Kubernetes é›†ç¾¤ä¸­ï¼Œ**æ‰€æœ‰çš„èµ„æºå¯¹è±¡ï¼ˆå¦‚ Podã€Deploymentã€Service ç­‰ï¼‰éƒ½å­˜å‚¨åœ¨ etcd**ï¼Œå¹¶ä¸”è¿™äº›èµ„æºéƒ½æœ‰ä¸€ä¸ª**èµ„æºç‰ˆæœ¬ï¼ˆResource Versionï¼‰**ï¼Œç”¨äºæ ‡è¯†è¯¥èµ„æºçš„å½“å‰çŠ¶æ€ã€‚

å½“ **etcd æ•°æ®å›æ»š** æ—¶ï¼Œä¼šå‡ºç° **èµ„æºç‰ˆæœ¬ä¸åŒ¹é…** çš„é—®é¢˜ï¼Œä¸»è¦æ˜¯å› ä¸º

- etcd ç‰ˆæœ¬å›æ»šåï¼Œèµ„æºçŠ¶æ€æ¢å¤åˆ°äº†è¿‡å»çš„æŸä¸ªæ—¶é—´ç‚¹ï¼Œä½† API Server çš„çŠ¶æ€ä»ç„¶æ˜¯å½“å‰æ—¶é—´ç‚¹çš„èµ„æºã€‚
- API Server åœ¨å¤„ç†èµ„æºå˜æ›´æ—¶ï¼Œä¾èµ–äº etcd çš„é€’å¢ç‰ˆæœ¬å·ï¼ˆrevisionï¼‰ã€‚å¦‚æœ etcd è¢«å›æ»šï¼Œè¿™äº› revision å¯èƒ½ä¼šé”™ä¹±ï¼Œå¯¼è‡´ API Server æ— æ³•æ­£ç¡®åŒæ­¥èµ„æº
- **Controller Managerã€Scheduler ä¾èµ–çš„èµ„æºç‰ˆæœ¬ï¼ˆResourceVersionï¼‰å’Œ etcd ä¸åŒ¹é…ï¼Œå¯èƒ½å¯¼è‡´è°ƒåº¦å¤±è´¥ã€æ— æ³•æ›´æ–° Deploymentã€æ— æ³•åˆ›å»ºæ–° Podã€‚**



#### ä»€ä¹ˆæ˜¯èµ„æºç‰ˆæœ¬ï¼ˆResource Versionï¼‰ï¼Ÿ

**ResourceVersion** æ˜¯ Kubernetes API ä¸­çš„ä¸€ä¸ªå­—æ®µï¼Œæ¯ä¸ª Kubernetes èµ„æºï¼ˆå¦‚ Podã€Deploymentï¼‰åœ¨ **etcd** ä¸­å­˜å‚¨æ—¶éƒ½ä¼šæœ‰ä¸€ä¸ª **ç‰ˆæœ¬å·**ã€‚

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
  namespace: default
  resourceVersion: "13579"  # èµ„æºç‰ˆæœ¬å·
```

- æ¯æ¬¡èµ„æºæ›´æ–°ï¼ˆå¢åˆ æ”¹ï¼‰æ—¶ï¼ŒresourceVersion éƒ½ä¼šå¢åŠ 
- å½“ API Server æŸ¥è¯¢èµ„æºæ—¶ï¼Œä¼šæ ¹æ® resourceVersion ç¡®ä¿è·å–çš„æ˜¯æœ€æ–°çš„çŠ¶æ€ã€‚

**ä¸¾ä¾‹**

å‡è®¾ etcd å­˜å‚¨äº†å¦‚ä¸‹ Deployment èµ„æº

```yaml
Deployment A:
  ResourceVersion: 1001
Deployment B:
  ResourceVersion: 1002
```

- ä¹‹åæŸä¸ª Pod è¿›è¡Œäº† `kubectl apply`ï¼ŒDeployment A çš„ `ResourceVersion` å˜æˆ `1003`
- ä½†æ˜¯å¦‚æœ **å›æ»š etcd æ•°æ®**ï¼ˆä¾‹å¦‚å›åˆ° `resourceVersion: 1001`ï¼‰ï¼Œé‚£ä¹ˆ



#### etcd èµ„æºç‰ˆæœ¬å¦‚ä½•å½±å“ Kubernetesï¼Ÿ

etcd **å­˜å‚¨çš„æ‰€æœ‰ Kubernetes èµ„æº**ï¼Œä¾‹å¦‚ï¼š

- **Deployments**
- **Pods**
- **Services**
- **ConfigMaps**
- **Secrets**
- **DaemonSets**

è¿™äº›èµ„æºéƒ½æœ‰ä¸€ä¸ª **resourceVersion**ï¼Œç”¨äºè·Ÿè¸ªå˜æ›´ã€‚

å½“ etcd å‘ç”Ÿå›æ»šï¼Œå¯èƒ½ä¼šå¯¼è‡´ï¼š

1. **Pod æ— æ³•è°ƒåº¦**
   - **Scheduler ä¾èµ–äº API Server è·å–æœ€æ–°çš„ Pod ç‰ˆæœ¬**ï¼Œå¦‚æœ API Server å‘ç° etcd ç‰ˆæœ¬æ¯”è‡ªå·±ä½ï¼Œè°ƒåº¦å™¨å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œã€‚
   - `kubectl get pods` å¯èƒ½ä¼šå‡ºç°æ—§ç‰ˆæœ¬çš„ Podï¼Œä½†æ— æ³•æ›´æ–°æˆ–è°ƒåº¦æ–°çš„ Podã€‚
2. **Deployment/DaemonSet å¤±æ•ˆ**
   - `kubectl rollout history deployment/<deployment_name>` å¯èƒ½ä¼šæ˜¾ç¤ºæ—§ç‰ˆæœ¬ï¼Œè€Œæ–°çš„ Pod å¯èƒ½å› ä¸ºèµ„æºç‰ˆæœ¬ä¸åŒ¹é…è€Œæ— æ³•åˆ›å»ºã€‚
3. **Service æ‰¾ä¸åˆ° Endpoints**
   - `kubectl get endpoints` å¯èƒ½ä¼šå‡ºç°ä¸ºç©ºçš„æƒ…å†µï¼Œå› ä¸º etcd é‡Œçš„ Service å¯èƒ½ä¸¢å¤±äº†æœ€æ–°çš„ Endpoint ç»‘å®šä¿¡æ¯ã€‚
4. **API Server æ— æ³•æ­£ç¡®æŸ¥è¯¢èµ„æº**
   - `kubectl get pods` å¯èƒ½å‡ºç° **"resource version too old"** é”™è¯¯ã€‚



#### ä¸ºä»€ä¹ˆ etcd å›æ»šåï¼ŒAPI Server å¯èƒ½ä¼šæŠ¥é”™ï¼Ÿ

**å› ä¸º API Server å’Œ etcd ä¹‹é—´çš„é€šä¿¡åŸºäºèµ„æºç‰ˆæœ¬çš„é€’å¢**ï¼Œå½“ etcd å‘ç”Ÿå›æ»šæ—¶ï¼ŒAPI Server ä»ç„¶è®°å¾—ä¹‹å‰çš„è¾ƒé«˜ç‰ˆæœ¬çš„ resourceVersionï¼Œä½† etcd é‡Œå­˜å‚¨çš„æ˜¯æ—§æ•°æ®ï¼Œå¯¼è‡´ API Server å‘ç°ï¼š

- ä¹‹å‰å­˜åœ¨ `resourceVersion: 1050` çš„èµ„æº
- ä½† etcd é‡Œç°åœ¨åªæœ‰ `resourceVersion: 1000`
- äºæ˜¯ **API Server è®¤ä¸ºæ•°æ®ä¸ä¸€è‡´ï¼Œå¯èƒ½ä¼šæ‹’ç»æ›´æ–°æˆ–å‡ºç°é”™è¯¯**

**ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š** å¦‚æœ etcd å›æ»šäº†æ•°æ®ï¼Œå¹¶ä¸” Kubernetes ç»„ä»¶å‡ºç°é—®é¢˜ï¼Œå¯èƒ½çš„ä¿®å¤æ–¹å¼ï¼š

- **å®Œå…¨é‡å¯ API Server**

  ```bash
  systemctl restart kube-apiserver
  ```

  

- **æ£€æŸ¥ etcd æ•°æ®ä¸€è‡´æ€§**

  ```bash
  etcdctl endpoint health
  etcdctl endpoint status --write-out=table
  ```

- **æ‰‹åŠ¨å›æ»š Deployment åˆ°æ­£ç¡®ç‰ˆæœ¬**

  ```bash
  kubectl rollout history deployment/<deployment_name>
  kubectl rollout undo deployment/<deployment_name> --to-revision=<version>
  ```

- **åˆ é™¤å¹¶é‡å»º pod**

  ```bash
  kubectl delete pod --all -n default
  ```

- **å¦‚æœé—®é¢˜ä¸¥é‡ï¼Œè€ƒè™‘é‡æ–°åˆå§‹åŒ– etcd**

  ```bash
  kubeadm init phase etcd
  ```

  **é‡æ–°åˆå§‹åŒ– etcd**ï¼ˆä¾‹å¦‚ `kubeadm init phase etcd`ï¼‰ï¼Œé‚£ä¹ˆ **etcd çš„æ•°æ®é€šå¸¸ä¼šè¢«æ¸…ç©º**ï¼Œé›†ç¾¤ä¸­çš„æ‰€æœ‰èµ„æºï¼ˆPodsã€Deploymentsã€Servicesã€ConfigMaps ç­‰ï¼‰éƒ½ä¼šä¸¢å¤±ã€‚**è¿™ç±»ä¼¼äºå…¨æ–°éƒ¨ç½² etcdã€‚**



