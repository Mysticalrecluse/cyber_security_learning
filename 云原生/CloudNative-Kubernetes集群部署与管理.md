## Kubernetesé›†ç¾¤éƒ¨ç½²



### Kubernetes é›†ç¾¤ç»„ä»¶è¿è¡Œæ¨¡å¼

#### **ç‹¬ç«‹ç»„ä»¶æ¨¡å¼** 

- å„å…³é”®ç»„ä»¶éƒ½ä»¥äºŒè¿›åˆ¶æ–¹å¼éƒ¨ç½²äºä¸»æœºèŠ‚ç‚¹ä¸Šï¼Œå¹¶ä»¥å®ˆæŠ¤è¿›ç¨‹å½¢å¼è¿è¡Œ 
- å„é™„ä»¶Add-ons åˆ™ä»¥Podå½¢å¼è¿è¡Œ 
- éœ€è¦å®ç°å„ç§è¯ä¹¦çš„ç”³è¯·é¢å‘
-  éƒ¨ç½²è¿‡ç¨‹ç¹çå¤æ‚

![alt text](images/image21.png)



#### **é™æ€Podæ¨¡å¼**

- **kubeletå’Œå®¹å™¨è¿è¡Œæ—¶dockerä»¥äºŒè¿›åˆ¶éƒ¨ç½²ï¼Œè¿è¡Œä¸ºå®ˆæŠ¤è¿›ç¨‹**
- é™¤æ­¤ä¹‹å¤–æ‰€æœ‰ç»„ä»¶ä¸ºPod æ–¹å¼è¿è¡Œ

- æ§åˆ¶å¹³å°å„ç»„ä»¶ä»¥é™æ€Podå¯¹è±¡è¿è¡ŒäºMasterä¸»æœºä¹‹ä¸Š
- é™æ€Podç”±kubeletæ‰€æ§åˆ¶å®ç°åˆ›å»ºç®¡ç†,è€Œæ— éœ€ä¾èµ–kube-apiserverç­‰æ§åˆ¶å¹³å°ç»„ä»¶
- kube-proxyç­‰åˆ™ä»¥Podå½¢å¼è¿è¡Œ
- ç›¸å…³podæ—©æœŸæ˜¯ä»ä»“åº“k8s.gcr.ioä¸‹è½½é•œåƒï¼Œæ–°ç‰ˆæ”¹ä¸ºä»“åº“registry.k8s.io
- ä½¿ç”¨kuberneteså®˜æ–¹æä¾›çš„kubeadmå·¥å…·å®ç°kubernetesé›†ç¾¤æ–¹ä¾¿å¿«é€Ÿçš„éƒ¨ç½²

![alt text](images/image22.png)



### åŸºäºKubeadmå’Œ Docker éƒ¨ç½² kubernetes é«˜å¯ç”¨é›†ç¾¤


![alt text](images/image23.png)


å‚è€ƒæ–‡æ¡£ï¼š

``````
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/
https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md
``````



kubeadmæ˜¯Kubernetesç¤¾åŒºæä¾›çš„é›†ç¾¤æ„å»ºå·¥å…·

- è´Ÿè´£æ‰§è¡Œæ„å»ºä¸€ä¸ªæœ€å°åŒ–å¯ç”¨é›†ç¾¤å¹¶å°†å…¶å¯åŠ¨ç­‰å¿…è¦çš„åŸºæœ¬æ­¥éª¤
- Kubernetesé›†ç¾¤å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å·¥å…·ï¼Œå¯ç”¨äºå®ç°é›†ç¾¤çš„éƒ¨ç½²ã€å‡çº§/é™çº§åŠå¸è½½ç­‰
- kubeadmä»…å…³å¿ƒå¦‚ä½•åˆå§‹åŒ–å¹¶æ‹‰èµ·ä¸€ä¸ªé›†ç¾¤ï¼Œå…¶èŒè´£ä»…é™äºä¸‹å›¾ä¸­èƒŒæ™¯è“è‰²çš„éƒ¨åˆ†
- è“è‰²çš„éƒ¨åˆ†ä»¥å¤–çš„å…¶å®ƒç»„ä»¶è¿˜éœ€è¦è‡ªè¡Œéƒ¨ç½² 

![alt text](images/image24.png)

æ³¨æ„ï¼šåœ¨kubeadmæ–¹å¼å®‰è£…æ—¶ï¼ŒKubernetes çš„æ‰€æœ‰ç»„ä»¶ä¸­é™¤kubelet æ˜¯ä»¥ä¼ ç»ŸæœåŠ¡è¿›ç¨‹çš„æ–¹å¼è¿è¡Œï¼Œå…¶å®ƒéƒ½ä»¥å®¹å™¨è¿è¡Œ



#### éƒ¨ç½²ç¯å¢ƒè¯´æ˜

![alt text](images/image25.png)



| IP         | ä¸»æœºå           | è§’è‰²                                      |
| ---------- | ---------------- | ----------------------------------------- |
| 10.0.0.101 | master1.wang.org | K8s é›†ç¾¤ä¸»èŠ‚ç‚¹ 1ï¼ŒMasterå’Œetcd            |
| 10.0.0.102 | master2.wang.org | K8s é›†ç¾¤ä¸»èŠ‚ç‚¹ 2ï¼ŒMasterå’Œetcd            |
| 10.0.0.103 | master3.wang.org | K8s é›†ç¾¤ä¸»èŠ‚ç‚¹ 3ï¼ŒMasterå’Œetcd            |
| 10.0.0.104 | node1.wang.org   | K8s é›†ç¾¤å·¥ä½œèŠ‚ç‚¹ 1                        |
| 10.0.0.105 | node2.wang.org   | K8s é›†ç¾¤å·¥ä½œèŠ‚ç‚¹ 2                        |
| 10.0.0.106 | node3.wang.org   | K8s é›†ç¾¤å·¥ä½œèŠ‚ç‚¹ 3                        |
| 10.0.0.107 | ha1.wang.org     | K8s ä¸»èŠ‚ç‚¹è®¿é—®å…¥å£ 1,æä¾›é«˜å¯ç”¨åŠè´Ÿè½½å‡è¡¡ |
| 10.0.0.108 | ha2.wang.org     | K8s ä¸»èŠ‚ç‚¹è®¿é—®å…¥å£ 2,æä¾›é«˜å¯ç”¨åŠè´Ÿè½½å‡è¡¡ |
| 10.0.0.109 | harbor.wang.org  | å®¹å™¨é•œåƒä»“åº“                              |
| 10.0.0.100 | kubeapi.wang.org | VIPï¼Œåœ¨ha1å’Œha2ä¸»æœºå®ç°                   |

æ³¨æ„ï¼š MasterèŠ‚ç‚¹å†…å­˜è‡³å°‘2Gä»¥ä¸Šï¼Œå¦åˆ™åœ¨åˆå§‹åŒ–æ—¶ä¼šå‡ºé”™



#### ç½‘ç»œåœ°å€è§„åˆ’

``````bash
ç‰©ç†ä¸»æœºç½‘ç»œ        10.0.0.0/24 
é›†ç¾¤podç½‘ç»œ        --pod-network-cidr=10.244.0.0/16
åº”ç”¨serviceç½‘ç»œ    --service-cidr=10.96.0.0/12 
``````

![alt text](images/image26.png)



#### åŸºäº kubeadm å’Œ Docker å®ç°Kuberenetesé›†ç¾¤æµç¨‹è¯´æ˜

- æ¯ä¸ªèŠ‚ç‚¹ä¸»æœºçš„åˆå§‹ç¯å¢ƒå‡†å¤‡
- å‡†å¤‡ä»£ç†æœåŠ¡,ä»¥ä¾¿è®¿é—®k8s.gcr.ioï¼Œæˆ–æ ¹æ®éƒ¨ç½²è¿‡ç¨‹æç¤ºçš„æ–¹æ³•è·å–ç›¸åº”çš„Iå›½å†…é•œåƒçš„imageï¼ˆå¯é€‰ï¼‰
- Kubernetesé›†ç¾¤APIè®¿é—®å…¥å£çš„é«˜å¯ç”¨å’Œharborï¼ˆå¯é€‰ï¼‰
- **åœ¨æ‰€æœ‰Masterå’ŒNodeèŠ‚ç‚¹éƒ½å®‰è£…å®¹å™¨è¿è¡Œæ—¶ Docker**
- **åœ¨æ‰€æœ‰èŠ‚ç‚¹å®‰è£…å’Œé…ç½® cri-dockerd(kubernetes-v1.24ç‰ˆæœ¬ä»¥åéœ€è¦)**
- **åœ¨æ‰€æœ‰Masterå’ŒNodeèŠ‚ç‚¹éƒ½å®‰è£…kubeadm ã€kubeletã€kubectl(é›†ç¾¤ç®¡ç†å·¥å…·,åœ¨nodeèŠ‚ç‚¹å¯ ä¸å®‰è£…)**
- **åœ¨ç¬¬ä¸€ä¸ª master èŠ‚ç‚¹è¿è¡Œ kubeadm init åˆå§‹åŒ–å‘½ä»¤ ,å¹¶éªŒè¯ master èŠ‚ç‚¹çŠ¶æ€**
- **åœ¨ç¬¬ä¸€ä¸ª master èŠ‚ç‚¹å®‰è£…é…ç½®CNIè§„èŒƒçš„ç½‘ç»œæ’ä»¶**
- åœ¨å…¶å®ƒmasterèŠ‚ç‚¹è¿è¡Œkubeadm join å‘½ä»¤åŠ å…¥åˆ°æ§åˆ¶å¹³é¢é›†ç¾¤ä¸­å®ç°é«˜å¯ç”¨(æµ‹è¯•ç¯å¢ƒå¯é€‰)
- **åœ¨æ‰€æœ‰ node èŠ‚ç‚¹ä½¿ç”¨ kubeadm join å‘½ä»¤åŠ å…¥é›†ç¾¤ , å¹¶éªŒè¯ node èŠ‚ç‚¹çŠ¶æ€**
- åˆ›å»º pod å¹¶å¯åŠ¨å®¹å™¨æµ‹è¯•è®¿é—® ï¼Œå¹¶æµ‹è¯•ç½‘ç»œé€šä¿¡



#### åˆå§‹ç¯å¢ƒå‡†å¤‡

- ç¡¬ä»¶å‡†å¤‡ç¯å¢ƒ: æ¯ä¸ªä¸»æœºè‡³å°‘2Gä»¥ä¸Šå†…å­˜,CPU2æ ¸ä»¥ä¸Š
- æ“ä½œç³»ç»Ÿ: æœ€å°åŒ–å®‰è£…æ”¯æŒKubernetesçš„Linuxç³»ç»Ÿ
- å”¯ä¸€çš„ä¸»æœºåï¼ŒMACåœ°å€ä»¥åŠproduct_uuidå’Œä¸»æœºåè§£æ
- ä¿è¯å„ä¸ªèŠ‚ç‚¹ç½‘ç»œé…ç½®æ­£ç¡®,å¹¶ä¸”ä¿è¯é€šä¿¡æ­£å¸¸
- ç¦ç”¨ swap 
- ç¦ç”¨ SELinux
- æ”¾è¡ŒKubernetesä½¿ç”¨åˆ°çš„ç›¸å…³ç«¯å£æˆ–ç¦ç”¨firewalld/iptables
- é…ç½®æ­£ç¡®çš„æ—¶åŒºå’Œæ—¶é—´åŒæ­¥
- å†…æ ¸å‚æ•°ä¼˜åŒ– 
- æ‰€æœ‰èŠ‚ç‚¹å®ç°åŸºäº ssh key éªŒè¯(å¯é€‰)



**æ£€æŸ¥æ¯å°æœºå™¨çš„product_uuidï¼Œproject_uuidè¦å…·å¤‡å”¯ä¸€æ€§**

``````bash
[root@ubuntu2204 ~]#cat /sys/class/dmi/id/product_uuid
e0c84d56-f33b-6754-eab2-d5e7cb846dc1
 
[root@rocky8 ~]#cat /sys/class/dmi/id/product_uuid
10324d56-9c12-c716-dfa1-196e5242b4d3
``````





**æ¯å¤©æœºå™¨ä¸Šè®¾ç½®hostname,å¹¶é…ç½®/etc/hosts**

``````bash
# cat >> /etc/hosts <<EOF
10.0.0.100 kubeapi kubeapi.wang.org 
10.0.0.101 master1 master1.wang.org
10.0.0.102 master2 master2.wang.org
10.0.0.103 master3 master3.wang.org
10.0.0.104 node1 node1.wang.org
10.0.0.105 node2 node2.wang.org
10.0.0.106 node3 node3.wang.org
10.0.0.107 ha1 ha1.wang.org
10.0.0.108 ha2 ha2.wang.org
10.0.0.109 harbor harbor.wang.org
EOF
``````



**ä½¿ç”¨sshæ‰“é€šæ¯å°æœºå™¨**

``````bash
ssh-keygen

ssh-copy-id 127.0.0.1

for i in {101..108}; do scp -r .ssh 10.0.0.$i:/root/; done
``````



**è®¾ç½®æ¯å°ä¸»æœºçš„ä¸»æœºå**

``````bash
for i in {1..3} ;do ssh 10.0.0.10$i hostnamectl set-hostname master$i;done
for i in {4..6} ;do ssh 10.0.0.10$i hostnamectl set-hostname node$(($i-3));done
ssh 10.0.0.107 hostnamectl set-hostname ha1
ssh 10.0.0.108 hostnamectl set-hostname ha2
``````



**å®ç°ä¸»æœºæ—¶é—´åŒæ­¥**

``````bash
timedatectl set-timezone Asia/Shanghai

apt update
apt install  chrony -y

vim /etc/chrony/chrony.conf
 #åŠ ä¸‹é¢ä¸€è¡Œ
pool ntp.aliyun.com        iburst maxsources 2
pool ntp.ubuntu.com        iburst maxsources 4
pool 0.ubuntu.pool.ntp.org iburst maxsources 1
pool 1.ubuntu.pool.ntp.org iburst maxsources 1
pool 2.ubuntu.pool.ntp.org iburst maxsources 2

systemctl enable chrony
systemctl restart chrony
``````



 **å…³é—­SELinux**

``````bash
 ~# setenforce 0
 ~# sed -i 's#^\(SELINUX=\).*#\1disabled#' /etc/sysconfig/selinux
``````



**å…³é—­é˜²ç«å¢™**

``````bash
# Rocky
systemctl disable --now firewalld 

# Ubuntu
systemctl disable --now ufw
``````



 **ç¦ç”¨ Swap è®¾å¤‡**

``````bash
#æ–¹æ³•1
~# swapoff -a
~# sed -i  '/swap/s/^/#/' /etc/fstab
~# for i in {101..106};do ssh 10.0.0.$i "sed -i  '/swap/s/^/#/' /etc/fstab"; ssh 10.0.0.$i swapoff -a ; done

#æ–¹æ³•2
~# systemctl stop  swap.img.swap
~# systemctl mask swap.img.swap æˆ–è€… systemctl mask swap.target
 
#æ–¹æ³•3
~# systemctl mask swap.img.swap æˆ–è€… systemctl mask swap.target
~# reboot

#ç¡®è®¤æ˜¯å¦ç¦ç”¨swap
~# systemctl -t swap 
~# swapon -s 

``````



**å†…æ ¸ä¼˜åŒ–**  

æ ¹æ®ç¡¬ä»¶å’Œä¸šåŠ¡éœ€æ±‚,å¯¹å†…æ ¸å‚æ•°åšç›¸åº”çš„ä¼˜åŒ– 

æ³¨æ„:å®‰è£…dockeræ—¶ä¼šè‡ªåŠ¨ä¿®æ”¹å†…æ ¸å‚æ•°





#### å®ç°é«˜å¯ç”¨çš„åå‘ä»£ç†



**å®ç° keepalived**

åœ¨ä¸¤å°ä¸»æœºha1å’Œha2 æŒ‰ä¸‹é¢æ­¥éª¤éƒ¨ç½²å’Œé…ç½® keepalived

``````bash
[root@ha1 ~]#apt update && apt -y install keepalived 

#keepalivedé…ç½®
[root@ha1 ~]#cp  /usr/share/doc/keepalived/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf

[root@ha1 ~]#vim /etc/keepalived/keepalived.conf

! Configuration File for keepalived
global_defs {
  notification_email {
    acassen
  }
  notification_email_from Alexandre.Cassen@firewall.loc
  smtp_server 192.168.200.1
  smtp_connect_timeout 30
  router_id ha1.wang.org  #æŒ‡å®šrouter_id,#åœ¨ha2ä¸Šä¸ºha2.wang.org
}
vrrp_script check_haproxy {
   script "/etc/keepalived/check_haproxy.sh"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
vrrp_instance VI_1 {
   state MASTER              #åœ¨ha2ä¸Šä¸ºBACKUP        
   interface eth0
   garp_master_delay 10
   smtp_alert
   virtual_router_id 66      #æŒ‡å®šè™šæ‹Ÿè·¯ç”±å™¨ID,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ
   priority 100              #åœ¨ha2ä¸Šä¸º80          
   advert_int 1
   authentication {
       auth_type PASS
       auth_pass 123456      #æŒ‡å®šéªŒè¯å¯†ç ,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ  
   }
   virtual_ipaddress {
       10.0.0.100/24 dev eth0  label eth0:1  #æŒ‡å®šVIP,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ
   }
   track_script {
       check_haproxy 
   }
}
 [root@ha1 ~]#cat /etc/keepalived/check_haproxy.sh
 #!/bin/bash
 /usr/bin/killall -0 haproxy  || systemctl restart haproxy
 [root@ha1 ~]#chmod +x /etc/keepalived/check_haproxy.sh
 [root@ha1 ~]#hostname -I
 10.0.0.107 
[root@ha1 ~]#systemctl start keepalived.service 
#éªŒè¯keepalivedæœåŠ¡æ˜¯å¦æ­£å¸¸
``````





**å®ç° Haproxy**

é€šè¿‡ Harproxy å®ç° kubernetes Api-serverçš„å››å±‚åå‘ä»£ç†å’Œè´Ÿè½½å‡è¡¡åŠŸèƒ½

``````bash
#åœ¨ä¸¤å°ä¸»æœºha1å’Œha2éƒ½æ‰§è¡Œä¸‹é¢æ“ä½œ
[root@ha1 ~]#cat >> /etc/sysctl.conf <<EOF
net.ipv4.ip_nonlocal_bind = 1
EOF
root@ha1 ~]#sysctl -p 

#å®‰è£…é…ç½®haproxy
[root@ha1 ~]#apt -y install haproxy
[root@ha1 ~]#vim /etc/haproxy/haproxy.cfg 
[root@ha1 ~]#cat /etc/haproxy/haproxy.cfg

global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http

##########æ·»åŠ ä»¥ä¸‹å†…å®¹######################

listen stats
    mode http
    bind 0.0.0.0:8888
    stats enable
    log global
    stats uri /status
    stats auth admin:123456

listen  kubernetes-api-6443
    bind 10.0.0.100:6443
    mode tcp 
    server master1 10.0.0.101:6443 check inter 3s fall 3 rise 3 
    server master2 10.0.0.102:6443 check inter 3s fall 3 rise 3 
    server master3 10.0.0.103:6443 check inter 3s fall 3 rise 3 
``````



æµè§ˆå™¨è®¿é—®ï¼š http://ha2.wang.org:8888/status ï¼Œå¯ä»¥çœ‹åˆ°ä¸‹é¢ç•Œé¢


![alt text](images/image27.png)



#### åœ¨masterå’Œworkerä¸Šå®‰è£…docker

``````bash
# master
wget https://www.mysticalrecluse.com/script/Shell/install_docker_offline.sh
bash install_docker_offline.sh
``````



####  æ‰€æœ‰ä¸»æœºå®‰è£… cri-dockerd(v1.24ä»¥åç‰ˆæœ¬)

```````bash
wget https://mirror.ghproxy.com/https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.14/cri-dockerd_0.3.14.3-0.ubuntu-jammy_amd64.deb

# å¦‚æœå‡ºç°ä¾èµ–é—®é¢˜ï¼Œä½¿ç”¨è¯¥å‘½ä»¤ä¿®å¤
apt --fix-broken install -y

# å¦‚æœå‡ºç°å¦‚ä¸‹æŠ¥é”™
[root@ubuntu2204 ~]#systemctl status cri-docker.service 
â—‹ cri-docker.service - CRI Interface for Docker Application Container Engine
     Loaded: loaded (/lib/systemd/system/cri-docker.service; enabled; vendor preset: enabled)
     Active: inactive (dead)
TriggeredBy: Ã— cri-docker.socket
       Docs: https://docs.mirantis.com

12æœˆ 15 16:23:19 master2 systemd[1]: Dependency failed for CRI Interface for Docker Application Container Engine.
12æœˆ 15 16:23:19 master2 systemd[1]: cri-docker.service: Job cri-docker.service/start failed with result 'dependency'.

# è§£å†³æ–¹æ³•ï¼šæ·»åŠ dockerç»„
groupadd docker

# é‡å¯cri-docker
systemctl restart cri-docker.service
systemctl status cri-docker.service
```````





#### æ‰€æœ‰ä¸»æœºé…ç½® cri-dockerd(v1.24ä»¥åç‰ˆæœ¬

``````bash
# vim /lib/systemd/system/cri-docker.service
ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint fd:// --pod-infra-container-image registry.aliyuncs.com/google_containers/pause:3.9
``````





#### æ‰€æœ‰ master å’Œ node èŠ‚ç‚¹å®‰è£…kubeadmç­‰ç›¸å…³åŒ…

æ‰€æœ‰ master å’Œ node èŠ‚ç‚¹éƒ½å®‰è£…kubeadm, kubelet,kubectl ç›¸å…³åŒ…

æ³¨æ„: nodeèŠ‚ç‚¹å¯ä»¥ä¸å®‰è£…ç®¡ç†å·¥å…· kubectl åŒ…,ä½†ä¾èµ–å…³ç³»ä¼šè‡ªåŠ¨å®‰è£…



``````bash
# cat install_k8s.sh
#!/bin/bash
apt update && apt-get install -y apt-transport-https
curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/deb/ /" | tee /etc/apt/sources.list.d/kubernetes.list
apt-get update
apt-get install -y kubelet kubeadm kubectl
``````





#### åœ¨ç¬¬ä¸€ä¸ª master èŠ‚ç‚¹è¿è¡Œ kubeadm init åˆå§‹åŒ–å‘½ä»¤

``````
K8S_RELEASE_VERSION=1.30.2 && kubeadm init --control-plane-endpoint kubeapi.wang.org --kubernetes-version=v${K8S_RELEASE_VERSION} --pod-network-cidr 10.244.0.0/16 --service-cidr 10.96.0.0/12 --image-repository registry.aliyuncs.com/google_containers --token-ttl=0 --upload-certs --cri-socket=unix:///run/cri-dockerd.sock
``````



**å®Œæ•´å‘½ä»¤**

``````bash
K8S_RELEASE_VERSION=1.30.2 && kubeadm init --control-plane-endpoint master1.mystical.org --kubernetes-version=v${K8S_RELEASE_VERSION} --pod-network-cidr 10.244.0.0/16 --service-cidr 10.96.0.0/12 --image-repository registry.aliyuncs.com/google_containers --token-ttl=0 --upload-certs --cri-socket=unix:///run/cri-dockerd.sock
``````



**é€ä¸ªå­—æ®µçš„è¯¦ç»†è§£é‡Š**

1ï¸âƒ£ `K8S_RELEASE_VERSION=1.30.2`

- **å«ä¹‰**ï¼šå®šä¹‰ä¸€ä¸ªç¯å¢ƒå˜é‡ `K8S_RELEASE_VERSION`ï¼Œç”¨äºæŒ‡å®š Kubernetes ç‰ˆæœ¬ã€‚

- **ä½œç”¨**ï¼šåœ¨ `kubeadm init` å‘½ä»¤ä¸­ï¼Œé€šè¿‡ `${K8S_RELEASE_VERSION}` å¼•ç”¨è¿™ä¸ªå˜é‡ï¼Œç®€åŒ–ç‰ˆæœ¬æ§åˆ¶ï¼Œä¾¿äºæ›´æ–° Kubernetes ç‰ˆæœ¬ã€‚

- ç¤ºä¾‹ï¼š

  ```
  bashCopy codeK8S_RELEASE_VERSION=1.30.2
  echo $K8S_RELEASE_VERSION  # è¾“å‡º 1.30.2
  ```



2ï¸âƒ£ **`kubeadm init`**

- **å«ä¹‰**ï¼š`kubeadm init` å‘½ä»¤ç”¨äºåˆå§‹åŒ– Kubernetes æ§åˆ¶å¹³é¢ï¼ˆMaster èŠ‚ç‚¹ï¼‰ã€‚
- **ä½œç”¨**ï¼šè¯¥å‘½ä»¤åœ¨æ§åˆ¶èŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œåˆå§‹åŒ– Kubernetes é›†ç¾¤ï¼Œç”Ÿæˆ tokenã€è¯ä¹¦å’Œ Kubeconfig æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆ `kubeadm join` å‘½ä»¤ï¼Œä»¥ä¾¿å…¶ä»–èŠ‚ç‚¹åŠ å…¥é›†ç¾¤ã€‚



3ï¸âƒ£ **`--control-plane-endpoint kubeapi.wang.org`**

- **å«ä¹‰**ï¼šè®¾ç½® Kubernetes æ§åˆ¶å¹³é¢çš„**é«˜å¯ç”¨å…¥å£åœ°å€**ã€‚
- ä½œç”¨ï¼š
  - å¦‚æœä½ æœ‰å¤šä¸ª master æ§åˆ¶å¹³é¢èŠ‚ç‚¹ï¼Œéœ€è¦ä¸ºè¿™äº›æ§åˆ¶å¹³é¢æä¾›ä¸€ä¸ª**ç»Ÿä¸€çš„è®¿é—®å…¥å£**ã€‚
  - è¿™ä¸ªæ§åˆ¶å¹³é¢å…¥å£ï¼ˆ`kubeapi.wang.org`ï¼‰é€šå¸¸æ˜¯ä¸€ä¸ª **VIP (è™šæ‹ŸIP)**ï¼Œæˆ–è€…æ˜¯ä¸€ä¸ªå¯ä»¥è´Ÿè½½å‡è¡¡åˆ°å¤šä¸ªæ§åˆ¶å¹³é¢èŠ‚ç‚¹çš„ FQDNã€‚
  - è¿™æ ·ï¼ŒKubernetes é›†ç¾¤å†…çš„ kubelet åªéœ€è¿æ¥è¿™ä¸ªåŸŸåï¼Œ**ä¸éœ€è¦çŸ¥é“å…·ä½“çš„æ§åˆ¶å¹³é¢èŠ‚ç‚¹çš„ IP**ã€‚
- ç¤ºä¾‹ï¼š
  - å¦‚æœä½ æœ‰ 3 å°æ§åˆ¶å¹³é¢èŠ‚ç‚¹ï¼Œ`10.0.0.1, 10.0.0.2, 10.0.0.3`ï¼Œé‚£ä¹ˆä½ å¯ä»¥è®¾ç½®ä¸€ä¸ª VIP ä¾‹å¦‚ `10.0.0.100` å¹¶å°†åŸŸå `kubeapi.wang.org` è§£æä¸º `10.0.0.100`ã€‚
  - é€šè¿‡ **Keepalived** å’Œ **HAProxy**ï¼Œå¯ä»¥å°†è¯·æ±‚ä» `10.0.0.100` è½¬å‘åˆ° 3 å°æ§åˆ¶å¹³é¢èŠ‚ç‚¹ä¸­çš„ä»»æ„ä¸€ä¸ªã€‚



4ï¸âƒ£ **`--kubernetes-version=v${K8S_RELEASE_VERSION}`**

- **å«ä¹‰**ï¼šæŒ‡å®šè¦å®‰è£…çš„ Kubernetes ç‰ˆæœ¬ã€‚

- **ä½œç”¨**ï¼šå¼ºåˆ¶ kubeadm ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬çš„ Kubernetes ç»„ä»¶ã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --kubernetes-version=v1.30.2
  ```



5ï¸âƒ£ **`--pod-network-cidr 10.244.0.0/16`**

- **å«ä¹‰**ï¼šè®¾ç½® Pod ç½‘ç»œçš„ CIDR åœ°å€æ®µã€‚
- ä½œç”¨ï¼š
  - åœ¨ Kubernetes é›†ç¾¤ä¸­ï¼Œæ¯ä¸ª Pod éƒ½éœ€è¦æœ‰ä¸€ä¸ªå”¯ä¸€çš„ IP åœ°å€ã€‚
  - `--pod-network-cidr` æŒ‡å®šäº†**Pod IP åœ°å€æ®µ**ã€‚
  - è¯¥ IP åœ°å€æ®µè¢« CNIï¼ˆå¦‚ Flannelã€Calicoã€Weaveï¼‰ä½¿ç”¨ï¼Œé€šå¸¸ä¸ä¸æœåŠ¡å™¨çš„æœ¬åœ° IP åœ°å€å†²çªã€‚
- æ³¨æ„äº‹é¡¹ï¼š
  - Flannel é€šå¸¸ä½¿ç”¨ `10.244.0.0/16`ã€‚
  - Calico é»˜è®¤ä½¿ç”¨ `192.168.0.0/16`ã€‚
- ç¤ºä¾‹ï¼š
  - `--pod-network-cidr=10.244.0.0/16` è¡¨ç¤º Pod IP åœ°å€çš„èŒƒå›´æ˜¯ `10.244.0.0 - 10.244.255.255`ã€‚



6ï¸âƒ£ **`--service-cidr 10.96.0.0/12`**

- **å«ä¹‰**ï¼šæŒ‡å®š Service çš„è™šæ‹Ÿ IP åœ°å€æ®µã€‚

- ä½œç”¨ï¼š

  - åœ¨ Kubernetes ä¸­ï¼ŒService æ˜¯ä¸€ç§é›†ç¾¤å†…çš„**è™šæ‹Ÿ IP**ï¼Œè¿™äº› IP ä¸ä¸ç‰©ç†ä¸»æœº IP å†²çªã€‚
  - è¿™ä¸ª IP æ®µç”± kube-proxy å’Œ iptables ç»´æŠ¤ã€‚

- æ³¨æ„äº‹é¡¹ï¼š

  - Service IP åªèƒ½åœ¨**é›†ç¾¤å†…éƒ¨è®¿é—®**ã€‚
  - é€šå¸¸ä¸ä¸ç‰©ç†ç½‘ç»œ IP æ®µå†²çªã€‚
  - ä¸€èˆ¬æ˜¯ `10.96.0.0/12`ï¼Œè¡¨ç¤º `10.96.0.0 - 10.111.255.255` è¿™ä¸ªèŒƒå›´ã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --service-cidr=10.96.0.0/12
  ```





7ï¸âƒ£ **`--image-repository registry.aliyuncs.com/google_containers`**

- **å«ä¹‰**ï¼šæŒ‡å®š Kubernetes ç»„ä»¶é•œåƒçš„æ‹‰å–åœ°å€ã€‚

- ä½œç”¨ï¼š

  - ç”±äºå›½å†…æ— æ³•ç›´æ¥è®¿é—® **Google å®¹å™¨é•œåƒä»“åº“ (gcr.io)**ï¼Œæ‰€ä»¥ç”¨é˜¿é‡Œäº‘çš„é•œåƒæºã€‚
  - `registry.aliyuncs.com/google_containers` æ˜¯å›½å†…å¸¸ç”¨çš„é•œåƒæºï¼ŒåŒ…å«æ‰€æœ‰ Kubernetes ç›¸å…³çš„é•œåƒã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --image-repository registry.aliyuncs.com/google_containers
  ```





8ï¸âƒ£ **`--token-ttl=0`**

- **å«ä¹‰**ï¼šè®¾ç½® kubeadm join å‘½ä»¤ä¸­ Token çš„æœ‰æ•ˆæ—¶é—´ã€‚

- ä½œç”¨ï¼š

  - é»˜è®¤çš„ token è¿‡æœŸæ—¶é—´æ˜¯ 24 å°æ—¶ã€‚
  - é€šè¿‡ `--token-ttl=0`ï¼Œè¡¨ç¤ºç”Ÿæˆçš„ token**æ°¸ä¸è¿‡æœŸ**ã€‚
  - é€‚ç”¨äºé•¿æ—¶é—´éƒ¨ç½²èŠ‚ç‚¹ï¼Œæˆ–è€…éœ€è¦ä¸€æ®µæ—¶é—´å†…å¤šæ¬¡åŠ å…¥æ–°èŠ‚ç‚¹çš„åœºæ™¯ã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --token-ttl=0
  ```





9ï¸âƒ£ **`--upload-certs`**

- **å«ä¹‰**ï¼šå°†è¯ä¹¦ä¸Šä¼ åˆ°é›†ç¾¤ä¸­çš„æ§åˆ¶å¹³é¢èŠ‚ç‚¹ã€‚

- ä½œç”¨ï¼š

  - åœ¨é«˜å¯ç”¨é›†ç¾¤ä¸­ï¼Œæ§åˆ¶å¹³é¢èŠ‚ç‚¹ä¹‹é—´éœ€è¦å…±äº«è¯ä¹¦ã€‚
  - kubeadm ä¼šå°†è¯ä¹¦åŠ å¯†å­˜å‚¨åœ¨ **Kubernetes Secret** ä¸­ã€‚
  - é€šè¿‡è¿™ä¸ªå‚æ•°ï¼Œ**å…è®¸å…¶ä»–æ§åˆ¶å¹³é¢èŠ‚ç‚¹ä¸‹è½½è¿™äº›è¯ä¹¦**ã€‚

- ç¤ºä¾‹ï¼š

  ```
  --upload-certs
  ```





ğŸ”Ÿ **`--cri-socket=unix:///run/cri-dockerd.sock`**

- **å«ä¹‰**ï¼šæŒ‡å®š Kubelet è¿æ¥çš„ CRIï¼ˆå®¹å™¨è¿è¡Œæ—¶æ¥å£ï¼‰ã€‚

- ä½œç”¨ï¼š

  - Kubernetes æ”¯æŒå¤šä¸ª CRIï¼Œå¦‚ **containerd**ã€**cri-o** å’Œ **Docker**ã€‚
  - cri-dockerd æ˜¯ä¸€ä¸ªä¸“é—¨çš„ Docker CRI æ’ä»¶ã€‚
  - æ­¤é€‰é¡¹å‘Šè¯‰ Kubernetesï¼š**å°† Kubelet è¿æ¥åˆ° /run/cri-dockerd.sock**ã€‚

- æ³¨æ„ï¼š

  - å¦‚æœæœªæŒ‡å®šæ­¤é€‰é¡¹ï¼ŒKubelet å°†å°è¯•è‡ªåŠ¨æ£€æµ‹ CRIã€‚
  - cri-dockerd æ˜¯ç”¨äºä» Docker è½¬æ¢åˆ° Containerd çš„ä¸´æ—¶è§£å†³æ–¹æ¡ˆã€‚

- ç¤ºä¾‹ï¼š

  ```bash
  --cri-socket=unix:///run/cri-dockerd.sock
  ```





**æ€»ç»“**

| é€‰é¡¹                       | å«ä¹‰                 | ç¤ºä¾‹                           |
| -------------------------- | -------------------- | ------------------------------ |
| `--control-plane-endpoint` | æ§åˆ¶å¹³é¢çš„é«˜å¯ç”¨å…¥å£ | `kubeapi.feng.org`             |
| `--kubernetes-version`     | æŒ‡å®š Kubernetes ç‰ˆæœ¬ | `v1.30.2`                      |
| `--pod-network-cidr`       | æŒ‡å®š Pod IP åœ°å€æ®µ   | `10.244.0.0/16`                |
| `--service-cidr`           | Service IP åœ°å€æ®µ    | `10.96.0.0/12`                 |
| `--image-repository`       | å®¹å™¨é•œåƒä»“åº“         | `registry.aliyuncs.com`        |
| `--token-ttl`              | kubeadm token æœ‰æ•ˆæœŸ | `0` è¡¨ç¤ºæ°¸ä¸è¿‡æœŸ               |
| `--upload-certs`           | ä¸Šä¼ æ§åˆ¶å¹³é¢è¯ä¹¦     | **å¯ç”¨è¯ä¹¦å…±äº«**               |
| `--cri-socket`             | å®¹å™¨è¿è¡Œæ—¶æ¥å£ (CRI) | `unix:///run/cri-dockerd.sock` |



å¦‚æœè¿è¡Œå‡ºç°é—®é¢˜ï¼Œéœ€è¦é‡ç½®ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤

``````
kubeadm reset -f
``````



#### å°†å…¶ä»–çš„masterå’Œworkerä¸»æœºåŠ å…¥é›†ç¾¤



æ‰§è¡Œä¸Šè¿°åˆå§‹åŒ–å‘½ä»¤åï¼Œå¾—åˆ°å¦‚ä¸‹ç»“æœ

``````bash
############ è¿™éƒ¨åˆ†æ˜¯æˆæƒkubectlå‘½ä»¤ #######################################################
o start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

############## è¿™éƒ¨åˆ†æ˜¯masterèŠ‚ç‚¹åŠ å…¥é›†ç¾¤çš„å‘½ä»¤###############################

  kubeadm join kubeapi.wang.org:6443 --token jizd9o.tjfoyvdoisbklfi5 \
	--discovery-token-ca-cert-hash sha256:c27e15a7a39394b6d64e419b60df835f9dedb7b015a92c1d9285effa1fbea600 \
	--control-plane --certificate-key 9fa84696a800c6b995a9249972c1dd76735701e5ea2ae05191c9f612a0d1252c --cri-socket=unix:///run/cri-dockerd.sock # åé¢è¿½åŠ  --cri-socket=unix:///run/cri-dockerd.sock

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

############## è¿™éƒ¨åˆ†æ˜¯workerèŠ‚ç‚¹åŠ å…¥é›†ç¾¤çš„å‘½ä»¤###############################

kubeadm join kubeapi.wang.org:6443 --token jizd9o.tjfoyvdoisbklfi5 \
	--discovery-token-ca-cert-hash sha256:c27e15a7a39394b6d64e419b60df835f9dedb7b015a92c1d9285effa1fbea600 --cri-socket=unix:///run/cri-dockerd.sock # åé¢è¿½åŠ  --cri-socket=unix:///run/cri-dockerd.sock
``````



æ ¹æ®ä¸Šè¿°æŒ‡ä»¤åŠ masterä¸»æœºå’Œå…¶ä»–workerä¸»æœºåŠ å…¥é›†ç¾¤



#### å®‰è£…ç½‘ç»œæ’ä»¶flanny

``````bash
wget https://mirror.ghproxy.com/https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

# è¦ç¡®ä¿dockerå¯ä»¥æ‹‰å–é•œåƒï¼Œå»ºè®®å¼€ä»£ç†
kubectl apply -f kube-flannel.yml
``````



#### æŸ¥çœ‹æ˜¯å¦éƒ¨ç½²æˆåŠŸ

``````bash
[root@ubuntu2204 ~]#kubectl get nodes
NAME      STATUS   ROLES           AGE   VERSION
master1   Ready    control-plane   97m   v1.30.8
master2   Ready    control-plane   94m   v1.30.8
master3   Ready    control-plane   93m   v1.30.8
node1     Ready    <none>          92m   v1.30.8
node2     Ready    <none>          92m   v1.30.8
node3     Ready    <none>          92m   v1.30.8

``````



#### å¯ç”¨è‡ªåŠ¨è¡¥å…¨è„šæœ¬







### åŸºäºKubeadmå’ŒContainerdéƒ¨ç½²Kubernetes

éƒ¨ç½²ç¯å¢ƒUbuntu 22.04.X

```bash
root@k8s-master1
root@k8s-node1
root@k8s-node2
```



#### å®‰è£…è¿è¡Œæ—¶

```bash
# æ‰€æœ‰èŠ‚ç‚¹éƒ½éƒ¨ç½²containerdï¼Œruncï¼Œcniï¼Œnerdctlï¼ˆnodeèŠ‚ç‚¹é€‰åšï¼‰
[root@node1 ~]# bash k8s_containerd_runc_cni.sh

# æŸ¥çœ‹è„šæœ¬
#!/bin/bash

PROXY_IP=11.0.1.1
PROXY_PORT=10809
DIR=/usr/local/src

ubuntu_install_containerd() {
	if [ -e k8s_contaierd-2.0.4-runc-1.2.6-buildkit-0.20.2-nerdctl-2.0.4-cni-1.6.2.tar ];then
		echo -e "\e[1;32må®‰è£…åŒ…å·²å­˜åœ¨\e[0m"

        else
	        wget https://www.mysticalrecluse.com/script/tools/k8s_contaierd-2.0.4-runc-1.2.6-buildkit-0.20.2-nerdctl-2.0.4-cni-1.6.2.tar
	fi
	tar xf k8s_contaierd-2.0.4-runc-1.2.6-buildkit-0.20.2-nerdctl-2.0.4-cni-1.6.2.tar -C ${DIR}
	tar xf ${DIR}/containerd-2.0.4-linux-amd64.tar.gz -C /usr/local
	cat >/lib/systemd/system/containerd.service<<EOF
[Unit]
Description=containerd container runtime
Documentation=https://containerd.io
After=network.target local-fs.target dbus.service

[Service]
#uncomment to enable the experimental sbservice (sandboxed) version of containerd/cri integration
#Environment="ENABLE_CRI_SANDBOXES=sandboxed"
Environment="HTTP_PROXY=http://${PROXY_IP}:${PROXY_PORT}"
Environment="HTTPS_PROXY=http://${PROXY_IP}:${PROXY_PORT}"
ExecStartPre=-/sbin/modprobe overlay
ExecStart=/usr/local/bin/containerd

Type=notify
Delegate=yes
KillMode=process
Restart=always
RestartSec=5
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNPROC=infinity
LimitCORE=infinity
LimitNOFILE=infinity
# Comment TasksMax if your systemd version does not supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
OOMScoreAdjust=-999

[Install]
WantedBy=multi-user.target
EOF
    mkdir /etc/containerd -p
	containerd config default > /etc/containerd/config.toml
    systemctl daemon-reload
	systemctl restart containerd.service
	systemctl enable containerd.service
	chmod a+x ${DIR}/runc.amd64
	mv ${DIR}/runc.amd64 /usr/local/bin/runc
	tar xf ${DIR}/nerdctl-2.0.4-linux-amd64.tar.gz  -C /usr/local/bin
	tar xf ${DIR}/buildkit-v0.20.2.linux-amd64.tar.gz -C /usr/local/bin
	mkdir /etc/nerdctl
	cat > /etc/nerdctl/nerdctl.toml <<EOF
namespace    = "k8s.io"
debug        = false
debug_full   = false
insecure_registry = true
address = "/run/containerd/containerd.sock"
EOF
        mkdir /opt/cni/bin -p
	tar xf ${DIR}/cni-plugins-linux-amd64-v1.6.2.tgz -C /opt/cni/bin/
	if echo $? &>/dev/null ;then
	        echo -e "\e[1;32må®‰è£…åŒ…å·²å­˜åœ¨\e[0m"
	else
		echo -e "\e[1;31méƒ¨ç½²å¤±è´¥\e[0m"
	fi
    
}

ubuntu_install_containerd
```



#### éƒ¨ç½² kubeadmã€kubectlã€kubelet

```bash
# Debian/Ubuntu
apt-get update && apt-get install -y apt-transport-https
curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/deb/Release.key |
    gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb/ /" |
    tee /etc/apt/sources.list.d/kubernetes.list
apt-get update
apt-get install -y kubelet kubeadm kubectl

# CentOS / RHEL / Fedora
cat <<EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/repodata/repomd.xml.key
EOF
setenforce 0
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet && systemctl start kubelet
```



#### é…ç½®ä»£ç†

```bash
[root@master1 ~]# vim .bashrc
export http_proxy=http://11.0.1.1:10809
export https_proxy=http://11.0.1.1:10809
export no_proxy="localhost,127.0.0.1,::1,10.0.0.0/8,10.96.0.0/12,10.244.0.0/16,11.0.1.101,11.0.1.102,11.0.1.103,master1.mystical.org,node1.mystical.org,node2.mystical.org,192.168.0.0/16"

[root@master1 ~]# . .bashrc
```





#### ä¸‹è½½ Kubernetes é•œåƒ

æå‰ä¸‹è½½é•œåƒçš„å¥½å¤„ï¼šé˜²æ­¢åˆå§‹åŒ–çš„æ—¶å€™ç”±äºé•œåƒä¸‹è½½è¶…æ—¶è€ŒæŠ¥é”™

```bash
# æŸ¥çœ‹éœ€è¦çš„é•œåƒ
[root@master1 ~]# kubeadm config images list --kubernetes-version v1.32.0
registry.k8s.io/kube-apiserver:v1.32.0
registry.k8s.io/kube-controller-manager:v1.32.0
registry.k8s.io/kube-scheduler:v1.32.0
registry.k8s.io/kube-proxy:v1.32.0
registry.k8s.io/pause:3.9
registry.k8s.io/etcd:3.5.15-0
registry.k8s.io/coredns/coredns:v1.10.1

# ä¸‹è½½
[root@master1 ~]# cat images-down.sh 
#!/bin/bash
#nerdctl pull registry.k8s.io/kube-apiserver:v1.32.0
#nerdctl pull registry.k8s.io/kube-controller-manager:v1.32.0
#nerdctl pull registry.k8s.io/kube-scheduler:v1.32.0
#nerdctl pull registry.k8s.io/kube-proxy:v1.32.0
#nerdctl pull registry.k8s.io/pause:3.9
#nerdctl pull registry.k8s.io/etcd:3.5.15-0
#nerdctl pull registry.k8s.io/coredns/coredns:v1.10.1

nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.32.0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.32.0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.32.0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.32.0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.9
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.15-0
nerdctl pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.10.1
```



#### å†…æ ¸å‚æ•°ä¼˜åŒ–

```bash
[root@master1 ~]# vim /etc/sysctl.conf
net.ipv4.ip_forward=1                     # æ•°æ®åŒ…è·¨ç½‘å¡ä¼ è¾“ï¼Œå¿…é¡»æ‰“å¼€
vm.max_map_count=262144
kernel.pid.max=4194303
fs.file-max=100000
net.ipv4.tcp_max_tw_buckets=6000
net.netfilter.nf_conntrack_max=2097152

net.bridge.bridge-nf-call-ip6tables=1
net.bridge.bridge-nf-call-iptables=1      # å†…æ ¸æ”¯æŒå¯¹ç½‘æ¡¥ä¸Šçš„æŠ¥æ–‡çš„æ£€æŸ¥ï¼Œå¿…é¡»æ‰“å¼€
vm.swappiness=0

[root@node1 ~]# sysctl --load

# å†…æ ¸æ¨¡å—å¼€æœºæŒ‚è½½
[root@master1 ~]# vim /etc/modules-load.d/modules.conf 
ip_vs
ip_vs_ls
ip_vs_lblc
ip_vs_lblcr
ip_vs_rr
ip_vs_wrr
ip_vs_sh
ip_vs_dh
ip_vs_fo
ip_vs_nq
ip_vs_sed
ip_vs_ftp
ip_vs_sh
ip_tables
ip_set
ipt_set
ipt_rpfilter
ipt_REJECT
ipip
xt_set
br_netfilter
nf_conntrack
overlay

# éªŒè¯å†…æ ¸æ¨¡å—ä¸å†…å­˜å‚æ•°
[root@master1 ~]# lsmod|grep br_netfilter

# ä¼˜åŒ–å†…æ ¸èƒ½æ‰“å¼€çš„æœ€å¤§æ–‡ä»¶æ•°ï¼ˆç”Ÿäº§ä¸­ä¸€å®šè¦åšï¼‰
[root@master1 ~]# vim /etc/security/limits.conf
root     soft   core  unlimited
root     hard   core  unlimited
root     soft   nproc  1000000
root     hard   nproc  1000000
root     soft   nofile 1000000
root     hard   nofile 1000000
root     soft   memlock 32000
root     hard   memlock 32000
root     soft   msgqueue 819200
root     hard   msgqueue 819200

# ä¿®æ”¹åé‡å¯
[root@master1 ~]# reboot
```



#### Kubernetes é›†ç¾¤åˆå§‹åŒ–

```bash
# è¿™é‡Œçš„ç‰ˆæœ¬ä¸€å®šè¦å’Œä¸Šé¢çš„kubeadmåŒ¹é…ï¼Œå¦åˆ™å®¹æ˜“æŠ¥é”™
k8s_release_version=1.32.0 && kubeadm init --control-plane-endpoint master1.mystical.org --kubernetes-version=v${k8s_release_version} --pod-network-cidr 192.168.0.0/16 --service-cidr 10.96.0.0/12 --token-ttl=0 --upload-certs

# åˆå§‹åŒ–
  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config
```



#### Kubernetes - åŸºäºinitæ–‡ä»¶åˆå§‹åŒ– - æ¨è

```bash
# kubeadm config print init-defaults # è¾“å‡ºé»˜è®¤åˆå§‹åŒ–é…ç½®
# kubeadm config print init-defaults > kubeadm-init.yaml  # å°†é»˜è®¤é…ç½®è¾“å‡ºè‡³æ–‡ä»¶
# cat kubeadm-init.yaml  # ä¿®æ”¹åçš„åˆå§‹åŒ–æ–‡ä»¶å†…å®¹
[root@master1 ~]# cat kubeadm-init.yaml 
apiVersion: kubeadm.k8s.io/v1beta4
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 11.0.1.101   # è¿™é‡Œæ”¹ä¸ºæŸä¸ªmasterä¸Šçš„IPåœ°å€ï¼Œä¸€èˆ¬ä¸ºå½“å‰masterçš„IPåœ°å€
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock  # è¿™é‡Œé»˜è®¤1.24å¼€å§‹ä½¿ç”¨containerd,è¿™é‡Œæ˜¯containerdçš„                                                                 socketæ–‡ä»¶
  imagePullPolicy: IfNotPresent
  imagePullSerial: true
  name: node
  taints: null
timeouts:
  controlPlaneComponentHealthCheck: 4m0s
  discovery: 5m0s
  etcdAPICall: 2m0s
  kubeletHealthCheck: 4m0s
  kubernetesAPICall: 1m0s
  tlsBootstrap: 5m0s
  upgradeManifests: 5m0s
---
apiServer: 
  timeoutForControlPlane: 4m0s       # è¿™é‡Œæ·»åŠ åˆå§‹åŒ–çš„è¶…æ—¶æ—¶é—´
apiVersion: kubeadm.k8s.io/v1beta4
caCertificateValidityPeriod: 87600h0m0s
certificateValidityPeriod: 8760h0m0s
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: IP:6443        # è‡ªè¡Œæ·»åŠ è¿™è¡Œï¼Œè¿™è¡Œæ˜¯ä¸€èˆ¬æ˜¯è´Ÿè½½å‡è¡¡å™¨çš„VIPç›‘å¬çš„ç«¯å£åœ°å€
                                     # å¦‚æœæ²¡æœ‰ä½¿ç”¨è´Ÿè½½å‡è¡¡å™¨ï¼Œè¿™é‡Œå¯ä»¥åˆ æ‰
controllerManager: {}
dns: {}
encryptionAlgorithm: RSA-2048
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.k8s.io      # é•œåƒä»“åº“ï¼Œå¯ä»¥æ¢æˆå›½å†…ä»“åº“ï¼Œæ¯”å¦‚ï¼š
                                      # registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: 1.32.0             # è¿™é‡Œå¯ä»¥æ¢æˆä½ æƒ³è£…çš„k8sç‰ˆæœ¬
networking:
  dnsDomain: cluster.local
  podSubnet: 10.200.0.0/16            # è‡ªè¡Œåœ¨è¿™é‡Œæ·»åŠ podç½‘ç»œç½‘æ®µï¼Œå’ŒCNIç½‘ç»œæ’ä»¶çš„ç½‘æ®µåœ°å€ä¸€è‡´
  serviceSubnet: 10.96.0.0/12
proxy: {}
scheduler: {}

--- # æŒ‡å®škubeletä½¿ç”¨systemd
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
cgroupDriver: systemd            # è¿™é‡Œè¦å’Œcontainerdçš„cgroupé©±åŠ¨ä¸€è‡´
                                 # å°¤å…¶æ˜¯ubuntu22.04ä¹‹åï¼Œcgroupä½¿ç”¨v2ï¼Œè¿™é‡Œå°±å¿…é¡»å¼ºè¡ŒæŒ‡å®šä¸ºsystemd

--- # æŒ‡å®šKubeproxyä½¿ç”¨ipvs
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs

# ä½¿ç”¨åˆå§‹åŒ–æ–‡ä»¶è¿›è¡Œåˆå§‹åŒ–
[root@master1 ~]# kubeadm init --config kubeadm-init.yaml   # åŸºäºæ–‡ä»¶æ‰§è¡Œk8s masteråˆå§‹åŒ–
```



##### è¡¥å……ï¼škubelet ä¸å®¹å™¨è¿è¡Œæ—¶çš„ cgroup driver è¦ä¸€è‡´

**èƒŒæ™¯ï¼šèµ„æºé™åˆ¶ä¾èµ–çš„ cgroup é©±åŠ¨**

- å®¹å™¨è¿è¡Œæ—¶å¦‚ `Docker`ã€`containerd` éƒ½ä½¿ç”¨ Linux çš„ **cgroup** å®ç°èµ„æºé™åˆ¶ï¼ˆå¦‚ CPUã€å†…å­˜ï¼‰ã€‚
- `cgroup` æœ¬èº«æœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼š**cgroup v1** å’Œ **cgroup v2**ã€‚
- å¯¹äºå¦‚ä½•**ç®¡ç†è¿™äº› cgroup çš„åˆ†å±‚ç»“æ„**ï¼Œå­˜åœ¨ä¸¤ç§ä¸»æµé©±åŠ¨æ–¹å¼ï¼š
  - **`cgroupfs`**ï¼ˆæ—©æœŸ Docker é»˜è®¤ï¼‰
  - **`systemd`**ï¼ˆKubernetes æ¨èï¼‰



**kubelet ä¸å®¹å™¨è¿è¡Œæ—¶çš„ cgroup driver è¦ä¸€è‡´**

 kubelet å’Œå®¹å™¨è¿è¡Œæ—¶ï¼ˆæ— è®ºæ˜¯ docker è¿˜æ˜¯ containerdï¼‰**å¿…é¡»ä½¿ç”¨åŒä¸€ç§ cgroup é©±åŠ¨**ï¼Œå¦åˆ™ pod ä¼šå› ä¸ºèµ„æºæ— æ³•é™åˆ¶æˆ–è¯†åˆ«è€Œè°ƒåº¦å¤±è´¥ã€‚



**æŸ¥çœ‹ containerd çš„ cgroup é©±åŠ¨**

**æŸ¥çœ‹ containerd é…ç½®æ–‡ä»¶**

æ‰“å¼€é…ç½®æ–‡ä»¶ `/etc/containerd/config.toml`ï¼Œæ‰¾åˆ°è¿™ä¸€æ®µï¼š

```toml
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
  SystemdCgroup = true
```

- `SystemdCgroup = true` è¡¨ç¤ºä½¿ç”¨ `systemd` é©±åŠ¨
- `SystemdCgroup = true` æˆ–ä¸å­˜åœ¨è¯¥å­—æ®µï¼Œåˆ™è¡¨ç¤ºä½¿ç”¨ `cgroupfs`



å¦‚æœæ²¡æœ‰è¯¥é…ç½®æ–‡ä»¶ï¼Œå¯è‡ªè¡Œåˆ›å»ºä¿®æ”¹

```bash
containerd config default > /etc/containerd/config.toml
```

ç„¶åç¼–è¾‘ `config.toml`ï¼Œæ‰‹åŠ¨åŠ ä¸Š `SystemdCgroup = true`ï¼š

```toml
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
  SystemdCgroup = true
```

âš ï¸ ä¿®æ”¹åè¯·åŠ¡å¿…é‡å¯ containerdï¼š

```bash
systemctl restart containerd
```



**åŒæ—¶åˆ«å¿˜äº†ç¡®ä¿ kubelet çš„é…ç½®ä¸€è‡´ï¼š**

```yaml
# /var/lib/kubelet/config.yaml
cgroupDriver: systemd
```

ä¹Ÿéœ€è¦é‡å¯ kubeletï¼š

```bash
systemctl restart kubelet
```



#### å°†nodeèŠ‚ç‚¹åŠ å…¥é›†ç¾¤

````bash
kubeadm join master1.mystical.org:6443 --token 75y4xk.fceeqawwqvujq7la \
	--discovery-token-ca-cert-hash sha256:441a979658ef2c8605752dbf7f87d15423963a25ec0099d09aea864e7821c88e
````



#### éƒ¨ç½²ç½‘ç»œæ’ä»¶Calico

```bash
curl https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/calico.yaml -o

# ç¼–è¾‘ä¿®æ”¹calico.yaml
# é€‰ç”¨çš„pod cidråŠå­ç½‘æ©ç é•¿åº¦  
- name: calico_ipv4pool_cidr
  vlaue: "192.168.0.0/16"
  name: calico_ipv4pool_block_size
  values: "24"

# é€‰ç”¨çš„è·¯ç”±æ¨¡å¼ï¼šalways, never, cross-subnet
env:
- name: IP_AUTODETECTION_METHOD   # æŒ‡å®šåŸºäºeth0çš„ç½‘å¡IPå»ºç«‹BGPè¿æ¥ï¼Œé»˜è®¤ä¸ºæœåŠ¡å™¨ç¬¬ä¸€å—
  value: "interface=eth0"
- name: calico_ipv4pool_ipip
  value: "always"
- name: calico_ipv4pool_vxlan
  value: "never"
- name: calico_ipv6pool_vxlan
  value: "never"
```

- æ‰§è¡Œcalicoçš„yaml

```shell
kubectl apply -f calico.yaml

# calicoéœ€è¦å°†.kube/configæ–‡ä»¶æ‹·è´åˆ°æ‰€æœ‰èŠ‚ç‚¹ï¼Œå› ä¸ºcalicoéœ€è¦åšè®¤è¯
scp .kube/config node1:
scp .kube/config node2:

# ä¸‹è½½calicoctl
curl -l https://github.com/projectcalico/calico/releases/download/v3.28.1/calicoctl-linux-amd64 -o calicoctl

# æˆæƒå¹¶åŠ å…¥pathå˜é‡
chmod +x ./calicoctl
mv calicoctl /usr/local/bin

# ä½¿ç”¨calicoctlæŸ¥çœ‹nodeçŠ¶æ€
[root@master1 ~]#calicoctl get node -o wide
name               asn       ipv4            ipv6   
master1.feng.org   (64512)   10.0.0.121/24          
worker1.feng.org   (64512)   10.0.0.122/24          
worker2.feng.org   (64512)   10.0.0.123/24          
worker3.feng.org   (64512)   10.0.0.124/24 
```





### äºŒè¿›åˆ¶éƒ¨ç½²é«˜å¯ç”¨k8sé›†ç¾¤éƒ¨ç½²

- å¤šmasterã€å®ç°masteré«˜å¯ç”¨å’Œé«˜æ€§èƒ½ï¼Œmasteræœ€å°‘ä¸‰ä¸ªï¼Œåˆ†å¸ƒåœ¨ä¸åŒå¯ç”¨åŒº
- å•ç‹¬çš„etcdåˆ†å¸ƒå¼é›†ç¾¤ï¼Œé«˜å¯ç”¨æŒä¹…åŒ–Kubernetesèµ„æºå¯¹è±¡æ•°æ®ï¼Œå¹¶å®ç°é«˜å¯ç”¨
  - etcdåº”è¯¥ä½¿ç”¨é«˜æ€§èƒ½ç¡¬ç›˜ï¼Œæ¯”å¦‚SSD
  - ä¹Ÿå¯ä»¥ä½¿ç”¨4å—10000-15000è½¬çš„SASç›˜åšraid10ï¼Œåœ¨ç»„raidçš„æ—¶å€™ï¼Œå»ºè®®åŒå‚å•†ï¼ŒåŒè§„æ ¼ï¼Œè‡³å°‘è¦ä¿è¯åŒè§„æ ¼
  - etcdæœ€å°‘ä¸‰ä¸ªï¼Œåˆ†å¸ƒåœ¨ä¸åŒå¯ç”¨åŒº
- å¤šnodeèŠ‚ç‚¹è¿è¡Œä¸šåŠ¡podï¼ŒnodeèŠ‚ç‚¹å¯ä»¥æ˜¯ä¸åŒç¡¬ä»¶è§„æ ¼ï¼Œå¦‚CPUèŠ‚ç‚¹ã€MemoryèŠ‚ç‚¹ï¼ŒGPUèŠ‚ç‚¹ï¼ŒBigdataèŠ‚ç‚¹ç­‰
- å„nodeèŠ‚ç‚¹é€šè¿‡è´Ÿè½½å‡è¡¡å™¨ä¸Masterç›¸è¿ï¼Œç”±è´Ÿè½½å‡è¡¡å™¨å®ç°å¯¹masterçš„è½®è¯¢è°ƒç”¨åŠçŠ¶æ€ç›‘æµ‹åŠè·¯éšœè½¬ç§»ï¼Œä»¥åœ¨masterå‡ºç°å®•æœºçš„æ—¶å€™ä¾ç„¶å¯ä»¥ä¿æŒnodeä¸masterçš„é€šä¿¡
  - åŒæ—¶å®ç°nodeèŠ‚ç‚¹ä¸masterèŠ‚ç‚¹ä¹‹é—´çš„è§£è€¦
  - è´Ÿè½½å‡è¡¡å™¨ä¼šè´Ÿè´£å¯¹masterå³åç«¯æœåŠ¡å™¨è¿›è¡Œå‘¨æœŸæ€§å¥åº·æ€§ç›‘æµ‹
- å„èŠ‚ç‚¹å¯å¼¹æ€§ä¼¸ç¼©

| ç±»å‹        | æœåŠ¡å™¨IP   | ä¸»æœºå               | VIP        |
| ----------- | ---------- | -------------------- | ---------- |
| K8S Master1 | 10.0.0.201 | master1.mystical.org | 10.0.0.200 |
| K8S Master2 | 10.0.0.202 | master2.mystical.org | rooroot    |
| K8S Master3 | 10.0.0.203 | master3.mystical.org |            |
| Harbor1     | 10.0.0.204 | harbor1.mystical.org |            |
| Harbor2     | 10.0.0.205 | harbor2.mystical.org |            |
| etcdèŠ‚ç‚¹1   | 10.0.0.206 | etcd1.mystical.org   |            |
| etcdèŠ‚ç‚¹2   | 10.0.0.207 | etcd2.mystical.org   |            |
| etcdèŠ‚ç‚¹3   | 10.0.0.208 | etcd3.mystical.org   |            |
| Haproxy1    | 10.0.0.209 | ha1.mystical.org     |            |
| Haproxy2    | 10.0.0.210 | ha2.mystical.org     |            |
| NodeèŠ‚ç‚¹1   | 10.0.0.211 | node1.mystical.org   |            |
| NodeèŠ‚ç‚¹2   | 10.0.0.212 | node2.mystical.org   |            |
| NodeèŠ‚ç‚¹3   | 100.0.213  | node3.mystical.org   |            |

- k8sé›†ç¾¤èŠ‚ç‚¹çš„ä¸»æœºåä¸€å®šä¸èƒ½ä¸€æ ·ï¼Œå¦åˆ™åæœŸkube-proxyä¼šå‡ºç°å¼‚å¸¸

- machine-idä¹Ÿä¸èƒ½ä¸€æ ·ï¼Œå¦‚æœä¸€æ ·éœ€è¦é‡æ–°ç”Ÿæˆä¸ä¸€æ ·çš„id

  ```bash
  rm -rf /etc/machine-id && dbus-uuidgen --ensure=/etc/machine-id && cat /etc/macheine-id
  ```

- åœ¨k8sé›†ç¾¤è¿™ä¸€å±‚ï¼Œmachine-idä¸€æ ·æ˜¯æ²¡é—®é¢˜çš„ï¼Œé‚£æ˜¯æœ‰äº›æœåŠ¡ä¼šå‡ºé—®é¢˜ï¼Œæ‰€ä»¥å»ºè®®æ‰€ä»¥èŠ‚ç‚¹çš„machine-idä¿®æ”¹ä¸ºä¸ä¸€æ ·çš„

- å‘etcd,zookeeperè¿™ç§æœåŠ¡ï¼Œå¹¶ä¸æ˜¯æœºå™¨è¶Šå¤šï¼Œæ€§èƒ½è¶Šå¼ºï¼Œå› ä¸ºä¼šæœ‰**å†™æ”¾å¤§**ç°è±¡ï¼Œå¦‚æœé›†ç¾¤æ•°é‡è¶Šå¤šï¼Œä¸€ä¸»å¤šå¤‡çš„æƒ…å†µä¸‹ï¼Œå‘ä¸»æ•°æ®åº“å†™å…¥æ•°æ®ï¼Œå®ƒä¼šå‘å…¶ä»–æ‰€æœ‰å¤‡ç”¨æ•°æ®åº“è¿›è¡Œå¤åˆ¶ï¼Œæ‰€ä»¥å¤‡ç”¨æ•°æ®åº“è¶Šå¤šï¼Œä¼šå¯¼è‡´å†™IOè¿‡å¤šï¼Œæ€§èƒ½å˜å·®



#### Linux Kernel å‡çº§ï¼ˆé€‰åšï¼‰

k8s,docker,ciliumç­‰å¾ˆå¤šåŠŸèƒ½ã€**ç‰¹æ€§éœ€è¦è¾ƒæ–°çš„linuxå†…æ ¸æ”¯æŒï¼Œæ‰€ä»¥æœ‰å¿…è¦åœ¨é›†ç¾¤éƒ¨ç½²å‰å¯¹å†…æ ¸è¿›è¡Œå‡çº§**ï¼›CentOS7 å’Œ Ubuntu16.04å¯ä»¥å¾ˆæ–¹ä¾¿çš„å®Œæˆå†…æ ¸å‡çº§ã€‚

##### CentOS7

çº¢å¸½ä¼ä¸šç‰ˆ Linux ä»“åº“ç½‘ç«™ [https://www.elrepo.orgï¼Œä¸»è¦æä¾›å„ç§ç¡¬ä»¶é©±åŠ¨ï¼ˆæ˜¾å¡ã€ç½‘å¡ã€å£°å¡ç­‰ï¼‰å’Œå†…æ ¸å‡çº§ç›¸å…³èµ„æºï¼›å…¼å®¹](https://www.elrepo.xn--org,();-2o3fa1948e1xbtycqzkwdwf25rn5cinbb925a0zdt91bfjp0v1chhnvsmjj7bb70codjwwk02l531a36exp2iil2ag45h/) CentOS7 å†…æ ¸å‡çº§ã€‚å¦‚ä¸‹æŒ‰ç…§ç½‘ç«™æç¤ºè½½å…¥elrepoå…¬é’¥åŠæœ€æ–°elrepoç‰ˆæœ¬ï¼Œç„¶åæŒ‰æ­¥éª¤å‡çº§å†…æ ¸ï¼ˆä»¥å®‰è£…é•¿æœŸæ”¯æŒç‰ˆæœ¬ kernel-lt ä¸ºä¾‹ï¼‰

```bash
# è½½å…¥å…¬é’¥
rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
# å®‰è£…ELRepo
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
# è½½å…¥elrepo-kernelå…ƒæ•°æ®
yum --disablerepo=\* --enablerepo=elrepo-kernel repolist
# æŸ¥çœ‹å¯ç”¨çš„rpmåŒ…
yum --disablerepo=\* --enablerepo=elrepo-kernel list kernel*
# å®‰è£…é•¿æœŸæ”¯æŒç‰ˆæœ¬çš„kernel
yum --disablerepo=\* --enablerepo=elrepo-kernel install -y kernel-lt.x86_64
# åˆ é™¤æ—§ç‰ˆæœ¬å·¥å…·åŒ…
yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64 -y
# å®‰è£…æ–°ç‰ˆæœ¬å·¥å…·åŒ…
yum --disablerepo=\* --enablerepo=elrepo-kernel install -y kernel-lt-tools.x86_64

#æŸ¥çœ‹é»˜è®¤å¯åŠ¨é¡ºåº
awk -F\' '$1=="menuentry " {print $2}' /etc/grub2.cfg  
CentOS Linux (4.4.183-1.el7.elrepo.x86_64) 7 (Core)  
CentOS Linux (3.10.0-327.10.1.el7.x86_64) 7 (Core)  
CentOS Linux (0-rescue-c52097a1078c403da03b8eddeac5080b) 7 (Core)
#é»˜è®¤å¯åŠ¨çš„é¡ºåºæ˜¯ä»0å¼€å§‹ï¼Œæ–°å†…æ ¸æ˜¯ä»å¤´æ’å…¥ï¼ˆç›®å‰ä½ç½®åœ¨0ï¼Œè€Œ4.4.4çš„æ˜¯åœ¨1ï¼‰ï¼Œæ‰€ä»¥éœ€è¦é€‰æ‹©0ã€‚
grub2-set-default 0  
#é‡å¯å¹¶æ£€æŸ¥
reboot
```



##### Ubuntu16.04

```bash
æ‰“å¼€ http://kernel.ubuntu.com/~kernel-ppa/mainline/ å¹¶é€‰æ‹©åˆ—è¡¨ä¸­é€‰æ‹©ä½ éœ€è¦çš„ç‰ˆæœ¬ï¼ˆä»¥4.16.3ä¸ºä¾‹ï¼‰ã€‚
æ¥ä¸‹æ¥ï¼Œæ ¹æ®ä½ çš„ç³»ç»Ÿæ¶æ„ä¸‹è½½ å¦‚ä¸‹.deb æ–‡ä»¶ï¼š
Build for amd64 succeeded (see BUILD.LOG.amd64):
  linux-headers-4.16.3-041603_4.16.3-041603.201804190730_all.deb
  linux-headers-4.16.3-041603-generic_4.16.3-041603.201804190730_amd64.deb
  linux-image-4.16.3-041603-generic_4.16.3-041603.201804190730_amd64.deb
#å®‰è£…åé‡å¯å³å¯
$ sudo dpkg -i *.deb
```



#### éƒ¨ç½² keepalived å’Œ haproxy

##### å®ç° keepalived

```bash
# haproxy1.mystical.org å’Œ haproxy2.mystical.org è¿™ä¸¤ä¸ªæœåŠ¡å™¨ä¸Šéƒ¨ç½²
[root@haproxy1 ~]#apt install -y keepalived haproxy

# ä½¿ç”¨keepalivedé…ç½®vip
[root@haproxy1 ~]#cp  /usr/share/doc/keepalived/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf

[root@haproxy1 ~]#vim /etc/keepalived/keepalived.conf

! Configuration File for keepalived
global_defs {
  notification_email {
    acassen
  }
  notification_email_from Alexandre.Cassen@firewall.loc
  smtp_server 192.168.200.1
  smtp_connect_timeout 30
  router_id ha1.wang.org  #æŒ‡å®šrouter_id,#åœ¨ha2ä¸Šä¸ºha2.wang.org
}
vrrp_script check_haproxy {
   script "/etc/keepalived/check_haproxy.sh"
   interval 1
   weight -30
   fall 3
   rise 2
   timeout 2
}
vrrp_instance VI_1 {
   state MASTER              #åœ¨ha2ä¸Šä¸ºBACKUP        
   interface eth0
   garp_master_delay 10
   smtp_alert
   virtual_router_id 66      #æŒ‡å®šè™šæ‹Ÿè·¯ç”±å™¨ID,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ
   priority 100              #åœ¨ha2ä¸Šä¸º80          
   advert_int 1
   authentication {
       auth_type PASS
       auth_pass 123456      #æŒ‡å®šéªŒè¯å¯†ç ,ha1å’Œha2æ­¤å€¼å¿…é¡»ç›¸åŒ  
   }
   virtual_ipaddress {
        10.0.0.88/24 dev eth0 label eth0:0   # è¿™é‡Œæ˜¯k8s-masterçš„vip
        10.0.0.89/24 dev eth0 label eth0:1   # åç»­æœåŠ¡çš„vipï¼Œç”¨äºæµ‹è¯•k8sä¸­çš„vipèƒ½å¦è®¿é—®
        10.0.0.90/24 dev eth0 label eth0:2   # åç»­æœåŠ¡çš„vipï¼Œç”¨äºæµ‹è¯•k8sä¸­çš„vipèƒ½å¦è®¿é—®
        10.0.0.91/24 dev eth0 label eth0:3   # åç»­æœåŠ¡çš„vipï¼Œç”¨äºæµ‹è¯•k8sä¸­çš„vipèƒ½å¦è®¿é—®

   }
   track_script {
       check_haproxy 
   }
}
 [root@ha1 ~]#cat /etc/keepalived/check_haproxy.sh
 #!/bin/bash
 /usr/bin/killall -0 haproxy  || systemctl restart haproxy
 [root@ha1 ~]#chmod +x /etc/keepalived/check_haproxy.sh
 [root@ha1 ~]#hostname -I
 10.0.0.107 
[root@ha1 ~]#systemctl start keepalived.service 
#éªŒè¯keepalivedæœåŠ¡æ˜¯å¦æ­£å¸¸

# å¯ç”¨å¼€æœºè‡ªå¯
[root@haproxy1 ~]# systemctl enable keepalived
Synchronizing state of keepalived.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable keepalived
```



**å®ç° Haproxy**

é€šè¿‡ Harproxy å®ç° kubernetes Api-serverçš„å››å±‚åå‘ä»£ç†å’Œè´Ÿè½½å‡è¡¡åŠŸèƒ½

``````bash
#åœ¨ä¸¤å°ä¸»æœºha1å’Œha2éƒ½æ‰§è¡Œä¸‹é¢æ“ä½œ
# ä¸‹é¢çš„å†…æ ¸å‚æ•°å¿…é¡»ä¿®æ”¹ï¼Œå› ä¸ºhaproxyé»˜è®¤ä¸èƒ½ç›‘å¬æœ¬æœºæ²¡æœ‰çš„ipï¼ŒåŠ ä¸Šå¼€å¯ä¸‹é¢çš„å†…æ ¸å‚æ•°ï¼Œæ‰èƒ½å…è®¸
[root@ha1 ~]#cat >> /etc/sysctl.conf <<EOF
net.ipv4.ip_nonlocal_bind = 1
EOF
root@ha1 ~]#sysctl -p 

#å®‰è£…é…ç½®haproxy
[root@ha1 ~]#apt -y install haproxy
[root@ha1 ~]#vim /etc/haproxy/haproxy.cfg 
[root@ha1 ~]#cat /etc/haproxy/haproxy.cfg

global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http

##########æ·»åŠ ä»¥ä¸‹å†…å®¹######################

listen stats
    mode http
    bind 0.0.0.0:8888
    stats enable
    log global
    stats uri /status
    stats auth admin:123456

listen  kubernetes-api-6443
    bind 10.0.0.88:6443
    mode tcp 
    server master1 10.0.0.201:6443 check inter 3s fall 3 rise 3 
    server master2 10.0.0.202:6443 check inter 3s fall 3 rise 3 
    server master3 10.0.0.203:6443 check inter 3s fall 3 rise 3 
``````



æµè§ˆå™¨è®¿é—®ï¼š http://ha2.wang.org:8888/status ï¼Œå¯ä»¥çœ‹åˆ°ä¸‹é¢ç•Œé¢



#### éƒ¨ç½²harbor

##### ç”³è¯·è¯ä¹¦ï¼ˆç”Ÿäº§ç¯å¢ƒä¸­ä¸å»ºè®®ä½¿ç”¨è‡ªç­¾è¯ä¹¦ï¼‰

è¦ä½¿ç”¨httpsçš„harborï¼Œå»ºè®®ä½¿ç”¨å•†ä¸šç‰ˆçš„è¯ä¹¦ï¼Œè€Œä¸æ˜¯è‡ªç­¾è¯ä¹¦

åœ¨é˜¿é‡Œäº‘æˆ–è…¾è®¯äº‘ä¹°ä¸ªåŸŸåï¼Œæœ‰å…è´¹è¯ä¹¦é¢åº¦ï¼Œå¯ä»¥ä½¿ç”¨å…è´¹è¯ä¹¦

![image-20250407091828813](../markdown_img/image-20250407091828813.png)

![image-20250407092306507](../markdown_img/image-20250407092306507.png)

![image-20250407092332226](../markdown_img/image-20250407092332226.png)

![image-20250407110939341](../markdown_img/image-20250407110939341.png)

![image-20250407111225625](../markdown_img/image-20250407111225625.png)



##### **æ·»åŠ ä¸€å—æ•°æ®ç›˜ï¼Œç”¨æ¥æ”¾harborçš„é•œåƒ**

```bash
# æŸ¥çœ‹æ–°åŠ ç£ç›˜æ˜¯å¦è¯†åˆ«
[root@harbor1 ~]#fdisk -l
Disk /dev/sdaï¼š200 GiBï¼Œ214748364800 å­—èŠ‚ï¼Œ419430400 ä¸ªæ‰‡åŒº
Disk model: VMware Virtual S
å•å…ƒï¼šæ‰‡åŒº / 1 * 512 = 512 å­—èŠ‚
æ‰‡åŒºå¤§å°(é€»è¾‘/ç‰©ç†)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚
I/O å¤§å°(æœ€å°/æœ€ä½³)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚
ç£ç›˜æ ‡ç­¾ç±»å‹ï¼šgpt
ç£ç›˜æ ‡è¯†ç¬¦ï¼šCD107A96-8A31-4B05-B62C-EA05609760ED

è®¾å¤‡          èµ·ç‚¹      æœ«å°¾      æ‰‡åŒº  å¤§å° ç±»å‹
/dev/sda1     2048      4095      2048    1M BIOS å¯åŠ¨
/dev/sda2     4096   4198399   4194304    2G Linux æ–‡ä»¶ç³»ç»Ÿ
/dev/sda3  4198400 419428351 415229952  198G Linux æ–‡ä»¶ç³»ç»Ÿ


Disk /dev/sdbï¼š500 GiBï¼Œ536870912000 å­—èŠ‚ï¼Œ1048576000 ä¸ªæ‰‡åŒº       # å·²è¯†åˆ«
Disk model: VMware Virtual S
å•å…ƒï¼šæ‰‡åŒº / 1 * 512 = 512 å­—èŠ‚
æ‰‡åŒºå¤§å°(é€»è¾‘/ç‰©ç†)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚
I/O å¤§å°(æœ€å°/æœ€ä½³)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚


Disk /dev/mapper/ubuntu--vg-ubuntu--lvï¼š99 GiBï¼Œ106296246272 å­—èŠ‚ï¼Œ207609856 ä¸ªæ‰‡åŒº
å•å…ƒï¼šæ‰‡åŒº / 1 * 512 = 512 å­—èŠ‚
æ‰‡åŒºå¤§å°(é€»è¾‘/ç‰©ç†)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚
I/O å¤§å°(æœ€å°/æœ€ä½³)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚

# æ ¼å¼åŒ–ç£ç›˜
[root@harbor1 ~]#mkfs.xfs /dev/sdb
meta-data=/dev/sdb               isize=512    agcount=4, agsize=32768000 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=1, rmapbt=0
         =                       reflink=1    bigtime=0 inobtcount=0
data     =                       bsize=4096   blocks=131072000, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
log      =internal log           bsize=4096   blocks=64000, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =æ—                     extsz=4096   blocks=0, rtextents=0

# ç¼–è¾‘ä¸‹/etc/fstab
[root@harbor1 ~]#vim /etc/fstab 
/dev/sdb /data  xfs defaults 0 0    # æ·»åŠ è¿™è¡Œ

[root@harbor1 ~]#mkdir /data
[root@harbor1 ~]#mount -a

# æ£€æŸ¥æ˜¯å¦æˆåŠŸæŒ‚è½½
[root@harbor1 ~]#df -TH
æ–‡ä»¶ç³»ç»Ÿ                          ç±»å‹   å¤§å°  å·²ç”¨  å¯ç”¨ å·²ç”¨% æŒ‚è½½ç‚¹
tmpfs                             tmpfs  407M  1.6M  405M    1% /run
/dev/mapper/ubuntu--vg-ubuntu--lv ext4   105G  9.0G   90G   10% /
tmpfs                             tmpfs  2.1G     0  2.1G    0% /dev/shm
tmpfs                             tmpfs  5.3M     0  5.3M    0% /run/lock
/dev/sda2                         ext4   2.1G  247M  1.7G   13% /boot
tmpfs                             tmpfs  407M     0  407M    0% /run/user/0
/dev/sdb                          xfs    537G  3.8G  533G    1% /data             # æŒ‚è½½æˆåŠŸ
```



##### éƒ¨ç½²harbor

harborä¸‹è½½ç½‘å€

```http
https://github.com/goharbor/harbor/releases   # æ³¨æ„ä¸‹è½½æ­£å¼ç‰ˆï¼Œä¸è¦ä¸‹è½½rcç‰ˆæœ¬
```

```bash
# ä¸‹è½½harbor
[root@harbor1 ~]#wget https://github.com/goharbor/harbor/releases/download/v2.12.2/harbor-offline-installer-v2.12.2.tgz

# éƒ¨ç½²docker
[root@harbor1 harbor]#wget https://www.mysticalrecluse.com/script/Shell/install_docker_offline.sh
[root@harbor1 harbor]#bash install_docker_offline.sh
[root@harbor1 harbor]#source /etc/bash_completion.d/docker_completion

# éƒ¨ç½²docker-compose
[root@harbor1 harbor]# cat ~/docker-compose-repo.sh
# Add Docker's official GPG key:
apt-get update
apt-get install ca-certificates curl
install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
chmod a+r /etc/apt/keyrings/docker.asc

echo "GPG OVER"

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update

[root@harbor1 harbor]# bash ~/docker-compose-repo.sh

# å®˜æ–¹ä»“åº“é…ç½®å¥½åï¼Œæ‰§è¡Œä¸‹é¢çš„æŒ‡ä»¤
[root@ubuntu2204 ~]#apt install -y docker-compose-plugin

# åˆ›å»ºæ”¾ç½®harborçš„ç›®å½•
[root@ubuntu2204 ~]#mkdir /apps
[root@ubuntu2204 ~]#tar xvf harbor-offline-installer-v2.12.2.tgz -C /apps/
harbor/harbor.v2.12.2.tar.gz
harbor/prepare
harbor/LICENSE
harbor/install.sh
harbor/common.sh
harbor/harbor.yml.tmpl

[root@ubuntu2204 harbor]# cd /apps/harbor

# åˆ›å»ºè¯ä¹¦ç›®å½•
[root@harbor1 harbor]#mkdir certs

# å°†ä¸‹è½½nginxæ ¼å¼çš„è¯ä¹¦ä¼ å…¥è¯¥ç›®å½•
[root@harbor1 certs]# ls
harbor.mysticalrecluse.com_nginx.zip

# è§£å‹
[root@harbor1 certs]#unzip harbor.mysticalrecluse.com_nginx.zip 
Archive:  harbor.mysticalrecluse.com_nginx.zip
   creating: harbor.mysticalrecluse.com_nginx/
  inflating: harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com.csr  
  inflating: harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com_bundle.crt  
  inflating: harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com_bundle.pem  
  inflating: harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com.key
[root@harbor1 certs]# cd harbor.mysticalrecluse.com_nginx/
[root@harbor1 harbor.mysticalrecluse.com_nginx]# ls
harbor.mysticalrecluse.com_bundle.crt  harbor.mysticalrecluse.com.csr
harbor.mysticalrecluse.com_bundle.pem  harbor.mysticalrecluse.com.key


[root@ubuntu2204 harbor]#cp harbor.yml.tmpl harbor.yml
[root@ubuntu2204 harbor]#vim harbor.yml
# è¿™é‡Œçš„åŸŸåä¸€å®šå’Œè¯ä¹¦çš„åŸŸåä¸€è‡´
hostname: harbor.mysticalrecluse.com

# http related config
http:
  # port for http, default is 80. If https enabled, this port will redirect to https port
  port: 80

# https related config
https:
  # https port for harbor, default is 443
  port: 443
  # The path of cert and key files for nginx  
  certificate: /apps/harbor/certs/harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com_bundle.pem
  private_key: /apps/harbor/certs/harbor.mysticalrecluse.com_nginx/harbor.mysticalrecluse.com.key
......
# æ›´æ”¹harborçš„å¯†ç 
harbor_admin_password: 646130

......
# è¿™é‡Œå¯ä»¥æ›´æ”¹harborçš„æ•°æ®å­˜æ”¾è·¯å¾„ï¼Œå»ºè®®è¿™é‡ŒæŒ‚ä¸€ä¸ªæ•°æ®ç›˜æ¥ä¿å­˜harborçš„é•œåƒï¼Œå°†æ•°æ®å’Œç³»ç»Ÿåˆ†å¼€ï¼Œç³»ç»ŸæŒ‚äº†ä¸å½±å“æ•°æ®
data_volume: /data

# å¯ç”¨é•œåƒæ¼æ´æ‰«æ
trivy:
  enabled: true

# å¯ç”¨éƒ¨ç½²harbor
[root@harbor1 harbor]#./install.sh 
......
[Step 5]: starting Harbor ...
[+] Running 10/10
 âœ” Network harbor_harbor        Created                                               0.2s 
 âœ” Container harbor-log         Started                                               1.4s 
 âœ” Container redis              Started                                               4.5s 
 âœ” Container registryctl        Started                                               5.2s 
 âœ” Container harbor-db          Started                                               5.2s 
 âœ” Container harbor-portal      Started                                               4.8s 
 âœ” Container registry           Started                                               4.5s 
 âœ” Container harbor-core        Started                                               6.3s 
 âœ” Container harbor-jobservice  Started                                               7.9s 
 âœ” Container nginx              Started                                               8.6s 
âœ” ----Harbor has been installed and started successfully.----

# éƒ¨ç½²æˆåŠŸåï¼Œæµè§ˆå™¨è®¿é—®æµ‹è¯•
https://harbor.mysticalrecluse.com/
```

![image-20250407115822490](../markdown_img/image-20250407115822490.png)

ä¸ºå…¬å¸åˆ›å»ºä¸€ä¸ªé¡¹ç›®ï¼ˆæš‚è®¾ä¸ºå…¬å¼€ï¼Œå¦‚æœè®¾ä¸ºç§æœ‰ï¼Œåé¢éœ€è¦åœ¨k8sä¸­é…ç½®secretï¼‰

![image-20250407120231183](../markdown_img/image-20250407120231183.png)

![image-20250407120248022](../markdown_img/image-20250407120248022.png)



##### nerdctlæµ‹è¯•ç™»å½•harbor

åœ¨harbor2èŠ‚ç‚¹æµ‹è¯•ç™»å½•harboræœåŠ¡å™¨ï¼Œä»¥éªŒè¯æ˜¯å¦èƒ½å¤Ÿç™»å½•harboråŠpushé•œåƒ

```bash
# å®‰è£…éƒ¨ç½²containerdåŠå®¢æˆ·ç«¯nerdctl
[root@harbor2 ~]#wget https://www.mysticalrecluse.com/script/Shell/k8s_containerd_runc_cni.sh
[root@harbor2 ~]#bash k8s_containerd_runc_cni.sh
[root@harbor2 ~]#nerdctl login harbor.mysticalrecluse.com
Enter Username: admin
Enter Password: 
WARN[0004] skipping verifying HTTPS certs for "harbor.mysticalrecluse.com:443" 

WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.
Configure a credential helper to remove this warning. See
https://docs.docker.com/go/credential-store/

Login Succeeded

# æµ‹è¯•ä¸Šä¼ 
[root@harbor2 ~]#nerdctl pull alpine
docker.io/library/alpine:latest:                                                  resolved       |++++++++++++++++++++++++++++++++++++++| 
index-sha256:a8560b36e8b8210634f77d9f7f9efd7ffa463e380b75e2e74aff4511df3ef88c:    done           |++++++++++++++++++++++++++++++++++++++| 
manifest-sha256:1c4eef651f65e2f7daee7ee785882ac164b02b78fb74503052a26dc061c90474: done           |++++++++++++++++++++++++++++++++++++++| 
config-sha256:aded1e1a5b3705116fa0a92ba074a5e0b0031647d9c315983ccba2ee5428ec8b:   done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:f18232174bc91741fdf3da96d85011092101a032a93a388b79e99e69c2d5c870:    done           |++++++++++++++++++++++++++++++++++++++| 
elapsed: 8.5 s                                                                    total:  3.5 Mi (419.7 KiB/s) 

[root@harbor2 ~]#nerdctl tag alpine:latest harbor.mysticalrecluse.com/baseimages/alpine:latest
[root@harbor2 ~]#nerdctl push harbor.mysticalrecluse.com/baseimages/alpine
INFO[0000] pushing as a reduced-platform image (application/vnd.oci.image.index.v1+json, sha256:c5048da63aaf2a23ef85098b8a8dfc0cf571ccfa285812d28b71e21e7d60de7f) 
WARN[0000] skipping verifying HTTPS certs for "harbor.mysticalrecluse.com" 
index-sha256:c5048da63aaf2a23ef85098b8a8dfc0cf571ccfa285812d28b71e21e7d60de7f:    done           |++++++++++++++++++++++++++++++++++++++| 
manifest-sha256:1c4eef651f65e2f7daee7ee785882ac164b02b78fb74503052a26dc061c90474: done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:f18232174bc91741fdf3da96d85011092101a032a93a388b79e99e69c2d5c870:    done           |++++++++++++++++++++++++++++++++++++++| 
config-sha256:aded1e1a5b3705116fa0a92ba074a5e0b0031647d9c315983ccba2ee5428ec8b:   done           |++++++++++++++++++++++++++++++++++++++| 
elapsed: 0.8 s                                                                    total:  3.5 Mi (4.3 MiB/s)

# æŸ¥çœ‹harbor
```

![image-20250407122040531](../markdown_img/image-20250407122040531.png)

```bash
# æµ‹è¯•ä¸‹è½½
[root@harbor2 ~]#nerdctl images
REPOSITORY                                      TAG       IMAGE ID        CREATED          PLATFORM       SIZE       BLOB SIZE
harbor.mysticalrecluse.com/baseimages/alpine    latest    a8560b36e8b8    2 minutes ago    linux/amd64    8.503MB    3.644MB
<none>                                          <none>    a8560b36e8b8    4 minutes ago    linux/amd64    8.503MB    3.644MB
alpine                                          latest    a8560b36e8b8    4 minutes ago    linux/amd64    8.503MB    3.644MB
[root@harbor2 ~]#nerdctl rmi -f a8560b36e8b8
[root@harbor2 ~]#nerdctl pull harbor.mysticalrecluse.com/baseimages/alpine
WARN[0000] skipping verifying HTTPS certs for "harbor.mysticalrecluse.com" 
harbor.mysticalrecluse.com/baseimages/alpine:latest:                              resolved       |++++++++++++++++++++++++++++++++++++++| 
index-sha256:c5048da63aaf2a23ef85098b8a8dfc0cf571ccfa285812d28b71e21e7d60de7f:    done           |++++++++++++++++++++++++++++++++++++++| 
manifest-sha256:1c4eef651f65e2f7daee7ee785882ac164b02b78fb74503052a26dc061c90474: done           |++++++++++++++++++++++++++++++++++++++| 
config-sha256:aded1e1a5b3705116fa0a92ba074a5e0b0031647d9c315983ccba2ee5428ec8b:   done           |++++++++++++++++++++++++++++++++++++++| 
layer-sha256:f18232174bc91741fdf3da96d85011092101a032a93a388b79e99e69c2d5c870:    done           |++++++++++++++++++++++++++++++++++++++| 
elapsed: 1.1 s                                                                    total:  3.5 Mi (3.2 MiB/s) 
```



#### kubeaszéƒ¨ç½²é«˜å¯ç”¨Kubernetes

![image-20250407123739224](D:\git_repository\cyber_security_learning\markdown_img\image-20250407123739224.png)

- ä¸Šè¿°æ¶æ„æœ‰ä¸¤ç±»è´Ÿè½½å‡è¡¡å™¨
  - kube-lbï¼šä½¿ç”¨nignxå®ç°ï¼Œæ‰€æœ‰çš„kubeletå°†è¯·æ±‚å‘ç»™127.0.0.1:6443ï¼Œç„¶åç”±nginxï¼Œåå‘ä»£ç†ç»™å„master
  - external-lbï¼šè¿™é‡Œä½¿ç”¨haproxyï¼Œç”¨äºæ‰¿æ¥kubectlæˆ–è€…dashboardç­‰å¤–éƒ¨è¯·æ±‚ï¼Œç¼“è§£äº†å¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨çš„å‹åŠ›



ä½¿ç”¨ansibleåœ¨éƒ¨ç½²æœåŠ¡å™¨éƒ¨ç½²k8sé›†ç¾¤

```bash
#!/bin/bash

# å¯†é’¥æ‰“é€šè„šæœ¬
IP="
10.0.0.201
10.0.0.202
10.0.0.203
10.0.0.204
10.0.0.205
10.0.0.206
10.0.0.207
10.0.0.208
10.0.0.209
10.0.0.210
10.0.0.211
10.0.0.212
10.0.0.213
"
REMOTE_PORT="22"
REMOTE_USER="root"
REMOTE_PASS="646130"

for REMOTE_HOST in ${IP}; do
  REMOTE_CMD="echo ${REMOTE_HOST} is successfully!"
  # æ·»åŠ ç›®æ ‡è¿œç¨‹ä¸»æœºå…¬é’¥ï¼Œç›¸å½“äºè¾“å…¥yes
  ssh-keyscan -p "${REMOTE_PORT}" "${REMOTE_HOST}" >> ~/.ssh/known_hosts
  
  # é€šè¿‡sshpassé…ç½®å…ç§˜é’¥ç™»å½•ï¼Œå¹¶åˆ›å»ºpython3è½¯é“¾æ¥
  apt install -y sshpass
  sshpass -p "${REMOTE_PASS}" ssh-copy-id "${REMOTE_USER}@${REMOTE_HOST}"
  ssh ${REMOTE_HOST} ln -sv /usr/bin/python3 /usr/bin/python
  echo ${REMOTE_HOST} å…ç§˜é’¥é…ç½®å®Œæˆï¼
done
```



```bash
# éƒ¨ç½²ansibleï¼Œè¿™é‡Œåœ¨haproxy1æœåŠ¡å™¨ä½œä¸ºéƒ¨ç½²æœåŠ¡å™¨
[root@haproxy1 ~]#wget https://www.mysticalrecluse.com/script/Shell/install_ansible.sh
[root@haproxy1 ~]#bash install_ansible.sh

# æ‰€æœ‰èŠ‚ç‚¹æ‰“é€šï¼Œé…ç½®å…å¯†è®¤è¯
# æµ‹è¯•
[root@haproxy1 ansible]#ansible test -m ping
10.0.0.202 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.207 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.201 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.206 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.203 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.208 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.213 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.212 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
10.0.0.211 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}

```



#### ä¸‹è½½kubeaszé¡¹ç›®åŠç»„ä»¶

```bash
# ç°éƒ¨ç½²k8sv1.30
[root@haproxy1 ~]#mkdir 1.30
[root@haproxy1 ~]#cd 1.30/
[root@haproxy1 1.30]#wget https://github.com/easzlab/kubeasz/releases/download/3.6.4/ezdow
[root@haproxy1 1.30]#chmod a+x ezdown
[root@haproxy1 1.30]#./ezdown -D
```



#### ç”Ÿäº§å¹¶è‡ªå®šä¹‰hostsæ–‡ä»¶

```bash
[root@haproxy1 1.30]#cd /etc/kubeasz/
[root@haproxy1 kubeasz]#ls
ansible.cfg  docs  example  ezdown     pics       README.md  tools
bin          down  ezctl    manifests  playbooks  roles

[root@haproxy1 kubeasz]#./ezctl new k8s-cluster1
2025-04-07 15:33:44 DEBUG generate custom cluster files in /etc/kubeasz/clusters/k8s-cluster1
2025-04-07 15:33:44 DEBUG set versions
2025-04-07 15:33:44 DEBUG cluster k8s-cluster1: files successfully created.
2025-04-07 15:33:44 INFO next steps 1: to config '/etc/kubeasz/clusters/k8s-cluster1/hosts'
2025-04-07 15:33:44 INFO next steps 2: to config '/etc/kubeasz/clusters/k8s-cluster1/config.yml'

# config.yamlé’ˆå¯¹Kubernetesçš„å…·ä½“é…ç½®
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/config.yml
......
############################
# role:deploy
############################
# default: ca will expire in 100 years
# default: certs issued by the ca will expire in 50 years
CA_EXPIRY: "876000h"           # è¿™é‡Œé…ç½®è¯ä¹¦æœ‰æ•ˆæœŸ
CERT_EXPIRY: "438000h"

############################
# role:etcd
############################
# è®¾ç½®ä¸åŒçš„walç›®å½•ï¼Œå¯ä»¥é¿å…ç£ç›˜ioç«äº‰ï¼Œæé«˜æ€§èƒ½ï¼Œetcdè¿™é‡Œæœ€å¥½æ˜¯é«˜æ€§èƒ½å›ºæ€ç›˜ï¼Œæ€§èƒ½å¥½ï¼Œetcdéå¸¸æ¶ˆè€—ç£ç›˜IO
ETCD_DATA_DIR: "/var/lib/etcd"
ETCD_WAL_DIR: ""


############################
# role:runtime [containerd,docker]
############################
# [.]å¯ç”¨æ‹‰å–åŠ é€Ÿé•œåƒä»“åº“
ENABLE_MIRROR_REGISTRY: true

# [.]æ·»åŠ ä¿¡ä»»çš„ç§æœ‰ä»“åº“
# å¿…é¡»æŒ‰ç…§å¦‚ä¸‹ç¤ºä¾‹æ ¼å¼ï¼Œåè®®å¤´'http://'å’Œ'https://'ä¸èƒ½çœç•¥
INSECURE_REG:                                               # è¿™é‡Œå¯ä»¥æ”¾æœ¬åœ°è‡ªç­¾åçš„harboråœ°å€ï¼Œè¿›è¡Œä¿¡ä»»
  - "http://easzlab.io.local:5000"
  - "https://reg.yourcompany.com"

# [.]åŸºç¡€å®¹å™¨é•œåƒ
SANDBOX_IMAGE: "easzlab.io.local:5000/easzlab/pause:3.9"     # è¿™é‡Œå¯ä»¥æ¢æˆç§æœ‰ä»“åº“çš„åœ°å€æä¾›pauseå®¹å™¨

# [containerd]å®¹å™¨æŒä¹…åŒ–å­˜å‚¨ç›®å½•
CONTAINERD_STORAGE_DIR: "/var/lib/containerd"                # å®¹å™¨æ•°æ®ç›®å½•å¯ä»¥å•ç‹¬ç»™ä¸€å—é«˜æ€§èƒ½æ•°æ®ç›˜ï¼Œæé«˜å®¹å™¨çš„è¿è¡Œ                                                                é€Ÿåº¦ï¼Œå¦‚æœä½¿ç”¨æœºæ¢°ç›˜ï¼Œé€Ÿåº¦éå¸¸æ…¢

# [docker]å®¹å™¨å­˜å‚¨ç›®å½•
DOCKER_STORAGE_DIR: "/var/lib/docker"

......
############################
# role:kube-master
############################
# k8s é›†ç¾¤ master èŠ‚ç‚¹è¯ä¹¦é…ç½®ï¼Œå¯ä»¥æ·»åŠ å¤šä¸ªipå’ŒåŸŸåï¼ˆæ¯”å¦‚å¢åŠ å…¬ç½‘ipå’ŒåŸŸåï¼‰
MASTER_CERT_HOSTS:
  - "10.0.0.88"                                              # æ‰“ç®—é€šè¿‡å“ªé‡Œè®¿é—®ï¼Œè¿™é‡Œè¯ä¹¦å°±ç­¾å‘ç»™è°ï¼Œæ¯”å¦‚é€šè¿‡è´Ÿè½½å‡è¡¡                                                                å™¨è®¿é—®ï¼Œè¿™ä¸ªåœ°å€å°±æ˜¯ç”¨vip,ä¹Ÿå› æ­¤å…¬æœ‰äº‘ä¸Šçš„å…¬ç½‘ipæ˜¯ä¸                                                                èƒ½éšä¾¿æ¢çš„ï¼Œå¦åˆ™ä¼šå¯¼è‡´è¯ä¹¦å’Œå¯¹åº”çš„ipä¸ä¸€è‡´ï¼Œä¼šå‡ºé—®é¢˜
  - "api.mystical.org"
  #- "www.test.com"

# node èŠ‚ç‚¹ä¸Š pod ç½‘æ®µæ©ç é•¿åº¦ï¼ˆå†³å®šæ¯ä¸ªèŠ‚ç‚¹æœ€å¤šèƒ½åˆ†é…çš„pod ipåœ°å€ï¼‰
# å¦‚æœflannel ä½¿ç”¨ --kube-subnet-mgr å‚æ•°ï¼Œé‚£ä¹ˆå®ƒå°†è¯»å–è¯¥è®¾ç½®ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ†é…podç½‘æ®µ
# https://github.com/coreos/flannel/issues/847
NODE_CIDR_LEN: 24

############################
# role:kube-node
############################
# Kubelet æ ¹ç›®å½•
KUBELET_ROOT_DIR: "/var/lib/kubelet"

# nodeèŠ‚ç‚¹æœ€å¤§pod æ•°
MAX_PODS: 110                                              # å¦‚æœæœåŠ¡å™¨æ€§èƒ½ç‰¹åˆ«å¼ºï¼Œè¿™é‡Œå¯ä»¥æŠŠpodæ•°ä¸Šè°ƒ

############################
# role:cluster-addon
############################
# coredns è‡ªåŠ¨å®‰è£…
dns_install: "no"                                          # è¿™é‡Œæ”¹ä¸ºnoï¼Œå¯ä»¥åé¢è‡ªå·±è£…
corednsVer: "1.11.1"
ENABLE_LOCAL_DNS_CACHE: false                              # trueå¯ç”¨ç¼“å­˜ï¼Œæé«˜æ€§èƒ½
dnsNodeCacheVer: "1.22.28"
# è®¾ç½® local dns cache åœ°å€
LOCAL_DNS_CACHE: "169.254.20.10"

# metric server è‡ªåŠ¨å®‰è£…
metricsserver_install: "no"
metricsVer: "v0.7.1"

# dashboard è‡ªåŠ¨å®‰è£…
dashboard_install: "no"
dashboardVer: "v2.7.0"
dashboardMetricsScraperVer: "v1.0.8"

# prometheus è‡ªåŠ¨å®‰è£…
prom_install: "no"
prom_namespace: "monitor"

```



#### ç¼–è¾‘ansible hostsæ–‡ä»¶

æŒ‡å®šetcdèŠ‚ç‚¹ã€masterèŠ‚ç‚¹ã€nodeèŠ‚ç‚¹ã€VIPã€è¿è¡Œæ—¶ã€ç½‘ç»œç»„ä»¶ç±»å‹ã€Service IPä¸Pod IPèŒƒå›´ç­‰é…ç½®ä¿¡æ¯

```bash
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/hosts
# 'etcd' cluster should have odd member(s) (1,3,5,...)
[etcd]
10.0.0.206
10.0.0.207
10.0.0.208
# master node(s), set unique 'k8s_nodename' for each node
# CAUTION: 'k8s_nodename' must consist of lower case alphanumeric characters, '-' or '.',
# and must start and end with an alphanumeric character
[kube_master]
10.0.0.201 k8s_nodename='master-01'
10.0.0.202 k8s_nodename='master-02'

# work node(s), set unique 'k8s_nodename' for each node
# CAUTION: 'k8s_nodename' must consist of lower case alphanumeric characters, '-' or '.',
# and must start and end with an alphanumeric character
[kube_node]
10.0.0.211 k8s_nodename='worker-01'
10.0.0.212 k8s_nodename='worker-02'
......
# K8S Service CIDR, not overlap with node(host) networking      # ä¸åŒæœºæˆ¿çš„ç½‘æ®µä¸€å®šä¸èƒ½ä¸€æ ·ï¼Œå¦åˆ™ä¼šå¯¼è‡´æ— æ³•é€šä¿¡
SERVICE_CIDR="10.100.0.0/16"

# Cluster CIDR (Pod CIDR), not overlap with node(host) networking
CLUSTER_CIDR="10.200.0.0/16"
......

bin_dir="/user/local/bin"          # äºŒè¿›åˆ¶æ–‡ä»¶æ”¾ç½®è·¯å¾„

......
# Default python interpreter
ansible_python_interpreter=/usr/bin/python3.10
```



#### å¯ç”¨Kubeaszéƒ¨ç½² â€” ç¯å¢ƒåˆå§‹åŒ–

```bash
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 00
Usage: ezctl setup <cluster> <step>
available steps:
    01  prepare            to prepare CA/certs & kubeconfig & other system settings 
    02  etcd               to setup the etcd cluster
    03  container-runtime  to setup the container runtime(docker or containerd)
    04  kube-master        to setup the master nodes
    05  kube-node          to setup the worker nodes
    06  network            to setup the network plugin
    07  cluster-addon      to setup other useful plugins
    90  all                to run 01~07 all at once
    10  ex-lb              to install external loadbalance for accessing k8s from outside
    11  harbor             to install a new harbor server or to integrate with an existed one

examples: ./ezctl setup test-k8s 01  (or ./ezctl setup test-k8s prepare)
	  ./ezctl setup test-k8s 02  (or ./ezctl setup test-k8s etcd)
          ./ezctl setup test-k8s all
          ./ezctl setup test-k8s 04 -t restart_master
          
# å¯ç”¨01,ç¯å¢ƒåˆå§‹åŒ–
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 01
......
PLAY RECAP ********************************************************************************
10.0.0.201                 : ok=28   changed=7    unreachable=0    failed=0    skipped=115  rescued=0    ignored=0   
10.0.0.202                 : ok=25   changed=4    unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.206                 : ok=25   changed=20   unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.207                 : ok=25   changed=4    unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.208                 : ok=25   changed=4    unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.211                 : ok=25   changed=4    unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
10.0.0.212                 : ok=25   changed=20   unreachable=0    failed=0    skipped=111  rescued=0    ignored=0   
localhost                  : ok=31   changed=21   unreachable=0    failed=0    skipped=13   rescued=0    ignored=0 
```



#### éƒ¨ç½²ETCDé›†ç¾¤

```bash
# éƒ¨ç½²etcdé›†ç¾¤,02
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 02
......
PLAY RECAP ********************************************************************************
10.0.0.206                 : ok=10   changed=9    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
10.0.0.207                 : ok=8    changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
10.0.0.208                 : ok=8    changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0 

# å„etcdæœåŠ¡å™¨éªŒè¯etcdæœåŠ¡
[root@haproxy1 kubeasz]# export NODE_IPS="10.0.0.206 10.0.0.207 10.0.0.208"
[root@k8s-10-0-0-206 ~]#for ip in ${NODE_IPS}; do ETCDCTL_API=3 etcdctl --endpoints=https://${ip}:2379 --cacert=/etc/kubernetes/ssl/ca.pem --cert=/etc/kubernetes/ssl/etcd.pem --key=/etc/kubernetes/ssl/etcd-key.pem endpoint health; done
https://10.0.0.206:2379 is healthy: successfully committed proposal: took = 79.772114ms
https://10.0.0.207:2379 is healthy: successfully committed proposal: took = 96.188498ms
https://10.0.0.208:2379 is healthy: successfully committed proposal: took = 92.900676ms

# æŸ¥çœ‹etcd.serviceæ–‡ä»¶
[root@k8s-10-0-0-206 ~]#vim /etc/systemd/system/etcd.service
```



#### éƒ¨ç½²å®¹å™¨è¿è¡Œæ—¶containerd

ç”±è¯ä¹¦ç­¾å‘æœºæ„ç­¾å‘çš„è¯ä¹¦ä¸éœ€è¦æ‰§è¡Œåˆ†å‘æ­¥éª¤ï¼Œè¯ä¹¦å¯è¢«ä¿¡ä»»

```bash
# éªŒè¯åŸºç¡€å®¹å™¨é•œåƒ
[root@haproxy1 kubeasz]#grep SANDBOX_IMAGE ./clusters/* -R
./clusters/k8s-cluster1/config.yml:SANDBOX_IMAGE: "harbor.mysticalrecluse.com/baseimages/pause:3.9â€œ

# å°†pauseå®¹å™¨æ‹‰ä¸‹æ¥åï¼Œä¸Šä¼ è‡³ç§æœ‰harborä»“åº“ï¼Œåç»­çš„pauseå®¹å™¨ä»ç§æœ‰ä»“æ‹‰å–
[root@harbor1 harbor]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.9
[root@harbor1 harbor]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.9 harbor.mysticalrecluse.com/baseimages/pause:3.9
[root@harbor1 harbor]#docker push harbor.mysticalrecluse.com/baseimages/pause:3.9

# é…ç½®åŸºç¡€é•œåƒ
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/config.yml
......
SANDBOX_IMAGE: "harbor.mysticalrecluse.com/baseimages/pause:3.9â€œ
......

# é…ç½®harboré•œåƒä»“åº“åŸŸåè§£æ-å…¬å¸æœ‰DNSæœåŠ¡å™¨è¿›è¡ŒåŸŸåè§£æ
[root@haproxy1 kubeasz]#vim roles/containerd/tasks/main.yml
......
    - name: æ·»åŠ  crictl è‡ªåŠ¨è¡¥å…¨
      lineinfile:
        dest: ~/.bashrc
        state: present
        regexp: 'crictl completion'
        line: 'source <(crictl completion bash) # generated by kubeasz'

    # æ·»åŠ å¦‚ä¸‹ä¸¤è¡Œ
    - name: æ·»åŠ åŸŸåè§£æ
      shell: "echo '10.0.0.204 harbor.mysticalrecluse.com' >> /etc/hosts"

# å¯é€‰è‡ªå®šä¹‰containersé…ç½®æ–‡ä»¶
[root@haproxy1 kubeasz]#vim roles/containerd/templates/config.toml.j2 


# é…ç½®nerdctlå®¢æˆ·ç«¯
[root@haproxy1 ~]#wget https://github.com/containerd/nerdctl/releases/download/v2.0.4/nerdctl-2.0.4-linux-amd64.tar.gz
[root@haproxy1 ~]#tar xvf nerdctl-2.0.4-linux-amd64.tar.gz -C /etc/kubeasz/bin/containerd-bin/
nerdctl
containerd-rootless-setuptool.sh
containerd-rootless.sh

[root@haproxy1 roles]#vim containerd/tasks/main.yml
- block:
    - name: å‡†å¤‡containerdç›¸å…³ç›®å½•
      file: name={{ item }} state=directory
      with_items:
      - "{{ bin_dir }}/containerd-bin"
      - "/etc/containerd"
      - "/etc/nerdctl/"                          # æ·»åŠ è¿™è¡Œï¼Œé…ç½®æ–‡ä»¶ç›®å½•
      
      
    - name: ä¸‹è½½ containerd äºŒè¿›åˆ¶æ–‡ä»¶
      copy: src={{ item }} dest={{ bin_dir }}/containerd-bin/ mode=0755
      with_fileglob:                             # ç”¨æ¥æ‰¹é‡è¯»å–æœ¬åœ°å¤šä¸ªæ–‡ä»¶ï¼Œå¹¶å¾ªç¯å¤„ç†
      - "{{ base_dir }}/bin/containerd-bin/*"
      tags: upgrade

    - name: åˆ›å»º containerd é…ç½®æ–‡ä»¶
      template: src=config.toml.j2 dest=/etc/containerd/config.toml
      tags: upgrade

    # æ·»åŠ ä¸‹é¢ä¸‰è¡Œ
    - name: åˆ›å»º nerdctl é…ç½®æ–‡ä»¶
      template: src=nerdctl.toml.j2 dest=/etc/nerdctl/nerdctl.toml
      tags: upgrade
      
[root@haproxy1 kubeasz]#vim roles/containerd/templates/nerdctl.toml.j2
namespace    = "k8s.io"
debug        = false
debug_full   = false
insecure_registry = true

# å¯ç”¨03 åˆ›å»ºè¿è¡Œæ—¶
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 03
......
PLAY RECAP ********************************************************************************
10.0.0.201                 : ok=15   changed=14   unreachable=0    failed=0    skipped=13   rescued=0    ignored=0   
10.0.0.202                 : ok=15   changed=14   unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
10.0.0.211                 : ok=15   changed=14   unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
10.0.0.212                 : ok=15   changed=14   unreachable=0    failed=0    skipped=10   rescued=0    ignored=0 

# åœ¨master2æµ‹è¯•
[root@master-02 ~]# nerdctl pull nginx
[root@master-02 ~]# nerdctl tag nginx:lastest harbor.mysticalrecluse.com/myserver/nginx:v1
[root@master-02 ~]# nerdctl login harbor.mysticalrecluse.com
[root@master-02 ~]# nerdctl push harbor.mysticalrecluse.com/myserver/nginx:v1

# åœ¨node1æµ‹è¯•æ˜¯å¦èƒ½æ‹‰ç§æœ‰ä»“çš„é•œåƒ
[root@worker-01 ~]#nerdctl pull harbor.mysticalrecluse.com/myserver/nginx:v1
```



#### éƒ¨ç½² Kubernetes master èŠ‚ç‚¹

å¯é€‰æ›´æ”¹å¯åŠ¨è„šæœ¬å‚æ•°ä»¥åŠè·¯å¾„ç­‰è‡ªå®šä¹‰åŠŸèƒ½

```bash
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 04

# é»˜è®¤æƒ…å†µä¸‹ï¼Œåªåœ¨éƒ¨ç½²èŠ‚ç‚¹æœ‰kubeconfigæ–‡ä»¶
[root@haproxy1 kubeasz]#kubectl get nodes
NAME        STATUS                     ROLES    AGE    VERSION
master-01   Ready,SchedulingDisabled   master   8m8s   v1.30.1
master-02   Ready,SchedulingDisabled   master   8m8s   v1.30.1
```



#### éƒ¨ç½² Kubernetes Node èŠ‚ç‚¹

```bash
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 05
......
PLAY RECAP ********************************************************************************
10.0.0.211                 : ok=38   changed=36   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
10.0.0.212                 : ok=38   changed=36   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0

# åœ¨éƒ¨ç½²èŠ‚ç‚¹æŸ¥çœ‹
[root@haproxy1 kubeasz]#kubectl get nodes
NAME        STATUS                     ROLES    AGE    VERSION
master-01   Ready,SchedulingDisabled   master   8m8s   v1.30.1
master-02   Ready,SchedulingDisabled   master   8m8s   v1.30.1
worker-01   Ready                      node     32s    v1.30.1
worker-02   Ready                      node     33s    v1.30.1

```



#### éƒ¨ç½²ç½‘ç»œæœåŠ¡calico

å¯é€‰æ›´æ”¹calicoçš„é•œåƒåœ°å€åŠå„ç§é…ç½®ä¿¡æ¯

```bash
[root@haproxy1 kubeasz]# vim clusters/k8s-cluster1/config.yml
# ------------------------------------------- calico
# [calico] IPIPéš§é“æ¨¡å¼å¯é€‰é¡¹æœ‰: [Always, CrossSubnet, Never],è·¨å­ç½‘å¯ä»¥é…ç½®ä¸ºAlwaysä¸CrossSubnet(å…¬æœ‰äº‘å»ºè®®ä½¿ç”¨alwaysæ¯”è¾ƒçœäº‹ï¼Œå…¶ä»–çš„è¯éœ€è¦ä¿®æ”¹å„è‡ªå…¬æœ‰äº‘çš„ç½‘ç»œé…ç½®ï¼Œå…·ä½“å¯ä»¥å‚è€ƒå„ä¸ª
å…¬æœ‰äº‘è¯´æ˜)
# å…¶æ¬¡CrossSubnetä¸ºéš§é“+BGPè·¯ç”±æ··åˆæ¨¡å¼å¯ä»¥æå‡ç½‘ç»œæ€§èƒ½ï¼ŒåŒå­ç½‘é…ç½®ä¸ºNeverå³å¯.
CALICO_IPV4POOL_IPIP: "Always"

# [calico]è®¾ç½® calico-nodeä½¿ç”¨çš„host IPï¼Œbgpé‚»å±…é€šè¿‡è¯¥åœ°å€å»ºç«‹ï¼Œå¯æ‰‹å·¥æŒ‡å®šä¹Ÿå¯ä»¥è‡ªåŠ¨å‘ç°
IP_AUTODETECTION_METHOD: "can-reach={{ groups['kube_master'][0] }}"

# [calico]è®¾ç½®calico ç½‘ç»œ backend: bird, vxlan, none
CALICO_NETWORKING_BACKEND: "bird"

# [calico]è®¾ç½®calico æ˜¯å¦ä½¿ç”¨route reflectors
# å¦‚æœé›†ç¾¤è§„æ¨¡è¶…è¿‡50ä¸ªèŠ‚ç‚¹ï¼Œå»ºè®®å¯ç”¨è¯¥ç‰¹æ€§
CALICO_RR_ENABLED: false

# CALICO_RR_NODES é…ç½®route reflectorsçš„èŠ‚ç‚¹ï¼Œå¦‚æœæœªè®¾ç½®é»˜è®¤ä½¿ç”¨é›†ç¾¤masterèŠ‚ç‚¹ 
# CALICO_RR_NODES: ["192.168.1.1", "192.168.1.2"]
CALICO_RR_NODES: []

# [calico]æ›´æ–°æ”¯æŒcalico ç‰ˆæœ¬: ["3.19", "3.23"]
calico_ver: "v3.26.4"

# [calico]calico ä¸»ç‰ˆæœ¬
calico_ver_main: "{{ calico_ver.split('.')[0] }}.{{ calico_ver.split('.')[1] }}"


# æŸ¥çœ‹éƒ¨ç½²èŠ‚ç‚¹é•œåƒ
[root@haproxy1 kubeasz]#docker images
REPOSITORY                                           TAG       IMAGE ID       CREATED         SIZE
easzlab/kubeasz                                      3.6.4     1108a8be8fcc   9 months ago    157MB
easzlab/kubeasz-ext-bin                              1.10.1    fb29543bf6ab   10 months ago   722MB
easzlab/kubeasz-k8s-bin                              v1.30.1   41c3580883c5   10 months ago   1.2GB
easzlab/metrics-server                               v0.7.1    2c06895dd9cd   12 months ago   66.9MB
easzlab.io.local:5000/easzlab/metrics-server         v0.7.1    2c06895dd9cd   12 months ago   66.9MB
calico/kube-controllers                              v3.26.4   b32f99198153   16 months ago   74.7MB
easzlab.io.local:5000/calico/kube-controllers        v3.26.4   b32f99198153   16 months ago   74.7MB
easzlab.io.local:5000/calico/cni                     v3.26.4   17d35f5bad38   16 months ago   209MB
calico/cni                                           v3.26.4   17d35f5bad38   16 months ago   209MB
calico/node                                          v3.26.4   ded66453eb63   16 months ago   252MB
easzlab.io.local:5000/calico/node                    v3.26.4   ded66453eb63   16 months ago   252MB
easzlab/k8s-dns-node-cache                           1.22.28   c0120d8e4c91   17 months ago   77.5MB
easzlab.io.local:5000/easzlab/k8s-dns-node-cache     1.22.28   c0120d8e4c91   17 months ago   77.5MB
registry                                             2         26b2eb03618e   18 months ago   25.4MB
coredns/coredns                                      1.11.1    cbb01a7bd410   20 months ago   59.8MB
easzlab.io.local:5000/coredns/coredns                1.11.1    cbb01a7bd410   20 months ago   59.8MB
easzlab/pause                                        3.9       78d53e70b442   2 years ago     744kB
easzlab.io.local:5000/easzlab/pause                  3.9       78d53e70b442   2 years ago     744kB
kubernetesui/dashboard                               v2.7.0    07655ddf2eeb   2 years ago     246MB
easzlab.io.local:5000/kubernetesui/dashboard         v2.7.0    07655ddf2eeb   2 years ago     246MB
kubernetesui/metrics-scraper                         v1.0.8    115053965e86   2 years ago     43.8MB
easzlab.io.local:5000/kubernetesui/metrics-scraper   v1.0.8    115053965e86   2 years ago     43.8MB

# æŸ¥çœ‹ansibleæ–‡ä»¶ï¼Œå¼•ç”¨çš„é•œåƒ
[root@haproxy1 kubeasz]#grep "image:" roles/calico/templates/calico-v3.26.yaml.j2 
          image: easzlab.io.local:5000/calico/cni:{{ calico_ver }}
          image: easzlab.io.local:5000/calico/node:{{ calico_ver }} 
          image: easzlab.io.local:5000/calico/node:{{ calico_ver }}
          image: easzlab.io.local:5000/calico/kube-controllers:{{ calico_ver }}
          
# æŸ¥çœ‹/kubeasz/clusters/k8s-cluster1/config.yml
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/config.yml
......
# [calico]æ›´æ–°æ”¯æŒcalico ç‰ˆæœ¬: ["3.19", "3.23"]
calico_ver: "v3.26.4

# å°†calicoç›¸å…³é•œåƒä¸Šä¼ åˆ°ç§æœ‰ä»“åº“
[root@haproxy1 kubeasz]# docker login harbor.mysticalrecluse.com
Username: admin
Password: 
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded

[root@haproxy1 ~]# docker tag easzlab.io.local:5000/calico/cni:v3.26.4 harbor.mysticalrecluse.com/baseimages/calico-cni:v3.26.4
[root@haproxy1 ~]# docker push harbor.mysticalrecluse.com/baseimages/calico-cni:v3.26.4
[root@haproxy1 ~]#docker tag easzlab.io.local:5000/calico/node:v3.26.4 harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
[root@haproxy1 ~]#docker push harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
[root@haproxy1 ~]#docker tag easzlab.io.local:5000/calico/kube-controllers:v3.26.4 harbor.mysticalrecluse.com/baseimages/calico-kube-controllers:v3.26.4
[root@haproxy1 ~]#docker push harbor.mysticalrecluse.com/baseimages/calico-kube-controllers:v3.26.4

# æ›´æ”¹é…ç½®æ–‡ä»¶
[root@haproxy1 kubeasz]#vim roles/calico/templates/calico-v3.26.yaml.j2
......
initContainers:
        # This container installs the CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          #image: easzlab.io.local:5000/calico/cni:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-cni:v3.26.4
          imagePullPolicy: IfNotPresent
          command: ["/opt/cni/bin/install"]
          envFrom:
          - configMapRef:
              # Allow KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT to be overridden for eBPF mode.
......
        # in best effort fashion, i.e. no failure for errors, to not disrupt pod creation in iptable mode.
        - name: "mount-bpffs"
          # image: easzlab.io.local:5000/calico/node:{{ calico_ver }} 
          image: harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
          imagePullPolicy: IfNotPresent
          command: ["calico-node", "-init", "-best-effort"]
          volumeMounts:
            - mountPath: /sys/fs
              name: sys-fs
......
      containers:
        # Runs calico-node container on each Kubernetes node. This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          # image: easzlab.io.local:5000/calico/node:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
          imagePullPolicy: IfNotPresent
          envFrom:
          - configMapRef:
              # Allow KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT to be overridden for eBPF mode.
              name: kubernetes-services-endpoint
              optional: true
......
      containers:
        - name: calico-kube-controllers
          # image: easzlab.io.local:5000/calico/kube-controllers:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-kube-controllers:v3.26.4
          imagePullPolicy: IfNotPresent
          env:
            # The location of the etcd cluster.
            - name: ETCD_ENDPOINTS
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_endpoints
                  
# æ£€æŸ¥æµ‹è¯•
[root@haproxy1 kubeasz]#grep "image:" roles/calico/templates/calico-v3.26.yaml.j2
          # image: easzlab.io.local:5000/calico/cni:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-cni:v3.26.4
          # image: easzlab.io.local:5000/calico/node:{{ calico_ver }} 
          image: harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
          # image: easzlab.io.local:5000/calico/node:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-node:v3.26.4
          # image: easzlab.io.local:5000/calico/kube-controllers:{{ calico_ver }}
          image: harbor.mysticalrecluse.com/baseimages/calico-kube-controllers:v3.26.4

# httpsé•œåƒä»“åº“é…ç½®ä¸‹è½½è®¤è¯

# å¯ç”¨
[root@haproxy1 kubeasz]#./ezctl setup k8s-cluster1 06
......
PLAY RECAP ********************************************************************************
10.0.0.201                 : ok=13   changed=12   unreachable=0    failed=0    skipped=36   rescued=0    ignored=0   
10.0.0.202                 : ok=7    changed=6    unreachable=0    failed=0    skipped=13   rescued=0    ignored=0   
10.0.0.211                 : ok=7    changed=6    unreachable=0    failed=0    skipped=13   rescued=0    ignored=0   
10.0.0.212                 : ok=7    changed=6    unreachable=0    failed=0    skipped=13   rescued=0    ignored=0 

# åœ¨masterèŠ‚ç‚¹æµ‹è¯•
[root@master-01 ~]#calicoctl node status
Calico process is running.

IPv4 BGP status
+--------------+-------------------+-------+----------+-------------+
| PEER ADDRESS |     PEER TYPE     | STATE |  SINCE   |    INFO     |
+--------------+-------------------+-------+----------+-------------+
| 10.0.0.212   | node-to-node mesh | up    | 02:43:28 | Established |
| 10.0.0.211   | node-to-node mesh | up    | 02:43:41 | Established |
| 10.0.0.202   | node-to-node mesh | up    | 02:43:50 | Established |
+--------------+-------------------+-------+----------+-------------+

IPv6 BGP status
No IPv6 peers found.

# å°†éƒ¨ç½²èŠ‚ç‚¹çš„configæ–‡ä»¶å¤åˆ¶åˆ°masterèŠ‚ç‚¹
[root@haproxy1 kubeasz]#scp /root/.kube/config master1:/root/.kube/
config                                                   100% 6194     2.8MB/s   00:00 

# åœ¨workerçš„contianerd.serviceé…ç½®ä»£ç†ï¼Œæ³¨æ„ï¼šè¿™é‡Œè¿›ä½œç”¨äºcontainerdï¼Œå¯¹å®¿ä¸»æœºæ— æ•ˆ
# åŒæ—¶åœ¨å®¿ä¸»æœºé…ç½®çš„ä»£ç†ï¼Œä»…ä½œç”¨äºå®¿ä¸»æœºï¼Œå¯¹containerdæ— æ•ˆï¼Œè€Œk8sä¸­æ˜¯kubeletè°ƒç”¨containerdè¿›è¡Œé•œåƒæ‹‰å–
[root@worker-02 ~]#vim /etc/systemd/system/containerd.service
[Service]
Environment="HTTP_PROXY=http://your.proxy:port"
Environment="HTTPS_PROXY=http://your.proxy:port"
Environment="NO_PROXY=127.0.0.1,localhost,::1,10.0.0.0/8,10.244.0.0/16,10.96.0.0/12"
```



#### éªŒè¯Podé€šä¿¡

```bash
[root@master-01 ~]#kubectl run net-test1 --image=centos:7.9.2009 sleep 10000000
[root@master-01 ~]#kubectl run net-test2 --image=centos:7.9.2009 sleep 10000000
[root@master-01 ~]#kubectl get pod
NAME        READY   STATUS    RESTARTS   AGE
net-test1   1/1     Running   0          11m
net-test2   1/1     Running   0          23m

# æµ‹è¯•ï¼Œè®¿é—®å¤–ç½‘ip
[root@master-01 ~]#kubectl exec net-test1 -- ping 223.6.6.6
PING 223.6.6.6 (223.6.6.6) 56(84) bytes of data.
64 bytes from 223.6.6.6: icmp_seq=1 ttl=127 time=6.32 ms
64 bytes from 223.6.6.6: icmp_seq=2 ttl=127 time=5.81 ms

# æµ‹è¯•ï¼Œè®¿é—®net-test2
[root@master-01 ~]#kubectl exec net-test1 -- ping 10.200.171.2
```



### é›†ç¾¤èŠ‚ç‚¹ä¼¸ç¼©ç®¡ç†

é›†ç¾¤ç®¡ç†ä¸»è¦æ˜¯æ·»åŠ masterã€æ·»åŠ nodeã€åˆ é™¤masterä¸åˆ é™¤nodeç­‰èŠ‚ç‚¹ç®¡ç†åŠç›‘æ§

```bash
# å½“å‰é›†ç¾¤çŠ¶æ€
[root@master-01 ~]#kubectl get nodes
NAME        STATUS                     ROLES    AGE    VERSION
master-01   Ready,SchedulingDisabled   master   128m   v1.30.1
master-02   Ready,SchedulingDisabled   master   128m   v1.30.1
worker-01   Ready                      node     120m   v1.30.1
worker-02   Ready                      node     120m   v1.30.1

[root@haproxy1 kubeasz]#./ezctl --help
Usage: ezctl COMMAND [args]
-------------------------------------------------------------------------------------
Cluster setups:
    list		             to list all of the managed clusters
    checkout    <cluster>            to switch default kubeconfig of the cluster
    new         <cluster>            to start a new k8s deploy with name 'cluster'
    setup       <cluster>  <step>    to setup a cluster, also supporting a step-by-step way
    start       <cluster>            to start all of the k8s services stopped by 'ezctl stop'
    stop        <cluster>            to stop all of the k8s services temporarily
    upgrade     <cluster>            to upgrade the k8s cluster
    destroy     <cluster>            to destroy the k8s cluster
    backup      <cluster>            to backup the cluster state (etcd snapshot)
    restore     <cluster>            to restore the cluster state from backups
    start-aio		             to quickly setup an all-in-one cluster with default settings

Cluster ops:
    add-etcd    <cluster>  <ip>      to add a etcd-node to the etcd cluster
    add-master  <cluster>  <ip>      to add a master node to the k8s cluster
    add-node    <cluster>  <ip>      to add a work node to the k8s cluster
    del-etcd    <cluster>  <ip>      to delete a etcd-node from the etcd cluster
    del-master  <cluster>  <ip>      to delete a master node from the k8s cluster
    del-node    <cluster>  <ip>      to delete a work node from the k8s cluster

Extra operation:
    kca-renew   <cluster>            to force renew CA certs and all the other certs (with caution)
    kcfg-adm    <cluster>  <args>    to manage client kubeconfig of the k8s cluster

Use "ezctl help <command>" for more information about a given command.

```



#### æ·»åŠ NodeèŠ‚ç‚¹

```bash
# 1. æ‰“é€šæ–°åŠ å…¥çš„NodeèŠ‚ç‚¹å’Œé›†ç¾¤å†…å…¶ä»–èŠ‚ç‚¹çš„ssh

# 2. åœ¨é›†ç¾¤éƒ¨ç½²æœåŠ¡å™¨ï¼Œå³kubeaszæ‰€åœ¨æœåŠ¡å™¨ï¼Œæ¯”å¦‚æ–°åŠ å…¥nodeçš„ipæ˜¯10.0.0.213
[root@haproxy1 kubeasz]#./ezctl add-node k8s-cluster1 10.0.0.213

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE    VERSION
k8s-10-0-0-213   Ready                      node     54s    v1.30.1
master-01        Ready,SchedulingDisabled   master   144m   v1.30.1
master-02        Ready,SchedulingDisabled   master   144m   v1.30.1
worker-01        Ready                      node     137m   v1.30.1
worker-02        Ready                      node     137m   v1.30.1
```



#### æ·»åŠ masterèŠ‚ç‚¹

```bash
# 1. æ‰“é€šæ–°åŠ å…¥çš„masterèŠ‚ç‚¹å’Œé›†ç¾¤å†…å…¶ä»–èŠ‚ç‚¹çš„ssh

# 2. åœ¨é›†ç¾¤éƒ¨ç½²æœåŠ¡å™¨ï¼Œå³kubeaszæ‰€åœ¨æœåŠ¡å™¨ï¼Œæ¯”å¦‚æ–°åŠ å…¥masterçš„ipæ˜¯10.0.0.203
[root@haproxy1 kubeasz]#./ezctl add-master k8s-cluster1 10.0.0.203

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   2m36s   v1.30.1
k8s-10-0-0-213   Ready                      node     19m     v1.30.1
master-01        Ready,SchedulingDisabled   master   163m    v1.30.1
master-02        Ready,SchedulingDisabled   master   163m    v1.30.1
worker-01        Ready                      node     155m    v1.30.1
worker-02        Ready                      node     155m    v1.30.1
```



#### åˆ é™¤nodeèŠ‚ç‚¹

```bash
# æœ¬è´¨ä¸Šæ˜¯å¿½ç•¥daemonset,å¼ºåˆ¶drainé©±é€nodeä¸Šçš„podï¼Œå†è¸¢å‡ºnodeèŠ‚ç‚¹
# --delete-local-data --ignore-daemonsets --force
# --delete-emptydir-data --ignore-daemonsets --force

# æ³¨æ„ï¼ï¼ï¼ï¼Œè¯¥æ“ä½œä¸å»ºè®®åœ¨ä¸šåŠ¡é«˜å³°æœŸæ‰§è¡Œ

# æ‰§è¡Œåˆ é™¤æŒ‡å®šèŠ‚ç‚¹
[root@haproxy1 kubeasz]#./ezctl del-node k8s-cluster1 10.0.0.213

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE    VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   10m    v1.30.1
master-01        Ready,SchedulingDisabled   master   170m   v1.30.1
master-02        Ready,SchedulingDisabled   master   170m   v1.30.1
worker-01        Ready                      node     163m   v1.30.1
worker-02        Ready                      node     163m   v1.30.1

# åˆ é™¤åï¼Œé‡å¯è¢«åˆ é™¤çš„nodeèŠ‚ç‚¹ï¼Œä»¥æ¸…ç†ç¼“å­˜ä¿¡æ¯
# ä½†æ˜¯ï¼ï¼ï¼ï¼Œæ­¤æ—¶å¯èƒ½ä¼šå‡ºç°ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åˆ é™¤çš„èŠ‚ç‚¹ï¼Œæ— æ³•ç›´æ¥å†åŠ å…¥é›†ç¾¤ï¼ŒåŸå› æ˜¯hostsæ–‡ä»¶å†…çš„è¯¥ä¸»æœºåæ²¡æœ‰è¢«åˆ é™¤ï¼Œåˆ é™¤åé‡æ–°æ·»åŠ å°±å¯ä»¥äº†
[root@haproxy1 kubeasz]#vim clusters/k8s-cluster1/hosts
[kube_node]
10.0.0.211 k8s_nodename='worker-01'
10.0.0.212 k8s_nodename='worker-02'
# ï¼Ÿï¼Ÿï¼Ÿ åŸ10.0.0.213ï¼Œå¦‚æœè¿™é‡Œæ²¡æœ‰ä»ç„¶åç—•è¿¹ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ— æ³•åŠ å…¥é›†ç¾¤

# å°†10.0.0.213å†æ¬¡åŠ å…¥é›†ç¾¤
[root@haproxy1 kubeasz]#./ezctl add-node k8s-cluster1 10.0.0.213

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   36m     v1.30.1
k8s-10-0-0-213   Ready                      node     17m     v1.30.1
master-01        Ready,SchedulingDisabled   master   3h17m   v1.30.1
master-02        Ready,SchedulingDisabled   master   3h17m   v1.30.1
worker-01        Ready                      node     3h10m   v1.30.1
worker-02        Ready                      node     3h10m   v1.30.1
```



### å‡çº§é›†ç¾¤

å¯¹å½“å‰ Kubernetes é›†ç¾¤è¿›è¡Œç‰ˆæœ¬æ›´æ–°ï¼Œè§£å†³å·²çŸ¥ Bug æˆ–æ–°å¢æŸäº›åŠŸèƒ½

å‡çº§çš„ä¸»è¦è¡Œä¸ºæ˜¯æ›¿æ¢äºŒè¿›åˆ¶

å¦‚æœè·¨å°ç‰ˆæœ¬å‡çº§ï¼Œæ¯”å¦‚1.26.0å‡çº§åˆ°1.26.4ï¼Œé€šå¸¸æ²¡æœ‰é—®é¢˜ï¼Œå¦‚æœæ˜¯è·¨å¤§ç‰ˆæœ¬å‡çº§ï¼Œæ¯”å¦‚1.26å‡çº§åˆ°1.27ï¼Œéœ€è¦çœ‹å®˜æ–¹çš„å…¼å®¹æ€§ï¼Œå¯èƒ½ä¼šå‡ºé—®é¢˜ï¼Œæ¯”å¦‚å¤§ç‰ˆæœ¬å‡çº§åï¼Œæºç‰ˆæœ¬çš„å‚æ•°å¯èƒ½åœ¨æ–°ç‰ˆæœ¬ä¸æ”¯æŒ

```bash
[root@master-01 src]#kubectl api-resources 
NAME                                SHORTNAMES   APIVERSION                        NAMESPACED   KIND
bindings                                         v1                                true         Binding
componentstatuses                   cs           v1                                false        ComponentStatus
configmaps                          cm           v1                                true         ConfigMap
endpoints                           ep           v1                                true         Endpoints
events                              ev           v1                                true         Event
limitranges                         limits       v1                                true         LimitRange
namespaces                          ns           v1                                false        Namespace
nodes                               no           v1                                false        Node
persistentvolumeclaims              pvc          v1                                true         PersistentVolumeClaim
persistentvolumes                   pv           v1                                false        PersistentVolume
pods                                po           v1                                true         Pod
podtemplates                                     v1                                true         PodTemplate
replicationcontrollers              rc           v1                                true         ReplicationController
resourcequotas                      quota        v1                                true         ResourceQuota
secrets                                          v1                                true         Secret
serviceaccounts                     sa           v1                                true         ServiceAccount
services                            svc          v1                                true         Service
mutatingwebhookconfigurations                    admissionregistration.k8s.io/v1   false        MutatingWebhookConfiguration
validatingadmissionpolicies                      admissionregistration.k8s.io/v1   false        ValidatingAdmissionPolicy
validatingadmissionpolicybindings                admissionregistration.k8s.io/v1   false        ValidatingAdmissionPolicyBinding
validatingwebhookconfigurations                  admissionregistration.k8s.io/v1   false        ValidatingWebhookConfiguration
customresourcedefinitions           crd,crds     apiextensions.k8s.io/v1           false        CustomResourceDefinition
apiservices                                      apiregistration.k8s.io/v1         false        APIService
controllerrevisions                              apps/v1                           true         ControllerRevision
daemonsets                          ds           apps/v1                           true         DaemonSet
deployments                         deploy       apps/v1                           true         Deployment
replicasets                         rs           apps/v1                           true         ReplicaSet
statefulsets                        sts          apps/v1                           true         StatefulSet
......

# å¦‚æœå‡çº§åï¼Œæ¯”å¦‚Statefulsetçš„apiVersionä»apps/v1å˜ä¸ºv1ï¼Œé‚£ä¹ˆå‡çº§åï¼Œæºk8sé›†ç¾¤çš„Statefulsæ— æ³•ä½¿ç”¨ï¼Œæ‰€ä»¥æ‰€æœ‰çš„Statefulséƒ½éœ€è¦é‡æ–°åˆ›å»ºï¼Œå› æ­¤è·¨å¤§ç‰ˆæœ¬å‡çº§ï¼Œæœ€å¥½åœ¨æµ‹è¯•ç¯å¢ƒåšå¥½è¶³å¤Ÿçš„æµ‹è¯•å†å‡çº§
# é€šå¸¸æƒ…å†µä¸‹ï¼Œå‡çº§1åˆ°2ä¸ªå¤§ç‰ˆæœ¬ï¼Œæ²¡æœ‰å¤§é—®é¢˜ï¼Œé‡ç‚¹çœ‹å®˜æ–¹è¯´æ˜
```





#### æ‰¹é‡æ›´æ–°

```bash
# å½“å‰é›†ç¾¤ç‰ˆæœ¬
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   85m     v1.30.1
k8s-10-0-0-213   Ready                      node     66m     v1.30.1
master-01        Ready,SchedulingDisabled   master   4h6m    v1.30.1
master-02        Ready,SchedulingDisabled   master   4h6m    v1.30.1
worker-01        Ready                      node     3h58m   v1.30.1
worker-02        Ready                      node     3h58m   v1.30.1

```

**å‡çº§éœ€è¦ä¸‹è½½Kuberneteså¯¹åº”ç‰ˆæœ¬çš„æºç åŒ…å’ŒäºŒè¿›åˆ¶åŒ…**
**ä¸‹è½½ç½‘ç«™**

```http
https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.30.md#source-code
```

![image-20250408135807496](../markdown_img/image-20250408135807496.png)

![image-20250408140107110](../markdown_img/image-20250408140107110.png)

```bash
[root@haproxy1 src]#pwd
/usr/local/src

# ä¸‹è½½Source Code
[root@haproxy1 src]# wget https://dl.k8s.io/v1.30.11/kubernetes.tar.gz

# ä¸‹è½½ Client Binaries
[root@haproxy1 src]#wget https://dl.k8s.io/v1.30.11/kubernetes-client-linux-amd64.tar.gz

# ä¸‹è½½ Server Binaries
[root@haproxy1 src]#wget https://dl.k8s.io/v1.30.11/kubernetes-server-linux-amd64.tar.gz

# ä¸‹è½½ Node Binaries
[root@haproxy1 src]#wget https://dl.k8s.io/v1.30.11/kubernetes-node-linux-amd64.tar.gz

# æŸ¥çœ‹
[root@haproxy1 src]#ls
kubernetes-client-linux-amd64.tar.gz  kubernetes-server-linux-amd64.tar.gz
kubernetes-node-linux-amd64.tar.gz    kubernetes.tar.gz


# å…¨éƒ¨è§£å‹
[root@haproxy1 src]#tar xf kubernetes-client-linux-amd64.tar.gz 
[root@haproxy1 src]#tar xf kubernetes-node-linux-amd64.tar.gz 
[root@haproxy1 src]#tar xf kubernetes-server-linux-amd64.tar.gz 
[root@haproxy1 src]#tar xf kubernetes.tar.gz 

# æŸ¥çœ‹
[root@haproxy1 src]#ls
kubernetes                            kubernetes-server-linux-amd64.tar.gz
kubernetes-client-linux-amd64.tar.gz  kubernetes.tar.gz
kubernetes-node-linux-amd64.tar.gz
[root@haproxy1 src]#ls kubernetes
addons  cluster  hack                   LICENSES  README.md  version
client  docs     kubernetes-src.tar.gz  node      server

# è¿›å…¥äºŒè¿›åˆ¶æ‰€åœ¨ç›®å½•
[root@haproxy1 src]#cd kubernetes/server/bin/
[root@haproxy1 bin]#ls
apiextensions-apiserver             kubectl.docker_tag
kubeadm                             kubectl.tar
kube-aggregator                     kubelet
kube-apiserver                      kube-log-runner
kube-apiserver.docker_tag           kube-proxy
kube-apiserver.tar                  kube-proxy.docker_tag
kube-controller-manager             kube-proxy.tar
kube-controller-manager.docker_tag  kube-scheduler
kube-controller-manager.tar         kube-scheduler.docker_tag
kubectl                             kube-scheduler.tar
kubectl-convert                     mounter


# æŸ¥çœ‹æºäºŒè¿›åˆ¶æ–‡ä»¶ç‰ˆæœ¬
[root@haproxy1 bin]#/etc/kubeasz/bin/kube-apiserver --version
Kubernetes v1.30.1

# ï¼ˆå¯é€‰ï¼‰å¦‚æœæ˜¯è·¨å¤§ç‰ˆæœ¬å‡çº§ï¼Œå¯èƒ½éœ€è¦æ”¹kube-apiserverï¼Œkube-schedulerç­‰serviceæ–‡ä»¶
[root@haproxy1 bin]#vim /etc/kubeasz/roles/kube-master/templates/
aggregator-proxy-csr.json.j2        kubernetes-csr.json.j2
kube-apiserver.service.j2           kube-scheduler.service.j2
kube-controller-manager.service.j2 

# å°†æ‰€æœ‰çš„æ–°ç‰ˆäºŒè¿›åˆ¶å¤åˆ¶åˆ°kubeaszé¡¹ç›®çš„binç›®å½•ä¸‹
[root@haproxy1 bin]#cp kube-apiserver kube-controller-manager kubectl kubelet kube-proxy kube-scheduler /etc/kubeasz/bin/

# è¦†ç›–åæŸ¥çœ‹ç‰ˆæœ¬ï¼Œç¡®è®¤è¦†ç›–æˆåŠŸ
[root@haproxy1 bin]#/etc/kubeasz/bin/kube-apiserver --version
Kubernetes v1.30.11

# æ‰§è¡Œå‘½ä»¤ï¼Œæ‰¹é‡å‡çº§
[root@haproxy1 kubeasz]#./ezctl upgrade k8s-cluster1
......
PLAY RECAP ***************************************************************************
10.0.0.201                 : ok=50   changed=38   unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
10.0.0.202                 : ok=50   changed=38   unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
10.0.0.203                 : ok=55   changed=40   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
10.0.0.211                 : ok=31   changed=22   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
10.0.0.212                 : ok=31   changed=22   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
10.0.0.213                 : ok=31   changed=22   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0  

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE   VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   18m   v1.30.11
k8s-10-0-0-213   Ready                      node     16m   v1.30.11
master-01        Ready,SchedulingDisabled   master   18m   v1.30.11
master-02        Ready,SchedulingDisabled   master   18m   v1.30.11
worker-01        Ready                      node     16m   v1.30.11
worker-02        Ready                      node     16m   v1.30.11
```

```ABAP
ä¸ºé¿å…å¯¹ä¸šåŠ¡é€ æˆå®è´¨æ€§å½±å“ï¼Œä¸€å®šè¦åœ¨æ™šä¸Šå‡çº§
```



#### æ‰‹åŠ¨æ›´æ–°

**æ–¹å¼1**ï¼šå°†äºŒè¿›åˆ¶æ–‡ä»¶åŒæ­¥åˆ°å…¶å®ƒè·¯å¾„ï¼Œä¿®æ”¹serviceæ–‡ä»¶åŠ è½½æ–°ç‰ˆæœ¬äºŒè¿›åˆ¶ï¼š**å³ç”¨æ–°ç‰ˆæœ¬æ›¿æ¢æ—§ç‰ˆæœ¬**

**æ–¹æ³•2**ï¼šå…³é—­æºæœåŠ¡ï¼Œæ›¿æ¢äºŒè¿›åˆ¶æ–‡ä»¶ç„¶åå¯åŠ¨æœåŠ¡ï¼š**å³ç›´æ¥æ›¿æ¢æ—§ç‰ˆæœ¬**

```bash
# å‡çº§nodeèŠ‚ç‚¹

# æ³¨æ„è¦†ç›–äºŒè¿›åˆ¶ï¼Œå°½é‡åœ¨ä¸šåŠ¡ä½å³°æœŸæ‰§è¡Œï¼Œå› ä¸ºä¼šåœæœåŠ¡
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   146m    v1.30.1
k8s-10-0-0-213   Ready                      node     127m    v1.30.1
master-01        Ready,SchedulingDisabled   master   5h7m    v1.30.1
master-02        Ready,SchedulingDisabled   master   5h7m    v1.30.1
worker-01        Ready                      node     4h59m   v1.30.1
worker-02        Ready                      node     4h59m   v1.30.1

# ä¸‹çº¿å¾…æ›´æ–°èŠ‚ç‚¹ï¼Œå³åç»­ä¸ä¼šå¾€è¿™ä¸ªèŠ‚ç‚¹è°ƒåº¦pod
[root@master-01 ~]#kubectl cordon k8s-10-0-0-213
node/k8s-10-0-0-213 cordoned

# æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE    VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   147m   v1.30.1
k8s-10-0-0-213   Ready,SchedulingDisabled   node     127m   v1.30.1
master-01        Ready,SchedulingDisabled   master   5h7m   v1.30.1
master-02        Ready,SchedulingDisabled   master   5h7m   v1.30.1
worker-01        Ready                      node     5h     v1.30.1
worker-02        Ready                      node     5h     v1.30.1

# é©±é€ä¸‹çº¿èŠ‚ç‚¹ä¸Šé¢çš„podï¼Œdadmonsetsç±»å‹çš„podè¦å¿½ç•¥æ‰ï¼Œå¦‚æœæœ‰å¸¦æ•°æ®çš„podï¼Œä¹Ÿè¦å¿½ç•¥æ‰
[root@master-01 ~]#kubectl drain k8s-10-0-0-213 --ignore-daemonsets
node/k8s-10-0-0-213 already cordoned
Warning: ignoring DaemonSet-managed Pods: kube-system/calico-node-btpzm
node/k8s-10-0-0-213 drained

# æ­¤æ—¶å°±å¯ä»¥åœ¨10.0.0.213è¿™ä¸ªèŠ‚ç‚¹ä»»æ„æ“ä½œï¼Œä¸ä¼šå½±å“åˆ°åŸé›†ç¾¤
# æ›¿æ¢å‡çº§kubelet
## æŸ¥çœ‹åŸkubeletç‰ˆæœ¬
[root@k8s-10-0-0-213 ~]#/usr/local/bin/kubelet --version
Kubernetes v1.30.1

## åœæ­¢æœåŠ¡
[root@k8s-10-0-0-213 ~]#systemctl stop kubelet.service

## ç”¨æ–°ç‰ˆkubeletæ›¿æ¢æ‰æ—§ç‰ˆkubelet 
[root@haproxy1 bin]#scp kubelet node3:/usr/local/bin/
kubelet                                             100%   96MB  42.5MB/s   00:02 

## æŸ¥çœ‹
[root@k8s-10-0-0-213 ~]#/usr/local/bin/kubelet --version
Kubernetes v1.30.11

## ç„¶åå¯åŠ¨kubelet
[root@k8s-10-0-0-213 ~]#systemctl start kubelet.service

## åœ¨masterèŠ‚ç‚¹æŸ¥çœ‹
[root@master-01 ~]#kubectl get node
NAME             STATUS                     ROLES    AGE     VERSION
k8s-10-0-0-203   Ready,SchedulingDisabled   master   155m    v1.30.1
k8s-10-0-0-213   Ready,SchedulingDisabled   node     136m    v1.30.11      # å‡çº§æˆåŠŸ
master-01        Ready,SchedulingDisabled   master   5h16m   v1.30.1
master-02        Ready,SchedulingDisabled   master   5h16m   v1.30.1
worker-01        Ready                      node     5h8m    v1.30.1
worker-02        Ready                      node     5h8m    v1.30.1

## å‡çº§æˆåŠŸåï¼Œæ¢å¤è°ƒåº¦
[root@master-01 ~]#kubectl uncordon k8s-10-0-0-213
node/k8s-10-0-0-213 uncordoned
```



### éƒ¨ç½²Kuberneteså†…éƒ¨åŸŸåè§£ææœåŠ¡â€”CoreDNS

ç›®å‰å¸¸ç”¨çš„dnsç»„ä»¶æœ‰kube-dnså’ŒCorednsä¸¤ä¸ªï¼Œåˆ°k8sç‰ˆæœ¬1.17.Xéƒ½å¯ä»¥ä½¿ç”¨ï¼Œkube-dnså’Œcorednsç”¨äºè§£æk8sé›†ç¾¤ä¸­service nameæ‰€å¯¹åº”å¾—åˆ°IPåœ°å€ï¼Œä»Kubernetes v1.18å¼€å§‹ä¸æ”¯æŒä½¿ç”¨kube-dns



#### éƒ¨ç½²Coredns

å¤åˆ¶coredns.yamlæ¨¡ç‰ˆ

```http
https://github.com/coredns/deployment/blob/master/kubernetes/coredns.yaml.sed
```

![image-20250408180337386](D:\git_repository\cyber_security_learning\markdown_img\image-20250408180337386.png)

```bash
# æ‹·è´å¹¶æ›´æ”¹coredns.yamlæ¨¡ç‰ˆ
[root@master-01 ~]# vim coredns.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    - pods
    - namespaces
    verbs:
    - list
    - watch
  - apiGroups:
    - discovery.k8s.io
    resources:
    - endpointslices
    verbs:
    - list
    - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors                      # errorsæ’ä»¶ï¼šé”™è¯¯ä¿¡æ¯æ ‡å‡†è¾“å‡º
        health {                    # healthæ’ä»¶ï¼šåœ¨CoreDNSçš„http://localhost:8080/healthç«¯å£æä¾›CoreDNSæœåŠ¡çš„å¥                                       åº·æŠ¥å‘Š
          lameduck 5s
        }
        ready                       # readyæ’ä»¶ï¼šç›‘å¬8181ç«¯å£ï¼Œå½“corednsçš„æ’ä»¶éƒ½å·²å°±ç»ªæ—¶ï¼Œè®¿é—®è¯¥ç«¯å£ä¼šè¿”å›200 OK
        # CLUSTER_DOMAIN REVERSE_CIDRS æ”¹ä¸º cluster.local in-addr.arpa ip6.arpa
        # åŸºäºKubernetes service nameè¿›è¡ŒDNSæŸ¥è¯¢å¹¶è¿”å›æŸ¥è¯¢è®°å½•ç»™å®¢æˆ·ç«¯
        kubernetes CLUSTER_DOMAIN REVERSE_CIDRS {
          fallthrough in-addr.arpa ip6.arpa
        }
        # CoreDNSçš„åº¦é‡æŒ‡æ ‡æ•°æ®ä»¥Prometheusçš„key-valueçš„æ ¼å¼åœ¨http://localhost:9153/metrics URLä¸Šæä¾›
        prometheus :9153
        # è¿™é‡Œ UPSTREAMNAMESERVER æ”¹ä¸º /etc/resolv.conf
        # é›†ç¾¤å†…è§£æä¸äº†çš„åŸŸåï¼Œè½¬å‘ç»™å®¿ä¸»æœºçš„/etc/resolv.confè§£æ
        forward . UPSTREAMNAMESERVER {
          max_concurrent 1000
        }
        cache 30             # å¯ç”¨serviceè§£æç¼“å­˜ï¼Œå•ä½ä¸ºç§’
        # æ£€æµ‹åŸŸåè§£ææ˜¯å¦æœ‰æ­»å¾ªç¯ï¼Œå¦‚corednsè½¬å‘ç»™å†…ç½‘DNSæœåŠ¡å™¨ï¼Œè€Œå†…ç½‘DNSæœåŠ¡å™¨åˆè½¬ç»™corednsï¼Œå¦‚æœå‘ç°è§£ææ˜¯æ­»å¾ªç¯ï¼Œåˆ™å¼ºåˆ¶           ä¸­æ­¢CoreDNSè¿›ç¨‹ï¼ˆKubernetesä¼šé‡å»ºï¼‰
        loop
        # æ£€æµ‹corefileæ˜¯å¦æ›´æ”¹ï¼Œåœ¨é‡æ–°ç¼–è¾‘configmapé…ç½®åï¼Œé»˜è®¤2åˆ†é’Ÿåä¼šä¼˜é›…çš„è‡ªåŠ¨åŠ è½½
        reload
        loadbalance           # è½®è¯¢DNSåŸŸåè§£æï¼Œå¦‚æœä¸€ä¸ªåŸŸåå­˜åœ¨å¤šä¸ªè®°å½•åˆ™è½®è¯¢è§£æ
    }STUBDOMAINS              # åˆ é™¤ STUBDOMAINS
    
    # é›†ç¾¤å†…è§£æä¸äº†çš„åŸŸåï¼Œè½¬å‘ç»™233.6.6.6è§£æ
    forward . 223.6.6.6 {
        max_concurrent 1000
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/name: "CoreDNS"
    app.kubernetes.io/name: coredns
spec:
  # replicas: not specified here:
  # 1. Default is 1.
  # 2. Will be tuned in real time if DNS horizontal auto-scaling is turned on.
  # è¿™é‡Œå¯ä»¥æ”¹ä¸º replicas: 2ï¼Œä¿è¯é«˜å¯ç”¨
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
      app.kubernetes.io/name: coredns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
        app.kubernetes.io/name: coredns
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: coredns
      tolerations:
        - key: "CriticalAddonsOnly"
          operator: "Exists"
      nodeSelector:
        kubernetes.io/os: linux
      affinity:
         podAntiAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
               - key: k8s-app
                 operator: In
                 values: ["kube-dns"]
             topologyKey: kubernetes.io/hostname
      containers:
      - name: coredns
        image: coredns/coredns:1.9.4            # è¿™é‡Œå¯ä»¥æ”¹ä¸ºç§æœ‰é•œåƒä»“åº“åœ°å€
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            memory: 170Mi
          requests:                          # è¿™é‡Œçš„èµ„æºé™åˆ¶ï¼Œåœ¨é«˜è´Ÿè½½ï¼Œéœ€è¦é¢‘ç¹è§£æåŸŸåçš„åœºæ™¯ä¸‹ï¼Œå¯èƒ½è¦åŠ å¤§èµ„æºï¼ˆæ¯”                                                  å¦‚1-2CPU,512Miå†…å­˜/1G,è¿™ä¸ªè¦æ ¹æ®ç›‘æ§æ¥å®šï¼‰ï¼Œå¦åˆ™CoreDNSä¼šè§£æåŸŸåå¯èƒ½                                                ä¼šå¾ˆæ…¢ï¼Œå¯¼è‡´ç½‘ç«™æ‰“å¼€æ…¢ï¼Œå†æˆ–è€…ä¹Ÿå¯ä»¥å¤šå‰¯æœ¬è§£å†³
            cpu: 100m            
            memory: 70Mi
        args: [ "-conf", "/etc/coredns/Corefile" ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
          readOnly: true
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        - containerPort: 9153
          name: metrics
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - all
          readOnlyRootFilesystem: true
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8181
            scheme: HTTP
      dnsPolicy: Default
      volumes:
        - name: config-volume
          configMap:
            name: coredns
            items:
            - key: Corefile
              path: Corefile
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  annotations:
    prometheus.io/port: "9153"
    prometheus.io/scrape: "true"
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "CoreDNS"
    app.kubernetes.io/name: coredns
spec:
  selector:
    k8s-app: kube-dns
    app.kubernetes.io/name: coredns
  clusterIP: CLUSTER_DNS_IP    # è¿™é‡Œæ”¹ä¸º10.100.0.2 ,æ ¹æ®POD_IPç½‘æ®µç¡®å®šï¼Œé€šå¸¸æ˜¯ç¬¬äºŒä¸ª
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP
  - name: metrics
    port: 9153
    protocol: TCP
```

```bash
# å¯ç”¨
[root@master-01 ~]#kubectl apply -f coredns.yaml
```



### Kubectl å¸¸ç”¨å‘½ä»¤

**kubectlå‘½ä»¤è¡Œä½¿ç”¨ç®€ä»‹**

```http
https://kubernetes.io/zh-cn/docs/reference/kubectl/generated/
```

| å‘½ä»¤é›†       | å‘½ä»¤                                                         | ç”¨é€”         |
| ------------ | ------------------------------------------------------------ | ------------ |
| åŸºç¡€å‘½ä»¤     | **create/delete/edit/get/describe/logs/scale**               | å¢åˆ æ”¹æŸ¥     |
| é…ç½®å‘½ä»¤     | **Label**ï¼šæ ‡ç­¾ç®¡ç†<br />**apply**ï¼šåŠ¨æ€é…ç½®<br />**cluster-info/top**ï¼šé›†ç¾¤çŠ¶æ€ |              |
| é›†ç¾¤ç®¡ç†å‘½ä»¤ | **cordon**ï¼šè­¦æˆ’çº¿ï¼Œæ ‡è®°nodeä¸è¢«è°ƒåº¦<br />**uncordon**ï¼šå–æ¶ˆè­¦æˆ’çº¿æ ‡è®°ä¸ºcordonçš„node<br />**drain**ï¼šé©±é€nodeä¸Šçš„podï¼Œç”¨äºnodeä¸‹çº¿ç­‰åœºæ™¯<br />**taint**ï¼šç»™nodeæ ‡è®°æ±¡ç‚¹ï¼Œå®ç°åäº²å’Œä¸nodeåäº²å’Œæ€§<br />**api-resources/api-versions/version**ï¼šapièµ„æº<br />**config**ï¼šå®¢æˆ·ç«¯kube-configé…ç½® | nodeèŠ‚ç‚¹ç®¡ç† |