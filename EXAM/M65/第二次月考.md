# 第二次月考



**姓名：**



## 什么是OOM，Java程序如何解决OOM问题？



**OOM**：在 **Java 程序中**，OOM 通常指 **JVM 在堆或非堆内存中无法再分配对象空间**，导致运行时崩溃。通常系统级OOM发生的情况很少。



**生产环境中的 Java OOM 故障定位流程**

**业务告警触发（通常从前端开始）**

- 大量 500 错误、接口响应超时、服务不可用

- 日志/监控平台告警、Prometheus 报警、APM 探针（如 Skywalking）预警



 **临时恢复业务**

- 重启服务！

- 临时提升 `-Xmx` 或元空间大小
- 如在容器中，临时调高 `memory limit`



**运维介入排查协助开发分析堆快照并推进根因修复**

**在上游服务中发现 Java 报错，根据报错内容判断地址的OOM原因**

- **JVM OOM**
- **OS OOM**（通常很少）



**JVM OOM 最常见的三种类型**



**一、堆内存 OOM（Heap Space OOM）**

```ABAP
# 错误信息
java.lang.OutOfMemoryError: Java heap space
```

**典型成因：**

- 对象创建过多或生命周期过长（如：大缓存、无限集合）
- 内存泄漏（对象不再使用但仍被引用）
- GC 策略不当，无法及时回收无用对象
- 堆配置太小（如默认 `-Xmx256m`）

**解决思路：**

- 增加堆大小：`-Xmx1g -Xms1g`
- 配置合适的 GC 策略（如 CMS/G1）

> **快速止损：重启服务 + 增加堆内存（临时)**
>
> **收集现场信息（关键）**
>
> `-XX:+PrintGCDetails -Xloggc:/tmp/gc.log`
>
> 这是 **开启 GC 日志记录并输出到指定文件** 的方式，用于分析 JVM 内部垃圾回收行为
>
> ```bash
> java -XX:+PrintGCDetails -Xloggc:/tmp/gc.log ...
> ```
>
> - `-XX:+PrintGCDetails`：输出详细的 GC 日志，包括 Minor GC、Full GC 次数、时间、回收大小等
> - `-Xloggc=/tmp/gc.log`：把这些信息写入日志文件中（不会输出到 stdout）
>
> **用于分析是否存在：**
>
> - Full GC 频繁
> - 每次 GC 回收内存太少
> - GC 时间是否过长
> - 是否因为 GC 耗时导致 OOM
>
> `-XX:+HeapDumpOnOutOfMemoryError`
>
> 这是 **发生 OOM 时自动生成堆内存快照（heap dump）** 的方式：
>
> ```bash
> java -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heap.hprof ...
> ```
>
> - `.hprof` 是 JVM 堆转储文件（包含内存中所有对象、引用、类等信息）
> - 文件很大，注意磁盘空间（通常几十 MB ~ 几百 MB）
>
> 使用 VisualVM 分析 `.hprof`



**二、元空间 OOM（Metaspace OOM）**

```ABAP
java.lang.OutOfMemoryError: Metaspace
```

**典型成因：**

- 大量类加载（如反射、动态代理、热部署）
- 第三方类加载器未释放（如 Tomcat 中部署多 war 包）
- 开发代码逻辑问题：重复加载类、频繁动态生成类

**解决思路：**

- 增加元空间大小：`-XX:MaxMetaspaceSize=256m`
- 优化代码结构，避免频繁加载类
- 热部署使用专业框架（Spring Boot Devtools、JRebel）

> 临时解决：**扩大 Metaspace 限制**
>
> 通过增加启动参数：
>
> ```bash
> -XX:MaxMetaspaceSize=512m
> ```
>
> （默认是无限制，直到系统内存用完）注意：这个方法只是延迟 OOM 的发生，**不是根本解决方案**。
>
> ![image-20250808185357670](D:\git_repository\cyber_security_learning\markdown_img\image-20250808185357670.png)
>
> Metaspace OOM 的本质是：**类加载太多且无法卸载**，具体诱因通常有：
>
> | 诱因                                | 你可以通过 Probe 观察到的现象                       |
> | ----------------------------------- | --------------------------------------------------- |
> | 动态类大量生成（如 CGLIB 动态代理） | 某些 Servlet 或 Filter 的类数异常高，请求数也异常高 |
> | 类加载器泄漏（如热部署失败）        | 应用重启后类仍旧残留（可结合 JMX 查看类加载器）     |
> | 某些业务请求路径导致类爆炸增长      | 某些 Servlet 请求数暴增，但代码无明显业务量支持     |
>
> ```bat
> 注意：不要仅凭请求数就“断言”代码有问题,你发给开发的应该是“观察+建议”，而不是“定性指责”。
> ```





**三、本地线程 OOM（Native Thread OOM）**

```ABAP
java.lang.OutOfMemoryError: unable to create new native thread
```

**典型成因：**

- 创建线程数太多，超过了系统线程限制（ulimit -u）

- 每个线程栈大小太大：默认 `-Xss1m`，成千上万线程就会耗尽内存

- 使用了线程池但没设置上限（如无限队列、无限提交）



**解决思路：**

- 限制线程数：使用线程池 + 合理的最大线程配置
- 减小线程栈大小：`-Xss256k`

>  JVM 线程栈是在 **本地内存（native memory）** 中分配的，**不是在 Java 堆中！**
>
> 通常线程数越多，推荐内存越小

- 查看系统线程上限：`ulimit -u`，或 `/proc/sys/kernel/threads-max`

```bash
# 修改Tomcat 的配置：maxThreads
<Connector
    ...
    maxThreads="300"
    minSpareThreads="20"
/>

# 注意：maxThreads 一定要小于 ulimit -u
# 建议示例
ulimit -u = 4096
JVM 和系统基础线程消耗约 200～500
那么你 Tomcat 的 maxThreads 应该设在 2000～3000 左右是比较合理的

# 注意：根据业务的实际情况对 maxThreads 和 ulimit -u，通常CPU核数决定了maxThreads的值，否则maxThreads过多，会导致CPU抢占，从而导致响应变慢
# 建议：maxThreads 控制在 2～8 × CPU核数范围内，ulimit -u 设置为高于 maxThreads + 500，但不可无限大
```



 **总结：发给开发的信息建议包括**

```bat
OOM时间点及频次  
当时服务是否出现请求堆积或响应慢（结合 Probe 线程或请求数）  
导出的 heap dump（如 hprof）  
`jmap -histo:live` 中前 20 占用内存最多的类  
是否有 FullGC 频繁、GC回收率低
```













## 你在工作中监控过Java程序的哪些指标



**probe重点关注数据总结**

- **请求数**，分析是按个站点的请求内容比较多，如果出问题的话是哪个类引起的，这些都可以从下图看出，虽然运维看的不是特别明确但是开发是看的懂的，哪个类在消耗，开发自身应该很清楚
- ![alt text](D:\git_repository\cyber_security_learning\markdown_img\image98.png)
- 通过线程池数据分析线程数，看线程够不够用，如果线程用满了就即使去增大，防止出现排队，出现排队超时
- ![alt text](D:\git_repository\cyber_security_learning\markdown_img\image94.png)
- 观察内存中内存分布的情况（青年态，老年态）
  - （可以在catalina.sh的文件中指定内存的大小），后期根据实际情况去调整内存的分布,防止内存溢出和产生频发回收机制（比如年轻态过小，就会频繁出发回收，而频繁的GC会消耗系统资源）
    ![alt text](D:\git_repository\cyber_security_learning\markdown_img\image99.png)
  - 通过看系统资源的情况分析，比如由于内存过小，导致频繁出发GC，导致CPU使用率增高
  - JMP CPU UTILIZATION过高，就会导致CPU负载变高
  - FILE DESCRIPTIONS变高，又或者发生频繁的读取文件，频繁导致磁盘IO变高
    ![alt text](D:\git_repository\cyber_security_learning\markdown_img\image100.png)
- 观察（http）连接器里的点击率和吞吐量
  ![alt text](D:\git_repository\cyber_security_learning\markdown_img\image112.png)









## Nginx负载均衡的算法怎么实现的?策略有哪些?

**轮询与加权轮询**

```bash
#round-robin
upstream rrups {
    server 127.0.0.1:8011;
    server 127.0.0.1:8012;
    keepalive 32;
}

#加权round-robin
upstream rrups {
    server 127.0.0.1:8011 weight=2 max_conns=2 max_fails=2 fail_timeout=5;
    server 127.0.0.1:8012;
    keepalive 32;
}
```



**源地址hash**

```bash
#源ip地址hash
#ip_hash算法只使用ipv4的前24位做hash运算，如果客户端前24位一致，则会被调度 到同一台后端服务器
# Proxy_Server 配置
upstream group1 {
    ip_hash;         # 只要加上ip_hash即可
    server 10.0.0.210;
    server 10.0.0.159;
}
```



**使用自行指定的key做hash调度**

```bash
#使用自行指定的key做hash调度
# 三台server权重一样，调度算法hash($remote_addr)%3,值为0,1,2根据不同的值调度到不同server
upstream group1 {
    hash $remote_addr;
    server 10.0.0.210;
    server 10.0.0.159;
    server 10.0.0.213;
}

# 三台server权重不一样，调度算法hash($remote_addr)%(1+2+3),值为0,1,2,3,4,5
# 0 调度到210
# 1，2调度到159
# 3,4,5调度到213
upstream group1 {
    hash $remote_addr;
    server 10.0.0.210 weight=1;
    server 10.0.0.159 weight=2;
    server 10.0.0.213 weight=3;
}

# 也可以根据request_uri进行调度，不同客户端访问同一个资源会被调度到同一个后端服务器上
upstream group1 {
    hash $request_uri
    server 10.0.0.210;
    server 10.0.0.159;
    server 10.0.0.213;
}
```



**最少连接调度算法**

```bash
# 根据哪台服务器上的连接数少，就调度到哪里，如果多台服务器连接数一致，则这几台服务器按照轮询的方式进行调度
upstream group1 {
    least_conn;
    server 10.0.0.210;
    server 10.0.0.159;
}
```



**一致性hash**

```bash
upstream group1 {
    hash $remote_addr consistent;
    server 10.0.0.210;
    server 10.0.0.159;
    server 10.0.0.213;
}
```





## 你对nginx做过哪些优化

**根据CPU核数使用进程数**

```bash
worker_processes auto
```



**在主跑nginx的服务器上将worker进程优先级调高**

```bash
# -10起步，如果基本只跑nginx，可以调为-5
worker_priority -10
```



**调整 worker_rlimit_nofile** 

```bash
#nginx启动后，每个worker能够使用的文件描述符上限
#但因为文件描述符（FD）不仅用于连接，在 Nginx worker 进程里，FD 消耗来源主要有：
#- 网络连接（socket），每个客户端连接占用 1 个 FD（有时长连接、反向代理还会占更多 FD）。
#- 日志文件（access.log、error.log），每个打开的日志文件占用 1 个 FD。
#- 静态文件（HTML、图片等），传输过程中会打开文件 FD。
#- 反向代理/上游连接，如果启用了 upstream，一个请求可能占 2 个 FD（客户端 + upstream 服务器）。
#- 临时文件（大文件缓存、proxy_temp 等），占用临时文件 FD。

# 因此 worker_rlimit_nofile 必须大于 worker_connection

# 该数据受内核参数`ulimit -n`数量限制，来需要该外面的其他设置
# 如果是nginx直接启动，更改/etc/security/limits.conf 
# 更改limits.conf
# 添加 * hard nofile 10000
# * soft nofile 10000
# root hard nofile 10000
# root soft nofile 10000

# 如果是systemctl启动，则更改service文件中的参数
# LimitNOFILE=100000

# 百万并发建议
worker_rlimit_nofile 3200000

```



**通过亲源机制，把CPU和进程进行绑定**

```bash
# worker_cpu_affinity 不支持 auto，需要手动配置绑定掩码 
worker_cpu_affinity 00000001 00000010 00000100 00001000

# 通过脚本生成 worker_cpu_affinity 配置，实现细粒度的 CPU 绑定
CORES=$(nproc) # CPU 核数

for ((i=0; i<$CORES; i++)); do
    # 生成二进制掩码（1 左移 i 位）
    MASK=$(printf "%0${CORES}d" "$(echo "obase=2; $((1 << i))" | bc)")
    echo -n "$MASK "
done
```



**调整 worker_connection**

```bash
worker_connection 65535 # 设置单个工作进程的最大并发连接数,默认512，建议加大，否则，只能接受最大指定连接数，超出则会丢弃请求，不会处理。
```



**开启防惊群**

```bash
accept mutex on    # 惊群，推荐on，on为同一时刻一个请求轮流由worker进程处理，而防治被同时唤醒所有worker
                   # 默认为off，新请求会唤醒所有的worker进程
```



**开启多路复用**

```bash
multi_accept on  # on时Nginx服务器的每个工作进程可以同时接受多个新的网络连接，此指令默认为off，即默认为一个工作进程只能一次接受一个新的网络连接，打开后可以同时接受多个，建议设置on，充分利用多路复用的理念
```



**优化多路复用开启，导致连接在各 worker 间分布不均**

```bash
#用 SO_REUSEPORT 让每个 worker 拥有各自独立的监听队列，由内核做均衡分发，天然避免一个 worker 吸走所有连接。
#做法（Linux ≥3.9，Nginx ≥1.9.1）
# 每个 worker 拥有独立的 listen socket 与 backlog
worker_processes auto;

http {
  server {
    listen 80 reuseport;   # 关键
    # listen [::]:80 reuseport;  # IPv6 也要配
  }
}
```



**启用后端异步更新缓存**

当 Nginx 发现缓存过期时，不会立刻等待后端返回新的数据，而是先返回旧缓存给客户端，同时在后台向后端发起请求更新缓存**。这样可以**减少对后端服务器的压力，提高 Nginx 吞吐量

```bash
proxy_cache_use_stale updating error timeout http_500 http_502 http_503 http_504;
proxy_cache_background_update on;
```

1. 客户端请求到达。
2. **Nginx 发现缓存过期**，但**仍然返回旧的缓存数据**（减少客户端延迟）。
3. **同时在后台向后端请求最新数据**，更新缓存。
4. **下次有新的客户端请求时，Nginx 直接使用最新缓存**。



**`proxy_cache_use_stale` 参数详解**

| 参数                        | 作用                                   |
| --------------------------- | -------------------------------------- |
| **`updating`**              | 旧缓存过期时，仍然返回它，后台异步更新 |
| **`error`**                 | 如果后端请求失败，仍然返回旧缓存       |
| **`timeout`**               | 如果后端超时，仍然返回旧缓存           |
| **`http_500` ~ `http_504`** | 如果后端返回 5xx 错误，仍然返回旧缓存  |



**对上游服务使用keepalive长连接**

通过复用连接，降低nginx与上游服务建立，关闭连接的消耗，提升吞吐量的同时降低时延

```bash
upstream rrups {
    server 127.0.0.1:8011 weight=2 max_conns=2 max_fails=2 fail_timeout=5;
    server 127.0.0.1:8012;
    keepalive 512;
    keepalive_requests 10000;
    keepalive_time  30m;   # 限制连接寿命，避免“永久脏连接”
}

server {
    server_name rrups.feng.tech;
    error_log myerror.log info;

    location / {
        proxy_pass http://rrups;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }
}
```



**开启 gzip 压缩**

```bash
gzip on    # 确保cpu资源富裕
```







## 叙述Https的工作过程

```bat
1. 第一步：客户端发起请求
2. 第二步：服务端将证书传给客户端
3. 第三步：客户端使用CA公钥解析验证证书,没问题的话生成一个随机值,使用服务器公钥加密随机值发给服务端
4. 第四步：服务端收到公钥加密的随机值,使用自己的私钥解密,后续客户端和服务端使用这个随机值进行对称加密，机密传输。
```











## 写出Web浏览器发起HTTP请求访问网站的过程

```bat
- 首先服务器监听打开了443或者80端口
- 浏览器从url中解析出域名
- 根据域名查询DNS，获取域名对应得IP地址
- 浏览器根据ip地址，和服务器三次握手建立TCP链接，https会额外完成TLS/SSL的握手
- 构造HTTP请求，在构造请求的过程中，填充相应的HTTP头部，包括上下文所需要的信息，至头部中
- 通过链接发起HTTP请求
- 服务器接收到HTTP请求后，完成资源的表述，把客户端请求的文件如html页面作为包体返回给浏览器
- 浏览器在渲染引擎中解析响应，根据这个响应中一些其他的超链接资源去构造其他HTTP请求
```





## 什么是linu系统负载load average

```bat
[root@ubuntu2204 ~]#man uptime
System  load  averages  is the average number of processes that are either in a runnable or uninterruptable state.  A process in a runnable state is either using the CPU or waiting to use the CPU.  A process in uninterruptable state is waiting for some I/O
access, eg waiting for disk.  The averages are taken over the three time intervals.  Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a  4  CPU  system it means it was idle 75% of the time.

系统平均负载是指处于可运行或不可中断状态的进程的平均数量。处于可运行状态的进程要么正在使用 CPU，要么正在等待使用 CPU。处于不可中断状态的进程正在等待某些 I/O 访问，例如等待磁盘访问。系统平均负载是在三个时间间隔内计算得出的。平均负载并未根据系统中的 CPU 数量进行标准化，因此，对于单 CPU 系统，平均负载为 1 表示始终处于负载状态；而对于四 CPU 系统，平均负载为 1 表示 75% 的时间处于空闲状态。
```





## 简述DNS进行域名解析的过程？

```bat
用户要访问http://www.baidu.com，会先找本机的host文件，再找本地设置的DNS服务器，如果也没有
的话，就去网络中找根服务器，根服务器反馈结果，说只能提供一级域名服务器.cn，就去找一级域名服
务器，一级域名服务器说只能提供二级域名服务器.com.cn,就去找二级域名服务器，二级域服务器只能
提供三级域名服务器.http://baidu.com.cn，就去找三级域名服务器，三级域名服务器正好有这个网站
http://www.baidu.com，然后发给请求的服务器，保存一份之后，再发给客户端
```





## TCP三次握手过程

```bat
三次握手：

初始阶段，客户端是CLOSE状态，服务端需要监听服务所在端口，因此处于LISTEN状态

客户端发来SYN分组，到达了服务器，此时客户端会从CLOSE状态立即变为SYN-SENT状态

SYN到达服务端，在服务器内核中，会将"根据SYN分组内容创建的内核数据结构实例"放入SYN队列中，同时会发送一个SYN+ACK数据分组给客户端，此时服务端从LISTEN状态变为SYN-RECEIVED状态

客户端收到SYN+ACK分组，会给服务端发送ACK分组，并从SYN-SENT状态变为ESTABLISTED状态

服务端收到ACK分组后会从SYN-RECEIVED状态转换为ESTABLISHED状态，但实际在内核中，会把之前放入SYN队列中的数据结构实例移出，放入ACCEPT队列中，然后由应用程序调用accept方法从ACCEPT队列中将该数据结构实例取出，并返回一个新的文件描述符，供应用程序进行后续数据处理和通信。该文件描述符对应的是一个新的 socket，通过它，应用程序可以继续与客户端进行数据收发。
```





10. free -m ，解释 total , used , free , buff/cache , available 之间的关系

```bat
buff/cache = 页缓存 + 脏页缓存 + slab
total = used + free + shared + buff/cache
available = buff/cache(部分可回收的) + free
```

