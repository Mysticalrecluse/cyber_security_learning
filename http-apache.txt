重点概念：
浏览器访问网站的过程（必备）
1. 在浏览器地址栏中输入网址
2. DNS解析域名，获得服务器IP地址
			DNS缓存查询
			DNS递归查询
                        返回服务器IP
3. TCP连接
	3次握手
	4次挥手

4. HTTP请求
	发送请求参数到服务器
	服务器返回内容

5. 客户端浏览器渲染页面
	获取HTML，CSS，JS等各种资源
	渲染模块，CSS CORE，JS CORE等
	构建DOM树
	样式计算：布局
	生成效果页面



url,uri,urn的概念


http请求头和响应头结构

数据包 ---> 网卡缓冲区 ---> 内核缓冲区 ---> 用户空间缓冲区

同步异步，阻塞非阻塞
·
session和cookie

无状态连接，不记录状态，在浏览器的表现形式就是，用户登录后，当连接断开后，还需要重新登录，每次连接需要重新验证身份

场景：比如我登录京东购物，进入一个产品界面进行观看，此时这个产品界面相当于下载到本地，是离线观看，但当我打算购物的时候，点击购物，此时需要重新访问网站，  理论上如果没有其他措施，此时点击购物后，需要重新登录进行身份验证，假设重新登录后点击购买后，到了支付页面，又断了……，后续支付仍需要重新登录以重新验证身份，这种情况明显不合理


经由上述场景，既然http是无状态连接，且连接后访问会断开，那么后续的连接就必然需要身份认证，但是人为交互体验不可忍受，因此可以交给浏览器进行后续的身份认证

如何实现让浏览器进行后续的身份认证，实现思路：服务器在第一次客户端发送请求后，向客户端返回响应的时候，向浏览器发送一条身份标识，即token，且该token具有时效性，比如15分钟内有效，此时浏览器上就保存第一次登录的身份信息，当后续访问断开，再次请求访问时，无需用户再次手动认证，而是浏览器使用该身份标识，即token信息作为身份标识发给服务端，而服务端在第一次返沪itoken时，记录了访问者和token的对应关系，因此当服务端收到这个token后，即可查出访问者是谁。

互联网中实现上述过程的技术就是cookie和session


cookie是可以在http首部字段中可以携带的一个小数据，cookie中可以带有用户的登录信息，当第一次服务器被登录成功后，服务器会生成一个cookie信息，通过http响应报文，将这个cookie发送给浏览器，浏览器就记住了服务器发送的cookie，当过了一段时间，浏览器和服务器断开连接后（在cookie有效期内），重新发起访问该网站时，浏览器会自动将cookie提交给服务器，而此时，cookie里就有服务器最初发给浏览器的token信息。服务器收到这个token后，就i可以验证其身份，从而实现身份认证，就不需要人为的输入验证密码了，这就是cookie的作用/

由于网络带宽限制，cookie中不适合携带大量数据，因此cookie通常仅存放少量信息，那像购物车这类大量信息的数据如何携带，则通常交由session负责

cookie和sessioni

session通常放在服务器端，在服务器端的内存中，有一个空间，存放各种cookie及其其他的相关信息，cookie相当于这些信息的主键，比如uuid，而session这是这些全部数据的集合
，

session的定义：
1. Session 是服务器端维护用户状态的一种机制。
2. 每个用户访问服务器时，服务器会为用户创建一个唯一的 Session ID（通常是随机生成的 UUID），用于标识用户会话。

3.Session 是一个数据集合，通常存储在服务器的内存中或某种存储介质（如 Redis 或数据库）中，用于保存用户的临时会话数据，例如：

- 用户登录状态
- 用户偏好设置
- 购物车信息

cookie的定义
1.  Cookie 是存储在客户端（浏览器）上的一小段数据。
2. 在基于 Session 的会话中，Cookie 通常用来存储 Session ID，并在后续请求中将这个 ID 发送回服务器，以便服务器识别用户会话。

cookie和session的关系
- Cookie 是 Session 的载体
	- Cookie 中通常包含一个字段（如 sessionid），用来携带 Session ID。
	- 服务器根据这个 Session ID 检索到与之对应的 Session 数据。

Session 和 Cookie 协作的典型工作流程：
1. 客户端首次请求服务器：
- 用户第一次访问网站时，服务器会创建一个唯一的 Session ID，存储在服务器端。
- 服务器将这个 Session ID 返回给客户端，通常通过 HTTP 响应头的 Set-Cookie 字段。
```
Set-Cookie: sessionid=abc123; Path=/; HttpOnly
```

2. 客户端保存 Cookie：
- 浏览器将服务器返回的 Cookie 保存到本地
- Cookie 包括 Session ID 和一些元信息（如有效期、路径、作用域等）。

3. 客户端后续请求携带cookie
- 在后续请求中，浏览器会自动将 Cookie 附加到 HTTP 请求中
```
Cookie: sessionid=abc123
```

4. 服务器端检索 Session：
- 服务器根据请求中的 Session ID，在服务器的存储介质中查找对应的 Session 数据
- 如果找到匹配的 Session，则验证并处理用户请求；否则，可能返回未登录或无效会话的响应。

5. 服务器更新 Session 数据
- 服务器可以根据需要更新或删除 Session 数据，例如更新用户登录状态、清空购物车等。



IO模型

Unix网络编程卷一：网络IO模型分为5类

阻塞型、非阻塞型、复用型、信号驱动型、异步

######################

阻塞型IO模型(blocking IO)

######################

web服务器会使用recvfrom这个系统调用去探测内核中是否获取到数据

客户端浏览器发送一个请求，这个请求通过网络到达nginx服务器的网卡，网卡收到这个请求后，会将这个请求先交给内核，内核中有一个内核缓存区，此时数据被暂存到内核缓存区，然后在将数据从内核缓冲区复制到应用程序的缓冲区

上述过程分为两个阶段，

阶段1：客户端请求通过网络到达服务端的内核缓冲区

阶段2：内核空间收到后将请求复制到nginx的用户空间，并发送一个信号，告知nginx服务，数据准备好了

在第一阶段和第二阶段过程中，应用程序发送了个请求，让内核去帮这个应用程序准备数据，然后应用程序发送这个请求后，就什么都不做，一致等待，直到数据在内核缓冲区被接收后，被复制到用户空间，并发送信号告知应用程序，才会继续处理这个数据，在收到数据前，会什么都不做，一直等待，这个就是阻塞IO


完整描述修订版
阻塞型 I/O 模型的具体过程可以这样描述：

客户端（如浏览器）发送一个 HTTP 请求。
请求到达服务端网卡后，网卡将数据交给操作系统的内核，数据暂时存储在内核缓冲区。
应用程序（如 nginx）调用阻塞型 I/O 操作（如 recvfrom）。
如果内核缓冲区中没有数据，应用程序会进入阻塞状态，等待数据到达。
如果内核缓冲区中有数据，内核会将数据从内核缓冲区复制到用户缓冲区。
数据复制完成后，内核向应用程序发送信号，通知数据已准备好。
应用程序解除阻塞状态，开始处理接收到的数据。
在整个过程中，应用程序在数据未准备好之前会挂起，不做其他操作。这种模型的典型特点是简单但可能导致效率低下。

##############

非阻塞IO模型

###########

当应用程序希望能处理网络资源，请求的时候，会发送一个系统调用，通常是recvfrom或read，这个系统调用交给内核，内核会把数据从网络中拿到，并复制到用户空间，仍然是上述的两个阶段，不同的是，

应用程序把请求交给系统调用后，应用程序本身是非阻塞的，这就意味着应用程序会定期的跑到内核去看，数据是否准备好

在第一阶段，应用程序是不阻塞的，即应用程序调用系统调用，去监听内核中的数据是否准备好，应用程序会在数据未准备好期间反复询问资源是否在内核空间被准备好

非阻塞 I/O 的核心特点
系统调用是非阻塞的：

应用程序调用非阻塞的 I/O 操作（如 recvfrom 或 read 配置为非阻塞模式）时，不会等待数据准备好。
如果数据未准备好，系统调用会立即返回一个状态值，通知应用程序数据尚未准备好，而不会阻塞应用程序。
应用程序主动轮询：

应用程序需要定期或不断地重新调用系统调用，检查数据是否准备好。
这种模式被称为 “轮询式非阻塞 I/O”。
应用程序是非阻塞的：

应用程序在调用 I/O 操作时不会阻塞自身，可以继续处理其他任务。
但如果采用简单的轮询模式，应用程序会消耗大量 CPU 时间进行重复检查。

可以将非阻塞 I/O 的理解归纳如下：

非阻塞系统调用：

系统调用不会让程序挂起，如果数据未准备好，立即返回错误码，通知应用程序数据未就绪。
应用程序的非阻塞行为：

应用程序可以继续做其他事情，或者定期轮询系统调用检查数据是否准备好。
您的理解进一步补充：

系统调用是非阻塞的，但在简单轮询模式下，应用程序会频繁调用系统调用进行检查（即忙等）。
为了避免 CPU 消耗，实际应用中通常结合 I/O 多路复用（如 select、poll 或 epoll），优化非阻塞 I/O 的性能

阻塞 I/O 和非阻塞 I/O 的关键区别在于 应用程序调用的系统调用是否会阻塞。以下是对阻塞 I/O 和非阻塞 I/O 的详细对比解析：


阻塞 I/O 和非阻塞 I/O 的对比
1. 阻塞 I/O
应用程序调用阻塞的 recvfrom：

调用 recvfrom 时，如果数据尚未准备好，应用程序会进入阻塞状态，直到数据准备好并从内核缓冲区复制到用户缓冲区。
在数据就绪之前，应用程序无法执行其他任务，完全挂起等待。
调用流程：

应用程序调用 recvfrom。
如果内核缓冲区中没有数据，recvfrom 阻塞。
一旦数据到达内核缓冲区并复制到用户缓冲区，recvfrom 返回，应用程序继续处理数据。
适用场景：

简单的 I/O 操作。
对实时性要求不高，或者系统资源有限时。
2. 非阻塞 I/O
应用程序调用非阻塞的 recvfrom：

调用 recvfrom 时，如果数据尚未准备好，系统调用立即返回错误码（如 EAGAIN 或 EWOULDBLOCK），而不会阻塞应用程序。
应用程序需要主动轮询 recvfrom 多次，直到数据准备好。
调用流程：

应用程序调用 recvfrom。
如果内核缓冲区中没有数据，recvfrom 返回错误码，应用程序可以做其他任务或再次尝试调用。
一旦数据到达内核缓冲区并复制到用户缓冲区，recvfrom 返回成功，应用程序继续处理数据。
适用场景：

高并发场景，如 Web 服务器。
需要实时响应多个 I/O 操作。

在非阻塞 I/O 中，应用程序调用系统调用（如 recvfrom 或 read），查看数据是否已经在内核缓冲区准备好。如果数据已准备好，系统调用会直接将数据从内核缓冲区复制到用户空间缓冲区并返回。如果数据尚未准备好，系统调用会立即返回一个错误码（如 EAGAIN 或 EWOULDBLOCK），通知应用程序数据未就绪。

非阻塞 I/O 的工作流程
调用系统调用查看数据状态

应用程序调用非阻塞的系统调用（如 recvfrom 或 read）来查看内核缓冲区中是否有可用数据。
系统调用的行为：
如果数据已准备好：
数据从内核缓冲区复制到用户空间缓冲区。
系统调用返回成功，应用程序可以立即处理数据。
如果数据未准备好：
系统调用立即返回一个错误码（如 EAGAIN 或 EWOULDBLOCK）。
应用程序需要稍后重新调用系统调用，或者执行其他任务。
重复调用直到数据就绪

应用程序通常会以一定的时间间隔重复调用系统调用，直到数据准备好。
这种模式被称为 轮询（polling），虽然简单，但可能会浪费 CPU 资源。
数据准备好时的处理

当数据准备好后，系统调用会：
将数据从内核缓冲区复制到用户空间缓冲区。
返回已读取的数据字节数。
应用程序随后可以处理这些数据。

阶段 1 和阶段 2 的行为分析
阶段 1：数据从客户端到达服务端的内核缓冲区
非阻塞性：
应用程序调用非阻塞的系统调用（如 recvfrom 或 read）时，检查数据是否已到达内核缓冲区。
如果数据尚未到达，系统调用立即返回错误码（如 EAGAIN），不会挂起应用程序。
应用程序可以继续其他操作或稍后再次调用系统调用。
阶段 2：数据从内核缓冲区复制到用户缓冲区
阻塞性：
一旦数据准备好，内核会将数据从内核缓冲区复制到用户缓冲区。
这个复制过程是同步的，意味着应用程序需要等待数据完全复制到用户缓冲区后，系统调用才会返回。
为什么阶段 2 是阻塞的？
数据复制是同步操作：

在非阻塞 I/O 中，数据从内核缓冲区复制到用户缓冲区是由应用程序的系统调用直接触发的。
内核必须完成数据的拷贝操作后，才会返回给应用程序。
阻塞的意义：

这是 I/O 操作的核心部分，复制操作完成后，才能确保应用程序可以安全地访问用户缓冲区中的数据。
如果不等待复制完成就返回，可能导致数据不完整或用户态缓冲区状态异常。
复制的数据量影响阻塞时间：

如果数据量较大，复制过程需要的时间会更长。
但这个阻塞时间通常很短，因为数据已经在内核缓冲区中，复制只是一次内存操作，不涉及外部设备。

对比阻塞IO模型和非阻塞IO模型
阻塞IO模型两个阶段都阻塞
非阻塞IO模型，第一个阶段不阻塞，第二个阶段阻塞


#########

信号驱动IO模型

############


应用程序要处理网路数据的时候，会发送一个系统调用，


信号驱动 I/O 模型的核心是：

应用程序通过在内核中注册一个信号处理函数，等待内核在数据准备好后主动通知。
信号触发时，应用程序可以调用非阻塞的系统调用（如 recvfrom）从内核缓冲区读取数据。
数据复制完成后，系统调用返回，应用程序处理数据。

详细分解信号驱动 I/O 的步骤
1. 注册信号处理函数
应用程序通过 sigaction 系统调用向内核注册一个信号处理函数，并为文件描述符启用信号驱动模式（O_ASYNC）。
注册行为的目的是：
当内核检测到指定文件描述符（如 socket）的数据已准备好，会向应用程序发送信号（通常是 SIGIO）。
2. 内核监控数据是否到达
数据未到达：

内核缓冲区中没有数据时，应用程序不被挂起，也无需主动轮询。
应用程序可以继续执行其他任务，或者进入休眠等待信号触发。
数据到达：

当客户端发送的数据到达服务器时，网卡将数据传递给内核，内核将数据存储到内核缓冲区。
数据存入内核缓冲区后，内核向应用程序发送 SIGIO 信号。
3. 信号触发
当内核发送信号时，应用程序的信号处理函数被触发。
信号处理函数的作用：
通知应用程序可以安全地调用非阻塞的 I/O 系统调用（如 recvfrom）读取数据。
4. 应用程序调用非阻塞系统调用
在信号处理函数中，应用程序调用 recvfrom：
如果数据已经在内核缓冲区中准备好，recvfrom 会直接将数据从内核缓冲区复制到用户缓冲区。
数据复制完成后，系统调用返回，应用程序可以开始处理这些数据。
5. 数据处理
应用程序在用户缓冲区中处理从内核缓冲区复制过来的数据。
处理完成后，等待下一个 SIGIO 信号或执行其他任务。

在信号驱动IO中，第一阶段不阻塞，但是第二阶段是同步的，因此还是需要阻塞

###########

异步IO模型（asynchronous IO）

############


异步IO模型中，两个阶段都不阻塞

应用程序在发起 I/O 请求后，不需要等待数据的任何准备过程，也不需要轮询或注册信号处理函数。整个 I/O 操作的完成是由内核负责管理，内核会在操作完成后主动通知应用程序。

异步 I/O 的工作流程
以下是异步 I/O 的典型工作流程：

发起 I/O 请求：

应用程序调用异步 I/O 函数（如 aio_read 或 aio_write），将 I/O 请求发送给内核。
请求包括目标文件描述符、用户缓冲区地址、操作大小等参数。
内核将请求放入队列并立即返回给应用程序。
内核处理 I/O 操作：

内核异步地完成 I/O 操作：
阶段 1：当数据到达时，内核将其存入内核缓冲区。
阶段 2：内核将数据从内核缓冲区复制到用户缓冲区。
I/O 操作完成通知：

内核完成 I/O 操作后，通过以下方式通知应用程序：
回调函数：内核调用用户定义的回调函数。
信号：发送信号（如 SIGIO）。
轮询结果：应用程序可以检查操作状态（通过 aio_error）。
应用程序处理数据：

接收到通知后，应用程序处理用户缓冲区中的数据。


上述的IO模型，应用程序都是通过调用某个系统调用来处理网路IO，一个系统调用调用一个网路IO，如果我们有100个请求，则需要100个系统调用，跟踪100个网络IO，这种情况下，资源消耗很大，为了解决这个情况，出现了多路复用IO模型

#########

多路复用IO模型

#########

多路复用 I/O 的核心思想
应用程序通过一个系统调用监听多个文件描述符（如 socket）。
内核检测这些文件描述符的状态，通知应用程序哪些文件描述符已准备好。
应用程序只需对已准备好的文件描述符进行 I/O 操作，避免了对每个文件描述符的轮询或单独阻塞。

多路复用 I/O 的工作流程
1. 注册文件描述符
应用程序将所有需要监听的文件描述符（如网络 socket）注册到多路复用机制中。
注册方式由具体实现决定：
在 select 和 poll 中，通过提供文件描述符列表。
在 epoll 中，通过系统调用将文件描述符添加到内核管理的事件列表中。
2. 内核监听文件描述符的状态
内核负责监控这些文件描述符，检测它们是否可读、可写或发生异常。
当某个文件描述符的状态变为“就绪”时，内核将该信息返回给应用程序。
3. 应用程序处理就绪的文件描述符
应用程序获取就绪的文件描述符列表后，仅对这些描述符执行 I/O 操作（如 recvfrom）。
未就绪的文件描述符不进行处理，避免了不必要的系统调用。
4. 重复监听和处理
应用程序处理完一次事件后，可以继续调用多路复用机制监听文件描述符的状态变化。

也就是说多路复用IO第一阶段可以同时监听多个请求，但是第二阶段还是会有阻塞，因为是同步特性

关于多路复用系统调用有：select, poll, epoll

select

select 模型
原理：
应用程序将文件描述符添加到一个固定大小的数组中，调用 select 系统调用。
内核遍历数组，检查每个文件描述符的状态。
内核将就绪的文件描述符标记为可读、可写或异常，返回给应用程序。
实现步骤：
创建文件描述符集合。
调用 select，等待事件发生。
遍历返回的集合，处理就绪的文件描述符。
缺点：
文件描述符的数量有限（通常为 1024 或 2048）。
每次调用都需要将文件描述符集合从用户态复制到内核态，开销较大

poll

原理：
与 select 类似，但 poll 使用一个动态的结构体数组存储文件描述符，避免了 select 固定大小的限制。
每个文件描述符对应一个 pollfd 结构体，包含文件描述符及其监听的事件类型。
内核遍历这些结构体，检查文件描述符的状态。
实现步骤：
构建 pollfd 数组。
调用 poll，等待事件发生。
遍历数组，处理就绪的文件描述符。
优点：
支持更多的文件描述符。
缺点：
内核仍需遍历整个数组，效率较低。

epoll



select：遍历， 数组， 最大连接数1024-2048

poll： 遍历，链表， 无限

epoll：回调， 哈希表，无限



零拷贝MMAP

传统网路IO和磁盘IO的标准过程：

用户发送就请通过网络，请求从网络复制到内核空间的socket缓冲区，

然从socket缓冲区复制到用户空间，然后nignx收到用户请求，

假设用户发送的get请求，访问a.html文件，a.html在硬盘上，此时需要将a.html文件从磁盘拉到内存，让nginx进行处理,用于将来封装html的报文头，用户空间是没有能力直接访问磁盘的，因此需要借助于内核通过系统调用完成，内核收到用户空间程序的请求后，会发送DMA（直接内存访问）指令，内核就会从硬盘将数据复制到内核的缓冲区，在复制到用户空间的缓冲区，此时ningx拿到a.html这个文件，拿到这个文件后，封装成html响应报文头，然后发送到内核的socket缓冲区在发送到网络中，

这个过程发生了多次用户空间到内核空间的切换

MMAP就是内存映射技术，内核特性，磁盘文件复制到内核空间后，不复制到用户空间，而是做一个内存空间的映射，将指定用户空间和存放磁盘数据的内核空间做一个映射，这样就可以在用户空间处理内核空间的数据，就好像是软链接一样，将数据封装成响应报文后，直接从socket缓冲区发到网路，整个过程，数据都是在内核空间被处理的

nginx支持MMAP

SENDFILE


DMA复制的SENDFILE






         