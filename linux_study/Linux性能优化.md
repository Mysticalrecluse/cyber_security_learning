# 性能指标
性能优化的两个核心指标
- 吞吐
- 延时

# 什么是性能分析
性能分析，就是找出应用或系统的瓶颈，并设法去避免或者缓解它们，从而更高效地利用系统资源处理更多的请求。
- 选择指标评估应用程序和系统的性能
- 为应用程序和系统设置性能目标
- 进行性能基准测试
- 性能分析定位瓶颈
- 优化系统和应用程序
- 性能监控和告警

# CPU性能
## 平均负载
当系统变慢了，第一件事通常就是执行`top`或者`uptime`命令，来了解系统的负载情况
```shell
[root@master201 ~]# uptime
 20:33:39 up 4 min,  1 user,  load average: 1.86, 0.80, 0.32

# 20:33:39  // 当前时间
# up 4 min  // 系统运行时间
# 1 user    // 正在登录用户数
# load average: 后面的三个数字分别是
# 过去1分钟，5分钟，15分钟的平均负载(Load Average)
```

### 平均负载概念
平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是`平均活跃进程数`，它和CPU使用率没有直接关系

#### 可运行状态
所谓可运行状态的进程，是指正常使用CPU或者等待CPU的进程。也就是我们常用ps命令看到的，处于R状态(Running或Runnable)的进程

#### 不可中断状态
不可中断状态的进程则是处于内核态关键流程的进程，并且这些流程是不可打断的
- 比如最常见的等待硬件设备的IO响应，也就是我们在ps命令中看到的D状态(Uninterruptible Sleep,也称为Disk Sleep)的进程

比如，当一个进程向磁盘读写数据时，为了保护数据一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题

所以，<span style="color:red">不可中断状态实际上是系统对进程和硬件设备的一种保护机制`</span>

平均活跃进程数的理想指标是每个CPU刚好运行着一个进程，这样每个CPU都得到了充分的利用
- 当平均负载为2时
  - 在只有2个CPU的系统上，意味着所有的CPU都刚好完全占用
  - 在4个CPU的系统上，意味着CPU有50%的空闲
  - 而在只有一个CPU的系统上，则意味着有一半的进程竞争不到CPU

### 平均负载多少合理

#### 先判断CPU个数
- 问题1：在uptime命令的结果里，那三个时间段的平均负载数，多大的时候说明系统负载高，或是多小的时候能说明系统负载很低呢

- 我们知道，平均负载最理想的情况是等于CPU个数。所以在评判平均负载时，首先你要知道`系统有几个CPU`，这可以通过`top`或者从文件/proc/cpuinfo中读取
```shell
grep 'model name' /proc/cpuinfo | wc -l
2
```
从这里可以判断出，当平均负载比CPU个数还大的时候，系统已经出现了过载

#### 平均负载的三个数值如何参考
- 问题2：平均负载有三个数值，应该如何参考，该参考哪个

实际上，都要看，三个不同时间间隔的平均值，其实给我们提供了，分析系统负载趋势的数据来源，让我们更全面，立体的理解目前的负载情况

```
打个比方，就好像初秋北京的天气，如果只看中午的温度，你可能以为还在7月份的大夏天，但如果你结合了早，中，晚三个时间点的温度来看，基本就可以全方位了解这一天的天气情况
```

同样的，CPU的三个负载时间段也是这个道理

- 如果1分钟，5分钟，15分钟的三个值基本相同，或相差不大
  - 那就说明系统负载很平稳
- 但如果1分钟的值远小于15分钟的值
  - 就说明系统最近1分钟的负载在减少，而过去15分钟内却又有很大的负载
- 反过来，如果1分钟的值远大与15分钟的值
  - 就说明最近1分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦1分钟的平均值接近或超过CPU个数，就意味着系统正在发生过载的问题，这时就得分析调查是哪里导致的问题，想办法优化

- 问题3：实际生产环境中，平均负载多高时，需要我们重点关注呢?

在我看来，<span style="color:red">当平均负载高于CPU数量70%的时候，</span>你就应该分析排查负载高的问题。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能

当然70%这个数据不是绝对的，最佳实践是，把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势，当发现负载有明显的升高趋势时，比如说负载翻倍了，再去做分析调查


### 平均负载与CPU使用率的区别
- 平均负载指单位时间内，处于可运行状态和不可中断状态的进程数
  - 正在使用CPU的进程
  - 等待CPU的进程
  - 等待IO的进程

- CPU使用率是单位时间CPU的繁忙程度

- CPU使用率和平均负载不一定对等
  - CPU密集型进程，使用大量CPU会导致平混负载升高，此时这两者一致
  - IO密集型进程，等待IO也会导致平均负载升高，但CPU使用率不一定很高
  - 大量等待CPU的进程调度也会导致平均负载升高，此时CPU使用率也比较高

### 案例分析
#### 环境准备
- 机器配置：2CPU，8GB内存
- 预先安装stree和sysstat包
```shell
apt install stress sysstat
```

#### stree和sysstat介绍
- stree是一个Linux系统压力测试工具，这里用作异常进程模拟平均负载升高的场景
  
- sysstat包含了常用的Linux性能工具，用来监控和分析系统的性能，这里会用到这个包的两个命令`mpstat`和`pidstat`
  - `mpstat`是一个常用的多核CPU性能分析工具，用来实时查看每个CPU的性能指标，以及所有CPU的平均指标
  - `pidstat`是一个常用的进程性能分析工具，用来实时查看进程的CPU，内存，IO以及上下文切换等性能指标

#### 场景一：CPU密集型进程
在第一个终端运行stress命令，模拟一个CPU使用率100%的场景
```shell
stress --cpu 1 --timeout 600
```

在第二个终端运行uptime查看平均负载的变化情况
```shell
# -d表示高亮显示变化的区域
watch -d uptime

23:04:29 up 13 min,  4 users,  load average: 1.00, 0.91, 0.59
```

在第三个终端运行mpstat查看CPU使用率的变化情况
```shell
-P ALL 表示监控所有CPU，后面数字5表示间隔5秒后输出一组数据
mpstat -P ALL 5

3时04分38秒  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
23时04分43秒  all   49.85    0.00    0.10    0.00    0.00    0.50    0.00    0.00    0.00   49.55
23时04分43秒    0  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00 23时04分43秒    1    0.00    0.00    0.20    0.00    0.00    0.99    0.00    0.00    0.00   98.8
```

从终端二中可以看到，1 分钟的平均负载会慢慢增加到 1.00，而从终端三中还可以看到，正好有一个 CPU 的使用率为 100%，但它的 iowait 只有 0。这说明，平均负载的升高正是由于 CPU 使用率为 100%

那么是哪个进程导致了CPU使用率为100%呢？可以使用pidstat查询
```shell
[root@ubuntu2204 ~]#pidstat -u 5 1
Linux 5.15.0-52-generic (ubuntu2204.wang.org)   2024年07月19日  _x86_64_        (2 CPU)

23时00分38秒   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
23时00分43秒     0       730    0.20    0.00    0.00    0.00    0.20     1  vmtoolsd
23时00分43秒     0       844    0.20    0.00    0.00    0.00    0.20     1  kworker/1:4-events
23时00分43秒     0      2548   99.80    0.00    0.00    0.20   99.80     0  stress

平均时间:   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
平均时间:     0       730    0.20    0.00    0.00    0.00    0.20     -  vmtoolsd
平均时间:     0       844    0.20    0.00    0.00    0.00    0.20     -  kworker/1:4-events
平均时间:     0      2548   99.80    0.00    0.00    0.20   99.80     -  stress
```

从这里可以明显看到，stree进程的CPU使用率是100%

#### 场景二： I/O 密集型进程

首先运行`stress`命令，这次模拟IO压力，即不停执行sync
```shell
stress -i 1 --timeout 600

16:24:57 up 33 min,  9 users,  load average: 1.27, 0.89, 0.55
```

在第二个终端运行uptime查看平均负载的变化
```shell
watch -d uptime

```

第三个终端运行mpstat查看CPU使用率的变化情况

```shell
root@mystical:~# mpstat -P ALL 5
Linux 5.15.0-100-generic (mystical)     07/19/24        _x86_64_        (2 CPU)

Average:     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
Average:     all    1.25    0.00   41.21    0.06    0.00    0.52    0.00    0.00    0.00   56.96
Average:       0    2.42    0.00   89.11    0.13    0.00    0.20    0.00    0.00    0.00    8.14
Average:       1    0.36    0.00    4.81    0.00    0.00    0.77    0.00    0.00    0.00   94.07
```

为什么 sys 高而 iowait 低
系统调用的高频率：

stress -i 启动的 I/O 工作者通常会进行大量的系统调用，如 read() 和 write()，这些调用会消耗大量的系统态 CPU 时间。因此，%sys 高是因为大量的 CPU 时间花费在处理系统调用上。
低 iowait：

%iowait 低表示 CPU 几乎没有在等待实际的 I/O 操作完成。这是因为 I/O 工作者主要在执行快速的 I/O 操作，这些操作可能是内存到内存的 I/O（如缓冲区操作）或者是一些小而快的 I/O 操作，而不是长时间的磁盘 I/O。

#### 场景三：大量进程场景
使用stress模拟8个进程
```shell
stress -c 8 --timeout 600
```

由于系统只有2个CPU，明显比8个CPU少的多，因而系统的CPU处于严重过载状态，平均负载高度为8.17

运行pidstat来看一下情况
```shell
root@mystical:~# pidstat -u 5 1
Linux 5.15.0-100-generic (mystical)     07/19/24        _x86_64_        (2 CPU)

17:18:00      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
17:18:05        0      1774    0.00    0.20    0.00    0.20    0.20     0  kworker/0:0-events
17:18:05        0      6957   24.06    0.60    0.00   75.35   24.65     1  stress
17:18:05        0      6958   24.25    0.40    0.00   75.35   24.65     0  stress
17:18:05        0      6959   24.06    0.40    0.00   74.35   24.45     0  stress
17:18:05        0      6960   23.86    0.80    0.00   75.15   24.65     1  stress
17:18:05        0      6961   23.86    0.60    0.00   75.35   24.45     1  stress
17:18:05        0      6962   25.25    0.20    0.00   74.35   25.45     0  stress
17:18:05        0      6963   24.25    0.40    0.00   75.15   24.65     1  stress
17:18:05        0      6964   24.65    0.00    0.00   74.95   24.65     0  stress
17:18:05        0      7592    0.00    0.40    0.00    0.20    0.40     1  kworker/1:0-event
```

#### 总结
- 平均负载高，有可能是CPU密集型进程导致的
- 平均负载高并不一定是CPU使用率高，还可能是IO繁忙
- 多个进程竞争CPU，导致平均负载升高


## CPU上下文切换
- 进程上下文切换
- 线程上下文切换
- 中断上下文切换
### CPU上下文概念
CPU运行任何任务前，必须的依赖环境，`CPU寄存器和程序计数器（CPU正在执行的指令位置）`，因此也被叫做CPU上下文

### CPU上下文切换概念
先把前一个任务的CPU上下文（也就是CPU寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，然后再跳到程序计数器所指的新位置，运行新任务

这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行

<span style="color:tomato">任务切换伴随着中断处理程序的调用（一种常见任务）</span>

所以，根据任务的不同，CPU的上下文切换就可以分为几个不同的场景，也就是`进程上下文切换`、`线程上下文切换`以及`中断上下文切换`

### 进程上下文切换
#### 系统调用的过程(特权模式切换)
系统调用开始：用户态指令位置 -- (调用中断程序) --> 内核态代码 
系统调用结束：内核态 -- 恢复为 --> 用户态 --> 继续执行

<span style="color:tomato">所以，一次系统调用的过程，发生了二次CPU上下文切换</span>
- 进程上下文切换，是指从一个进程切换到另一个进程进行
- 系统调用过程中一直是同一个进程运行


系统调用的过程称为特权模式切换，而不是上下文切换


#### 进程上下文切换概念
进程上下文包括两部分
- 进程的虚拟内存，栈，全局变量等用户空间的资源
- 内核堆栈，寄存器等内核空间状态

过程：
保存进程的用户空间资源 ---> 保存进程内核状态和CPU寄存器状态 ---> 加载进程2内核态资源 ---> 刷新进程的虚拟内存和用户栈 

#### 进程上下文切换的潜在问题
 - 问题1：各种（包括用户空间和内核空间）资源的保存和恢复
  - 根据Tsuna测试报告，每次上下文切换都需要几十纳秒到数微秒的CPU时间，因此在进程上下文切换次数过多的情况下，很容易导致CPU将大量时间耗费在寄存器，内核栈和虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。(也会导致平均负载升高)

 - 问题2：TLB快表刷新带来的影响
  - Linux通过TLB（Translation Lookaside Buffer）来管理虚拟内核到物理内存的映射关系（页表子集）。当虚拟内存更新后，TLB也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器进程。

#### 触发进程切换的几种情况
1. 为了保证所有进程可以得到公平调度，CPU时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其他正在等待CPU的进程运行
2. 进程资源不足，被迫挂起（重点关注）
3. 通过睡眠函数sleep，将自己主动挂起
4. 当有优先级更高的进程运行时，为了保证高级优先级仅存的运行，当前进程会被挂起
5. 发生硬件中断时， CPU上的进程会被中断挂起，转而执行内核中的中断服务程序


### 线程上下文切换

#### 线程基本概念
线程是调度的基本单位，而进程则是资源拥有的基本单位。（所谓内核中的任务调度，实际上的调度对象是线程），进程只是给线程提供了虚拟内存，全局变量等资源。
进程与线程
- 当进程只有一个线程时，可以认为进程就等于线程
- 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量资源。这些资源在上下文切换时不需要修改 
- 线程自己的私有资源，比如栈和寄存器需要保存和恢复

同进程内的线程切换，要比多进程的切换消耗更少的资源，这正是多线程代替多进程的一个优势


### 中断上下文切换
对同一个CPU来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生
跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存，全局变量等用户态资源。
中断上下文，其实只包括内核态中断服务程序所必须的状态，包括CPU寄存器，内核堆栈，硬件中断参数等。

### 查看系统的上下文切换情况
vmstat是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析CPU上下文`切换`和`中断`的次数

```shell
root@mystical:~# vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 1476936  14432 240536    0    0   406    48   96  152  1  4 94  1  0
 0  0      0 1476936  14432 240572    0    0     0    23  120  171  0  0 99  0  0
 0  0      0 1476936  14440 240572    0    0     0     5  120  172  0  1 99  0  0
 0  0      0 1476936  14440 240572    0    0     0    21  107  171  0  0 100  0  0
```

- cs(context switch) 是每秒上下文切换的次数
- in(interrupt) 则是每秒中断的次数
- r(Running or Runable) 是就绪队长的长度，也就是正在运行和等待CPU的进程数
- b(Blocked) 则是出于不可中断睡眠状态的进程数

### 查看每个进程上下文切换的情况
```shell
root@mystical:~# pidstat -w 5
Linux 5.15.0-116-generic (mystical)     07/27/24        _x86_64_        (2 CPU)

09:41:09      UID       PID   cswch/s nvcswch/s  Command
09:41:14        0        13      0.20      0.00  ksoftirqd/0
09:41:14        0        14     10.76      0.00  rcu_sched
09:41:14        0        15      0.40      0.00  migration/0
09:41:14        0        21      0.40      0.00  migration/1
09:41:14        0        22      9.16      0.00  ksoftirqd/1
09:41:14        0        28     13.75      0.00  kworker/0:2-events
09:41:14        0        32      1.99      0.00  kcompactd0
09:41:14        0       265      4.78      0.00  irq/16-vmwgfx
09:41:14        0       341      4.38      0.00  kworker/u256:27-events_unbound
09:41:14        0       343      1.39      0.00  kworker/u256:29-events_power_efficient
09:41:14        0       554      1.59      0.00  multipathd
09:41:14     1000       956      0.40      0.00  sshd
09:41:14        0       991     39.44      6.57  kworker/1:1-pm
09:41:14        0       997      3.19      0.00  kworker/1:0-events
09:41:14        0       998      0.20      0.40  pidstat
```

#### cswch
表示每秒自愿上下文切换（voluntary context switches）的次数
- 自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换
  - 比如：I/O，内存等系统资源不足时，就会发生自愿上下文切换

#### nvcswch
表示每秒非自愿上下文切换（non voluntaryu context switches）的次数
- 非自愿上下文切换：则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。
  - 比如说：大量进程都在争抢CPU时，就容易发生非自愿上下文切换

### 关于上下文切换的案例分析
- 使用`sysbench`模拟系统多线程调度切换的情况
  - `sysbench`是一个多线程的基准测试工具，一般用来评估不同系统参数下的数据库负载情况。
  - 这里把它当做一个异常进程，作用是模拟上下文切换过多的问题
```shell
apt install -y sysbench sysstat
```

#### 空闲系统的上下文切换次数
```shell
root@mystical:~# vmstat 1 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 1024208  17368 653928    0    0   101   106   64  100  1  1 98  0  0
```

#### 模拟系统多线程调度的瓶颈
```shell
# 以10个线程运行5分钟的基准测试，模拟多线程切换的问题
sysbench --threads=10 --max-time=300 threads run
```

#### 第二个终端运行vmstat，观察上下文切换情况
```shell
[root@ubuntu2204 ~]#vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 6  0    780 568420  83664 971092    0    0   180   288  218 1270  1  1 98  0  0
 7  0    780 568420  83664 971092    0    0     0     0 92643 983569 29 64  7  0  0
 7  0    780 568420  83664 971092    0    0     0     0 90240 988329 29 65  6  0  0
 7  0    780 568420  83664 971092    0    0     0     0 92775 1024990 29 66  5  0  0
 8  0    780 568420  83664 971092    0    0     0     0 91951 1000145 28 66  6  0  0
```

指标分析

- r列：就绪队列的长度已经到了8，远远超过了系统CPU的个数2，此时肯定有大量CPU竞争
- us(user)和sy(system)列：这两列的CPU使用率加起来上升到了100%，其中系统CPU使用率，也就是sy列高达84%，说明CPU主要被内核占用了
- in列：中断次数也上升到了1万左右，说明中断处理也是个潜在问题

根据上述指标分析可得
系统就绪队列过程过长，也就是正在运行和等待CPU的进程数过多，导致了大量的上下文切换，而上下文切换又导致了系统CPU的占用率升高 

#### 分析是什么进程导致这些问题
使用pidstat，观察CPU和进程上下文切换的情况
```shell
# -w参数表示输出进程切换指标，而-u参数则表示输出CPU使用指标
[root@ubuntu2204 ~]#pidstat -w -u 1
Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:        0       861    0.20    0.00    0.00    0.00    0.20     -  containerd
Average:        0     14833    0.20    0.00    0.00    0.00    0.20     -  kworker/1:0-events
Average:        0     15197   54.65  127.33    0.00    0.00  181.98     -  sysbench
Average:        0     15208    0.40    0.40    0.00    0.00    0.79     -  pidstat

Average:      UID       PID   cswch/s nvcswch/s  Command
Average:        0        13      1.19      0.00  ksoftirqd/0
Average:        0        14     15.45      0.00  rcu_sched
Average:        0        15      0.40      0.00  migration/0
Average:        0        21      0.40      0.00  migration/1
Average:        0        22      0.79      0.00  ksoftirqd/1
Average:        0        29      0.20      0.00  khungtaskd
Average:        0        32      1.78      0.00  kcompactd0
Average:        0        91      0.20      0.00  kworker/0:1H-kblockd
Average:        0       210      2.97      0.00  irq/16-vmwgfx
Average:        0       565      1.98      0.00  multipathd
Average:        0       783     11.09      0.00  vmtoolsd
Average:        0      1218     50.30      0.00  kworker/u256:1-events_power_efficient
Average:        0     14272      0.59      0.00  sshd
Average:        0     14400      0.99     62.18  sshd
Average:        0     14483      0.20      0.40  vmstat
Average:        0     14730     42.77      0.00  kworker/u256:2-events_unbound
Average:        0     14833     19.21      0.00  kworker/1:0-events
Average:        0     14836      5.54      0.00  kworker/0:2-events
Average:        0     15208      0.99      1.19  pidstat
```

从`pidstat`的输出可以发现，CPU使用率的升高果然是sysbench导致的，它的CPU使用率已经达到了181%。但上下文切换则来自其他进程，包括非自愿上下文切换频率最高的pidstat，以及自愿上下文切换频率最高的内核线程kworker和sshd

但这里的切换远远到不了100万次以上，因为pidstat默认显示进程的指标数据，它忽略了线程的数据，需要加上`-t`参数后才能查看到线程的指标
```shell
08:17:13 PM   UID      TGID       TID   cswch/s nvcswch/s  Command
08:17:14 PM     0        13         -      6.00      0.00  ksoftirqd/0
08:17:14 PM     0         -        13      6.00      0.00  |__ksoftirqd/0
08:17:14 PM     0        14         -     30.00      0.00  rcu_sched
08:17:14 PM     0         -        14     30.00      0.00  |__rcu_sched
08:17:14 PM     0        22         -      4.00      0.00  ksoftirqd/1
08:17:14 PM     0         -        22      4.00      0.00  |__ksoftirqd/1
08:17:14 PM     0        32         -      2.00      0.00  kcompactd0
08:17:14 PM     0         -        32      2.00      0.00  |__kcompactd0
08:17:14 PM     0       210         -      3.00      0.00  irq/16-vmwgfx
08:17:14 PM     0         -       210      3.00      0.00  |__irq/16-vmwgfx
08:17:14 PM     0       565         -      1.00      0.00  multipathd
08:17:14 PM     0         -       565      1.00      0.00  |__multipathd
08:17:14 PM     0         -       576      1.00      0.00  |__multipathd
08:17:14 PM     0       783         -     11.00      0.00  vmtoolsd
08:17:14 PM     0         -       783     11.00      0.00  |__vmtoolsd
08:17:14 PM     0         -       793      1.00      0.00  |__HangDetector
08:17:14 PM     0       861       894     34.00      0.00  (containerd)__containerd
08:17:14 PM     0         -       897     17.00      0.00  |__containerd
08:17:14 PM     0         -      1016     35.00      0.00  |__containerd
08:17:14 PM     0      1218         -      2.00      0.00  kworker/u256:1-events_unbound
08:17:14 PM     0         -      1218      2.00      0.00  |__kworker/u256:1-events_unbound
08:17:14 PM     0      1294         -    718.00      0.00  kworker/u256:3-events_power_efficient
08:17:14 PM     0         -      1294    718.00      0.00  |__kworker/u256:3-events_power_efficient
08:17:14 PM     0     14400         -      1.00      1.00  sshd
08:17:14 PM     0         -     14400      1.00      1.00  |__sshd
08:17:14 PM     0     14833         -      6.00      0.00  kworker/1:0-mpt_poll_0
08:17:14 PM     0         -     14833      6.00      0.00  |__kworker/1:0-mpt_poll_0
08:17:14 PM     0     14836         -     16.00      3.00  kworker/0:2-events
08:17:14 PM     0         -     14836     16.00      3.00  |__kworker/0:2-events
08:17:14 PM     0     15197     15198  13660.00  67977.00  (sysbench)__sysbench
08:17:14 PM     0         -     15199  17341.00  74090.00  |__sysbench
08:17:14 PM     0         -     15200  11809.00  71461.00  |__sysbench
08:17:14 PM     0         -     15201   9858.00  78763.00  |__sysbench
08:17:14 PM     0         -     15202  13724.00  67014.00  |__sysbench
08:17:14 PM     0         -     15203  15101.00  61757.00  |__sysbench
08:17:14 PM     0         -     15204  13966.00  69949.00  |__sysbench
08:17:14 PM     0         -     15205  11728.00  63455.00  |__sysbench
08:17:14 PM     0         -     15206   9771.00  77609.00  |__sysbench
08:17:14 PM     0         -     15207  15677.00  60855.00  |__sysbench
08:17:14 PM     0     15216         -      1.00   1879.00  pidstat
08:17:14 PM     0         -     15216      1.00   1898.00  |__pidstat
```

此时就可以看到sysbench的子线程上下文切换次数很很多。

#### 查看中断的详细信息
```shell
# -d 参数表示高亮显示变化的区域
$ watch -d cat /proc/interrupts
           CPU0       CPU1
...
RES:    2450431    5279697   Rescheduling interrupts
...
```

观察一段时间，你可以发现，变化速度最快的是重调度中断(RES)，这个中断类型表示，唤醒空闲状态的CPU来调度新的任务运行。这是多处理器系统(SMP)中，调度器用来分散任务到不同CPU的机制，通常也被称为处理期间中断(Inter-Processor Interrupts,IPI)

这里中断升高还是因为多任务调度问题

#### 每秒上下文切换多少次才算正常
这个数值其实取决于系统本身的CPU性能。
如果系统的上下文切换次数比较稳定，那么数百到一万以内，都应该算正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。

此时应该这样具体分析
- 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题；
- 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈；
- 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。

#### 此次案例使用排查工具总结
```shell
vmstat   # 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析CPU上下文和中断的次数
mpstat   # 是一个常用的多核CPU性能分析工具，用来实时查看每个CPU的性能指标，以及所有CPU的平均指标
pidstat  # 一个常用的进程性能分析工具，用来实时查看进程的CPU，内存，IO，上下文切换等性能指标 
/proc/interrupts      # 查看中断数值
```


## CPU使用率
### 查看CPU使用率工具
- top
- ps
- pidstat

### 查看占用CPU的到底是代码里的哪个函数
使用工具perf，它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析应用程序的性能问题

### perf用法
#### 用法1：perf top
能够实时显示占用CPU时钟最多的函数或指令，可以用来查找热点函数
